  File "ars.py", line 73
    self..params = self.hp.params
         ^
SyntaxError: invalid syntax
2021-04-11 11:12:46.086484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(ars.py:812046): Gdk-CRITICAL **: 11:12:48.519: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-04-11 11:12:49.319105: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-11 11:12:49.320510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-11 11:12:49.354052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.355447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-11 11:12:49.355598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-11 11:12:49.360591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-11 11:12:49.360820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-11 11:12:49.363208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-11 11:12:49.363727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-11 11:12:49.369538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-11 11:12:49.370911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-11 11:12:49.371273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-11 11:12:49.371517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.372870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.374114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-04-11 11:12:49.391109: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-11 11:12:49.391642: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-11 11:12:49.392241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.393455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-11 11:12:49.393570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-11 11:12:49.393891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-11 11:12:49.394031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-11 11:12:49.394166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-11 11:12:49.394299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-11 11:12:49.394466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-11 11:12:49.394709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-11 11:12:49.395100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-11 11:12:49.395556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.397011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:49.397973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-11 11:12:49.398207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-11 11:12:51.036452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-11 11:12:51.036616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-11 11:12:51.036685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-11 11:12:51.037074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:51.038552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:51.040138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-11 11:12:51.041395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13579 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1618139574.234159534, 1.309000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1618139574.235656154, 1.310000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1618139574.235975737, 1.311000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1618139575.494338957, 2.374000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1618139576.202514088, 3.000000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1618139577.117917397, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1618139578.021576959, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[DDPG] Resetting Environment
2021-04-11 11:13:21.049200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-11 11:13:22.024763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[ARS] Step 0 Reward -7.27915 Time 9.40032
[ARS] Step 1 Reward -28.56935 Time 8.36013
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
[DDPG] Quadruped Not Upright
[DDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "ars.py", line 525, in <module>
    learner.learn(path, experiment = args.experiment, start_epoch = args.start)
  File "ars.py", line 286, in learn
    negative_rewards[k] = self.explore(
  File "ars.py", line 170, in explore
    self.current_time_step = self.env.step(
  File "/home/ubuntu/CPGController/src/rl/env.py", line 72, in step
    return self._step(action, desired_motion, last_step)
  File "/home/ubuntu/CPGController/src/rl/env.py", line 94, in _step
    self.quadruped.set_support_lines()
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 982, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
