2021-05-03 07:11:29.548087: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 07:11:29.548130: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620006096.283036900, 1.056000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620006096.284895392, 1.056000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620006096.286296173, 1.057000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620006097.734052689, 2.069000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620006099.090542697, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620006100.178653416, 3.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620006101.281106376, 4.605000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 0: episode_reward:-2.10678002392578 steps:1[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 1: episode_reward:-1.5070202695312536 steps:2[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 2: episode_reward:-1.5739290526123058 steps:4[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 3: episode_reward:-1.6743150028076186 steps:6[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 4: episode_reward:-2.4013309418945274 steps:9[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 5: episode_reward:-2.9057634440917774 steps:11[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 6: episode_reward:-1.840111593750004 steps:12[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 7: episode_reward:-4.1149536296386735 steps:15[00m
[RDDPG] Episode Done
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 175, in train
    state0 = None
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 22, in __call__
    observation = env.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 857, in reset
    rospy.sleep(1.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-03 07:13:27.638963: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 07:13:27.639005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620006214.568236087, 1.082000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620006214.571019812, 1.083000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620006214.571167150, 1.083000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620006216.091258554, 2.138000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620006217.347520198, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620006218.442416424, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620006219.582313883, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 87, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-03 07:21:14.544321: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 07:21:14.544356: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620006681.601954538, 1.380000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620006681.604921335, 1.385000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620006681.605102883, 1.385000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620006683.184789277, 2.507000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620006683.960621551, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620006684.541308687, 3.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620006685.126258961, 3.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-1.5447985281188994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 0: episode_reward:-1.175510164062494 steps:1[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 1: episode_reward:-1.7778881264648616 steps:2[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 2: episode_reward:-1.4448975408935507 steps:3[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 3: episode_reward:-2.437187889282247 steps:6[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 4: episode_reward:-1.5767268024902394 steps:7[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 5: episode_reward:-2.249871449707046 steps:9[00m
[RDDPG] Episode Done
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[92m [RDDPG] 6: episode_reward:-1.2523706237792944 steps:10[00m
[RDDPG] Episode Done
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1217, in step
    rospy.sleep(15.0/60.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-03 07:25:11.194041: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 07:25:11.194076: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620006918.037535878, 1.084000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620006918.040150836, 1.085000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620006918.042418448, 1.088000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620006919.834407981, 2.247000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620006920.863011172, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620006921.945244874, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620006923.089380636, 4.602000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-1.8449449662944821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-4.917141188476597 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:-1.6677209307971954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.6056082714843725 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.4114595666503806 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-3.442751650878894 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.912814464843748 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-1.7922596948242213 steps:15[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000015: mean_reward:-1.5867240905044593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.9312811545410877 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-1.8594256835937413 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-4.058769458251917 steps:23[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-1.4660119426269471 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-1.480947230590815 steps:25[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000025: mean_reward:-1.9252544056005534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.5216073059081663 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.0818329423827917 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-2.4491773763428 steps:30[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1217, in step
    rospy.sleep(15.0/60.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-03 07:49:12.724699: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 07:49:12.724756: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620008359.735790952, 1.315000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620008359.737946858, 1.317000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620008359.738376880, 1.317000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620008361.490834948, 2.511000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620008362.340990856, 3.136000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620008363.432400336, 3.937000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620008364.563975782, 4.737000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:5391.784486808352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:1.8653293778780855 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:5.452890335242435 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.5564837308349737 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:15831.519664380114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.2685764384765643 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:52.29467727866711 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:22927.724231137025 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:21198.92748577086 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-1.7017416350097665 steps:15[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000015: mean_reward:19215.21156785565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:106189.34779507213 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:8.770021249984461 steps:23[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-1.9624703022460577 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.4003961269531326 steps:25[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000025: mean_reward:46623.263355711846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.659824083496141 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:29.262904056181014 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:26668.78491543494 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:140371.84886979705 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:19.927762007336984 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-1.5213551408691781 steps:40[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-03 08:07:56.386540: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 08:07:56.386574: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620009483.093406706, 0.852000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620009483.095392824, 0.852000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620009483.095506628, 0.852000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620009484.655642188, 1.957000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620009485.509562809, 2.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620009486.678624015, 3.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620009487.774148616, 4.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:187183.2586871109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:11.92903897740994 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.4635386437988385 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:7.281301610880971 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:45981.608732525594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.5049014506836385 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:67696.30122897122 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-1.9745087687988798 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:20798.588671929818 steps:15[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000015: mean_reward:17520.342416712203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-1.3514563172607494 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1.9854180786132396 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:0.0598374206479555 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:85499.3648835129 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:25070.486327855164 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:26.649581012914236 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.6516652768554825 steps:32[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:12.650639940849778 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-1.4999219748534953 steps:35[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000035: mean_reward:66686.20186519525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:28579.394013847163 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:42.25881882335384 steps:40[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000040: mean_reward:4830.157383868236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:2.67379056517993 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:14.928147021968385 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:7.327324759068111 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:12.827541185468311 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:219906.1225278811 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:6.817110940597955 steps:55[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000055: mean_reward:15157.61661507673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:4.480673094628973 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-1.9372177297363486 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:8.757151483472809 steps:60[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000060: mean_reward:60982.62097527863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:27139.37960221236 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.099234212402476 steps:65[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000065: mean_reward:22857.143961928618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-1.935038657714608 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-1.3373719791259946 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:10.312534241130615 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-1.5426551103515522 steps:70[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000070: mean_reward:56410.8009814205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:24.49917285957291 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-1.4174902905272706 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-1.403216291381821 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.3100882543944925 steps:75[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000075: mean_reward:59746.59979454569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-1.6207004560544855 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:5.1489559807768455 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-1.9110195839850501 steps:80[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000080: mean_reward:29004.26673318168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-1.7392613896484201 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:112.82473461674694 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.2916325324705984 steps:85[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000085: mean_reward:163585.80343076834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:36853.82646416267 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-1.9561593427737503 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:37.316845913508736 steps:91[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:2008.6993753198763 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-1.594065952636277 steps:95[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000095: mean_reward:24477.12393294115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-1.5438449963377954 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:166.64135873566366 steps:98[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:13.886425081540956 steps:100[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000100: mean_reward:117793.66966692568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:42.65860765129996 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-1.4181615219727928 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:65463.46160424445 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:238.00518757648587 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:62936.45484413573 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-1.4984208577878584 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:95.05695507301434 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:7.88557369445123 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:49343.02816219231 steps:126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-2.0579910546878035 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:28.601192779272115 steps:129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:65072.42527005699 steps:132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:16.295669220174048 steps:135[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000135: mean_reward:203999.39362579468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-1.8810898535160168 steps:136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-1.5022221049805116 steps:137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:0.9404725389576836 steps:139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:0.3462415070106015 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:27.916065183550344 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-1.2562934580078855 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:6.024242995751303 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:1.2796879082454868 steps:148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-2.1149533229988737 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:4.84949044360912 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:20.60531453605303 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-1.7062180932607425 steps:154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-1.746665367187714 steps:155[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000155: mean_reward:24633.14597744185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:373.6774877197359 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:109774.3078550573 steps:164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:8.73980163839944 steps:166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-2.054697777099869 steps:167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:16.61760522645374 steps:170[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000170: mean_reward:7570.00849228608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:176.50754257896946 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-1.415628654784945 steps:173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:21705.07399723109 steps:178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-2.2515887731935758 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:15.74204530526554 steps:181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:13.11459394071149 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:1.2076678659477555 steps:185[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000185: mean_reward:25530.861215509656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:11314.160048099353 steps:188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:2.717713168735635 steps:190[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000190: mean_reward:61702.21264686405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:47.11486690311221 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:27.101683774365625 steps:194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:57029.550022730386 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:40571.63755459253 steps:201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-1.297294284057624 steps:202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:13.635525984427899 steps:204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:4.889719086563269 steps:206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:16.717330182782 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:11.843904989055893 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.65818598339873 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1.4474694760742082 steps:213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-2.2200037536614277 steps:214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-1.6246766699210973 steps:215[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000215: mean_reward:15355.27211633269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:25869.409464305176 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:9.773417085434962 steps:220[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000220: mean_reward:71340.01944596448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-1.7925513442385386 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:12.073530082994612 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:11795.933015414548 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:38221.54576171687 steps:231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-1.661947497558812 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:17432.417861194037 steps:235[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000235: mean_reward:372903.5300514229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:2.142714137780393 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:12905.198173033104 steps:240[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000240: mean_reward:143358.4214126562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-1.3088032587889515 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-1.4346212916258265 steps:242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:7.5070269836244226 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-1.8959239702138073 steps:245[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000245: mean_reward:14366.06913893644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:58678.709214015136 steps:250[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000250: mean_reward:50585.00461293481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:52927.21366158738 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:6285.671546319366 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:146028.30841487486 steps:266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:6.158370101090732 steps:268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-1.4811342143554338 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:61.02055465635222 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:8.875151057502544 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-1.9002712382801643 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:6.5901763846266705 steps:276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-1.5920525703126693 steps:277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:4.3945717375112405 steps:279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:8.721520701526607 steps:281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:4.741605994459927 steps:283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:3.583502834674335 steps:285[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000285: mean_reward:49065.28632778325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:73823.05267538705 steps:289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-1.8896509914565134 steps:290[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000290: mean_reward:180343.63502386853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-1.5593730878906622 steps:291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:47.14473601316949 steps:293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-1.6340008300787154 steps:294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:3.018693863682493 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:3.668109988717614 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:35453.857182073734 steps:301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-1.4775923525388244 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:39176.78238748961 steps:306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:301.1570616243732 steps:308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:187.40402581245158 steps:310[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000310: mean_reward:15721.26514108496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:71868.8487008946 steps:314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:149236.07369859182 steps:318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:9.429274741638332 steps:320[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000320: mean_reward:133356.85739571528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-1.280208728027253 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:17936.20856335393 steps:324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:0.7142118048367521 steps:326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:42891.53373802448 steps:331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:4845.9430557852775 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:18.108386554269185 steps:336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:-1.8913132995622917 steps:337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-1.253300825805904 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:8.84299611913289 steps:340[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000340: mean_reward:69310.68932208276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:33856.602689804226 steps:345[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000345: mean_reward:109571.73828676571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-1.5915436999514705 steps:346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:20217.651061745124 steps:349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:115.81279078613402 steps:351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-1.9698924575198813 steps:352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:7752.377504996393 steps:355[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000355: mean_reward:21244.115614692553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:39.96926395793356 steps:357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-1.140614325317386 steps:358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:9235.43167826272 steps:362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:-1.8325637595215034 steps:363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:12.709581051953217 steps:366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:12422.440271125148 steps:369[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:2.9650670408986817 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:8.833442991177707 steps:373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:11761.998513889826 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:120.27298139472784 steps:379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:5.502761245491258 steps:381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-2.4585380976531352 steps:382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:8.673855575328679 steps:384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:20.609838231720012 steps:386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-2.234345080079691 steps:387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:7.900783748171928 steps:389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-1.5253551220694064 steps:390[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000390: mean_reward:26820.89688994406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:-1.7067069750975286 steps:391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:5969.335890359383 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-1.94187967773352 steps:395[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000395: mean_reward:169675.53769834264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:9.495162687187984 steps:397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-1.9964150483388559 steps:398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:184.66584483190925 steps:400[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000400: mean_reward:2229.2907053263075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:35.36577209709426 steps:402[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 290, in update_policy
    self.agent.actor_target(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 280, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 257, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-03 18:53:06.124388: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 18:53:06.124432: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620048193.288214818, 1.491000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620048193.290201909, 1.492000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620048193.290673074, 1.492000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620048194.647856580, 2.576000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620048195.829355846, 3.513000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620048196.791753252, 4.312000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620048197.770737172, 5.112000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:891.5610960462493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.6668907617187592 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:29095.25466851409 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 290, in update_policy
    self.agent.actor_target(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 280, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 257, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-03 18:58:12.277157: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 18:58:12.277206: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620048499.105264556, 1.363000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620048499.107333859, 1.364000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620048499.108438284, 1.365000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620048500.519609720, 2.478000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620048501.577409284, 3.300000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620048502.543863589, 4.100000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620048503.521418532, 4.900000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:9367.847993385383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:114.06092338302604 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:5.356935258266301 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:32939.817811661174[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 290, in update_policy
    self.agent.actor_target(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 280, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 257, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-03 19:50:39.386594: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 19:50:39.386676: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620051646.023702080, 1.053000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620051646.026228468, 1.055000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620051646.026366256, 1.055000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620051647.466193880, 2.214000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620051648.417344267, 3.000000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620051649.456453553, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620051650.410795942, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:4107.651126594262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:242.89942593435558 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.7453131030273494 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:34.317200358393386 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:56453.575188766255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 314, in update_policy
    value_loss /= len(experiences) # divide by trajectory length
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 336, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-03 19:56:05.067003: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 19:56:05.067090: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620051977.355559954, 249.474000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620051977.364519863, 249.478000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620051977.364706603, 249.478000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 24, in <module>
    env = Env(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 12, in __init__
    self.quadruped = Quadruped(params, experiment)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 489, in __init__
    self.kinematics = Kinematics(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 21, in __init__
    self.front_right_leg = moveit_commander.MoveGroupCommander(
  File "/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py", line 53, in __init__
    self._g = _moveit_move_group_interface.MoveGroupInterface(name, robot_description, ns, wait_for_servers)
RuntimeError: Unable to connect to move_group action server 'move_group' within allotted time (5s)
2021-05-03 19:56:37.429239: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 19:56:37.429354: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620052007.321184912, 275.139000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620052007.329776063, 275.145000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620052007.330024095, 275.145000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620052008.741618434, 275.935000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620052009.097059815, 276.149000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620052010.341130326, 276.549000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620052011.707494391, 276.949000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2408.676995879857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:22.78088689004532 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 304, in update_policy
    current_q = self.agent.critic(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 351, in forward
    q = self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 336, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 20:01:55.814850: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 20:01:55.814905: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620052323.086157069, 373.449000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620052323.094556221, 373.454000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620052323.094815417, 373.454000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620052324.550993846, 374.420000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620052325.253271755, 374.902000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620052326.106635253, 375.504000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620052327.158733469, 376.102000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:818.4749255492427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.8516344584962234 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:76.10934163384695 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.4703597812501474 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.5890771972656978 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:15991.335025275952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 290, in update_policy
    self.agent.actor_target(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 280, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 257, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    value_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-03 20:15:46.984282: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 20:15:46.984319: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620053153.879287714, 1.330000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620053153.881201807, 1.330000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620053153.881317460, 1.330000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620053155.595036454, 2.703000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620053156.235746139, 3.248000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620053156.954788559, 3.848000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620053157.425877377, 4.248000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:79.83187296867891[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.919901659179684 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:120.95113218409008 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.8953927529296875 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.3651544006347736 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:10697.934905122649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 323, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 280, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 257, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 335, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 20:41:12.428277: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 20:41:12.428326: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620054679.451591616, 1.122000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620054679.456954817, 1.126000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620054679.457168252, 1.126000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620054681.024988326, 2.223000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620054682.114462564, 3.004000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620054683.318666036, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620054684.456272630, 4.600000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:1997.8238422621787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:82.84954506992872 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.4981446508789025 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-0.001855439330423092 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:-395.73080803772064[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 323, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 335, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 20:48:05.837584: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 20:48:05.837632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620055092.897280607, 1.138000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620055092.902737944, 1.149000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620055092.902971265, 1.150000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620055094.498998520, 2.452000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620055095.362898911, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620055096.382654904, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620055097.343962736, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:6164.843719125439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:5.527627122770246 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.7726349316406542 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:3.3930855859228974 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:22953.00662260519[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 323, in update_policy
    policy_loss = -self.agent.critic(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 358, in forward
    q = self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 337, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 20:55:51.591305: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 20:55:51.591357: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620055558.571520181, 1.328000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620055558.573553657, 1.328000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620055558.573693756, 1.328000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620055560.093176317, 2.498000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620055561.046390586, 3.316000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620055561.976705833, 4.115000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620055563.003360367, 4.916000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:5236.881220844038[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:8.914477233396845 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:2.098480860146341 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.4376310043945297 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:24638.435628182022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 323, in update_policy
    policy_loss = -self.agent.critic(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 358, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 337, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 21:04:37.866744: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 21:04:37.866800: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620056086.343244580, 1.447000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620056086.348482655, 1.452000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620056086.348762467, 1.452000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620056087.796464225, 2.575000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620056089.027927851, 3.521000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620056090.040476496, 4.321000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620056091.020297946, 5.121000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1654.416895451443[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:229.2763680030277 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.9228397304687448 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:20623.05910419586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 323, in update_policy
    policy_loss = -self.agent.critic(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 358, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 337, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 21:12:59.972576: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 21:12:59.972628: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620056587.141101165, 1.377000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620056587.143122865, 1.377000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620056587.143469952, 1.381000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620056588.675838126, 2.615000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620056589.302009684, 3.038000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620056589.807239835, 3.438000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620056590.310307021, 3.837000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:4120.433586703351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:71473.91096802142 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:49.00098949846637 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:31518.647804412925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 322, in update_policy
    q_val = self.agent.critic(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 358, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 336, in update_policy
    policy_loss.backward(retain_graph=True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 23:47:43.908656: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 23:47:43.908699: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620065870.781476936, 1.257000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620065870.784302572, 1.258000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620065870.784607353, 1.258000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620065872.186987686, 2.415000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620065873.103531835, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620065874.350844338, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620065875.307808681, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:685.6015695441047[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.7918713586425636 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:30565.28189537176 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 317, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-03 23:54:09.229205: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-03 23:54:09.229276: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620066256.342462002, 1.275000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620066256.344192285, 1.276000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620066256.344299525, 1.276000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620066257.795207302, 2.407000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620066258.835238388, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620066259.828639210, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620066261.032735124, 4.802000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:19779.31898853792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.935493378906248 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:33.233365161648415 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:16.515067502055597 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:33816.81711319146[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 317, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 00:54:10.507416: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 00:54:10.507462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620069857.152408853, 1.065000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620069857.156193661, 1.068000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620069857.156413853, 1.068000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620069858.751652543, 2.368000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620069859.778079954, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620069860.718199420, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620069861.682840040, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:16070.467877670515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:73.94608734941855 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:14.713244959074071 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 317, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 333, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 01:01:22.941826: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:01:22.941876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620070316.405700540, 23.505000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620070316.408875709, 23.507000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620070316.409168484, 23.507000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620070317.911553888, 24.668000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620070319.084650476, 25.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620070320.057025478, 26.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620070321.039665308, 27.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:99.03951877838165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:9393.607828666863 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 01:06:14.653204: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:06:14.653363: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
Traceback (most recent call last):
  File "rddpg_torch.py", line 24, in <module>
    env = Env(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 12, in __init__
    self.quadruped = Quadruped(params, experiment)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 485, in __init__
    self.all_legs = AllLegs(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 296, in __init__
    self.front_left = Leg(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 44, in __init__
    self.jta = actionlib.SimpleActionClient(
  File "/opt/ros/noetic/lib/python3/dist-packages/actionlib/simple_action_client.py", line 55, in __init__
    self.action_client = ActionClient(ns, ActionSpec)
  File "/opt/ros/noetic/lib/python3/dist-packages/actionlib/action_client.py", line 521, in __init__
    self.pub_queue_size = rospy.get_param('actionlib_client_pub_queue_size', 10)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/client.py", line 467, in get_param
    return _param_server[param_name] #MasterProxy does all the magic for us
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/msproxy.py", line 121, in __getitem__
    code, msg, value = self.target.getParam(rospy.names.get_caller_id(), resolved_key)
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1109, in __call__
    return self.__send(self.__name, args)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/core.py", line 669, in _ServerProxy__request
    return xmlrpcclient.ServerProxy._ServerProxy__request(
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1450, in __request
    response = self.__transport.request(
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1153, in request
    return self.single_request(host, handler, request_body, verbose)
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1165, in single_request
    http_conn = self.send_request(host, handler, request_body, verbose)
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1278, in send_request
    self.send_content(connection, request_body)
  File "/usr/lib/python3.8/xmlrpc/client.py", line 1308, in send_content
    connection.endheaders(request_body)
  File "/usr/lib/python3.8/http/client.py", line 1250, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.8/http/client.py", line 1010, in _send_output
    self.send(msg)
  File "/usr/lib/python3.8/http/client.py", line 950, in send
    self.connect()
  File "/usr/lib/python3.8/http/client.py", line 921, in connect
    self.sock = self._create_connection(
  File "/usr/lib/python3.8/socket.py", line 808, in create_connection
    raise err
  File "/usr/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
2021-05-04 01:09:36.724446: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:09:36.724495: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620070783.900787738, 1.275000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620070783.902548773, 1.277000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620070783.902778873, 1.277000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620070785.434440628, 2.517000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620070786.590196273, 3.402000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620070787.549148085, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620070788.880656219, 5.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2787.8994590351367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:78.28762402920412 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:101.85525546923391 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.3588967226562485 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:20943.280074953076[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 318, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-04 01:18:41.043609: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:18:41.043657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620071328.723493092, 1.257000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620071328.728754037, 1.260000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620071328.729156102, 1.260000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620071330.342371074, 2.426000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620071331.378387787, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620071332.212815499, 3.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620071333.317377134, 4.602000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:4401.243456848027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:101131.00703493913 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:6190.032976451959[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 312, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-04 01:25:47.239453: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:25:47.239503: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620071757.204398914, 3.895000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620071757.207053932, 3.895000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620071757.207492576, 3.895000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620071758.819379170, 5.138000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620071759.916461158, 6.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620071760.895117536, 6.804000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620071761.859960444, 7.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:162.4772577839621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:116.29623610537342 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.1595475228881835 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:9.739214749988044 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000005: mean_reward:71765.44775389899[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 312, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-04 01:30:00.109801: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:30:00.109849: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620072007.408122036, 0.916000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620072007.411416483, 0.917000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620072007.412283615, 0.917000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620072009.093335534, 2.006000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620072010.171161236, 2.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620072011.270790783, 3.600000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620072012.426978058, 4.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:49.285529309244204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.7489388190917938 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:16035.987588406557 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.871559084472655 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:5815.1616008978635[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 312, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 334, in update_policy
    policy_loss.backward(retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [135, 30]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 01:41:55.766426: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:41:55.766476: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620072722.761680353, 1.221000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620072722.764426612, 1.223000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620072722.764576823, 1.223000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620072724.319456619, 2.482000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620072725.481177008, 3.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620072726.419274423, 4.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620072727.355275628, 5.002000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:354.4953321769623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.3226425185546826 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:3.3883183742016953 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:4.532581881154591 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:2764.183472739865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.9680018078613348 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 315, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 261, in forward
    self.pretrain_cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 201, in forward
    actions, Z, _, _ = self.rhythm_gen(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 187, in forward
    out = self.complex_mlp(z)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 74, in forward
    return apply_complex(self.fc_r, self.fc_i, input)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 46, in apply_complex
    fr(y) + fi(x)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1690, in linear
    ret = torch.addmm(bias, input, weight.t())
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 347, in update_policy
    policy_loss_total.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [100, 12]], which is output 0 of TBackward, is at version 7; expected version 6 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 01:50:19.932111: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 01:50:19.932148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620073229.358150984, 0.938000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620073229.359643582, 0.939000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620073229.359766167, 0.939000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620073230.723412464, 1.733000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620073232.465702365, 2.634000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620073234.017329390, 3.435000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620073235.510699036, 4.233000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:96.06188860478407[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.9423287048339721 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:15.936382013727687 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:24.86252674402938 steps:5[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000005: mean_reward:7538.915405192367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.0966352770995815 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:39769.811681425825 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:27194.108027295995 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:33170.06662380176 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:30052.85901144458 steps:30[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000030: mean_reward:81138.8715624433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1.450777116699229 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:38699.567390188764 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:15091.63557881974 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:990.2358875427656 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:40941.82231978553 steps:55[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000055: mean_reward:4771.37890240026[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:4.29817136269605 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:61328.47953503886 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:17299.121636769472 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:582.1247494585903 steps:75[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000075: mean_reward:5186.761178156142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-1.4828904299316767 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:13343.139018841635 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:13692.046240448479 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:25221.883913193793 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:87287.78016801851 steps:100[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000100: mean_reward:13978.953734992505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-1.689288602539002 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:69819.64017597778 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:48653.57996306676 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:11804.037649862448 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:42096.68377309579 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:110118.52399516033 steps:130[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 562, in connect
    self.read_header()
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 657, in read_header
    self._validate_header(read_ros_handshake_header(sock, self.read_buff, self.protocol.buff_size))
  File "/opt/ros/noetic/lib/python3/dist-packages/rosgraph/network.py", line 357, in read_ros_handshake_header
    d = sock.recv(buff_size)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1022, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 104] Connection reset by peer
2021-05-04 02:09:26.142825: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:09:26.142862: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620074384.826950509, 8.435000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620074384.829574376, 8.436000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620074384.830091062, 8.437000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620074386.330981187, 9.386000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620074387.780875546, 10.294000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620074388.945397065, 11.094000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620074390.114629339, 11.894000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:17854.705107645983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.76068157812501 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:5.387875132402882 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.7723629765625162 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Updating
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
Updating
updating done
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:32986.42144933438 steps:10[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 02:13:40.601590: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:13:40.601637: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620074627.779526864, 1.288000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620074627.786464488, 1.289000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620074627.787753291, 1.290000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620074629.462452309, 2.401000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620074630.341358736, 2.966000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620074631.482900651, 3.765000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620074632.373980128, 4.365000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:875.4974806661132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-596.5795077704729 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-290.4248115234332 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Updating Policy
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:34296.04619270422 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:20614.58666233369 steps:15[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 192, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 22, in __call__
    observation = env.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    rospy.sleep(2.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 02:19:08.346186: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:19:08.346233: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620074955.795017516, 1.478000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620074955.796776868, 1.479000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620074955.796904087, 1.479000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620074957.239381506, 2.413000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620074957.896874004, 2.866000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620074958.722451159, 3.466000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620074959.655460755, 4.065000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1532.1245702644865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-597.794805959667 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-261.15305126952876 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-45.42006349182143 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:5174.459528823608 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-70.21879174804661 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-196.23515954589928 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-685.8505503021024 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-417.2279057655011 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-488.4508845188526 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:8825.33192418847 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-345.46053841293315 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:30267.712087416836 steps:25[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000025: mean_reward:55781.17250912765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:16508.161367769702 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:4320.9761961495 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-359.2090993651137 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:4226.268390012268 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-311.93177929687687 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-534.9196761698986 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-237.6176860351046 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:10195.383686742922 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:614.578669316762 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-253.57293444828198 steps:52[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 130, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1217, in step
    rospy.sleep(15.0/60.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 02:47:48.086793: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:47:48.086841: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620076675.000006128, 1.380000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620076675.002528237, 1.382000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620076675.002627293, 1.382000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620076676.719531078, 2.494000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620076677.465085593, 3.003000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620076678.288888205, 3.602000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620076679.127273432, 4.203000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1824.419394240902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-484.877484937361 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-320.2624773874046 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-201.19856542968628 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-276.3161565677496 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-258.65957109803026 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-592.9240318915627 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:11943.162347244195 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-422.6756544706833 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-162.29966290283812 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:13243.326517568308 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-301.08929233402824 steps:23[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-449.4674345365022 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-410.6484021840348 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:731.1018934185772 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-376.9946596543331 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-109.44174203490715 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-504.04550298865115 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-255.74228637695387 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-655.3736188644301 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-604.8061503151112 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-459.00810826425226 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-146.1538090209942 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-102.88332815551657 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-86.35416815186026 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:20413.404498351472 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-106.16930187988834 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-146.2552530517586 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-462.10064172536175 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-123.14889312744828 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-416.99984213561197 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-71.20402935791282 steps:64[00m
[RDDPG] Resetting Environment
2021-05-04 02:53:31.477353: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:53:31.477527: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-222.82081611775547 steps:66[00m
[RDDPG] Resetting Environment
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
shutdown request: [/joint_position_node_exp45] Reason: new node registered with same name
[DDPG] Waiting for joint trajectory action
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 114, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 857, in reset
    rospy.sleep(1.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620077048.277478926, 176.922000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620077048.280581240, 176.922000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620077048.283502113, 176.923000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 24, in <module>
    env = Env(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 12, in __init__
    self.quadruped = Quadruped(params, experiment)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 489, in __init__
    self.kinematics = Kinematics(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 21, in __init__
    self.front_right_leg = moveit_commander.MoveGroupCommander(
  File "/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py", line 53, in __init__
    self._g = _moveit_move_group_interface.MoveGroupInterface(name, robot_description, ns, wait_for_servers)
RuntimeError: Unable to connect to move_group action server 'move_group' within allotted time (5s)
2021-05-04 02:54:33.784048: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 02:54:33.784106: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620077081.353706099, 0.926000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620077081.355693119, 0.927000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620077081.356904114, 0.928000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620077083.099792902, 1.972000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620077084.388604968, 2.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620077085.598146596, 3.600000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620077086.814809525, 4.400000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:122.53482245520988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-106.6422441406257 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-671.4686103445936 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:3996.696917994505 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-266.6070459488014 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-511.7176724130174 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-346.88170907556844 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-218.0959011230479 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-185.8490412597667 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-142.52913014975783 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-317.415116088869 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-120.3634191284174 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-517.3038848345498 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:4105.995734102757 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-230.74901293945115 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-182.83607714843887 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-361.22931562148324 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-471.35609003477055 steps:32[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:6883.973951674704 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-89.13134252929547 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-150.1651852814736 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-492.8923203612002 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-441.6059567188595 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:297.11894221811554 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-211.88127038573515 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-245.33187695312597 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-121.88960321044678 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:6292.59850910332 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-568.9191014822761 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-181.9237138671887 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-147.6189512281258 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:10292.639367413565 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-423.04769551048764 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-35.198352447509144 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-477.9926632380865 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:14677.945212248049 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-75.16330619812395 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-417.4621140344318 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:1165.858389603299 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-288.92387419749105 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-559.5339521818081 steps:77[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-370.6483323286903 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:5387.659125778613 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-314.115813663625 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:8280.990022351434 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-83.78896005249211 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-514.1123739745185 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:382.7026564146778 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-229.8218520507977 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-106.08504150390675 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-138.41535828687162 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:9601.8978384341 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:1682.0085460705498 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-526.3292421009044 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:5328.634836900884 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:1603.963303956636 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:317.39327568287496 steps:115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-194.80727757441676 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:4004.483026521872 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-405.5301559659134 steps:122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-165.40783886720484 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-121.2007862548837 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-204.91960314940744 steps:125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:3623.4823257634407 steps:129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-512.4983594322642 steps:131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-306.3774938073095 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-93.87372491454494 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-343.6285762389191 steps:136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-175.88116380349675 steps:138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-216.56065434568802 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-88.38845214844082 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-424.03774361592536 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-184.0053043823148 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-357.55529157419346 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-231.66581217535173 steps:148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-266.37429508547206 steps:150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-258.6574400591339 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:11089.785348307552 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-420.453896101096 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-209.42566687928735 steps:160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:2845.649477461854 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:257.15409614632136 steps:166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-292.7820751589081 steps:168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-288.54838821024543 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-52.201423645016526 steps:171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:16432.00189727764 steps:174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:19710.85552952941 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-585.2898203135131 steps:182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:7591.511515016881 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-255.31265974590087 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-309.96692110871095 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-232.63432519530582 steps:190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-329.699793090816 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-62.83509381103575 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-173.17060224301414 steps:194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-242.6478020679413 steps:196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-582.7178190732672 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:8623.534399655302 steps:202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-529.2515846779767 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:4708.433491823233 steps:208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-107.22195874022174 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:1027.187997676958 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-132.26653967285267 steps:213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-705.3316771544211 steps:216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-714.8532697963135 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-83.26445666504499 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-244.3805618695906 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:51174.33804326503 steps:225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-529.4545707777207 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-580.4480717771321 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-267.3261264648857 steps:230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-740.9431579375544 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-162.68075878907868 steps:233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-117.90799859618234 steps:234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-486.92499160768136 steps:236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-199.38050317382633 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-206.6487521972766 steps:238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-433.7672373421334 steps:240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-291.07733064678223 steps:242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-141.7682279052411 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-916.2535851845134 steps:246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-136.51248962402425 steps:247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-48.5810695037988 steps:248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-552.4289991223753 steps:250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-270.6387502668855 steps:252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-421.6204793720231 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:15717.008405631806 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-222.61851599123992 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:4768.523227659785 steps:263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-191.49207275390452 steps:264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:9664.068170348377 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-353.12909876021484 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-260.61286303713604 steps:272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-203.78763867188266 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-143.2595199279816 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-143.5761889343461 steps:275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-243.17585840529765 steps:277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-533.9582352041213 steps:279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-254.94790821737223 steps:281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-70.05496051024525 steps:282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:8297.7343206307 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-263.50009266317204 steps:289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-179.65016796871444 steps:290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:24889.757241050775 steps:294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:5680.659292641163 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-294.71921236115674 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-214.3094868164012 steps:301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:6290.925069085362 steps:306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-128.20214117431476 steps:307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:6045.057139529468 steps:310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-173.2420977172993 steps:311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-672.1938046304044 steps:313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-288.75846649622406 steps:315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:22976.200336613452 steps:319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:-469.2895071248966 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:-555.8253281519496 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-581.3136269113013 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:-159.75406439206614 steps:326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:-214.9222321606328 steps:328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-154.25851538085035 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-41.28183456421798 steps:330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-431.52721196415257 steps:333[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-55.461640319822166 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-126.49054376219966 steps:335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-344.48058605110987 steps:337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-126.83624139403557 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:4043.878765438739 steps:342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:-413.7685574481257 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-181.6176009521968 steps:345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:-1086.3004326178889 steps:347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:-199.46350055571122 steps:349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-116.54435123859213 steps:352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-232.08731439780078 steps:354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-226.56334454351264 steps:355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-625.7228563731143 steps:357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-158.27189831547486 steps:358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-165.87921899409577 steps:359[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:2257.5503410532174 steps:362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-221.0746763915274 steps:363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-321.50644760070924 steps:365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:27522.470902314075 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:-472.69232082529714 steps:373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:11000.654946904304 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-261.89236421665873 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-102.10411093141514 steps:379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-617.046144845418 steps:381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-310.681457077377 steps:383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-364.8988761964829 steps:385[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-472.9888611520636 steps:387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-619.7064525037474 steps:389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-37.12992989966435 steps:391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:3088.88992594009 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-331.5901779197414 steps:396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:1604.4526055667425 steps:399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:-510.44620376267557 steps:401[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:36608.45854056779 steps:423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:16058.850993188596 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:60827.092417074986 steps:449[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:11821.562533592145 steps:454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:13639.30163487089 steps:459[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:5900.366657760486 steps:464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:5215.195860423254 steps:469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:7086.510290222608 steps:474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-162.08832503623998 steps:479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:17685.20436539049 steps:495[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:9433.880197410266 steps:504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:5234.74896563529 steps:512[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:3198.073702685382 steps:521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:3245.567189588152 steps:529[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:12577.246986415978 steps:538[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:10673.001256525273 steps:550[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:20416.36378323588 steps:562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:20373.82368592329 steps:572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:12098.540356261181 steps:579[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:12582.673970050513 steps:589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:18748.209561019023 steps:600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-138.72242364631202 steps:604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-115.89367752929701 steps:608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:-133.47287014108576 steps:612[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:3823.963911629744 steps:627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:1434.3156047636312 steps:638[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:7958.818952072301 steps:644[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:25426.065764524832 steps:664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:18647.751072117426 steps:678[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:-93.04200216896919 steps:685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:6644.96705028856 steps:693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-178.82201517743349 steps:699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:-41.481581793567585 steps:710[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:6885.455268064313 steps:722[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:8519.248787668404 steps:734[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:28641.053927187855 steps:744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:10230.590156690432 steps:752[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:13190.688234056553 steps:762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:19854.90922201255 steps:770[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-206.5177263253525 steps:776[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-2829.955114654879 steps:791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-97.80400901606748 steps:795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:6230.776935199501 steps:799[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:24580.403915970073 steps:810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:19184.817125780126 steps:819[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:50981.26946985073 steps:832[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:194707.98476612577 steps:983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:12764.586943682001 steps:995[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:1533.8837677605566 steps:1008[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:7287.344073969253 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:357.0424442000741 steps:1028[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:8158.1305805301945 steps:1048[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:14379.29723215474 steps:1066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:28075.53484403311 steps:1078[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:8562.427078831895 steps:1089[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-61.14432758500094 steps:1092[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:157365.01467860112 steps:1292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:-137.19264072847642 steps:1295[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:7227.708465489055 steps:1303[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:227079.02377929687 steps:1503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:32312.155860455794 steps:1519[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:34842.646787531514 steps:1535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-99.22117362194389 steps:1539[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-2046.7480785320336 steps:1548[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:190.2604484468673 steps:1559[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:9877.910990058623 steps:1566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:26655.14843372475 steps:1575[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:34537.81559369884 steps:1588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:2236.7918001163357 steps:1598[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:191.03913871470814 steps:1604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-189.59547849499356 steps:1614[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Updating Policy
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:312436.89277712494 steps:1814[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:12706.494536160146 steps:1822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:5118.093170145003 steps:1835[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:42300.96018139583 steps:1850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:12185.673912355158 steps:1855[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:20877.64564474786 steps:1864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:16729.157837029874 steps:1871[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:27893.637323325518 steps:1887[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
2021-05-04 12:59:25.322712: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 12:59:25.322975: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-05-04 13:00:14.325690: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:00:14.325739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620113501.592114230, 62.029000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620113501.598608360, 62.032000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620113501.598709244, 62.032000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620113503.512998793, 62.945000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620113504.751092903, 63.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620113505.432289739, 64.007000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620113506.237514449, 64.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1157.6134677658035[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:17611.850098424962 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-396.96168925701465 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-484.95307672701347 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-96.85408593749891 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-77.34208251953177 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-147.16944378661609 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 314, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 336, in update_policy
    policy_loss.backward()
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-04 13:06:45.937981: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:06:45.938017: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620113813.289006925, 1.116000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620113813.291766971, 1.118000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620113813.292011009, 1.118000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620113814.850826626, 2.133000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620113816.272063121, 3.000000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620113817.557558387, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620113818.825810684, 4.600000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:756.8055723758283[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-664.8161435660701 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-691.1982902793518 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-288.5565187522129 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-81.316551635741 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-516.9676497486041 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in EluBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 314, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 287, in forward
    action, robot_enc_state, z = self.cell(
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/Desktop/CNS/DDP/src/layers/torch_l.py", line 258, in forward
    rs_r = self.robot_state_enc(self.robot_enc_state)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 477, in forward
    return F.elu(input, self.alpha, self.inplace)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 1227, in elu
    result = torch._C._nn.elu(input, alpha)
 (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 336, in update_policy
    policy_loss.backward()#retain_graph = True)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/shandilya/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.
2021-05-04 13:20:42.041830: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:20:42.041886: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-05-04 13:23:09.830357: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:23:09.830397: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620114796.719966116, 1.042000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620114796.723154944, 1.045000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620114796.723295391, 1.045000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620114798.248942648, 2.164000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620114799.429658893, 3.002000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620114800.507592802, 3.802000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620114801.542857469, 4.603000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:665.6388646424573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-312.75856678214996 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:243.8706258738826 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:19915.749425672147 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-365.8895598251662 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 156, in train
    self.update_policy()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 238, in update_policy
    start = time.perf_counter()
NameError: name 'time' is not defined
2021-05-04 13:27:34.840964: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:27:34.841015: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620115062.399940934, 1.146000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620115062.404723776, 1.155000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620115062.405258278, 1.156000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620115064.016092967, 2.216000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620115064.914675622, 2.809000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620115065.786992784, 3.408000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620115066.429247299, 3.808000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-173.31352596398835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-100.5466450195299 steps:1[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-259.13573668046837 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-575.5324602961402 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:2096.2872830600936 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-248.43687939452596 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-287.65971630859315 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 3.25616
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-20.11053491113137 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-103.9444161058523 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.95366
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-116.2352833412819 steps:23[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.75133
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-146.60021381006322 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.32343
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-160.8634620058292 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.92043
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-133.16577859008478 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-143.18603701298179 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.66823
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:4289.476230063934 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.20726
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:6710.992867201611 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.73009
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:17586.481139730226 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.97870
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:3318.5238710895455 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:4469.216596594433 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.64892
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:4029.448273193282 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.04644
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:2984.514922093608 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.23297
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:3579.7027051901887 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-158.76540319621915 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.53863
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-217.69405686610355 steps:77[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.76020
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-138.0495282121596 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:6211.190595974148 steps:83[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.52898
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:14883.533406524293 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.18240
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-129.80811755200654 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:13140.114134101947 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.55718
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:9511.709100723678 steps:98[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.40869
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:6857.917609309164 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.43177
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:6799.046273900292 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:13178.12229744108 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.10184
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:2067.51160055456 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-247.02494070088636 steps:114[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.97429
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-164.8688285251772 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-218.3629531973408 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.43844
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-270.8974874748637 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:6695.118832465937 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.39513
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-185.03279524410917 steps:125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:162.66440796520538 steps:128[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.35544
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:11719.596239072878 steps:131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-339.15811782380723 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.43790
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:10318.132766790623 steps:137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.80126
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:1673.2423108120913 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-340.2690786132289 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-323.9621168623556 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-271.5378586425836 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.81851
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-142.24956631470488 steps:145[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:7097.900315622462 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.25280
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-190.35870251465863 steps:150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-186.23915423583816 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-359.32621411134795 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-363.9868710937124 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-349.3289853516003 steps:154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.95841
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-279.1541706543119 steps:155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-233.19184185792267 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-386.4943964843374 steps:157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-143.07746359253687 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-359.3916860351459 steps:159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.13990
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-132.79067590330615 steps:160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-199.00942578124577 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:27.41670636395805 steps:164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.60411
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-380.07420703118953 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-437.02795849609583 steps:166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-340.1653462985694 steps:168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.19038
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-479.95394092643994 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:12023.236186329026 steps:173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.01963
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-203.43377971734958 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-253.5721801260231 steps:177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-394.2856128738164 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.29165
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-296.9523279828226 steps:181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-163.38005290866133 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.28024
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-340.5339634899714 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-334.5567415941681 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-341.88306424750624 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.97078
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-248.87680655613445 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-285.6900429715155 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.56154
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-300.4529810851303 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-267.648673731807 steps:197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-406.75003995676786 steps:199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.16111
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-249.0748824261055 steps:201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-321.84007375995486 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.45773
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-131.9614984959877 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-208.683709597155 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-337.9066372775564 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.06839
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-315.2141964030933 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-173.33537727068267 steps:213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.21713
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-288.6717499410129 steps:215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-170.51600343561196 steps:217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-273.45830105177964 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.39333
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-162.6220476385228 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-273.1841590976527 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.13636
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-290.9418908460671 steps:225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-276.4244242604584 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-61.46349437355516 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.04458
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-207.3854695407056 steps:231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-310.9272595541736 steps:233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.99484
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-117.36164097111472 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-235.42536874115564 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-260.2319629048822 steps:239[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.13477
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-340.9755545509125 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-292.449729629932 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.01518
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-270.5255306162984 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-268.01876893192104 steps:247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-304.84599659616197 steps:249[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.86411
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-272.820634583804 steps:251[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1217, in step
    rospy.sleep(15.0/60.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 13:49:42.931054: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:49:42.931103: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620116389.900293191, 1.090000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620116389.903165709, 1.092000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620116389.903501170, 1.092000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620116391.436118175, 2.154000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620116392.285906991, 2.800000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620116393.432899000, 3.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620116394.521878667, 4.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:6352.298474408503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-405.7542963971527 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:3682.1072418932854 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-121.72213787841866 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-240.52749737549323 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-121.3113931274418 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-205.01366406249565 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-128.15677221679965 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-630.2210873936788 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-80.38568835449267 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-157.62266839599468 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-66.70131481933844 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-638.8068824611462 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-694.1399100259814 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-150.97095037706885 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:11449.009322289468 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-283.7624096627156 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-378.1617672118987 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-183.24294366455462 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:13534.1436844989 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-377.613388756775 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-267.5926167439174 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-128.4053293762189 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-152.20112200926522 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:7257.185661043537 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-94.96406860351317 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:212.7136909552949 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-267.5162698233017 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-257.50364608978794 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-376.43162937225105 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-98.65363903808647 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-58.864989669797446 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-292.3485288453369 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-269.03589746093894 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-644.8378008321777 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-396.1726571485547 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-217.92217187500037 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-805.0768513549012 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-555.0833643497622 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-383.6931199219834 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-585.2210592935229 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-316.25670962368207 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-321.2675195738422 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-68.19567979431098 steps:77[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    #rospy.sleep(2.0)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 13:58:05.442308: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:58:05.442362: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620116892.596757197, 1.000000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620116892.599039673, 1.001000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620116892.599374955, 1.001000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620116894.013774562, 2.030000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620116895.131120978, 2.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620116896.230236019, 3.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620116897.311753740, 4.400000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[]
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[]
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 88, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 22, in __call__
    observation = env.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 965, in reset
    A, B = AB
ValueError: not enough values to unpack (expected 2, got 1)
2021-05-04 13:59:41.892961: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 13:59:41.892995: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620116988.339703922, 1.004000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620116988.342987847, 1.005000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620116988.343338505, 1.005000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620116990.188908486, 2.257000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620116991.179739614, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620116992.289250066, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620116993.377244276, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:31154.018759291474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:8158.70338909847 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:27187.075344285506 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:22879.549483034178 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:40187.24205738 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:4873.515501589055 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:4293.054029262193 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:24649.565458131747 steps:32[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:22523.464315406618 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:5101.274457143429 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:2932.5254138157493 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:11480.279430831137 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:11620.463864692496 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:10137.841031473787 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:5240.9491704114935 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:6154.47617738491 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:4352.99962198431 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:6545.652555579224 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:26887.023478396906 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:7557.615319770049 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:3844.833504170856 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:17090.581136231194 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:21935.134709322767 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:9862.450032006256 steps:83[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-123.43721740724071 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:17423.371366840798 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:42796.22994367374 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:2409.150938881294 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:4220.726446614157 steps:98[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-246.16518024852112 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:21355.889712121294 steps:108[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 10.52126
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.77425
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:26514.004994096522 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.97662
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:30017.97154698303 steps:132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:5922.697025847687 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.60221
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:39765.24990670321 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.36009
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:28286.076265118583 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.73382
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.30744
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:21514.354100835502 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:1945.756108395894 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.74436
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:7002.773904374634 steps:181[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.95640
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:34725.274731306235 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:8138.46340636908 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.45322
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:5462.457347256696 steps:204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:11968.421214808388 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.86574
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:3776.439634373421 steps:214[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07723
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:7923.520271567668 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.04508
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:17148.993028991652 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:6440.471740877716 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.50675
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:10290.850211075254 steps:240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:1750.3700463259731 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:2011.1161109473471 steps:249[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 1.68316
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 14:08:16.497485: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 14:08:16.497524: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620117503.588179977, 1.225000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620117503.593651838, 1.227000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620117503.594087600, 1.227000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620117505.109905652, 2.304000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620117506.240039389, 3.084000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620117507.379898388, 3.885000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620117508.463548773, 4.684000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:18313.66800707766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:10326.286360359993 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:1776.4988793814302 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:12388.13794999711 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:6454.567056474539 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:2819.8827851869783 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:3559.716074722042 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:18309.18552602581 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:52572.83811720019 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:4762.704506222974 steps:32[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:8379.822790048938 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:14206.54282311995 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:29159.886565010183 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:3335.620394132768 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:15996.84612777935 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:21427.963575014706 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:5006.822920010278 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:15969.091275711717 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:55470.87728307046 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:16211.994411453676 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:15692.528527686467 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:89918.64969709575 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:10521.4711351621 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:13328.378854988649 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:7769.830755294766 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:6503.609060319815 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:17224.99084786401 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:6238.232719508508 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:5501.031066834199 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:2192.9301119707097 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:1508.9132965041817 steps:102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:2371.647595515136 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:13551.5004950996 steps:108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:9715.226254104316 steps:111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:7038.934854292181 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:8476.932996762222 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:23893.57052866758 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:1349.0174939235233 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:6579.414793535035 steps:129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:12616.027175391038 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:8143.781269402647 steps:136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:5905.75414360126 steps:138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:6556.549283075453 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:8165.597151824458 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:10522.116778693133 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:3705.804382873383 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:10361.56272541785 steps:154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:781.529281728368 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:2128.8279012257276 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:12859.181199295463 steps:160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:12669.438678376095 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:7472.463107455854 steps:167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:1556.5173339652285 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:3370.6917008169976 steps:173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-94.87903906251557 steps:174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:3385.0932609700913 steps:176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:5516.994669857575 steps:178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:2436.9701519948526 steps:181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:1617.0711532701396 steps:184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:1014.899053147152 steps:186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:10549.463583018905 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:5368.61323644176 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:2884.6691302420268 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:5066.604361153111 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-111.75917724609162 steps:199[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-74.83110107422968 steps:200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:5632.659496831703 steps:202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:19616.50390258208 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:2152.0825040314394 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:51785.18420591032 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:30937.832805024438 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:8547.587844538546 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-124.29900000000468 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:4491.432530920721 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:19584.320175529574 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:48227.61327577682 steps:236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:36881.111038277464 steps:242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:2278.2204512796966 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:5248.046862447512 steps:248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:65528.22024816038 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:2286.7473696960246 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:3102.2975175702936 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:5277.966181586242 steps:260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:16166.569162987922 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:36146.06691190753 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:12903.038860347979 steps:272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:60934.49537238866 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:8666.604713730134 steps:284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:10823.507095802737 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:28576.79593991367 steps:292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:38231.17328954655 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:11470.170348270263 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:20044.94633767936 steps:303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:1838.5059293103675 steps:306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:5456.624546139313 steps:308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:12379.595750750674 steps:314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:2926.0032978309596 steps:317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:21613.96921040136 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:3616.5513970893426 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:18681.087138108887 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:25934.421273722674 steps:335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:3706.563014844055 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:3405.121643470197 steps:340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:1357.042384332862 steps:342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:7729.538636220984 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:7848.037010119568 steps:348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:2691.814996904165 steps:350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:1069.2417783134297 steps:352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:3746.8110250453956 steps:354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:4001.334342669578 steps:356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-121.30327978515005 steps:357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:9911.290195148373 steps:359[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:1184.948233371431 steps:361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:1538.862073240331 steps:363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:13487.588129642323 steps:367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:7483.156641079565 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:17226.24824803049 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:5222.055652621012 steps:380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:36176.91995600057 steps:388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:10930.868663821802 steps:391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:22802.271777980975 steps:398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:12091.877235058697 steps:403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:10459.680349857583 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:49262.285044576296 steps:417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:35816.58588597369 steps:426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:39073.42908116581 steps:434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:6177.911639959129 steps:439[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 126.16919
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:65063.36779325171 steps:457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:14529.7042394694 steps:462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:47304.86126381304 steps:487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:61837.221039185366 steps:497[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 139.92738
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:24220.81499867871 steps:517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:7805.910630104086 steps:520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:19531.697526921398 steps:527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:8320.298062147032 steps:536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:14649.94391863424 steps:542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:10237.929906789765 steps:547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:13407.076304063708 steps:549[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 143.24025
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:7749.78664081566 steps:554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:6812.510308137359 steps:557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:70973.40793872703 steps:585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:20206.473932588404 steps:592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:6807.838933112401 steps:594[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 136.49240
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:8138.200521960166 steps:605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:5000.697123240387 steps:610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:46571.10100576153 steps:617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:4303.445042387795 steps:621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:23103.366429263675 steps:637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:9283.956793072655 steps:639[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:7610.16130452961 steps:644[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 125.20659
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:9362.824663852482 steps:651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:19816.59198569032 steps:656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:8947.751523573002 steps:658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:15899.086145731939 steps:665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:20055.79230787811 steps:677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:53054.17808251063 steps:694[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 108.62613
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:18049.086782888317 steps:701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:27211.407264355646 steps:707[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:6033.41123355036 steps:709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:25912.098832637694 steps:726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:69910.29747617044 steps:741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:4830.885827569135 steps:744[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 128.93651
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    ]
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 14:34:35.715633: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 14:34:35.715669: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620119095.483666727, 10.876000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620119095.486611831, 10.879000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620119095.487007790, 10.879000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620119097.091501912, 12.012000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620119098.502998813, 13.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620119099.569460214, 13.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620119100.651178860, 14.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
24620868.30552101
1729219.2616329228
1729192.2377367998
1729115.0246499134
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
11471054.794662757
5694831.051561017
5694836.172483055
5650209.907905332
7041035.210995048
8690969.770637702
6626180.0417823205
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
22905417.491662443
-1.0
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:72.38346205930867[00m
[RDDPG] Resetting Environment
25230179.593132596
6169463.172559559
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-225.8400074801545 steps:3[00m
[RDDPG] Resetting Environment
7824291.344355214
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-304.23355902043807 steps:5[00m
[RDDPG] Resetting Environment
17069079.68570858
555918.5151912465
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-368.91899812636836 steps:8[00m
[RDDPG] Resetting Environment
21620143.359359168
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-101.56129040046514 steps:10[00m
[RDDPG] Resetting Environment
1440981.8664754727
3870401.45834894
2815550.9639397943
24837316.213221572
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-260.2579952879228 steps:15[00m
[RDDPG] Resetting Environment
4973426.178558877
5438962.99838817
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-241.82269534571088 steps:18[00m
[RDDPG] Resetting Environment
7375758.230776135
25106579.870452527
25112799.826486815
12477396.853652272
-374159.18677257746
146700.59516018548
124658.6107105444
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-485.3903379556433 steps:26[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-109.25639513672286 steps:27[00m
[RDDPG] Resetting Environment
5318006.726891714
5285486.93216363
5267340.873450242
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-252.93453643904132 steps:31[00m
[RDDPG] Resetting Environment
1839897.199281974
8580027.643070944
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-214.45354289759865 steps:34[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-117.78622423828568 steps:35[00m
[RDDPG] Resetting Environment
8207964.739521291
5647462.258801436
6071949.776566938
22802060.36169858
3525928.2715726346
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-432.1044626271739 steps:41[00m
[RDDPG] Resetting Environment
7044980.0547767
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-275.8162280171575 steps:43[00m
[RDDPG] Resetting Environment
18075234.74655112
8129017.47046557
8129069.820114419
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-372.6502916649197 steps:47[00m
[RDDPG] Resetting Environment
4126580.515845478
4398176.879341525
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-171.38900814894328 steps:50[00m
[RDDPG] Resetting Environment
9761055.904910795
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-186.03519910825932 steps:52[00m
[RDDPG] Resetting Environment
2346577.1878501093
606100.2115106148
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-76.51831577236865 steps:55[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-237.54297375000334 steps:56[00m
[RDDPG] Resetting Environment
10656132.397856457
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-82.2301737602378 steps:58[00m
[RDDPG] Resetting Environment
10491839.906891014
1278043.7386050338
1276263.9944667816
1275730.416850492
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-368.56803097566853 steps:63[00m
[RDDPG] Resetting Environment
3956713.268123066
2043498.764086784
21656181.507342473
21857846.828806307
5279747.725096555
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-459.87696419095505 steps:69[00m
[RDDPG] Resetting Environment
6721402.475262506
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-233.29740668616856 steps:71[00m
[RDDPG] Resetting Environment
1368272.8579924917
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-113.84579012409317 steps:73[00m
[RDDPG] Resetting Environment
15496072.128166568
15802464.407950494
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-306.5115781787838 steps:76[00m
[RDDPG] Resetting Environment
8107519.622590542
7854368.496790102
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-143.82001667361652 steps:79[00m
[RDDPG] Resetting Environment
8741895.704740759
1479197.4477660244
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-227.131212821466 steps:82[00m
[RDDPG] Resetting Environment
19162609.99318122
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-56.19464839345086 steps:84[00m
[RDDPG] Resetting Environment
12187143.68608074
25802126.72140126
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-96.50068958369457 steps:87[00m
[RDDPG] Resetting Environment
12640882.908970337
9562043.560551971
7440715.730594316
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-478.7603071830157 steps:91[00m
[RDDPG] Resetting Environment
4890743.287788629
6124343.886831237
6294016.496356423
13310136.802012548
10823355.962593455
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-628.0796110789337 steps:97[00m
[RDDPG] Resetting Environment
9434962.663113795
7484569.54545526
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-222.97061702848941 steps:100[00m
[RDDPG] Resetting Environment
5099925.335429868
9943240.158835184
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-349.3070779192897 steps:103[00m
[RDDPG] Resetting Environment
5246863.224075574
12204419.441868553
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-234.00979870153498 steps:106[00m
[RDDPG] Resetting Environment
13670815.670575686
13533187.164123852
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-315.33454600226287 steps:109[00m
[RDDPG] Resetting Environment
9627381.633260943
11579181.863808755
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-181.32704811032147 steps:112[00m
[RDDPG] Resetting Environment
467145.06308845774
5853172.5095765935
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-188.58719136762068 steps:115[00m
[RDDPG] Resetting Environment
6132245.148163538
12468023.589274816
13227121.366608975
10240862.287759174
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-394.8186834706271 steps:120[00m
[RDDPG] Resetting Environment
18717999.512273595
8034071.582264475
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-177.0766385410049 steps:123[00m
[RDDPG] Resetting Environment
14760774.23745406
7064570.235089029
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-232.9089049517599 steps:126[00m
[RDDPG] Resetting Environment
4782536.521470215
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-161.68233191409942 steps:128[00m
[RDDPG] Resetting Environment
3708325.3007108895
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-107.14010640173211 steps:130[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-101.19306652342928 steps:131[00m
[RDDPG] Resetting Environment
13806503.498871833
11875352.202632394
19435178.017007656
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-303.2630706603267 steps:135[00m
[RDDPG] Resetting Environment
11193436.25657866
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-197.85600584604643 steps:137[00m
[RDDPG] Resetting Environment
3357007.896698511
2742323.889989675
8251826.8177605
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-361.4985236233525 steps:141[00m
[RDDPG] Resetting Environment
2799258.6755581005
16060349.570792079
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-115.27928554559745 steps:144[00m
[RDDPG] Resetting Environment
8399622.848024718
11828005.018132562
10176642.838924011
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-283.4267151341709 steps:148[00m
[RDDPG] Resetting Environment
8346272.3069966845
9004701.141516512
8521347.836520793
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-514.0984912261985 steps:152[00m
[RDDPG] Resetting Environment
5893788.870845374
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-148.32273227660534 steps:154[00m
[RDDPG] Resetting Environment
9878559.909032017
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-147.88380555251706 steps:156[00m
[RDDPG] Resetting Environment
16364127.658782158
13652184.95573769
11907079.15444826
5630804.37218088
-1128535.8684623428
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-357.4025308154916 steps:162[00m
[RDDPG] Resetting Environment
6648501.694968383
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-226.52301642263842 steps:164[00m
[RDDPG] Resetting Environment
12039864.92294718
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-254.0980714985453 steps:166[00m
[RDDPG] Resetting Environment
3425019.9459663057
13209837.844917249
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-304.75100266664106 steps:169[00m
[RDDPG] Resetting Environment
5703845.712219745
5298961.272200969
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-220.57651145974646 steps:172[00m
[RDDPG] Resetting Environment
3987428.663135432
454087.5452371114
454092.6426320779
454089.0035117982
454098.03987883334
25977040.38971173
39541220.4131029
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-199.58632869164856 steps:180[00m
[RDDPG] Resetting Environment
5395791.767953613
10910879.051046109
2009129.2443820331
-737136.6471679467
-616990.2278455156
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-616.7317486773487 steps:186[00m
[RDDPG] Resetting Environment
8983900.662093958
7104854.092331061
3547950.074056573
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-411.0504409405348 steps:190[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-163.20241540040936 steps:191[00m
[RDDPG] Resetting Environment
2232499.96665129
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-181.98104483959375 steps:193[00m
[RDDPG] Resetting Environment
11515600.846331853
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-189.7825986687156 steps:195[00m
[RDDPG] Resetting Environment
2740213.610972895
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-208.5931173650739 steps:197[00m
[RDDPG] Resetting Environment
8327971.40260046
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-189.65650003774653 steps:199[00m
[RDDPG] Resetting Environment
1682968.531566839
1441117.4534282424
1643487.2957911403
11977906.831001436
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-627.2974490455994 steps:204[00m
[RDDPG] Resetting Environment
8035346.692778144
8065529.988286197
6487481.239456051
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-290.96193805367267 steps:208[00m
[RDDPG] Resetting Environment
6254327.396769574
3860178.439757423
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-184.6051719843212 steps:211[00m
[RDDPG] Resetting Environment
18168102.860157527
16844100.372760087
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-194.25921783933396 steps:214[00m
[RDDPG] Resetting Environment
17073676.55447092
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-86.78367396161059 steps:216[00m
[RDDPG] Resetting Environment
2975712.2683195584
2869722.076308995
2905605.8811558783
1871622.9717988083
3093974.615659099
3022659.5505444556
3160933.1574875396
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-481.55717465924977 steps:224[00m
[RDDPG] Resetting Environment
13299369.521106731
4206511.9958245475
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-378.5020046418678 steps:227[00m
[RDDPG] Resetting Environment
11808927.487777263
11039111.447122062
11037542.442217503
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-175.29492489661436 steps:231[00m
[RDDPG] Resetting Environment
7379462.277731972
7540694.200647122
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-145.09263616826237 steps:234[00m
[RDDPG] Resetting Environment
9566848.375536345
10831907.96370548
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-211.62931461234916 steps:237[00m
[RDDPG] Resetting Environment
6235548.609440835
60602683.77399286
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-19.840383366017093 steps:240[00m
[RDDPG] Resetting Environment
13637400.647111628
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-241.71045586601832 steps:242[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-162.06976623047484 steps:243[00m
[RDDPG] Resetting Environment
5711442.721645456
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-319.5114912208409 steps:245[00m
[RDDPG] Resetting Environment
12729524.513189655
19531885.653968483
5886790.397529269
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-224.35693308470883 steps:249[00m
[RDDPG] Resetting Environment
3174926.1147201536
2816426.0490735676
3173405.4092091033
2586957.2698161122
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-524.3911102292637 steps:254[00m
[RDDPG] Resetting Environment
20123334.550478708
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-90.16350326812679 steps:256[00m
[RDDPG] Resetting Environment
10742519.311531778
12934960.983811352
12935419.944169559
12934190.460053738
12934247.833204485
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-330.0655232736044 steps:262[00m
[RDDPG] Resetting Environment
11720230.818786088
12211678.692254987
12387494.977195825
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-638.788947402602 steps:266[00m
[RDDPG] Resetting Environment
10181558.099594904
21248502.1336293
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-284.6067082283835 steps:269[00m
[RDDPG] Resetting Environment
9410033.859193813
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-391.6117754013224 steps:271[00m
[RDDPG] Resetting Environment
12176422.855073527
6912943.5908988
16413060.68666587
22552779.54760051
22198720.478419684
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-36.11133559151807 steps:277[00m
[RDDPG] Resetting Environment
12770379.936646432
8703757.47352686
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-386.96490217763636 steps:280[00m
[RDDPG] Resetting Environment
18851384.721279707
29476014.42978531
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-343.5729906899552 steps:283[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-84.59393859375317 steps:284[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-71.16138732424096 steps:285[00m
[RDDPG] Resetting Environment
10876143.705177449
45553427.47711924
21957828.5202657
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-348.54745448537125 steps:289[00m
[RDDPG] Resetting Environment
3822332.4229652584
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-114.55288390079103 steps:291[00m
[RDDPG] Resetting Environment
9627394.173958039
6206354.87559224
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-214.5779055042006 steps:294[00m
[RDDPG] Resetting Environment
2532814.611944094
2536326.3805916775
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-397.461707263912 steps:297[00m
[RDDPG] Resetting Environment
15674501.899891356
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-14.419492258956964 steps:299[00m
[RDDPG] Resetting Environment
1635149.1384782072
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-49.85302737401204 steps:301[00m
[RDDPG] Resetting Environment
18507897.93182888
1645066.4816389503
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-231.89769312562328 steps:304[00m
[RDDPG] Resetting Environment
6135254.288128873
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-135.1401002585477 steps:306[00m
[RDDPG] Resetting Environment
17487327.886838816
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-5.576094386572834 steps:308[00m
[RDDPG] Resetting Environment
13710382.793747663
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-205.22185543548375 steps:310[00m
[RDDPG] Resetting Environment
4882649.770486414
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-105.20047862073939 steps:312[00m
[RDDPG] Resetting Environment
4365070.005953349
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-286.8704752827048 steps:314[00m
[RDDPG] Resetting Environment
9324474.701752882
9344836.370876398
4521765.482210478
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-391.17414151297913 steps:318[00m
[RDDPG] Resetting Environment
25571707.881277528
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-184.44054152129277 steps:320[00m
[RDDPG] Resetting Environment
14298152.141443212
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-59.49634866284234 steps:322[00m
[RDDPG] Resetting Environment
10833952.24437966
10325321.11475093
4184833.39570296
10838945.38868878
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-196.51674916525877 steps:327[00m
[RDDPG] Resetting Environment
11522093.159640796
9675977.50552318
19246413.274561502
19221298.24629081
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-223.55932551535784 steps:332[00m
[RDDPG] Resetting Environment
7765367.20789501
7705589.50327874
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-390.1099384851386 steps:335[00m
[RDDPG] Resetting Environment
15650575.661339737
20444545.591008477
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-101.08605584275313 steps:338[00m
[RDDPG] Resetting Environment
6747862.317865757
22332533.020057052
4900826.022550971
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-481.50789990666954 steps:342[00m
[RDDPG] Resetting Environment
12781211.323075242
20902265.56619036
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-129.75477265333313 steps:345[00m
[RDDPG] Resetting Environment
6852199.227163224
3061979.545657374
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-417.7790688995466 steps:348[00m
[RDDPG] Resetting Environment
13997253.064752877
13957109.779775515
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-175.95489330636738 steps:351[00m
[RDDPG] Resetting Environment
6015852.528288658
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-175.8765416749972 steps:353[00m
[RDDPG] Resetting Environment
7790130.733342055
1085891.3340401528
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-208.77616614747006 steps:356[00m
[RDDPG] Resetting Environment
9574651.93202848
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-107.89956333301969 steps:358[00m
[RDDPG] Resetting Environment
9717176.08727451
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-50.55886824980711 steps:360[00m
[RDDPG] Resetting Environment
7427263.93099055
7732178.649452248
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-398.4919256426523 steps:363[00m
[RDDPG] Resetting Environment
16709025.065102518
16422909.246504674
10315820.071391579
15104548.9089265
16658009.26459416
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-43.02973579632121 steps:369[00m
[RDDPG] Resetting Environment
6979316.161751345
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-205.54406078786343 steps:371[00m
[RDDPG] Resetting Environment
6464726.420901698
8080476.9611578565
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-371.53467668835486 steps:374[00m
[RDDPG] Resetting Environment
16590224.585034281
7433286.858504975
7433261.076249967
2365863.514338417
2367244.0373625793
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-340.17122128054484 steps:380[00m
[RDDPG] Resetting Environment
4575566.412385181
14758583.64572163
13313724.523389779
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-285.8285605593824 steps:384[00m
[RDDPG] Resetting Environment
6684232.118415475
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-365.0814830797884 steps:386[00m
[RDDPG] Resetting Environment
6752065.911837423
7118466.899922177
43204596.82022313
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-177.9098368204082 steps:390[00m
[RDDPG] Resetting Environment
12881929.492206203
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-241.13294396475104 steps:392[00m
[RDDPG] Resetting Environment
13545243.836049918
13601826.509643337
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-162.61695820319017 steps:395[00m
[RDDPG] Resetting Environment
3143307.336024572
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-381.94442339811843 steps:397[00m
[RDDPG] Resetting Environment
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-117.50678625000441 steps:398[00m
[RDDPG] Resetting Environment
16192330.097818917
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-335.93985853926216 steps:400[00m
[RDDPG] Resetting Environment
10169830.84767574
11300492.517511267
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-111.20717760275207 steps:403[00m
[RDDPG] Resetting Environment
7020371.696390644
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:18.960433743186798 steps:405[00m
[RDDPG] Resetting Environment
12099438.686819775
11883672.95137494
11523682.91494798
11395567.495076306
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:114.12669459200211 steps:410[00m
[RDDPG] Resetting Environment
13966845.257797515
14388778.189809823
15375970.232314702
15900468.055750238
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:175.03347347818124 steps:415[00m
[RDDPG] Resetting Environment
14497427.593671702
1736914.3928039381
9916488.866498742
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:17.007003512919688 steps:419[00m
[RDDPG] Resetting Environment
18732693.92493599
16340208.625114957
17808050.197253056
18362015.459863774
18792130.45205065
18635540.015422598
2281687.8527965536
2376524.2802679543
2403575.709122451
2288865.2020230973
2270126.0380056063
2499010.6407902883
1065754.6078878348
1894690.3878844231
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:490.8237804823355 steps:434[00m
[RDDPG] Resetting Environment
26170312.56011703
24490650.57208136
20845138.6218836
8736270.820060031
8369121.18206598
8650012.56154178
8511223.572193496
8384306.34716589
9211044.930662451
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:431.1670991115738 steps:444[00m
[RDDPG] Resetting Environment
6120020.780424828
1222968.067624047
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-39.669107085442874 steps:447[00m
[RDDPG] Resetting Environment
14114505.742643854
1816342.0756843626
1816390.0573552419
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 135.28228
1816461.2190061524
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-3.9411896107554654 steps:452[00m
[RDDPG] Resetting Environment
7324461.782971669
7890942.691979015
6463301.424812244
7983146.454097154
7979409.23854466
7945230.730939937
-603846.2228154829
-603809.2489955975
-603789.3345774324
-603792.3401398459
-603796.1505348552
-603801.9495297628
-603795.668760703
-603803.7238521497
-603800.7716239067
-603776.3941812236
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-47.14478360553809 steps:469[00m
[RDDPG] Resetting Environment
8674813.27849871
8133205.626194703
7706180.96459372
5030194.360531222
4940305.781091636
4962714.411992404
4992916.403409942
8156212.392773779
8387831.249309707
8730350.188135585
8559351.321765669
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:231.88453449742798 steps:481[00m
[RDDPG] Resetting Environment
12640637.900214339
2183803.19767887
2183832.433712464
2183886.0308046024
2183998.735810017
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-43.53836341116208 steps:487[00m
[RDDPG] Resetting Environment
9676432.14386387
9769194.058873374
10244771.765279267
10176627.1768445
10530751.35163722
4639340.5246862555
4946366.170350051
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:109.68650608096064 steps:495[00m
[RDDPG] Resetting Environment
19572121.306346834
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:42.30818991065846 steps:497[00m
[RDDPG] Resetting Environment
17157326.147531543
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:49.71575320960832 steps:499[00m
[RDDPG] Resetting Environment
11207922.476835547
[RDDPG] Updating Policy
[RDDPG] Update Time: 145.57459
11294305.844127934
11367645.174302647
11558077.5616931
3307301.0122074666
-411476.64520505536
-411485.5994509058
-411494.97931226064
-411502.2153182789
-411506.5113134915
-411511.0840103808
-411518.55396701815
-411520.8402714045
-411351.69674666366
-411351.34110444924
-411514.74766706955
3264603.9537392478
3525599.4068433437
3302745.6874569585
3081421.8229057975
2790240.3012288967
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:188.82459782992416 steps:521[00m
[RDDPG] Resetting Environment
19804232.18852485
4625151.649153363
4625170.998097936
4624325.648975028
4625183.244036572
4625160.645983307
4625127.986843073
4625127.44937591
4624319.593457652
4625125.973976171
6571138.968649438
7954848.282171707
7901021.028937515
8026192.459395528
7977030.176672451
7947144.356552839
7923290.212474598
8007721.871412946
7921143.306736672
7936202.84862322
7968488.190535391
8025970.803445718
8023493.898965781
8013473.517834564
7967107.562957453
-1.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:770.3463134372778 steps:547[00m
[RDDPG] Resetting Environment
7692886.796294042
3073179.8137512626
3073180.936302045
[RDDPG] Updating Policy
[RDDPG] Update Time: 50.15096
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1217, in step
    #rospy.sleep(15.0/60.0)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 14:49:26.494760: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 14:49:26.494796: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620119973.531416905, 1.191000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620119973.533590092, 1.193000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620119973.534315146, 1.194000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620119975.142531322, 2.364000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620119975.997599259, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620119977.071249520, 3.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620119978.200049319, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
d1:28555878.29253, d2:0.04028, d3:8621151.31348
d1:28555726.24045, d2:0.04029, d3:8621102.76317
d1:28555854.46925, d2:0.04028, d3:8621143.78883
d1:28556092.15750, d2:0.04027, d3:8621217.51774
d1:28556086.24533, d2:0.04027, d3:8621215.71973
d1:1877862.27936, d2:0.05866, d3:1203418.60916
d1:1876894.55059, d2:0.05843, d3:1203497.84789
d1:740499.60560, d2:0.05873, d3:146596.21985
d1:8049107.63059, d2:0.05829, d3:5937427.65748
d1:5722953.89155, d2:0.05934, d3:836885.37036
d1:1771771.77992, d2:0.03978, d3:1053613.66895
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
d1:18782013.96643, d2:0.05210, d3:7517949.91861
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
d1:7339994.21547, d2:0.05916, d3:3167605.74593
d1:3512675.10612, d2:0.05924, d3:2393784.86545
d1:3510846.97447, d2:0.05925, d3:2392902.31551
d1:3511244.58992, d2:0.05924, d3:2393094.42510
d1:3511407.96409, d2:0.05924, d3:2393173.31427
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:140.03083417778723[00m
[RDDPG] Resetting Environment
d1:26526001.87321, d2:0.05923, d3:10859032.79151
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-172.11574045409313 steps:2[00m
[RDDPG] Resetting Environment
d1:9724598.75061, d2:0.02922, d3:1751002.27879
d1:6404701.00788, d2:0.05939, d3:4310464.52440
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-221.84156136966885 steps:5[00m
[RDDPG] Resetting Environment
d1:9957987.30294, d2:0.04111, d3:3063853.27536
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-266.950808212203 steps:7[00m
[RDDPG] Resetting Environment
d1:19427261.92661, d2:0.04107, d3:5452618.88730
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-112.81146481344345 steps:9[00m
[RDDPG] Resetting Environment
d1:8051387.95630, d2:0.04549, d3:2435842.17151
d1:7240152.37961, d2:0.05872, d3:1438138.80492
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-474.76503953421957 steps:12[00m
[RDDPG] Resetting Environment
d1:8289922.49671, d2:0.05702, d3:841555.48480
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-278.5737595809634 steps:14[00m
[RDDPG] Resetting Environment
d1:12633024.57995, d2:0.04185, d3:3833333.40242
d1:12482977.69546, d2:0.04278, d3:3953412.98743
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-117.6861459094054 steps:17[00m
[RDDPG] Resetting Environment
d1:20933111.57332, d2:0.05427, d3:7099509.00781
d1:18322499.20512, d2:0.04830, d3:6067585.18386
d1:18539701.14095, d2:0.05939, d3:10626248.04707
d1:33689580.83367, d2:0.01438, d3:14632721.41511
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-248.09470975088885 steps:22[00m
[RDDPG] Resetting Environment
d1:6717706.11102, d2:0.05865, d3:2378245.71078
d1:9515721.36915, d2:0.05759, d3:3367243.61557
d1:16322112.36161, d2:0.01487, d3:2879114.59929
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-249.64797500061184 steps:26[00m
[RDDPG] Resetting Environment
d1:14297605.77473, d2:0.05388, d3:4906851.99019
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-263.5427640566819 steps:28[00m
[RDDPG] Resetting Environment
d1:25563039.29695, d2:0.04299, d3:8838598.75240
d1:27960071.83409, d2:0.05931, d3:10072212.42795
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-0.7600399377528575 steps:31[00m
[RDDPG] Resetting Environment
d1:12626222.55601, d2:0.03528, d3:6533263.05120
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-340.96368055278936 steps:33[00m
[RDDPG] Resetting Environment
d1:7192150.93957, d2:0.00150, d3:239167.61660
d1:6881697.93736, d2:0.05818, d3:1921637.59626
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-151.57239928276528 steps:36[00m
[RDDPG] Resetting Environment
d1:3672066.59616, d2:0.04676, d3:1135511.29282
d1:23670066.57820, d2:0.05639, d3:3950318.47980
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-435.6705168272871 steps:39[00m
[RDDPG] Resetting Environment
d1:31513500.66817, d2:0.03862, d3:8687812.80553
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:15.615263221697369 steps:41[00m
[RDDPG] Resetting Environment
d1:4442536.75431, d2:0.05938, d3:1466727.83437
d1:14471247.31421, d2:0.03085, d3:11659958.83948
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-230.60861381466137 steps:44[00m
[RDDPG] Resetting Environment
d1:10602870.64428, d2:0.05871, d3:2070922.53684
d1:28717673.07630, d2:0.05845, d3:8957003.39511
d1:28717772.01628, d2:0.05845, d3:8957062.06300
d1:28717635.20252, d2:0.05845, d3:8956980.95596
d1:4122292.55265, d2:0.05938, d3:2177044.57322
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-444.26468524094565 steps:50[00m
[RDDPG] Resetting Environment
d1:2665876.94222, d2:0.05934, d3:845862.97609
d1:12890360.77808, d2:0.05929, d3:4091623.12933
d1:5882592.04497, d2:0.05924, d3:1867062.50272
d1:15699351.00079, d2:0.05101, d3:4932106.81143
d1:14503510.87670, d2:0.05152, d3:7606464.11603
d1:13215450.71645, d2:0.05018, d3:10047325.67184
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-282.23078053764453 steps:57[00m
[RDDPG] Resetting Environment
d1:4710386.05809, d2:0.05472, d3:1270944.45814
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-12.754788645980216 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-154.34078991211518 steps:60[00m
[RDDPG] Resetting Environment
d1:9742896.80419, d2:0.05886, d3:3497741.48391
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-154.53860393703442 steps:62[00m
[RDDPG] Resetting Environment
d1:14315713.89351, d2:0.00853, d3:622029.30815
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:36.52044138765827 steps:64[00m
[RDDPG] Resetting Environment
d1:16617698.34122, d2:0.05270, d3:1363498.72258
d1:7698201.57623, d2:0.05913, d3:2383103.22629
d1:12663977.24220, d2:0.05900, d3:3956851.74859
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-303.2256688166574 steps:68[00m
[RDDPG] Resetting Environment
d1:22731269.47855, d2:0.02560, d3:2768803.82660
d1:22572627.20867, d2:0.05000, d3:4508237.03633
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-165.88329363943515 steps:71[00m
[RDDPG] Resetting Environment
d1:23636826.79201, d2:0.05607, d3:6558318.35892
d1:10839129.16937, d2:0.05564, d3:4201657.99728
d1:10124780.76688, d2:0.02327, d3:6761515.32766
d1:22389949.41386, d2:0.04024, d3:19780905.37920
d1:33279993.62126, d2:0.05781, d3:14075923.14674
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-234.58446183818958 steps:77[00m
[RDDPG] Resetting Environment
d1:12262661.72021, d2:0.05903, d3:4067391.12967
d1:17028489.52815, d2:0.05679, d3:4171531.37427
d1:9477571.35338, d2:0.03052, d3:390986.86302
d1:12349220.04360, d2:0.01854, d3:359348.83498
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-295.52932042388 steps:82[00m
[RDDPG] Resetting Environment
d1:17109340.33019, d2:0.05934, d3:5778980.77503
d1:7083117.90633, d2:0.05939, d3:780601.67378
d1:2657187.06796, d2:0.05859, d3:1742317.49849
d1:13352130.17842, d2:0.05047, d3:1727059.18286
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-549.2190991799971 steps:87[00m
[RDDPG] Resetting Environment
d1:10476933.94950, d2:0.05866, d3:2547215.35237
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-164.16584101859962 steps:89[00m
[RDDPG] Resetting Environment
d1:26953480.00673, d2:0.05673, d3:8551838.09550
d1:11818697.04092, d2:0.05522, d3:3425184.14576
d1:11783449.44131, d2:0.05522, d3:3415153.22190
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:16.066844172301778 steps:93[00m
[RDDPG] Resetting Environment
d1:234198.71424, d2:0.05940, d3:75817.16319
d1:1230057.76419, d2:0.02599, d3:150818.81501
d1:6715367.28981, d2:0.05649, d3:1956130.56308
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-246.36082577571165 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-165.49489879882236 steps:98[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 14:52:03.714369: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 14:52:03.714408: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620120130.319959828, 1.261000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620120130.321654286, 1.263000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620120130.321739330, 1.263000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620120131.669742007, 2.601000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620120132.568661526, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620120133.386746278, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620120134.201195601, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
0.75702393
0.7091548
d1:14242712.15337, d2:0.03958, d3:4400993.71581
0.6495556
0.70568025
d1:2763740.59484, d2:0.05902, d3:845927.34317
0.7951998
0.73595923
d1:2494780.45055, d2:0.05887, d3:2634867.25938
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
0.7475943
0.74151736
d1:12461709.18083, d2:0.04669, d3:4097530.72219
0.7475943
0.74151736
d1:12517811.58289, d2:0.04700, d3:4127494.30514
0.5976358
0.7457205
d1:9306335.71871, d2:0.03587, d3:2269215.32881
0.5976358
0.7457205
d1:9303042.02694, d2:0.03585, d3:2268215.37905
0.5976358
0.7457205
d1:9301012.95275, d2:0.03585, d3:2267599.06980
0.5976358
0.7457205
d1:9301537.72927, d2:0.03585, d3:2267758.49751
0.5976358
0.7457205
d1:9299004.03495, d2:0.03584, d3:2266988.69274
0.6402862
0.85648304
d1:7946940.65805, d2:0.05031, d3:3216054.83817
0.54969895
0.7269825
d1:2715106.12385, d2:0.03772, d3:398827.47480
0.54969895
0.7269825
d1:3140955.80018, d2:0.04985, d3:298785.86108
0.54969895
0.7269825
d1:2945600.65026, d2:0.04090, d3:380239.29787
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
0.70960087
0.611842
d1:5034918.96008, d2:0.03138, d3:989428.66100
0.60617197
0.611842
d1:27178025.76527, d2:0.05642, d3:858998.98917
0.4523651
0.49292076
d1:3453638.87524, d2:0.05344, d3:980539.00612
0.4523651
0.49292076
d1:3505463.65663, d2:0.05304, d3:964483.97231
0.4523651
0.49292076
d1:3541198.98679, d2:0.05276, d3:953318.95501
0.4523651
0.49292076
d1:3545005.06476, d2:0.05273, d3:952124.93836
0.4523651
0.49292076
d1:3427864.58590, d2:0.05363, d3:988471.11550
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:52.40336979407753[00m
[RDDPG] Resetting Environment
0.69744265
0.58739185
d1:16286498.88678, d2:0.05592, d3:4026131.36526
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-164.35511689075645 steps:2[00m
[RDDPG] Resetting Environment
0.7573208
0.7247731
d1:21988446.01053, d2:0.05863, d3:4374644.40023
0.6389736
0.8490891
d1:27422539.34144, d2:0.05868, d3:9630026.44294
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-25.469560239875598 steps:5[00m
[RDDPG] Resetting Environment
0.753336
0.75895756
d1:4134840.06774, d2:0.04469, d3:1321019.13954
0.753336
0.75895756
d1:3551098.50425, d2:0.05886, d3:778611.45548
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-259.7559561113814 steps:8[00m
[RDDPG] Resetting Environment
0.6285658
0.72778755
d1:3385172.74320, d2:0.05834, d3:118998.69799
0.6285658
0.72778755
d1:6139948.66299, d2:0.05594, d3:823578.16406
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-222.31933167884932 steps:11[00m
[RDDPG] Resetting Environment
0.7003272
0.7254078
d1:14680441.88966, d2:0.05913, d3:5058238.98300
0.648893
0.66635317
d1:8882441.42689, d2:0.02770, d3:2357958.29774
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-280.07526849244704 steps:14[00m
[RDDPG] Resetting Environment
0.68108565
0.78040403
d1:4502974.88974, d2:0.04691, d3:1784867.49596
0.6617247
0.97359097
d1:26370334.04708, d2:0.05931, d3:8627533.98381
0.6617247
0.70777035
d1:9627360.24122, d2:0.05332, d3:6554777.40453
0.6617247
0.41171196
d1:16940147.74502, d2:0.05675, d3:4567332.03719
0.6617247
0.33265647
d1:25258377.27154, d2:0.04727, d3:9984120.29384
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-433.61426564036583 steps:20[00m
[RDDPG] Resetting Environment
0.7688392
0.6991544
d1:10086726.57016, d2:0.02124, d3:1316937.69652
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-47.581496075050985 steps:22[00m
[RDDPG] Resetting Environment
0.7390911
0.7247609
d1:6544834.84858, d2:0.02896, d3:1310760.18076
0.7390911
0.7247609
d1:4506647.79721, d2:0.05923, d3:1400784.32716
0.7641226
0.72706985
d1:39466775.35416, d2:0.04020, d3:12643053.96615
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-135.45655603509408 steps:26[00m
[RDDPG] Resetting Environment
0.7471434
0.6850528
d1:8414098.25463, d2:0.04611, d3:2972722.63022
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-317.7638592862195 steps:28[00m
[RDDPG] Resetting Environment
0.7421753
0.7224855
d1:10697619.86455, d2:0.03752, d3:2901000.74772
0.7708579
0.7618216
d1:12775548.42587, d2:0.05924, d3:3417628.96482
0.7708579
0.7618216
d1:12761963.41669, d2:0.05924, d3:3413313.26704
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-186.2369051141014 steps:32[00m
[RDDPG] Resetting Environment
0.75091255
0.751957
d1:14448894.10139, d2:0.05370, d3:1655080.75370
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-95.72476915747711 steps:34[00m
[RDDPG] Resetting Environment
0.75334644
0.63561195
d1:9534350.08816, d2:0.02595, d3:1605608.54199
0.75334644
0.63561195
d1:8189123.42961, d2:0.03603, d3:1943909.48314
0.75334644
0.45454732
d1:4490472.73633, d2:0.05940, d3:4860626.67811
0.6858987
0.20961915
d1:43253768.18327, d2:0.02056, d3:12380572.60008
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-188.46313771524888 steps:39[00m
[RDDPG] Resetting Environment
0.7529908
0.6784582
d1:10688950.26919, d2:0.01665, d3:1025192.75318
0.56169
0.6784582
d1:5979215.99312, d2:0.05909, d3:862872.44790
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-249.1307674065304 steps:42[00m
[RDDPG] Resetting Environment
0.73617375
0.67000324
d1:2732807.18082, d2:0.05940, d3:898530.74004
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-190.74947563213718 steps:44[00m
[RDDPG] Resetting Environment
0.74864143
0.80400527
d1:12991860.80758, d2:0.04215, d3:3935066.74786
0.98788154
0.5305106
d1:15224688.34703, d2:0.02129, d3:2918564.66790
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-110.13670781014784 steps:47[00m
[RDDPG] Resetting Environment
0.7880777
0.6909342
d1:14846502.55424, d2:0.02124, d3:2441384.93112
0.68982875
0.61264384
d1:592279.48786, d2:0.05940, d3:152821.60502
0.68982875
0.61264384
d1:592919.87456, d2:0.05940, d3:152981.61087
0.68982875
0.515418
d1:34304290.93427, d2:0.05824, d3:10954678.08691
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-244.74818952618244 steps:52[00m
[RDDPG] Resetting Environment
0.7473639
0.73245466
d1:9045009.72255, d2:0.01395, d3:269245.87140
0.7473639
0.73245466
d1:2040578.68033, d2:0.05754, d3:102715.29871
0.7473639
0.73245466
d1:3392132.14238, d2:0.05261, d3:343073.61089
0.7473639
0.73245466
d1:1809855.51014, d2:0.05812, d3:50706.55113
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-337.8300323947142 steps:57[00m
[RDDPG] Resetting Environment
0.7584313
0.7454168
d1:19776258.36481, d2:0.05533, d3:2781415.82693
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-7.119329208401126 steps:59[00m
[RDDPG] Resetting Environment
0.7525396
0.70129097
d1:9379765.02469, d2:0.05940, d3:3267009.43135
0.7525396
0.70129097
d1:9238730.72068, d2:0.05938, d3:3216537.20926
0.7525396
0.63317823
d1:16510762.76023, d2:0.02474, d3:10288687.40809
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-312.2550233255842 steps:63[00m
[RDDPG] Resetting Environment
0.75236386
0.708638
d1:2465891.74743, d2:0.05375, d3:122863.16916
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-82.82716068674087 steps:65[00m
[RDDPG] Resetting Environment
0.76876944
0.7276027
d1:14276410.31465, d2:0.05899, d3:5147602.65345
0.76876944
0.5040283
d1:5627096.06146, d2:0.05859, d3:716295.06980
0.76876944
0.63139594
d1:27409687.98803, d2:0.05871, d3:16472262.82945
0.6304564
0.8765176
d1:8285102.41533, d2:0.05783, d3:5281821.53233
0.36463466
0.49044314
d1:57635965.69887, d2:0.05376, d3:18728291.01347
0.65828496
0.66094106
d1:24095921.22129, d2:0.05924, d3:8818899.88997
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-151.96753272384117 steps:72[00m
[RDDPG] Resetting Environment
0.6887139
0.6987718
d1:22461527.00303, d2:0.05349, d3:7709670.69009
0.6887139
0.6987718
d1:26935898.51775, d2:0.05752, d3:9339631.74691
0.6887139
0.6167245
d1:16572704.11688, d2:0.05938, d3:9638810.27516
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-135.31876363158722 steps:76[00m
[RDDPG] Resetting Environment
0.7136948
0.6929256
d1:3128348.95412, d2:0.01980, d3:417051.60617
0.7262934
0.6660064
d1:3017521.74708, d2:0.00880, d3:439245.48516
0.7262934
0.6660064
d1:3017388.51168, d2:0.00878, d3:439195.59618
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-262.67548450317065 steps:80[00m
[RDDPG] Resetting Environment
0.75569046
0.75521296
d1:14315240.11627, d2:0.05932, d3:4636725.48600
0.75569046
0.75521296
d1:12330510.16365, d2:0.05925, d3:3979902.20938
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-96.04979528091036 steps:83[00m
[RDDPG] Resetting Environment
0.70850074
0.7198574
d1:9069262.18711, d2:0.02729, d3:1644320.35333
0.70850074
0.7198574
d1:3300474.87032, d2:0.05938, d3:1150169.30767
0.70850074
0.7198574
d1:9461964.98289, d2:0.02610, d3:1453328.63338
0.5232372
0.7198574
d1:21608939.65862, d2:0.05938, d3:13974339.79975
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-357.17254340307954 steps:88[00m
[RDDPG] Resetting Environment
0.7337049
0.73468935
d1:9661493.71579, d2:0.02576, d3:1474686.09869
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-118.0951234153655 steps:90[00m
[RDDPG] Resetting Environment
0.7470556
0.710723
d1:12503218.09423, d2:0.05890, d3:4782465.04018
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-150.50098004495223 steps:92[00m
[RDDPG] Resetting Environment
0.7188167
0.7152337
d1:22653776.68522, d2:0.02540, d3:3117691.31707
0.5236659
0.801217
d1:22031110.79155, d2:0.04411, d3:7097557.63151
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-32.47949314187467 steps:95[00m
[RDDPG] Resetting Environment
0.7301435
0.640076
d1:6010210.76159, d2:0.05595, d3:1691484.11683
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-137.13643650909552 steps:97[00m
[RDDPG] Resetting Environment
0.7614226
0.7563881
d1:19114337.76453, d2:0.03337, d3:4421095.56723
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-111.27380296939626 steps:99[00m
[RDDPG] Resetting Environment
0.71680707
0.7277689
d1:19622442.87547, d2:0.04315, d3:1453943.64704
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-149.28222196423792 steps:101[00m
[RDDPG] Resetting Environment
0.7437781
0.78836566
d1:5814857.95037, d2:0.05921, d3:2357808.65960
0.85328174
0.5364226
d1:3862598.45916, d2:0.05860, d3:1044469.84507
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-263.70255014679327 steps:104[00m
[RDDPG] Resetting Environment
0.7547685
0.745567
d1:4352533.78502, d2:0.05893, d3:588407.10499
0.44851556
0.49082488
d1:8867119.81615, d2:0.05921, d3:2709764.24332
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-193.25393417013004 steps:107[00m
[RDDPG] Resetting Environment
0.76552796
0.6715389
d1:7348078.56240, d2:0.04844, d3:2448231.78876
0.6857182
0.8083422
d1:14413150.80164, d2:0.05303, d3:4307858.03515
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-148.08892658105913 steps:110[00m
[RDDPG] Resetting Environment
0.7488294
0.7290643
d1:21658348.02154, d2:0.02695, d3:2874874.02796
0.7488294
0.7290643
d1:11277078.33809, d2:0.05936, d3:3926147.92753
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-39.46552650160893 steps:113[00m
[RDDPG] Resetting Environment
0.7589613
0.69246125
d1:5050254.30672, d2:0.05935, d3:1771418.64745
0.7589613
0.69246125
d1:11664901.79131, d2:0.02890, d3:2014872.23748
0.7589613
0.69246125
d1:12262687.09544, d2:0.02733, d3:1712702.99438
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-187.07433065768595 steps:117[00m
[RDDPG] Resetting Environment
0.7212205
0.8588366
d1:6646576.62254, d2:0.05882, d3:2508401.67311
0.7212205
0.8588366
d1:6967973.80240, d2:0.05921, d3:2615424.50731
0.7212205
0.8588366
d1:1877339.58933, d2:0.05820, d3:728009.87122
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-211.50464569018726 steps:121[00m
[RDDPG] Resetting Environment
0.762283
0.704897
d1:12780227.34610, d2:0.05881, d3:4733082.06995
0.762283
0.704897
d1:11248000.54101, d2:0.05926, d3:4041827.53314
0.762283
0.704897
d1:12863010.31929, d2:0.05786, d3:4770979.08018
0.762283
0.704897
d1:2415674.57514, d2:0.05924, d3:334246.20371
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-280.56797558971203 steps:126[00m
[RDDPG] Resetting Environment
0.76957554
0.60354036
d1:7882372.51615, d2:0.05416, d3:2667983.76860
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-101.70449970331052 steps:128[00m
[RDDPG] Resetting Environment
0.7319771
0.8020708
d1:13546476.82089, d2:0.00589, d3:298294.99880
0.7319771
0.8020708
d1:5569310.07853, d2:0.05657, d3:334586.17921
0.7319771
0.8020708
d1:13305030.52753, d2:0.05933, d3:3413765.94467
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-892.6087082867259 steps:132[00m
[RDDPG] Resetting Environment
0.7422798
0.63863134
d1:2652590.10359, d2:0.05276, d3:537158.69290
0.7200495
0.75564116
d1:6963734.10996, d2:0.05800, d3:1282812.72913
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-171.51450709908897 steps:135[00m
[RDDPG] Resetting Environment
0.76801115
0.6445612
d1:7431004.57429, d2:0.04031, d3:2070837.51089
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-135.29738735278144 steps:137[00m
[RDDPG] Resetting Environment
0.7688624
0.76509607
d1:20270244.24536, d2:0.05725, d3:2784422.25053
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-94.75225333480486 steps:139[00m
[RDDPG] Resetting Environment
0.7354907
0.7231681
d1:11675727.60166, d2:0.05577, d3:3797472.42611
0.58662695
0.7317916
d1:9325950.80774, d2:0.05670, d3:2452757.80575
0.58662695
0.7317916
d1:9325632.85147, d2:0.05670, d3:2452612.33191
0.5241195
0.55086136
d1:20998116.13215, d2:0.04287, d3:9818450.98567
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-361.8310106703913 steps:144[00m
[RDDPG] Resetting Environment
0.75158226
0.7010084
d1:13545804.95898, d2:0.04679, d3:4902978.61594
0.75158226
0.7010084
d1:15835931.40433, d2:0.03413, d3:3324676.64948
0.75158226
0.7010084
d1:15652976.25063, d2:0.04755, d3:583207.72652
0.75158226
0.97997886
d1:24311428.21485, d2:0.05063, d3:11038052.38256
0.5777153
0.67998075
d1:23959328.76263, d2:0.04836, d3:23530370.32941
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-216.62805000227132 steps:150[00m
[RDDPG] Resetting Environment
0.76611125
0.67310125
d1:11840239.50932, d2:0.01610, d3:1685734.05589
0.76611125
0.67310125
d1:11866629.60182, d2:0.01617, d3:1695654.35059
0.76611125
0.67310125
d1:12194002.68747, d2:0.01817, d3:1837220.96797
0.76611125
0.67310125
d1:11323184.85593, d2:0.05854, d3:4026891.26323
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-372.53150524567195 steps:155[00m
[RDDPG] Resetting Environment
0.7518846
0.7244691
d1:18212029.15943, d2:0.05908, d3:5152036.14068
0.7501568
0.53510046
d1:4045943.39818, d2:0.05887, d3:1392775.71873
0.7501568
0.53510046
d1:4046048.08000, d2:0.05887, d3:1392809.26305
0.8891351
0.42015457
d1:40544311.10889, d2:0.05922, d3:16084405.41093
0.8891351
0.96124524
d1:6795615.55278, d2:0.04360, d3:3724354.63965
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-255.20072461514633 steps:161[00m
[RDDPG] Resetting Environment
0.57152665
0.5362607
d1:7435457.31859, d2:0.01905, d3:977193.26903
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-38.95358615364521 steps:163[00m
[RDDPG] Resetting Environment
0.69040215
0.642335
d1:16328076.26627, d2:0.05939, d3:6001513.84584
0.69040215
0.642335
d1:17582370.06633, d2:0.05922, d3:6472540.61295
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-105.51910188809319 steps:166[00m
[RDDPG] Resetting Environment
0.73499626
0.7314719
d1:13569433.82659, d2:0.04882, d3:4497384.37460
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-197.25457579417517 steps:168[00m
[RDDPG] Resetting Environment
0.7398986
0.6983081
d1:12892796.56244, d2:0.05786, d3:4289868.18896
0.77550626
0.6977744
d1:15404969.32176, d2:0.05581, d3:4157589.55221
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-56.37128333080366 steps:171[00m
[RDDPG] Resetting Environment
0.7576537
0.7723472
d1:1043425.31305, d2:0.05477, d3:333320.10929
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-162.03687622773475 steps:173[00m
[RDDPG] Resetting Environment
0.7395614
0.6761059
d1:10656496.44594, d2:0.04421, d3:3234459.59021
0.7395614
0.6761059
d1:13389857.69937, d2:0.05890, d3:4784466.12998
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-229.8603879872357 steps:176[00m
[RDDPG] Resetting Environment
0.7663745
0.68296814
d1:12225402.96881, d2:0.04530, d3:4155247.43931
0.7663745
0.6314644
d1:17142661.65529, d2:0.05665, d3:10908154.75325
0.59059775
0.54443455
d1:12539614.01153, d2:0.05463, d3:4554048.41663
0.59059775
0.54443455
d1:12518360.60239, d2:0.05467, d3:4546204.16052
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-360.03669803352506 steps:181[00m
[RDDPG] Resetting Environment
0.73022
0.70851004
d1:12340579.25022, d2:0.05852, d3:3342388.58778
0.7526936
0.5141775
d1:5174518.18590, d2:0.05861, d3:1384525.04181
0.65446204
0.48464954
d1:14153842.35315, d2:0.05880, d3:7947632.35762
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-399.8849091838535 steps:185[00m
[RDDPG] Resetting Environment
0.7589763
0.678072
d1:15355609.09871, d2:0.05186, d3:5619571.27736
0.7589763
0.678072
d1:16477374.27443, d2:0.05462, d3:6154149.79665
0.7589763
0.678072
d1:7227302.01975, d2:0.05858, d3:1019216.36587
0.7589763
0.678072
d1:16770230.23425, d2:0.05908, d3:6510285.22471
1.0194417
0.678072
d1:2507942.19006, d2:0.05578, d3:1461866.78498
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-531.8608427879694 steps:191[00m
[RDDPG] Resetting Environment
0.7559615
0.696786
d1:21630483.70466, d2:0.05864, d3:7302828.07154
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-211.81608406114685 steps:193[00m
[RDDPG] Resetting Environment
0.73081166
0.74977326
d1:8514219.36476, d2:0.05706, d3:2651140.51752
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-202.93039644951466 steps:195[00m
[RDDPG] Resetting Environment
0.7416623
0.7654357
d1:17370060.78705, d2:0.05094, d3:5865881.02833
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-46.53173491793883 steps:197[00m
[RDDPG] Resetting Environment
0.7576207
0.70505476
d1:9611248.85948, d2:0.05910, d3:2908015.35682
0.7576207
0.70505476
d1:9990693.44394, d2:0.05607, d3:2704448.23739
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-216.3331601254988 steps:200[00m
[RDDPG] Resetting Environment
0.7542333
0.68157226
d1:6641416.14043, d2:0.05761, d3:2380733.33072
0.7542333
0.68157226
d1:9003908.43702, d2:0.05937, d3:3045969.46674
0.7542333
0.68157226
d1:9011492.01784, d2:0.05763, d3:3215627.33220
0.9415742
0.67026746
d1:11634408.26163, d2:0.05454, d3:3603382.89624
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-452.6916396176297 steps:205[00m
[RDDPG] Resetting Environment
0.7291475
0.78119856
d1:4323724.95118, d2:0.05762, d3:1532135.96000
0.7291475
0.78119856
d1:4734651.28931, d2:0.05734, d3:1677622.58499
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-264.25729868906024 steps:208[00m
[RDDPG] Resetting Environment
0.77758706
0.70623106
d1:2487374.42948, d2:0.04070, d3:728673.77004
0.77758706
0.70623106
d1:2878933.01970, d2:0.05135, d3:996224.84328
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-277.3394476091007 steps:211[00m
[RDDPG] Resetting Environment
0.73690945
0.7445791
d1:3914191.46446, d2:0.05540, d3:544164.38372
0.73690945
0.7445791
d1:2792039.85265, d2:0.05939, d3:952770.61192
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-238.82774711120044 steps:214[00m
[RDDPG] Resetting Environment
0.7456198
0.66497326
d1:17236943.46453, d2:0.05864, d3:3886787.36792
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-50.22970692685699 steps:216[00m
[RDDPG] Resetting Environment
0.75328135
0.75347894
d1:15932884.61971, d2:0.05929, d3:5823946.94203
0.75328135
0.75347894
d1:16663917.56623, d2:0.05920, d3:6102514.14777
0.7896503
0.5199756
d1:15693378.80356, d2:0.05914, d3:4462134.25440
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-163.3516326238103 steps:220[00m
[RDDPG] Resetting Environment
0.76253897
0.7784635
d1:14572672.45430, d2:0.05762, d3:1361827.68645
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-198.46087129260903 steps:222[00m
[RDDPG] Resetting Environment
0.7637911
0.65888774
d1:14544961.45030, d2:0.05905, d3:5261183.99580
0.91945505
0.65888774
d1:9538909.08212, d2:0.05939, d3:7552323.28780
1.0061482
0.65888774
d1:18126788.69276, d2:0.05936, d3:5287452.83083
0.6507217
0.65888774
d1:1693881.51050, d2:0.05742, d3:866228.14274
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-390.5424166352102 steps:227[00m
[RDDPG] Resetting Environment
0.74039286
0.74954927
d1:9035999.92249, d2:0.01164, d3:584826.62994
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-46.29422673026161 steps:229[00m
[RDDPG] Resetting Environment
0.74895
0.7822891
d1:5352743.57288, d2:0.04155, d3:1612868.74813
0.74895
0.60339725
d1:20214071.84743, d2:0.05679, d3:657524.77415
0.5567934
0.60339725
d1:15292966.71779, d2:0.04504, d3:3805485.33210
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-302.8400539955725 steps:233[00m
[RDDPG] Resetting Environment
0.7534609
0.69596255
d1:4515213.93838, d2:0.02003, d3:535873.66466
0.7534609
0.69596255
d1:4439641.06735, d2:0.02088, d3:564528.58746
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-193.07809617280662 steps:236[00m
[RDDPG] Resetting Environment
0.73890615
0.72672665
d1:11839995.93120, d2:0.05484, d3:3979158.22553
0.8484579
0.92047036
d1:11324647.06329, d2:0.01214, d3:872751.56579
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-132.20847042260885 steps:239[00m
[RDDPG] Resetting Environment
0.76702785
0.54323065
d1:7572717.18638, d2:0.05750, d3:1805833.13712
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-144.96422212613226 steps:241[00m
[RDDPG] Resetting Environment
0.7562175
0.71565527
d1:2174618.32848, d2:0.05883, d3:1250119.56355
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-242.36018139138702 steps:243[00m
[RDDPG] Resetting Environment
0.7598344
0.7396182
d1:8135454.28274, d2:0.05797, d3:2864795.83518
0.7598344
0.7396182
d1:472113.33872, d2:0.05933, d3:79195.27491
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-272.94709678455456 steps:246[00m
[RDDPG] Resetting Environment
0.7465328
0.7089976
d1:19032101.71399, d2:0.03009, d3:3616725.39335
0.7465328
0.7089976
d1:21387446.02720, d2:0.04877, d3:1455495.96968
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-39.23886526306903 steps:249[00m
[RDDPG] Resetting Environment
0.7026194
0.70771813
d1:21299579.43265, d2:0.02607, d3:2950103.18697
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-142.30591638241611 steps:251[00m
[RDDPG] Resetting Environment
0.7467667
0.8146926
d1:5506929.18339, d2:0.05820, d3:1864595.24486
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-155.65826333275714 steps:253[00m
[RDDPG] Resetting Environment
0.73522425
0.6999146
d1:30058898.55726, d2:0.03455, d3:6543588.82380
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-82.09582430332947 steps:255[00m
[RDDPG] Resetting Environment
0.74685854
0.7325619
d1:2766478.55688, d2:0.05093, d3:943001.71525
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-218.54377314614516 steps:257[00m
[RDDPG] Resetting Environment
0.76155096
0.65546036
d1:14841334.51786, d2:0.05484, d3:2116571.68617
0.76155096
0.65546036
d1:12172705.94179, d2:0.05858, d3:4406192.37905
0.97308964
0.65546036
d1:4757323.11862, d2:0.05117, d3:2174810.44483
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-256.3236693685498 steps:261[00m
[RDDPG] Resetting Environment
0.75005585
0.7005954
d1:2867036.91747, d2:0.05801, d3:1018352.93642
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-194.99117083404496 steps:263[00m
[RDDPG] Resetting Environment
0.73091066
0.73804057
d1:14788037.09703, d2:0.03798, d3:3981287.29889
0.81053126
0.5219867
d1:12914572.26678, d2:0.02583, d3:2632988.41023
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-154.9083614597347 steps:266[00m
[RDDPG] Resetting Environment
0.77347505
0.70618534
d1:11758743.49415, d2:0.05887, d3:3811927.76089
0.77347505
0.70618534
d1:10146705.24531, d2:0.03002, d3:892915.65028
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-69.53399979910567 steps:269[00m
[RDDPG] Resetting Environment
0.7388429
0.7187352
d1:3822499.41347, d2:0.05481, d3:1306938.14111
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-66.91677418379709 steps:271[00m
[RDDPG] Resetting Environment
0.66723937
0.7211426
d1:10131221.80903, d2:0.04136, d3:5026299.72761
0.995527
0.7211426
d1:13267724.68907, d2:0.03935, d3:3890854.35564
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-287.60359093668035 steps:274[00m
[RDDPG] Resetting Environment
0.7463706
0.69465435
d1:23289371.76293, d2:0.01721, d3:2130123.83988
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:12.52162719151356 steps:276[00m
[RDDPG] Resetting Environment
0.7572367
0.75452954
d1:15399860.45659, d2:0.05855, d3:5231866.13238
0.7572367
0.75452954
d1:5811674.45561, d2:0.05776, d3:320617.90018
0.7572367
0.75452954
d1:6499510.65382, d2:0.05633, d3:76396.51292
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-114.76209439575062 steps:280[00m
[RDDPG] Resetting Environment
0.7511005
0.7501891
d1:7289016.17801, d2:0.05196, d3:356315.12668
0.7511005
0.7501891
d1:7234025.35979, d2:0.05227, d3:317490.57436
0.7138895
0.46405137
d1:13696311.28548, d2:0.05178, d3:3607511.40071
0.7138895
0.32038602
d1:18248491.15980, d2:0.05699, d3:6522450.48681
0.57129556
0.32038602
d1:27814885.85895, d2:0.05840, d3:14939116.72445
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-452.8191002450635 steps:286[00m
[RDDPG] Resetting Environment
0.76457715
0.6873557
d1:5318712.30707, d2:0.05897, d3:1685565.15862
0.76457715
0.6873557
d1:5287434.33468, d2:0.04462, d3:1754417.65025
0.76457715
0.6873557
d1:5287982.30236, d2:0.04462, d3:1754596.49293
0.76457715
0.6873557
d1:5196808.56370, d2:0.04464, d3:1724560.08657
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-304.22366774139925 steps:291[00m
[RDDPG] Resetting Environment
0.74840313
0.7360418
d1:18083733.00361, d2:0.05938, d3:5819511.50434
0.74840313
0.5685054
d1:3292758.98392, d2:0.05936, d3:2039957.48867
0.74840313
0.6166427
d1:12422897.88225, d2:0.04189, d3:7114874.44437
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-304.3224079185018 steps:295[00m
[RDDPG] Resetting Environment
0.75457644
0.7640525
d1:4763245.19696, d2:0.00666, d3:155380.29072
0.5754744
0.8062073
d1:12997762.13939, d2:0.03293, d3:3459381.28201
0.6462817
1.039375
d1:14755155.95449, d2:0.01694, d3:2577178.23515
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-136.75763826451248 steps:299[00m
[RDDPG] Resetting Environment
0.74915737
0.71956015
d1:19061422.08118, d2:0.01230, d3:1165196.82027
0.74915737
0.71956015
d1:16821868.21170, d2:0.05868, d3:4157045.88341
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-37.15715000012541 steps:302[00m
[RDDPG] Resetting Environment
0.6840756
0.69596684
d1:19305832.54715, d2:0.05711, d3:6455675.14392
0.8594237
0.7204892
d1:16464205.30861, d2:0.05924, d3:4515047.14295
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-72.58931030567325 steps:305[00m
[RDDPG] Resetting Environment
0.7547768
0.7141023
d1:20924638.54409, d2:0.05896, d3:7559894.24999
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:27.594771671892445 steps:307[00m
[RDDPG] Resetting Environment
0.746689
0.74809843
d1:10725863.59613, d2:0.04683, d3:3519396.57591
0.57507724
0.74809843
d1:10747839.50551, d2:0.05935, d3:2991912.70531
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-171.56139775309924 steps:310[00m
[RDDPG] Resetting Environment
0.7951691
0.5631634
d1:8307526.47203, d2:0.05613, d3:4885123.88807
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-126.24953974220841 steps:312[00m
[RDDPG] Resetting Environment
0.7415326
0.8217674
d1:14081512.98998, d2:0.05807, d3:5084477.02374
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-50.406944871496364 steps:314[00m
[RDDPG] Resetting Environment
0.74852437
0.7364704
d1:4963485.49143, d2:0.05849, d3:1719454.97058
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-152.53599844010813 steps:316[00m
[RDDPG] Resetting Environment
0.7374574
0.7298857
d1:6316483.97654, d2:0.05720, d3:2107420.30511
0.7374574
0.7298857
d1:5851655.92048, d2:0.05727, d3:1952484.80508
0.7374574
0.7298857
d1:6250804.54537, d2:0.04619, d3:2087939.84933
0.7374574
0.7298857
d1:6338954.77981, d2:0.05565, d3:2115635.82079
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-329.961927055811 steps:321[00m
[RDDPG] Resetting Environment
0.74843234
0.72070295
d1:23895725.53321, d2:0.03896, d3:6435155.56760
0.74843234
0.72070295
d1:24723596.19805, d2:0.03725, d3:6256185.99308
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-109.47074612963584 steps:324[00m
[RDDPG] Resetting Environment
0.7599698
0.7276725
d1:11388863.76607, d2:0.05264, d3:769981.25006
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-111.60469912853917 steps:326[00m
[RDDPG] Resetting Environment
0.69050586
0.53782946
d1:9792107.55616, d2:0.05778, d3:298352.01138
0.69050586
0.53782946
d1:30586834.31547, d2:0.05865, d3:10879182.89841
0.3845214
0.69185007
d1:6035291.52220, d2:0.05480, d3:1767493.56702
0.3845214
0.69185007
d1:6035316.37053, d2:0.05480, d3:1767484.82460
0.3845214
0.69185007
d1:6035396.02768, d2:0.05479, d3:1767456.72514
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-248.84981106368213 steps:332[00m
[RDDPG] Resetting Environment
0.74528027
0.80152345
d1:6896650.54229, d2:0.02051, d3:598912.09642
0.74528027
0.80152345
d1:4040736.84004, d2:0.05343, d3:486315.41639
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-121.60733496204094 steps:335[00m
[RDDPG] Resetting Environment
0.74186647
0.6839343
d1:14570822.00343, d2:0.05733, d3:4683822.45806
0.74186647
0.6839343
d1:15259428.26025, d2:0.05622, d3:4899820.27221
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-100.10622267677363 steps:338[00m
[RDDPG] Resetting Environment
0.75602496
0.7046677
d1:6977713.73200, d2:0.05773, d3:1380928.44651
0.5362367
0.7046677
d1:24980268.66388, d2:0.05274, d3:3295386.02161
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-271.6060548295783 steps:341[00m
[RDDPG] Resetting Environment
0.7598017
0.7477575
d1:23175991.57238, d2:0.05405, d3:2005875.56814
0.7598017
0.7477575
d1:23770493.66342, d2:0.05909, d3:8193345.43363
0.66577876
0.7477575
d1:7704634.04316, d2:0.05924, d3:5091887.44821
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-254.8166990313158 steps:345[00m
[RDDPG] Resetting Environment
0.7459713
0.74259
d1:21502892.60576, d2:0.05645, d3:7400881.20453
0.7459713
0.74259
d1:19313559.81852, d2:0.05718, d3:6649799.75533
0.53983355
0.76687646
d1:38053319.12679, d2:0.01183, d3:4829248.95385
0.53983355
0.76687646
d1:38053319.42228, d2:0.01183, d3:4829249.16662
0.53983355
0.59970176
d1:42207096.89038, d2:0.04735, d3:15243403.58198
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:65.26047766453699 steps:351[00m
[RDDPG] Resetting Environment
0.74592394
0.7288918
d1:14113452.96994, d2:0.03454, d3:2995636.43676
0.74592394
0.7288918
d1:12910901.25793, d2:0.03972, d3:3335775.33873
0.74592394
0.7288918
d1:14038438.20779, d2:0.03486, d3:3020891.63074
0.91872126
0.63163775
d1:19535646.62514, d2:0.05656, d3:5722038.48504
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-454.48921700209496 steps:356[00m
[RDDPG] Resetting Environment
0.9053964
0.7287706
d1:13323968.25870, d2:0.03233, d3:3529268.32750
0.9053964
0.7287706
d1:18410232.27459, d2:0.01838, d3:3552998.21294
0.9053964
0.7287706
d1:12200830.59290, d2:0.05778, d3:5288560.01750
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-231.17349466415533 steps:360[00m
[RDDPG] Resetting Environment
0.757127
0.61682796
d1:6287650.24722, d2:0.04603, d3:1133951.53163
0.7461268
0.61682796
d1:12435628.00233, d2:0.05656, d3:1712460.20913
0.7887041
0.61682796
d1:12094233.99282, d2:0.05939, d3:7492099.82380
0.7887041
0.61682796
d1:11812056.20045, d2:0.05939, d3:7883073.30314
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-199.33725395309233 steps:365[00m
[RDDPG] Resetting Environment
0.7382158
0.7313672
d1:14101141.73579, d2:0.02555, d3:2008460.31657
0.89566064
0.7863185
d1:6172963.46303, d2:0.05897, d3:182330.84764
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-57.66378217333232 steps:368[00m
[RDDPG] Resetting Environment
0.72226673
0.8790616
d1:2582648.10739, d2:0.05765, d3:830257.79724
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-145.58052029026118 steps:370[00m
[RDDPG] Resetting Environment
0.7434303
0.7741778
d1:12244096.19818, d2:0.01775, d3:954050.72160
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-163.90762951247012 steps:372[00m
[RDDPG] Resetting Environment
0.77955014
0.6749175
d1:14527357.19075, d2:0.05882, d3:4076947.05427
0.77955014
0.6749175
d1:6144425.23916, d2:0.05936, d3:2413702.41422
0.77955014
0.6749175
d1:16756961.55673, d2:0.02435, d3:2771761.83950
0.77955014
0.6749175
d1:15310190.79249, d2:0.03002, d3:3156984.06757
0.67443806
0.6749175
d1:50657877.13286, d2:0.05917, d3:8073245.79239
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-174.80366672068465 steps:378[00m
[RDDPG] Resetting Environment
0.7406552
0.7213982
d1:17199881.53345, d2:0.05524, d3:3119221.03766
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-189.3006466448996 steps:380[00m
[RDDPG] Resetting Environment
0.75159
0.7598127
d1:13480524.89159, d2:0.05346, d3:574453.60707
0.57824874
0.9297847
d1:24015170.48577, d2:0.05623, d3:6270706.30163
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-57.970320941947875 steps:383[00m
[RDDPG] Resetting Environment
0.74102414
0.6736903
d1:1738814.16538, d2:0.05767, d3:632341.81952
0.74102414
0.6736903
d1:1724693.37336, d2:0.05041, d3:633965.78888
0.74102414
0.6736903
d1:1735595.67948, d2:0.05814, d3:628876.65483
0.7314249
0.58705723
d1:7678828.67265, d2:0.05881, d3:1597616.63347
0.78004575
0.6027755
d1:22015280.54734, d2:0.05909, d3:9191722.90830
0.78004575
0.6027755
d1:17042717.92143, d2:0.05625, d3:7848243.25215
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-504.85353000472884 steps:390[00m
[RDDPG] Resetting Environment
0.773987
0.71642506
d1:4311544.38462, d2:0.01540, d3:226380.19866
0.8650574
0.62357605
d1:5773918.28309, d2:0.03680, d3:1755609.52047
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-238.32124122610995 steps:393[00m
[RDDPG] Resetting Environment
0.7317487
0.68966454
d1:5937417.04535, d2:0.04250, d3:2031501.99095
0.7317487
0.68966454
d1:6495320.15161, d2:0.05523, d3:973615.59200
0.6107383
0.50204283
d1:22669233.93883, d2:0.05425, d3:6224581.35662
0.6107383
0.50204283
d1:22671262.38657, d2:0.05425, d3:6225086.29430
0.45278588
0.6631578
d1:41496846.54215, d2:0.05671, d3:10582595.81432
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-273.8895421168505 steps:399[00m
[RDDPG] Resetting Environment
0.75162506
0.75433165
d1:10931207.08654, d2:0.05918, d3:3360770.16405
0.75162506
0.75433165
d1:20121233.63919, d2:0.02827, d3:2946477.28976
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-104.02755641164549 steps:402[00m
[RDDPG] Resetting Environment
0.7431614
0.7380063
d1:15661788.85673, d2:0.05407, d3:5262265.01644
0.7522984
0.8325942
d1:2737425.04101, d2:0.05859, d3:879862.63182
0.7522984
0.8325942
d1:2737383.62527, d2:0.05859, d3:879849.91903
0.7522984
0.8325942
d1:2737443.93403, d2:0.05859, d3:879868.43206
0.58302736
0.7750841
d1:13385304.76417, d2:0.04777, d3:815574.73328
0.58302736
0.7750841
d1:13184575.48178, d2:0.04977, d3:348467.08140
0.58302736
0.7750841
d1:13029751.69066, d2:0.05139, d3:612388.23920
0.58302736
0.7750841
d1:13034400.44424, d2:0.05134, d3:599779.87363
0.58302736
0.7750841
d1:13035851.91117, d2:0.05132, d3:595857.79585
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:232.9998665520488 steps:412[00m
[RDDPG] Resetting Environment
0.7522662
0.7507706
d1:14748064.15173, d2:0.04438, d3:4744779.18436
0.7522662
0.7507706
d1:14377447.76531, d2:0.04328, d3:4626742.62614
0.7522662
0.7507706
d1:14079448.68376, d2:0.04245, d3:4531086.53312
0.7522662
0.7507706
d1:13859721.87845, d2:0.04187, d3:4461832.23133
0.7522662
0.7507706
d1:14032971.60223, d2:0.04232, d3:4516070.96148
0.7522662
0.7507706
d1:13979971.99835, d2:0.04218, d3:4499116.08723
0.7522662
0.7507706
d1:14041535.02399, d2:0.04234, d3:4518840.14776
0.7522662
0.7507706
d1:14398152.69438, d2:0.04334, d3:4633358.68781
0.7522662
0.7507706
d1:14628099.61701, d2:0.04402, d3:4706652.18929
0.7522662
0.7507706
d1:15064100.58252, d2:0.04537, d3:4844946.40600
0.7522662
0.7507706
d1:15451271.06591, d2:0.04665, d3:4967225.85817
0.7522662
0.7507706
d1:15561484.50623, d2:0.04703, d3:5001958.42634
0.7522662
0.7507706
d1:15772438.51606, d2:0.04777, d3:5068348.42322
0.5448851
0.7507706
d1:6523898.09040, d2:0.03794, d3:1153929.93347
0.5448851
0.7507706
d1:6460863.00994, d2:0.03798, d3:1166942.78033
0.5448851
0.7507706
d1:6458905.13416, d2:0.03798, d3:1167342.49950
0.5448851
0.7507706
d1:6435682.32914, d2:0.03800, d3:1172063.85967
0.5448851
0.7507706
d1:6435782.38664, d2:0.03800, d3:1172043.74936
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:576.1489089550292 steps:431[00m
[RDDPG] Resetting Environment
0.7483324
0.6037165
d1:30561718.90509, d2:0.04243, d3:10858506.61474
0.7608225
0.8078499
d1:2821509.44012, d2:0.05930, d3:924134.65889
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1073, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 15:03:25.350552: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:03:25.350587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620120812.022765805, 1.005000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620120812.025751789, 1.006000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620120812.026155633, 1.006000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620120813.614870564, 2.139000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620120814.825263979, 3.000000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620120815.895975611, 3.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620120816.985079427, 4.602000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[31493868.59005371 -1092086.26694697        0.        ]
d1:33009638.14872, d2:0.04318, d3:10590362.36312
[ 611615.73220722 1868594.71405517       0.        ]
d1:2392989.29315, d2:0.05030, d3:809556.94862
[ 612635.37801188 1868571.33268442       0.        ]
d1:2394029.48437, d2:0.05032, d3:809885.13823
[ 615065.75010536 1868511.91915065       0.        ]
d1:2396505.43747, d2:0.05036, d3:810666.19444
[-8457931.13865133  8870839.88120606        0.        ]
d1:19661542.35448, d2:0.05772, d3:5729425.76804
[-10586601.53950858 -16396372.79747228         0.        ]
d1:29993136.22890, d2:0.05128, d3:2877772.54836
[-10335704.45258943 -16581630.31295034         0.        ]
d1:30398953.32293, d2:0.05125, d3:2737072.39170
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[-8871690.60478544  5652407.76427612        0.        ]
d1:14112786.71525, d2:0.05548, d3:415655.90281
[ 36730348.34065393 -10482718.32299152         0.        ]
d1:57317983.30216, d2:0.05562, d3:16022825.05366
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[-20189556.47323674  16104119.92906707         0.        ]
d1:33441478.42084, d2:0.05086, d3:2716323.39383
[ 32821122.85031435 -13332113.82305208         0.        ]
d1:60401029.24005, d2:0.05430, d3:18213810.90477
[1381171.5632237  3174002.72180755       0.        ]
d1:2432546.45858, d2:0.05702, d3:1210972.88560
[2718450.77434263 6025352.95951388       0.        ]
d1:5723423.51752, d2:0.02810, d3:1724542.34677
[2722761.63428222 6022882.44390819       0.        ]
d1:5723978.14492, d2:0.02813, d3:1726869.39722
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:234.46021535786102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-109.43896666991843 steps:1[00m
[RDDPG] Resetting Environment
[11480433.8397253  -7027505.78712563        0.        ]
d1:17707219.77889, d2:0.05728, d3:6202442.71935
[ 6894396.26051167 -1831275.05083807        0.        ]
d1:8448799.12283, d2:0.05883, d3:3001944.23475
[11459618.04430079 -7027125.58541442        0.        ]
d1:17686424.31959, d2:0.05730, d3:6194937.03684
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-188.53313353110414 steps:5[00m
[RDDPG] Resetting Environment
[-246722.24289807 6962595.97638156       0.        ]
d1:7380219.93454, d2:0.04418, d3:2486838.06745
[4144404.66720572 3066080.15702128       0.        ]
d1:7140948.70799, d2:0.05338, d3:594654.45322
[24694469.63519307 12104112.6326852         0.        ]
d1:27946406.66531, d2:0.05340, d3:11124644.68104
[17739162.59474725  8539238.39482909        0.        ]
d1:27778556.13305, d2:0.05781, d3:8720185.23054
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-497.9638567525756 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-89.20744103516469 steps:11[00m
[RDDPG] Resetting Environment
[ 4180198.97094334 -4396599.23691394        0.        ]
d1:8135353.00962, d2:0.05940, d3:2893993.06080
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-482.3809875353434 steps:13[00m
[RDDPG] Resetting Environment
[ 7939704.05278006 -9397384.42575319        0.        ]
d1:16812245.25181, d2:0.00850, d3:539960.77864
[ 7362237.89907444 -9441210.31404748        0.        ]
d1:16284421.19173, d2:0.00867, d3:735248.18038
[-5413948.10532263   189319.81816746        0.        ]
d1:5675067.02503, d2:0.05333, d3:1859195.46879
[4158847.35042036  430957.90917628       0.        ]
d1:4121632.20999, d2:0.05803, d3:1949081.15623
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-461.28493768960476 steps:18[00m
[RDDPG] Resetting Environment
[5107983.96846073 -409626.71647945       0.        ]
d1:3703478.55491, d2:0.05855, d3:2348842.00381
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-276.94208523255816 steps:20[00m
[RDDPG] Resetting Environment
[ 4336471.40544322 -8059045.19323866        0.        ]
d1:12029054.86789, d2:0.05719, d3:4032989.32015
[-5939866.60374742  7613764.21278731        0.        ]
d1:11782120.31848, d2:0.01691, d3:525095.80475
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-189.06094422322622 steps:23[00m
[RDDPG] Resetting Environment
[16811860.47224388 -4676417.36956685        0.        ]
d1:19788919.68122, d2:0.05917, d3:6989785.14709
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-162.2550562580637 steps:25[00m
[RDDPG] Resetting Environment
[9831297.55682638 8767955.00133335       0.        ]
d1:19205335.57317, d2:0.05288, d3:864372.13677
[-15028560.44788742   6974669.09719031         0.        ]
d1:19583276.13791, d2:0.05895, d3:7709442.76321
[-16408139.94277265  -2327102.36628521         0.        ]
d1:19709303.33143, d2:0.05694, d3:5948681.04416
[-16395010.93396112  -2278991.14754557         0.        ]
d1:19656106.81028, d2:0.05698, d3:5929119.61047
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-11.522813178928658 steps:30[00m
[RDDPG] Resetting Environment
[12654587.89509532  7673490.19778545        0.        ]
d1:20707111.28454, d2:0.01860, d3:1624355.22713
[14610143.56438882  7751102.18147542        0.        ]
d1:22779460.85312, d2:0.01997, d3:2225848.32190
[7259334.90152698 8777853.3598612        0.        ]
d1:11730294.52147, d2:0.04278, d3:3994214.28304
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-571.3916663008067 steps:34[00m
[RDDPG] Resetting Environment
[-5218132.29399959 -4639307.96344328        0.        ]
d1:10186853.05493, d2:0.00425, d3:246699.32968
[-7973621.22550358 -2062592.8562064         0.        ]
d1:10441093.35409, d2:0.05465, d3:1944413.88197
[-2357136.56567627 -2666701.05646897        0.        ]
d1:5187786.14791, d2:0.04852, d3:103480.63964
[-6883903.42538731 -5818595.60863348        0.        ]
d1:8984514.02760, d2:0.05440, d3:3645565.93175
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-491.97813088363216 steps:39[00m
[RDDPG] Resetting Environment
[13684810.76799521 26553752.21687568        0.        ]
d1:39516638.32804, d2:0.02115, d3:5134149.22319
[-21587520.97063188  -2889467.69759898         0.        ]
d1:30232985.26284, d2:0.05040, d3:8398566.02616
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-78.35527053493271 steps:42[00m
[RDDPG] Resetting Environment
[-9997008.56557332 -7275906.63259358        0.        ]
d1:17139858.02140, d2:0.05939, d3:5646466.29455
[  5889524.8459766  -40971976.27304418         0.        ]
d1:55182757.04882, d2:0.04772, d3:16100327.45291
[ -3606761.53769379 -22039637.07441278         0.        ]
d1:25569659.40164, d2:0.05928, d3:12426167.52212
[43405272.78065309 28545812.94696039        0.        ]
d1:64131476.40403, d2:0.05495, d3:16636893.21818
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-10.49914879995029 steps:47[00m
[RDDPG] Resetting Environment
[ -702561.38488562 16354858.82256456        0.        ]
d1:17002195.19219, d2:0.04096, d3:4936804.74904
[  916160.84274168 16496814.31266886        0.        ]
d1:18094677.56762, d2:0.04465, d3:5512001.19030
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-164.97441278085608 steps:50[00m
[RDDPG] Resetting Environment
[ 883798.16641873 3923960.34072534       0.        ]
d1:4726190.16315, d2:0.05601, d3:1112616.21573
[ 445142.82817676 -723720.5864524        0.        ]
d1:700465.66140, d2:0.05887, d3:101990.42186
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-257.6885776327522 steps:53[00m
[RDDPG] Resetting Environment
[17419585.85196641  2265592.0480551         0.        ]
d1:20485865.36229, d2:0.05921, d3:5235709.41895
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:3.2075734013812536 steps:55[00m
[RDDPG] Resetting Environment
[7694956.71005817 -484453.92349816       0.        ]
d1:8098094.25029, d2:0.04500, d3:2640200.03885
[7351035.75340616 -244937.31247315       0.        ]
d1:7623511.05743, d2:0.05648, d3:2452874.59903
[13070310.65567646  3826219.32945242        0.        ]
d1:13093461.92428, d2:0.05785, d3:6138341.66464
[-5408945.68959978 -5932322.82442085        0.        ]
d1:7871988.70574, d2:0.05764, d3:3856351.79640
[-1242652.54366916  4740923.79494962        0.        ]
d1:6130724.56331, d2:0.02518, d3:2563655.07411
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-485.76711727574263 steps:61[00m
[RDDPG] Resetting Environment
[-332480.30083539 1933113.64828633       0.        ]
d1:2089724.80355, d2:0.04774, d3:723871.28451
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-349.0708616669274 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-84.37046459472613 steps:64[00m
[RDDPG] Resetting Environment
[-5492305.7386709   5166084.21202871        0.        ]
d1:10410197.89551, d2:0.05937, d3:3412690.66108
[-11338846.2174696  -20199977.65412205         0.        ]
d1:23924111.01369, d2:0.04199, d3:5958446.81604
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-502.54618814125365 steps:67[00m
[RDDPG] Resetting Environment
[-12094508.31231956 -17707093.09010013         0.        ]
d1:27304986.92892, d2:0.01861, d3:1723465.26581
[-20789268.94197672  -6586523.64373308         0.        ]
d1:25154376.11793, d2:0.05589, d3:6465465.71871
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:16.377691804372105 steps:70[00m
[RDDPG] Resetting Environment
[ 11717058.72145234 -18218405.77351334         0.        ]
d1:29092256.38806, d2:0.01353, d3:2373058.87440
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-173.94243229426462 steps:72[00m
[RDDPG] Resetting Environment
[17241225.62039467  2154999.95240671        0.        ]
d1:19251985.85141, d2:0.05599, d3:5415275.81536
[-5360459.0205222   2180355.35459385        0.        ]
d1:3713018.27386, d2:0.00415, d3:2915382.86153
[17265670.06034661  1494121.13944059        0.        ]
d1:18124401.57085, d2:0.05938, d3:3370952.70561
[9766733.8487366  4862083.32706571       0.        ]
d1:12414106.22016, d2:0.04931, d3:541710.11024
[9332978.35647459 2880287.55261394       0.        ]
d1:10801355.25078, d2:0.05746, d3:1051768.95493
[9410936.72596689 3478701.8858729        0.        ]
d1:11225652.38470, d2:0.05579, d3:847065.49504
[5741016.34463428 4468849.47286453       0.        ]
d1:8724168.10192, d2:0.05905, d3:2788619.42912
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-461.8953795920099 steps:80[00m
[RDDPG] Resetting Environment
[-924710.45690316 9027418.6088702        0.        ]
d1:9808409.48971, d2:0.05352, d3:3196024.35399
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-181.448975535007 steps:82[00m
[RDDPG] Resetting Environment
[20642435.19399545  6981186.26171777        0.        ]
d1:27167637.14309, d2:0.05901, d3:8985287.22818
[-4784400.40717728 20707292.67204956        0.        ]
d1:22936033.72512, d2:0.03398, d3:5321919.70715
[ 4698337.95551915 23006565.95626279        0.        ]
d1:26261646.42436, d2:0.04503, d3:9074168.35578
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-32.73184109290154 steps:86[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1022, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
2021-05-04 15:06:28.852975: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:06:28.853013: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620120995.845112895, 1.194000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620120995.851017537, 1.195000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620120995.851588033, 1.197000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620120997.404046318, 2.326000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620120998.616616054, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620120999.681915107, 4.000000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620121000.774929042, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
zmp_s
[        0.           1124729.926578   -23249288.84470906]
[16557862.63119282   796764.03361326        0.        ]
zmp_s
[        0.           1124729.91183856 -23249288.87629817]
[16565925.9165178    796729.56031866        0.        ]
zmp_s
[        0.           1124729.80411035 -23249289.10138879]
[16617015.26679879   793781.33706998        0.        ]
zmp_s
[       0.         12998705.51835549 -1526752.12628508]
[-2571154.37038769 11568804.45105557        0.        ]
zmp_s
[       0.         12998712.24480605 -1526750.40065005]
[ 3328141.65308911 12643416.94904412        0.        ]
zmp_s
[       0.         -7114527.47544446  -978211.15586386]
[  787695.05932564 -7137433.12567085        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
zmp_s
[       0.          4726211.35444083 -5752108.5703709 ]
[1007432.63776323 1630088.71986475       0.        ]
zmp_s
[       0.         20246661.42812011  2486321.93783485]
[12862882.20491545  1083152.07758977        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
zmp_s
[       0.         27639037.96077964  1522820.5208725 ]
[-2342676.87981535 27581335.17873668        0.        ]
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:39.0651521845847[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         20921725.91185618 -2722564.9395583 ]
[ 3282727.12038156 20805046.55796108        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-219.8328104311157 steps:2[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         10028725.99361337 -1243041.87808327]
[7646542.13254984 2301716.05423914       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-201.12657541390857 steps:4[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         18833524.17879318 -4110876.89619934]
[-9494716.89676616  6815815.36872707        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-269.34892142751494 steps:6[00m
[RDDPG] Resetting Environment
zmp_s
[        0.          -4036269.31597553 -15731367.64913703]
[11067815.68719203 -3598038.94848004        0.        ]
zmp_s
[        0.          -4036269.91044581 -15731373.10754487]
[13576070.02440072 -2142349.74162953        0.        ]
zmp_s
[       0.         30154730.58586992 29456432.20027836]
[  608970.44787359 11365064.34532196        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-552.9357599360179 steps:10[00m
[RDDPG] Resetting Environment
zmp_s
[       0.          4592130.36219783 -8927532.00506863]
[7646813.69026327 4072188.28365521       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-89.22764013405983 steps:12[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -15715107.84910461   5849460.16851727]
[ 6644235.28945358 -3156050.26281764        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-257.968764373239 steps:14[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -2425887.25630622 -5837115.11159394]
[2380552.18156254 -940272.38758611       0.        ]
zmp_s
[        0.         -16356671.97271721   4145787.80547763]
[10646886.12041471 -1896254.72217556        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-361.6740268021529 steps:17[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -15009809.99711389 -12786743.30527428]
[  7649778.69381219 -14628276.07011173         0.        ]
zmp_s
[       0.          1051842.3181446  -1041127.91245001]
[1045726.1844779   901505.65868799       0.        ]
zmp_s
[       0.          1051842.31829875 -1041127.91544543]
[1045086.64658154  901322.96613047       0.        ]
zmp_s
[        0.         -11833134.02561679   -825827.23467961]
[-1973402.15436359  8320702.05155769        0.        ]
zmp_s
[       0.         35603295.36219025 -8842246.21274146]
[-14931339.00316022  22902905.4176486          0.        ]
zmp_s
[        0.         -33618689.93825383  -1551118.56650648]
[ 12806326.43255733 -30430927.03389994         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-227.08734608734483 steps:24[00m
[RDDPG] Resetting Environment
zmp_s
[       0.          4886949.05207246 13075550.90670409]
[-10657972.97860885   4949644.38255817         0.        ]
zmp_s
[       0.         35444356.34444318  1889372.38896009]
[-12822530.86615546  32890523.83763268         0.        ]
zmp_s
[        0.         -32537481.52397604 -22878344.476413  ]
[ 9173702.64635079 16208133.723433          0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-460.3702764092693 steps:28[00m
[RDDPG] Resetting Environment
zmp_s
[        0.          18342472.93321372 -13122528.48008278]
[14752267.14461573 16998092.90557654        0.        ]
zmp_s
[       0.          -244627.37720944 -1819463.97606091]
[ 846796.66342459 -123590.45967815       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-273.6378362917547 steps:31[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -20466096.15950971 -25936296.81228694]
[ 15972163.35734447 -19615614.91516542         0.        ]
zmp_s
[        0.         -20466096.26386654 -25936296.1361083 ]
[32282006.62504184 -5134584.25639064        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-4.289781668751388 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-73.6172322949209 steps:35[00m
[RDDPG] Resetting Environment
zmp_s
[        0.          -2027097.6950604  -19506813.94330709]
[15560129.36702228   -89562.25801738        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-219.78225455770638 steps:37[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -8551114.99012317  4124770.64092202]
[-8594301.42617414 -2762968.30871936        0.        ]
zmp_s
[        0.         -19872475.41328751 -11634993.48720653]
[ 7227132.99462659 -4596060.45733864        0.        ]
zmp_s
[        0.           3182438.36202386 -19985497.60710319]
[16962052.79476513  4725830.22377698        0.        ]
zmp_s
[        0.           3182437.61294775 -19985499.58799008]
[18012626.14307725  6884558.25078282        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-615.059164473602 steps:42[00m
[RDDPG] Resetting Environment
zmp_s
[      0.         5304778.74758952 1896051.54160653]
[-4560712.53390469  2701098.83542428        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-57.004266203722246 steps:44[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         30301414.0160044    877238.97585772]
[-20269537.99273664   8915002.60379202         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-173.10045414411178 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-122.43425255859836 steps:47[00m
[RDDPG] Resetting Environment
zmp_s
[        0.           6452655.7672188  -22989240.97872136]
[10948897.75868966  2542692.11212086        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-256.22736612720905 steps:49[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         28291403.95938036 -7431063.66363447]
[ 5112000.82944591 28572696.36619966        0.        ]
zmp_s
[       0.         28291403.95945108 -7431063.6626353 ]
[ 4638446.04679501 28590579.56800318        0.        ]
zmp_s
[        0.          18543025.87326602 -14765391.37209293]
[12228752.44853157 17285511.32195735        0.        ]
zmp_s
[       0.        28695120.1375307 -7939795.7942305]
[ 15423131.57114232 -24221193.43375321         0.        ]
zmp_s
[       0.         28695120.13454214 -7939795.79528053]
[ 17091178.79076895 -22935616.60561614         0.        ]
zmp_s
[        0.         -31657311.93589669   5450539.49361296]
[   645987.06526539 -16654472.26761713         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-138.89874218637686 steps:56[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -9359794.94007752  8056839.77933197]
[-4834252.85838601 -9287855.63071074        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-64.58984404506356 steps:58[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -11995402.02952261   4805781.1752808 ]
[ -2815239.60990815 -11826824.41141894         0.        ]
zmp_s
[        0.         -11995402.01960419   4805781.83007465]
[ 4569193.59849112 -4258656.11366274        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-236.03499660382573 steps:61[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         18589228.91760037  5870451.3737734 ]
[-6271594.66149995 18385837.78147981        0.        ]
zmp_s
[       0.         18589225.06636984  5870470.33590905]
[-4962640.2106673  18613327.40771348        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-50.336472605258386 steps:64[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -21725417.9797939  -10942785.29798952]
[  7992263.09007794 -21401055.44668623         0.        ]
zmp_s
[        0.         -21725417.97219188 -10942789.5567455 ]
[  8246988.41895678 -21401437.32277653         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-172.47645114361072 steps:67[00m
[RDDPG] Resetting Environment
zmp_s
[        0.          -1554970.62937501 -17424247.95406903]
[12086377.63186818  -892066.66190853        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-240.81533447594006 steps:69[00m
[RDDPG] Resetting Environment
zmp_s
[      0.         2446950.87801261 9047173.22316627]
[-8077646.93455579  1220110.92841679        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-102.22982379700179 steps:71[00m
[RDDPG] Resetting Environment
zmp_s
[        0.         -11689593.79012349 -18824222.76964095]
[ 10754342.50915254 -10270772.86345306         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-295.7815929071704 steps:73[00m
[RDDPG] Resetting Environment
zmp_s
[       0.           374432.72300301 -2134301.54653392]
[1451667.3214633   300943.96344647       0.        ]
zmp_s
[       0.           374431.93520688 -2134301.95271019]
[1720858.48496121   49619.7148327        0.        ]
zmp_s
[        0.          -9578032.22161219 -48930978.59822458]
[41346796.1237485  20607034.39999349        0.        ]
zmp_s
[        0.          -9578032.2727586  -48930978.68592209]
[41344485.23527265 20614035.53618503        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:103.13585603951284 steps:78[00m
[RDDPG] Resetting Environment
zmp_s
[        0.           -495937.89963111 -16466275.55988515]
[12653924.04024875  -211446.0245968         0.        ]
zmp_s
[        0.           -495937.84719883 -16466275.06032062]
[12685158.41883609   -67777.12929775        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-379.33997193933345 steps:81[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -6354163.89694199   127705.63921749]
[ 4396261.98617205 -1562935.52938582        0.        ]
zmp_s
[       0.         -6354163.87883992   127705.91011189]
[ 4134064.3446545 -2504224.1074259        0.       ]
zmp_s
[       0.         19463173.41375032 -7506104.95276937]
[3827781.27145968 2324405.3553047        0.        ]
zmp_s
[       0.          1051447.60859506 -3087950.3136657 ]
[2959135.88674721 -554777.79281471       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-563.7098072339172 steps:86[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -4466637.97824979  1505992.42231727]
[-4168409.43771755  -770136.50995177        0.        ]
zmp_s
[        0.         -20143957.99987419   3920593.46779226]
[13705848.62694311    60137.56552881        0.        ]
zmp_s
[        0.         -24879295.96358848  -2989393.99390754]
[12660642.25095663  2759445.4548343         0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-291.28623583628985 steps:90[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         21786555.97727359 -7502241.38081623]
[ 6937538.43484699 21635496.52749592        0.        ]
zmp_s
[       0.         21786555.97678117 -7502241.37740752]
[ 6566985.24065982 21683541.38726652        0.        ]
zmp_s
[       0.         23468421.40413469 11355311.7636967 ]
[-7843955.83083772 11449959.49307479        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-98.15952243122192 steps:94[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         12287603.17977289  -509507.63786077]
[  288898.18166605 12270527.17921861        0.        ]
zmp_s
[       0.         -2016169.60886368  2735159.25622744]
[-2113190.5133338  -2058369.39180272        0.        ]
zmp_s
[       0.         -2016169.60886403  2735159.25623312]
[-2113211.60746786 -2058367.34886092        0.        ]
zmp_s
[       0.         -2016169.6088624   2735159.25620698]
[-2113114.7667281 -2058376.6021855        0.       ]
zmp_s
[       0.         -2016169.60886853  2735159.25630578]
[-2113481.17450312 -2058341.51165588        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-129.98482605960868 steps:100[00m
[RDDPG] Resetting Environment
zmp_s
[      0.         2548169.05162168 3307785.77642737]
[-4129390.39653738   304241.56265971        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-142.67361636725965 steps:102[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -6673031.16756735 -4922475.45437572]
[ 1971972.01814608 -6049252.79560215        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-259.6489981054526 steps:104[00m
[RDDPG] Resetting Environment
zmp_s
[       0.         -1547364.79350703  3271124.241783  ]
[-1951852.53536521 -1360318.45057682        0.        ]
zmp_s
[       0.         -1547364.79460347  3271124.33546661]
[-2402725.4752575  -1407494.15893683        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-335.1951887325929 steps:107[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620121114.701805013, 64.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121114.701923869, 64.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620121115.704277139, 64.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121115.704409623, 64.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620121116.710128265, 64.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121116.710245156, 64.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620121118.318137171, 64.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121118.318290332, 64.806000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:10:12.287900: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:10:12.287954: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620121219.208379344, 1.128000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620121219.211178303, 1.128000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620121219.211270439, 1.128000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620121220.861257558, 2.343000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620121222.054873555, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620121223.106089986, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620121224.175201770, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
[-7.23897032e-09  1.00845729e-08 -6.77485786e-09]
[0. 0. 0.]
[13681275.46913809  -619370.9611185         0.        ]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
[-7.11829282e-09  1.01701150e-08 -6.77485786e-09]
[0. 0. 0.]
[13681549.35470399  -619365.04766354        0.        ]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
[-6.53640598e-09  1.05535166e-08 -6.77485786e-09]
[0. 0. 0.]
[13682838.0283067   -619399.65719913        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[ 555.38715  212.13387 1284.7126 ]
[ 0.   0.  -9.8]
[ 274.69950849 -358.52563586 -386.59439252]
[0. 0. 0.]
[-4326561.1152259    990344.10248248        0.        ]
[ 259.7604  -313.95795 1232.3759 ]
[ 0.   0.  -9.8]
[-287.69822154  187.82882625 -219.07791759]
[0. 0. 0.]
[6498776.04761403  100929.56027513       0.        ]
[-126.80929 -400.2674  1392.8842 ]
[ 0.   0.  -9.8]
[ 356.52125433 -200.8858293    93.9788889 ]
[0. 0. 0.]
[-5115781.40296274  -233355.59748233        0.        ]
[-126.80929 -400.2674  1392.8842 ]
[ 0.   0.  -9.8]
[  23.23786575 -358.0608277   218.05279762]
[0. 0. 0.]
[3362453.4998817   726951.72984438       0.        ]
[-126.80929 -400.2674  1392.8842 ]
[ 0.   0.  -9.8]
[ 227.04739495 -277.84317297  218.05279762]
[0. 0. 0.]
[3316783.13844129  780614.55369907       0.        ]
[-476.86844  237.289    478.456  ]
[ 0.   0.  -9.8]
[-209.87596043 -365.46078982  325.73006079]
[0. 0. 0.]
[ 649405.05785912 -355732.30352699       0.        ]
[-32.1589   -40.309246 350.37585 ]
[ 0.   0.  -9.8]
[-42.2647278  -26.55566297  12.94294604]
[0. 0. 0.]
[-3478826.22572374  3289894.73016817        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[-231.70047  206.75871  922.47974]
[ 0.   0.  -9.8]
[-81.25863259 260.06409095 148.98985775]
[0. 0. 0.]
[3439543.36515061 3991790.93113452       0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.20380284 -83.80983272  74.28454558]
[0. 0. 0.]
[21611245.51731446  2511402.31829754        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.19368737 -83.81093857  74.28454558]
[0. 0. 0.]
[21611108.19640424  2515047.01034657        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.13083999 -83.81780887  74.28454558]
[0. 0. 0.]
[21610255.36135919  2537687.827396          0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.14214346 -83.81657396  74.28454558]
[0. 0. 0.]
[21610408.9439337   2533615.80949637        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.1782348  -83.81262823  74.28454558]
[0. 0. 0.]
[21610898.60133938  2520613.99117291        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.17791621 -83.81266556  74.28454558]
[0. 0. 0.]
[21610894.98763957  2520728.50185442        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.14065174 -83.8167451   74.28454558]
[0. 0. 0.]
[21610390.87542096  2534153.354707          0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.10190028 -83.82096092  74.28454558]
[0. 0. 0.]
[21609859.66036407  2548112.1390073         0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.12404071 -83.81855238  74.28454558]
[0. 0. 0.]
[21610163.21181925  2540136.82013408        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.09916362 -83.82125036  74.28454558]
[0. 0. 0.]
[21609819.90955352  2549097.78913195        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.07924896 -83.8234174   74.28454558]
[0. 0. 0.]
[21609547.0746335   2556271.08151265        0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.0648716  -83.82496172  74.28454558]
[0. 0. 0.]
[21609344.70695621  2561449.1325531         0.        ]
[-111.56789  -13.4014   477.3177 ]
[ 0.   0.  -9.8]
[ -9.08424579 -83.82287441  74.28454558]
[0. 0. 0.]
[21609615.73507801  2554471.2084972         0.        ]
[-139.58223 -276.92346  217.82896]
[ 0.   0.  -9.8]
[  -8.86940151 -305.52515592  -52.3977189 ]
[0. 0. 0.]
[-3691060.56925147 -6749397.74212438        0.        ]
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:245.33531659443372[00m
[RDDPG] Resetting Environment
[-559.31976  -105.852425 -804.4062  ]
[ 0.   0.  -9.8]
[  42.84875273 -411.83913466  390.63520937]
[0. 0. 0.]
[2309123.25431543  -48478.67898771       0.        ]
[-559.31976  -105.852425 -804.4062  ]
[ 0.   0.  -9.8]
[ -16.9342582  -413.7157436   390.63520937]
[0. 0. 0.]
[2318416.91455851 -104657.59931273       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-379.17441669369435 steps:3[00m
[RDDPG] Resetting Environment
[-711.56433  557.5079   561.14044]
[ 0.   0.  -9.8]
[-598.07401219  452.96157577  504.25406477]
[0. 0. 0.]
[5018618.05200916 5651030.24193006       0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-128.22551428334432 steps:5[00m
[RDDPG] Resetting Environment
[-346.5986  -474.6421  1019.03955]
[ 0.   0.  -9.8]
[ -85.84184491 -525.81724473  248.11917093]
[0. 0. 0.]
[ 2309178.83760224 20392617.09315316        0.        ]
[-346.5986  -474.6421  1019.03955]
[ 0.   0.  -9.8]
[  27.56972254 -554.27561088  193.4791266 ]
[0. 0. 0.]
[9773259.12233447 3058995.52903129       0.        ]
[1594.5133  -460.21982 -106.49801]
[ 0.   0.  -9.8]
[-861.14943208 1010.6979169  -995.58349661]
[0. 0. 0.]
[-5625800.3913199 -1160152.4862607        0.       ]
[1594.5133  -460.21982 -106.49801]
[ 0.   0.  -9.8]
[ -312.12848102 -1290.60615491  -995.58349661]
[0. 0. 0.]
[  280387.75247348 -1161648.66633672        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-557.3822502208028 steps:10[00m
[RDDPG] Resetting Environment
[ 306.11078  286.2169  1147.0171 ]
[ 0.   0.  -9.8]
[ 269.76542455  238.22896303 -214.70327487]
[0. 0. 0.]
[ -491569.08890717 -9938638.29114795        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-229.41794055202797 steps:12[00m
[RDDPG] Resetting Environment
[ 266.20908  -32.32486 -693.2726 ]
[ 0.   0.  -9.8]
[ 183.96716294   37.49955917 -191.47332211]
[0. 0. 0.]
[ 1603349.24559248 -6545581.98988272        0.        ]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-113.70093842086226 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-151.49672277343706 steps:15[00m
[RDDPG] Resetting Environment
2021-05-04 15:12:03.924753: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:12:03.924795: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620121330.862632437, 1.175000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620121330.871670500, 1.181000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620121330.872048493, 1.181000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620121332.305022106, 2.223000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620121333.334453052, 3.000000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620121334.434628405, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620121335.494222045, 4.600000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
inertial
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[-7.18109266e-09  1.02532665e-08 -6.58045840e-09]
[0. 0. 0.]
inertial
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[-7.78872356e-09  9.79966108e-09 -6.58045840e-09]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[ 674.85596 -208.82375  881.67944]
[ 0.   0.  -9.8]
support
[-132.19033346 -499.63025185 -481.59452109]
[0. 0. 0.]
inertial
[ 674.85596 -208.82375  881.67944]
[ 0.   0.  -9.8]
support
[-179.18067404  -58.24814512 -680.83724875]
[0. 0. 0.]
inertial
[290.54697 299.2881  251.58928]
[ 0.   0.  -9.8]
support
[ -89.39488585 -324.09263769 -246.9077475 ]
[0. 0. 0.]
inertial
[290.54697 299.2881  251.58928]
[ 0.   0.  -9.8]
support
[  35.85511009 -334.27815702 -246.9077475 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[ 667.0518   125.94998 1053.9062 ]
[ 0.   0.  -9.8]
support
[ 297.86954177 -387.65596797 -470.97571755]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-132.44856850646198[00m
[RDDPG] Resetting Environment
inertial
[ 334.28064 -287.10242  172.89183]
[ 0.   0.  -9.8]
support
[  72.55478955 -359.03241636 -244.95483772]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-189.57525206096935 steps:2[00m
[RDDPG] Resetting Environment
inertial
[ 334.28064 -287.10242  172.89183]
[ 0.   0.  -9.8]
support
[-239.33234654 -278.13774762 -243.98929384]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-165.2594913793701 steps:4[00m
[RDDPG] Resetting Environment
inertial
[   20.898277 -1019.56305   1363.7996  ]
[ 0.   0.  -9.8]
support
[-854.41580219 -556.70212546   -1.41798099]
[0. 0. 0.]
inertial
[ 637.3484  1126.0868  -592.05347]
[ 0.   0.  -9.8]
support
[1202.22590752  387.37483036  280.85270593]
[0. 0. 0.]
inertial
[ 684.7785      -7.0530295 -331.41812  ]
[ 0.   0.  -9.8]
support
[  -2.08199572  576.32492139 -369.88738099]
[0. 0. 0.]
inertial
[ 684.7785      -7.0530295 -331.41812  ]
[ 0.   0.  -9.8]
support
[226.3426106  395.05681986 511.53760991]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-156.05106776473775 steps:9[00m
[RDDPG] Resetting Environment
inertial
[ 419.47104 -140.36815 1177.3759 ]
[ 0.   0.  -9.8]
support
[ 272.77612401 -164.24771706 -307.04242089]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-153.1149378052659 steps:11[00m
[RDDPG] Resetting Environment
inertial
[226.53006 207.52315 329.62543]
[ 0.   0.  -9.8]
support
[-195.73962748  175.64253413 -158.79994054]
[0. 0. 0.]
inertial
[226.53006 207.52315 329.62543]
[ 0.   0.  -9.8]
support
[  55.01570845  206.19612335 -220.99358943]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-202.20274449856572 steps:14[00m
[RDDPG] Resetting Environment
inertial
[-461.75418 -184.36601  801.84766]
[ 0.   0.  -9.8]
support
[ -34.28350017 -145.12152168  474.31228925]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-170.0049497886482 steps:16[00m
[RDDPG] Resetting Environment
inertial
[-80.38905 435.78485 583.03284]
[ 0.   0.  -9.8]
support
[-49.02603789 436.50038902  58.60643444]
[0. 0. 0.]
inertial
[-408.3661  -724.89276 1064.0736 ]
[ 0.   0.  -9.8]
support
[ 192.19348218 -750.90569764  302.38171705]
[0. 0. 0.]
inertial
[-408.3661  -724.89276 1064.0736 ]
[ 0.   0.  -9.8]
support
[ 192.60972697 -750.79904267  302.38171705]
[0. 0. 0.]
inertial
[-408.3661  -724.89276 1064.0736 ]
[ 0.   0.  -9.8]
support
[ 603.4351223  -542.46415194  183.93241991]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-158.72737979445154 steps:21[00m
[RDDPG] Resetting Environment
inertial
[-340.84656   -34.621807 -101.70006 ]
[ 0.   0.  -9.8]
support
[-239.69204214  -55.46776909  238.4242319 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-75.13916985260568 steps:23[00m
[RDDPG] Resetting Environment
inertial
[-340.84656   -34.621807 -101.70006 ]
[ 0.   0.  -9.8]
support
[238.14921514  -9.08203716 246.12502123]
[0. 0. 0.]
inertial
[ 762.60895   -11.943803 1828.7202  ]
[ 0.   0.  -9.8]
support
[ 477.67107087 -230.28792786 -548.19061151]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-399.8466126523065 steps:26[00m
[RDDPG] Resetting Environment
inertial
[ -90.665565 -437.59314  -123.05952 ]
[ 0.   0.  -9.8]
support
[ 402.83419411 -178.60777409   74.37664417]
[0. 0. 0.]
inertial
[ -90.665565 -437.59314  -123.05952 ]
[ 0.   0.  -9.8]
support
[-440.45077419   13.38747299   74.37664417]
[0. 0. 0.]
inertial
[ -90.665565 -437.59314  -123.05952 ]
[ 0.   0.  -9.8]
support
[-441.47719821  -47.52634452   50.46905783]
[0. 0. 0.]
inertial
[1094.343   -386.27347  227.40714]
[ 0.   0.  -9.8]
support
[-944.83901828 -603.56404609 -299.63906265]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-362.1794961368995 steps:31[00m
[RDDPG] Resetting Environment
inertial
[ -23.822256 -176.1848   -272.4357  ]
[ 0.   0.  -9.8]
support
[ 119.55557662 -131.04238044   11.95586453]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-174.62389603737662 steps:33[00m
[RDDPG] Resetting Environment
inertial
[ -23.822256 -176.1848   -272.4357  ]
[ 0.   0.  -9.8]
support
[  -9.20827402 -176.37226424   20.41121191]
[0. 0. 0.]
inertial
[ -23.822256 -176.1848   -272.4357  ]
[ 0.   0.  -9.8]
support
[  -9.25349163 -176.36989966   20.41121191]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-219.0670574024372 steps:36[00m
[RDDPG] Resetting Environment
inertial
[-91.82066 138.94128 330.16763]
[ 0.   0.  -9.8]
support
[-86.24372167 126.68755644  65.17668402]
[0. 0. 0.]
inertial
[-91.82066 138.94128 330.16763]
[ 0.   0.  -9.8]
support
[-153.19731281   -4.27772979   65.17668402]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-495.00934653428476 steps:39[00m
[RDDPG] Resetting Environment
inertial
[-217.71289 -225.85338  130.55154]
[ 0.   0.  -9.8]
support
[ 145.11509123 -234.4080581   149.67673152]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-124.80634760958195 steps:41[00m
[RDDPG] Resetting Environment
inertial
[-425.97992 -147.17445  553.601  ]
[ 0.   0.  -9.8]
support
[-323.46219917  -64.8236759   307.06564099]
[0. 0. 0.]
inertial
[-425.97992 -147.17445  553.601  ]
[ 0.   0.  -9.8]
support
[ -24.82976428 -328.95805351  307.06564099]
[0. 0. 0.]
inertial
[-425.97992 -147.17445  553.601  ]
[ 0.   0.  -9.8]
support
[ -7.09259568  76.44624929 444.1000645 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-122.22620279745009 steps:45[00m
[RDDPG] Resetting Environment
inertial
[ 754.5653    -452.86774      3.2917707]
[ 0.   0.  -9.8]
support
[ 587.31778357 -347.41747965 -555.71300923]
[0. 0. 0.]
inertial
[ 754.5653    -452.86774      3.2917707]
[ 0.   0.  -9.8]
support
[-263.24888799 -629.55632702 -555.71300923]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-185.4585923371319 steps:48[00m
[RDDPG] Resetting Environment
inertial
[-498.0591 -975.094   776.5783]
[ 0.   0.  -9.8]
support
[-600.95426851 -830.70211379  384.26444894]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-151.77267395395194 steps:50[00m
[RDDPG] Resetting Environment
inertial
[ -278.31006 -1040.2412    374.54053]
[ 0.   0.  -9.8]
support
[1031.49652165 -241.05561998  193.55994498]
[0. 0. 0.]
inertial
[ -278.31006 -1040.2412    374.54053]
[ 0.   0.  -9.8]
support
[  167.62426597 -1045.94215517   193.55994498]
[0. 0. 0.]
inertial
[ -278.31006 -1040.2412    374.54053]
[ 0.   0.  -9.8]
support
[ 868.02342881 -607.14759356  193.55994498]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-79.65766315642834 steps:54[00m
[RDDPG] Resetting Environment
inertial
[ -278.31006 -1040.2412    374.54053]
[ 0.   0.  -9.8]
support
[   77.78242211 -1066.30276949   128.47778711]
[0. 0. 0.]
inertial
[ -278.31006 -1040.2412    374.54053]
[ 0.   0.  -9.8]
support
[   54.70604699 -1067.73543258   128.47778711]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-47.899439612736316 steps:57[00m
[RDDPG] Resetting Environment
inertial
[-478.0627  820.5516 -916.1927]
[ 0.   0.  -9.8]
support
[-582.07445497  679.59315339  318.10585929]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-210.10772372696698 steps:59[00m
[RDDPG] Resetting Environment
inertial
[-311.9202  121.6968 -482.8708]
[ 0.   0.  -9.8]
support
[ 44.50490574 243.40878058 225.55666743]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-50.823689805851814 steps:61[00m
[RDDPG] Resetting Environment
inertial
[-349.8182    111.300835  -32.268158]
[ 0.   0.  -9.8]
support
[ -3.19021825 264.83838803 254.18716401]
[0. 0. 0.]
inertial
[-349.8182    111.300835  -32.268158]
[ 0.   0.  -9.8]
support
[-120.65185806  -29.62859564  345.43588021]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-253.59792164086937 steps:64[00m
[RDDPG] Resetting Environment
inertial
[ 79.16104  238.78198  -15.764273]
[ 0.   0.  -9.8]
support
[107.55875597 220.00850728 -57.53853717]
[0. 0. 0.]
inertial
[ 79.16104  238.78198  -15.764273]
[ 0.   0.  -9.8]
support
[-155.66579968  189.05232283  -57.53853717]
[0. 0. 0.]
inertial
[ 79.16104  238.78198  -15.764273]
[ 0.   0.  -9.8]
support
[ 130.50830218  155.75403431 -148.29556831]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-308.9581121035924 steps:68[00m
[RDDPG] Resetting Environment
inertial
[ 79.16104  238.78198  -15.764273]
[ 0.   0.  -9.8]
support
[205.84934792 131.16030763 -60.87962669]
[0. 0. 0.]
inertial
[ 79.16104  238.78198  -15.764273]
[ 0.   0.  -9.8]
support
[-243.67035984  -14.20345634  -60.87962669]
[0. 0. 0.]
inertial
[ 268.60858 -213.2501  -236.21431]
[ 0.   0.  -9.8]
support
[  93.29190469 -196.8903475  -264.87164574]
[0. 0. 0.]
inertial
[ 268.60858 -213.2501  -236.21431]
[ 0.   0.  -9.8]
support
[ 102.76543012 -192.11573728 -264.87164574]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-402.9169701949186 steps:73[00m
[RDDPG] Resetting Environment
inertial
[ 268.60858 -213.2501  -236.21431]
[ 0.   0.  -9.8]
support
[-198.8784614  -212.81784789 -181.05832879]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-371.076403015249 steps:75[00m
[RDDPG] Resetting Environment
inertial
[-540.19714  658.1874  1426.1907 ]
[ 0.   0.  -9.8]
support
[-343.61725272  659.29954408  415.06014181]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-157.84350015932816 steps:77[00m
[RDDPG] Resetting Environment
inertial
[-482.30167  502.62952 1478.9178 ]
[ 0.   0.  -9.8]
support
[-570.40079348 -176.46414256  358.82407418]
[0. 0. 0.]
inertial
[ -90.890434 -619.11646   728.34644 ]
[ 0.   0.  -9.8]
support
[581.17721099  15.17017341 231.4501199 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-230.83154765152432 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-131.81179699217697 steps:81[00m
[RDDPG] Resetting Environment
inertial
[ 406.59082 -117.29818   67.80706]
[ 0.   0.  -9.8]
support
[  -0.61743605 -307.10632784 -291.13621339]
[0. 0. 0.]
inertial
[ 647.7419  527.4333 2422.3782]
[ 0.   0.  -9.8]
support
[ 664.4413548   423.93264445 -276.68445062]
[0. 0. 0.]
inertial
[-2008.5702   -343.70328  3044.8206 ]
[ 0.   0.  -9.8]
support
[1451.83624349 1417.42662771  188.57318277]
[0. 0. 0.]
inertial
[-2008.5702   -343.70328  3044.8206 ]
[ 0.   0.  -9.8]
support
[ 909.02239056  223.98183094 1809.97148782]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-484.2572596641155 steps:86[00m
[RDDPG] Resetting Environment
inertial
[-2008.5702   -343.70328  3044.8206 ]
[ 0.   0.  -9.8]
support
[  119.77003224 -1476.09495112  1399.74490789]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-283.694848285543 steps:88[00m
[RDDPG] Resetting Environment
inertial
[  38.793877 -473.64963  -113.160805]
[ 0.   0.  -9.8]
support
[-455.8661529  -131.89959768  -25.24832245]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-61.12930475896384 steps:90[00m
[RDDPG] Resetting Environment
inertial
[  -52.0238    -70.80388 -1129.7257 ]
[ 0.   0.  -9.8]
support
[ -7.73254479 -78.48983747  38.71974365]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-236.08720592531662 steps:92[00m
[RDDPG] Resetting Environment
inertial
[-120.63394    -4.650177  384.15097 ]
[ 0.   0.  -9.8]
support
[-82.97324464  -8.60150705  87.26756561]
[0. 0. 0.]
inertial
[-120.63394    -4.650177  384.15097 ]
[ 0.   0.  -9.8]
support
[-11.22059929 -82.65980331  87.26756561]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-88.1863757903119 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-178.82484752929594 steps:96[00m
[RDDPG] Resetting Environment
inertial
[811.45667 629.44104 911.93036]
[ 0.   0.  -9.8]
support
[ 787.7208086  -336.34512292 -566.59147226]
[0. 0. 0.]
inertial
[-712.72815 -333.28894  733.1773 ]
[ 0.   0.  -9.8]
support
[-506.00284129 -387.63161306  461.26544974]
[0. 0. 0.]
inertial
[1067.8251   372.91055 -529.23615]
[ 0.   0.  -9.8]
support
[-262.5614673   578.35154949 -935.88659743]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-480.9870153497702 steps:100[00m
[RDDPG] Resetting Environment
inertial
[-238.31485 -771.50806  652.475  ]
[ 0.   0.  -9.8]
support
[-779.68306292  -91.18905649  189.20247249]
[0. 0. 0.]
inertial
[-238.31485 -771.50806  652.475  ]
[ 0.   0.  -9.8]
support
[-762.42461465 -186.89518537  189.20247249]
[0. 0. 0.]
inertial
[ -58.765984  -68.8146   -311.30182 ]
[ 0.   0.  -9.8]
support
[-76.75701178 -46.30530192  12.37215297]
[0. 0. 0.]
inertial
[ -58.765984  -68.8146   -311.30182 ]
[ 0.   0.  -9.8]
support
[-76.77284369 -46.27904985  12.37215297]
[0. 0. 0.]
inertial
[ -58.765984  -68.8146   -311.30182 ]
[ 0.   0.  -9.8]
support
[-76.72687031 -46.35523572  12.37215297]
[0. 0. 0.]
inertial
[ -58.765984  -68.8146   -311.30182 ]
[ 0.   0.  -9.8]
support
[-76.7312048  -46.34805754  12.37215297]
[0. 0. 0.]
inertial
[ -58.765984  -68.8146   -311.30182 ]
[ 0.   0.  -9.8]
support
[-76.76047282 -46.29956407  12.37215297]
[0. 0. 0.]
inertial
[-739.2531 1089.6544  405.6506]
[ 0.   0.  -9.8]
support
[1135.87463148 -190.12876402  638.34308581]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:170.47938357205683 steps:109[00m
[RDDPG] Resetting Environment
inertial
[866.3562   275.1093    31.690662]
[ 0.   0.  -9.8]
support
[ 647.30337955  188.09394853 -609.81740568]
[0. 0. 0.]
inertial
[866.3562   275.1093    31.690662]
[ 0.   0.  -9.8]
support
[ -89.04592286  668.17052126 -609.81740568]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-205.78347461988426 steps:112[00m
[RDDPG] Resetting Environment
inertial
[866.3562   275.1093    31.690662]
[ 0.   0.  -9.8]
support
[-644.83949279  365.70334016 -526.02409704]
[0. 0. 0.]
inertial
[866.3562   275.1093    31.690662]
[ 0.   0.  -9.8]
support
[-698.60773822  248.00022846 -526.02409704]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-178.67497271082618 steps:115[00m
[RDDPG] Resetting Environment
inertial
[-33.264668 -95.72787  646.3578  ]
[ 0.   0.  -9.8]
support
[-21.54681998 -96.83277739  20.72464419]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-43.76511467825061 steps:117[00m
[RDDPG] Resetting Environment
inertial
[-237.45627  -269.4101   -119.427185]
[ 0.   0.  -9.8]
support
[ 221.21963822 -228.63888643  166.59355707]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-87.38849098498228 steps:119[00m
[RDDPG] Resetting Environment
inertial
[-237.45627  -269.4101   -119.427185]
[ 0.   0.  -9.8]
support
[-212.19383413 -240.055205    162.21767035]
[0. 0. 0.]
inertial
[-237.45627  -269.4101   -119.427185]
[ 0.   0.  -9.8]
support
[-158.9615709  -278.17969577  162.21767035]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-391.2781942001534 steps:122[00m
[RDDPG] Resetting Environment
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[-446.6644798  -497.3194323   418.91748406]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-156.69569031187098 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-152.30616588867758 steps:125[00m
[RDDPG] Resetting Environment
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[605.29754991 191.79542786 468.14201744]
[0. 0. 0.]
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[634.64932102 -19.77073802 468.14201744]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-98.38661241213583 steps:128[00m
[RDDPG] Resetting Environment
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[-262.74953974 -599.63959537  440.13929307]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-146.11056210683347 steps:130[00m
[RDDPG] Resetting Environment
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[-142.53642926 -577.59274433  518.0710128 ]
[0. 0. 0.]
inertial
[-644.18445 -455.36136  699.1175 ]
[ 0.   0.  -9.8]
support
[-341.23112325 -487.33085609  518.0710128 ]
[0. 0. 0.]
inertial
[103.14315 -94.86159 338.53824]
[ 0.   0.  -9.8]
support
[ -73.70707995 -111.99381746  -40.76619224]
[0. 0. 0.]
inertial
[103.14315 -94.86159 338.53824]
[ 0.   0.  -9.8]
support
[ -60.67242296 -119.55838126  -40.76619224]
[0. 0. 0.]
inertial
[103.14315 -94.86159 338.53824]
[ 0.   0.  -9.8]
support
[132.55628061  20.10428142 -40.76619224]
[0. 0. 0.]
inertial
[103.14315 -94.86159 338.53824]
[ 0.   0.  -9.8]
support
[  82.23449857 -105.89068134  -40.76619224]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:209.637267813516 steps:137[00m
[RDDPG] Resetting Environment
inertial
[ 303.62558  383.04483 -195.16008]
[ 0.   0.  -9.8]
support
[ 392.60510822 -192.20398995 -218.7023006 ]
[0. 0. 0.]
inertial
[ 303.62558  383.04483 -195.16008]
[ 0.   0.  -9.8]
support
[ 421.69222708 -115.1382126  -218.7023006 ]
[0. 0. 0.]
inertial
[ 303.62558  383.04483 -195.16008]
[ 0.   0.  -9.8]
support
[ 430.25411903  -77.2175634  -218.7023006 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-224.9811089138084 steps:141[00m
[RDDPG] Resetting Environment
inertial
[ 2.1417515e+00 -2.8874326e-01  4.2246835e+02]
[ 0.   0.  -9.8]
support
[ 1.10946785  1.20281612 -1.41166094]
[0. 0. 0.]
inertial
[1389.8693  -188.91777 1862.0714 ]
[ 0.   0.  -9.8]
support
[  502.05067164 -1175.74538889  -577.05677969]
[0. 0. 0.]
inertial
[1389.8693  -188.91777 1862.0714 ]
[ 0.   0.  -9.8]
support
[  502.21867913 -1175.67358193  -577.05677969]
[0. 0. 0.]
inertial
[1389.8693  -188.91777 1862.0714 ]
[ 0.   0.  -9.8]
support
[  502.05119886 -1175.74514439  -577.05677969]
[0. 0. 0.]
inertial
[1389.8693  -188.91777 1862.0714 ]
[ 0.   0.  -9.8]
support
[  502.28448957 -1175.64549908  -577.05677969]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-130.9574209245014 steps:147[00m
[RDDPG] Resetting Environment
inertial
[1389.8693  -188.91777 1862.0714 ]
[ 0.   0.  -9.8]
support
[-270.52535231 -955.72952488 -990.36546838]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-208.0059338850284 steps:149[00m
[RDDPG] Resetting Environment
inertial
[ 719.51874  701.68823 1040.2173 ]
[ 0.   0.  -9.8]
support
[ 828.36083087 -213.16387128 -527.68660429]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-251.65959302680955 steps:151[00m
[RDDPG] Resetting Environment
inertial
[  365.8747  -1403.4744    428.65082]
[ 0.   0.  -9.8]
support
[-1332.34317813  -502.91801997  -274.8448128 ]
[0. 0. 0.]
inertial
[  365.8747  -1403.4744    428.65082]
[ 0.   0.  -9.8]
support
[-1283.71190189  -616.56205318  -274.8448128 ]
[0. 0. 0.]
inertial
[  365.8747  -1403.4744    428.65082]
[ 0.   0.  -9.8]
support
[  226.68539095 -1405.94406106  -274.8448128 ]
[0. 0. 0.]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-106.29538713303793 steps:155[00m
[RDDPG] Resetting Environment
inertial
[ 201.4657  -444.18735 -783.0462 ]
[ 0.   0.  -9.8]
support
[ 126.76225819 -445.79779035 -151.94247821]
[0. 0. 0.]
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1022, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:14:55.604470: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:14:55.604508: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620121502.593636542, 1.340000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620121502.595277725, 1.341000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620121502.595379018, 1.341000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620121504.257100666, 2.524000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620121505.116187015, 3.095000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620121505.919819151, 3.694000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620121506.725552615, 4.294000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
inertial
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[-7.05261278e-09  1.01505704e-08 -6.87216070e-09]
[-7.05261278e-09  1.01505704e-08 -6.87216070e-09]
[0. 0. 0.]
zmp [26559282.95368354  -884458.12662676        0.        ]
d1:27524702.02273, d2:0.04029, d3:8579923.98995
inertial
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[-6.83711445e-09  1.02969551e-08 -6.87216070e-09]
[-6.83711445e-09  1.02969551e-08 -6.87216070e-09]
[0. 0. 0.]
zmp [26559658.59462858  -884462.27767479        0.        ]
d1:27525089.40966, d2:0.04028, d3:8580047.87236
inertial
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[-6.67164110e-09  1.04049324e-08 -6.87216070e-09]
[-6.67164110e-09  1.04049324e-08 -6.87216070e-09]
[0. 0. 0.]
zmp [26559943.279684    -884472.94176383        0.        ]
d1:27525384.71318, d2:0.04028, d3:8580139.48067
inertial
[-10.279756 -77.853294 135.23257 ]
[ 7.74074745 38.98345171 15.41631287]
[ 0.   0.  -9.8]
support
[ -5.61308392 -78.26440231   3.16008229]
[ 4.73529159 39.3219226  -3.31546263]
[0. 0. 0.]
zmp [1253599.71872258 3989462.62502357       0.        ]
d1:4132832.74905, d2:0.02479, d3:916665.12339
inertial
[-20.160332 106.64827  383.08292 ]
[ 46.40106866 263.81578407  75.1059801 ]
[ 0.   0.  -9.8]
support
[100.68071784 -36.24857851  18.15835796]
[266.46455968   3.33477945  27.15407539]
[0. 0. 0.]
zmp [-12824669.36738957   1784906.6850458          0.        ]
d1:12007724.97769, d2:0.05923, d3:3573740.45594
inertial
[-20.160332 106.64827  383.08292 ]
[ 46.40106866 263.81578407  75.1059801 ]
[ 0.   0.  -9.8]
support
[ 99.81120166 -38.57836816  18.15835796]
[266.47009959  -2.85811686  27.15407539]
[0. 0. 0.]
zmp [-12762964.45720927   2098579.64355005         0.        ]
d1:11987627.87920, d2:0.05928, d3:3455798.45034
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[-35.8432565   49.08526561  54.34366381]
[-666.25144086 -664.39847864 -298.33043515]
[0. 0. 0.]
zmp [-1932003.02505295  2368278.11862914        0.        ]
d1:1625729.36636, d2:0.05900, d3:1459846.61670
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[ 1.05058132 60.77005151 54.34366381]
[-932.22496092 -127.56603398 -298.33043515]
[0. 0. 0.]
zmp [-2457650.55771668  -962374.42693511        0.        ]
d1:2972927.33302, d2:0.05857, d3:425859.11024
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[-1.4843594  60.76100218 54.34366381]
[-926.09481471 -166.32727885 -298.33043515]
[0. 0. 0.]
zmp [-2472455.11264503  -743344.88587003        0.        ]
d1:2743020.14717, d2:0.05891, d3:316240.62201
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[-5.54710913 60.52546527 54.34366381]
[-912.88833789 -227.92798512 -298.33043515]
[0. 0. 0.]
zmp [-2482332.33737492  -389704.15188428        0.        ]
d1:2192029.86501, d2:0.05924, d3:210378.74247
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[-4.64577003 60.60131501 54.34366381]
[-916.17923787 -214.31736129 -298.33043515]
[0. 0. 0.]
zmp [-2481669.5169644   -468458.73802578        0.        ]
d1:2307034.72461, d2:0.05918, d3:180582.25510
inertial
[-81.32514    -5.7928452 472.24152  ]
[ 371.84861163 -914.35545987  -41.83604404]
[ 0.   0.  -9.8]
support
[-12.26428145  48.74427493  64.19438474]
[-820.7074331     3.99601492 -548.39831524]
[0. 0. 0.]
zmp [2899986.53874891 3159147.34694043       0.        ]
d1:4158140.40240, d2:0.05847, d3:1363427.83269
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[-379.5823 -834.1577 1240.0787]
[  12.47859481 -344.42537393   -0.7221818 ]
[ 0.   0.  -9.8]
support
[-126.96905523 -879.12760735  225.64442355]
[  60.46523208 -337.94480256  -30.36165646]
[0. 0. 0.]
zmp [3872264.77489216 3985407.11235889       0.        ]
d1:7908471.42175, d2:0.00963, d3:527466.57656
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[-414.01102  497.94464  416.10733]
[  29.38155795 -375.45708779   12.55023691]
[ 0.   0.  -9.8]
support
[-345.37217664  463.64987333  291.72049514]
[  57.95523881 -371.36134196  -23.73290149]
[0. 0. 0.]
zmp [-4000156.08215966  2430167.04997226        0.        ]
d1:5769971.01210, d2:0.05796, d3:2227822.71812
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-13.808692411413872[00m
[RDDPG] Resetting Environment
inertial
[-414.01102  497.94464  416.10733]
[  29.38155795 -375.45708779   12.55023691]
[ 0.   0.  -9.8]
support
[-48.61972725 482.85451103 428.76760753]
[  48.65691008 -371.20731491  -40.85275618]
[0. 0. 0.]
zmp [ 9761486.22455939 -5082441.44395275        0.        ]
d1:8508761.51393, d2:0.02615, d3:4804514.58205
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-205.8644408814825 steps:2[00m
[RDDPG] Resetting Environment
inertial
[ 128.21677 -211.18333 -285.1836 ]
[ 19.58313213 -54.58837797 -12.21589232]
[ 0.   0.  -9.8]
support
[-135.22198636 -184.31656395  -93.70361322]
[-39.87115204 -39.52669028 -14.53693427]
[0. 0. 0.]
zmp [3595670.80095811 -212779.34844831       0.        ]
d1:3773144.66000, d2:0.05595, d3:1286496.20873
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-224.52141634371634 steps:4[00m
[RDDPG] Resetting Environment
inertial
[-486.27554 -182.82228  506.6558 ]
[  80.42775311 -372.89103173  -38.92888801]
[ 0.   0.  -9.8]
support
[-364.19445882 -119.05181183  350.82325697]
[  -3.93410128 -378.20886751  -49.5876101 ]
[0. 0. 0.]
zmp [ 2352714.15004202 11008831.66106295        0.        ]
d1:13966285.33568, d2:0.03386, d3:2721397.29170
inertial
[-486.27554 -182.82228  506.6558 ]
[  80.42775311 -372.89103173  -38.92888801]
[ 0.   0.  -9.8]
support
[-336.7264246  -182.82851482  350.82325697]
[  64.39171134 -372.70784167  -49.5876101 ]
[0. 0. 0.]
zmp [ 3748955.65712281 11147084.51586157        0.        ]
d1:15532925.40773, d2:0.02692, d3:2317391.50983
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-210.0345972546026 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-173.0450479687565 steps:8[00m
[RDDPG] Resetting Environment
inertial
[  -3.28641 -702.8408  1180.9812 ]
[ 1.17635801e+00 -2.88604494e+02  2.57749754e-01]
[ 0.   0.  -9.8]
support
[ -93.17374909 -695.19572507   44.91758613]
[ -36.55905288 -285.79990873   16.60686357]
[0. 0. 0.]
zmp [-3891462.66827351 20958771.04998811        0.        ]
d1:24147236.62872, d2:0.05041, d3:8689723.79494
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:28.446732261960392 steps:10[00m
[RDDPG] Resetting Environment
inertial
[ -522.55383 -1441.8463   1885.6022 ]
[   8.76756871 -165.83750815   -4.07386056]
[ 0.   0.  -9.8]
support
[-1453.54205379  -361.22575502   329.71927603]
[-142.31999999  -85.07285585   -9.30468383]
[0. 0. 0.]
zmp [10071211.96513224   189042.72596153        0.        ]
d1:10485142.33419, d2:0.05622, d3:3579672.11885
inertial
[-821.04706  789.9551   146.9053 ]
[  15.29158132 -120.92278376  -27.0895417 ]
[ 0.   0.  -9.8]
support
[ 386.58597259 -691.68800395  818.69797822]
[-98.66265553  19.66198023 -68.81307811]
[0. 0. 0.]
zmp [ 8178055.03032169 -1214593.72710749        0.        ]
d1:9311089.18111, d2:0.05657, d3:2209909.82668
inertial
[-821.04706  789.9551   146.9053 ]
[  15.29158132 -120.92278376  -27.0895417 ]
[ 0.   0.  -9.8]
support
[ 385.83727623 -692.10593039  818.69797822]
[-98.6413236   19.76872978 -68.81307811]
[0. 0. 0.]
zmp [ 8174297.62857916 -1223629.10503271        0.        ]
d1:9295242.44828, d2:0.05660, d3:2205839.27311
inertial
[499.2704   99.64882 564.8732 ]
[   3.5996176  -194.81000609   -8.64791156]
[ 0.   0.  -9.8]
support
[ -61.4526362   356.06013715 -358.67197098]
[186.70134135  30.04125935  46.94714929]
[0. 0. 0.]
zmp [5021843.087073   3840545.03019098       0.        ]
d1:10853921.42770, d2:0.05840, d3:2056343.16094
inertial
[499.2704   99.64882 564.8732 ]
[   3.5996176  -194.81000609   -8.64791156]
[ 0.   0.  -9.8]
support
[ 220.96169285   57.76076735 -455.01698374]
[154.58783897 -50.32760226 107.39475   ]
[0. 0. 0.]
zmp [-14396436.75942659 -20349677.60109854         0.        ]
d1:25846539.60167, d2:0.04806, d3:16843861.69564
inertial
[499.2704   99.64882 564.8732 ]
[   3.5996176  -194.81000609   -8.64791156]
[ 0.   0.  -9.8]
support
[ 194.14687708  120.2803847  -455.01698374]
[162.55367721  -2.56281246 107.39475   ]
[0. 0. 0.]
zmp [-22612167.46274814  -8892428.79433081         0.        ]
d1:29537248.35753, d2:0.05916, d3:16430148.46085
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-659.1377053398792 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-159.843471796881 steps:18[00m
[RDDPG] Resetting Environment
inertial
[-485.97894 -195.84404 1272.0472 ]
[   9.40240571 -259.04049152   -7.35680188]
[ 0.   0.  -9.8]
support
[-359.81837092 -161.11785564  345.11193798]
[ -16.87109239 -258.6210986    -4.56906763]
[0. 0. 0.]
zmp [-2123316.87442424 12389960.41332461        0.        ]
d1:14023755.51439, d2:0.04861, d3:4609386.90305
inertial
[ 288.01813  725.39905 -252.2656 ]
[0. 0. 0.]
[ 0.   0.  -9.8]
support
[-158.11380374  687.11732392 -334.70591047]
[0. 0. 0.]
[0. 0. 0.]
zmp [-6455400.3563463  -2331832.45663377        0.        ]
d1:9933441.72638, d2:0.04915, d3:2827372.82471
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-161.89389552991682 steps:21[00m
[RDDPG] Resetting Environment
inertial
[ 336.26654 -353.33698  877.7953 ]
[ 129.49996246 -453.06613036  -66.29713222]
[ 0.   0.  -9.8]
support
[-292.86912424 -310.38960429 -236.23757   ]
[-421.74895313 -190.40433     -88.9560418 ]
[0. 0. 0.]
zmp [-3708735.79424397   843055.10381571        0.        ]
d1:4447781.17764, d2:0.05893, d3:1482589.20933
inertial
[ 270.751  -405.9796 2637.3455]
[-224.775445    259.17888377  168.60210908]
[ 0.   0.  -9.8]
support
[-341.12036106   40.22522921 -346.61849883]
[208.23746174 -43.32469325 269.17991255]
[0. 0. 0.]
zmp [2928378.67403134 1116103.46039199       0.        ]
d1:4141006.47252, d2:0.05750, d3:1300269.19404
inertial
[ 270.751  -405.9796 2637.3455]
[-224.775445    259.17888377  168.60210908]
[ 0.   0.  -9.8]
support
[-341.09933153   40.40328481 -346.61849883]
[208.21482852 -43.4333846  269.17991255]
[0. 0. 0.]
zmp [2927544.59691647 1111732.85123119       0.        ]
d1:4135031.28559, d2:0.05750, d3:1298601.58764
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-699.8335265757092 steps:25[00m
[RDDPG] Resetting Environment
inertial
[ 620.32214 -418.85742  207.95694]
[  45.33406162 -105.23066481  -19.25900245]
[ 0.   0.  -9.8]
support
[-312.51486497 -527.16205761 -429.73919242]
[-95.81103755 -54.11197186 -31.95012477]
[0. 0. 0.]
zmp [ 6169839.15546643 -3122971.76019712        0.        ]
d1:8963203.83239, d2:0.05932, d3:3002701.34245
inertial
[-841.4757       1.0747771  370.98944  ]
[ -85.77299269 -289.66822578   72.86339646]
[ 0.   0.  -9.8]
support
[-144.27662783 -478.92487893  676.68149502]
[-297.55458189  -51.8582881     6.05628231]
[0. 0. 0.]
zmp [16508612.33349046 -1205713.62324255        0.        ]
d1:16308929.48444, d2:0.05898, d3:4774225.96926
inertial
[-841.4757       1.0747771  370.98944  ]
[ -85.77299269 -289.66822578   72.86339646]
[ 0.   0.  -9.8]
support
[-144.38454814 -478.89226324  676.68149502]
[-297.56627327  -51.79122677    6.05628231]
[0. 0. 0.]
zmp [16507838.93483782 -1210070.82031911        0.        ]
d1:16309149.76904, d2:0.05898, d3:4772575.19208
inertial
[-841.4757       1.0747771  370.98944  ]
[ -85.77299269 -289.66822578   72.86339646]
[ 0.   0.  -9.8]
support
[-144.52362721 -478.85033666  676.68149502]
[-297.58129615  -51.7048116     6.05628231]
[0. 0. 0.]
zmp [16506844.73382229 -1215686.21178505        0.        ]
d1:16309446.58386, d2:0.05898, d3:4770448.52280
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-295.71410881516096 steps:30[00m
[RDDPG] Resetting Environment
inertial
[-203.74152 -533.143    380.28278]
[  73.61204272 -195.89536562  -26.10850114]
[ 0.   0.  -9.8]
support
[-221.42945464 -508.00323005  136.5788711 ]
[  28.69071247 -201.57383005  -48.35867483]
[0. 0. 0.]
zmp [  5243103.33364725 -11350162.81476626         0.        ]
d1:16378795.01573, d2:0.05452, d3:5573369.60496
inertial
[-833.9095  -147.02383  645.6483 ]
[  73.61204272 -195.89536562  -26.10850114]
[ 0.   0.  -9.8]
support
[-156.3369164     1.02122501  832.21321117]
[-195.03144898   -3.56289579  -75.78764135]
[0. 0. 0.]
zmp [10380655.86910059  -244313.94307116        0.        ]
d1:7126611.73732, d2:0.05939, d3:4744435.11918
inertial
[-833.9095  -147.02383  645.6483 ]
[  73.61204272 -195.89536562  -26.10850114]
[ 0.   0.  -9.8]
support
[-156.33606774    1.14474575  832.21321117]
[-195.03421306   -3.40880127  -75.78764135]
[0. 0. 0.]
zmp [10380724.59230046  -238180.11482669        0.        ]
d1:7125725.07110, d2:0.05939, d3:4744438.42130
inertial
[-833.9095  -147.02383  645.6483 ]
[  73.61204272 -195.89536562  -26.10850114]
[ 0.   0.  -9.8]
support
[-156.33648408    1.08576439  832.21321117]
[-195.03290643   -3.48238243  -75.78764135]
[0. 0. 0.]
zmp [10380691.7819081   -241109.05661114        0.        ]
d1:7126146.32831, d2:0.05939, d3:4744436.84697
inertial
[-723.8026   -886.8533    109.565834]
[  61.53250078 -122.10499374  -11.37286891]
[ 0.   0.  -9.8]
support
[985.91871856 444.96304384 374.66148486]
[-10.93442738  68.08653721 118.07007669]
[0. 0. 0.]
zmp [ -2450038.69528428 -14559209.25063284         0.        ]
d1:4797514.05277, d2:0.02970, d3:3713254.99673
inertial
[  308.58145  -315.72733 -1231.8337 ]
[ -59.72227739 -431.65478698  143.13623089]
[ 0.   0.  -9.8]
support
[ 51.4669943  394.39943896 191.58943152]
[-310.95322492  274.85295612  132.87793748]
[0. 0. 0.]
zmp [ 20098560.9254481  -26126048.95813044         0.        ]
d1:54775372.32767, d2:0.04630, d3:9224240.11956
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-187.16557968620089 steps:37[00m
[RDDPG] Resetting Environment
inertial
[344.35938 364.94308 -76.37393]
[ -37.40185603 -123.34990177   17.76799857]
[ 0.   0.  -9.8]
support
[-336.96989471  278.60031164 -246.170646  ]
[119.8799793  -38.73452141  27.24930853]
[0. 0. 0.]
zmp [13497628.99153509    70672.86615048        0.        ]
d1:14198904.13510, d2:0.05926, d3:4393070.94336
inertial
[ 273.33975 -532.2629   933.4526 ]
[  942.72046877 -1709.84701766  -312.99642754]
[ 0.   0.  -9.8]
support
[ 549.00833767 -190.1045155  -143.06822335]
[1768.02311876 -657.95681694 -503.47378329]
[0. 0. 0.]
zmp [-9584984.34642766  -468327.40879796        0.        ]
d1:10643904.75506, d2:0.05933, d3:3231846.53452
inertial
[ 273.33975 -532.2629   933.4526 ]
[  942.72046877 -1709.84701766  -312.99642754]
[ 0.   0.  -9.8]
support
[ 546.94500819   13.84725419 -242.23504545]
[1768.90539902    3.3639271  -826.59616954]
[0. 0. 0.]
zmp [8969122.9119502  3283333.33439026       0.        ]
d1:7288644.47757, d2:0.05785, d3:4120024.62946
inertial
[1568.667  -816.2612  570.654 ]
[ 38.41946308 267.20777807  14.56497517]
[ 0.   0.  -9.8]
support
[  627.91154092   783.22173016 -1455.77796982]
[-176.69685632 -191.42826079  -70.77779928]
[0. 0. 0.]
zmp [22336049.37062427 22424535.36986841        0.        ]
d1:22063622.19869, d2:0.05190, d3:2303057.26435
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-384.50467399613535 steps:42[00m
[RDDPG] Resetting Environment
inertial
[  44.622326 -368.23322   218.41954 ]
[ -17.70270532 -223.36617801  -56.89662916]
[ 0.   0.  -9.8]
support
[367.79967549 -10.53571527 -46.8962701 ]
[220.80401123 -37.96186468   3.21311892]
[0. 0. 0.]
zmp [-19395271.42423647  -3600273.52785527         0.        ]
d1:22204373.41619, d2:0.05899, d3:5486040.51717
inertial
[  44.622326 -368.23322   218.41954 ]
[ -17.70270532 -223.36617801  -56.89662916]
[ 0.   0.  -9.8]
support
[-344.39703098 -129.53101599  -46.8962701 ]
[-218.73509241  -48.48167686    3.21311892]
[0. 0. 0.]
zmp [22583962.41290847 -8362792.36891           0.        ]
d1:30359368.88407, d2:0.05922, d3:10155830.22506
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-414.24245737126455 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-151.14876134766192 steps:46[00m
[RDDPG] Resetting Environment
inertial
[-445.77673  405.42764  848.9077 ]
[ 174.51211978 -371.39529736  -52.9076472 ]
[ 0.   0.  -9.8]
support
[-359.52690781  373.13758666  307.56662964]
[ 165.72618648 -357.22295967 -115.3930157 ]
[0. 0. 0.]
zmp [21023105.11054672  7081497.18170567        0.        ]
d1:26325240.47547, d2:0.02694, d3:6263511.23986
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-291.1068369839877 steps:48[00m
[RDDPG] Resetting Environment
inertial
[-506.88022 -823.14636  201.92636]
[  53.9505063  -294.98722813  -44.30394755]
[ 0.   0.  -9.8]
support
[-919.58090241  109.86938028  277.12314518]
[-268.2283267  -116.5407519   -66.33207104]
[0. 0. 0.]
zmp [-1158376.41602656  1950866.18884455        0.        ]
d1:2968724.94379, d2:0.05865, d3:971517.27915
inertial
[-506.88022 -823.14636  201.92636]
[  53.9505063  -294.98722813  -44.30394755]
[ 0.   0.  -9.8]
support
[   1.83039554 -930.10755847  263.42769133]
[  62.26318083 -266.35227242 -122.91416276]
[0. 0. 0.]
zmp [-5166820.66329286  1549135.67132485        0.        ]
d1:3885496.57891, d2:0.03258, d3:2776642.20507
inertial
[190.8591  483.13596 261.68967]
[-181.20323896 -989.26129386 -276.50104988]
[ 0.   0.  -9.8]
support
[-500.21615427   75.90485604 -117.77013146]
[1001.15234225   -6.44859157   95.52458813]
[0. 0. 0.]
zmp [5620867.95465042 -314254.87535094       0.        ]
d1:5680171.03116, d2:0.05930, d3:2387420.46496
inertial
[279.5351   752.51276   15.911363]
[ 1081.09157827 -1610.16336698  -266.39986854]
[ 0.   0.  -9.8]
support
[-173.19752838  782.66545372  -43.0433912 ]
[-1291.44383916 -1446.79975184    18.12420122]
[0. 0. 0.]
zmp [ -4044471.09275751 -25063389.51419313         0.        ]
d1:36723992.18216, d2:0.01419, d3:9771155.74592
inertial
[ 138.04996  300.09137 1227.493  ]
[ 144.91563445 -284.89075713  -69.34220713]
[ 0.   0.  -9.8]
support
[319.85841517  -6.49941945 -82.22510749]
[-244.09624081 -150.47075697 -141.20505885]
[0. 0. 0.]
zmp [-7893382.36898579  4422903.46577997        0.        ]
d1:10377816.16306, d2:0.05939, d3:2369513.78933
inertial
[ 269.06012    16.633896 -604.7957  ]
[  16.70944682 -248.50667987   77.75719048]
[ 0.   0.  -9.8]
support
[-160.72187228  -87.41288501 -197.98360858]
[ 184.31944905 -142.08813579  -88.7247373 ]
[0. 0. 0.]
zmp [-21454931.63857622  19082483.18600577         0.        ]
d1:35778053.96440, d2:0.04788, d3:4185020.37102
inertial
[ 160.33263  179.10117 -588.5229 ]
[  16.70944682 -248.50667987   77.75719048]
[ 0.   0.  -9.8]
support
[ 179.70488342  -93.97257732 -129.07010136]
[-216.64008144  108.94010463  -56.86748342]
[0. 0. 0.]
zmp [ 1090617.50184723 24544593.23713034        0.        ]
d1:37248346.85437, d2:0.05900, d3:3307844.10451
inertial
[ 160.33263  179.10117 -588.5229 ]
[  16.70944682 -248.50667987   77.75719048]
[ 0.   0.  -9.8]
support
[ 110.31878442 -170.16007947 -129.07010136]
[-135.12925525  201.34782882  -56.86748342]
[0. 0. 0.]
zmp [ 4085698.04295393 44768073.02633763        0.        ]
d1:65796550.07910, d2:0.05940, d3:5204558.02829
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-165.67186498857566 steps:57[00m
[RDDPG] Resetting Environment
inertial
[ 160.33263  179.10117 -588.5229 ]
[  16.70944682 -248.50667987   77.75719048]
[ 0.   0.  -9.8]
support
[ 136.74178607  156.48725507 -120.81890505]
[-241.94795081  -58.98932566   -4.02836854]
[0. 0. 0.]
zmp [10654299.2585356   1543543.41343838        0.        ]
d1:12167086.56194, d2:0.05875, d3:4038707.99610
inertial
[  478.36786  1183.6243  -1129.941  ]
[  76.77531634 -373.43506559  138.00244631]
[ 0.   0.  -9.8]
support
[1120.14565552   52.29461089 -610.19771707]
[-319.89136813 -198.55893637   59.93383109]
[0. 0. 0.]
zmp [-11663792.05737825   -561461.58847207         0.        ]
d1:12144649.85888, d2:0.05321, d3:3767836.83185
inertial
[  478.36786  1183.6243  -1129.941  ]
[  76.77531634 -373.43506559  138.00244631]
[ 0.   0.  -9.8]
support
[1187.6634115  -374.18252089 -281.50561357]
[-266.53187761   33.61461898  270.51621676]
[0. 0. 0.]
zmp [-19865554.84681123  -3660671.29109509         0.        ]
d1:9866492.59393, d2:0.05388, d3:9749141.59423
inertial
[  478.36786  1183.6243  -1129.941  ]
[  76.77531634 -373.43506559  138.00244631]
[ 0.   0.  -9.8]
support
[1187.665978   -374.17425385 -281.50561357]
[-266.53210374   33.61276396  270.51621676]
[0. 0. 0.]
zmp [-19865418.30758848  -3660438.19034659         0.        ]
d1:9866245.84852, d2:0.05388, d3:9749071.23815
inertial
[  478.36786  1183.6243  -1129.941  ]
[  76.77531634 -373.43506559  138.00244631]
[ 0.   0.  -9.8]
support
[1188.08384985 -372.84536462 -281.50561357]
[-266.56954256   33.31456698  270.51621676]
[0. 0. 0.]
zmp [-19843472.39521858  -3622967.39878608         0.        ]
d1:9826708.37827, d2:0.05393, d3:9737762.85059
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-493.89941598171674 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-242.28138878904966 steps:64[00m
[RDDPG] Resetting Environment
inertial
[ 552.10657  -305.30444   115.444954]
[  -7.26791273 -275.67467137    3.26051163]
[ 0.   0.  -9.8]
support
[ 327.441232    367.63100368 -394.54046064]
[274.95183349 -20.34339615   6.08214412]
[0. 0. 0.]
zmp [16662555.60607883  1050377.89426228        0.        ]
d1:18618449.98105, d2:0.05935, d3:5360620.93168
inertial
[ 552.10657  -305.30444   115.444954]
[  -7.26791273 -275.67467137    3.26051163]
[ 0.   0.  -9.8]
support
[ 426.45097598 -245.98756991 -394.54046064]
[  35.89977357 -273.35611979    6.08214412]
[0. 0. 0.]
zmp [ 5558519.69236652 18465110.73487628        0.        ]
d1:25013995.69329, d2:0.02979, d3:3987606.67752
inertial
[-1072.042       65.124695  1537.0629  ]
[  23.78420707 -149.92878669  -17.27558097]
[ 0.   0.  -9.8]
support
[406.59399555 -15.62671926 993.95791048]
[  11.34639395 -145.31912178  -42.40216797]
[0. 0. 0.]
zmp [4144744.49910888 4567791.7027827        0.        ]
d1:9261939.43747, d2:0.05617, d3:2782735.63556
inertial
[-1072.042       65.124695  1537.0629  ]
[  23.78420707 -149.92878669  -17.27558097]
[ 0.   0.  -9.8]
support
[406.58076234 -15.96785006 993.95791048]
[  11.22446888 -145.32858153  -42.40216797]
[0. 0. 0.]
zmp [4146444.30989526 4568391.17778644       0.        ]
d1:9264392.27535, d2:0.05616, d3:2783475.09990
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:43.30368944935336 steps:69[00m
[RDDPG] Resetting Environment
inertial
[308.2286  -97.79403  35.92877]
[ -13.65630769 -175.053273     19.87813013]
[ 0.   0.  -9.8]
support
[ 133.56937583  197.06163817 -218.84809005]
[170.27306545 -42.3152881    6.82961674]
[0. 0. 0.]
zmp [-7456274.27302846 -2586445.72210478        0.        ]
d1:10017808.08981, d2:0.05848, d3:1927136.33581
inertial
[308.2286  -97.79403  35.92877]
[ -13.65630769 -175.053273     19.87813013]
[ 0.   0.  -9.8]
support
[ 209.39963465 -113.25129329 -218.84809005]
[ -25.12363355 -173.64418766    6.82961674]
[0. 0. 0.]
zmp [  2723400.72391193 -13561030.23865538         0.        ]
d1:14998841.19977, d2:0.04939, d3:5083083.12118
inertial
[308.2286  -97.79403  35.92877]
[ -13.65630769 -175.053273     19.87813013]
[ 0.   0.  -9.8]
support
[ 122.2598823  -144.58400603 -262.13839446]
[ -33.7047451  -169.90555531   28.74431305]
[0. 0. 0.]
zmp [ -7094951.66721938 -12140624.66641051         0.        ]
d1:14052855.49102, d2:0.03313, d3:4586995.60067
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-628.2893942485427 steps:73[00m
[RDDPG] Resetting Environment
inertial
[308.2286  -97.79403  35.92877]
[ -13.65630769 -175.053273     19.87813013]
[ 0.   0.  -9.8]
support
[ -93.45910389  203.37685637 -233.39195386]
[-173.04185588  -27.91989216  -10.35093907]
[0. 0. 0.]
zmp [1075659.99032682 2672108.66951645       0.        ]
d1:3746384.80614, d2:0.05926, d3:1228774.72659
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-383.652569156345 steps:75[00m
[RDDPG] Resetting Environment
inertial
[308.2286  -97.79403  35.92877]
[ -13.65630769 -175.053273     19.87813013]
[ 0.   0.  -9.8]
support
[-165.79334017  168.60369347 -220.57631892]
[-160.9730422   -69.50255946    9.3390433 ]
[0. 0. 0.]
zmp [8358719.63768456 3234174.85058696       0.        ]
d1:11853062.55320, d2:0.05877, d3:3654288.58878
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-114.43815256159749 steps:77[00m
[RDDPG] Resetting Environment
inertial
[-244.89516 -328.26236 -711.21185]
[ 116.42939581 -317.70516941  -19.84017824]
[ 0.   0.  -9.8]
support
[-166.32447497 -334.15363723  168.54478069]
[  86.42498833 -314.76136085  -89.15377217]
[0. 0. 0.]
zmp [ -2356303.55338817 -25308317.56763352         0.        ]
d1:26873678.51474, d2:0.03839, d3:8112447.01008
inertial
[-244.89516 -328.26236 -711.21185]
[ 116.42939581 -317.70516941  -19.84017824]
[ 0.   0.  -9.8]
support
[-240.77471553 -285.21923716  168.54478069]
[   9.3705843  -326.27622678  -89.15377217]
[0. 0. 0.]
zmp [  1868406.5504131  -24679315.91687108         0.        ]
d1:26309087.58586, d2:0.04606, d3:9223899.71196
inertial
[-244.89516 -328.26236 -711.21185]
[ 116.42939581 -317.70516941  -19.84017824]
[ 0.   0.  -9.8]
support
[109.79310341  19.18303689 394.09047714]
[309.49702591 -81.24563376 110.01422877]
[0. 0. 0.]
zmp [-15104416.31045558  -1488683.77296338         0.        ]
d1:11200444.04132, d2:0.05566, d3:6849100.85240
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-119.16054882014342 steps:81[00m
[RDDPG] Resetting Environment
inertial
[ -30.166758  834.41864  1313.3127  ]
[  61.88251199 -371.28256765  -34.66370983]
[ 0.   0.  -9.8]
support
[-80.63010742 830.99622361 -10.41881925]
[  71.28232854 -368.49814507  -28.42772148]
[0. 0. 0.]
zmp [ 7417112.93834762 13512295.31884384        0.        ]
d1:21288341.23492, d2:0.01507, d3:2059256.90502
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:1.0079639373740577 steps:83[00m
[RDDPG] Resetting Environment
inertial
[ -30.166758  834.41864  1313.3127  ]
[  61.88251199 -371.28256765  -34.66370983]
[ 0.   0.  -9.8]
support
[-63.35927615 831.30777019  45.58070721]
[  -8.54179694 -372.73063161  -51.7602741 ]
[0. 0. 0.]
zmp [-3271461.0654113  -3922467.88579709        0.        ]
d1:7129261.05938, d2:0.05854, d3:2364414.60615
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-286.10348591720094 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-124.85239562500011 steps:86[00m
[RDDPG] Resetting Environment
inertial
[  714.8519 -1437.4066  -690.7351]
[  15.07432458 -185.79363674   -8.81464953]
[ 0.   0.  -9.8]
support
[-1322.29572162  -779.84533735  -469.60241528]
[-180.71022164  -45.002207     -8.07024543]
[0. 0. 0.]
zmp [ 9398948.87281069 -2694556.21422513        0.        ]
d1:11935314.56391, d2:0.05914, d3:4023423.50902
inertial
[  714.8519 -1437.4066  -690.7351]
[  15.07432458 -185.79363674   -8.81464953]
[ 0.   0.  -9.8]
support
[  438.48863864 -1471.17382838  -469.60241528]
[ 1.62895708e-01 -1.86229313e+02 -8.07024543e+00]
[0. 0. 0.]
zmp [  -371710.4044221  -14559250.63397745         0.        ]
d1:15074030.11310, d2:0.03942, d3:4709145.13850
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-74.13264148912006 steps:89[00m
[RDDPG] Resetting Environment
inertial
[ 198.38861  273.9666  1175.2019 ]
[ -39.68949115 -346.49449513   24.89689591]
[ 0.   0.  -9.8]
support
[ 197.47682117  238.03215663 -136.96474508]
[-106.7764541  -331.36436229   20.73976188]
[0. 0. 0.]
zmp [ 4653032.64479042 -3436763.33007193        0.        ]
d1:7476895.98763, d2:0.05863, d3:2703275.65312
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-61.26392095459294 steps:91[00m
[RDDPG] Resetting Environment
inertial
[ 198.38861  273.9666  1175.2019 ]
[ -39.68949115 -346.49449513   24.89689591]
[ 0.   0.  -9.8]
support
[-125.37925323  278.87032451 -144.66214784]
[  12.65528926 -347.20728304   30.34209708]
[0. 0. 0.]
zmp [-982472.88445122 2006419.30033573       0.        ]
d1:2975438.55133, d2:0.02061, d3:378640.57199
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-434.5719055872432 steps:93[00m
[RDDPG] Resetting Environment
inertial
[626.41125  -23.482288 775.6493  ]
[  83.78368287 -109.90707421  -25.97031895]
[ 0.   0.  -9.8]
support
[  82.99516375 -439.66872916 -439.02811431]
[-92.52043358 -84.52571842 -58.26356798]
[0. 0. 0.]
zmp [14210614.83397814  -789274.46278684        0.        ]
d1:14989098.87980, d2:0.05861, d3:5175253.37730
inertial
[626.41125  -23.482288 775.6493  ]
[  83.78368287 -109.90707421  -25.97031895]
[ 0.   0.  -9.8]
support
[ 261.2010432  -536.77294046  191.28864965]
[ -57.35377894 -106.90344821   66.19266083]
[0. 0. 0.]
zmp [-20868970.95490183  12106833.46310015         0.        ]
d1:16308344.25577, d2:0.05937, d3:10434259.86758
inertial
[  16.732553 -561.7652   1007.5565  ]
[ -47.1500205  -844.84322521    9.17121293]
[ 0.   0.  -9.8]
support
[-556.86039245    7.59393017   75.55770071]
[-826.18239572   43.22819773  177.58718389]
[0. 0. 0.]
zmp [-2733845.14042209  -850387.30814604        0.        ]
d1:2188676.02429, d2:0.05940, d3:817006.63539
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-423.83363326824093 steps:97[00m
[RDDPG] Resetting Environment
inertial
[-430.31955 -309.64014  104.86658]
[   1.08967567 -228.35800758    8.18563153]
[ 0.   0.  -9.8]
support
[-357.92375189 -242.1984513   307.05448872]
[ -50.54263155 -222.62257737   -5.76231609]
[0. 0. 0.]
zmp [ 4278003.08833473 -6412433.67950833        0.        ]
d1:9991326.91701, d2:0.05859, d3:3606230.17357
inertial
[-430.31955 -309.64014  104.86658]
[   1.08967567 -228.35800758    8.18563153]
[ 0.   0.  -9.8]
support
[-388.83212697  188.62412504  307.05448872]
[-218.02503573  -67.67901005   -5.76231609]
[0. 0. 0.]
zmp [ 7589714.86600317 -2000892.86795643        0.        ]
d1:8939617.59172, d2:0.05883, d3:3216990.07367
inertial
[-430.31955 -309.64014  104.86658]
[   1.08967567 -228.35800758    8.18563153]
[ 0.   0.  -9.8]
support
[-144.25937054 -407.38031119  307.05448872]
[  91.48146928 -209.15665401   -5.76231609]
[0. 0. 0.]
zmp [ 1525733.44748817 -6043539.63092285        0.        ]
d1:7270785.75318, d2:0.05342, d3:2560665.89223
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-199.23973653597312 steps:101[00m
[RDDPG] Resetting Environment
inertial
[ 147.26878   43.3275  1081.0479 ]
[  14.38177882 -372.85935629  -12.26083929]
[ 0.   0.  -9.8]
support
[  89.49091072   60.66191297 -108.98108476]
[  75.91481051 -365.13208481  -12.10161425]
[0. 0. 0.]
zmp [-1858347.45744054 11846381.36883228        0.        ]
d1:13795298.08302, d2:0.05003, d3:4800557.61624
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-170.27547137331027 steps:103[00m
[RDDPG] Resetting Environment
inertial
[ -95.447136 -349.7245    801.015   ]
[  77.02191124 -340.57762844  -58.22295344]
[ 0.   0.  -9.8]
support
[-355.36647149  -29.50381177   65.28074604]
[-312.4080299  -146.05840642  -54.71440666]
[0. 0. 0.]
zmp [ 4589986.88591727 -1847669.67477614        0.        ]
d1:6254596.56470, d2:0.05910, d3:2111055.89062
inertial
[ -95.447136 -349.7245    801.015   ]
[  77.02191124 -340.57762844  -58.22295344]
[ 0.   0.  -9.8]
support
[ -13.37902536 -356.33805011   65.28074604]
[ 107.49041826 -327.68528577  -54.71440666]
[0. 0. 0.]
zmp [ -857739.87106226 -6693095.84772665        0.        ]
d1:7842506.80468, d2:0.03636, d3:1770761.53390
inertial
[ -95.447136 -349.7245    801.015   ]
[  77.02191124 -340.57762844  -58.22295344]
[ 0.   0.  -9.8]
support
[ -19.24352307 -356.06949258   65.28074604]
[ 102.08123224 -329.41045897  -54.71440666]
[0. 0. 0.]
zmp [ -778537.53576358 -6709506.0346094         0.        ]
d1:7783432.76064, d2:0.03676, d3:1801849.04545
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-323.86662769774284 steps:107[00m
[RDDPG] Resetting Environment
inertial
[451.52637    -4.0249434 261.4458   ]
[ -24.51325174 -224.70883024    5.66934118]
[ 0.   0.  -9.8]
support
[ 135.61815473  283.49307172 -324.24014612]
[ 199.54527989 -103.33617219   24.45969166]
[0. 0. 0.]
zmp [14993988.6943935   6661150.10962064        0.        ]
d1:22205937.16983, d2:0.05547, d3:2956630.86192
inertial
[330.11603 520.9555  755.53534]
[  -4.17416697 -335.76918122  -67.66447437]
[ 0.   0.  -9.8]
support
[-368.81898323 -393.57107431 -299.07458341]
[303.28281526  66.59001006 127.84237331]
[0. 0. 0.]
zmp [13228357.37053595   416886.07293696        0.        ]
d1:17742636.03253, d2:0.05686, d3:4593847.86307
inertial
[-1382.0425   -811.11084   209.41559]
[ -60.87317378 -642.47345264 -348.50497524]
[ 0.   0.  -9.8]
support
[-745.89468463  691.52670778 1238.29472794]
[-635.20694755  103.10310308   48.57506698]
[0. 0. 0.]
zmp [12549357.90755161  3174599.17647           0.        ]
d1:15475168.76176, d2:0.05898, d3:3177917.44297
inertial
[-1382.0425   -811.11084   209.41559]
[ -60.87317378 -642.47345264 -348.50497524]
[ 0.   0.  -9.8]
support
[1464.89152376  495.14410488  420.5568719 ]
[ 542.65718978  -98.45435032 -335.12311573]
[0. 0. 0.]
zmp [-8773716.60778124 11521823.00260623        0.        ]
d1:6057747.38272, d2:0.05481, d3:10911761.44658
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-446.97621270341614 steps:112[00m
[RDDPG] Resetting Environment
inertial
[ -53.03181 1277.0464   694.11774]
[ -17.20118395 -311.94420608    9.61975318]
[ 0.   0.  -9.8]
support
[-1199.1611656    441.02984973    34.13443344]
[ 285.15558604 -126.91130998   13.5973207 ]
[0. 0. 0.]
zmp [3483212.39847366 2573037.53869145       0.        ]
d1:5970673.30831, d2:0.05522, d3:112023.84806
inertial
[ -688.0991 -1364.7137   765.519 ]
[ -1.94239201 -51.03262125 -45.73599997]
[ 0.   0.  -9.8]
support
[1088.18321604  776.20348136  741.14073284]
[46.84563693  7.86567868 18.75416665]
[0. 0. 0.]
zmp [11931538.40938997   243723.14074408        0.        ]
d1:15197905.62601, d2:0.05713, d3:3999935.15042
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-133.99863946406595 steps:115[00m
[RDDPG] Resetting Environment
inertial
[ -688.0991 -1364.7137   765.519 ]
[ -1.94239201 -51.03262125 -45.73599997]
[ 0.   0.  -9.8]
support
[-1351.97341047   -99.57362197   705.81652328]
[-50.83552326  -4.12780125   2.60999938]
[0. 0. 0.]
zmp [5716105.36150321  -82374.02552043       0.        ]
d1:4217133.45647, d2:0.05920, d3:2791733.99014
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-67.07324111859359 steps:117[00m
[RDDPG] Resetting Environment
inertial
[ -688.0991 -1364.7137   765.519 ]
[ -1.94239201 -51.03262125 -45.73599997]
[ 0.   0.  -9.8]
support
[-1168.26009593  -872.81509541   457.47808693]
[-48.38532356 -16.3331738    0.43498276]
[0. 0. 0.]
zmp [9543135.58706265  836280.17027718       0.        ]
d1:10663855.70757, d2:0.05820, d3:3349209.27655
inertial
[ -688.0991 -1364.7137   765.519 ]
[ -1.94239201 -51.03262125 -45.73599997]
[ 0.   0.  -9.8]
support
[1437.37373358 -246.15965252  457.47808693]
[ 45.16155677 -23.8400072    0.43498276]
[0. 0. 0.]
zmp [5022498.70589941 1519618.91862156       0.        ]
d1:6710384.51363, d2:0.05803, d3:2111331.51630
inertial
[ 521.3793   -91.70079 -693.6112 ]
[  -2.66269613 -250.49665806   -1.30219096]
[ 0.   0.  -9.8]
support
[-144.73622911   19.29244078 -508.84635104]
[ -16.84221014 -245.49830635  -46.93175225]
[0. 0. 0.]
zmp [18728329.41875688 -2025770.49538663        0.        ]
d1:12965882.86058, d2:0.01039, d3:8924177.88873
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-750.7742375383677 steps:121[00m
[RDDPG] Resetting Environment
inertial
[ 226.66344  641.8629  1110.9158 ]
[ -88.8867083  -362.86719359   56.62160396]
[ 0.   0.  -9.8]
support
[  -0.71086016  661.80569424 -159.3017517 ]
[  27.12234626 -367.3973013    62.10517463]
[0. 0. 0.]
zmp [ 2438537.12369448 17517348.28441737        0.        ]
d1:20512460.10427, d2:0.03793, d3:5525493.52257
inertial
[ 226.66344  641.8629  1110.9158 ]
[ -88.8867083  -362.86719359   56.62160396]
[ 0.   0.  -9.8]
support
[ 659.80328215  -51.44788029 -159.3017517 ]
[-368.3920722     1.91638725   62.10517463]
[0. 0. 0.]
zmp [-13153935.57466682   2967714.0751172          0.        ]
d1:15174022.95682, d2:0.05918, d3:5768180.44770
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-86.53593830290492 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-193.87121056641354 steps:125[00m
[RDDPG] Resetting Environment
inertial
[-148.25945   72.65565 -126.67692]
[ -23.87617171 -231.84566474   18.93683043]
[ 0.   0.  -9.8]
support
[-97.44544308  82.59019955 104.6085646 ]
[ -48.88971087 -227.77584946    7.102147  ]
[0. 0. 0.]
zmp [ 399291.44961655 4403653.71514034       0.        ]
d1:4944204.51483, d2:0.03701, d3:1603444.48560
inertial
[-148.25945   72.65565 -126.67692]
[ -23.87617171 -231.84566474   18.93683043]
[ 0.   0.  -9.8]
support
[ 29.99197188 124.16616235 104.6085646 ]
[-225.45189726  -58.68126848    7.102147  ]
[0. 0. 0.]
zmp [-2327861.09601776  1408779.68178735        0.        ]
d1:3374234.61124, d2:0.05937, d3:1423529.70441
inertial
[-148.25945   72.65565 -126.67692]
[ -23.87617171 -231.84566474   18.93683043]
[ 0.   0.  -9.8]
support
[ 47.42415785  27.21924203 155.78758388]
[-229.97286645  -36.8042887    -8.96717951]
[0. 0. 0.]
zmp [-391344.79226113 4545291.22414782       0.        ]
d1:7441124.99360, d2:0.05878, d3:717057.57501
inertial
[-148.25945   72.65565 -126.67692]
[ -23.87617171 -231.84566474   18.93683043]
[ 0.   0.  -9.8]
support
[ 47.42045594  27.22569071 155.78758388]
[-229.96785925  -36.83556753   -8.96717951]
[0. 0. 0.]
zmp [-390720.22084375 4549140.22210185       0.        ]
d1:7446795.41982, d2:0.05878, d3:717966.61811
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-255.88443635621078 steps:130[00m
[RDDPG] Resetting Environment
inertial
[-81.37201  696.814     63.905262]
[ -54.14739607 -230.05721309   27.68271314]
[ 0.   0.  -9.8]
support
[-662.93131647  213.95517815   83.16511582]
[ 198.72061338 -124.45720585   29.6442989 ]
[0. 0. 0.]
zmp [-2726260.0883525  -1261957.41729471        0.        ]
d1:3995583.30979, d2:0.05512, d3:480308.31561
inertial
[-876.838   -451.568   -806.36597]
[  44.05909357 -323.64276362 -120.32057761]
[ 0.   0.  -9.8]
support
[235.22849942 368.76131821 883.99163097]
[314.9271524  -59.7470893   62.74560795]
[0. 0. 0.]
zmp [3892932.00583969 1163497.52088024       0.        ]
d1:5066947.13688, d2:0.05663, d3:1689942.73971
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-236.1249336751982 steps:133[00m
[RDDPG] Resetting Environment
inertial
[ 46.471138 -85.83331  553.8057  ]
[  49.42144521 -402.10802591  -16.30945784]
[ 0.   0.  -9.8]
support
[-75.37160387 -52.88774979 -32.38721082]
[-381.8485211  -131.04022974  -33.96326452]
[0. 0. 0.]
zmp [22219271.10198168 -1705366.82261594        0.        ]
d1:23495030.15770, d2:0.05867, d3:7446642.07638
inertial
[ 46.471138 -85.83331  553.8057  ]
[  49.42144521 -402.10802591  -16.30945784]
[ 0.   0.  -9.8]
support
[ 24.81667521 -88.66863651 -32.38721082]
[  -3.3841556  -403.69346926  -33.96326452]
[0. 0. 0.]
zmp [17697752.82637151 -7173445.32896366        0.        ]
d1:23983959.46458, d2:0.05498, d3:7845573.86990
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-88.34867454176515 steps:136[00m
[RDDPG] Resetting Environment
inertial
[ 748.02856 -265.90262 -136.51968]
[  9.02546039 -19.42339164  -4.65123616]
[ 0.   0.  -9.8]
support
[  67.05399336 -567.81720493 -550.76163385]
[-12.72257913 -15.78149582  -6.91429578]
[0. 0. 0.]
zmp [-2669655.34527662 -1426282.5642109         0.        ]
d1:4029510.89148, d2:0.05042, d3:445617.61539
inertial
[-350.54724  -81.79592  924.4801 ]
[  39.81949444 -319.80285538  217.52349042]
[ 0.   0.  -9.8]
support
[-191.55570935 -280.30522758  119.62163237]
[-247.40858547   39.00588514 -202.7979144 ]
[0. 0. 0.]
zmp [13112164.07247345   926306.86788538        0.        ]
d1:17965192.44421, d2:0.05223, d3:4699058.84388
inertial
[-350.54724  -81.79592  924.4801 ]
[  39.81949444 -319.80285538  217.52349042]
[ 0.   0.  -9.8]
support
[-191.47554372 -280.36000551  119.62163237]
[-247.41973169   38.93513119 -202.7979144 ]
[0. 0. 0.]
zmp [13113957.89806774   930433.14122284        0.        ]
d1:17970277.43419, d2:0.05222, d3:4700960.51962
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-267.4015150908783 steps:140[00m
[RDDPG] Resetting Environment
inertial
[-1307.4994  -611.5264 -1837.3783]
[  25.01607464 -297.77305795   -3.3671438 ]
[ 0.   0.  -9.8]
support
[-754.08567969 -738.37958238  984.7180957 ]
[  74.3220342  -289.31241676   -8.31668117]
[0. 0. 0.]
zmp [-2694996.47060802 -7821107.53122658        0.        ]
d1:10272117.14743, d2:0.02979, d3:1755935.82581
inertial
[-1307.4994  -611.5264 -1837.3783]
[  25.01607464 -297.77305795   -3.3671438 ]
[ 0.   0.  -9.8]
support
[-871.25581493 -595.6195991   984.7180957 ]
[  22.75032356 -297.83863395   -8.31668117]
[0. 0. 0.]
zmp [-1764514.86701945 -7968831.83195066        0.        ]
d1:9461515.99895, d2:0.03409, d3:2089485.96098
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-313.26009256437646 steps:143[00m
[RDDPG] Resetting Environment
inertial
[-192.3382  -300.65903  477.7995 ]
[ -12.2356151  -397.34633567  -30.14468842]
[ 0.   0.  -9.8]
support
[ -91.21210601 -320.26291044  128.45956288]
[  48.32144803 -394.58535615   -1.12414869]
[0. 0. 0.]
zmp [3221857.67790609 8165057.42391657       0.        ]
d1:10956174.41071, d2:0.02504, d3:1475582.34043
inertial
[-192.3382  -300.65903  477.7995 ]
[ -12.2356151  -397.34633567  -30.14468842]
[ 0.   0.  -9.8]
support
[-332.98983002    2.39958117  128.45956288]
[-367.36281659 -151.91158403   -1.12414869]
[0. 0. 0.]
zmp [-3105160.68799172  3271777.60137457        0.        ]
d1:5631685.05561, d2:0.05937, d3:2050591.29442
inertial
[-192.3382  -300.65903  477.7995 ]
[ -12.2356151  -397.34633567  -30.14468842]
[ 0.   0.  -9.8]
support
[  30.17905583 -343.77852329   91.07909959]
[  95.39474687 -372.60442544 -100.4968889 ]
[0. 0. 0.]
zmp [-6773211.35185997 35605878.00252265        0.        ]
d1:56430606.03793, d2:0.05933, d3:1525986.06699
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-78.39518886477364 steps:147[00m
[RDDPG] Resetting Environment
inertial
[ -354.70285  -215.99391 -1229.6307 ]
[   8.99971865 -223.74116064   -6.27749743]
[ 0.   0.  -9.8]
support
[-223.35186597 -219.38881356  272.85523781]
[  12.98129444 -223.51528156   -3.67539943]
[0. 0. 0.]
zmp [11146036.2370252  18132710.36269676        0.        ]
d1:29582341.02254, d2:0.01837, d3:2070668.07870
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:37.63707727875388 steps:149[00m
[RDDPG] Resetting Environment
inertial
[ -354.70285  -215.99391 -1229.6307 ]
[   8.99971865 -223.74116064   -6.27749743]
[ 0.   0.  -9.8]
support
[-138.93225867 -304.03619382  246.42912907]
[-215.02260531  -61.04937389  -13.39245345]
[0. 0. 0.]
zmp [-5739514.86123078 -1502846.45440779        0.        ]
d1:7419042.84582, d2:0.05843, d3:2337569.16250
inertial
[ -354.70285  -215.99391 -1229.6307 ]
[   8.99971865 -223.74116064   -6.27749743]
[ 0.   0.  -9.8]
support
[ 248.64330005 -223.42044188  246.42912907]
[  -5.9786575  -223.44127056  -13.39245345]
[0. 0. 0.]
zmp [-2262642.18687485 -5226027.59782203        0.        ]
d1:7530142.99736, d2:0.05545, d3:2365678.68394
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-467.3246295506508 steps:152[00m
[RDDPG] Resetting Environment
inertial
[-111.78647 -312.93094 1327.3892 ]
[  -8.42107505 -584.43944233  -12.40450357]
[ 0.   0.  -9.8]
support
[  56.67760939 -318.50049268   75.94123434]
[ 232.50742337 -536.26198379   -1.93739872]
[0. 0. 0.]
zmp [2521264.83591261 5018257.45446351       0.        ]
d1:7657230.72751, d2:0.03022, d3:921989.63691
inertial
[-111.78647 -312.93094 1327.3892 ]
[  -8.42107505 -584.43944233  -12.40450357]
[ 0.   0.  -9.8]
support
[-123.41855379 -299.03641372   75.94123434]
[ -92.21185815 -577.17726516   -1.93739872]
[0. 0. 0.]
zmp [ 395059.17987842 5434864.73408968       0.        ]
d1:5939140.68406, d2:0.03997, d3:1699908.37082
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-385.0427352555556 steps:155[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620121651.366212116, 80.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121651.366340365, 80.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620121652.401644718, 80.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620121652.401772445, 80.806000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:19:22.013467: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:19:22.013507: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620121768.767278273, 1.213000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620121768.769496501, 1.214000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620121768.770377641, 1.214000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620121770.660178991, 2.554000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620121771.759008746, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620121772.825310060, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620121773.905537480, 5.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-7.14860788e-09  9.77134297e-09 -7.30878061e-09]
[-7.14860788e-09  9.77134297e-09 -7.30878061e-09]
[0. 0. 0.]
zmp [23807728.85222974   946430.77403197        0.        ]
d1:25692684.74024, d2:0.04338, d3:8116315.43964
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-7.03725320e-09  9.85184282e-09 -7.30878061e-09]
[-7.03725320e-09  9.85184282e-09 -7.30878061e-09]
[0. 0. 0.]
zmp [23810044.86590412   946452.65623885        0.        ]
d1:25695125.33412, d2:0.04339, d3:8117082.27346
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-7.11947251e-09  9.79259148e-09 -7.30878061e-09]
[-7.11947251e-09  9.79259148e-09 -7.30878061e-09]
[0. 0. 0.]
zmp [23808336.5957255    946440.13497673        0.        ]
d1:25693328.20582, d2:0.04338, d3:8116517.83544
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-7.57164691e-09  9.44732230e-09 -7.30878061e-09]
[-7.57164691e-09  9.44732230e-09 -7.30878061e-09]
[0. 0. 0.]
zmp [23798757.14219949   945992.19893238        0.        ]
d1:25682934.08501, d2:0.04341, d3:8113230.36590
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-360.71748787  -37.49552248   48.10428806]
[-551.14639281 -192.89436386  -60.14941254]
[0. 0. 0.]
zmp [12282721.37369684 -2686074.67225447        0.        ]
d1:14392206.12138, d2:0.05900, d3:5207026.84948
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-358.15577504  -56.98650334   48.10428806]
[-539.88436377 -222.47573912  -60.14941254]
[0. 0. 0.]
zmp [12172083.86226575 -3144091.99732369        0.        ]
d1:14680722.84558, d2:0.05886, d3:5327292.80989
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-350.70658498  -92.34673176   48.10428806]
[-515.06378076 -275.09978272  -60.14941254]
[0. 0. 0.]
zmp [11924304.98870667 -3963668.37714274        0.        ]
d1:15171620.88330, d2:0.05866, d3:5525159.03953
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-339.14311911 -128.47171258   48.10428806]
[-483.51346718 -327.39172922  -60.14941254]
[0. 0. 0.]
zmp [11604765.68735012 -4784954.02978589        0.        ]
d1:15611505.82581, d2:0.05856, d3:5698636.67695
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-342.2616133  -119.91669259   48.10428806]
[-491.58051947 -315.14944799  -60.14941254]
[0. 0. 0.]
zmp [11686822.35463087 -4591999.26931691        0.        ]
d1:15513821.87321, d2:0.05857, d3:5660310.47602
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-343.30279667 -116.90256292   48.10428806]
[-494.33260855 -310.81482563  -60.14941254]
[0. 0. 0.]
zmp [11714766.91410333 -4523783.91164053        0.        ]
d1:15478402.00824, d2:0.05858, d3:5646390.26951
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-344.27998669 -113.99257788   48.10428806]
[-496.94570184 -306.61953503  -60.14941254]
[0. 0. 0.]
zmp [11741274.47249792 -4457811.82474945        0.        ]
d1:15443721.62339, d2:0.05858, d3:5632747.49115
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-343.44706956 -116.47802637   48.10428806]
[-494.71651636 -310.20340594  -60.14941254]
[0. 0. 0.]
zmp [11718662.52623908 -4514166.12870566        0.        ]
d1:15473371.57383, d2:0.05858, d3:5644412.20642
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-343.16609113 -117.30329413   48.10428806]
[-493.96941201 -311.39174613  -60.14941254]
[0. 0. 0.]
zmp [11711080.05195696 -4532860.05182606        0.        ]
d1:15483140.30681, d2:0.05858, d3:5648253.23099
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-344.47622013 -113.39820846   48.10428806]
[-497.47417035 -305.76138157  -60.14941254]
[0. 0. 0.]
zmp [11746631.86171061 -4444323.2070625         0.        ]
d1:15436580.01162, d2:0.05858, d3:5629936.39702
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-346.76149984 -106.20491946   48.10428806]
[-503.72949601 -295.34247496  -60.14941254]
[0. 0. 0.]
zmp [11809969.56041905 -4280717.04942101        0.        ]
d1:15348634.63156, d2:0.05861, d3:5595268.05852
inertial
[0.        0.        1.2181312]
[ -85.7802  -355.63858 1454.9705 ]
[  54.8500613  -584.44845472  -48.08815155]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  94.92494627 -350.01754531   48.10428806]
[ 278.8824984  -513.02548546  -60.14941254]
[0. 0. 0.]
zmp [ 3545211.45558587 -8350401.94250736        0.        ]
d1:11342074.97017, d2:0.05626, d3:4128989.66497
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-781.45845886  128.04345556  695.78306139]
[ 194.79788451 -271.87485813 -106.47894278]
[0. 0. 0.]
zmp [ -544478.40767565 29293540.05243306        0.        ]
d1:31553809.26613, d2:0.04548, d3:11550464.52960
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-778.99821832  142.24714151  695.78306139]
[ 189.81667767 -275.37572307 -106.47894278]
[0. 0. 0.]
zmp [ -908661.82916555 29481541.43670216        0.        ]
d1:31868656.49001, d2:0.04564, d3:11767970.07152
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-775.96746129  157.94603579  695.78306139]
[ 184.21816901 -279.15196937 -106.47894278]
[0. 0. 0.]
zmp [-1315905.20987747 29678979.10692098        0.        ]
d1:32257427.47297, d2:0.04584, d3:12006243.26805
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-780.05092305  136.35603636  695.78306139]
[ 191.89230614 -273.93337301 -106.47894278]
[0. 0. 0.]
zmp [ -757123.51267747 29404640.50446245        0.        ]
d1:31733371.86043, d2:0.04557, d3:11677978.59896
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-776.57261316  154.94354669  695.78306139]
[ 185.29652278 -278.43736335 -106.47894278]
[0. 0. 0.]
zmp [-1237631.6602125  29642065.13835378        0.        ]
d1:32180198.06437, d2:0.04580, d3:11960846.50817
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-773.6584665   168.89344781  695.78306139]
[ 180.25580208 -281.72681123 -106.47894278]
[0. 0. 0.]
zmp [-1602855.4091556  29810159.96100531        0.        ]
d1:32548852.74641, d2:0.04599, d3:12171063.49441
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-765.99451099  200.81057387  695.78306139]
[ 168.42554161 -288.95500958 -106.47894278]
[0. 0. 0.]
zmp [-2453589.29783906 30161633.09368984        0.        ]
d1:33464154.73063, d2:0.04648, d3:12645225.53067
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-762.55629009  213.49552704  695.78306139]
[ 163.60676748 -291.71042251 -106.47894278]
[0. 0. 0.]
zmp [-2797647.95140186 30288279.60484043        0.        ]
d1:33845890.28032, d2:0.04670, d3:12830992.38028
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-762.60095226  213.33603188  695.78306139]
[ 163.66779324 -291.67620672 -106.47894278]
[0. 0. 0.]
zmp [-2793300.12508015 30286734.95852534        0.        ]
d1:33841048.44670, d2:0.04669, d3:12828666.44580
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-761.1072247   218.60528427  695.78306139]
[ 161.64656439 -292.80119359 -106.47894278]
[0. 0. 0.]
zmp [-2937213.44795591 30337165.03499005        0.        ]
d1:34001519.67602, d2:0.04679, d3:12905385.02996
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[221.65836685 760.22365167 695.78306139]
[-293.44763335 -160.47004045 -106.47894278]
[0. 0. 0.]
zmp [-30301624.9361845    7957503.04757796         0.        ]
d1:35973059.16215, d2:0.05929, d3:15123966.82544
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-750.62195402  252.26805639  695.78306139]
[ 148.45277164 -299.7064205  -106.47894278]
[0. 0. 0.]
zmp [-3870894.21117109 30628016.68438397        0.        ]
d1:35042853.93298, d2:0.04743, d3:13389063.84144
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-742.49049574  275.28207203  695.78306139]
[ 139.14540609 -304.13928449 -106.47894278]
[0. 0. 0.]
zmp [-4523818.752622  30794849.3509656        0.       ]
d1:35761528.76539, d2:0.04790, d3:13713155.59259
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-731.54277915  303.17915432  695.78306139]
[ 127.53780814 -309.18644927 -106.47894278]
[0. 0. 0.]
zmp [-5331820.4443391  30960814.62487208        0.        ]
d1:36630361.22453, d2:0.04852, d3:14098556.00761
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-729.86224822  307.20276914  695.78306139]
[ 125.83335196 -309.88404103 -106.47894278]
[0. 0. 0.]
zmp [-5449898.51605705 30981376.71018106        0.        ]
d1:36755058.01967, d2:0.04861, d3:14153448.60324
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-719.38698618  330.99048212  695.78306139]
[ 115.59553816 -313.84681119 -106.47894278]
[0. 0. 0.]
zmp [-6156162.47534698 31084998.39262077        0.        ]
d1:37487460.89826, d2:0.04918, d3:14474286.04558
inertial
[0.        0.        1.2181312]
[-959.0784  437.4414  849.2332]
[ 122.18686787 -329.04449804  -41.8618558 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-711.21620112  348.20089296  695.78306139]
[ 108.0119099  -316.53684588 -106.47894278]
[0. 0. 0.]
zmp [-6676119.76792451 31140290.57283703        0.        ]
d1:38011063.33352, d2:0.04960, d3:14702365.98644
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  7.09458326 196.33937369  41.86355974]
[-13.37137682 102.05385396   1.30289639]
[0. 0. 0.]
zmp [  527531.36158082 -1994208.83731959        0.        ]
d1:2030931.95948, d2:0.03434, d3:550857.44048
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.97887735 196.34352286  41.86355974]
[-13.43151668 102.04595741   1.30289639]
[0. 0. 0.]
zmp [  528266.19539136 -1994129.04554126        0.        ]
d1:2030243.65768, d2:0.03432, d3:550620.93809
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  7.17970785 196.33627542  41.86355974]
[-13.32712894 102.05963955   1.30289639]
[0. 0. 0.]
zmp [  526990.75980033 -1994267.08853403        0.        ]
d1:2031439.36308, d2:0.03435, d3:551031.27227
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.60487328 196.35646213  41.86355974]
[-13.62586599 102.02018947   1.30289639]
[0. 0. 0.]
zmp [  530641.34747302 -1993866.50544489        0.        ]
d1:2028030.73674, d2:0.03427, d3:549854.87983
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.07361344 196.37361502  41.86355974]
[-13.90182843 101.98295308   1.30289639]
[0. 0. 0.]
zmp [  534015.01446892 -1993481.54476556        0.        ]
d1:2024921.24128, d2:0.03419, d3:548762.53797
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  5.88874342 196.37923784  41.86355974]
[-13.99782982 101.96981642   1.30289639]
[0. 0. 0.]
zmp [  535188.95921695 -1993344.18788326        0.        ]
d1:2023849.18671, d2:0.03417, d3:548381.23790
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  5.78084201 196.38245122  41.86355974]
[-14.05385469 101.96211382   1.30289639]
[0. 0. 0.]
zmp [  535874.12248646 -1993263.34789703        0.        ]
d1:2023226.18596, d2:0.03415, d3:548158.45890
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.48560034 196.36043451  41.86355974]
[-13.6878339  102.01189226   1.30289639]
[0. 0. 0.]
zmp [  531398.78566584 -1993781.26855515        0.        ]
d1:2027328.98632, d2:0.03425, d3:549610.05180
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.66555037 196.35441248  41.86355974]
[-13.59433938 102.02439573   1.30289639]
[0. 0. 0.]
zmp [  530256.00595337 -1993909.58691859        0.        ]
d1:2028388.49680, d2:0.03428, d3:549979.33529
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.91123679 196.34592196  41.86355974]
[-13.46666975 102.04132771   1.30289639]
[0. 0. 0.]
zmp [  528695.75327067 -1994082.14304975        0.        ]
d1:2029842.15019, d2:0.03431, d3:550482.59615
inertial
[0.        0.        1.2181312]
[-32.48082 198.2348  242.55536]
[  9.74745654 102.47178863  80.95456801]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.45554298 196.36142938  41.86355974]
[-13.7034487  102.00979811   1.30289639]
[0. 0. 0.]
zmp [  531589.66316835 -1993759.72760529        0.        ]
d1:2027152.52291, d2:0.03425, d3:549548.33275
inertial
[0.        0.        1.2181312]
[176.13892 123.75587 542.4416 ]
[   8.93315302 -302.8380929   -14.76519852]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-213.62208114    3.91796954  -26.28101998]
[181.0907425  232.22994558 -71.17665886]
[0. 0. 0.]
zmp [ -69186.40845624 1368231.72439457       0.        ]
d1:1656643.17971, d2:0.03789, d3:471245.03198
inertial
[0.        0.        1.2181312]
[-303.1559   -116.374306  510.87643 ]
[  56.58958586 -277.14135286  -70.64588009]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  60.68319082 -185.74912129  259.3478671 ]
[-230.68302431 -163.61565267   -4.99798465]
[0. 0. 0.]
zmp [ 4056035.16959126 -3568163.91696633        0.        ]
d1:7417866.65839, d2:0.04368, d3:1697044.69249
inertial
[0.        0.        1.2181312]
[ 20.017197 -80.30798  921.0946  ]
[ 110.08297574 -367.8634511   -89.58324061]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 76.10836612 -21.33582584 -24.5429302 ]
[ 355.84082018  -82.02496732 -118.7051095 ]
[0. 0. 0.]
zmp [-6902100.02897795 -6291821.52315396        0.        ]
d1:9364417.60089, d2:0.05058, d3:1697082.00707
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 71.10933397 395.4813944  163.734198  ]
[140.04336985 246.38702336 -22.26000373]
[0. 0. 0.]
zmp [6582152.22104333  989911.27109227       0.        ]
d1:8837184.72667, d2:0.04547, d3:2170001.76391
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 70.65564877 395.56269755 163.734198  ]
[139.76067829 246.54749139 -22.26000373]
[0. 0. 0.]
zmp [6582204.1551407   989878.67033142       0.        ]
d1:8837250.56726, d2:0.04545, d3:2169998.26204
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 71.08197483 395.48630498 163.734198  ]
[140.02634502 246.39669963 -22.26000373]
[0. 0. 0.]
zmp [6582155.35009223  989909.30457937       0.        ]
d1:8837188.69335, d2:0.04547, d3:2170001.55174
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 80.98614941 393.5775712  163.734198  ]
[146.16669991 242.80445593 -22.26000373]
[0. 0. 0.]
zmp [6581021.61298047  990646.63503239       0.        ]
d1:8835754.02584, d2:0.04592, d3:2170091.08667
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[284.13677079 284.12736952 163.734198  ]
[255.62965834 122.36091819 -22.26000373]
[0. 0. 0.]
zmp [6557824.96093312 1019233.22158351       0.        ]
d1:8807932.62659, d2:0.05612, d3:2178812.86693
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[286.81267762 281.42592734 163.734198  ]
[256.77607533 119.93647481 -22.26000373]
[0. 0. 0.]
zmp [6557520.53995554 1019851.04046095       0.        ]
d1:8807597.41881, d2:0.05625, d3:2179051.16770
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[288.81207763 279.37366754 163.734198  ]
[257.62474651 118.10250055 -22.26000373]
[0. 0. 0.]
zmp [6557293.11411155 1020319.13503084       0.        ]
d1:8807347.84590, d2:0.05634, d3:2179232.53248
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[291.87518746 276.17192432 163.734198  ]
[258.91140687 115.25446398 -22.26000373]
[0. 0. 0.]
zmp [6556944.74015606 1021047.30669253       0.        ]
d1:8806967.00400, d2:0.05648, d3:2179516.03370
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.16555107 271.56589737 163.734198  ]
[260.68507793 111.18454388 -22.26000373]
[0. 0. 0.]
zmp [6556456.90234474 1022090.49132924       0.        ]
d1:8806436.78349, d2:0.05668, d3:2179925.02416
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[295.6982214  272.07467296 163.734198  ]
[260.4935331  111.63256673 -22.26000373]
[0. 0. 0.]
zmp [6556510.03756957 1021975.50819391       0.        ]
d1:8806494.35620, d2:0.05666, d3:2179879.78311
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.73668714 270.94167676 163.734198  ]
[260.91860305 110.63540248 -22.26000373]
[0. 0. 0.]
zmp [6556391.97500609 1022231.47839833       0.        ]
d1:8806366.49739, d2:0.05671, d3:2179980.55348
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.17566202 271.5548734  163.734198  ]
[260.689219   111.17484769 -22.26000373]
[0. 0. 0.]
zmp [6556455.7566099  1022092.98091732       0.        ]
d1:8806435.54329, d2:0.05668, d3:2179926.00490
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.74696924 270.93042664 163.734198  ]
[260.92280043 110.62550242 -22.26000373]
[0. 0. 0.]
zmp [6556390.80333872 1022234.01985278       0.        ]
d1:8806365.22880, d2:0.05671, d3:2179981.55414
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.61270569 271.07740844 163.734198  ]
[260.86796212 110.75475786 -22.26000373]
[0. 0. 0.]
zmp [6556406.06801785 1022200.83006075       0.        ]
d1:8806381.74756, d2:0.05670, d3:2179968.47694
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[293.56908683 274.37066343 163.734198  ]
[259.6157263  113.65909168 -22.26000373]
[0. 0. 0.]
zmp [6556752.12237047 1021455.86323537       0.        ]
d1:8806757.21384, d2:0.05656, d3:2179675.81780
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[293.35097079 274.60385372 163.734198  ]
[259.52532862 113.86535062 -22.26000373]
[0. 0. 0.]
zmp [6556776.9230466 1021403.0160651       0.       ]
d1:8806784.19369, d2:0.05655, d3:2179655.12059
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[291.31232518 276.76560345 163.734198  ]
[258.67622246 115.78136291 -22.26000373]
[0. 0. 0.]
zmp [6557008.75276446 1020912.47755826       0.        ]
d1:8807036.84761, d2:0.05646, d3:2179463.41565
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[293.54375872 274.39775678 163.734198  ]
[259.60523855 113.68304987 -22.26000373]
[0. 0. 0.]
zmp [6556755.00085198 1021449.72413691       0.        ]
d1:8806760.34457, d2:0.05656, d3:2179673.41282
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[295.75783914 272.0098717  163.734198  ]
[260.51799383 111.57547313 -22.26000373]
[0. 0. 0.]
zmp [6556503.25510177 1021990.15809976       0.        ]
d1:8806487.00390, d2:0.05666, d3:2179885.54406
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[295.53940641 272.24717629 163.734198  ]
[260.42835389 111.78455354 -22.26000373]
[0. 0. 0.]
zmp [6556528.09350261 1021936.50936168       0.        ]
d1:8806513.92981, d2:0.05665, d3:2179864.44732
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[297.00519634 270.64734044 163.734198  ]
[261.02817133 110.37664779 -22.26000373]
[0. 0. 0.]
zmp [6556361.44800478 1022297.92870888       0.        ]
d1:8806333.47248, d2:0.05672, d3:2180006.74457
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[296.02365099 271.72058427 163.734198  ]
[260.62696327 111.32072252 -22.26000373]
[0. 0. 0.]
zmp [6556473.03929049 1022055.53807831       0.        ]
d1:8806454.26365, d2:0.05667, d3:2179911.26762
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[291.49269004 276.57561064 163.734198  ]
[258.75165908 115.61268687 -22.26000373]
[0. 0. 0.]
zmp [6556988.24034615 1020955.63514086       0.        ]
d1:8807014.46039, d2:0.05647, d3:2179480.25250
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 63.40313678 396.78975342 163.734198  ]
[135.22428203 249.06446614 -22.26000373]
[0. 0. 0.]
zmp [6583034.43162545  989371.41051484       0.        ]
d1:8838304.60061, d2:0.04514, d3:2169949.38754
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 66.84802765 396.22392859 163.734198  ]
[137.38304069 247.88023834 -22.26000373]
[0. 0. 0.]
zmp [6582640.04900922  989609.09878879       0.        ]
d1:8837803.59839, d2:0.04529, d3:2169970.93883
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 68.01755723 396.02486234 163.734198  ]
[138.11430536 247.47355378 -22.26000373]
[0. 0. 0.]
zmp [6582506.15649792  989691.12821591       0.        ]
d1:8837633.64553, d2:0.04534, d3:2169978.93651
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 68.42906948 395.95395724 163.734198  ]
[138.37139247 247.32989207 -22.26000373]
[0. 0. 0.]
zmp [6582459.04905598  989720.15480836       0.        ]
d1:8837573.86801, d2:0.04535, d3:2169981.83513
inertial
[0.        0.        1.2181312]
[-134.93472 -412.38763  901.9004 ]
[  71.75307751 -275.07401289  -48.81319418]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[227.93721246 330.91796901 163.734198  ]
[229.22010941 166.66390882 -22.26000373]
[0. 0. 0.]
zmp [6564227.4171458  1008162.54484454       0.        ]
d1:8815229.21209, d2:0.05331, d3:2174782.42406
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 16.98361257 -63.59418076 -75.53842061]
[-145.29022567 -265.90419074   60.86148488]
[0. 0. 0.]
zmp [8640046.92125707 2579142.94315144       0.        ]
d1:9011452.98029, d2:0.03048, d3:3163190.01035
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 12.46451833 -64.6320295  -75.53842061]
[-163.64910357 -255.01619894   60.86148488]
[0. 0. 0.]
zmp [8652972.3272084  2607132.21811723       0.        ]
d1:9024476.32330, d2:0.03372, d3:3163181.91366
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  6.53000699 -65.49826416 -75.53842061]
[-186.18125038 -239.06239138   60.86148488]
[0. 0. 0.]
zmp [8666905.12106398 2647434.99030965       0.        ]
d1:9038753.47872, d2:0.03777, d3:3161182.88116
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  3.86795058 -65.70922547 -75.53842061]
[-195.72465615 -231.31394176   60.86148488]
[0. 0. 0.]
zmp [8672079.70786486 2666783.76102612       0.        ]
d1:9044212.04735, d2:0.03952, d3:3159579.96317
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  3.67111151 -65.72052114 -75.53842061]
[-196.41664519 -230.7266613    60.86148488]
[0. 0. 0.]
zmp [8672437.19879466 2668245.35282729       0.        ]
d1:9044594.58565, d2:0.03964, d3:3159444.69616
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  2.46850848 -65.77667142 -75.53842061]
[-200.60362551 -227.09573564   60.86148488]
[0. 0. 0.]
zmp [8674552.62974729 2677268.37954346       0.        ]
d1:9046876.56383, d2:0.04041, d3:3158570.76596
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  2.43208612 -65.7780313  -75.53842061]
[-200.729378   -226.98459442   60.86148488]
[0. 0. 0.]
zmp [8674615.0623912  2677544.24235872       0.        ]
d1:9046944.42302, d2:0.04043, d3:3158543.09447
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  2.11789319 -65.78889262 -75.53842061]
[-201.81116889 -226.02332623   60.86148488]
[0. 0. 0.]
zmp [8675149.97591399 2679929.48098133       0.        ]
d1:9047527.11497, d2:0.04063, d3:3158301.74911
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  1.31430663 -65.8098538  -75.53842061]
[-204.55635304 -223.54190024   60.86148488]
[0. 0. 0.]
zmp [8676504.73083842 2686083.06393394       0.        ]
d1:9049012.85299, d2:0.04114, d3:3157668.38804
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  1.50888717 -65.80567917 -75.53842061]
[-203.89454    -224.145723     60.86148488]
[0. 0. 0.]
zmp [8676176.18679291 2684585.82781904       0.        ]
d1:9048651.32581, d2:0.04102, d3:3157822.95197
inertial
[0.        0.        1.2181312]
[ 98.522766 -18.220348 505.5555  ]
[  43.33478228 -306.00736463 -120.33265259]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-29.27655384  -6.69714745 -95.5863438 ]
[ 200.86892758 -179.09470433 -151.97097692]
[0. 0. 0.]
zmp [-1291349.28187973   523592.63024255        0.        ]
d1:1352691.84965, d2:0.04411, d3:787536.70731
inertial
[0.        0.        1.2181312]
[1213.6359  -459.48764 1206.6095 ]
[  99.73298959 -114.18367612  -11.95752473]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-290.72150544 -874.57326552 -913.58836045]
[ -80.5182644  -117.5784424   -51.73686426]
[0. 0. 0.]
zmp [27690826.22029159 -5254348.01494166        0.        ]
d1:32139178.66586, d2:0.04509, d3:15435075.33455
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1109.0978024307299[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 641.2149   371.696   -429.56464]
[  -1.20125357 -130.82096963    0.1514801 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 343.81693831  476.1910441  -452.04702974]
[ 3.19684465e+01 -1.26860498e+02 -5.00835841e-02]
[0. 0. 0.]
zmp [   332971.49783652 -14237377.32004465         0.        ]
d1:14561934.50967, d2:0.04435, d3:5147721.77471
inertial
[0.        0.        1.2181312]
[ 641.2149   371.696   -429.56464]
[  -1.20125357 -130.82096963    0.1514801 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -47.79550757  585.39182109 -452.04702974]
[ 1.06695021e+02 -7.57082495e+01 -5.00835841e-02]
[0. 0. 0.]
zmp [-5524421.43958847 -8444731.79491527        0.        ]
d1:14061878.77368, d2:0.04922, d3:1436164.83417
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-320.37143337476346 steps:3[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-222.27826 -157.25981 -637.7636 ]
[-29.70834038 -53.2851779   17.22786312]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 108.45640385 -198.63754308  151.38892919]
[ 45.29875602 -36.09610769  19.15696888]
[0. 0. 0.]
zmp [-541670.70852566  398863.23193473       0.        ]
d1:881229.34399, d2:0.05923, d3:329162.40002
inertial
[0.        0.        1.2181312]
[-222.27826 -157.25981 -637.7636 ]
[-29.70834038 -53.2851779   17.22786312]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-172.85806222 -146.08133837  151.38892919]
[-26.28059478 -51.61624518  19.15696888]
[0. 0. 0.]
zmp [-1372414.04147392  1193148.38817376        0.        ]
d1:2400321.97277, d2:0.05928, d3:897086.45217
inertial
[0.        0.        1.2181312]
[-222.27826 -157.25981 -637.7636 ]
[-29.70834038 -53.2851779   17.22786312]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-219.19580835   56.32818772  151.38892919]
[-57.29958029  -8.46548157  19.15696888]
[0. 0. 0.]
zmp [-2006356.58627789   625986.56356478        0.        ]
d1:2501980.61292, d2:0.05816, d3:924952.82445
inertial
[0.        0.        1.2181312]
[-222.27826 -157.25981 -637.7636 ]
[-29.70834038 -53.2851779   17.22786312]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[   3.76812859 -237.76994099  132.62551874]
[ 12.49691012 -59.39825136   6.12948691]
[0. 0. 0.]
zmp [-13366194.854562    55121950.33594936         0.        ]
d1:79638951.00015, d2:0.05938, d3:6064632.91388
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-483.27670442513386 steps:8[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[412.6419   81.17641 769.2498 ]
[-132.91949585 -203.83859524   73.95451069]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 219.52360004  206.13609609 -293.5647586 ]
[  11.85574111 -223.74098232   94.95882523]
[0. 0. 0.]
zmp [ 3730078.61305011 10496022.01706874        0.        ]
d1:14849874.94994, d2:0.03580, d3:2543972.50274
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-89.48926711290066 steps:10[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[412.6419   81.17641 769.2498 ]
[-132.91949585 -203.83859524   73.95451069]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -42.35806451  294.32378658 -297.39244606]
[-151.57988797 -159.72313077  103.58486675]
[0. 0. 0.]
zmp [10189942.77083514  1123471.61072371        0.        ]
d1:11137965.01307, d2:0.05821, d3:3665224.08881
inertial
[0.        0.        1.2181312]
[412.6419   81.17641 769.2498 ]
[-132.91949585 -203.83859524   73.95451069]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-284.47810828   86.56158119 -297.39244606]
[  80.29136586 -205.03961204  103.58486675]
[0. 0. 0.]
zmp [9234066.21920565 2085298.99339672       0.        ]
d1:11142664.50169, d2:0.05010, d3:3664825.86079
inertial
[0.        0.        1.2181312]
[-562.93036 -664.85223  120.8895 ]
[  36.30839474 -534.88921305  -21.31253647]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-492.70088213 -646.74236436  312.8726273 ]
[ -28.91201448 -530.60538746  -71.04087397]
[0. 0. 0.]
zmp [ 8606197.53633517 18610982.30658768        0.        ]
d1:28936214.41838, d2:0.01755, d3:3647726.74081
inertial
[0.        0.        1.2181312]
[-562.93036 -664.85223  120.8895 ]
[  36.30839474 -534.88921305  -21.31253647]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-554.23680283 -594.85411737  312.8726273 ]
[ -81.23710334 -525.14618922  -71.04087397]
[0. 0. 0.]
zmp [ 7122398.52258864 18306094.82622714        0.        ]
d1:27781291.97572, d2:0.02257, d3:3991765.20041
inertial
[0.        0.        1.2181312]
[-562.93036 -664.85223  120.8895 ]
[  36.30839474 -534.88921305  -21.31253647]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-372.15323189 -722.86360455  312.8726273 ]
[  64.21830047 -527.49785263  -71.04087397]
[0. 0. 0.]
zmp [11237528.36662589 18673379.86486838        0.        ]
d1:30664936.44463, d2:0.01184, d3:2877367.33406
inertial
[0.        0.        1.2181312]
[-562.93036 -664.85223  120.8895 ]
[  36.30839474 -534.88921305  -21.31253647]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-665.91988172 -466.45526036  312.8726273 ]
[-188.7709042  -496.73285558  -71.04087397]
[0. 0. 0.]
zmp [ 4060163.62417689 17035608.09305312        0.        ]
d1:24988686.32578, d2:0.03362, d3:4486925.93689
inertial
[0.        0.        1.2181312]
[-562.93036 -664.85223  120.8895 ]
[  36.30839474 -534.88921305  -21.31253647]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-251.2788342  -759.7230568   344.38191616]
[ -80.42401922 -497.49867513 -182.89836048]
[0. 0. 0.]
zmp [-21527387.40071265  -8315312.41624298         0.        ]
d1:21235362.70075, d2:0.01194, d3:15756709.05870
inertial
[0.        0.        1.2181312]
[ 355.5321   327.34924 -182.50688]
[  61.92687402 -228.04351673  -52.16583543]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-439.38379709  -80.09070085 -184.62928954]
[ 148.11213003  134.49452756 -125.7489901 ]
[0. 0. 0.]
zmp [14946914.95983927 -8234304.43947477        0.        ]
d1:20367829.16107, d2:0.05931, d3:9963387.43803
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-288.74553441038256 steps:19[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-171.15631  600.9587   470.46848]
[  49.40846787 -110.46454657  -17.2837729 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[544.52667285 286.25363222 109.52358962]
[-96.95058474 -64.22624816 -33.45425765]
[0. 0. 0.]
zmp [12634551.5803897  -1104031.40808999        0.        ]
d1:13407973.90240, d2:0.05795, d3:4556158.02934
inertial
[0.        0.        1.2181312]
[-467.58218  710.6821   325.3667 ]
[-108.40708133 -444.66287399  113.61342028]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 587.84285371 -447.02207721  422.27278236]
[-444.26720013  -70.48109074  -84.47638122]
[0. 0. 0.]
zmp [27123153.53840378 -2193815.58015736        0.        ]
d1:32161260.48488, d2:0.05793, d3:8783777.47514
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-132.41303545732313 steps:22[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-1005.24884  -569.73254  1977.7433 ]
[ -17.8616883  -303.57628959   15.7093967 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-631.600902   -629.58049669  734.73070953]
[  14.43015233 -303.51497659   12.16737804]
[0. 0. 0.]
zmp [-5735009.20785604  -233367.05202322        0.        ]
d1:6354129.94921, d2:0.03882, d3:1859772.39453
inertial
[0.        0.        1.2181312]
[-1005.24884  -569.73254  1977.7433 ]
[ -17.8616883  -303.57628959   15.7093967 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-716.01821153 -531.61004753  734.73070953]
[ -29.61997508 -302.41068201   12.16737804]
[0. 0. 0.]
zmp [-5709550.71601812  -233926.57632216        0.        ]
d1:6327174.38335, d2:0.03871, d3:1851039.07307
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-226.5725742430968 steps:25[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-338.34818   -94.306366  984.8388  ]
[  84.63520003 -444.90453145   15.8261664 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -69.81599862 -240.31207687  246.47317155]
[ 389.79435187 -224.14087267  -54.07772669]
[0. 0. 0.]
zmp [ -323330.14148775 -9464191.91761962        0.        ]
d1:9870087.28986, d2:0.05327, d3:3104899.79311
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-265.0639007903843 steps:27[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[140.69312 146.8706  -89.49285]
[  78.8346171  -296.11330176  -44.91128951]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[117.39727131 134.21478231 -97.8253688 ]
[  16.08957655 -299.87806765  -60.92836772]
[0. 0. 0.]
zmp [13858607.17026818  2147396.5654154         0.        ]
d1:16783062.38929, d2:0.03539, d3:3530520.18858
inertial
[0.        0.        1.2181312]
[140.69312 146.8706  -89.49285]
[  78.8346171  -296.11330176  -44.91128951]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-128.01518036  124.12832049  -97.8253688 ]
[300.30859756   0.68370151 -60.92836772]
[0. 0. 0.]
zmp [15782136.91885466   133887.96162649        0.        ]
d1:17023007.33396, d2:0.05880, d3:4781107.20270
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-249.7614522584939 steps:30[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[140.69312 146.8706  -89.49285]
[  78.8346171  -296.11330176  -44.91128951]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-168.78638387  -79.63747649  -80.83661004]
[ 277.787123   -104.40359915  -76.36876421]
[0. 0. 0.]
zmp [10693773.89350322 -2701025.73706708        0.        ]
d1:11194389.46773, d2:0.05918, d3:2935587.90427
inertial
[0.        0.        1.2181312]
[140.69312 146.8706  -89.49285]
[  78.8346171  -296.11330176  -44.91128951]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-171.13040766  -74.4671559   -80.83661004]
[ 274.48328829 -112.8039505   -76.36876421]
[0. 0. 0.]
zmp [10579647.46321083 -3311317.52533307        0.        ]
d1:11327138.36678, d2:0.05897, d3:2720101.43448
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-349.66679895182796 steps:33[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[404.90714 195.16858 974.53564]
[   6.15531218 -203.25484674   -3.39603664]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 276.70375736  203.63660718 -289.84087641]
[   8.66156769 -203.07070625   -6.1389254 ]
[0. 0. 0.]
zmp [ 4773644.87513698 15947121.16696012        0.        ]
d1:19714096.12075, d2:0.02917, d3:4089795.51512
inertial
[0.        0.        1.2181312]
[404.90714 195.16858 974.53564]
[   6.15531218 -203.25484674   -3.39603664]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 300.8032403  -165.98268284 -289.84087641]
[-180.77573399  -92.91323197   -6.1389254 ]
[0. 0. 0.]
zmp [-5504290.21167978  6962650.52515429        0.        ]
d1:11970344.83880, d2:0.05932, d3:4104329.28092
inertial
[0.        0.        1.2181312]
[ 680.7362  -141.01794 2249.3767 ]
[   6.15531218 -203.25484674   -3.39603664]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  89.50362428  127.58796207 -677.4941189 ]
[  48.6375506  -182.08369844  -76.35664068]
[0. 0. 0.]
zmp [21909825.08942378  5751879.19038           0.        ]
d1:19230056.80667, d2:0.01718, d3:10252965.73430
inertial
[0.        0.        1.2181312]
[ 552.09705 -208.1998  -862.94617]
[-297.70068675 -182.20371861   29.3828458 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 148.34726887 -523.73127709 -227.72206326]
[-288.89727706   82.2788407   177.74438796]
[0. 0. 0.]
zmp [-15958952.73164562   6051607.07617805         0.        ]
d1:18023093.75408, d2:0.05770, d3:9146006.41939
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-237.72933423368187 steps:38[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[126.99276 244.53625 935.5796 ]
[  11.09487069 -297.15545466    8.36029955]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[132.70886222 225.4212123  -86.59548906]
[ -48.02140616 -293.13457684  -13.80326364]
[0. 0. 0.]
zmp [-1364279.07066774 -7926792.10893646        0.        ]
d1:9313006.61498, d2:0.03610, d3:2267916.34057
inertial
[0.        0.        1.2181312]
[126.99276 244.53625 935.5796 ]
[  11.09487069 -297.15545466    8.36029955]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 45.28436751 257.63480504 -86.59548906]
[  57.76371608 -291.37139305  -13.80326364]
[0. 0. 0.]
zmp [-3376134.79343046 -7953639.43136365        0.        ]
d1:11295186.02145, d2:0.02517, d3:1676437.00338
inertial
[0.        0.        1.2181312]
[126.99276 244.53625 935.5796 ]
[  11.09487069 -297.15545466    8.36029955]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-23.05291826 268.21798299 -58.76071511]
[  85.56442226 -274.73821415  -74.98072018]
[0. 0. 0.]
zmp [-19143370.57328957  11370463.81808521         0.        ]
d1:11756466.05858, d2:0.04783, d3:8920154.21886
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-468.78973206226124 steps:42[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[797.83167 282.1036  708.1322 ]
[  -8.62091305 -177.97065213   -1.19337867]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 310.72828213 -549.05081061 -564.01145877]
[-177.83861348   -6.09799386    9.17148517]
[0. 0. 0.]
zmp [4759422.86997338  956379.10728651       0.        ]
d1:5877104.68657, d2:0.05927, d3:1221808.35589
inertial
[0.        0.        1.2181312]
[797.83167 282.1036  708.1322 ]
[  -8.62091305 -177.97065213   -1.19337867]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 553.69236665  302.37993978 -564.01145877]
[   3.4047863  -177.91055414    9.17148517]
[0. 0. 0.]
zmp [11890668.7189199   9933504.40870725        0.        ]
d1:22166145.69107, d2:0.00669, d3:668038.40069
inertial
[0.        0.        1.2181312]
[658.1389  172.7342  815.31335]
[  -8.62091305 -177.97065213   -1.19337867]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 182.78367747   -5.69647111 -655.39424238]
[ -32.81900681 -168.46034025   47.87382117]
[0. 0. 0.]
zmp [-27446690.36851608  -4518624.69113105         0.        ]
d1:22290090.13465, d2:0.01118, d3:12896072.65678
inertial
[0.        0.        1.2181312]
[ 549.3484  -715.2998  -438.51614]
[0. 0. 0.]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  14.29473619  202.23759609 -878.82481895]
[0. 0. 0.]
[0. 0. 0.]
zmp [-21737222.10661936  33126798.50354683         0.        ]
d1:44767024.47810, d2:0.03655, d3:20244697.70507
inertial
[0.        0.        1.2181312]
[-422.44382  175.66267  548.9056 ]
[2858.45681583  432.52529776 -957.86556956]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 66.11460307 -29.1699259  451.76778639]
[  751.6569124   -821.97706211 -2667.8117205 ]
[0. 0. 0.]
zmp [ 28891857.95853423 -27691572.09109025         0.        ]
d1:61684877.09494, d2:0.04847, d3:24742265.88527
inertial
[0.        0.        1.2181312]
[-240.45595  396.107    956.8624 ]
[  33.76661623 -324.02163868 -145.48175558]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -11.22350852  155.03070842 -436.53101228]
[108.2673781   -7.50295752 307.16784792]
[0. 0. 0.]
zmp [-2575272.82491297  1092523.86527622        0.        ]
d1:2019815.24067, d2:0.02928, d3:1468638.38899
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-407.2387134976424 steps:49[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -60.98111  552.7244  -157.89072]
[ -27.97952482 -176.63434846    7.79900881]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-513.87753677  208.38409696   41.58059102]
[148.90889797 -97.05103008  19.74302616]
[0. 0. 0.]
zmp [-5153161.33560766 -3397269.50260888        0.        ]
d1:8810304.72476, d2:0.05343, d3:694493.77980
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-276.36961167518496 steps:51[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -60.98111  552.7244  -157.89072]
[ -27.97952482 -176.63434846    7.79900881]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[487.29674713 261.22859031  59.36760911]
[-138.28017117 -112.502752     14.29246056]
[0. 0. 0.]
zmp [11889014.98679816 10961826.89767762        0.        ]
d1:23449430.34397, d2:0.05935, d3:7411574.82523
inertial
[0.        0.        1.2181312]
[ -60.98111  552.7244  -157.89072]
[ -27.97952482 -176.63434846    7.79900881]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-500.73199332  234.44821444   59.36760911]
[172.8536626  -43.58767255  14.29246056]
[0. 0. 0.]
zmp [-13869177.64577656   7138469.33006362         0.        ]
d1:19850228.72832, d2:0.05618, d3:2345116.17536
inertial
[0.        0.        1.2181312]
[ -60.98111  552.7244  -157.89072]
[ -27.97952482 -176.63434846    7.79900881]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[543.50282268 101.504571    59.36760911]
[-165.84313117  -65.37836645   14.29246056]
[0. 0. 0.]
zmp [13561369.25318501  5292443.78787567        0.        ]
d1:19424447.10858, d2:0.05890, d3:6142541.57949
inertial
[0.        0.        1.2181312]
[ -60.98111  552.7244  -157.89072]
[ -27.97952482 -176.63434846    7.79900881]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[551.70878784 -36.27529823  59.36760911]
[-176.86878015  -22.26450261   14.29246056]
[0. 0. 0.]
zmp [13952499.11688167   285959.33297192        0.        ]
d1:15034227.44519, d2:0.05937, d3:4665953.25908
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-351.5969582744533 steps:56[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-435.18277  446.4027  -612.012  ]
[   6.53395273 -278.23817563   -3.25727209]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-338.42729887  435.41456936  290.75855158]
[  24.44763294 -277.16168535    6.54920475]
[0. 0. 0.]
zmp [6047914.46729845 4645406.56528598       0.        ]
d1:10680104.10610, d2:0.00873, d3:595889.29770
inertial
[0.        0.        1.2181312]
[439.35892 106.9199  981.8858 ]
[   5.12324752 -274.59889077  -26.54120329]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-389.95487851  110.40745669 -200.53310563]
[  21.96482647 -268.15170534  -55.16345379]
[0. 0. 0.]
zmp [ 2483665.42279911 -7658243.00685992        0.        ]
d1:11440717.72075, d2:0.01336, d3:1815718.35055
inertial
[0.        0.        1.2181312]
[ -752.5985  -1082.2664    403.98804]
[ 199.77778322 -419.30507953 -174.42634931]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-1276.63876645   -67.06818153   321.55954348]
[-237.8244266  -390.44838063  -81.96054535]
[0. 0. 0.]
zmp [ 16705955.32712743 -15891639.89008313         0.        ]
d1:40723017.18997, d2:0.05841, d3:12617694.22749
inertial
[0.        0.        1.2181312]
[ -752.5985  -1082.2664    403.98804]
[ 199.77778322 -419.30507953 -174.42634931]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-620.53638426 -726.9281256  -907.86304737]
[ 177.18938768 -410.13923585 -126.95533344]
[0. 0. 0.]
zmp [ 1289492.28148024 11780741.38915854        0.        ]
d1:21180477.09506, d2:0.03661, d3:5516174.12481
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-390.45551171304305 steps:61[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[279.92288 486.11285  53.52256]
[ -33.34032053 -248.57391939   20.45232426]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 269.05016953  454.24319903 -189.57233426]
[ -59.01975958 -242.85350075   20.9623183 ]
[0. 0. 0.]
zmp [  2753744.98472349 -12528673.84492571         0.        ]
d1:14752042.24944, d2:0.04953, d3:5434312.66848
inertial
[0.        0.        1.2181312]
[279.92288 486.11285  53.52256]
[ -33.34032053 -248.57391939   20.45232426]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 213.5682067   482.81826221 -189.57233426]
[ -29.94991047 -248.1212465    20.9623183 ]
[0. 0. 0.]
zmp [  1678269.7336561  -12652234.37707575         0.        ]
d1:13847172.11768, d2:0.04639, d3:5097637.07388
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-146.00891245837144 steps:64[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 648.8478 -415.7167  553.1599]
[ -35.12086235 -515.11050506    0.76172296]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 428.97081453 -384.05806975 -512.15944895]
[ -11.06264828 -516.1709362     4.18250402]
[0. 0. 0.]
zmp [6733267.76538136 3873452.87190813       0.        ]
d1:10609591.86983, d2:0.01079, d3:1132713.52952
inertial
[0.        0.        1.2181312]
[ 648.8478 -415.7167  553.1599]
[ -35.12086235 -515.11050506    0.76172296]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 132.51327486 -502.01854563 -569.42206442]
[-105.77818667 -499.08656852   79.34667389]
[0. 0. 0.]
zmp [12796153.89398449 -2100684.24333282        0.        ]
d1:10120868.17591, d2:0.02986, d3:6188877.22895
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-325.05021186748047 steps:67[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 243.1535   131.82994 1897.2212 ]
[ 140.1738402  -791.84982197  -71.65099878]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 123.24521371  183.5555814  -166.19485074]
[ 319.5497721  -724.5067927  -140.18806714]
[0. 0. 0.]
zmp [-12006487.15441287  -5517654.16469632         0.        ]
d1:16527660.62855, d2:0.02517, d3:2961953.12980
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-88.88891416535115 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-19.567551997068506 steps:70[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-828.3314     42.407127  768.94806 ]
[ -69.69791443 -380.22995836   40.80934128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-580.94426886   13.71515979  591.81668535]
[ -32.34630514 -382.28039693   47.41358521]
[0. 0. 0.]
zmp [-1181306.26435038 -2164541.35589097        0.        ]
d1:3400234.86504, d2:0.01751, d3:344089.24401
inertial
[0.        0.        1.2181312]
[-828.3314     42.407127  768.94806 ]
[ -69.69791443 -380.22995836   40.80934128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-194.81508254  547.47737439  591.81668535]
[-368.59288648 -106.41368491   47.41358521]
[0. 0. 0.]
zmp [ 288056.96982961 -854977.03861169       0.        ]
d1:1108905.98670, d2:0.05845, d3:373894.14233
inertial
[0.        0.        1.2181312]
[-828.3314     42.407127  768.94806 ]
[ -69.69791443 -380.22995836   40.80934128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-580.80122484   18.82318237  591.81668535]
[ -35.70665188 -381.981172     47.41358521]
[0. 0. 0.]
zmp [-1167924.19159955 -2165281.75721756        0.        ]
d1:3387296.15531, d2:0.01772, d3:348463.95624
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-415.90069874756085 steps:74[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-828.3314     42.407127  768.94806 ]
[ -69.69791443 -380.22995836   40.80934128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[115.2960884  596.51230924 564.63370223]
[382.35602979 -41.24229936  39.18628796]
[0. 0. 0.]
zmp [2987259.55022736  236450.24391965       0.        ]
d1:3357525.28015, d2:0.05888, d3:1092424.31382
inertial
[0.        0.        1.2181312]
[-828.3314     42.407127  768.94806 ]
[ -69.69791443 -380.22995836   40.80934128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[219.38094975 566.56163707 564.63370223]
[ 368.95736321 -108.47822836   39.18628796]
[0. 0. 0.]
zmp [3056134.2110351   495737.80393528       0.        ]
d1:3672742.85363, d2:0.05809, d3:1193969.78533
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-369.27639810706887 steps:77[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-813.9478   150.61026  502.456  ]
[  -6.8519956  -370.38488493   25.17212792]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-555.39815179  202.33681624  579.47150536]
[ -40.66316878 -368.1979509     2.94950142]
[0. 0. 0.]
zmp [14932712.08782756 -1441330.12845138        0.        ]
d1:16222992.31038, d2:0.04580, d3:5811511.54045
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-309.3113159789828 steps:79[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-813.9478   150.61026  502.456  ]
[  -6.8519956  -370.38488493   25.17212792]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[584.89272044 156.68184489 564.39858848]
[  17.89824498 -369.98458735   -4.79321636]
[0. 0. 0.]
zmp [  2348741.90744058 -13657709.2977294          0.        ]
d1:14025900.78590, d2:0.03303, d3:3602373.11624
inertial
[0.        0.        1.2181312]
[-478.4525    -21.734482  682.2355  ]
[ -463.23716883 -1129.39722104    55.42067649]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-424.77392098   62.57399339  212.22823111]
[ -612.40546431 -1028.89181061   237.63034319]
[0. 0. 0.]
zmp [   308835.8282005  -16400362.72230906         0.        ]
d1:20711636.29968, d2:0.02917, d3:5636712.38374
inertial
[0.        0.        1.2181312]
[-478.4525    -21.734482  682.2355  ]
[ -463.23716883 -1129.39722104    55.42067649]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-427.07730027   44.19692306  212.22823111]
[ -567.46359231 -1054.34513908   237.63034319]
[0. 0. 0.]
zmp [  -320190.0952345  -16514488.60575266         0.        ]
d1:21276880.13561, d2:0.02653, d3:5480444.84104
inertial
[0.        0.        1.2181312]
[-478.4525    -21.734482  682.2355  ]
[ -463.23716883 -1129.39722104    55.42067649]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-213.96375563   -5.080604    428.46573743]
[ -266.61286514 -1111.59601164   428.25075132]
[0. 0. 0.]
zmp [-10635788.41250151  -5893444.20468105         0.        ]
d1:8704155.37763, d2:0.00413, d3:6969788.59404
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-377.1825763789092 steps:84[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-478.4525    -21.734482  682.2355  ]
[ -463.23716883 -1129.39722104    55.42067649]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[320.37601686  18.24446985 355.54967259]
[  424.30588574 -1084.58971553   365.72727592]
[0. 0. 0.]
zmp [  269608.70049049 14678436.40137776        0.        ]
d1:15254339.55037, d2:0.04508, d3:4605259.93162
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-158.90934223906618 steps:86[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[267.12943 -94.67112 -36.84255]
[  -7.58835455 -160.7470223     7.60543329]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -22.14703424 -202.28264731 -197.26123743]
[-151.28708465  -54.5258287     6.02835221]
[0. 0. 0.]
zmp [-9854001.4242438   5107620.19652627        0.        ]
d1:13025740.30530, d2:0.05890, d3:5321557.80259
inertial
[0.        0.        1.2181312]
[267.12943 -94.67112 -36.84255]
[  -7.58835455 -160.7470223     7.60543329]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 197.36055412  -49.57392983 -197.26123743]
[  33.34676322 -157.31765338    6.02835221]
[0. 0. 0.]
zmp [ 1029204.58097577 13457578.76018242        0.        ]
d1:14347215.82007, d2:0.04200, d3:4675237.95482
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-161.72978264418907 steps:89[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 140.00943  -263.7534    -75.439804]
[ -2.20324619 -89.10604715   1.65613853]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-253.68893948 -113.10243193 -109.62779185]
[-89.04644789  -3.37152111  -2.02614106]
[0. 0. 0.]
zmp [-4044697.14902256   314955.8363033         0.        ]
d1:4338789.52173, d2:0.05940, d3:1493514.02658
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-117.4271994765177 steps:91[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  -80.83045 -1062.4592    247.84428]
[   7.8330638  -146.45305773  -12.40214563]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -319.91583717 -1014.76644159    57.06351684]
[ -31.30590677 -143.16650541   -5.75758195]
[0. 0. 0.]
zmp [ 6768971.59513771 13501056.78115126        0.        ]
d1:20567400.92380, d2:0.02408, d3:2529760.92401
inertial
[0.        0.        1.2181312]
[  -80.83045 -1062.4592    247.84428]
[   7.8330638  -146.45305773  -12.40214563]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  127.62189512 -1056.31893843    57.06351684]
[  30.60031055 -143.31897452   -5.75758195]
[0. 0. 0.]
zmp [10869321.74667417 13734893.11130911        0.        ]
d1:24997295.60713, d2:0.01279, d3:1383417.83071
inertial
[0.        0.        1.2181312]
[  52.923244 -142.59404   495.0749  ]
[  16.13117301 -433.57997354   68.31694478]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-133.1680822    -1.08911084  -73.47793244]
[-422.68409916  -46.28343615  -86.30071586]
[0. 0. 0.]
zmp [-19731347.00686043   -357574.74237961         0.        ]
d1:22588646.54751, d2:0.05861, d3:6495154.59032
inertial
[0.        0.        1.2181312]
[  52.923244 -142.59404   495.0749  ]
[  16.13117301 -433.57997354   68.31694478]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-133.16847919   -1.03885949  -73.47793244]
[-422.70152023  -46.1239289   -86.30071586]
[0. 0. 0.]
zmp [-19730313.82609307   -349334.55364366         0.        ]
d1:22576459.85883, d2:0.05862, d3:6492235.86079
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-343.75698066803176 steps:96[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-453.4349  -239.48947  796.0873 ]
[ -72.7863681  -192.95315156   40.61465996]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 210.07358591 -325.51310214  335.95940242]
[187.71450388 -64.75845819  55.66309475]
[0. 0. 0.]
zmp [9159020.87619286  343665.44251587       0.        ]
d1:10047636.84120, d2:0.05931, d3:2940437.66561
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-109.3295805095428 steps:98[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-109.8882860058724 steps:99[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 280.10013   35.1313  -289.80826]
[  -6.29218727 -175.58660877    4.01680279]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 206.45141936   11.42082784 -192.19175839]
[ -28.00079144 -173.45152117    0.88071338]
[0. 0. 0.]
zmp [ 10285812.37826111 -15167742.44216447         0.        ]
d1:24622976.04701, d2:0.05802, d3:8400101.30689
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-208.9442238747414 steps:101[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 280.10013   35.1313  -289.80826]
[  -6.29218727 -175.58660877    4.01680279]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -23.06740563  201.25904921 -196.60361432]
[-167.50679955  -52.67719062    6.06914196]
[0. 0. 0.]
zmp [-4557451.0824775  -2263198.38448629        0.        ]
d1:5436886.18540, d2:0.05922, d3:2519971.06972
inertial
[0.        0.        1.2181312]
[ 280.10013   35.1313  -289.80826]
[  -6.29218727 -175.58660877    4.01680279]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-201.5455338    20.41351208 -196.60361432]
[  15.7170532  -174.88965415    6.06914196]
[0. 0. 0.]
zmp [ 1530451.98651676 -8236613.80281232        0.        ]
d1:9204466.40446, d2:0.03336, d3:2702362.68932
inertial
[0.        0.        1.2181312]
[-128.75638 -421.00488  319.51132]
[  257.52127793 -2213.14747946  -728.00655047]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[   8.86287219 -438.10676191   42.51169328]
[  428.66311781 -2101.10110985  -604.94738253]
[0. 0. 0.]
zmp [  -404325.1636662  -28670607.14480366         0.        ]
d1:30291258.59283, d2:0.05386, d3:9200006.55750
inertial
[0.        0.        1.2181312]
[-128.75638 -421.00488  319.51132]
[  257.52127793 -2213.14747946  -728.00655047]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 395.95990623 -187.70147668   42.51169328]
[2071.40499924 -554.67064447 -604.94738253]
[0. 0. 0.]
zmp [-7372463.65217352 -9710099.40271188        0.        ]
d1:5333281.63064, d2:0.05817, d3:865090.13626
inertial
[0.        0.        1.2181312]
[-128.75638 -421.00488  319.51132]
[  257.52127793 -2213.14747946  -728.00655047]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-405.90596256 -165.09522193   42.51169328]
[-1808.44576286 -1152.34622168  -604.94738253]
[0. 0. 0.]
zmp [ 14325561.53748048 -14826684.21878891         0.        ]
d1:28827053.15307, d2:0.05940, d3:9400857.75844
inertial
[0.        0.        1.2181312]
[-128.75638 -421.00488  319.51132]
[  257.52127793 -2213.14747946  -728.00655047]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-182.27286461 -370.58801099 -152.52687751]
[-1315.89712396 -1242.75488357 -1299.3514987 ]
[0. 0. 0.]
zmp [28799395.90643077  4938732.60041765        0.        ]
d1:27824077.82571, d2:0.04427, d3:14790678.40454
inertial
[0.        0.        1.2181312]
[-937.88007   827.9039     42.537178]
[-1766.18979026 -2954.26091921   444.0057334 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[904.42323834 858.15367217 103.12482544]
[ 1457.73643958 -2653.03648951  1638.134941  ]
[0. 0. 0.]
zmp [ 4375178.22276795 49933332.88605507        0.        ]
d1:43643690.89702, d2:0.02841, d3:26701882.44257
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:89.66675872612893 steps:109[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-87.8347   765.2071   -44.720028]
[-149.18043601 -111.24621356   64.49246575]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 41.125429   763.79941553  90.42156027]
[-119.70592851  -99.87983322  101.61218518]
[0. 0. 0.]
zmp [ 7453079.36560222 13104122.30983702        0.        ]
d1:20154612.66785, d2:0.01741, d3:2021473.45025
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-79.79510245614097 steps:111[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-786.20984  -64.42608 1656.6595 ]
[ -43.15272468 -167.89327485   22.7641308 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-566.35570234  -52.46470013  546.59432389]
[ -33.48876582 -167.215443     31.10962363]
[0. 0. 0.]
zmp [  6634486.59783662 -20245083.69827969         0.        ]
d1:25545325.34973, d2:0.05252, d3:8406733.45543
inertial
[0.        0.        1.2181312]
[-497.46942  673.1311  1361.391  ]
[ -94.86845988 -348.84066611  104.84157369]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[468.3976863  682.18052322 125.75646189]
[  96.66753449 -347.0148859    30.42858651]
[0. 0. 0.]
zmp [-4361186.17247414  9075260.88352068        0.        ]
d1:13858218.51828, d2:0.01028, d3:1614961.60687
inertial
[0.        0.        1.2181312]
[  811.36743 -1427.2426     71.68356]
[ 425.20870607  -81.29868874 -176.61669638]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-781.98671905 1328.37717774  565.02169858]
[-408.21264657  131.68384014  -58.59808113]
[0. 0. 0.]
zmp [ -571839.61281418 14507820.54993994        0.        ]
d1:25148331.55512, d2:0.01895, d3:6444891.21279
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-73.23968271547164 steps:115[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[737.6257    16.924356 583.3301  ]
[ -54.43187365 -248.48341994   21.37143189]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 490.41311424  -46.46721478 -549.28485862]
[ -65.14705759 -242.09075066   43.06705339]
[0. 0. 0.]
zmp [-1483720.09126265  2178775.51771462        0.        ]
d1:3627887.56274, d2:0.05889, d3:1202777.57357
inertial
[0.        0.        1.2181312]
[737.6257    16.924356 583.3301  ]
[ -54.43187365 -248.48341994   21.37143189]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 155.664242   -467.36808052 -549.28485862]
[-247.77054038  -38.23392804   43.06705339]
[0. 0. 0.]
zmp [-2710410.78169174   632814.03595101        0.        ]
d1:3222887.30848, d2:0.05847, d3:1079181.14173
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-363.8490673852523 steps:118[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-265.4791  -599.781    196.06001]
[ -34.95225926 -305.71015249   29.49551204]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-132.89929927 -614.7115636   186.23623689]
[-2.88681527e-01 -3.06992590e+02  2.08767335e+01]
[0. 0. 0.]
zmp [ 8958834.34354984 -4039581.35809245        0.        ]
d1:12445101.79610, d2:0.05456, d3:4333370.97838
inertial
[0.        0.        1.2181312]
[-265.4791  -599.781    196.06001]
[ -34.95225926 -305.71015249   29.49551204]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  -8.54908579 -588.4685577   289.56530611]
[  -3.96200773 -304.01674974   47.31251657]
[0. 0. 0.]
zmp [-14199732.8789285 -30888079.1341909         0.       ]
d1:44384887.42464, d2:0.05387, d3:7757563.59395
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-118.15434167521957 steps:121[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 495.32437  -28.39646 -417.1149 ]
[-1.79358757e+00 -2.17810459e+02 -8.99288150e-02]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  52.96384607 -311.80177462 -382.2657192 ]
[-213.36836882  -42.99887179   -8.34582234]
[0. 0. 0.]
zmp [-1240249.0688834   2095821.58404425        0.        ]
d1:3379571.57512, d2:0.05923, d3:1234624.46792
inertial
[0.        0.        1.2181312]
[1092.2888   505.66965 -766.6918 ]
[ -2.23337669 -84.22874653  10.3170491 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 647.118123    985.3582705  -243.11291432]
[-82.76735857   4.95931499 -14.98129084]
[0. 0. 0.]
zmp [765242.58111296 452622.52263729      0.        ]
d1:974041.58706, d2:0.05821, d3:419185.47708
inertial
[0.        0.        1.2181312]
[ 55.454983  96.257515 692.76544 ]
[  10.18984659 -274.86347621    8.54379   ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-55.06271454  75.38341716 -60.21796534]
[ 238.33730315 -126.19642359   54.06995983]
[0. 0. 0.]
zmp [9618578.95280079 4622041.16125224       0.        ]
d1:15735415.68547, d2:0.05433, d3:1796198.78698
inertial
[0.        0.        1.2181312]
[414.01144 851.24615 251.62549]
[ -1.00641642 -60.19835313  -8.741222  ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 725.74193866 -536.26389385  285.91103146]
[-26.75214861  42.26138306 -33.51346604]
[0. 0. 0.]
zmp [ 13412801.43873498 -15445217.41179815         0.        ]
d1:21120785.96180, d2:0.03428, d3:3389981.00696
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-202.98158172746082 steps:126[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 751.2828   -480.1833    -57.417797]
[   6.21975151 -263.70635367   -6.17349158]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-314.3524929  -625.06839726 -552.69688962]
[-252.5637006   -75.63878942   -8.37119026]
[0. 0. 0.]
zmp [9715343.82050884  465895.72240452       0.        ]
d1:10620527.56388, d2:0.05824, d3:3119111.63500
inertial
[0.        0.        1.2181312]
[ 751.2828   -480.1833    -57.417797]
[   6.21975151 -263.70635367   -6.17349158]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-296.09526677 -633.92081999 -552.69688962]
[-250.26421398  -82.93056141   -8.37119026]
[0. 0. 0.]
zmp [9730671.11475011  537125.99555667       0.        ]
d1:10699360.12595, d2:0.05795, d3:3102915.96347
inertial
[0.        0.        1.2181312]
[-710.08887  718.73846  911.7016 ]
[  74.58953972 -454.49033498   83.13365037]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 487.97695162 -662.96783506  585.80147654]
[-406.87675149  108.06706646 -186.80976811]
[0. 0. 0.]
zmp [-15350043.21653395   2622034.35041207         0.        ]
d1:15576323.94660, d2:0.05846, d3:4324501.62331
inertial
[0.        0.        1.2181312]
[-710.08887  718.73846  911.7016 ]
[  74.58953972 -454.49033498   83.13365037]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 485.48209769 -664.79693373  585.80147654]
[-406.4677623   109.59532372 -186.80976811]
[0. 0. 0.]
zmp [-15333330.41459409   2681397.82030318         0.        ]
d1:15497227.83492, d2:0.05850, d3:4300962.24189
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-577.8727436053842 steps:131[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-76.28646 777.81036 275.5017 ]
[ 7.62957403e-01 -2.35498377e+02 -1.36340164e-01]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-60.67713871 775.95721418  70.83335418]
[   2.52357427 -235.41672805   -5.71591199]
[0. 0. 0.]
zmp [-4781582.04009794  5316948.34801857        0.        ]
d1:9635884.43326, d2:0.05931, d3:3420549.72461
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-171.8570426907608 steps:133[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-76.28646 777.81036 275.5017 ]
[ 7.62957403e-01 -2.35498377e+02 -1.36340164e-01]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-182.87601383  757.86283837   54.85386977]
[  70.62160747 -224.65892819   -1.01459249]
[0. 0. 0.]
zmp [ 8908315.9367458  -6226598.41904636        0.        ]
d1:14579315.06159, d2:0.02085, d3:1124978.84719
inertial
[0.        0.        1.2181312]
[ 730.97845  -867.0372    109.287094]
[-169.22031332 -599.4043467   -32.84463194]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -464.41502925 -1026.89149545   126.07716977]
[-435.362654   -136.69997733  423.90282627]
[0. 0. 0.]
zmp [-9329635.35638303 -5279062.55852242        0.        ]
d1:5557177.02201, d2:0.04209, d3:1243970.23226
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-253.97120557717156 steps:136[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[243.98634 213.24812 686.3341 ]
[ 114.28614365 -191.45804596  -62.50457255]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 225.99910661  157.66530309 -170.49973805]
[  28.81750649 -207.11176798  -77.40655916]
[0. 0. 0.]
zmp [  8931946.66997914 -11229266.20240114         0.        ]
d1:18711446.55504, d2:0.05891, d3:6645237.54058
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-122.87894569592224 steps:138[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[243.98634 213.24812 686.3341 ]
[ 114.28614365 -191.45804596  -62.50457255]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-208.41054766  159.94033718 -189.70566329]
[ -23.58891922 -206.73021414  -80.14790598]
[0. 0. 0.]
zmp [ 9347876.44587865 12690060.87370076        0.        ]
d1:22083894.15765, d2:0.05923, d3:7282866.07314
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-78.45740344786915 steps:140[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[243.98634 213.24812 686.3341 ]
[ 114.28614365 -191.45804596  -62.50457255]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-198.88157866   67.73735278 -246.70198342]
[ 184.15631333  -57.51650236 -111.78467105]
[0. 0. 0.]
zmp [23494148.66170481  1537362.36950542        0.        ]
d1:17383089.25839, d2:0.05654, d3:11068304.71627
inertial
[0.        0.        1.2181312]
[-496.43835 -334.35416   71.37692]
[  9.15430191 -10.72950733  -3.66918419]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 355.13146641 -240.68252331  417.36953161]
[ -6.11608116 -12.05034292  -4.0381135 ]
[0. 0. 0.]
zmp [ -8406912.32490082 -10310271.5074933          0.        ]
d1:18904419.21687, d2:0.05916, d3:6190614.28651
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-245.61064110178484 steps:143[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-441.9809   831.58636  742.758  ]
[  82.0490321  -569.3080997   -81.30254069]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-507.62429113  739.59371605  286.7085061 ]
[ 196.1257974  -539.28664615  -39.34922874]
[0. 0. 0.]
zmp [ 7545023.21974177 10871385.91876141        0.        ]
d1:18690338.45288, d2:0.01777, d3:1206337.96289
inertial
[0.        0.        1.2181312]
[-525.85425    51.355072  693.1585  ]
[  82.0490321  -569.3080997   -81.30254069]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-247.22933456  -74.77353754  460.91931833]
[ 189.38344422 -524.61355397 -140.5642198 ]
[0. 0. 0.]
zmp [11604337.05912349 29578528.02022902        0.        ]
d1:43731094.74306, d2:0.04088, d3:7521558.90608
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:4.651065013414183 steps:146[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-685.091   -564.3225  -173.22717]
[-25.07990172 -79.64751989   5.21259554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-491.71540781 -568.12530894  472.50320736]
[-18.95539404 -79.76148485  15.85964785]
[0. 0. 0.]
zmp [11088392.86633721  3454397.30865477        0.        ]
d1:14180325.03188, d2:0.02743, d3:2893044.56933
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-159.45574174039314 steps:148[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-685.091   -564.3225  -173.22717]
[-25.07990172 -79.64751989   5.21259554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[674.63007777 328.98028186 473.76772281]
[82.12244175 -1.25349497 15.06859261]
[0. 0. 0.]
zmp [10743657.30464795 -2850508.98059533        0.        ]
d1:12888052.54701, d2:0.05843, d3:2765067.04187
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-111.27659021767987 steps:150[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-342.10587  366.98325  204.05202]
[  24.30093402 -107.59629772  -14.15783002]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-397.78895246 -189.39298944  240.01538644]
[109.06553476   2.67690383 -16.28012844]
[0. 0. 0.]
zmp [  79983.9955442 -959295.2635224       0.       ]
d1:1014611.62214, d2:0.05915, d3:373902.48249
inertial
[0.        0.        1.2181312]
[-342.10587  366.98325  204.05202]
[  24.30093402 -107.59629772  -14.15783002]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-254.88469646  359.35991227  240.01538644]
[  21.36488209 -106.98597177  -16.28012844]
[0. 0. 0.]
zmp [ 5344173.78607102 -7730485.96454557        0.        ]
d1:12040504.14633, d2:0.05850, d3:4361073.62153
inertial
[0.        0.        1.2181312]
[-342.10587  366.98325  204.05202]
[  24.30093402 -107.59629772  -14.15783002]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-237.46746398  303.13184067  321.61068964]
[  31.76453164 -101.40362591  -29.59424223]
[0. 0. 0.]
zmp [-14446794.31962825   5539633.41314227         0.        ]
d1:9742163.17515, d2:0.04693, d3:6948336.45878
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-797.5851031181047 steps:154[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-473.03992  543.8152   346.0754 ]
[ -60.18577128 -358.64740283   37.98755673]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-268.81524436  564.83483058  358.05273348]
[ -82.2214154  -352.98139316   29.9010927 ]
[0. 0. 0.]
zmp [-4079082.81201933 -8730496.15354931        0.        ]
d1:12852042.26553, d2:0.02162, d3:1664275.76293
inertial
[0.        0.        1.2181312]
[-473.03992  543.8152   346.0754 ]
[ -60.18577128 -358.64740283   37.98755673]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-340.99009882  524.42899207  358.05273348]
[ -34.92984001 -360.74384725   29.9010927 ]
[0. 0. 0.]
zmp [-4913700.90305896 -8785806.22905386        0.        ]
d1:13759663.64354, d2:0.01690, d3:1429451.29014
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-223.999035717292 steps:157[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-190.4408  -681.3301   864.23016]
[  43.27176874 -191.51372523  -17.40771451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-644.55876798 -274.18280637   99.22797268]
[-137.39418714 -135.69693443  -35.48428763]
[0. 0. 0.]
zmp [-959235.06451447 4333870.63552519       0.        ]
d1:5050945.43155, d2:0.05529, d3:1691220.02117
inertial
[0.        0.        1.2181312]
[-190.4408  -681.3301   864.23016]
[  43.27176874 -191.51372523  -17.40771451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  79.5824293  -702.47781092   25.88300009]
[  62.44718135 -169.75685855  -76.37349701]
[0. 0. 0.]
zmp [ 6693030.05567462 -2055161.50195964        0.        ]
d1:3895993.23860, d2:0.04124, d3:3085427.28996
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-182.95815641454084 steps:160[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-190.4408  -681.3301   864.23016]
[  43.27176874 -191.51372523  -17.40771451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 144.86081827 -682.99187955  114.08694655]
[ -29.50559317 -191.0118228   -34.55225538]
[0. 0. 0.]
zmp [ -336837.54800506 -5428235.72175875        0.        ]
d1:6171046.22404, d2:0.04347, d3:1851236.48410
inertial
[0.        0.        1.2181312]
[-190.4408  -681.3301   864.23016]
[  43.27176874 -191.51372523  -17.40771451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-657.95104835 -233.58721558  114.08694655]
[-193.23416043    4.08112892  -34.55225538]
[0. 0. 0.]
zmp [-4201834.59727861  -759427.39689769        0.        ]
d1:5211110.31668, d2:0.05911, d3:1599868.81229
inertial
[0.        0.        1.2181312]
[-190.4408  -681.3301   864.23016]
[  43.27176874 -191.51372523  -17.40771451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -56.76888972 -695.87345682  114.08694655]
[ -82.96351804 -174.56560981  -34.55225538]
[0. 0. 0.]
zmp [-1464634.47778416 -5215862.35405278        0.        ]
d1:7015563.64121, d2:0.05191, d3:2147042.96290
inertial
[0.        0.        1.2181312]
[-222.66386  -71.46664 1356.0881 ]
[ -85.2296246  -270.43696418  156.61646569]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -12.70828126 -229.25527633   44.35312314]
[ 207.57677828 -187.54095618  -46.26571051]
[0. 0. 0.]
zmp [33101822.1387062 19261384.8382644        0.       ]
d1:52868866.31178, d2:0.05237, d3:4553926.68996
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-118.73491669579946 steps:165[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-222.66386  -71.46664 1356.0881 ]
[ -85.2296246  -270.43696418  156.61646569]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -34.53401552 -170.76950745  155.9867164 ]
[-247.66557694 -128.79845202   49.72887795]
[0. 0. 0.]
zmp [  394642.214744   -1573239.44900074        0.        ]
d1:1855676.90608, d2:0.05818, d3:403088.00455
inertial
[0.        0.        1.2181312]
[-222.66386  -71.46664 1356.0881 ]
[ -85.2296246  -270.43696418  156.61646569]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -26.52440547 -172.19545993  155.9867164 ]
[-241.38293193 -140.21969531   49.72887795]
[0. 0. 0.]
zmp [  435726.72840864 -1804286.71760256        0.        ]
d1:2114213.71280, d2:0.05768, d3:467410.07300
inertial
[0.        0.        1.2181312]
[ 662.6647  -457.27475   41.84143]
[-239.68989932 -550.85380929  263.46237176]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 577.76797159 -445.91066904 -339.95962233]
[ -12.45123883 -489.81887948  347.58253444]
[0. 0. 0.]
zmp [ -4753441.94850391 -14910307.97517006         0.        ]
d1:20947135.31155, d2:0.03070, d3:3528088.75455
inertial
[0.        0.        1.2181312]
[ 662.6647  -457.27475   41.84143]
[-239.68989932 -550.85380929  263.46237176]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 514.82329751 -517.30949875 -339.95962233]
[ -76.09068379 -484.03280839  347.58253444]
[0. 0. 0.]
zmp [ -3528113.6901059  -15297946.45334662         0.        ]
d1:19959151.30714, d2:0.03428, d3:4028130.62394
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-541.6709897114108 steps:170[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -94.927734 1169.3843    224.92752 ]
[ -40.51650988 -315.20419966   31.49325314]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 172.57185116 1159.57108969   45.66051841]
[ -92.52397065 -302.12380955   33.99714525]
[0. 0. 0.]
zmp [1185106.13639969 5903906.62147222       0.        ]
d1:7501797.07420, d2:0.03418, d3:1574461.46251
inertial
[0.        0.        1.2181312]
[ -94.927734 1169.3843    224.92752 ]
[ -40.51650988 -315.20419966   31.49325314]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-176.06509207 1159.04573023   45.66051841]
[   0.41573969 -315.97356204   33.99714525]
[0. 0. 0.]
zmp [2450071.93738308 6003908.93820475       0.        ]
d1:8875952.29976, d2:0.02300, d3:1218113.05335
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-277.6079491106501 steps:173[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[575.9167   113.29265    7.298514]
[ -33.14347464 -245.31666213   16.2436959 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 417.82529185   -7.02429719 -412.17470724]
[ -92.20986025 -228.45668233   24.15868759]
[0. 0. 0.]
zmp [ 14101870.35504755 -11466439.45010559         0.        ]
d1:24825937.60445, d2:0.05904, d3:8395234.84359
inertial
[0.        0.        1.2181312]
[575.9167   113.29265    7.298514]
[ -33.14347464 -245.31666213   16.2436959 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 394.07218279  139.04829725 -412.17470724]
[  -6.79937178 -246.26994873   24.15868759]
[0. 0. 0.]
zmp [ 11152333.19256889 -11938980.8013982          0.        ]
d1:22428311.86182, d2:0.05939, d3:7576716.55280
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-143.98177182118118 steps:176[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-252.40054  153.72765  -26.88621]
[  13.39219097 -221.1989853    -4.34886127]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-174.86144155  160.72603425  175.86599814]
[   3.49429816 -221.47543296   -6.69096433]
[0. 0. 0.]
zmp [ 13055536.47123963 -10795985.11135415         0.        ]
d1:23566401.00062, d2:0.05915, d3:7625332.12547
inertial
[0.        0.        1.2181312]
[ 74.62925 872.74927 276.1801 ]
[-922.6394676  -291.52734341  146.05670275]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -33.64605392  868.45977727 -109.11654106]
[ 363.14171935 -249.96200128  861.33550694]
[0. 0. 0.]
zmp [ 2201024.51504692 12961436.84140477        0.        ]
d1:16165137.90775, d2:0.05777, d3:4922018.73803
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:19.07127599788633 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-131.921676386712 steps:180[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 671.18665 1091.0999   155.00902]
[-922.6394676  -291.52734341  146.05670275]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  57.78528482 1051.83904214 -728.89370976]
[  17.38081336 -243.23011731  936.37006649]
[0. 0. 0.]
zmp [21992932.54092863 -5235479.91818119        0.        ]
d1:17030398.07590, d2:0.01212, d3:10251687.94295
inertial
[0.        0.        1.2181312]
[ 247.44304   -123.06373     -4.0771537]
[ 12.84768623 -77.35871868   6.29897096]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-135.76669858 -117.36658799 -210.15526283]
[ -2.31774784 -76.7156992  -16.08616047]
[0. 0. 0.]
zmp [-14240219.64361428  45344572.21054198         0.        ]
d1:56032959.22865, d2:0.03580, d3:10612263.40977
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-266.40754017774975 steps:183[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[408.97772 604.9126  196.73898]
[  80.48816457 -102.75704764  -31.81118128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -81.97849344  675.20961749 -265.61923951]
[101.38458325 -55.0254799  -61.07960833]
[0. 0. 0.]
zmp [ -1692629.87681918 -14100294.87784951         0.        ]
d1:15465602.82435, d2:0.04502, d3:4018993.94995
inertial
[0.        0.        1.2181312]
[408.97772 604.9126  196.73898]
[  80.48816457 -102.75704764  -31.81118128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 454.35115159 -266.70237497 -505.58577487]
[-92.25500948 -89.62756902  22.20966294]
[0. 0. 0.]
zmp [-33736666.44478435  10344502.26241724         0.        ]
d1:28525564.48144, d2:0.04883, d3:15632434.23007
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-246.76439577787204 steps:186[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[408.97772 604.9126  196.73898]
[  80.48816457 -102.75704764  -31.81118128]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-677.60230432   23.3134665  -271.0971193 ]
[ 64.71994227 -94.85310405 -62.06104583]
[0. 0. 0.]
zmp [15445625.71537383 -4960820.91353361        0.        ]
d1:19600606.22472, d2:0.05475, d3:3646085.99922
inertial
[0.        0.        1.2181312]
[-179.70961 -129.87624  950.2539 ]
[  140.27852412 -1214.31449722   386.94637598]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 188.32786913 -103.93607174   53.78933559]
[ 752.31376134 -371.68881703 -888.88091329]
[0. 0. 0.]
zmp [ 7555531.5482089  -1380873.24710672        0.        ]
d1:6558745.27381, d2:0.04892, d3:3414709.49534
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-142.50226431691613 steps:189[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-230.60884  294.8694   495.43713]
[  80.62880297 -215.63712303  -34.72747068]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-109.08117649  321.29655094  158.10824036]
[  19.23376314 -223.25044288  -52.81737607]
[0. 0. 0.]
zmp [1827611.07708129  -14812.94614813       0.        ]
d1:1983997.81819, d2:0.04239, d3:624268.60896
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-218.7348791853285 steps:191[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-230.60884  294.8694   495.43713]
[  80.62880297 -215.63712303  -34.72747068]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[208.07539512 264.90134009 163.27984594]
[ -91.49414041 -203.58531604  -56.41113699]
[0. 0. 0.]
zmp [1624894.47280377 -151683.80660592       0.        ]
d1:1748739.63756, d2:0.03818, d3:482884.18901
inertial
[0.        0.        1.2181312]
[-230.60884  294.8694   495.43713]
[  80.62880297 -215.63712303  -34.72747068]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[185.66203987 281.06529517 163.27984594]
[ -74.49896946 -210.39976843  -56.41113699]
[0. 0. 0.]
zmp [1634441.68240628 -153418.29657619       0.        ]
d1:1759681.38188, d2:0.03756, d3:485459.88743
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-315.3273411226661 steps:194[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-175.84447 -318.05072  489.3598 ]
[  93.59803179 -414.61277554  -72.41545198]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-317.79963523 -120.20266422  128.96607499]
[-264.25976925 -327.22122175  -61.29769111]
[0. 0. 0.]
zmp [8477075.50148603 1252197.47990612       0.        ]
d1:10122078.91011, d2:0.04978, d3:2354891.65046
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-160.43135361865322 steps:196[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-175.84447 -318.05072  489.3598 ]
[  93.59803179 -414.61277554  -72.41545198]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  93.74739122 -326.79615183  128.42602753]
[ -93.95643419 -408.28373712  -71.70028849]
[0. 0. 0.]
zmp [11904461.12613415  6835385.10242478        0.        ]
d1:18896188.41297, d2:0.05652, d3:6042688.15533
inertial
[0.        0.        1.2181312]
[-175.84447 -318.05072  489.3598 ]
[  93.59803179 -414.61277554  -72.41545198]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-273.16786599 -146.02712302  190.08664731]
[-403.29314987 -118.35141072  -63.33978553]
[0. 0. 0.]
zmp [ 1862807.94419066 -3127838.64445768        0.        ]
d1:4190516.73616, d2:0.05696, d3:826090.14981
inertial
[0.        0.        1.2181312]
[-235.61197  747.2301   733.4151 ]
[ 129.70028839 -698.16100755    5.51348274]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 98.70794707 747.22853429 213.94414096]
[ -31.55578417 -696.85686236 -132.83715842]
[0. 0. 0.]
zmp [-4707350.78954761 18402294.02094873        0.        ]
d1:20232039.59706, d2:0.03290, d3:4946767.39356
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-512.6105468714319 steps:200[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-1105.5073    184.37552   927.0416 ]
[  57.36578873 -340.14898542  -38.72485969]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-356.59017073 -707.83090575  792.43909187]
[334.29978532 -58.91191196 -61.36131943]
[0. 0. 0.]
zmp [-7350369.13042253   -83807.29095989        0.        ]
d1:7859809.37644, d2:0.05754, d3:2509984.71733
inertial
[0.        0.        1.2181312]
[-1105.5073    184.37552   927.0416 ]
[  57.36578873 -340.14898542  -38.72485969]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-113.96176931  471.43073692 1010.39922149]
[ -63.80177991 -338.02634414   25.68450101]
[0. 0. 0.]
zmp [ -217126.09823252 -6695779.13548659        0.        ]
d1:11358302.65379, d2:0.05854, d3:1087603.85017
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-467.62523494630784 steps:203[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-1105.5073    184.37552   927.0416 ]
[  57.36578873 -340.14898542  -38.72485969]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 80.82435835 825.98374663 753.23243454]
[ 288.92655135 -188.28040287    8.00656749]
[0. 0. 0.]
zmp [ 7683841.16447066 -6504322.05548968        0.        ]
d1:13200446.06278, d2:0.05296, d3:506306.34926
inertial
[0.        0.        1.2181312]
[-1105.5073    184.37552   927.0416 ]
[  57.36578873 -340.14898542  -38.72485969]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-315.87660384  767.46581254  753.23243454]
[343.47786238 -30.83868458   8.00656749]
[0. 0. 0.]
zmp [8033018.00922417   28573.30166998       0.        ]
d1:8841094.82025, d2:0.05921, d3:2638998.60807
inertial
[0.        0.        1.2181312]
[ 568.88007 -691.4478  -331.40256]
[ -78.22169257 -244.82052377  -47.87404346]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-559.75842343 -547.77238085 -433.98219025]
[-242.4088009   -39.90662383   75.50600623]
[0. 0. 0.]
zmp [14123980.95161736 -1901427.73864552        0.        ]
d1:14922872.50083, d2:0.05703, d3:6103156.00874
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-321.1827291086996 steps:207[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[605.39026 829.36615 302.49936]
[ -71.59182315 -131.3272659    26.51829101]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 883.97164983 -247.75449836 -459.95371522]
[-137.10887333   22.69131774   55.30371596]
[0. 0. 0.]
zmp [8.10876540e+06 6.24926601e+03 0.00000000e+00]
d1:8388847.84679, d2:0.05861, d3:2809059.71013
inertial
[0.        0.        1.2181312]
[605.39026 829.36615 302.49936]
[ -71.59182315 -131.3272659    26.51829101]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 630.86834848  666.92832373 -459.95371522]
[ -83.92451349 -110.77191528   55.30371596]
[0. 0. 0.]
zmp [ 7479995.26765068 -1014506.42086248        0.        ]
d1:8255316.44664, d2:0.04734, d3:2921049.07454
inertial
[0.        0.        1.2181312]
[605.39026 829.36615 302.49936]
[ -71.59182315 -131.3272659    26.51829101]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 528.1296471   750.91099672 -459.95371522]
[ -67.07826044 -121.71379474   55.30371596]
[0. 0. 0.]
zmp [ 7349721.29285484 -1055276.22915158        0.        ]
d1:8161323.98165, d2:0.04689, d3:2889077.31208
inertial
[0.        0.        1.2181312]
[605.39026 829.36615 302.49936]
[ -71.59182315 -131.3272659    26.51829101]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-492.10016837  -39.13321068 -900.36196451]
[ 87.76612611   0.55142822 121.11582949]
[0. 0. 0.]
zmp [15304089.858179   13869451.83517912        0.        ]
d1:21747572.01527, d2:0.05367, d3:8274399.58281
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-703.4912296582514 steps:212[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[266.2935 696.7544 682.4368]
[  21.7753344  -219.00157803  -16.44195071]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-502.32450737  514.57776223 -198.13819583]
[197.36901646 -96.76779128 -10.83162945]
[0. 0. 0.]
zmp [ 1257859.52408885 -1480346.46366319        0.        ]
d1:2605895.33386, d2:0.05927, d3:894284.29662
inertial
[0.        0.        1.2181312]
[266.2935 696.7544 682.4368]
[  21.7753344  -219.00157803  -16.44195071]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 388.23247946  549.59159226 -321.87499904]
[ -67.94314536 -208.55607731   17.99852189]
[0. 0. 0.]
zmp [-6334549.07422593  5178431.00434936        0.        ]
d1:2281102.10021, d2:0.05705, d3:3067270.66819
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-641.9708996806016 steps:215[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[942.3907    36.798187 308.86664 ]
[ -39.24041355 -220.35642423    9.55453324]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 647.64412689   34.6136436  -684.69946608]
[ -22.97770391 -220.18331712   32.98644233]
[0. 0. 0.]
zmp [ -7407700.25690606 -18459975.10535824         0.        ]
d1:26559965.20314, d2:0.02480, d3:3559396.69074
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-369.51224264014405 steps:217[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-1421.5233   1364.4993    192.42094]
[  42.1184083  -504.58351898  -44.20446243]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-952.55240048 1406.15662626  998.97664193]
[  16.38888385 -505.60188391  -21.83177149]
[0. 0. 0.]
zmp [  2184922.16668444 -15398045.0645356          0.        ]
d1:17201290.71277, d2:0.04810, d3:5765647.13425
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-191.3563019963084 steps:219[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-397.7684   899.34595  792.76337]
[ 107.46533186 -448.92537719  -34.57744921]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-171.64059313  932.72601645  260.00858924]
[  22.06681655 -456.44301229  -65.23504038]
[0. 0. 0.]
zmp [-1225634.26316328 10052902.25647001        0.        ]
d1:11034050.03636, d2:0.04717, d3:3792824.40439
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-120.69048144608024 steps:221[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-397.7684   899.34595  792.76337]
[ 107.46533186 -448.92537719  -34.57744921]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 844.35615275 -338.5300834   373.50096825]
[-432.44895096  104.27496082 -123.2779072 ]
[0. 0. 0.]
zmp [1838051.92172223  257950.44348173       0.        ]
d1:2100285.11366, d2:0.05932, d3:668603.81365
inertial
[0.        0.        1.2181312]
[-397.7684   899.34595  792.76337]
[ 107.46533186 -448.92537719  -34.57744921]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 866.84592577 -275.8949607   373.50096825]
[-438.91505577   72.3804295  -123.2779072 ]
[0. 0. 0.]
zmp [1914897.50490058 1066928.52208139       0.        ]
d1:2991501.75709, d2:0.05906, d3:956528.91477
inertial
[0.        0.        1.2181312]
[-397.7684   899.34595  792.76337]
[ 107.46533186 -448.92537719  -34.57744921]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[338.35773784 844.42523945 373.50096825]
[-104.18669445 -432.47023083 -123.2779072 ]
[0. 0. 0.]
zmp [-4728149.72631146 11990627.94497168        0.        ]
d1:14967467.42996, d2:0.02355, d3:2436656.43815
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-331.3403140720356 steps:225[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-205.3072  -309.6354   469.97058]
[  31.45729949 -258.22730819  -32.1140957 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-334.84838464   63.36587595  147.94074055]
[-244.15733808  -87.90987458  -18.16467283]
[0. 0. 0.]
zmp [18196321.46893007 -2913634.94616756        0.        ]
d1:21019680.14493, d2:0.05864, d3:7087682.01401
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-172.08140990230362 steps:227[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -23.158415 -434.97388  1335.5304  ]
[ -92.74081788 -221.34477793   57.0299341 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 411.20909193 -143.51894982    6.92772408]
[ 192.6587961  -131.03110617   57.51357503]
[0. 0. 0.]
zmp [-4381981.12324533 -1392255.68761977        0.        ]
d1:5790484.50146, d2:0.05734, d3:1411693.05957
inertial
[0.        0.        1.2181312]
[ -23.158415 -434.97388  1335.5304  ]
[ -92.74081788 -221.34477793   57.0299341 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  -7.56278663 -434.43080901   30.84269544]
[ -45.86474399 -219.7406164    84.88144873]
[0. 0. 0.]
zmp [ 13844837.77398462 -11449466.86499202         0.        ]
d1:5465736.37278, d2:0.05612, d3:6615946.80954
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-454.2938148971668 steps:230[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  254.39803 -1179.3643   1563.0564 ]
[   7.88960763 -231.09335006   -3.8024305 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  -13.82525459 -1194.55070677  -168.74828033]
[ -31.66633721 -229.02812348   -3.12213754]
[0. 0. 0.]
zmp [9146021.6578919   453485.12278339       0.        ]
d1:9852223.22439, d2:0.04002, d3:2760029.15968
inertial
[0.        0.        1.2181312]
[  254.39803 -1179.3643   1563.0564 ]
[   7.88960763 -231.09335006   -3.8024305 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-1086.4053361   -496.85608924  -168.74828033]
[-220.66609064  -69.01532429   -3.12213754]
[0. 0. 0.]
zmp [8969464.54564515  227303.94610566       0.        ]
d1:9473479.56877, d2:0.05809, d3:2776067.30783
inertial
[0.        0.        1.2181312]
[  254.39803 -1179.3643   1563.0564 ]
[   7.88960763 -231.09335006   -3.8024305 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-1106.80765954  -449.57675323  -168.74828033]
[-223.43524785  -59.44178142   -3.12213754]
[0. 0. 0.]
zmp [8967120.94374387  214052.18500623       0.        ]
d1:9460396.88902, d2:0.05845, d3:2779547.85118
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-15.953440591513512 steps:234[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-286.54742 -257.27487  380.1713 ]
[ -55.67494864 -290.11578472   24.63390558]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 147.68414588 -295.79575286  197.46914462]
[ 245.19600164 -161.24269166   33.8612509 ]
[0. 0. 0.]
zmp [16319208.78144758  7815179.16156141        0.        ]
d1:24141155.63823, d2:0.05409, d3:3407915.50688
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:36.93070808158648 steps:236[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 562.5737    -63.628414 1193.0717  ]
[ -56.99987741 -272.55465407   23.84262171]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 274.29522514  282.34891338 -406.91401522]
[ 199.51074026 -190.37423258   38.5764811 ]
[0. 0. 0.]
zmp [-11481280.62327218  -8571490.08192818         0.        ]
d1:19513633.76046, d2:0.04854, d3:760253.76715
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-135.07231889911225 steps:238[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-351.2728  -103.58481 -258.35342]
[ -12.0820677  -241.56788499    5.5304645 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  60.15942398 -259.13493319  251.69889758]
[237.67537622 -41.68080682  16.55748471]
[0. 0. 0.]
zmp [11856146.92767695  1034989.9353108         0.        ]
d1:13452801.40122, d2:0.05919, d3:3536022.70518
inertial
[0.        0.        1.2181312]
[-351.2728  -103.58481 -258.35342]
[ -12.0820677  -241.56788499    5.5304645 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 60.91027714 -93.66644581 348.76772556]
[237.89847531 -25.29437367  35.57430509]
[0. 0. 0.]
zmp [1487129.45177343  626154.30436377       0.        ]
d1:1267600.55040, d2:0.05906, d3:775743.70855
inertial
[0.        0.        1.2181312]
[-232.46182  800.9644   710.6426 ]
[-149.165805   -641.6604204  -154.51299574]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-452.51250003 -695.80147861  -81.70237975]
[ 41.98188791 649.69327589 100.5720652 ]
[0. 0. 0.]
zmp [10851017.66098939 35056201.60663122        0.        ]
d1:38014026.16604, d2:0.02657, d3:10665900.93734
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-164.07464456008708 steps:242[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-232.46182  800.9644   710.6426 ]
[-149.165805   -641.6604204  -154.51299574]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-750.77362848  319.15620236  173.3805497 ]
[652.43958742 -15.66320719  89.7541119 ]
[0. 0. 0.]
zmp [-14416164.69936946   4438510.01706115         0.        ]
d1:17479807.67650, d2:0.05867, d3:3336174.03024
inertial
[0.        0.        1.2181312]
[-232.46182  800.9644   710.6426 ]
[-149.165805   -641.6604204  -154.51299574]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-723.23002376  377.43880392  173.3805497 ]
[649.16594679 -67.12913782  89.7541119 ]
[0. 0. 0.]
zmp [-14079843.38851644   6255000.33509286         0.        ]
d1:18899966.39203, d2:0.05767, d3:2664155.22396
inertial
[0.        0.        1.2181312]
[-404.359    682.07654  195.68896]
[-115.30400242 -262.36128497  102.12194209]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[389.00798561 488.49193386 488.65430816]
[-271.94671183  -85.03480043   30.70062245]
[0. 0. 0.]
zmp [-39199071.95287899  22806453.80789596         0.        ]
d1:57007133.28044, d2:0.05936, d3:20050593.68255
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-50.10967048729093 steps:246[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-221.71461  472.41574 1081.7329 ]
[ -14.92955387 -335.6949323    -5.14917742]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -8.842319   499.36513622 151.29533289]
[-109.22435136 -317.42599851   14.99193308]
[0. 0. 0.]
zmp [5262215.09728467 -157297.74535443       0.        ]
d1:5491308.37295, d2:0.04457, d3:1791383.42997
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-133.47504676776742 steps:248[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620122037.647766629, 142.858000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620122037.647837042, 142.858000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620122038.663668338, 142.858000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620122038.663722521, 142.858000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 958, in reset
    
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:24:46.200980: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:24:46.201022: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620122093.203967412, 1.433000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620122093.206960292, 1.435000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620122093.207127224, 1.435000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620122094.828561366, 2.579000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620122095.783620746, 3.311000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620122096.962939422, 4.110000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620122097.772460530, 4.710000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-7.15744421e-09  1.00468503e-08 -6.91605348e-09]
[-7.15744421e-09  1.00468503e-08 -6.91605348e-09]
[0. 0. 0.]
zmp [24683186.63928917  -574601.4251679         0.        ]
d1:25785896.56235, d2:0.04074, d3:7773439.94740
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-6.98940623e-09  1.01644686e-08 -6.91605348e-09]
[-6.98940623e-09  1.01644686e-08 -6.91605348e-09]
[0. 0. 0.]
zmp [24684604.84236627  -574591.46913057        0.        ]
d1:25787383.50055, d2:0.04072, d3:7773900.07857
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-6.72203168e-09  1.03432348e-08 -6.91605348e-09]
[-6.72203168e-09  1.03432348e-08 -6.91605348e-09]
[0. 0. 0.]
zmp [24686827.4628389   -574643.45246772        0.        ]
d1:25789705.38519, d2:0.04072, d3:7774599.96891
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-5.99694327e-10  1.13428561e-08 -8.42496321e-09]
[-5.99694327e-10  1.13428561e-08 -8.42496321e-09]
[0. 0. 0.]
zmp [ 3722190.03425171 -3648284.7873734         0.        ]
d1:4243647.06316, d2:0.03568, d3:1838894.50142
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[310.1029497  -19.33593953 -96.06540391]
[-643.28404311 -212.70069173  -48.63498108]
[0. 0. 0.]
zmp [2461103.09764161 1111803.07452745       0.        ]
d1:3656700.83964, d2:0.05770, d3:481579.28479
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[310.60158312  -8.02379115 -96.06540391]
[-635.10666137 -235.99897161  -48.63498108]
[0. 0. 0.]
zmp [2495639.31757309 1276325.70364581       0.        ]
d1:3858691.83969, d2:0.05710, d3:443158.35839
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[310.46412033 -12.23697955 -96.06540391]
[-638.2499533  -227.36075919  -48.63498108]
[0. 0. 0.]
zmp [2482292.10191973 1215280.86061554       0.        ]
d1:3783178.32917, d2:0.05734, d3:457236.86176
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 42.87968505 307.73212458 -96.06540391]
[ 163.12787358 -657.60572776  -48.63498108]
[0. 0. 0.]
zmp [6286028.59581125 4518678.65900428       0.        ]
d1:11040718.29150, d2:0.01410, d3:720670.34022
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 50.80812047 306.52285573 -96.06540391]
[ 146.10038408 -661.59705613  -48.63498108]
[0. 0. 0.]
zmp [6202235.04922609 4539349.38684086       0.        ]
d1:10975612.80695, d2:0.01267, d3:686519.09284
inertial
[0.        0.        1.2181312]
[140.1667  293.46136 559.81384]
[  56.69969338 -676.90947833  -59.49755916]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 57.41773481 305.35378533 -96.06540391]
[ 131.77456862 -664.59872712  -48.63498108]
[0. 0. 0.]
zmp [6131817.60118285 4554274.86962855       0.        ]
d1:10918424.28408, d2:0.01150, d3:658561.38021
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  34.095478 -221.19893   -87.15382 ]
[ -40.6247438  -240.66471559   16.18996824]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[218.65838968  27.95137205 -38.71300595]
[241.88846413 -32.36323682   3.53081095]
[0. 0. 0.]
zmp [9210375.53211134   56207.78938527       0.        ]
d1:11246792.30096, d2:0.05927, d3:3455050.90562
inertial
[0.        0.        1.2181312]
[  34.095478 -221.19893   -87.15382 ]
[ -40.6247438  -240.66471559   16.18996824]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  28.05577852 -218.64501587  -38.71300595]
[ -32.24772923 -241.90388809    3.53081095]
[0. 0. 0.]
zmp [   77014.56841847 12116761.25855079        0.        ]
d1:12611515.28847, d2:0.03472, d3:3217668.65768
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:25.754009775605486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-33.17361388671904 steps:1[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-201.61372 -345.82852  218.78629]
[ -14.21104316 -123.07849368   12.97089451]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-257.77856584 -265.22590589  153.13683794]
[ -54.93191618 -110.26347104   13.21821922]
[0. 0. 0.]
zmp [15174382.64437491 14624967.84464757        0.        ]
d1:29880346.54804, d2:0.02213, d3:581835.92321
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-214.76248079509557 steps:3[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-457.1404  -333.79138  619.9723 ]
[ -47.59610881 -574.41697236   24.67715752]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-300.78546891 -337.88446067  340.22973468]
[ -11.71721245 -574.3685799    46.7300856 ]
[0. 0. 0.]
zmp [ 11214386.97799792 -10234897.59082215         0.        ]
d1:21022089.82739, d2:0.05923, d3:6969733.02027
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-305.4648062214821 steps:5[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[899.97076 335.6107  782.29083]
[  -4.89947548 -418.81113013  -41.1120955 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 657.94579456  350.47276269 -605.68815448]
[  -2.93885491 -418.78399869   -6.17331206]
[0. 0. 0.]
zmp [-9253889.28583308  1352037.14764484        0.        ]
d1:10391075.82797, d2:0.04886, d3:3881201.34137
inertial
[0.        0.        1.2181312]
[899.97076 335.6107  782.29083]
[  -4.89947548 -418.81113013  -41.1120955 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 603.78804827   91.75473372 -741.35211275]
[-116.70570726 -398.99135838   51.11204319]
[0. 0. 0.]
zmp [-5807305.99672331 -2198123.04215138        0.        ]
d1:6113556.24329, d2:0.02227, d3:3513933.88962
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-492.2568517206827 steps:8[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-491.49686  241.65149  454.4554 ]
[ -13.84416168 -519.94608613    4.62138054]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-343.83265834  223.55473366  362.99727903]
[ -21.77814685 -518.89476925  -28.45211423]
[0. 0. 0.]
zmp [  292251.63779076 -5438090.69323193        0.        ]
d1:6026554.62125, d2:0.04398, d3:2007440.25012
inertial
[0.        0.        1.2181312]
[-189.25706 -471.03912 -867.5917 ]
[ 95.57301412 175.36262206   9.21886565]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 112.87381746 -472.23677979  148.14871494]
[-60.0593696  176.08061894 -72.62741581]
[0. 0. 0.]
zmp [5589839.23864445 2289703.33557761       0.        ]
d1:8700938.12718, d2:0.05518, d3:2756751.36500
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-520.0471004152325 steps:11[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 132.05986 -450.61    1029.2839 ]
[  -2.94882307 -515.69736451  -27.3862169 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 236.60940443 -396.49402313  -85.42631794]
[ 163.42539856 -489.07677611    6.9655069 ]
[0. 0. 0.]
zmp [-1835768.65642185  9776624.34573567        0.        ]
d1:10789056.40426, d2:0.04895, d3:3579153.85021
inertial
[0.        0.        1.2181312]
[ 132.05986 -450.61    1029.2839 ]
[  -2.94882307 -515.69736451  -27.3862169 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 177.47548557 -348.38566073 -260.03663997]
[ 163.9149541  -461.22939004 -162.33240551]
[0. 0. 0.]
zmp [-14990400.8025582 -10622037.6363147         0.       ]
d1:17716038.47247, d2:0.02686, d3:8116846.83609
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-387.0463303253795 steps:14[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 132.05986 -450.61    1029.2839 ]
[  -2.94882307 -515.69736451  -27.3862169 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -39.16858965 -453.04052024 -117.08672055]
[  66.14528733 -510.7126702   -27.38375596]
[0. 0. 0.]
zmp [-2862670.46355179 13664150.69158009        0.        ]
d1:15949168.25732, d2:0.03178, d3:3335710.26217
inertial
[0.        0.        1.2181312]
[ 132.05986 -450.61    1029.2839 ]
[  -2.94882307 -515.69736451  -27.3862169 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ -20.16735544 -454.28312227 -117.08672055]
[  87.46868121 -507.4956553   -27.38375596]
[0. 0. 0.]
zmp [-3272513.9497159  13581578.05698691        0.        ]
d1:16246788.30801, d2:0.03071, d3:3177159.28609
inertial
[0.        0.        1.2181312]
[  77.95021  944.88214 1265.0208 ]
[-321.96574896  -84.6256103  -127.64785649]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-231.74754662  918.40510007  -41.27511848]
[-202.38580087 -155.86805378  213.4680151 ]
[0. 0. 0.]
zmp [-15670908.92667295 -12096108.34661452         0.        ]
d1:21314178.78557, d2:0.02072, d3:1674830.82414
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-437.1935922422843 steps:18[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 52.2512  354.92084 347.1897 ]
[ -56.06745807 -128.53590853   16.83215213]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-339.99066468  108.81806584  -35.55227184]
[117.91388534 -64.86722062  39.41572224]
[0. 0. 0.]
zmp [ 7765629.27378737 -1170799.50677403        0.        ]
d1:8524328.23686, d2:0.05891, d3:2853948.81606
inertial
[0.        0.        1.2181312]
[ 562.08923 -203.54184  742.3006 ]
[  996.0635461  -2475.75207154 -1135.86416677]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 256.93948322 -390.50406693 -372.64227496]
[2549.04828705 -702.55068007 -360.92439671]
[0. 0. 0.]
zmp [ -525418.01835132 -1254867.29026559        0.        ]
d1:1645408.75225, d2:0.05889, d3:568019.14867
inertial
[0.        0.        1.2181312]
[ 562.08923 -203.54184  742.3006 ]
[  996.0635461  -2475.75207154 -1135.86416677]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 322.36310276    9.85667558 -503.34725309]
[2157.60246962 1403.71861563 -704.14273212]
[0. 0. 0.]
zmp [2753382.9764308  6748585.49484508       0.        ]
d1:9263850.82291, d2:0.05930, d3:2801009.98880
inertial
[0.        0.        1.2181312]
[ 562.08923 -203.54184  742.3006 ]
[  996.0635461  -2475.75207154 -1135.86416677]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 322.38077516    9.26036994 -503.34725309]
[2160.19522497 1399.7251767  -704.14273212]
[0. 0. 0.]
zmp [2759088.01257822 6734391.48305784       0.        ]
d1:9235697.15327, d2:0.05931, d3:2800879.61391
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-828.4264175326416 steps:23[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -62.403664    -6.7805557 -944.6307   ]
[   2.04218517 -162.86736492  -11.983538  ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-22.61281145  39.6655298   43.0755121 ]
[-151.93296804  -58.62364043   -3.0969409 ]
[0. 0. 0.]
zmp [11922134.95159366 -4533162.86320331        0.        ]
d1:16254414.37766, d2:0.05891, d3:5301281.81900
inertial
[0.        0.        1.2181312]
[ -62.403664    -6.7805557 -944.6307   ]
[   2.04218517 -162.86736492  -11.983538  ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-31.50998932  33.04260757  43.0755121 ]
[-133.31430489  -93.52889959   -3.0969409 ]
[0. 0. 0.]
zmp [10866901.46680951 -7280016.53496684        0.        ]
d1:17878145.79463, d2:0.05916, d3:5848746.71562
inertial
[0.        0.        1.2181312]
[-313.2577    67.4715  -169.53687]
[   2.04218517 -162.86736492  -11.983538  ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-167.56274453  -26.21688012  271.8789935 ]
[  49.36899231 -152.83714846  -27.08243507]
[0. 0. 0.]
zmp [7098413.31535361 2122107.44031641       0.        ]
d1:5195538.09804, d2:0.02173, d3:3245029.06701
inertial
[0.        0.        1.2181312]
[ -433.95822 -1206.455    1455.5905 ]
[ 24.61122773 203.52068953 -61.45974437]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-910.95857807 -153.20479981  889.12103343]
[ 173.51436184   27.48054408 -105.65970412]
[0. 0. 0.]
zmp [22937752.71393208  5532558.26285067        0.        ]
d1:21509347.35850, d2:0.05935, d3:11924889.11772
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-890.6778898664039 steps:28[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ -433.95822 -1206.455    1455.5905 ]
[ 24.61122773 203.52068953 -61.45974437]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[1193.08534307 -112.62924086  455.75813714]
[-202.00452817   20.4631519   -28.31638543]
[0. 0. 0.]
zmp [ 3135986.9069329  -1556042.41520513        0.        ]
d1:2579298.05865, d2:0.05917, d3:1540290.88714
inertial
[0.        0.        1.2181312]
[  23.36967    20.816578 -673.45325 ]
[  1.58896046 -86.54732553  -3.47863593]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-10.53291433  27.95343023  -9.33461014]
[ 75.85929716 -39.24197999 -14.08540132]
[0. 0. 0.]
zmp [5300516.0447052  3924003.80160808       0.        ]
d1:7287538.23569, d2:0.05177, d3:528951.66654
inertial
[0.        0.        1.2181312]
[-1097.7556    825.83716   541.30493]
[ -95.43896538  132.8926608  -244.08448755]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-1050.80583523   841.30807661  -274.01166712]
[-145.87898132   57.6007268   -46.5890218 ]
[0. 0. 0.]
zmp [7776621.43888735 -304620.63869578       0.        ]
d1:8268662.26931, d2:0.05591, d3:2316702.66408
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-826.5404725032794 steps:32[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[406.19946 398.15567 416.85434]
[  31.27787667 -326.61054145  -22.42187443]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 452.58178124 -175.69238363 -296.35767153]
[-309.23386314 -109.04583688  -11.66938978]
[0. 0. 0.]
zmp [-3213405.08448169  5139761.83073952        0.        ]
d1:7869640.26613, d2:0.05937, d3:2739180.18409
inertial
[0.        0.        1.2181312]
[406.19946 398.15567 416.85434]
[  31.27787667 -326.61054145  -22.42187443]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 198.22079688  443.177865   -296.35767153]
[  93.36327865 -314.32449469  -11.66938978]
[0. 0. 0.]
zmp [11476825.10152054 17675732.03147676        0.        ]
d1:29188313.81428, d2:0.01704, d3:2308684.16915
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-342.53420738090415 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-146.18384411132533 steps:36[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[297.37976  839.64557  -13.201377]
[   3.09308236 -195.75118762   -3.56051031]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 258.24995683  817.89190634 -240.41468133]
[ -11.67596278 -195.41113648    2.50109071]
[0. 0. 0.]
zmp [28691382.7296191   6510381.54535911        0.        ]
d1:35845205.05592, d2:0.02940, d3:6958688.89164
inertial
[0.        0.        1.2181312]
[297.37976  839.64557  -13.201377]
[   3.09308236 -195.75118762   -3.56051031]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-820.02535866  251.39334903 -240.41468133]
[195.50204071 -10.0395302    2.50109071]
[0. 0. 0.]
zmp [32786739.03698528  1305543.47122429        0.        ]
d1:35475734.22488, d2:0.05937, d3:9915706.91235
inertial
[0.        0.        1.2181312]
[-406.5292  -369.52914 -507.24854]
[  80.36260595 -104.26309109   26.96178173]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 325.65355826 -340.02752792  283.10573632]
[ -56.87293782 -109.63033731  -45.55876618]
[0. 0. 0.]
zmp [   768152.18979529 -11742132.05948263         0.        ]
d1:11805883.32518, d2:0.03539, d3:3437391.82338
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-341.54550992701473 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-170.33457140626356 steps:41[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  11.95012 -319.57214  -29.56826]
[  37.33439087 -165.87373841  -23.16532187]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[317.84558129 -34.09050965  -9.01056262]
[167.81981113   3.79768004 -27.01933091]
[0. 0. 0.]
zmp [-13526709.16152884  -3627573.31329481         0.        ]
d1:17195839.21497, d2:0.05900, d3:3085407.58780
inertial
[0.        0.        1.2181312]
[ 247.93018  321.02927 1807.7477 ]
[ 237.64148388 -185.15427176  105.50997777]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-294.57361772 -157.4597198  -230.13474227]
[ 205.63558979 -159.32611582 -151.93677179]
[0. 0. 0.]
zmp [ 1326990.64367513 -1193848.62829422        0.        ]
d1:1595826.03912, d2:0.05939, d3:55981.20545
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-423.03932030926273 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-109.92131261718404 steps:45[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-1007.8558  -365.8026   465.3836]
[  52.66400477 -231.57311363  -33.02204007]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-526.47813296  619.68739042  698.85134095]
[-218.40637592  -79.48206857  -48.79409122]
[0. 0. 0.]
zmp [11983037.51440697 -1859557.8029015         0.        ]
d1:13542877.32126, d2:0.05924, d3:4752756.98061
inertial
[0.        0.        1.2181312]
[-1007.8558  -365.8026   465.3836]
[  52.66400477 -231.57311363  -33.02204007]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  20.20573853 -450.99068004  972.51429225]
[  -1.97278363 -226.19548924  -72.32784622]
[0. 0. 0.]
zmp [10438919.20970054 -2460553.14902518        0.        ]
d1:7368453.79107, d2:0.01239, d3:5013905.63611
inertial
[0.        0.        1.2181312]
[-1175.7764   -812.3232   -682.00604]
[  -2.3152942  -401.70231185 -360.33392668]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 624.18783231  -30.43605502 1285.21682982]
[ 331.4445736  -208.31432892   90.10965189]
[0. 0. 0.]
zmp [10558904.04175421 -3301705.59414293        0.        ]
d1:7403540.59847, d2:0.05052, d3:5300174.70148
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-531.6706167288032 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-154.77222375000014 steps:50[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-270.7223   167.64243  468.42285]
[ -20.22314127 -504.10600211   -6.60345617]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 68.38600311 242.10448235 195.20072124]
[-462.5056674  -201.42447117    6.96709515]
[0. 0. 0.]
zmp [14908065.35649128  1974627.60619047        0.        ]
d1:16878880.59617, d2:0.05605, d3:4594606.49334
inertial
[0.        0.        1.2181312]
[-169.73737  -50.10154  780.2984 ]
[ -20.22314127 -504.10600211   -6.60345617]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 28.16232332 -80.77004643 154.93232474]
[  -6.76943064 -499.04432964  -73.76174269]
[0. 0. 0.]
zmp [1736420.63108187   64612.89851236       0.        ]
d1:1145483.81152, d2:0.01244, d3:858523.90095
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-470.40629474811055 steps:53[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[391.24182 513.3503  983.14154]
[ -24.09322754 -279.7951038    39.35933036]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 172.30065455  542.86157227 -303.6651461 ]
[  29.62396823 -278.28510306   23.35839736]
[0. 0. 0.]
zmp [ 4495512.56093408 -2053627.37500548        0.        ]
d1:6005630.91372, d2:0.05440, d3:2091002.98593
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-349.75523990062334 steps:55[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  -4.8924975 -135.8964     437.80347  ]
[ -21.73190255 -305.1269243   -50.36874314]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[131.18332545 -35.80688574   0.75452931]
[292.86643543 -87.85470978   9.2478276 ]
[0. 0. 0.]
zmp [11537120.17825484  1009021.98386661        0.        ]
d1:12861319.06695, d2:0.05827, d3:3456168.15939
inertial
[0.        0.        1.2181312]
[  -4.8924975 -135.8964     437.80347  ]
[ -21.73190255 -305.1269243   -50.36874314]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[135.6915856   -6.30799647   6.30621208]
[304.52301239 -14.87843195  24.88131443]
[0. 0. 0.]
zmp [-4994531.21672457 -1628350.874542          0.        ]
d1:4174203.42026, d2:0.05934, d3:2314373.02820
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-597.626857390711 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-125.26434679688496 steps:59[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-758.1401   715.45166 1096.8513 ]
[  52.3933281  -377.60446159    4.86565215]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[446.26801485 774.02090449 537.01404946]
[-331.97917939 -183.89148542  -36.11025736]
[0. 0. 0.]
zmp [10820149.85141761 -2573695.36093075        0.        ]
d1:12567697.38639, d2:0.05804, d3:4619299.65269
inertial
[0.        0.        1.2181312]
[170.1699  676.8927  962.60535]
[ -31.97905347 -401.2249765    30.98485663]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[656.09402699 201.46410769 126.86350846]
[-367.73935102  -92.49053228 -134.97186799]
[0. 0. 0.]
zmp [13136600.75873048  7142250.76859418        0.        ]
d1:23174155.95585, d2:0.05340, d3:6491515.05251
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-273.3738475282221 steps:62[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  61.529655 -195.58212   756.7962  ]
[ -21.04450486 -352.32273997   29.47677944]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  55.27754233 -190.59223063  -51.54861336]
[   7.57876168 -352.86741244    1.15531852]
[0. 0. 0.]
zmp [ 6354611.36653447 -6773493.80611292        0.        ]
d1:12671379.60712, d2:0.05939, d3:4306799.44211
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-284.3220075480891 steps:64[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[  61.529655 -195.58212   756.7962  ]
[ -21.04450486 -352.32273997   29.47677944]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[  30.63125568 -195.30233725  -54.37818322]
[  53.04218934 -347.29824952   33.83238889]
[0. 0. 0.]
zmp [ 6493465.43934801 15785833.34977177        0.        ]
d1:22440584.56494, d2:0.05467, d3:5467773.27217
inertial
[0.        0.        1.2181312]
[-492.22583 -222.23465  719.40106]
[  -2.90543275 -289.66354556  -76.70385444]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-266.27334912 -235.53365716  406.56722802]
[  96.42357965 -263.38505205   72.41704031]
[0. 0. 0.]
zmp [ 6114838.11408245 15993850.47979048        0.        ]
d1:17140348.55711, d2:0.02874, d3:3913020.03136
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-444.1540511975008 steps:67[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-492.22583 -222.23465  719.40106]
[  -2.90543275 -289.66354556  -76.70385444]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 297.25704487 -315.98272293  321.66396437]
[ -43.28520381 -284.31385813  -34.71952578]
[0. 0. 0.]
zmp [ -286566.29688514 22195999.94364218        0.        ]
d1:22812595.88957, d2:0.04335, d3:7287798.52130
inertial
[0.        0.        1.2181312]
[-492.22583 -222.23465  719.40106]
[  -2.90543275 -289.66354556  -76.70385444]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[387.23581775 195.58947255 321.66396437]
[ 260.41217664 -122.0387902   -34.71952578]
[0. 0. 0.]
zmp [-17517807.04016126  10148705.69145676         0.        ]
d1:24325977.37862, d2:0.05470, d3:2482763.26773
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-132.86722498  604.85494659 -183.689034  ]
[-59.39804006 380.13462309 -70.83340625]
[0. 0. 0.]
zmp [ -8754538.505849   -12291062.58886614         0.        ]
d1:10324578.16429, d2:0.05894, d3:6390780.21258
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-828.2251195192725 steps:71[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-350.69211887  478.59535728 -255.35537763]
[-187.33817107  319.20182478 -126.73763897]
[0. 0. 0.]
zmp [ 15202163.39776175 -18904470.74216706         0.        ]
d1:32837993.72874, d2:0.01188, d3:1710840.41705
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-0.4068576415716194 steps:73[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-577.06827294  -94.33555565 -274.47747389]
[-365.85204408  -23.69873251 -136.52283778]
[0. 0. 0.]
zmp [-2539595.22813863  -299119.66437251        0.        ]
d1:2783548.89078, d2:0.05835, d3:917114.40518
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 499.65071576  303.73702438 -274.47747389]
[ 330.30353487  159.08781875 -136.52283778]
[0. 0. 0.]
zmp [-3536973.04993972  -194719.48625731        0.        ]
d1:3678738.81622, d2:0.05927, d3:1204855.84935
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-567.12778056 -142.38356379 -274.47747389]
[-362.57718847  -54.28752575 -136.52283778]
[0. 0. 0.]
zmp [-2531373.19627727  -237832.10003666        0.        ]
d1:2716248.02724, d2:0.05884, d3:894452.08345
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-570.66216071 -127.48207308 -274.47747389]
[-363.87456283  -44.77327698 -136.52283778]
[0. 0. 0.]
zmp [-2533561.18058424  -257078.13048183        0.        ]
d1:2736716.64232, d2:0.05870, d3:901441.57203
inertial
[0.        0.        1.2181312]
[355.34863 539.4184   91.44434]
[173.9225643  350.42655325 -99.3579435 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-202.00535497  548.72655285 -274.47747389]
[ -92.61422993  354.72800007 -136.52283778]
[0. 0. 0.]
zmp [-3056995.82762475  -851023.57302506        0.        ]
d1:3850613.01674, d2:0.05065, d3:1264252.07944
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-744.4557681987643 steps:79[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[-411.81735  200.04172 -656.29663]
[  -4.03458484 -275.53519237  -11.03063566]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-329.74544833  143.01085659  283.59489897]
[  52.46218165 -270.38001975    8.84859046]
[0. 0. 0.]
zmp [3126803.52363941 5807775.73611176       0.        ]
d1:9047710.89304, d2:0.01985, d3:658185.81184
inertial
[0.        0.        1.2181312]
[-411.81735  200.04172 -656.29663]
[  -4.03458484 -275.53519237  -11.03063566]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-302.99708497 -193.33113345  283.59489897]
[ 253.4669095  -107.75968163    8.84859046]
[0. 0. 0.]
zmp [6207733.08743234 2307625.05584726       0.        ]
d1:8251893.84173, d2:0.05593, d3:1548443.87823
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-646.9237417277336 steps:82[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[635.05145 401.05182 921.95245]
[ -52.85787726 -240.63507753   31.97769482]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 539.27960181  271.8770229  -446.53484344]
[ -99.2553304  -222.62082612   35.88244085]
[0. 0. 0.]
zmp [-2391834.1604978   5329482.30146026        0.        ]
d1:7298877.87782, d2:0.05576, d3:2576720.90708
inertial
[0.        0.        1.2181312]
[635.05145 401.05182 921.95245]
[ -52.85787726 -240.63507753   31.97769482]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 223.48527094   60.97666699 -714.47120825]
[ -82.84444959 -184.74418766  140.37656458]
[0. 0. 0.]
zmp [ 2808447.65054252 -4184881.30870877        0.        ]
d1:4352765.65946, d2:0.05462, d3:1474484.79359
inertial
[0.        0.        1.2181312]
[-340.70148  589.5042   708.90814]
[  96.30999038 -486.10323865   41.4511244 ]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-641.62025444  220.637001     56.88158722]
[482.64319186 -67.18280247  90.07782219]
[0. 0. 0.]
zmp [-13875389.38743904   1707685.88094564         0.        ]
d1:16639737.45356, d2:0.05837, d3:3914900.51825
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-969.3231263689099 steps:86[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[240.2561    20.508865 845.1326  ]
[  95.62191049 -309.06742708   -5.01483362]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 152.81959716   79.27996    -168.83267025]
[ 167.02947323 -267.31559266  -72.86810649]
[0. 0. 0.]
zmp [ 1137975.51364399 -4407827.99579445        0.        ]
d1:5424203.52864, d2:0.05222, d3:1808302.01563
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-173.22111195383872 steps:88[00m
[RDDPG] Resetting Environment
inertial
[0.        0.        1.2181312]
[ 137.53006  197.299   -279.72726]
[   3.46532854 -278.5110446    -3.03920643]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[210.55776713 -59.48409439 -99.8423005 ]
[-273.81191315  -51.04298768   -1.43837364]
[0. 0. 0.]
zmp [2741532.66372005 -804314.2753003        0.        ]
d1:3386157.46642, d2:0.05916, d3:1173619.85095
inertial
[0.        0.        1.2181312]
[ 727.36005  343.56897 1683.4379 ]
[ 11.94437332 -42.88426395  -6.74256554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 429.88144441  491.7015443  -469.59965158]
[-40.34111109   5.9028378  -17.87398918]
[0. 0. 0.]
zmp [ 5649882.23280986 -1562162.72535498        0.        ]
d1:5485620.82775, d2:0.05890, d3:1356743.30295
inertial
[0.        0.        1.2181312]
[ 727.36005  343.56897 1683.4379 ]
[ 11.94437332 -42.88426395  -6.74256554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 429.95437374  491.63780793 -469.59965158]
[-40.34023453   5.90882164 -17.87398918]
[0. 0. 0.]
zmp [ 5649879.96842539 -1562179.8184548         0.        ]
d1:5485600.99946, d2:0.05890, d3:1356737.26034
inertial
[0.        0.        1.2181312]
[ 727.36005  343.56897 1683.4379 ]
[ 11.94437332 -42.88426395  -6.74256554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 429.90476908  491.6812195  -469.59965158]
[-40.34083219   5.90475016 -17.87398918]
[0. 0. 0.]
zmp [ 5649881.51552034 -1562168.18630393        0.        ]
d1:5485614.50056, d2:0.05890, d3:1356741.37444
inertial
[0.        0.        1.2181312]
[ 727.36005  343.56897 1683.4379 ]
[ 11.94437332 -42.88426395  -6.74256554]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 429.88082781  491.70209928 -469.59965158]
[-40.34111832   5.9027869  -17.87398918]
[0. 0. 0.]
zmp [ 5649882.2539066  -1562162.57943667        0.        ]
d1:5485620.99922, d2:0.05890, d3:1356743.35511
inertial
[0.        0.        1.2181312]
[  609.62134   710.06006 -1469.6882 ]
[199.68727958  16.68699788  15.96968723]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[-686.43022461  228.4212872  -593.68299855]
[  -9.85039205   87.98241164 -179.76519961]
[0. 0. 0.]
zmp [-35788837.14209305  -2330777.61052521         0.        ]
d1:42948406.14382, d2:0.05920, d3:14918380.57908
inertial
[0.        0.        1.2181312]
[  609.62134   710.06006 -1469.6882 ]
[199.68727958  16.68699788  15.96968723]
[ 0.   0.  -9.8]
support
[0. 0. 0.]
[ 693.61168591  602.96222684 -176.53014919]
[  50.51116898  118.50053151 -153.49173399]
[0. 0. 0.]
zmp [-35767256.13831802  20405998.79622015         0.        ]
d1:52359354.40084, d2:0.05491, d3:23889975.73501
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-79.0843285242647 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-182.0759449413999 steps:97[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 562, in connect
    self.read_header()
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 657, in read_header
    self._validate_header(read_ros_handshake_header(sock, self.read_buff, self.protocol.buff_size))
  File "/opt/ros/noetic/lib/python3/dist-packages/rosgraph/network.py", line 357, in read_ros_handshake_header
    d = sock.recv(buff_size)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1023, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 104] Connection reset by peer
2021-05-04 15:28:17.981778: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:28:17.981819: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620122304.802236759, 1.189000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620122304.807063702, 1.191000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620122304.808585799, 1.192000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620122306.447028265, 2.401000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620122307.487561168, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620122308.519973357, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620122309.642662898, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[-0.70244914 -0.02998528  0.        ]
 [-0.00775358  0.99937522  0.        ]
 [-0.7116918   0.01870809  0.        ]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70244914 -0.02998528  0.        ]
 [-0.00775358  0.99937522  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70244914 -0.02998528  0.        ]
 [-0.00775358  0.99937522  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70244914 -0.02998528  0.        ]
 [-0.00775358  0.99937522  0.        ]
 [-0.7116918   0.01870809  0.        ]]
support
[0. 0. 0.]
[-7.32434420e-09  9.91621641e-09 -6.92983707e-09]
[-7.32434420e-09  9.91621641e-09 -6.92983707e-09]
[0. 0. 0.]
transform [[-0.70244914 -0.00775358 -0.7116918 ]
 [-0.02998528  0.99937522  0.01870809]
 [ 0.          0.          0.        ]]
zmp [19243956.09699368  -474156.41022251        0.        ]
d1:19974262.49731, d2:0.04071, d3:6110128.07939
transform [[-0.70242822 -0.03241163  0.        ]
 [-0.00945908  0.99929953  0.        ]
 [-0.7116918   0.01870809  0.        ]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70242822 -0.03241163  0.        ]
 [-0.00945908  0.99929953  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70242822 -0.03241163  0.        ]
 [-0.00945908  0.99929953  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70242822 -0.03241163  0.        ]
 [-0.00945908  0.99929953  0.        ]
 [-0.7116918   0.01870809  0.        ]]
support
[0. 0. 0.]
[-7.34839849e-09  9.89840451e-09 -6.92983707e-09]
[-7.34839849e-09  9.89840451e-09 -6.92983707e-09]
[0. 0. 0.]
transform [[-0.70242822 -0.00945908 -0.7116918 ]
 [-0.03241163  0.99929953  0.01870809]
 [ 0.          0.          0.        ]]
zmp [19243901.97406041  -474158.80901645        0.        ]
d1:19974206.20829, d2:0.04072, d3:6110109.73348
transform [[-0.70247376 -0.0117603   0.        ]
 [ 0.00505433  0.99975586  0.        ]
 [-0.7116918   0.01870809  0.        ]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70247376 -0.0117603   0.        ]
 [ 0.00505433  0.99975586  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70247376 -0.0117603   0.        ]
 [ 0.00505433  0.99975586  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70247376 -0.0117603   0.        ]
 [ 0.00505433  0.99975586  0.        ]
 [-0.7116918   0.01870809  0.        ]]
support
[0. 0. 0.]
[-7.14234055e-09  1.00481019e-08 -6.92983707e-09]
[-7.14234055e-09  1.00481019e-08 -6.92983707e-09]
[0. 0. 0.]
transform [[-0.70247376  0.00505433 -0.7116918 ]
 [-0.0117603   0.99975586  0.01870809]
 [ 0.          0.          0.        ]]
zmp [19244362.55035115  -474144.35714306        0.        ]
d1:19974685.03889, d2:0.04068, d3:6110263.99876
transform [[-0.70248568 -0.02317077  0.        ]
 [-0.00296405  0.99955648  0.        ]
 [-0.7116918   0.01870809  0.        ]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70248568 -0.02317077  0.        ]
 [-0.00296405  0.99955648  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70248568 -0.02317077  0.        ]
 [-0.00296405  0.99955648  0.        ]
 [-0.7116918   0.01870809  0.        ]]
transform [[-0.70248568 -0.02317077  0.        ]
 [-0.00296405  0.99955648  0.        ]
 [-0.7116918   0.01870809  0.        ]]
support
[0. 0. 0.]
[-7.25656448e-09  9.96592429e-09 -6.92983707e-09]
[-7.25656448e-09  9.96592429e-09 -6.92983707e-09]
[0. 0. 0.]
transform [[-0.70248568 -0.00296405 -0.7116918 ]
 [-0.02317077  0.99955648  0.01870809]
 [ 0.          0.          0.        ]]
zmp [19244108.0904749   -474150.66781908        0.        ]
d1:19974420.54404, d2:0.04070, d3:6110179.29086
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.20927376  0.95626587  0.        ]
 [-0.66540372  0.29239598  0.        ]
 [-0.71654892  0.00775938  0.        ]]
inertial
[0.        0.        1.2181312]
[464.07275 752.43115 426.1677 ]
[  69.31387036 -213.27976459  -22.53048205]
[ 0.   0.  -9.8]
transform [[ 0.20927376  0.95626587  0.        ]
 [-0.66540372  0.29239598  0.        ]
 [-0.71654892  0.00775938  0.        ]]
transform [[ 0.20927376  0.95626587  0.        ]
 [-0.66540372  0.29239598  0.        ]
 [-0.71654892  0.00775938  0.        ]]
transform [[ 0.20927376  0.95626587  0.        ]
 [-0.66540372  0.29239598  0.        ]
 [-0.71654892  0.00775938  0.        ]]
support
[0. 0. 0.]
[ 816.64247613  -88.78789498 -326.69242971]
[-189.44658498 -108.48385304  -51.32169809]
[0. 0. 0.]
transform [[ 0.20927376 -0.66540372 -0.71654892]
 [ 0.95626587  0.29239598  0.00775938]
 [ 0.          0.          0.        ]]
zmp [ 6653071.87497024 -1706809.85497214        0.        ]
d1:8108697.12909, d2:0.05876, d3:2662491.64207
transform [[ 0.2652539  -0.16425332  0.        ]
 [ 0.22287294  0.96914119  0.        ]
 [-0.93806618  0.18381062  0.        ]]
inertial
[0.        0.        1.2181312]
[464.07275 752.43115 426.1677 ]
[  69.31387036 -213.27976459  -22.53048205]
[ 0.   0.  -9.8]
transform [[ 0.2652539  -0.16425332  0.        ]
 [ 0.22287294  0.96914119  0.        ]
 [-0.93806618  0.18381062  0.        ]]
transform [[ 0.2652539  -0.16425332  0.        ]
 [ 0.22287294  0.96914119  0.        ]
 [-0.93806618  0.18381062  0.        ]]
transform [[ 0.2652539  -0.16425332  0.        ]
 [ 0.22287294  0.96914119  0.        ]
 [-0.93806618  0.18381062  0.        ]]
support
[0. 0. 0.]
[-4.92209512e-01  8.32641279e+02 -2.97026120e+02]
[  53.41768487 -191.25001759 -104.22408398]
[0. 0. 0.]
transform [[ 0.2652539   0.22287294 -0.93806618]
 [-0.16425332  0.96914119  0.18381062]
 [ 0.          0.          0.        ]]
zmp [3370663.18175669 2783323.23983021       0.        ]
d1:3706271.35656, d2:0.02571, d3:1637872.52937
transform [[-0.51965547 -0.74821645  0.        ]
 [ 0.26873589 -0.60141152  0.        ]
 [-0.81101131  0.28013647  0.        ]]
inertial
[0.        0.        1.2181312]
[ 56.158863 203.81093   61.909157]
[31.58462824 31.449005   19.38805382]
[ 0.   0.  -9.8]
transform [[-0.51965547 -0.74821645  0.        ]
 [ 0.26873589 -0.60141152  0.        ]
 [-0.81101131  0.28013647  0.        ]]
transform [[-0.51965547 -0.74821645  0.        ]
 [ 0.26873589 -0.60141152  0.        ]
 [-0.81101131  0.28013647  0.        ]]
transform [[-0.51965547 -0.74821645  0.        ]
 [ 0.26873589 -0.60141152  0.        ]
 [-0.81101131  0.28013647  0.        ]]
support
[0. 0. 0.]
[-181.67794948 -107.4823387    11.54939985]
[-39.94378759 -10.4258709  -16.80547774]
[0. 0. 0.]
transform [[-0.51965547  0.26873589 -0.81101131]
 [-0.74821645 -0.60141152  0.28013647]
 [ 0.          0.          0.        ]]
zmp [-5684640.89095608   984661.21625828        0.        ]
d1:3632355.26842, d2:0.05632, d3:2515322.35912
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.22388744  0.9482547   0.        ]
 [-0.68100119  0.31746173  0.        ]
 [-0.69721723 -0.00557855  0.        ]]
inertial
[0.        0.        1.2181312]
[ 142.84874     -6.4431596 1177.8481   ]
[  70.02680327 -660.38466917  -64.57325748]
[ 0.   0.  -9.8]
transform [[ 0.22388744  0.9482547   0.        ]
 [-0.68100119  0.31746173  0.        ]
 [-0.69721723 -0.00557855  0.        ]]
transform [[ 0.22388744  0.9482547   0.        ]
 [-0.68100119  0.31746173  0.        ]
 [-0.69721723 -0.00557855  0.        ]]
transform [[ 0.22388744  0.9482547   0.        ]
 [-0.68100119  0.31746173  0.        ]
 [-0.69721723 -0.00557855  0.        ]]
support
[0. 0. 0.]
[ 25.87228274 -99.32561774 -99.5606585 ]
[-610.53474734 -257.33519502  -45.13990521]
[0. 0. 0.]
transform [[ 0.22388744 -0.68100119 -0.69721723]
 [ 0.9482547   0.31746173 -0.00557855]
 [ 0.          0.          0.        ]]
zmp [4710492.56637804 1127864.918999         0.        ]
d1:6018720.20292, d2:0.05718, d3:1280148.89262
transform [[ 0.36340263 -0.22857478  0.        ]
 [ 0.2557523   0.95666671  0.        ]
 [-0.89583999  0.18039499  0.        ]]
inertial
[0.        0.        1.2181312]
[ 23.79672 493.3966  530.0274 ]
[  70.02680327 -660.38466917  -64.57325748]
[ 0.   0.  -9.8]
transform [[ 0.36340263 -0.22857478  0.        ]
 [ 0.2557523   0.95666671  0.        ]
 [-0.89583999  0.18039499  0.        ]]
transform [[ 0.36340263 -0.22857478  0.        ]
 [ 0.2557523   0.95666671  0.        ]
 [-0.89583999  0.18039499  0.        ]]
transform [[ 0.36340263 -0.22857478  0.        ]
 [ 0.2557523   0.95666671  0.        ]
 [-0.89583999  0.18039499  0.        ]]
support
[0. 0. 0.]
[-104.13023113  478.10217311   67.68822315]
[ 176.39520701 -613.8585118  -181.86289795]
[0. 0. 0.]
transform [[ 0.36340263  0.2557523  -0.89583999]
 [-0.22857478  0.95666671  0.18039499]
 [ 0.          0.          0.        ]]
zmp [ 6164317.00588202 16408155.31099465        0.        ]
d1:22560152.63384, d2:0.04474, d3:3772817.72253
transform [[ 0.2045781   0.94397026  0.        ]
 [ 0.56177956  0.10343309  0.        ]
 [-0.80159318  0.31340367  0.        ]]
inertial
[0.        0.        1.2181312]
[147.69582 413.11362 132.02348]
[-100.241081    146.43131703   51.1135621 ]
[ 0.   0.  -9.8]
transform [[ 0.2045781   0.94397026  0.        ]
 [ 0.56177956  0.10343309  0.        ]
 [-0.80159318  0.31340367  0.        ]]
transform [[ 0.2045781   0.94397026  0.        ]
 [ 0.56177956  0.10343309  0.        ]
 [-0.80159318  0.31340367  0.        ]]
transform [[ 0.2045781   0.94397026  0.        ]
 [ 0.56177956  0.10343309  0.        ]
 [-0.80159318  0.31340367  0.        ]]
support
[0. 0. 0.]
[420.1822993  125.7021103   11.07936252]
[117.71967879 -41.16754593 126.24467891]
[0. 0. 0.]
transform [[ 0.2045781   0.56177956 -0.80159318]
 [ 0.94397026  0.10343309  0.31340367]
 [ 0.          0.          0.        ]]
zmp [11344302.02175694  1220563.50631395        0.        ]
d1:13130492.17796, d2:0.05703, d3:3984517.21469
transform [[ 0.34879866 -0.89184594  0.        ]
 [ 0.83252901  0.43597674  0.        ]
 [-0.43038937  0.12056198  0.        ]]
inertial
[0.        0.        1.2181312]
[ 94.64282 185.73892 379.6705 ]
[-161.20940294  232.9821132   106.58681599]
[ 0.   0.  -9.8]
transform [[ 0.34879866 -0.89184594  0.        ]
 [ 0.83252901  0.43597674  0.        ]
 [-0.43038937  0.12056198  0.        ]]
transform [[ 0.34879866 -0.89184594  0.        ]
 [ 0.83252901  0.43597674  0.        ]
 [-0.43038937  0.12056198  0.        ]]
transform [[ 0.34879866 -0.89184594  0.        ]
 [ 0.83252901  0.43597674  0.        ]
 [-0.43038937  0.12056198  0.        ]]
support
[0. 0. 0.]
[-132.63921406  159.77074542  -18.34021292]
[-264.01377623  -32.63672132   97.4715989 ]
[0. 0. 0.]
transform [[ 0.34879866  0.83252901 -0.43038937]
 [-0.89184594  0.43597674  0.12056198]
 [ 0.          0.          0.        ]]
zmp [4495721.61906886 2526936.47470116       0.        ]
d1:5336935.95649, d2:0.05385, d3:2033142.40817
transform [[ 0.42119312  0.90679967  0.        ]
 [ 0.47334886 -0.2363577   0.        ]
 [-0.7736519   0.3490693   0.        ]]
inertial
[0.        0.        1.2181312]
[ 37.866905 182.61298  348.80368 ]
[ 82.71005691 -12.6008334   64.4621025 ]
[ 0.   0.  -9.8]
transform [[ 0.42119312  0.90679967  0.        ]
 [ 0.47334886 -0.2363577   0.        ]
 [-0.7736519   0.3490693   0.        ]]
transform [[ 0.42119312  0.90679967  0.        ]
 [ 0.47334886 -0.2363577   0.        ]
 [-0.7736519   0.3490693   0.        ]]
transform [[ 0.42119312  0.90679967  0.        ]
 [ 0.47334886 -0.2363577   0.        ]
 [-0.7736519   0.3490693   0.        ]]
support
[0. 0. 0.]
[181.54266724 -25.23772745  34.44878015]
[ 23.41047554  42.12901487 -68.38735657]
[0. 0. 0.]
transform [[ 0.42119312  0.47334886 -0.7736519 ]
 [ 0.90679967 -0.2363577   0.3490693 ]
 [ 0.          0.          0.        ]]
zmp [1111974.41519399 -780726.83106229       0.        ]
d1:753443.63655, d2:0.05741, d3:201604.32007
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-21.38756587048682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-119.35283507812365 steps:1[00m
[RDDPG] Resetting Environment
transform [[-0.3083185  -0.87833804  0.        ]
 [-0.62762517  0.47640982  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
inertial
[0.        0.        1.2181312]
[ 37.866905 182.61298  348.80368 ]
[ 82.71005691 -12.6008334   64.4621025 ]
[ 0.   0.  -9.8]
transform [[-0.3083185  -0.87833804  0.        ]
 [-0.62762517  0.47640982  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
transform [[-0.3083185  -0.87833804  0.        ]
 [-0.62762517  0.47640982  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
transform [[-0.3083185  -0.87833804  0.        ]
 [-0.62762517  0.47640982  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
support
[0. 0. 0.]
[-172.07099054   63.23239283  -34.27305893]
[-14.43324903 -57.91407412 -58.62914548]
[0. 0. 0.]
transform [[-0.3083185  -0.62762517 -0.71486115]
 [-0.87833804  0.47640982 -0.0394467 ]
 [ 0.          0.          0.        ]]
zmp [5512655.96657134  874739.31036354       0.        ]
d1:6343628.29504, d2:0.05643, d3:2113978.45966
transform [[-0.69852924  0.0861173   0.        ]
 [ 0.03210088  0.99550384  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
inertial
[0.        0.        1.2181312]
[ 37.866905 182.61298  348.80368 ]
[ 82.71005691 -12.6008334   64.4621025 ]
[ 0.   0.  -9.8]
transform [[-0.69852924  0.0861173   0.        ]
 [ 0.03210088  0.99550384  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
transform [[-0.69852924  0.0861173   0.        ]
 [ 0.03210088  0.99550384  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
transform [[-0.69852924  0.0861173   0.        ]
 [ 0.03210088  0.99550384  0.        ]
 [-0.71486115 -0.0394467   0.        ]]
support
[0. 0. 0.]
[-10.72500332 183.00748036 -34.27305893]
[-58.86054329  -9.88911258 -58.62914548]
[0. 0. 0.]
transform [[-0.69852924  0.03210088 -0.71486115]
 [ 0.0861173   0.99550384 -0.0394467 ]
 [ 0.          0.          0.        ]]
zmp [6249196.40689085 1454268.73994852       0.        ]
d1:7647397.01660, d2:0.05024, d3:2548062.49203
transform [[-0.05634353  0.97134662  0.        ]
 [-0.12868606  0.22226533  0.        ]
 [-0.99008352 -0.08416618  0.        ]]
inertial
[0.        0.        1.2181312]
[ 37.866905 182.61298  348.80368 ]
[ 82.71005691 -12.6008334   64.4621025 ]
[ 0.   0.  -9.8]
transform [[-0.05634353  0.97134662  0.        ]
 [-0.12868606  0.22226533  0.        ]
 [-0.99008352 -0.08416618  0.        ]]
transform [[-0.05634353  0.97134662  0.        ]
 [-0.12868606  0.22226533  0.        ]
 [-0.99008352 -0.08416618  0.        ]]
transform [[-0.05634353  0.97134662  0.        ]
 [-0.12868606  0.22226533  0.        ]
 [-0.99008352 -0.08416618  0.        ]]
support
[0. 0. 0.]
[175.24694126  35.71559126 -52.861236  ]
[-16.89995373 -13.44435941 -80.82929986]
[0. 0. 0.]
transform [[-0.05634353 -0.12868606 -0.99008352]
 [ 0.97134662  0.22226533 -0.08416618]
 [ 0.          0.          0.        ]]
zmp [11217922.26350912 -5513209.68655868        0.        ]
d1:8732085.24233, d2:0.05778, d3:5394030.77130
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-571.6455509250911 steps:5[00m
[RDDPG] Resetting Environment
transform [[ 5.86948451e-03  9.61798489e-01  0.00000000e+00]
 [-2.39309873e-02  2.73756951e-01  0.00000000e+00]
 [-9.99696374e-01 -9.06288100e-04  0.00000000e+00]]
inertial
[0.        0.        1.2181312]
[-1453.7955   -380.53873  1218.351  ]
[-135.25774152 -446.79875116   -2.0615607 ]
[ 0.   0.  -9.8]
transform [[ 5.86948451e-03  9.61798489e-01  0.00000000e+00]
 [-2.39309873e-02  2.73756951e-01  0.00000000e+00]
 [-9.99696374e-01 -9.06288100e-04  0.00000000e+00]]
transform [[ 5.86948451e-03  9.61798489e-01  0.00000000e+00]
 [-2.39309873e-02  2.73756951e-01  0.00000000e+00]
 [-9.99696374e-01 -9.06288100e-04  0.00000000e+00]]
transform [[ 5.86948451e-03  9.61798489e-01  0.00000000e+00]
 [-2.39309873e-02  2.73756951e-01  0.00000000e+00]
 [-9.99696374e-01 -9.06288100e-04  0.00000000e+00]]
support
[0. 0. 0.]
[-374.53460284  -69.38435914 1453.69899974]
[-430.52425701 -119.07741257  135.62160214]
[0. 0. 0.]
transform [[ 5.86948451e-03 -2.39309873e-02 -9.99696374e-01]
 [ 9.61798489e-01  2.73756951e-01 -9.06288100e-04]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]
zmp [1557302.33914251 6528813.35095704       0.        ]
d1:10633312.24622, d2:0.05926, d3:778028.53075
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-525.4940732911239 steps:7[00m
[RDDPG] Resetting Environment
transform [[-0.23803136  0.94835657  0.        ]
 [ 0.66356391  0.31642604  0.        ]
 [-0.70924187 -0.02223458  0.        ]]
inertial
[0.        0.        1.2181312]
[-1453.7955   -380.53873  1218.351  ]
[-135.25774152 -446.79875116   -2.0615607 ]
[ 0.   0.  -9.8]
transform [[-0.23803136  0.94835657  0.        ]
 [ 0.66356391  0.31642604  0.        ]
 [-0.70924187 -0.02223458  0.        ]]
transform [[-0.23803136  0.94835657  0.        ]
 [ 0.66356391  0.31642604  0.        ]
 [-0.70924187 -0.02223458  0.        ]]
transform [[-0.23803136  0.94835657  0.        ]
 [ 0.66356391  0.31642604  0.        ]
 [-0.70924187 -0.02223458  0.        ]]
support
[0. 0. 0.]
[  -14.83747715 -1085.09860547  1039.55377691]
[-391.52894677 -231.13091438  105.86483634]
[0. 0. 0.]
transform [[-0.23803136  0.66356391 -0.70924187]
 [ 0.94835657  0.31642604 -0.02223458]
 [ 0.          0.          0.        ]]
zmp [-6462265.69513918 -2154212.23994209        0.        ]
d1:8785591.22308, d2:0.05894, d3:2878862.19343
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-194.49403641600657 steps:9[00m
[RDDPG] Resetting Environment
transform [[ 0.4731676  -0.73801082  0.        ]
 [ 0.51483834  0.67478418  0.        ]
 [-0.71488035 -0.00251518  0.        ]]
inertial
[0.        0.        1.2181312]
[-140.54373  213.75313 -252.11673]
[-125.87838543 -170.09623674   64.60225048]
[ 0.   0.  -9.8]
transform [[ 0.4731676  -0.73801082  0.        ]
 [ 0.51483834  0.67478418  0.        ]
 [-0.71488035 -0.00251518  0.        ]]
transform [[ 0.4731676  -0.73801082  0.        ]
 [ 0.51483834  0.67478418  0.        ]
 [-0.71488035 -0.00251518  0.        ]]
transform [[ 0.4731676  -0.73801082  0.        ]
 [ 0.51483834  0.67478418  0.        ]
 [-0.71488035 -0.00251518  0.        ]]
support
[0. 0. 0.]
[-224.25286208   71.87992876   99.93432312]
[  65.97129049 -179.58526896   90.41580734]
[0. 0. 0.]
transform [[ 0.4731676   0.51483834 -0.71488035]
 [-0.73801082  0.67478418 -0.00251518]
 [ 0.          0.          0.        ]]
zmp [9689500.4157966  3618119.21769803       0.        ]
d1:13530403.76284, d2:0.04678, d3:1984871.75146
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-109.56434456668768 steps:11[00m
[RDDPG] Resetting Environment
transform [[ 0.70531309 -0.04845877  0.        ]
 [ 0.06341914  0.9979738   0.        ]
 [-0.7060535   0.04123205  0.        ]]
inertial
[0.        0.        1.2181312]
[ 389.7712  -138.20506  309.46823]
[  38.42006845 -246.39011029   -7.50959099]
[ 0.   0.  -9.8]
transform [[ 0.70531309 -0.04845877  0.        ]
 [ 0.06341914  0.9979738   0.        ]
 [-0.7060535   0.04123205  0.        ]]
transform [[ 0.70531309 -0.04845877  0.        ]
 [ 0.06341914  0.9979738   0.        ]
 [-0.7060535   0.04123205  0.        ]]
transform [[ 0.70531309 -0.04845877  0.        ]
 [ 0.06341914  0.9979738   0.        ]
 [-0.7060535   0.04123205  0.        ]]
support
[0. 0. 0.]
[ 281.6079823  -113.20607647 -280.8978025 ]
[  39.03793873 -243.45430684  -37.28579192]
[0. 0. 0.]
transform [[ 0.70531309  0.06341914 -0.7060535 ]
 [-0.04845877  0.9979738   0.04123205]
 [ 0.          0.          0.        ]]
zmp [ -4148189.45897488 -21892329.4309617          0.        ]
d1:25417969.06106, d2:0.03360, d3:6027360.01922
transform [[ 0.69055384  0.26130027  0.        ]
 [-0.15691993  0.96437657  0.        ]
 [-0.7060535   0.04123205  0.        ]]
inertial
[0.        0.        1.2181312]
[ 389.7712  -138.20506  309.46823]
[  38.42006845 -246.39011029   -7.50959099]
[ 0.   0.  -9.8]
transform [[ 0.69055384  0.26130027  0.        ]
 [-0.15691993  0.96437657  0.        ]
 [-0.7060535   0.04123205  0.        ]]
transform [[ 0.69055384  0.26130027  0.        ]
 [-0.15691993  0.96437657  0.        ]
 [-0.7060535   0.04123205  0.        ]]
transform [[ 0.69055384  0.26130027  0.        ]
 [-0.15691993  0.96437657  0.        ]
 [-0.7060535   0.04123205  0.        ]]
support
[0. 0. 0.]
[ 233.04498748 -194.44459386 -280.8978025 ]
[ -37.85067535 -243.64172346  -37.28579192]
[0. 0. 0.]
transform [[ 0.69055384 -0.15691993 -0.7060535 ]
 [ 0.26130027  0.96437657  0.04123205]
 [ 0.          0.          0.        ]]
zmp [   720755.37790342 -21149914.27022959         0.        ]
d1:21727461.64372, d2:0.04425, d3:7258419.19161
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-327.6641468451838 steps:14[00m
[RDDPG] Resetting Environment
transform [[-0.71752101 -0.14689428  0.        ]
 [-0.13386652  0.98836851  0.        ]
 [-0.68355203 -0.03936748  0.        ]]
inertial
[0.        0.        1.2181312]
[ 389.7712  -138.20506  309.46823]
[  38.42006845 -246.39011029   -7.50959099]
[ 0.   0.  -9.8]
transform [[-0.71752101 -0.14689428  0.        ]
 [-0.13386652  0.98836851  0.        ]
 [-0.68355203 -0.03936748  0.        ]]
transform [[-0.71752101 -0.14689428  0.        ]
 [-0.13386652  0.98836851  0.        ]
 [-0.68355203 -0.03936748  0.        ]]
transform [[-0.71752101 -0.14689428  0.        ]
 [-0.13386652  0.98836851  0.        ]
 [-0.68355203 -0.03936748  0.        ]]
support
[0. 0. 0.]
[-259.36750011 -188.77484717 -260.98811555]
[   8.62609051 -248.6673873   -16.56235833]
[0. 0. 0.]
transform [[-0.71752101 -0.13386652 -0.68355203]
 [-0.14689428  0.98836851 -0.03936748]
 [ 0.          0.          0.        ]]
zmp [7865096.52188911 7252080.50694728       0.        ]
d1:14535358.08510, d2:0.05939, d3:5057169.83862
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-500.62521445519064 steps:16[00m
[RDDPG] Resetting Environment
transform [[ 0.03050741 -0.97056186  0.        ]
 [-0.09102236  0.23533262  0.        ]
 [-0.99538147 -0.05126663  0.        ]]
inertial
[0.        0.        1.2181312]
[ 447.3775   -268.80997  -111.905685]
[  38.42006845 -246.39011029   -7.50959099]
[ 0.   0.  -9.8]
transform [[ 0.03050741 -0.97056186  0.        ]
 [-0.09102236  0.23533262  0.        ]
 [-0.99538147 -0.05126663  0.        ]]
transform [[ 0.03050741 -0.97056186  0.        ]
 [-0.09102236  0.23533262  0.        ]
 [-0.99538147 -0.05126663  0.        ]]
transform [[ 0.03050741 -0.97056186  0.        ]
 [-0.09102236  0.23533262  0.        ]
 [-0.99538147 -0.05126663  0.        ]]
support
[0. 0. 0.]
[ 274.545031   -103.98111289 -431.53029712]
[240.308941   -61.48071645 -25.61103395]
[0. 0. 0.]
transform [[ 0.03050741 -0.09102236 -0.99538147]
 [-0.97056186  0.23533262 -0.05126663]
 [ 0.          0.          0.        ]]
zmp [10518292.11328334 -2673596.13450992        0.        ]
d1:8322420.91130, d2:0.05789, d3:5066495.59677
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-393.9811814511834 steps:18[00m
[RDDPG] Resetting Environment
transform [[ 0.31449139  0.90335065  0.        ]
 [-0.63410354  0.42854613  0.        ]
 [-0.70640492  0.01748763  0.        ]]
inertial
[0.        0.        1.2181312]
[554.4602  -99.63969 702.64246]
[  26.29905636 -461.06286848    9.26545956]
[ 0.   0.  -9.8]
transform [[ 0.31449139  0.90335065  0.        ]
 [-0.63410354  0.42854613  0.        ]
 [-0.70640492  0.01748763  0.        ]]
transform [[ 0.31449139  0.90335065  0.        ]
 [-0.63410354  0.42854613  0.        ]
 [-0.70640492  0.01748763  0.        ]]
transform [[ 0.31449139  0.90335065  0.        ]
 [-0.63410354  0.42854613  0.        ]
 [-0.70640492  0.01748763  0.        ]]
support
[0. 0. 0.]
[  84.36338548 -394.28537909 -393.41588162]
[-408.2306157  -214.26303292  -26.6406816 ]
[0. 0. 0.]
transform [[ 0.31449139 -0.63410354 -0.70640492]
 [ 0.90335065  0.42854613  0.01748763]
 [ 0.          0.          0.        ]]
zmp [ 3294614.71469358 -4847476.23260601        0.        ]
d1:7983332.88086, d2:0.05912, d3:2608207.37835
transform [[ 0.31938219 -0.41197193  0.        ]
 [ 0.44401559  0.86063963  0.        ]
 [-0.837165    0.29929695  0.        ]]
inertial
[0.        0.        1.2181312]
[554.4602  -99.63969 702.64246]
[  26.29905636 -461.06286848    9.26545956]
[ 0.   0.  -9.8]
transform [[ 0.31938219 -0.41197193  0.        ]
 [ 0.44401559  0.86063963  0.        ]
 [-0.837165    0.29929695  0.        ]]
transform [[ 0.31938219 -0.41197193  0.        ]
 [ 0.44401559  0.86063963  0.        ]
 [-0.837165    0.29929695  0.        ]]
transform [[ 0.31938219 -0.41197193  0.        ]
 [ 0.44401559  0.86063963  0.        ]
 [-0.837165    0.29929695  0.        ]]
support
[0. 0. 0.]
[ 218.13346861  160.43511322 -493.99653033]
[ 198.34440849 -385.13178626 -160.01135761]
[0. 0. 0.]
transform [[ 0.31938219  0.44401559 -0.837165  ]
 [-0.41197193  0.86063963  0.29929695]
 [ 0.          0.          0.        ]]
zmp [6226345.14735365 6192044.20547224       0.        ]
d1:8278313.82099, d2:0.03310, d3:2927951.46176
transform [[ 0.22750431 -0.75018978  0.        ]
 [-0.09328964  0.61784738  0.        ]
 [-0.96929938 -0.23553763  0.        ]]
inertial
[0.        0.        1.2181312]
[-141.2813  -826.79645  309.49573]
[ 49.90306306 -23.63287364 -39.0438275 ]
[ 0.   0.  -9.8]
transform [[ 0.22750431 -0.75018978  0.        ]
 [-0.09328964  0.61784738  0.        ]
 [-0.96929938 -0.23553763  0.        ]]
transform [[ 0.22750431 -0.75018978  0.        ]
 [-0.09328964  0.61784738  0.        ]
 [-0.96929938 -0.23553763  0.        ]]
transform [[ 0.22750431 -0.75018978  0.        ]
 [-0.09328964  0.61784738  0.        ]
 [-0.96929938 -0.23553763  0.        ]]
support
[0. 0. 0.]
[ 588.11214209 -497.65393982  331.68555036]
[ 29.08230238 -19.2569481  -42.80457676]
[0. 0. 0.]
transform [[ 0.22750431 -0.09328964 -0.96929938]
 [-0.75018978  0.61784738 -0.23553763]
 [ 0.          0.          0.        ]]
zmp [ 1050457.27113361 -9286416.44463342        0.        ]
d1:13680478.75660, d2:0.05867, d3:2909548.07235
transform [[ 0.23474237 -0.80102181  0.        ]
 [-0.07317656  0.5503509   0.        ]
 [-0.96929938 -0.23553763  0.        ]]
inertial
[0.        0.        1.2181312]
[-141.2813  -826.79645  309.49573]
[ 49.90306306 -23.63287364 -39.0438275 ]
[ 0.   0.  -9.8]
transform [[ 0.23474237 -0.80102181  0.        ]
 [-0.07317656  0.5503509   0.        ]
 [-0.96929938 -0.23553763  0.        ]]
transform [[ 0.23474237 -0.80102181  0.        ]
 [-0.07317656  0.5503509   0.        ]
 [-0.96929938 -0.23553763  0.        ]]
transform [[ 0.23474237 -0.80102181  0.        ]
 [-0.07317656  0.5503509   0.        ]
 [-0.96929938 -0.23553763  0.        ]]
support
[0. 0. 0.]
[ 629.11728401 -444.68969427  331.68555036]
[ 30.64481078 -16.65810764 -42.80457676]
[0. 0. 0.]
transform [[ 0.23474237 -0.07317656 -0.96929938]
 [-0.80102181  0.5503509  -0.23553763]
 [ 0.          0.          0.        ]]
zmp [  750835.72973891 -8280931.94201079        0.        ]
d1:12409103.14637, d2:0.05839, d3:2639508.82563
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1099.9937830213892 steps:23[00m
[RDDPG] Resetting Environment
transform [[ 0.64366972  0.2947329   0.        ]
 [-0.19753425  0.95557886  0.        ]
 [-0.73937112  0.00128635  0.        ]]
inertial
[0.        0.        1.2181312]
[-401.06104  466.1106  -176.12744]
[ -20.12915092 -173.30428881   11.03520525]
[ 0.   0.  -9.8]
transform [[ 0.64366972  0.2947329   0.        ]
 [-0.19753425  0.95557886  0.        ]
 [-0.73937112  0.00128635  0.        ]]
transform [[ 0.64366972  0.2947329   0.        ]
 [-0.19753425  0.95557886  0.        ]
 [-0.73937112  0.00128635  0.        ]]
transform [[ 0.64366972  0.2947329   0.        ]
 [-0.19753425  0.95557886  0.        ]
 [-0.73937112  0.00128635  0.        ]]
support
[0. 0. 0.]
[-120.77271911  524.62872344  297.13252831]
[ -64.03500039 -161.62971867   14.65998298]
[0. 0. 0.]
transform [[ 0.64366972 -0.19753425 -0.73937112]
 [ 0.2947329   0.95557886  0.00128635]
 [ 0.          0.          0.        ]]
zmp [ 4710767.29084824 23255993.97928614        0.        ]
d1:27363841.82889, d2:0.03782, d3:6982517.14427
transform [[ 0.66878784  0.11695801  0.        ]
 [-0.07780304  0.99313605  0.        ]
 [-0.73937112  0.00128635  0.        ]]
inertial
[0.        0.        1.2181312]
[-401.06104  466.1106  -176.12744]
[ -20.12915092 -173.30428881   11.03520525]
[ 0.   0.  -9.8]
transform [[ 0.66878784  0.11695801  0.        ]
 [-0.07780304  0.99313605  0.        ]
 [-0.73937112  0.00128635  0.        ]]
transform [[ 0.66878784  0.11695801  0.        ]
 [-0.07780304  0.99313605  0.        ]
 [-0.73937112  0.00128635  0.        ]]
transform [[ 0.66878784  0.11695801  0.        ]
 [-0.07780304  0.99313605  0.        ]
 [-0.73937112  0.00128635  0.        ]]
support
[0. 0. 0.]
[-213.70937233  494.11500208  297.13252831]
[ -33.73145686 -170.54862745   14.65998298]
[0. 0. 0.]
transform [[ 0.66878784 -0.07780304 -0.73937112]
 [ 0.11695801  0.99313605  0.00128635]
 [ 0.          0.          0.        ]]
zmp [ 7626750.69126827 24170677.00526217        0.        ]
d1:31049453.31677, d2:0.03044, d3:6499455.11144
transform [[ 0.14083943  0.34657359  0.        ]
 [-0.43502751  0.86311388  0.        ]
 [-0.88933426 -0.3673164   0.        ]]
inertial
[0.        0.        1.2181312]
[-401.06104  466.1106  -176.12744]
[ -20.12915092 -173.30428881   11.03520525]
[ 0.   0.  -9.8]
transform [[ 0.14083943  0.34657359  0.        ]
 [-0.43502751  0.86311388  0.        ]
 [-0.88933426 -0.3673164   0.        ]]
transform [[ 0.14083943  0.34657359  0.        ]
 [-0.43502751  0.86311388  0.        ]
 [-0.88933426 -0.3673164   0.        ]]
transform [[ 0.14083943  0.34657359  0.        ]
 [-0.43502751  0.86311388  0.        ]
 [-0.88933426 -0.3673164   0.        ]]
support
[0. 0. 0.]
[105.0564164  576.77910829 185.46725578]
[ -62.89766784 -140.82460276   81.55905018]
[0. 0. 0.]
transform [[ 0.14083943 -0.43502751 -0.88933426]
 [ 0.34657359  0.86311388 -0.3673164 ]
 [ 0.          0.          0.        ]]
zmp [ -9290094.6608533  -24569740.92520992         0.        ]
d1:39212499.07071, d2:0.05275, d3:4828841.72945
transform [[ 0.20632949  0.89166552  0.        ]
 [ 0.28119576  0.34039614  0.        ]
 [-0.9372071   0.29843435  0.        ]]
inertial
[0.        0.        1.2181312]
[-513.74554 -568.39545 -222.67746]
[-224.47771064  502.8069045    31.81718511]
[ 0.   0.  -9.8]
transform [[ 0.20632949  0.89166552  0.        ]
 [ 0.28119576  0.34039614  0.        ]
 [-0.9372071   0.29843435  0.        ]]
transform [[ 0.20632949  0.89166552  0.        ]
 [ 0.28119576  0.34039614  0.        ]
 [-0.9372071   0.29843435  0.        ]]
transform [[ 0.20632949  0.89166552  0.        ]
 [ 0.28119576  0.34039614  0.        ]
 [-0.9372071   0.29843435  0.        ]]
support
[0. 0. 0.]
[-612.81947924 -337.94268253  311.85724931]
[402.01920648 108.03134707 360.43695499]
[0. 0. 0.]
transform [[ 0.20632949  0.28119576 -0.9372071 ]
 [ 0.89166552  0.34039614  0.29843435]
 [ 0.          0.          0.        ]]
zmp [ -721080.5348112  15876838.98584662        0.        ]
d1:26463012.43044, d2:0.05834, d3:4400611.98389
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-63.1086145928472 steps:28[00m
[RDDPG] Resetting Environment
transform [[-0.06637555 -0.98797971  0.        ]
 [ 0.04571933  0.1367581   0.        ]
 [-0.99674672  0.07206463  0.        ]]
inertial
[0.        0.        1.2181312]
[-513.74554 -568.39545 -222.67746]
[-224.47771064  502.8069045    31.81718511]
[ 0.   0.  -9.8]
transform [[-0.06637555 -0.98797971  0.        ]
 [ 0.04571933  0.1367581   0.        ]
 [-0.99674672  0.07206463  0.        ]]
transform [[-0.06637555 -0.98797971  0.        ]
 [ 0.04571933  0.1367581   0.        ]
 [-0.99674672  0.07206463  0.        ]]
transform [[-0.06637555 -0.98797971  0.        ]
 [ 0.04571933  0.1367581   0.        ]
 [-0.99674672  0.07206463  0.        ]]
support
[0. 0. 0.]
[ 595.66330983 -101.22078722  471.1129778 ]
[-481.8631891    58.49994772  259.98201542]
[0. 0. 0.]
transform [[-0.06637555  0.04571933 -0.99674672]
 [-0.98797971  0.1367581   0.07206463]
 [ 0.          0.          0.        ]]
zmp [ 8072524.65724775 -1441116.33068754        0.        ]
d1:6046223.47861, d2:0.05874, d3:3881128.89446
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-371.7534044431933 steps:30[00m
[RDDPG] Resetting Environment
transform [[ 0.64017147 -0.01997292  0.        ]
 [-0.01702067  0.99904794  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[ 0.64017147 -0.01997292  0.        ]
 [-0.01702067  0.99904794  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
transform [[ 0.64017147 -0.01997292  0.        ]
 [-0.01702067  0.99904794  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
transform [[ 0.64017147 -0.01997292  0.        ]
 [-0.01702067  0.99904794  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
support
[0. 0. 0.]
[-114.77476468  441.95998589  110.11820241]
[  -9.03418635 -194.19605451   23.05773878]
[0. 0. 0.]
transform [[ 0.64017147 -0.01702067 -0.76804352]
 [-0.01997292  0.99904794 -0.0387876 ]
 [ 0.          0.          0.        ]]
zmp [ -8706017.04004957 -17625885.80856855         0.        ]
d1:22413468.92339, d2:0.02409, d3:4956150.87061
transform [[ 0.63501012  0.08307664  0.        ]
 [-0.08289421  0.99578804  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[ 0.63501012  0.08307664  0.        ]
 [-0.08289421  0.99578804  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
transform [[ 0.63501012  0.08307664  0.        ]
 [-0.08289421  0.99578804  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
transform [[ 0.63501012  0.08307664  0.        ]
 [-0.08289421  0.99578804  0.        ]
 [-0.76804352 -0.0387876   0.        ]]
support
[0. 0. 0.]
[-68.62368527 451.4339791  110.11820241]
[ -28.99632333 -192.23145373   23.05773878]
[0. 0. 0.]
transform [[ 0.63501012 -0.08289421 -0.76804352]
 [ 0.08307664  0.99578804 -0.0387876 ]
 [ 0.          0.          0.        ]]
zmp [ -7573796.40233242 -17569855.23650666         0.        ]
d1:21381242.42056, d2:0.02741, d3:5196644.81767
transform [[ 0.06201376 -0.10394195  0.        ]
 [ 0.29380417  0.9523958   0.        ]
 [-0.95385188  0.28659797  0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[ 0.06201376 -0.10394195  0.        ]
 [ 0.29380417  0.9523958   0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06201376 -0.10394195  0.        ]
 [ 0.29380417  0.9523958   0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06201376 -0.10394195  0.        ]
 [ 0.29380417  0.9523958   0.        ]
 [-0.95385188  0.28659797  0.        ]]
support
[0. 0. 0.]
[-55.95659205 369.98918631 283.90972841]
[  18.98820252 -191.38646833  -36.55198826]
[0. 0. 0.]
transform [[ 0.06201376  0.29380417 -0.95385188]
 [-0.10394195  0.9523958   0.28659797]
 [ 0.          0.          0.        ]]
zmp [ 10302856.14116116 -20625959.14703965         0.        ]
d1:21167897.13802, d2:0.05474, d3:9892586.92676
transform [[ 0.06499    -0.09427849  0.        ]
 [ 0.2931602   0.95340091  0.        ]
 [-0.95385188  0.28659797  0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[ 0.06499    -0.09427849  0.        ]
 [ 0.2931602   0.95340091  0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06499    -0.09427849  0.        ]
 [ 0.2931602   0.95340091  0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06499    -0.09427849  0.        ]
 [ 0.2931602   0.95340091  0.        ]
 [-0.95385188  0.28659797  0.        ]]
support
[0. 0. 0.]
[-52.20170717 370.5376183  283.90972841]
[  17.04640314 -191.56918896  -36.55198826]
[0. 0. 0.]
transform [[ 0.06499     0.2931602  -0.95385188]
 [-0.09427849  0.95340091  0.28659797]
 [ 0.          0.          0.        ]]
zmp [ 10313703.65261801 -20642890.42645853         0.        ]
d1:21182793.84493, d2:0.05480, d3:9901995.64276
transform [[ 0.06514324 -0.09378007  0.        ]
 [ 0.29312617  0.95345002  0.        ]
 [-0.95385188  0.28659797  0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[ 0.06514324 -0.09378007  0.        ]
 [ 0.29312617  0.95345002  0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06514324 -0.09378007  0.        ]
 [ 0.29312617  0.95345002  0.        ]
 [-0.95385188  0.28659797  0.        ]]
transform [[ 0.06514324 -0.09378007  0.        ]
 [ 0.29312617  0.95345002  0.        ]
 [-0.95385188  0.28659797  0.        ]]
support
[0. 0. 0.]
[-52.00799394 370.56484214 283.90972841]
[  16.9462544  -191.57806567  -36.55198826]
[0. 0. 0.]
transform [[ 0.06514324  0.29312617 -0.95385188]
 [-0.09378007  0.95345002  0.28659797]
 [ 0.          0.          0.        ]]
zmp [ 10314276.95157626 -20643717.76271785         0.        ]
d1:21183476.90889, d2:0.05480, d3:9902478.69865
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-348.7796378466317 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-169.12963976561966 steps:37[00m
[RDDPG] Resetting Environment
transform [[-0.20980138 -0.9415772   0.        ]
 [-0.57253283  0.33674407  0.        ]
 [-0.79258418  0.00598949  0.        ]]
inertial
[0.        0.        1.2181312]
[-165.57355  439.5603  -182.31087]
[ -20.18742675 -194.725049     11.8062927 ]
[ 0.   0.  -9.8]
transform [[-0.20980138 -0.9415772   0.        ]
 [-0.57253283  0.33674407  0.        ]
 [-0.79258418  0.00598949  0.        ]]
transform [[-0.20980138 -0.9415772   0.        ]
 [-0.57253283  0.33674407  0.        ]
 [-0.79258418  0.00598949  0.        ]]
transform [[-0.20980138 -0.9415772   0.        ]
 [-0.57253283  0.33674407  0.        ]
 [-0.79258418  0.00598949  0.        ]]
support
[0. 0. 0.]
[-379.14239933  242.81561746  133.86371484]
[187.58401556 -54.01454092  14.83393207]
[0. 0. 0.]
transform [[-0.20980138 -0.57253283 -0.79258418]
 [-0.9415772   0.33674407  0.00598949]
 [ 0.          0.          0.        ]]
zmp [3827204.5593971 1149630.321193        0.       ]
d1:4392200.92325, d2:0.05830, d3:1610307.61789
transform [[-0.29566193 -0.83744752  0.        ]
 [-0.01684498  0.48564285  0.        ]
 [-0.95514411  0.25066447  0.        ]]
inertial
[0.        0.        1.2181312]
[  408.9477 -1464.3971  1414.4542]
[ 378.38959611 -493.85488181 -338.7055516 ]
[ 0.   0.  -9.8]
transform [[-0.29566193 -0.83744752  0.        ]
 [-0.01684498  0.48564285  0.        ]
 [-0.95514411  0.25066447  0.        ]]
transform [[-0.29566193 -0.83744752  0.        ]
 [-0.01684498  0.48564285  0.        ]
 [-0.95514411  0.25066447  0.        ]]
transform [[-0.29566193 -0.83744752  0.        ]
 [-0.01684498  0.48564285  0.        ]
 [-0.95514411  0.25066447  0.        ]]
support
[0. 0. 0.]
[1105.44545862 -718.06269508 -757.67630445]
[ 301.70215116 -246.21105782 -485.20846648]
[0. 0. 0.]
transform [[-0.29566193 -0.01684498 -0.95514411]
 [-0.83744752  0.48564285  0.25066447]
 [ 0.          0.          0.        ]]
zmp [12535353.6597337   9284289.65143934        0.        ]
d1:11630060.42085, d2:0.05828, d3:5750086.80667
transform [[-0.17066391 -0.96159238  0.        ]
 [-0.53571892  0.2736645   0.        ]
 [-0.82696986  0.0211639   0.        ]]
inertial
[0.        0.        1.2181312]
[1575.9935 1267.0334 1426.8531]
[ -283.67360757 -1214.30987242   695.2890158 ]
[ 0.   0.  -9.8]
transform [[-0.17066391 -0.96159238  0.        ]
 [-0.53571892  0.2736645   0.        ]
 [-0.82696986  0.0211639   0.        ]]
transform [[-0.17066391 -0.96159238  0.        ]
 [-0.53571892  0.2736645   0.        ]
 [-0.82696986  0.0211639   0.        ]]
transform [[-0.17066391 -0.96159238  0.        ]
 [-0.53571892  0.2736645   0.        ]
 [-0.82696986  0.0211639   0.        ]]
support
[0. 0. 0.]
[-1487.33491838  -497.54746831 -1276.48378846]
[1216.0839622  -180.34419122  208.88999658]
[0. 0. 0.]
transform [[-0.17066391 -0.53571892 -0.82696986]
 [-0.96159238  0.2736645   0.0211639 ]
 [ 0.          0.          0.        ]]
zmp [-20713450.45392295   4022149.42676149         0.        ]
d1:27749074.82299, d2:0.05761, d3:9767875.47662
transform [[ 0.38021946  0.92333633  0.        ]
 [-0.64600408  0.30666775  0.        ]
 [-0.66190028  0.231095    0.        ]]
inertial
[0.        0.        1.2181312]
[ 638.72687 1190.0491   107.38894]
[259.36754392 205.30774645  71.973119  ]
[ 0.   0.  -9.8]
transform [[ 0.38021946  0.92333633  0.        ]
 [-0.64600408  0.30666775  0.        ]
 [-0.66190028  0.231095    0.        ]]
transform [[ 0.38021946  0.92333633  0.        ]
 [-0.64600408  0.30666775  0.        ]
 [-0.66190028  0.231095    0.        ]]
transform [[ 0.38021946  0.92333633  0.        ]
 [-0.64600408  0.30666775  0.        ]
 [-0.66190028  0.231095    0.        ]]
support
[0. 0. 0.]
[1341.67192384  -47.67049745 -147.75910211]
[ 288.1846879  -104.59122814 -124.22985655]
[0. 0. 0.]
transform [[ 0.38021946 -0.64600408 -0.66190028]
 [ 0.92333633  0.30666775  0.231095  ]
 [ 0.          0.          0.        ]]
zmp [-15090719.02084448   4561239.70165058         0.        ]
d1:16721108.87168, d2:0.05930, d3:6956191.54631
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-467.70869856256525 steps:42[00m
[RDDPG] Resetting Environment
transform [[-0.70303118 -0.04681409  0.        ]
 [-0.03421476  0.99890208  0.        ]
 [-0.71033555 -0.00178145  0.        ]]
inertial
[0.        0.        1.2181312]
[ 638.72687 1190.0491   107.38894]
[259.36754392 205.30774645  71.973119  ]
[ 0.   0.  -9.8]
transform [[-0.70303118 -0.04681409  0.        ]
 [-0.03421476  0.99890208  0.        ]
 [-0.71033555 -0.00178145  0.        ]]
transform [[-0.70303118 -0.04681409  0.        ]
 [-0.03421476  0.99890208  0.        ]
 [-0.71033555 -0.00178145  0.        ]]
transform [[-0.70303118 -0.04681409  0.        ]
 [-0.03421476  0.99890208  0.        ]
 [-0.71033555 -0.00178145  0.        ]]
support
[0. 0. 0.]
[-504.7559711  1166.88861168 -455.83041466]
[-191.95476668  196.20813789 -184.60373301]
[0. 0. 0.]
transform [[-0.70303118 -0.03421476 -0.71033555]
 [-0.04681409  0.99890208 -0.00178145]
 [ 0.          0.          0.        ]]
zmp [ 319619.44550078 8082660.18678129       0.        ]
d1:8858453.83806, d2:0.04386, d3:2657326.40107
transform [[ 0.52152288  0.15464067  0.        ]
 [-0.20018598  0.97816491  0.        ]
 [-0.82942116 -0.13885137  0.        ]]
inertial
[0.        0.        1.2181312]
[-992.3189  -139.97333 -284.09213]
[-173.86438028 -474.29068622 -252.2839142 ]
[ 0.   0.  -9.8]
transform [[ 0.52152288  0.15464067  0.        ]
 [-0.20018598  0.97816491  0.        ]
 [-0.82942116 -0.13885137  0.        ]]
transform [[ 0.52152288  0.15464067  0.        ]
 [-0.20018598  0.97816491  0.        ]
 [-0.82942116 -0.13885137  0.        ]]
transform [[ 0.52152288  0.15464067  0.        ]
 [-0.20018598  0.97816491  0.        ]
 [-0.82942116 -0.13885137  0.        ]]
support
[0. 0. 0.]
[-539.16258455   61.73133994  842.48579184]
[-164.01888393 -429.12929488  210.06271006]
[0. 0. 0.]
transform [[ 0.52152288 -0.20018598 -0.82942116]
 [ 0.15464067  0.97816491 -0.13885137]
 [ 0.          0.          0.        ]]
zmp [   -62527.6784304 -38723862.9356413         0.       ]
d1:35890202.12795, d2:0.05063, d3:12276402.82917
transform [[ 0.78741634 -0.35113198  0.        ]
 [ 0.6147747   0.50737703  0.        ]
 [-0.04502948  0.78694022  0.        ]]
inertial
[0.        0.        1.2181312]
[-992.3189  -139.97333 -284.09213]
[-173.86438028 -474.29068622 -252.2839142 ]
[ 0.   0.  -9.8]
transform [[ 0.78741634 -0.35113198  0.        ]
 [ 0.6147747   0.50737703  0.        ]
 [-0.04502948  0.78694022  0.        ]]
transform [[ 0.78741634 -0.35113198  0.        ]
 [ 0.6147747   0.50737703  0.        ]
 [-0.04502948  0.78694022  0.        ]]
transform [[ 0.78741634 -0.35113198  0.        ]
 [ 0.6147747   0.50737703  0.        ]
 [-0.04502948  0.78694022  0.        ]]
support
[0. 0. 0.]
[-732.21901105 -681.07181438  -65.46704006]
[  29.6349719  -347.53162192 -365.40939355]
[0. 0. 0.]
transform [[ 0.78741634  0.6147747  -0.04502948]
 [-0.35113198  0.50737703  0.78694022]
 [ 0.          0.          0.        ]]
zmp [-2313860.49929632 -6724646.95242586        0.        ]
d1:10787633.57412, d2:0.02470, d3:926015.80562
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-553.36523229337 steps:46[00m
[RDDPG] Resetting Environment
transform [[ 0.21792038 -0.943501    0.        ]
 [ 0.6654129   0.33074886  0.        ]
 [-0.71395826  0.02027639  0.        ]]
inertial
[0.        0.        1.2181312]
[126.0157 610.737  382.7755]
[-63.28315914 -63.49909306  27.22073462]
[ 0.   0.  -9.8]
transform [[ 0.21792038 -0.943501    0.        ]
 [ 0.6654129   0.33074886  0.        ]
 [-0.71395826  0.02027639  0.        ]]
transform [[ 0.21792038 -0.943501    0.        ]
 [ 0.6654129   0.33074886  0.        ]
 [-0.71395826  0.02027639  0.        ]]
transform [[ 0.21792038 -0.943501    0.        ]
 [ 0.6654129   0.33074886  0.        ]
 [-0.71395826  0.02027639  0.        ]]
support
[0. 0. 0.]
[-548.76957787  285.85303755  -77.58641193]
[ 46.12076758 -63.11168301  43.89400226]
[0. 0. 0.]
transform [[ 0.21792038  0.6654129  -0.71395826]
 [-0.943501    0.33074886  0.02027639]
 [ 0.          0.          0.        ]]
zmp [24583965.9521755   7767639.90444518        0.        ]
d1:32511324.37645, d2:0.05659, d3:5395333.80956
transform [[ 0.13013689  0.98600686  0.        ]
 [-0.6879884   0.16546702  0.        ]
 [-0.71395826  0.02027639  0.        ]]
inertial
[0.        0.        1.2181312]
[126.0157 610.737  382.7755]
[-63.28315914 -63.49909306  27.22073462]
[ 0.   0.  -9.8]
transform [[ 0.13013689  0.98600686  0.        ]
 [-0.6879884   0.16546702  0.        ]
 [-0.71395826  0.02027639  0.        ]]
transform [[ 0.13013689  0.98600686  0.        ]
 [-0.6879884   0.16546702  0.        ]
 [-0.71395826  0.02027639  0.        ]]
transform [[ 0.13013689  0.98600686  0.        ]
 [-0.6879884   0.16546702  0.        ]
 [-0.71395826  0.02027639  0.        ]]
support
[0. 0. 0.]
[618.59016044  14.3594929  -77.58641193]
[-70.84601477  33.03107348  43.89400226]
[0. 0. 0.]
transform [[ 0.13013689 -0.6879884  -0.71395826]
 [ 0.98600686  0.16546702  0.02027639]
 [ 0.          0.          0.        ]]
zmp [-8185287.42540869  3765750.52734397        0.        ]
d1:11168306.60476, d2:0.05935, d3:3928849.87361
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-555.2664172828395 steps:49[00m
[RDDPG] Resetting Environment
transform [[ 0.03131478  0.9972201   0.        ]
 [-0.65249854  0.07163895  0.        ]
 [-0.75714272 -0.0204936   0.        ]]
inertial
[0.        0.        1.2181312]
[-39.14723   -64.17616    -3.7746398]
[ -98.08553357 -309.95762085   52.46390888]
[ 0.   0.  -9.8]
transform [[ 0.03131478  0.9972201   0.        ]
 [-0.65249854  0.07163895  0.        ]
 [-0.75714272 -0.0204936   0.        ]]
transform [[ 0.03131478  0.9972201   0.        ]
 [-0.65249854  0.07163895  0.        ]
 [-0.75714272 -0.0204936   0.        ]]
transform [[ 0.03131478  0.9972201   0.        ]
 [-0.65249854  0.07163895  0.        ]
 [-0.75714272 -0.0204936   0.        ]]
support
[0. 0. 0.]
[-65.223646    20.94599654  30.95523973]
[-312.16749579   41.79562951   80.61689617]
[0. 0. 0.]
transform [[ 0.03131478 -0.65249854 -0.75714272]
 [ 0.9972201   0.07163895 -0.0204936 ]
 [ 0.          0.          0.        ]]
zmp [-2625405.45585416   320632.95980934        0.        ]
d1:2851244.58705, d2:0.05928, d3:949401.38212
transform [[-0.03253271  0.99705249  0.        ]
 [ 0.32450214  0.07629127  0.        ]
 [-0.94532537 -0.00812433  0.        ]]
inertial
[0.        0.        1.2181312]
[-39.14723   -64.17616    -3.7746398]
[ -98.08553357 -309.95762085   52.46390888]
[ 0.   0.  -9.8]
transform [[-0.03253271  0.99705249  0.        ]
 [ 0.32450214  0.07629127  0.        ]
 [-0.94532537 -0.00812433  0.        ]]
transform [[-0.03253271  0.99705249  0.        ]
 [ 0.32450214  0.07629127  0.        ]
 [-0.94532537 -0.00812433  0.        ]]
transform [[-0.03253271  0.99705249  0.        ]
 [ 0.32450214  0.07629127  0.        ]
 [-0.94532537 -0.00812433  0.        ]]
support
[0. 0. 0.]
[-62.71343744 -17.59944034  37.52825683]
[-305.85302961  -55.47602629   95.24094324]
[0. 0. 0.]
transform [[-0.03253271  0.32450214 -0.94532537]
 [ 0.99705249  0.07629127 -0.00812433]
 [ 0.          0.          0.        ]]
zmp [-14416294.91360873  -1451287.48338563         0.        ]
d1:10227500.64158, d2:0.05927, d3:7124175.76015
transform [[-0.16685443 -0.97357523  0.        ]
 [-0.85647577  0.22145897  0.        ]
 [-0.48847619 -0.05574251  0.        ]]
inertial
[0.        0.        1.2181312]
[ 589.9748 -458.5567 1206.9564]
[  41.98848844 -438.14726644  -78.07789726]
[ 0.   0.  -9.8]
transform [[-0.16685443 -0.97357523  0.        ]
 [-0.85647577  0.22145897  0.        ]
 [-0.48847619 -0.05574251  0.        ]]
transform [[-0.16685443 -0.97357523  0.        ]
 [-0.85647577  0.22145897  0.        ]
 [-0.48847619 -0.05574251  0.        ]]
transform [[-0.16685443 -0.97357523  0.        ]
 [-0.85647577  0.22145897  0.        ]
 [-0.48847619 -0.05574251  0.        ]]
support
[0. 0. 0.]
[ 347.9995428  -606.85061047 -262.62753568]
[ 419.56336248 -132.99376598    3.9130515 ]
[0. 0. 0.]
transform [[-0.16685443 -0.85647577 -0.48847619]
 [-0.97357523  0.22145897 -0.05574251]
 [ 0.          0.          0.        ]]
zmp [2907896.09269705 1981109.93036664       0.        ]
d1:2858138.44180, d2:0.05936, d3:964229.29234
transform [[ 0.40686214  0.86657143  0.        ]
 [ 0.73237514 -0.12035742  0.        ]
 [-0.54597598  0.48432228  0.        ]]
inertial
[0.        0.        1.2181312]
[ 589.9748 -458.5567 1206.9564]
[  41.98848844 -438.14726644  -78.07789726]
[ 0.   0.  -9.8]
transform [[ 0.40686214  0.86657143  0.        ]
 [ 0.73237514 -0.12035742  0.        ]
 [-0.54597598  0.48432228  0.        ]]
transform [[ 0.40686214  0.86657143  0.        ]
 [ 0.73237514 -0.12035742  0.        ]
 [-0.54597598  0.48432228  0.        ]]
transform [[ 0.40686214  0.86657143  0.        ]
 [ 0.73237514 -0.12035742  0.        ]
 [-0.54597598  0.48432228  0.        ]]
support
[0. 0. 0.]
[-157.3337286   487.27357754 -544.20129447]
[-362.6023754    83.48560164 -235.12918918]
[0. 0. 0.]
transform [[ 0.40686214  0.73237514 -0.54597598]
 [ 0.86657143 -0.12035742  0.48432228]
 [ 0.          0.          0.        ]]
zmp [ 9391200.77977536 -3009564.04286712        0.        ]
d1:15275592.05319, d2:0.05872, d3:4315457.90286
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-637.2061911957728 steps:54[00m
[RDDPG] Resetting Environment
transform [[ 0.20591013  0.9490869   0.        ]
 [-0.66516596  0.31443354  0.        ]
 [-0.71774328 -0.0191208   0.        ]]
inertial
[0.        0.        1.2181312]
[-373.9468  613.9863 1084.5308]
[  72.25778778 -525.24259597  -35.07914533]
[ 0.   0.  -9.8]
transform [[ 0.20591013  0.9490869   0.        ]
 [-0.66516596  0.31443354  0.        ]
 [-0.71774328 -0.0191208   0.        ]]
transform [[ 0.20591013  0.9490869   0.        ]
 [-0.66516596  0.31443354  0.        ]
 [-0.71774328 -0.0191208   0.        ]]
transform [[ 0.20591013  0.9490869   0.        ]
 [-0.66516596  0.31443354  0.        ]
 [-0.71774328 -0.0191208   0.        ]]
support
[0. 0. 0.]
[505.72694726 441.79458539 256.6578981 ]
[-483.62225896 -213.2173122   -41.81948313]
[0. 0. 0.]
transform [[ 0.20591013 -0.66516596 -0.71774328]
 [ 0.9490869   0.31443354 -0.0191208 ]
 [ 0.          0.          0.        ]]
zmp [-17082582.12396937   5964391.5257957          0.        ]
d1:22021634.89559, d2:0.05866, d3:7350739.14704
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-149.29668060330692 steps:56[00m
[RDDPG] Resetting Environment
transform [[ 0.70271784 -0.07841437  0.        ]
 [ 0.07062566  0.996687    0.        ]
 [-0.70795465  0.02159532  0.        ]]
inertial
[0.        0.        1.2181312]
[ 473.49722   -21.406675 1310.7753  ]
[  66.94823622 -331.69342689  -38.0358143 ]
[ 0.   0.  -9.8]
transform [[ 0.70271784 -0.07841437  0.        ]
 [ 0.07062566  0.996687    0.        ]
 [-0.70795465  0.02159532  0.        ]]
transform [[ 0.70271784 -0.07841437  0.        ]
 [ 0.07062566  0.996687    0.        ]
 [-0.70795465  0.02159532  0.        ]]
transform [[ 0.70271784 -0.07841437  0.        ]
 [ 0.07062566  0.996687    0.        ]
 [-0.70795465  0.02159532  0.        ]]
support
[0. 0. 0.]
[ 334.41353691   12.10530029 -335.67684242]
[  73.05524965 -325.86626136  -54.55934042]
[0. 0. 0.]
transform [[ 0.70271784  0.07062566 -0.70795465]
 [-0.07841437  0.996687    0.02159532]
 [ 0.          0.          0.        ]]
zmp [  1619056.80959909 -11687068.5803526          0.        ]
d1:13145402.27534, d2:0.04756, d3:4350339.73146
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-245.51835902230937 steps:58[00m
[RDDPG] Resetting Environment
transform [[ 0.67752582  0.16382262  0.        ]
 [-0.13048783  0.98618698  0.        ]
 [-0.7238313  -0.02444126  0.        ]]
inertial
[0.        0.        1.2181312]
[-830.8109    -183.71907     -2.7498734]
[  35.09146164 -249.65507564  -25.51250856]
[ 0.   0.  -9.8]
transform [[ 0.67752582  0.16382262  0.        ]
 [-0.13048783  0.98618698  0.        ]
 [-0.7238313  -0.02444126  0.        ]]
transform [[ 0.67752582  0.16382262  0.        ]
 [-0.13048783  0.98618698  0.        ]
 [-0.7238313  -0.02444126  0.        ]]
transform [[ 0.67752582  0.16382262  0.        ]
 [-0.13048783  0.98618698  0.        ]
 [-0.7238313  -0.02444126  0.        ]]
support
[0. 0. 0.]
[-592.99318345  -72.77064273  605.85726496]
[ -17.1237776  -250.78559405  -19.29841426]
[0. 0. 0.]
transform [[ 0.67752582 -0.13048783 -0.7238313 ]
 [ 0.16382262  0.98618698 -0.02444126]
 [ 0.          0.          0.        ]]
zmp [ 3327610.58163513 12364861.21028434        0.        ]
d1:15579879.74334, d2:0.03218, d3:2916984.14531
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-161.31278290805 steps:60[00m
[RDDPG] Resetting Environment
transform [[ 0.70975858 -0.0559614   0.        ]
 [ 0.03023561  0.99834102  0.        ]
 [-0.70379591 -0.01354601  0.        ]]
inertial
[0.        0.        1.2181312]
[-128.95145   117.529686  234.92732 ]
[ -31.40988326 -465.64816243   23.92903297]
[ 0.   0.  -9.8]
transform [[ 0.70975858 -0.0559614   0.        ]
 [ 0.03023561  0.99834102  0.        ]
 [-0.70379591 -0.01354601  0.        ]]
transform [[ 0.70975858 -0.0559614   0.        ]
 [ 0.03023561  0.99834102  0.        ]
 [-0.70379591 -0.01354601  0.        ]]
transform [[ 0.70975858 -0.0559614   0.        ]
 [ 0.03023561  0.99834102  0.        ]
 [-0.70379591 -0.01354601  0.        ]]
support
[0. 0. 0.]
[-98.10152091 113.43578127  89.16344261]
[   3.76488733 -465.82536027   28.41382096]
[0. 0. 0.]
transform [[ 0.70975858  0.03023561 -0.70379591]
 [-0.0559614   0.99834102 -0.01354601]
 [ 0.          0.          0.        ]]
zmp [  4373920.38984732 -19244126.03203551         0.        ]
d1:22567460.05366, d2:0.05013, d3:7424403.21355
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-391.6183335989278 steps:62[00m
[RDDPG] Resetting Environment
transform [[ 0.69358528  0.06894756  0.        ]
 [-0.05332872  0.99759221  0.        ]
 [-0.71839792 -0.00748792  0.        ]]
inertial
[0.        0.        1.2181312]
[ 1922.2423 -2791.7988  1713.9535]
[ -7.82298374 -81.37550534  -2.46650836]
[ 0.   0.  -9.8]
transform [[ 0.69358528  0.06894756  0.        ]
 [-0.05332872  0.99759221  0.        ]
 [-0.71839792 -0.00748792  0.        ]]
transform [[ 0.69358528  0.06894756  0.        ]
 [-0.05332872  0.99759221  0.        ]
 [-0.71839792 -0.00748792  0.        ]]
transform [[ 0.69358528  0.06894756  0.        ]
 [-0.05332872  0.99759221  0.        ]
 [-0.71839792 -0.00748792  0.        ]]
support
[0. 0. 0.]
[ 1140.75124374 -2887.58749209 -1360.03010792]
[-11.03654897 -80.76238055   6.22934831]
[0. 0. 0.]
transform [[ 0.69358528 -0.05332872 -0.71839792]
 [ 0.06894756  0.99759221 -0.00748792]
 [ 0.          0.          0.        ]]
zmp [-2022437.36475849 -8945072.66849597        0.        ]
d1:11262230.52303, d2:0.03272, d3:2208684.13307
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-204.0881726278613 steps:64[00m
[RDDPG] Resetting Environment
transform [[ 0.12362295  0.97975159  0.        ]
 [-0.7088815   0.19825451  0.        ]
 [-0.69440943 -0.027965    0.        ]]
inertial
[0.        0.        1.2181312]
[-182.67789 -361.56406  361.9649 ]
[  81.26821508 -485.68954426  -60.53664022]
[ 0.   0.  -9.8]
transform [[ 0.12362295  0.97975159  0.        ]
 [-0.7088815   0.19825451  0.        ]
 [-0.69440943 -0.027965    0.        ]]
transform [[ 0.12362295  0.97975159  0.        ]
 [-0.7088815   0.19825451  0.        ]
 [-0.69440943 -0.027965    0.        ]]
transform [[ 0.12362295  0.97975159  0.        ]
 [-0.7088815   0.19825451  0.        ]
 [-0.69440943 -0.027965    0.        ]]
support
[0. 0. 0.]
[-376.82613802   57.81526894  136.96438751]
[-465.80848493 -153.89967698  -42.85110505]
[0. 0. 0.]
transform [[ 0.12362295 -0.7088815  -0.69440943]
 [ 0.97975159  0.19825451 -0.027965  ]
 [ 0.          0.          0.        ]]
zmp [ 6432037.92803271 -1264463.4722607         0.        ]
d1:6390508.29489, d2:0.05889, d3:2551623.37118
transform [[ 0.71014333  0.13466562  0.        ]
 [-0.11615496  0.99049646  0.        ]
 [-0.69440943 -0.027965    0.        ]]
inertial
[0.        0.        1.2181312]
[-182.67789 -361.56406  361.9649 ]
[  81.26821508 -485.68954426  -60.53664022]
[ 0.   0.  -9.8]
transform [[ 0.71014333  0.13466562  0.        ]
 [-0.11615496  0.99049646  0.        ]
 [-0.69440943 -0.027965    0.        ]]
transform [[ 0.71014333  0.13466562  0.        ]
 [-0.11615496  0.99049646  0.        ]
 [-0.69440943 -0.027965    0.        ]]
transform [[ 0.71014333  0.13466562  0.        ]
 [-0.11615496  0.99049646  0.        ]
 [-0.69440943 -0.027965    0.        ]]
support
[0. 0. 0.]
[-178.41773157 -336.90897381  136.96438751]
[  -7.69360452 -490.51347899  -42.85110505]
[0. 0. 0.]
transform [[ 0.71014333 -0.11615496 -0.69440943]
 [ 0.13466562  0.99049646 -0.027965  ]
 [ 0.          0.          0.        ]]
zmp [ 2450532.95979747 -6586165.62039049        0.        ]
d1:7357360.07196, d2:0.05378, d3:3065071.79630
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-615.903954263804 steps:67[00m
[RDDPG] Resetting Environment
transform [[ 0.24465039 -0.94414806  0.        ]
 [ 0.66307765  0.32902303  0.        ]
 [-0.70744205 -0.01811929  0.        ]]
inertial
[0.        0.        1.2181312]
[1053.0321   -241.88994    18.279041]
[ -99.74681012 -269.48100318   52.1263163 ]
[ 0.   0.  -9.8]
transform [[ 0.24465039 -0.94414806  0.        ]
 [ 0.66307765  0.32902303  0.        ]
 [-0.70744205 -0.01811929  0.        ]]
transform [[ 0.24465039 -0.94414806  0.        ]
 [ 0.66307765  0.32902303  0.        ]
 [-0.70744205 -0.01811929  0.        ]]
transform [[ 0.24465039 -0.94414806  0.        ]
 [ 0.66307765  0.32902303  0.        ]
 [-0.70744205 -0.01811929  0.        ]]
support
[0. 0. 0.]
[ 486.00463588  618.65469454 -740.57631162]
[ 230.02687097 -154.8053378    75.44789193]
[0. 0. 0.]
transform [[ 0.24465039  0.66307765 -0.70744205]
 [-0.94414806  0.32902303 -0.01811929]
 [ 0.          0.          0.        ]]
zmp [10016288.86543041  1105892.03639457        0.        ]
d1:11256096.97096, d2:0.05757, d3:2924302.62193
transform [[ 0.13356006  0.22445652  0.        ]
 [-0.35491338  0.92024589  0.        ]
 [-0.92530984 -0.32057276  0.        ]]
inertial
[0.        0.        1.2181312]
[ 856.4872  -102.23662  346.4562 ]
[ -99.74681012 -269.48100318   52.1263163 ]
[ 0.   0.  -9.8]
transform [[ 0.13356006  0.22445652  0.        ]
 [-0.35491338  0.92024589  0.        ]
 [-0.92530984 -0.32057276  0.        ]]
transform [[ 0.13356006  0.22445652  0.        ]
 [-0.35491338  0.92024589  0.        ]
 [-0.92530984 -0.32057276  0.        ]]
transform [[ 0.13356006  0.22445652  0.        ]
 [-0.35491338  0.92024589  0.        ]
 [-0.92530984 -0.32057276  0.        ]]
support
[0. 0. 0.]
[  91.44480536 -398.06159123 -759.74174003]
[ -73.80895797 -212.58730659  178.68497455]
[0. 0. 0.]
transform [[ 0.13356006 -0.35491338 -0.92530984]
 [ 0.22445652  0.92024589 -0.32057276]
 [ 0.          0.          0.        ]]
zmp [  9440453.29059345 -26664254.48059793         0.        ]
d1:38761790.60099, d2:0.05824, d3:4244075.06058
transform [[ 0.96315956 -0.24564795  0.        ]
 [-0.13655387 -0.79735464  0.        ]
 [-0.23168255 -0.55125558  0.        ]]
inertial
[0.        0.        1.2181312]
[-413.43503    36.147987  390.52475 ]
[ 131.00654136   -0.64160444 -104.79374592]
[ 0.   0.  -9.8]
transform [[ 0.96315956 -0.24564795  0.        ]
 [-0.13655387 -0.79735464  0.        ]
 [-0.23168255 -0.55125558  0.        ]]
transform [[ 0.96315956 -0.24564795  0.        ]
 [-0.13655387 -0.79735464  0.        ]
 [-0.23168255 -0.55125558  0.        ]]
transform [[ 0.96315956 -0.24564795  0.        ]
 [-0.13655387 -0.79735464  0.        ]
 [-0.23168255 -0.55125558  0.        ]]
support
[0. 0. 0.]
[-407.08357927   27.63338712   75.85890329]
[126.3378117  -17.37786376 -29.99824205]
[0. 0. 0.]
transform [[ 0.96315956 -0.13655387 -0.23168255]
 [-0.24564795 -0.79735464 -0.55125558]
 [ 0.          0.          0.        ]]
zmp [  258788.70862979 -7093594.85832647        0.        ]
d1:6364056.00869, d2:0.01524, d3:1599511.07928
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-421.7358362974062 steps:71[00m
[RDDPG] Resetting Environment
transform [[ 0.78460729  0.1281428   0.        ]
 [ 0.01039254  0.97555196  0.        ]
 [-0.61990595  0.1785436   0.        ]]
inertial
[0.        0.        1.2181312]
[646.60333 273.203    64.29713]
[ -24.028839   -244.32642196  -13.91418008]
[ 0.   0.  -9.8]
transform [[ 0.78460729  0.1281428   0.        ]
 [ 0.01039254  0.97555196  0.        ]
 [-0.61990595  0.1785436   0.        ]]
transform [[ 0.78460729  0.1281428   0.        ]
 [ 0.01039254  0.97555196  0.        ]
 [-0.61990595  0.1785436   0.        ]]
transform [[ 0.78460729  0.1281428   0.        ]
 [ 0.01039254  0.97555196  0.        ]
 [-0.61990595  0.1785436   0.        ]]
support
[0. 0. 0.]
[ 542.33868805  273.24357625 -352.05460526]
[ -50.16187506 -238.60284117  -28.7272981 ]
[0. 0. 0.]
transform [[ 0.78460729  0.01039254 -0.61990595]
 [ 0.1281428   0.97555196  0.1785436 ]
 [ 0.          0.          0.        ]]
zmp [ -572437.31374195 11063002.09400256        0.        ]
d1:12502541.16484, d2:0.03914, d3:4069062.60127
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-336.00640144036004 steps:73[00m
[RDDPG] Resetting Environment
transform [[ 0.70298815  0.33882308  0.        ]
 [-0.24775459  0.94081908  0.        ]
 [-0.66665244  0.00764472  0.        ]]
inertial
[0.        0.        1.2181312]
[-800.3096  -700.98486 1532.7719 ]
[-103.09470424 -413.77474056   50.45548974]
[ 0.   0.  -9.8]
transform [[ 0.70298815  0.33882308  0.        ]
 [-0.24775459  0.94081908  0.        ]
 [-0.66665244  0.00764472  0.        ]]
transform [[ 0.70298815  0.33882308  0.        ]
 [-0.24775459  0.94081908  0.        ]
 [-0.66665244  0.00764472  0.        ]]
transform [[ 0.70298815  0.33882308  0.        ]
 [-0.24775459  0.94081908  0.        ]
 [-0.66665244  0.00764472  0.        ]]
support
[0. 0. 0.]
[-800.1179929  -461.21956898  528.16949503]
[-212.67078723 -363.74498662   65.56514386]
[0. 0. 0.]
transform [[ 0.70298815 -0.24775459 -0.66665244]
 [ 0.33882308  0.94081908  0.00764472]
 [ 0.          0.          0.        ]]
zmp [  2258914.90407048 -10323786.84296634         0.        ]
d1:11273642.55416, d2:0.04949, d3:4510126.54136
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-46.26209321325443 steps:75[00m
[RDDPG] Resetting Environment
transform [[-0.19542786 -0.97157407  0.        ]
 [-0.67200446  0.23188889  0.        ]
 [-0.71429539  0.04765851  0.        ]]
inertial
[0.        0.        1.2181312]
[-800.3096  -700.98486 1532.7719 ]
[-103.09470424 -413.77474056   50.45548974]
[ 0.   0.  -9.8]
transform [[-0.19542786 -0.97157407  0.        ]
 [-0.67200446  0.23188889  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.19542786 -0.97157407  0.        ]
 [-0.67200446  0.23188889  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.19542786 -0.97157407  0.        ]
 [-0.67200446  0.23188889  0.        ]
 [-0.71429539  0.04765851  0.        ]]
support
[0. 0. 0.]
[837.46150577 375.26099962 538.24953999]
[422.16038588 -26.66966422  53.92018387]
[0. 0. 0.]
transform [[-0.19542786 -0.67200446 -0.71429539]
 [-0.97157407  0.23188889  0.04765851]
 [ 0.          0.          0.        ]]
zmp [ 7831042.47663998 -3722524.71326788        0.        ]
d1:11120408.90060, d2:0.05814, d3:1814514.08496
transform [[-0.21722379  0.93330485  0.        ]
 [ 0.66527885  0.35590833  0.        ]
 [-0.71429539  0.04765851  0.        ]]
inertial
[0.        0.        1.2181312]
[-800.3096  -700.98486 1532.7719 ]
[-103.09470424 -413.77474056   50.45548974]
[ 0.   0.  -9.8]
transform [[-0.21722379  0.93330485  0.        ]
 [ 0.66527885  0.35590833  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.21722379  0.93330485  0.        ]
 [ 0.66527885  0.35590833  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.21722379  0.93330485  0.        ]
 [ 0.66527885  0.35590833  0.        ]
 [-0.71429539  0.04765851  0.        ]]
support
[0. 0. 0.]
[-480.38628942 -781.9153872   538.24953999]
[-363.78334792 -215.85260516   53.92018387]
[0. 0. 0.]
transform [[-0.21722379  0.66527885 -0.71429539]
 [ 0.93330485  0.35590833  0.04765851]
 [ 0.          0.          0.        ]]
zmp [-15046791.55046097  -5844211.33326764         0.        ]
d1:20128382.03063, d2:0.05834, d3:7455313.43849
transform [[-0.30776069 -0.91742337  0.        ]
 [-0.62854236  0.39504826  0.        ]
 [-0.71429539  0.04765851  0.        ]]
inertial
[0.        0.        1.2181312]
[-800.3096  -700.98486 1532.7719 ]
[-103.09470424 -413.77474056   50.45548974]
[ 0.   0.  -9.8]
transform [[-0.30776069 -0.91742337  0.        ]
 [-0.62854236  0.39504826  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.30776069 -0.91742337  0.        ]
 [-0.62854236  0.39504826  0.        ]
 [-0.71429539  0.04765851  0.        ]]
transform [[-0.30776069 -0.91742337  0.        ]
 [-0.62854236  0.39504826  0.        ]
 [-0.71429539  0.04765851  0.        ]]
support
[0. 0. 0.]
[889.40371596 226.10561796 538.24953999]
[411.33511274 -98.66160249  53.92018387]
[0. 0. 0.]
transform [[-0.30776069 -0.62854236 -0.71429539]
 [-0.91742337  0.39504826  0.04765851]
 [ 0.          0.          0.        ]]
zmp [ 7087506.26086226 -6513805.30847497        0.        ]
d1:13064914.30375, d2:0.05460, d3:784482.84757
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-591.0767295336416 steps:79[00m
[RDDPG] Resetting Environment
transform [[ 0.69493896 -0.02855038  0.        ]
 [ 0.02130581  0.99959034  0.        ]
 [-0.71875304  0.00202615  0.        ]]
inertial
[0.        0.        1.2181312]
[ 338.65836  390.96204 1240.6195 ]
[ -15.86932741 -190.35298141    8.52719749]
[ 0.   0.  -9.8]
transform [[ 0.69493896 -0.02855038  0.        ]
 [ 0.02130581  0.99959034  0.        ]
 [-0.71875304  0.00202615  0.        ]]
transform [[ 0.69493896 -0.02855038  0.        ]
 [ 0.02130581  0.99959034  0.        ]
 [-0.71875304  0.00202615  0.        ]]
transform [[ 0.69493896 -0.02855038  0.        ]
 [ 0.02130581  0.99959034  0.        ]
 [-0.71875304  0.00202615  0.        ]]
support
[0. 0. 0.]
[ 224.18476825  398.01726373 -242.61957336]
[  -5.59356303 -190.61310974   11.02044287]
[0. 0. 0.]
transform [[ 0.69493896  0.02130581 -0.71875304]
 [-0.02855038  0.99959034  0.00202615]
 [ 0.          0.          0.        ]]
zmp [4375551.75563748 4651108.91732376       0.        ]
d1:8769448.72785, d2:0.00327, d3:308663.43029
transform [[-0.77028775 -0.04128375  0.        ]
 [-0.00765179  0.99842876  0.        ]
 [-0.63765067  0.03789004  0.        ]]
inertial
[0.        0.        1.2181312]
[ -151.603   -1044.877    -542.54047]
[ -52.79329576 -137.59057209   28.94497779]
[ 0.   0.  -9.8]
transform [[-0.77028775 -0.04128375  0.        ]
 [-0.00765179  0.99842876  0.        ]
 [-0.63765067  0.03789004  0.        ]]
transform [[-0.77028775 -0.04128375  0.        ]
 [-0.00765179  0.99842876  0.        ]
 [-0.63765067  0.03789004  0.        ]]
transform [[-0.77028775 -0.04128375  0.        ]
 [-0.00765179  0.99842876  0.        ]
 [-0.63765067  0.03789004  0.        ]]
support
[0. 0. 0.]
[  159.91437345 -1042.07516855    57.07932728]
[  46.34628428 -136.97042139   28.45036866]
[0. 0. 0.]
transform [[-0.77028775 -0.00765179 -0.63765067]
 [-0.04128375  0.99842876  0.03789004]
 [ 0.          0.          0.        ]]
zmp [-1149162.44796257  4132673.97367572        0.        ]
d1:4962309.10341, d2:0.02428, d3:926114.00302
transform [[-0.15536092  0.98186725  0.        ]
 [-0.75991201 -0.18904638  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
inertial
[0.        0.        1.2181312]
[196.99529 939.14606 918.00116]
[-193.9199445  -398.62907705 -109.51117281]
[ 0.   0.  -9.8]
transform [[-0.15536092  0.98186725  0.        ]
 [-0.75991201 -0.18904638  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
transform [[-0.15536092  0.98186725  0.        ]
 [-0.75991201 -0.18904638  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
transform [[-0.15536092  0.98186725  0.        ]
 [-0.75991201 -0.18904638  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
support
[0. 0. 0.]
[ 891.51139086 -327.24124892 -137.56114815]
[-361.27325575  222.72148072  128.01119427]
[0. 0. 0.]
transform [[-0.15536092 -0.75991201 -0.63118678]
 [ 0.98186725 -0.18904638 -0.01407697]
 [ 0.          0.          0.        ]]
zmp [-5478181.61218759 -1522696.5411291         0.        ]
d1:5687752.93356, d2:0.05876, d3:1164094.74401
transform [[-0.21185206  0.96494615  0.        ]
 [-0.7461381  -0.26207033  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
inertial
[0.        0.        1.2181312]
[196.99529 939.14606 918.00116]
[-193.9199445  -398.62907705 -109.51117281]
[ 0.   0.  -9.8]
transform [[-0.21185206  0.96494615  0.        ]
 [-0.7461381  -0.26207033  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
transform [[-0.21185206  0.96494615  0.        ]
 [-0.7461381  -0.26207033  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
transform [[-0.21185206  0.96494615  0.        ]
 [-0.7461381  -0.26207033  0.        ]
 [-0.63118678 -0.01407697  0.        ]]
support
[0. 0. 0.]
[ 864.49151614 -393.1080021  -137.56114815]
[-343.57325401  249.15991111  128.01119427]
[0. 0. 0.]
transform [[-0.21185206 -0.7461381  -0.63118678]
 [ 0.96494615 -0.26207033 -0.01407697]
 [ 0.          0.          0.        ]]
zmp [-5366090.91472938 -2116957.83719772        0.        ]
d1:5803941.15181, d2:0.05792, d3:934403.09385
transform [[ 0.07181656  0.96865237  0.        ]
 [ 0.50098801  0.17113757  0.        ]
 [-0.86246938  0.18006791  0.        ]]
inertial
[0.        0.        1.2181312]
[  -2.1969297  159.65457   -362.56165  ]
[-25.78913695 -64.58361037  90.67924344]
[ 0.   0.  -9.8]
transform [[ 0.07181656  0.96865237  0.        ]
 [ 0.50098801  0.17113757  0.        ]
 [-0.86246938  0.18006791  0.        ]]
transform [[ 0.07181656  0.96865237  0.        ]
 [ 0.50098801  0.17113757  0.        ]
 [-0.86246938  0.18006791  0.        ]]
transform [[ 0.07181656  0.96865237  0.        ]
 [ 0.50098801  0.17113757  0.        ]
 [-0.86246938  0.18006791  0.        ]]
support
[0. 0. 0.]
[154.49200279  26.2222602   30.64344988]
[-64.41115409 -23.97273054  10.61290498]
[0. 0. 0.]
transform [[ 0.07181656  0.50098801 -0.86246938]
 [ 0.96865237  0.17113757  0.18006791]
 [ 0.          0.          0.        ]]
zmp [-19435499.63582794   7412266.15995444         0.        ]
d1:17463753.49821, d2:0.05824, d3:3103708.47433
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-650.4160379014209 steps:85[00m
[RDDPG] Resetting Environment
transform [[ 0.19910027  0.93937659  0.        ]
 [-0.61945218  0.34137392  0.        ]
 [-0.75936693 -0.03217772  0.        ]]
inertial
[0.        0.        1.2181312]
[558.0432 580.1351 480.3095]
[ -62.09865586 -516.65144762   49.41397152]
[ 0.   0.  -9.8]
transform [[ 0.19910027  0.93937659  0.        ]
 [-0.61945218  0.34137392  0.        ]
 [-0.75936693 -0.03217772  0.        ]]
transform [[ 0.19910027  0.93937659  0.        ]
 [-0.61945218  0.34137392  0.        ]
 [-0.75936693 -0.03217772  0.        ]]
transform [[ 0.19910027  0.93937659  0.        ]
 [-0.61945218  0.34137392  0.        ]
 [-0.75936693 -0.03217772  0.        ]]
support
[0. 0. 0.]
[ 656.07186092 -147.63810041 -442.42698295]
[-497.69413565 -137.90418252   63.78032944]
[0. 0. 0.]
transform [[ 0.19910027 -0.61945218 -0.75936693]
 [ 0.93937659  0.34137392 -0.03217772]
 [ 0.          0.          0.        ]]
zmp [ 7809632.21233362 -1234137.92435005        0.        ]
d1:8510889.69935, d2:0.05759, d3:3070429.85308
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-133.1588050556907 steps:87[00m
[RDDPG] Resetting Environment
transform [[ 0.66204762 -0.28662476  0.        ]
 [ 0.20357659  0.95801502  0.        ]
 [-0.72128326  0.00730674  0.        ]]
inertial
[0.        0.        1.2181312]
[-436.16345  278.78033  125.61427]
[  22.53074958 -640.60679693   -5.54986973]
[ 0.   0.  -9.8]
transform [[ 0.66204762 -0.28662476  0.        ]
 [ 0.20357659  0.95801502  0.        ]
 [-0.72128326  0.00730674  0.        ]]
transform [[ 0.66204762 -0.28662476  0.        ]
 [ 0.20357659  0.95801502  0.        ]
 [-0.72128326  0.00730674  0.        ]]
transform [[ 0.66204762 -0.28662476  0.        ]
 [ 0.20357659  0.95801502  0.        ]
 [-0.72128326  0.00730674  0.        ]]
support
[0. 0. 0.]
[-368.66632373  178.28307873  316.63437186]
[ 198.5301983  -609.12420309  -20.93180223]
[0. 0. 0.]
transform [[ 0.66204762  0.20357659 -0.72128326]
 [-0.28662476  0.95801502  0.00730674]
 [ 0.          0.          0.        ]]
zmp [  6045128.13114779 -11392192.59470312         0.        ]
d1:16860363.60501, d2:0.05735, d3:5748644.92993
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-480.19259257542495 steps:89[00m
[RDDPG] Resetting Environment
transform [[ 0.72511601  0.0531459   0.        ]
 [-0.0556242   0.99827987  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
inertial
[0.        0.        1.2181312]
[-374.85278  212.09015 -515.781  ]
[  29.83785387 -344.54009497  -22.44225772]
[ 0.   0.  -9.8]
transform [[ 0.72511601  0.0531459   0.        ]
 [-0.0556242   0.99827987  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
transform [[ 0.72511601  0.0531459   0.        ]
 [-0.0556242   0.99827987  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
transform [[ 0.72511601  0.0531459   0.        ]
 [-0.0556242   0.99827987  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
support
[0. 0. 0.]
[-260.54003346  232.5762117   252.03975682]
[   3.32501083 -345.60714776  -11.95075377]
[0. 0. 0.]
transform [[ 0.72511601 -0.0556242  -0.68637651]
 [ 0.0531459   0.99827987 -0.02475546]
 [ 0.          0.          0.        ]]
zmp [  793792.14329519 -9554838.11069466        0.        ]
d1:10177093.65479, d2:0.04432, d3:2815338.15599
transform [[ 0.30753419  0.89578283  0.        ]
 [-0.65902203  0.44380215  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
inertial
[0.        0.        1.2181312]
[-374.85278  212.09015 -515.781  ]
[  29.83785387 -344.54009497  -22.44225772]
[ 0.   0.  -9.8]
transform [[ 0.30753419  0.89578283  0.        ]
 [-0.65902203  0.44380215  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
transform [[ 0.30753419  0.89578283  0.        ]
 [-0.65902203  0.44380215  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
transform [[ 0.30753419  0.89578283  0.        ]
 [-0.65902203  0.44380215  0.        ]
 [-0.68637651 -0.02475546  0.        ]]
support
[0. 0. 0.]
[ 74.70666715 341.16230703 252.03975682]
[-299.45694058 -172.57143738  -11.95075377]
[0. 0. 0.]
transform [[ 0.30753419 -0.65902203 -0.68637651]
 [ 0.89578283  0.44380215 -0.02475546]
 [ 0.          0.          0.        ]]
zmp [ 6574784.46128932 -4242538.22706632        0.        ]
d1:9916603.54493, d2:0.05908, d3:3517336.40763
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-326.1245322291162 steps:92[00m
[RDDPG] Resetting Environment
transform [[ 0.72906661 -0.01724084  0.        ]
 [-0.01047902  0.99928439  0.        ]
 [-0.68436253 -0.03366818  0.        ]]
inertial
[0.        0.        1.2181312]
[-150.87723   -30.270937 -132.59734 ]
[ -16.56765441 -286.6491548    -2.45951515]
[ 0.   0.  -9.8]
transform [[ 0.72906661 -0.01724084  0.        ]
 [-0.01047902  0.99928439  0.        ]
 [-0.68436253 -0.03366818  0.        ]]
transform [[ 0.72906661 -0.01724084  0.        ]
 [-0.01047902  0.99928439  0.        ]
 [-0.68436253 -0.03366818  0.        ]]
transform [[ 0.72906661 -0.01724084  0.        ]
 [-0.01047902  0.99928439  0.        ]
 [-0.68436253 -0.03366818  0.        ]]
support
[0. 0. 0.]
[-109.47765268  -28.6682292   104.27388887]
[  -7.13685169 -286.27041205   20.98923804]
[0. 0. 0.]
transform [[ 0.72906661 -0.01047902 -0.68436253]
 [-0.01724084  0.99928439 -0.03366818]
 [ 0.          0.          0.        ]]
zmp [8268456.55921131 9571769.48131875       0.        ]
d1:18336095.88875, d2:0.00265, d3:719040.30650
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-259.205581105865 steps:94[00m
[RDDPG] Resetting Environment
transform [[ 0.58589596 -0.48477527  0.        ]
 [ 0.345815    0.87428182  0.        ]
 [-0.73289698  0.02498565  0.        ]]
inertial
[0.        0.        1.2181312]
[-628.3505 -786.7069  589.9011]
[-20.92010003 -50.78025532   9.93709538]
[ 0.   0.  -9.8]
transform [[ 0.58589596 -0.48477527  0.        ]
 [ 0.345815    0.87428182  0.        ]
 [-0.73289698  0.02498565  0.        ]]
transform [[ 0.58589596 -0.48477527  0.        ]
 [ 0.345815    0.87428182  0.        ]
 [-0.73289698  0.02498565  0.        ]]
transform [[ 0.58589596 -0.48477527  0.        ]
 [ 0.345815    0.87428182  0.        ]
 [-0.73289698  0.02498565  0.        ]]
support
[0. 0. 0.]
[  13.22802702 -905.09658983  440.85982337]
[ 12.36001024 -51.63073868  14.06350068]
[0. 0. 0.]
transform [[ 0.58589596  0.345815   -0.73289698]
 [-0.48477527  0.87428182  0.02498565]
 [ 0.          0.          0.        ]]
zmp [ -265262.69698557 -9775942.29232902        0.        ]
d1:10179942.67505, d2:0.04737, d3:3345834.72573
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-415.7469606074821 steps:96[00m
[RDDPG] Resetting Environment
transform [[-0.70124179  0.06828295  0.        ]
 [ 0.06101093  0.99749875  0.        ]
 [-0.71030807  0.01826738  0.        ]]
inertial
[0.        0.        1.2181312]
[-628.3505 -786.7069  589.9011]
[-20.92010003 -50.78025532   9.93709538]
[ 0.   0.  -9.8]
transform [[-0.70124179  0.06828295  0.        ]
 [ 0.06101093  0.99749875  0.        ]
 [-0.71030807  0.01826738  0.        ]]
transform [[-0.70124179  0.06828295  0.        ]
 [ 0.06101093  0.99749875  0.        ]
 [-0.71030807  0.01826738  0.        ]]
transform [[-0.70124179  0.06828295  0.        ]
 [ 0.06101093  0.99749875  0.        ]
 [-0.71030807  0.01826738  0.        ]]
support
[0. 0. 0.]
[ 386.90698147 -823.07540939  431.95137909]
[ 11.20262293 -51.92959602  13.93209385]
[0. 0. 0.]
transform [[-0.70124179  0.06101093 -0.71030807]
 [ 0.06828295  0.99749875  0.01826738]
 [ 0.          0.          0.        ]]
zmp [ -9997279.22803733 -26440865.56119675         0.        ]
d1:38098656.66192, d2:0.05431, d3:11741983.62539
transform [[ 0.14670011  0.08614097  0.        ]
 [ 0.11987315  0.98731095  0.        ]
 [-0.9818908   0.13340482  0.        ]]
inertial
[0.        0.        1.2181312]
[-628.3505 -786.7069  589.9011]
[-20.92010003 -50.78025532   9.93709538]
[ 0.   0.  -9.8]
transform [[ 0.14670011  0.08614097  0.        ]
 [ 0.11987315  0.98731095  0.        ]
 [-0.9818908   0.13340482  0.        ]]
transform [[ 0.14670011  0.08614097  0.        ]
 [ 0.11987315  0.98731095  0.        ]
 [-0.9818908   0.13340482  0.        ]]
transform [[ 0.14670011  0.08614097  0.        ]
 [ 0.11987315  0.98731095  0.        ]
 [-0.9818908   0.13340482  0.        ]]
support
[0. 0. 0.]
[-159.94678826 -852.04670018  512.02110356]
[ -7.4432414  -52.64366023  13.76692282]
[0. 0. 0.]
transform [[ 0.14670011  0.11987315 -0.9818908 ]
 [ 0.08614097  0.98731095  0.13340482]
 [ 0.          0.          0.        ]]
zmp [ 1829654.08562979 12509237.96240514        0.        ]
d1:19271898.30708, d2:0.05689, d3:1709044.88637
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-363.6634477326496 steps:99[00m
[RDDPG] Resetting Environment
transform [[ 0.69976056  0.0203407   0.        ]
 [ 0.0133489   0.99904776  0.        ]
 [-0.71425271  0.03859951  0.        ]]
inertial
[0.        0.        1.2181312]
[-105.82609 -224.05829  203.69948]
[  44.51355936 -354.3460847   -11.00211537]
[ 0.   0.  -9.8]
transform [[ 0.69976056  0.0203407   0.        ]
 [ 0.0133489   0.99904776  0.        ]
 [-0.71425271  0.03859951  0.        ]]
transform [[ 0.69976056  0.0203407   0.        ]
 [ 0.0133489   0.99904776  0.        ]
 [-0.71425271  0.03859951  0.        ]]
transform [[ 0.69976056  0.0203407   0.        ]
 [ 0.0133489   0.99904776  0.        ]
 [-0.71425271  0.03859951  0.        ]]
support
[0. 0. 0.]
[ -78.6104237  -225.2575926    66.93803005]
[  23.94118708 -353.41445367  -45.47151557]
[0. 0. 0.]
transform [[ 0.69976056  0.0133489  -0.71425271]
 [ 0.0203407   0.99904776  0.03859951]
 [ 0.          0.          0.        ]]
zmp [ 6373735.3672117  -2053246.71987108        0.        ]
d1:6485386.24305, d2:0.05258, d3:3238116.31670
transform [[ 0.69905919 -0.00922973  0.        ]
 [ 0.03404876  0.99921215  0.        ]
 [-0.71425271  0.03859951  0.        ]]
inertial
[0.        0.        1.2181312]
[-105.82609 -224.05829  203.69948]
[  44.51355936 -354.3460847   -11.00211537]
[ 0.   0.  -9.8]
transform [[ 0.69905919 -0.00922973  0.        ]
 [ 0.03404876  0.99921215  0.        ]
 [-0.71425271  0.03859951  0.        ]]
transform [[ 0.69905919 -0.00922973  0.        ]
 [ 0.03404876  0.99921215  0.        ]
 [-0.71425271  0.03859951  0.        ]]
transform [[ 0.69905919 -0.00922973  0.        ]
 [ 0.03404876  0.99921215  0.        ]
 [-0.71425271  0.03859951  0.        ]]
support
[0. 0. 0.]
[ -71.91070125 -227.48501022   66.93803005]
[  34.38813198 -352.55128022  -45.47151557]
[0. 0. 0.]
transform [[ 0.69905919  0.03404876 -0.71425271]
 [-0.00922973  0.99921215  0.03859951]
 [ 0.          0.          0.        ]]
zmp [ 6338355.02439901 -2053527.73160007        0.        ]
d1:6445182.86321, d2:0.05260, d3:3224670.85669
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-489.3180270138953 steps:102[00m
[RDDPG] Resetting Environment
transform [[ 0.69562626  0.13093393  0.        ]
 [-0.09991772  0.99132782  0.        ]
 [-0.71142149 -0.01120312  0.        ]]
inertial
[0.        0.        1.2181312]
[ 102.53916 -174.95947 1151.6428 ]
[ -93.80228427 -284.64793315   29.06676352]
[ 0.   0.  -9.8]
transform [[ 0.69562626  0.13093393  0.        ]
 [-0.09991772  0.99132782  0.        ]
 [-0.71142149 -0.01120312  0.        ]]
transform [[ 0.69562626  0.13093393  0.        ]
 [-0.09991772  0.99132782  0.        ]
 [-0.71142149 -0.01120312  0.        ]]
transform [[ 0.69562626  0.13093393  0.        ]
 [-0.09991772  0.99132782  0.        ]
 [-0.71142149 -0.01120312  0.        ]]
support
[0. 0. 0.]
[  48.42080287 -183.68767273  -70.98847144]
[-102.52140335 -272.80690485   69.92190537]
[0. 0. 0.]
transform [[ 0.69562626 -0.09991772 -0.71142149]
 [ 0.13093393  0.99132782 -0.01120312]
 [ 0.          0.          0.        ]]
zmp [-1206499.51494977 -3273173.6742042         0.        ]
d1:4486861.59431, d2:0.02626, d3:685188.26305
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-651.7249517073883 steps:104[00m
[RDDPG] Resetting Environment
transform [[ 0.37959135 -0.86694729  0.        ]
 [ 0.59698123  0.49622831  0.        ]
 [-0.70677    -0.04647432  0.        ]]
inertial
[0.        0.        1.2181312]
[ 229.43645 -723.7746   220.92839]
[ -35.71883063 -187.06241119   13.92706922]
[ 0.   0.  -9.8]
transform [[ 0.37959135 -0.86694729  0.        ]
 [ 0.59698123  0.49622831  0.        ]
 [-0.70677    -0.04647432  0.        ]]
transform [[ 0.37959135 -0.86694729  0.        ]
 [ 0.59698123  0.49622831  0.        ]
 [-0.70677    -0.04647432  0.        ]]
transform [[ 0.37959135 -0.86694729  0.        ]
 [ 0.59698123  0.49622831  0.        ]
 [-0.70677    -0.04647432  0.        ]]
support
[0. 0. 0.]
[ 714.5665177  -222.18819153 -128.52186423]
[ 148.61469207 -114.14913505   33.93859688]
[0. 0. 0.]
transform [[ 0.37959135  0.59698123 -0.70677   ]
 [-0.86694729  0.49622831 -0.04647432]
 [ 0.          0.          0.        ]]
zmp [  287179.15315105 -2654847.5715897         0.        ]
d1:2805166.89839, d2:0.05580, d3:1066555.84713
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-30.808184702890088 steps:106[00m
[RDDPG] Resetting Environment
transform [[-0.63309848 -0.22941472  0.        ]
 [-0.16623192  0.97308362  0.        ]
 [-0.75601143 -0.02184548  0.        ]]
inertial
[0.        0.        1.2181312]
[ 229.43645 -723.7746   220.92839]
[ -35.71883063 -187.06241119   13.92706922]
[ 0.   0.  -9.8]
transform [[-0.63309848 -0.22941472  0.        ]
 [-0.16623192  0.97308362  0.        ]
 [-0.75601143 -0.02184548  0.        ]]
transform [[-0.63309848 -0.22941472  0.        ]
 [-0.16623192  0.97308362  0.        ]
 [-0.75601143 -0.02184548  0.        ]]
transform [[-0.63309848 -0.22941472  0.        ]
 [-0.16623192  0.97308362  0.        ]
 [-0.75601143 -0.02184548  0.        ]]
support
[0. 0. 0.]
[  20.78867727 -742.43286174 -157.64536919]
[  65.52840749 -176.08975774   31.09031303]
[0. 0. 0.]
transform [[-0.63309848 -0.16623192 -0.75601143]
 [-0.22941472  0.97308362 -0.02184548]
 [ 0.          0.          0.        ]]
zmp [  9849896.78702582 -12658273.62998058         0.        ]
d1:20931099.23997, d2:0.01787, d3:1071922.34576
transform [[ 0.02222172 -0.01471902  0.        ]
 [-0.39190215  0.91973776  0.        ]
 [-0.91973853 -0.39225742  0.        ]]
inertial
[0.        0.        1.2181312]
[ 229.43645 -723.7746   220.92839]
[ -35.71883063 -187.06241119   13.92706922]
[ 0.   0.  -9.8]
transform [[ 0.02222172 -0.01471902  0.        ]
 [-0.39190215  0.91973776  0.        ]
 [-0.91973853 -0.39225742  0.        ]]
transform [[ 0.02222172 -0.01471902  0.        ]
 [-0.39190215  0.91973776  0.        ]
 [-0.91973853 -0.39225742  0.        ]]
transform [[ 0.02222172 -0.01471902  0.        ]
 [-0.39190215  0.91973776  0.        ]
 [-0.91973853 -0.39225742  0.        ]]
support
[0. 0. 0.]
[  15.75172766 -755.59946066   72.88441687]
[   1.95964215 -158.05007587  106.22860402]
[0. 0. 0.]
transform [[ 0.02222172 -0.39190215 -0.91973853]
 [-0.01471902  0.91973776 -0.39225742]
 [ 0.          0.          0.        ]]
zmp [-1118862.55417977 -1172697.63194833        0.        ]
d1:1039160.28143, d2:0.04206, d3:501124.86829
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-550.6906354132718 steps:109[00m
[RDDPG] Resetting Environment
transform [[ 0.69490695  0.12684931  0.        ]
 [-0.11245066  0.99137789  0.        ]
 [-0.71025294 -0.03285115  0.        ]]
inertial
[0.        0.        1.2181312]
[-596.32367  710.6805  1203.5999 ]
[  13.38433923 -533.649875     15.91036585]
[ 0.   0.  -9.8]
transform [[ 0.69490695  0.12684931  0.        ]
 [-0.11245066  0.99137789  0.        ]
 [-0.71025294 -0.03285115  0.        ]]
transform [[ 0.69490695  0.12684931  0.        ]
 [-0.11245066  0.99137789  0.        ]
 [-0.71025294 -0.03285115  0.        ]]
transform [[ 0.69490695  0.12684931  0.        ]
 [-0.11245066  0.99137789  0.        ]
 [-0.71025294 -0.03285115  0.        ]]
support
[0. 0. 0.]
[-324.24013469  771.60990552  400.19396985]
[ -58.39224733 -530.55376491    8.02474494]
[0. 0. 0.]
transform [[ 0.69490695 -0.11245066 -0.71025294]
 [ 0.12684931  0.99137789 -0.03285115]
 [ 0.          0.          0.        ]]
zmp [ 7574040.28848098 21528115.136897          0.        ]
d1:30121764.80936, d2:0.02703, d3:4766483.93218
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-121.4950011399127 steps:111[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 562, in connect
    self.read_header()
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 657, in read_header
    self._validate_header(read_ros_handshake_header(sock, self.read_buff, self.protocol.buff_size))
  File "/opt/ros/noetic/lib/python3/dist-packages/rosgraph/network.py", line 357, in read_ros_handshake_header
    d = sock.recv(buff_size)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1023, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 104] Connection reset by peer
2021-05-04 15:30:58.907932: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:30:58.907967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620122466.012545146, 1.340000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620122466.015200384, 1.340000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620122466.015483512, 1.340000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620122467.883760297, 2.632000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620122468.947511256, 3.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620122470.016902501, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620122471.075413624, 5.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[-0.70163155 -0.02801996  0.        ]
 [-0.04458555  0.99899489  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
planes
[[ 0.71198881 -0.70163155 -0.02801996]
 [-0.00462203 -0.04458555  0.99899489]
 [-0.70217562 -0.71114367 -0.03498737]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70163155 -0.02801996  0.        ]
 [-0.04458555  0.99899489  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70163155 -0.02801996  0.        ]
 [-0.04458555  0.99899489  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70163155 -0.02801996  0.        ]
 [-0.04458555  0.99899489  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
support
[0. 0. 0.]
[-7.29651503e-09  9.54409339e-09 -7.46131044e-09]
[-7.29651503e-09  9.54409339e-09 -7.46131044e-09]
[0. 0. 0.]
transform [[-0.70163155 -0.04458555 -0.71114367]
 [-0.02801996  0.99899489 -0.03498737]
 [ 0.          0.          0.        ]]
zmp [35897388.34840074  1791681.64515564        0.        ]
d1:37907240.81344, d2:0.04376, d3:12663737.53223
transform [[-0.70068926 -0.04645162  0.        ]
 [-0.05752655  0.99830765  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
planes
[[ 0.71195287 -0.70068926 -0.04645162]
 [ 0.0085185  -0.05752655  0.99830765]
 [-0.70217562 -0.71114367 -0.03498737]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70068926 -0.04645162  0.        ]
 [-0.05752655  0.99830765  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70068926 -0.04645162  0.        ]
 [-0.05752655  0.99830765  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70068926 -0.04645162  0.        ]
 [-0.05752655  0.99830765  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
support
[0. 0. 0.]
[-7.47140877e-09  9.40781090e-09 -7.46131044e-09]
[-7.47140877e-09  9.40781090e-09 -7.46131044e-09]
[0. 0. 0.]
transform [[-0.70068926 -0.05752655 -0.71114367]
 [-0.04645162  0.99830765 -0.03498737]
 [ 0.          0.          0.        ]]
zmp [35897057.7333277   1791664.11170749        0.        ]
d1:37906890.69091, d2:0.04376, d3:12663620.55679
transform [[-0.70297825  0.02144386  0.        ]
 [-0.00981475  0.99915773  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
planes
[[ 0.71088803 -0.70297825  0.02144386]
 [-0.03984503 -0.00981475  0.99915773]
 [-0.70217562 -0.71114367 -0.03498737]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70297825  0.02144386  0.        ]
 [-0.00981475  0.99915773  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70297825  0.02144386  0.        ]
 [-0.00981475  0.99915773  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70297825  0.02144386  0.        ]
 [-0.00981475  0.99915773  0.        ]
 [-0.71114367 -0.03498737  0.        ]]
support
[0. 0. 0.]
[-6.81534395e-09  9.89342978e-09 -7.46131044e-09]
[-6.81534395e-09  9.89342978e-09 -7.46131044e-09]
[0. 0. 0.]
transform [[-0.70297825 -0.00981475 -0.71114367]
 [ 0.02144386  0.99915773 -0.03498737]
 [ 0.          0.          0.        ]]
zmp [35898276.67383243  1791685.7378019         0.        ]
d1:37908140.00862, d2:0.04383, d3:12664037.56148
transform [[-0.70076764  0.11563101  0.        ]
 [ 0.0565637   0.9926759   0.        ]
 [-0.71114367 -0.03498737  0.        ]]
planes
[[ 0.70395613 -0.70076764  0.11563101]
 [-0.10674828  0.0565637   0.9926759 ]
 [-0.70217562 -0.71114367 -0.03498737]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[-0.70076764  0.11563101  0.        ]
 [ 0.0565637   0.9926759   0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70076764  0.11563101  0.        ]
 [ 0.0565637   0.9926759   0.        ]
 [-0.71114367 -0.03498737  0.        ]]
transform [[-0.70076764  0.11563101  0.        ]
 [ 0.0565637   0.9926759   0.        ]
 [-0.71114367 -0.03498737  0.        ]]
support
[0. 0. 0.]
[-5.85136622e-09  1.04923960e-08 -7.46131044e-09]
[-5.85136622e-09  1.04923960e-08 -7.46131044e-09]
[0. 0. 0.]
transform [[-0.70076764  0.0565637  -0.71114367]
 [ 0.11563101  0.9926759  -0.03498737]
 [ 0.          0.          0.        ]]
zmp [35899972.54401502  1791519.99245848        0.        ]
d1:37909689.01539, d2:0.04419, d3:12664552.76088
transform [[ 0.66589677  0.57024467  0.        ]
 [-0.37344185  0.81297487  0.        ]
 [-0.6458503   0.11786834  0.        ]]
planes
[[ 0.48104319  0.66589677  0.57024467]
 [-0.44678083 -0.37344185  0.81297487]
 [ 0.75431061 -0.6458503   0.11786834]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[ 0.66589677  0.57024467  0.        ]
 [-0.37344185  0.81297487  0.        ]
 [-0.6458503   0.11786834  0.        ]]
transform [[ 0.66589677  0.57024467  0.        ]
 [-0.37344185  0.81297487  0.        ]
 [-0.6458503   0.11786834  0.        ]]
transform [[ 0.66589677  0.57024467  0.        ]
 [-0.37344185  0.81297487  0.        ]
 [-0.6458503   0.11786834  0.        ]]
support
[0. 0. 0.]
[120.51961489 144.34716564   8.63890793]
[  57.17240946 -103.31972142  -97.65694407]
[0. 0. 0.]
transform [[ 0.66589677 -0.37344185 -0.6458503 ]
 [ 0.57024467  0.81297487  0.11786834]
 [ 0.          0.          0.        ]]
zmp [-9800792.14085694 10900207.48319639        0.        ]
d1:24432093.03329, d2:0.05850, d3:6906557.18222
transform [[ 0.71935362  0.42491838  0.        ]
 [-0.25574914  0.89752525  0.        ]
 [-0.6458503   0.11786834  0.        ]]
planes
[[ 0.54952234  0.71935362  0.42491838]
 [-0.35922268 -0.25574914  0.89752525]
 [ 0.75431061 -0.6458503   0.11786834]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[ 0.71935362  0.42491838  0.        ]
 [-0.25574914  0.89752525  0.        ]
 [-0.6458503   0.11786834  0.        ]]
transform [[ 0.71935362  0.42491838  0.        ]
 [-0.25574914  0.89752525  0.        ]
 [-0.6458503   0.11786834  0.        ]]
transform [[ 0.71935362  0.42491838  0.        ]
 [-0.25574914  0.89752525  0.        ]
 [-0.6458503   0.11786834  0.        ]]
support
[0. 0. 0.]
[ 94.44010281 162.61042979   8.63890793]
[ 73.78346268 -92.19353752 -97.65694407]
[0. 0. 0.]
transform [[ 0.71935362 -0.25574914 -0.6458503 ]
 [ 0.42491838  0.89752525  0.11786834]
 [ 0.          0.          0.        ]]
zmp [-8361032.99008478 11934529.87853704        0.        ]
d1:23896062.72866, d2:0.05713, d3:6766254.01512
transform [[ 0.39459556  0.66316426  0.        ]
 [-0.62047309  0.70284015  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
planes
[[ 0.6360091   0.39459556  0.66316426]
 [-0.34789202 -0.62047309  0.70284015]
 [ 0.68881315 -0.67772233 -0.25734997]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[ 0.39459556  0.66316426  0.        ]
 [-0.62047309  0.70284015  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39459556  0.66316426  0.        ]
 [-0.62047309  0.70284015  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39459556  0.66316426  0.        ]
 [-0.62047309  0.70284015  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
support
[0. 0. 0.]
[132.26972801 118.61098969 -62.2243324 ]
[  13.41933189 -130.90856319  -78.50731034]
[0. 0. 0.]
transform [[ 0.39459556 -0.62047309 -0.67772233]
 [ 0.66316426  0.70284015 -0.25734997]
 [ 0.          0.          0.        ]]
zmp [-368320.52116735    4061.99466916       0.        ]
d1:195246.09676, d2:0.04605, d3:191432.61314
transform [[ 0.39578509  0.66181475  0.        ]
 [-0.61971503  0.70411104  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
planes
[[ 0.63667536  0.39578509  0.66181475]
 [-0.34667131 -0.61971503  0.70411104]
 [ 0.68881315 -0.67772233 -0.25734997]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[ 0.39578509  0.66181475  0.        ]
 [-0.61971503  0.70411104  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39578509  0.66181475  0.        ]
 [-0.61971503  0.70411104  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39578509  0.66181475  0.        ]
 [-0.61971503  0.70411104  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
support
[0. 0. 0.]
[132.04194756 118.86451022 -62.2243324 ]
[  13.67043134 -130.88258818  -78.50731034]
[0. 0. 0.]
transform [[ 0.39578509 -0.61971503 -0.67772233]
 [ 0.66181475  0.70411104 -0.25734997]
 [ 0.          0.          0.        ]]
zmp [-368204.26378743    4256.90311925       0.        ]
d1:195557.34161, d2:0.04603, d3:191406.35942
transform [[ 0.39958563  0.65747565  0.        ]
 [-0.6172713   0.70816439  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
planes
[[ 0.63879353  0.39958563  0.65747565]
 [-0.34275255 -0.6172713   0.70816439]
 [ 0.68881315 -0.67772233 -0.25734997]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[ 0.39958563  0.65747565  0.        ]
 [-0.6172713   0.70816439  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39958563  0.65747565  0.        ]
 [-0.6172713   0.70816439  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
transform [[ 0.39958563  0.65747565  0.        ]
 [-0.6172713   0.70816439  0.        ]
 [-0.67772233 -0.25734997  0.        ]]
support
[0. 0. 0.]
[131.30905903 119.67362428 -62.2243324 ]
[  14.47441788 -130.79610911  -78.50731034]
[0. 0. 0.]
transform [[ 0.39958563 -0.6172713  -0.67772233]
 [ 0.65747565  0.70816439 -0.25734997]
 [ 0.          0.          0.        ]]
zmp [-367829.48502115    4878.54066341       0.        ]
d1:196548.17454, d2:0.04596, d3:191320.56036
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[-0.23003845 -0.95536959  0.        ]
 [-0.64062303  0.29202259  0.        ]
 [-0.73258758  0.04462999  0.        ]]
planes
[[ 0.1853411  -0.23003845 -0.95536959]
 [ 0.71015847 -0.64062303  0.29202259]
 [-0.6792081  -0.73258758  0.04462999]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[-0.23003845 -0.95536959  0.        ]
 [-0.64062303  0.29202259  0.        ]
 [-0.73258758  0.04462999  0.        ]]
transform [[-0.23003845 -0.95536959  0.        ]
 [-0.64062303  0.29202259  0.        ]
 [-0.73258758  0.04462999  0.        ]]
transform [[-0.23003845 -0.95536959  0.        ]
 [-0.64062303  0.29202259  0.        ]
 [-0.73258758  0.04462999  0.        ]]
support
[0. 0. 0.]
[-183.52207337   41.33077883   -6.86502699]
[  27.95477095 -107.88168065 -105.16941028]
[0. 0. 0.]
transform [[-0.23003845 -0.64062303 -0.73258758]
 [-0.95536959  0.29202259  0.04462999]
 [ 0.          0.          0.        ]]
zmp [-11397403.6193546    6129877.40350155         0.        ]
d1:16509139.18888, d2:0.05716, d3:1615654.87327
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[-0.2449239  -0.94762343  0.        ]
 [-0.63451523  0.31653202  0.        ]
 [-0.73307759  0.04263021  0.        ]]
planes
[[ 0.20499302 -0.2449239  -0.94762343]
 [ 0.70512271 -0.63451523  0.31653202]
 [-0.67880774 -0.73307759  0.04263021]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[-0.2449239  -0.94762343  0.        ]
 [-0.63451523  0.31653202  0.        ]
 [-0.73307759  0.04263021  0.        ]]
transform [[-0.2449239  -0.94762343  0.        ]
 [-0.63451523  0.31653202  0.        ]
 [-0.73307759  0.04263021  0.        ]]
transform [[-0.2449239  -0.94762343  0.        ]
 [-0.63451523  0.31653202  0.        ]
 [-0.73307759  0.04263021  0.        ]]
support
[0. 0. 0.]
[-182.38196406   46.04321162   -7.24935127]
[  25.38760677 -108.57001647 -105.11208227]
[0. 0. 0.]
transform [[-0.2449239  -0.63451523 -0.73307759]
 [-0.94762343  0.31653202  0.04263021]
 [ 0.          0.          0.        ]]
zmp [-24755516.76260307  11667433.64076003         0.        ]
d1:34600643.50059, d2:0.05685, d3:4528582.87347
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:71.27080547065225[00m
[RDDPG] Resetting Environment
transform [[-0.66728407  0.14643125  0.        ]
 [ 0.21148925  0.97737652  0.        ]
 [-0.71414584  0.15262061  0.        ]]
planes
[[ 0.73026705 -0.66728407  0.14643125]
 [-0.00273197  0.21148925  0.97737652]
 [-0.68315637 -0.71414584  0.15262061]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 20.76892 187.09453 130.28973]
[139.72660272 -62.90472553  68.39656305]
[ 0.   0.  -9.8]
transform [[-0.66728407  0.14643125  0.        ]
 [ 0.21148925  0.97737652  0.        ]
 [-0.71414584  0.15262061  0.        ]]
transform [[-0.66728407  0.14643125  0.        ]
 [ 0.21148925  0.97737652  0.        ]
 [-0.71414584  0.15262061  0.        ]]
transform [[-0.66728407  0.14643125  0.        ]
 [ 0.21148925  0.97737652  0.        ]
 [-0.71414584  0.15262061  0.        ]]
support
[0. 0. 0.]
[ 13.53771598 187.25420241  13.72244325]
[-102.44855409  -31.93092801 -109.38572977]
[0. 0. 0.]
transform [[-0.66728407  0.21148925 -0.71414584]
 [ 0.14643125  0.97737652  0.15262061]
 [ 0.          0.          0.        ]]
zmp [ 3936210.45748521 32783071.29009918        0.        ]
d1:35659909.47727, d2:0.04858, d3:12054962.67746
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-183.20811377314783 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-215.83715636719188 steps:3[00m
[RDDPG] Resetting Environment
transform [[ 0.69322425  0.07112309  0.        ]
 [-0.06531961  0.99722362  0.        ]
 [-0.71775585 -0.02206042  0.        ]]
planes
[[ 0.71720403  0.69322425  0.07112309]
 [-0.03575619 -0.06531961  0.99722362]
 [ 0.69594538 -0.71775585 -0.02206042]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1396.8418  -182.3317  1847.823 ]
[  -0.7297048  -414.72662237  -12.16711983]
[ 0.   0.  -9.8]
transform [[ 0.69322425  0.07112309  0.        ]
 [-0.06531961  0.99722362  0.        ]
 [-0.71775585 -0.02206042  0.        ]]
transform [[ 0.69322425  0.07112309  0.        ]
 [-0.06531961  0.99722362  0.        ]
 [-0.71775585 -0.02206042  0.        ]]
transform [[ 0.69322425  0.07112309  0.        ]
 [-0.06531961  0.99722362  0.        ]
 [-0.71775585 -0.02206042  0.        ]]
support
[0. 0. 0.]
[-981.29260163  -90.58430762 1006.61369153]
[ -30.00248626 -413.52751783    9.67279506]
[0. 0. 0.]
transform [[ 0.69322425 -0.06531961 -0.71775585]
 [ 0.07112309  0.99722362 -0.02206042]
 [ 0.          0.          0.        ]]
zmp [17040966.57025355 10441389.59270231        0.        ]
d1:27395416.60163, d2:0.01353, d3:2137042.37754
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-144.25143204286994 steps:5[00m
[RDDPG] Resetting Environment
transform [[-0.09200032  0.99498218  0.        ]
 [ 0.69639629  0.092519    0.        ]
 [-0.71173602 -0.03808827  0.        ]]
planes
[[ 0.03932458 -0.09200032  0.99498218]
 [-0.71166879  0.69639629  0.092519  ]
 [-0.70141375 -0.71173602 -0.03808827]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1396.8418  -182.3317  1847.823 ]
[  -0.7297048  -414.72662237  -12.16711983]
[ 0.   0.  -9.8]
transform [[-0.09200032  0.99498218  0.        ]
 [ 0.69639629  0.092519    0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.09200032  0.99498218  0.        ]
 [ 0.69639629  0.092519    0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.09200032  0.99498218  0.        ]
 [ 0.69639629  0.092519    0.        ]
 [-0.71173602 -0.03808827  0.        ]]
support
[0. 0. 0.]
[ -52.9068954  -989.62459299 1001.12732395]
[-412.57846699  -38.87825616   16.31557502]
[0. 0. 0.]
transform [[-0.09200032  0.69639629 -0.71173602]
 [ 0.99498218  0.092519   -0.03808827]
 [ 0.          0.          0.        ]]
zmp [6941618.21235415  156622.11224446       0.        ]
d1:7204940.70384, d2:0.05936, d3:2372382.02462
transform [[-0.10519409 -0.98148954  0.        ]
 [-0.69452584  0.18769021  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
planes
[[ 0.16003917 -0.10519409 -0.98148954]
 [ 0.69455481 -0.69452584  0.18769021]
 [-0.70141375 -0.71173602 -0.03808827]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1396.8418  -182.3317  1847.823 ]
[  -0.7297048  -414.72662237  -12.16711983]
[ 0.   0.  -9.8]
transform [[-0.10519409 -0.98148954  0.        ]
 [-0.69452584  0.18769021  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.10519409 -0.98148954  0.        ]
 [-0.69452584  0.18769021  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.10519409 -0.98148954  0.        ]
 [-0.69452584  0.18769021  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
support
[0. 0. 0.]
[ 325.89615605  935.92084455 1001.12732395]
[407.1266021  -77.33332938  16.31557502]
[0. 0. 0.]
transform [[-0.10519409 -0.69452584 -0.71173602]
 [-0.98148954  0.18769021 -0.03808827]
 [ 0.          0.          0.        ]]
zmp [12350466.65989779  -213468.06767326        0.        ]
d1:12555466.90583, d2:0.05862, d3:4064470.63287
transform [[-0.17131421 -0.95896637  0.        ]
 [-0.68123662  0.28094989  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
planes
[[ 0.22590926 -0.17131421 -0.95896637]
 [ 0.67600584 -0.68123662  0.28094989]
 [-0.70141375 -0.71173602 -0.03808827]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1396.8418  -182.3317  1847.823 ]
[  -0.7297048  -414.72662237  -12.16711983]
[ 0.   0.  -9.8]
transform [[-0.17131421 -0.95896637  0.        ]
 [-0.68123662  0.28094989  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.17131421 -0.95896637  0.        ]
 [-0.68123662  0.28094989  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
transform [[-0.17131421 -0.95896637  0.        ]
 [-0.68123662  0.28094989  0.        ]
 [-0.71173602 -0.03808827  0.        ]]
support
[0. 0. 0.]
[ 414.14881353  900.35372105 1001.12732395]
[ 397.83389422 -116.02029755   16.31557502]
[0. 0. 0.]
transform [[-0.17131421 -0.68123662 -0.71173602]
 [-0.95896637  0.28094989 -0.03808827]
 [ 0.          0.          0.        ]]
zmp [12298789.21485056  -576124.89976633        0.        ]
d1:12749679.07610, d2:0.05776, d3:3937761.37494
transform [[ 0.26684931  0.92457986  0.        ]
 [-0.27392089  0.34328428  0.        ]
 [-0.92399073  0.16525136  0.        ]]
planes
[[ 0.27192569  0.26684931  0.92457986]
 [-0.89840037 -0.27392089  0.34328428]
 [ 0.34486693 -0.92399073  0.16525136]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-213.41406 -550.1641    90.16352]
[-67.06828235  47.72265243  28.58591651]
[ 0.   0.  -9.8]
transform [[ 0.26684931  0.92457986  0.        ]
 [-0.27392089  0.34328428  0.        ]
 [-0.92399073  0.16525136  0.        ]]
transform [[ 0.26684931  0.92457986  0.        ]
 [-0.27392089  0.34328428  0.        ]
 [-0.92399073  0.16525136  0.        ]]
transform [[ 0.26684931  0.92457986  0.        ]
 [-0.27392089  0.34328428  0.        ]
 [-0.92399073  0.16525136  0.        ]]
support
[0. 0. 0.]
[-565.6200628  -130.40412382  106.27724537]
[26.22627843 34.75384017 69.85670412]
[0. 0. 0.]
transform [[ 0.26684931 -0.27392089 -0.92399073]
 [ 0.92457986  0.34328428  0.16525136]
 [ 0.          0.          0.        ]]
zmp [-46354231.81380513  19451740.19113396         0.        ]
d1:55243529.26600, d2:0.05875, d3:22113956.27163
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-594.6131492717761 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-136.0305382031301 steps:11[00m
[RDDPG] Resetting Environment
transform [[-0.17510569 -0.94704908  0.        ]
 [-0.69643581  0.31237203  0.        ]
 [-0.69592756 -0.07430851  0.        ]]
planes
[[ 0.26913941 -0.17510569 -0.94704908]
 [ 0.64606577 -0.69643581  0.31237203]
 [-0.714257   -0.69592756 -0.07430851]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-213.41406 -550.1641    90.16352]
[-67.06828235  47.72265243  28.58591651]
[ 0.   0.  -9.8]
transform [[-0.17510569 -0.94704908  0.        ]
 [-0.69643581  0.31237203  0.        ]
 [-0.69592756 -0.07430851  0.        ]]
transform [[-0.17510569 -0.94704908  0.        ]
 [-0.69643581  0.31237203  0.        ]
 [-0.69592756 -0.07430851  0.        ]]
transform [[-0.17510569 -0.94704908  0.        ]
 [-0.69643581  0.31237203  0.        ]
 [-0.69592756 -0.07430851  0.        ]]
support
[0. 0. 0.]
[558.40244465 -23.22668816 189.40260666]
[-33.45165622  61.61597525  43.1284667 ]
[0. 0. 0.]
transform [[-0.17510569 -0.69643581 -0.69592756]
 [-0.94704908  0.31237203 -0.07430851]
 [ 0.          0.          0.        ]]
zmp [12215831.97963    -6873610.57608579        0.        ]
d1:19136659.82118, d2:0.05627, d3:1880014.11687
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-355.93167397664166 steps:13[00m
[RDDPG] Resetting Environment
transform [[ 0.01848413  0.01140224  0.        ]
 [ 0.01161545  0.99986506  0.        ]
 [-0.9997617   0.01182747  0.        ]]
planes
[[ 0.99976414  0.01848413  0.01140224]
 [-0.01161814  0.01161545  0.99986506]
 [ 0.01834919 -0.9997617   0.01182747]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-213.41406 -550.1641    90.16352]
[-67.06828235  47.72265243  28.58591651]
[ 0.   0.  -9.8]
transform [[ 0.01848413  0.01140224  0.        ]
 [ 0.01161545  0.99986506  0.        ]
 [-0.9997617   0.01182747  0.        ]]
transform [[ 0.01848413  0.01140224  0.        ]
 [ 0.01161545  0.99986506  0.        ]
 [-0.9997617   0.01182747  0.        ]]
transform [[ 0.01848413  0.01140224  0.        ]
 [ 0.01161545  0.99986506  0.        ]
 [-0.9997617   0.01182747  0.        ]]
support
[0. 0. 0.]
[ -10.21787523 -552.56878296  206.85615907]
[-0.69555388 46.93718394 67.61673803]
[0. 0. 0.]
transform [[ 0.01848413  0.01161545 -0.9997617 ]
 [ 0.01140224  0.99986506  0.01182747]
 [ 0.          0.          0.        ]]
zmp [ -4961720.54126871 -12318680.38017495         0.        ]
d1:19199764.00137, d2:0.05468, d3:2236991.80141
transform [[ 0.2353873  -0.9291907   0.        ]
 [ 0.81889725  0.34752232  0.        ]
 [-0.52345031  0.12582929  0.        ]]
planes
[[ 0.2849519   0.2353873  -0.9291907 ]
 [ 0.45676655  0.81889725  0.34752232]
 [ 0.84271395 -0.52345031  0.12582929]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-291.04565    83.385956 -616.6773  ]
[  9.99274684 -31.81187736  -5.80618656]
[ 0.   0.  -9.8]
transform [[ 0.2353873  -0.9291907   0.        ]
 [ 0.81889725  0.34752232  0.        ]
 [-0.52345031  0.12582929  0.        ]]
transform [[ 0.2353873  -0.9291907   0.        ]
 [ 0.81889725  0.34752232  0.        ]
 [-0.52345031  0.12582929  0.        ]]
transform [[ 0.2353873  -0.9291907   0.        ]
 [ 0.81889725  0.34752232  0.        ]
 [-0.52345031  0.12582929  0.        ]]
support
[0. 0. 0.]
[-145.98990368 -209.35800446  162.8403354 ]
[31.9114661  -2.87230449 -9.23357256]
[0. 0. 0.]
transform [[ 0.2353873   0.81889725 -0.52345031]
 [-0.9291907   0.34752232  0.12582929]
 [ 0.          0.          0.        ]]
zmp [-12658344.03088759  -3695022.54288579         0.        ]
d1:15785949.55197, d2:0.05587, d3:2236586.00753
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-115.04574931616025 steps:16[00m
[RDDPG] Resetting Environment
transform [[ 0.70567149 -0.01489432  0.        ]
 [-0.00706353  0.99958146  0.        ]
 [-0.70850408 -0.02480023  0.        ]]
planes
[[ 0.70838267  0.70567149 -0.01489432]
 [ 0.0280535  -0.00706353  0.99958146]
 [ 0.70527089 -0.70850408 -0.02480023]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-371.93085  843.07733  856.4492 ]
[ -34.43382624 -378.67875067   23.16186918]
[ 0.   0.  -9.8]
transform [[ 0.70567149 -0.01489432  0.        ]
 [-0.00706353  0.99958146  0.        ]
 [-0.70850408 -0.02480023  0.        ]]
transform [[ 0.70567149 -0.01489432  0.        ]
 [-0.00706353  0.99958146  0.        ]
 [-0.70850408 -0.02480023  0.        ]]
transform [[ 0.70567149 -0.01489432  0.        ]
 [-0.00706353  0.99958146  0.        ]
 [-0.70850408 -0.02480023  0.        ]]
support
[0. 0. 0.]
[-275.0180542   845.35161054  242.60600827]
[ -18.65880883 -378.27703274   33.78782786]
[0. 0. 0.]
transform [[ 0.70567149 -0.00706353 -0.70850408]
 [-0.01489432  0.99958146 -0.02480023]
 [ 0.          0.          0.        ]]
zmp [  -121229.35404738 -18532487.01746571         0.        ]
d1:20216408.03511, d2:0.04181, d3:5942094.97646
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-211.8615971423559 steps:18[00m
[RDDPG] Resetting Environment
transform [[ 0.29555193 -0.90896833  0.        ]
 [ 0.63751674  0.4168452   0.        ]
 [-0.71149242 -0.00407813  0.        ]]
planes
[[ 0.29398236  0.29555193 -0.90896833]
 [ 0.64792943  0.63751674  0.4168452 ]
 [ 0.70268196 -0.71149242 -0.00407813]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-242.01825  238.74503 -978.89514]
[  16.67526144 -121.87645343  -36.28085496]
[ 0.   0.  -9.8]
transform [[ 0.29555193 -0.90896833  0.        ]
 [ 0.63751674  0.4168452   0.        ]
 [-0.71149242 -0.00407813  0.        ]]
transform [[ 0.29555193 -0.90896833  0.        ]
 [ 0.63751674  0.4168452   0.        ]
 [-0.71149242 -0.00407813  0.        ]]
transform [[ 0.29555193 -0.90896833  0.        ]
 [ 0.63751674  0.4168452   0.        ]
 [-0.71149242 -0.00407813  0.        ]]
support
[0. 0. 0.]
[-288.54062686  -54.77096618  171.22051732]
[115.7102419  -40.17285664 -11.36729445]
[0. 0. 0.]
transform [[ 0.29555193  0.63751674 -0.71149242]
 [-0.90896833  0.4168452  -0.00407813]
 [ 0.          0.          0.        ]]
zmp [5642191.1104158  2799264.47525512       0.        ]
d1:8583454.18871, d2:0.05458, d3:1013424.21769
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-317.79518403106533 steps:20[00m
[RDDPG] Resetting Environment
transform [[ 0.70508516 -0.2002794   0.        ]
 [ 0.13054818  0.97955203  0.        ]
 [-0.69700223 -0.0191324   0.        ]]
planes
[[ 0.68025219  0.70508516 -0.2002794 ]
 [ 0.15308516  0.13054818  0.97955203]
 [ 0.71681374 -0.69700223 -0.0191324 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 225.02263  165.01604 -409.52756]
[  69.31621458 -267.69751644  -12.54598281]
[ 0.   0.  -9.8]
transform [[ 0.70508516 -0.2002794   0.        ]
 [ 0.13054818  0.97955203  0.        ]
 [-0.69700223 -0.0191324   0.        ]]
transform [[ 0.70508516 -0.2002794   0.        ]
 [ 0.13054818  0.97955203  0.        ]
 [-0.69700223 -0.0191324   0.        ]]
transform [[ 0.70508516 -0.2002794   0.        ]
 [ 0.13054818  0.97955203  0.        ]
 [-0.69700223 -0.0191324   0.        ]]
support
[0. 0. 0.]
[ 125.61080301  191.01808856 -159.99842673]
[ 102.48813204 -253.17454021  -43.19186133]
[0. 0. 0.]
transform [[ 0.70508516  0.13054818 -0.69700223]
 [-0.2002794   0.97955203 -0.0191324 ]
 [ 0.          0.          0.        ]]
zmp [17392954.00644167  6869257.85211108        0.        ]
d1:24306390.91844, d2:0.02689, d3:3653384.06066
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-317.82670033771643 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-189.71504894531964 steps:23[00m
[RDDPG] Resetting Environment
transform [[-0.15074115 -0.97382456  0.        ]
 [-0.68335629  0.22700197  0.        ]
 [-0.71435374 -0.01165781  0.        ]]
planes
[[ 0.17012614 -0.15074115 -0.97382456]
 [ 0.6938979  -0.68335629  0.22700197]
 [-0.69968766 -0.71435374 -0.01165781]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 225.02263  165.01604 -409.52756]
[  69.31621458 -267.69751644  -12.54598281]
[ 0.   0.  -9.8]
transform [[-0.15074115 -0.97382456  0.        ]
 [-0.68335629  0.22700197  0.        ]
 [-0.71435374 -0.01165781  0.        ]]
transform [[-0.15074115 -0.97382456  0.        ]
 [-0.68335629  0.22700197  0.        ]
 [-0.71435374 -0.01165781  0.        ]]
transform [[-0.15074115 -0.97382456  0.        ]
 [-0.68335629  0.22700197  0.        ]
 [-0.71435374 -0.01165781  0.        ]]
support
[0. 0. 0.]
[-194.61683844 -116.31166301 -162.66948208]
[ 250.24161078 -108.13553316  -46.3955304 ]
[0. 0. 0.]
transform [[-0.15074115 -0.68335629 -0.71435374]
 [-0.97382456  0.22700197 -0.01165781]
 [ 0.          0.          0.        ]]
zmp [4742028.26186994  210482.47788659       0.        ]
d1:5167024.62924, d2:0.05860, d3:1618048.20739
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-297.92397035173803 steps:25[00m
[RDDPG] Resetting Environment
transform [[-0.70077235 -0.09175478  0.        ]
 [-0.09133802  0.99507231  0.        ]
 [-0.70751369 -0.03758051  0.        ]]
planes
[[ 0.70745975 -0.70077235 -0.09175478]
 [ 0.03858238 -0.09133802  0.99507231]
 [-0.70569974 -0.70751369 -0.03758051]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 225.02263  165.01604 -409.52756]
[  69.31621458 -267.69751644  -12.54598281]
[ 0.   0.  -9.8]
transform [[-0.70077235 -0.09175478  0.        ]
 [-0.09133802  0.99507231  0.        ]
 [-0.70751369 -0.03758051  0.        ]]
transform [[-0.70077235 -0.09175478  0.        ]
 [-0.09133802  0.99507231  0.        ]
 [-0.70751369 -0.03758051  0.        ]]
transform [[-0.70077235 -0.09175478  0.        ]
 [-0.09133802  0.99507231  0.        ]
 [-0.70751369 -0.03758051  0.        ]]
support
[0. 0. 0.]
[-172.83064531  143.64976615 -165.40797704]
[ -24.01235972 -272.70959082  -38.98196189]
[0. 0. 0.]
transform [[-0.70077235 -0.09133802 -0.70751369]
 [-0.09175478  0.99507231 -0.03758051]
 [ 0.          0.          0.        ]]
zmp [ 9206008.28680559 -8827039.60128294        0.        ]
d1:17366969.27241, d2:0.00553, d3:583235.85945
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-50.31564057518353 steps:27[00m
[RDDPG] Resetting Environment
transform [[-0.08157422  0.99167424  0.        ]
 [ 0.69901943  0.12818679  0.        ]
 [-0.71043473  0.01226012  0.        ]]
planes
[[ 0.09963841 -0.08157422  0.99167424]
 [-0.7035197   0.69901943  0.12818679]
 [-0.70365632 -0.71043473  0.01226012]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 225.02263  165.01604 -409.52756]
[  69.31621458 -267.69751644  -12.54598281]
[ 0.   0.  -9.8]
transform [[-0.08157422  0.99167424  0.        ]
 [ 0.69901943  0.12818679  0.        ]
 [-0.71043473  0.01226012  0.        ]]
transform [[-0.08157422  0.99167424  0.        ]
 [ 0.69901943  0.12818679  0.        ]
 [-0.71043473  0.01226012  0.        ]]
transform [[-0.08157422  0.99167424  0.        ]
 [ 0.69901943  0.12818679  0.        ]
 [-0.71043473  0.01226012  0.        ]]
support
[0. 0. 0.]
[ 145.28610916  178.44806661 -157.84077498]
[-271.12314824   14.13809505  -52.52665054]
[0. 0. 0.]
transform [[-0.08157422  0.69901943 -0.71043473]
 [ 0.99167424  0.12818679  0.01226012]
 [ 0.          0.          0.        ]]
zmp [6317881.40714282 -105648.31785733       0.        ]
d1:6631028.13985, d2:0.05910, d3:2006012.27736
transform [[-0.02119389  0.98575854  0.        ]
 [-0.67057127  0.10974818  0.        ]
 [-0.7415424  -0.12741823  0.        ]]
planes
[[ 0.16682592 -0.02119389  0.98575854]
 [-0.73368227 -0.67057127  0.10974818]
 [ 0.65869534 -0.7415424  -0.12741823]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 82.706505 603.9192   684.69617 ]
[-162.54247157 -557.21977145   41.01971321]
[ 0.   0.  -9.8]
transform [[-0.02119389  0.98575854  0.        ]
 [-0.67057127  0.10974818  0.        ]
 [-0.7415424  -0.12741823  0.        ]]
transform [[-0.02119389  0.98575854  0.        ]
 [-0.67057127  0.10974818  0.        ]
 [-0.7415424  -0.12741823  0.        ]]
transform [[-0.02119389  0.98575854  0.        ]
 [-0.67057127  0.10974818  0.        ]
 [-0.7415424  -0.12741823  0.        ]]
support
[0. 0. 0.]
[ 593.56562774   10.81842446 -138.28069716]
[-545.83924279   47.84245697  191.53209405]
[0. 0. 0.]
transform [[-0.02119389 -0.67057127 -0.7415424 ]
 [ 0.98575854  0.10974818 -0.12741823]
 [ 0.          0.          0.        ]]
zmp [8300067.77021396  -46129.26342507       0.        ]
d1:9377993.39856, d2:0.05857, d3:2714148.44888
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-600.3864122208574 steps:30[00m
[RDDPG] Resetting Environment
transform [[-0.22753784 -0.95131886  0.        ]
 [-0.71008778  0.30818772  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
planes
[[ 0.20789166 -0.22753784 -0.95131886]
 [ 0.63308436 -0.71008778  0.30818772]
 [-0.74564427 -0.66633475 -0.00357067]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 82.706505 603.9192   684.69617 ]
[-162.54247157 -557.21977145   41.01971321]
[ 0.   0.  -9.8]
transform [[-0.22753784 -0.95131886  0.        ]
 [-0.71008778  0.30818772  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
transform [[-0.22753784 -0.95131886  0.        ]
 [-0.71008778  0.30818772  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
transform [[-0.22753784 -0.95131886  0.        ]
 [-0.71008778  0.30818772  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
support
[0. 0. 0.]
[-593.33857439  127.39160189  -57.26661703]
[567.07824076 -56.30887049 110.29734741]
[0. 0. 0.]
transform [[-0.22753784 -0.71008778 -0.66633475]
 [-0.95131886  0.30818772 -0.00357067]
 [ 0.          0.          0.        ]]
zmp [ 5022487.04672395 -1257180.23332193        0.        ]
d1:5788859.17354, d2:0.05741, d3:1258653.03328
transform [[-0.74562061 -0.00610565  0.        ]
 [-0.00693194  0.99997497  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
planes
[[ 0.66634279 -0.74562061 -0.00610565]
 [ 0.00140604 -0.00693194  0.99997497]
 [-0.74564427 -0.66633475 -0.00357067]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 82.706505 603.9192   684.69617 ]
[-162.54247157 -557.21977145   41.01971321]
[ 0.   0.  -9.8]
transform [[-0.74562061 -0.00610565  0.        ]
 [-0.00693194  0.99997497  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
transform [[-0.74562061 -0.00610565  0.        ]
 [-0.00693194  0.99997497  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
transform [[-0.74562061 -0.00610565  0.        ]
 [-0.00693194  0.99997497  0.        ]
 [-0.66633475 -0.00357067  0.        ]]
support
[0. 0. 0.]
[-65.35499461 603.33075474 -57.26661703]
[ 124.59720633 -556.07908796  110.29734741]
[0. 0. 0.]
transform [[-0.74562061 -0.00693194 -0.66633475]
 [-0.00610565  0.99997497 -0.00357067]
 [ 0.          0.          0.        ]]
zmp [ 2128446.29092642 -4104423.25041123        0.        ]
d1:5915056.52841, d2:0.01475, d3:679632.71855
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-654.43499818827 steps:33[00m
[RDDPG] Resetting Environment
transform [[-3.33689313e-05  9.90017414e-01  0.00000000e+00]
 [ 1.71685442e-02  1.40924826e-01  0.00000000e+00]
 [-9.99852657e-01  2.38678977e-03  0.00000000e+00]]
planes
[[ 1.40945032e-01 -3.33689313e-05  9.90017414e-01]
 [-9.89871442e-01  1.71685442e-02  1.40924826e-01]
 [-1.70018598e-02 -9.99852657e-01  2.38678977e-03]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 82.706505 603.9192   684.69617 ]
[-162.54247157 -557.21977145   41.01971321]
[ 0.   0.  -9.8]
transform [[-3.33689313e-05  9.90017414e-01  0.00000000e+00]
 [ 1.71685442e-02  1.40924826e-01  0.00000000e+00]
 [-9.99852657e-01  2.38678977e-03  0.00000000e+00]]
transform [[-3.33689313e-05  9.90017414e-01  0.00000000e+00]
 [ 1.71685442e-02  1.40924826e-01  0.00000000e+00]
 [-9.99852657e-01  2.38678977e-03  0.00000000e+00]]
transform [[-3.33689313e-05  9.90017414e-01  0.00000000e+00]
 [ 1.71685442e-02  1.40924826e-01  0.00000000e+00]
 [-9.99852657e-01  2.38678977e-03  0.00000000e+00]]
support
[0. 0. 0.]
[597.88775444  86.52715714 -81.25289048]
[-551.65185334  -81.3167171   161.18855568]
[0. 0. 0.]
transform [[-3.33689313e-05  1.71685442e-02 -9.99852657e-01]
 [ 9.90017414e-01  1.40924826e-01  2.38678977e-03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]
zmp [-2042346.9720971  -441519.5114854        0.       ]
d1:1646911.91184, d2:0.05883, d3:1017312.51206
transform [[-0.77373171  0.04118821  0.        ]
 [ 0.08730424  0.99529564  0.        ]
 [-0.62746894  0.08769345  0.        ]]
planes
[[ 0.63217312 -0.77373171  0.04118821]
 [ 0.04200688  0.08730424  0.99529564]
 [-0.77368772 -0.62746894  0.08769345]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[   7.4611187  190.27296   -615.02515  ]
[  49.62533251 -328.9347856    -6.14935891]
[ 0.   0.  -9.8]
transform [[-0.77373171  0.04118821  0.        ]
 [ 0.08730424  0.99529564  0.        ]
 [-0.62746894  0.08769345  0.        ]]
transform [[-0.77373171  0.04118821  0.        ]
 [ 0.08730424  0.99529564  0.        ]
 [-0.62746894  0.08769345  0.        ]]
transform [[-0.77373171  0.04118821  0.        ]
 [ 0.08730424  0.99529564  0.        ]
 [-0.62746894  0.08769345  0.        ]]
support
[0. 0. 0.]
[  2.06409875 190.02923999  12.00407297]
[ -51.94492842 -323.05485717  -59.98378207]
[0. 0. 0.]
transform [[-0.77373171  0.08730424 -0.62746894]
 [ 0.04118821  0.99529564  0.08769345]
 [ 0.          0.          0.        ]]
zmp [-3133526.15536467  1615768.74559302        0.        ]
d1:3927798.23345, d2:0.02377, d3:576887.73420
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-450.4527440037285 steps:36[00m
[RDDPG] Resetting Environment
transform [[ 0.38580778 -0.88294613  0.        ]
 [ 0.69539589  0.46885571  0.        ]
 [-0.60628134 -0.02409311  0.        ]]
planes
[[ 0.26750419  0.38580778 -0.88294613]
 [ 0.54460907  0.69539589  0.46885571]
 [ 0.79488528 -0.60628134 -0.02409311]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-750.95325  466.78302  286.34808]
[-146.47403043 -304.45048363   68.95629325]
[ 0.   0.  -9.8]
transform [[ 0.38580778 -0.88294613  0.        ]
 [ 0.69539589  0.46885571  0.        ]
 [-0.60628134 -0.02409311  0.        ]]
transform [[ 0.38580778 -0.88294613  0.        ]
 [ 0.69539589  0.46885571  0.        ]
 [-0.60628134 -0.02409311  0.        ]]
transform [[ 0.38580778 -0.88294613  0.        ]
 [ 0.69539589  0.46885571  0.        ]
 [-0.60628134 -0.02409311  0.        ]]
support
[0. 0. 0.]
[-701.86786971 -303.35591554  444.04268456]
[ 212.30255654 -244.60078561   96.13963162]
[0. 0. 0.]
transform [[ 0.38580778  0.69539589 -0.60628134]
 [-0.88294613  0.46885571 -0.02409311]
 [ 0.          0.          0.        ]]
zmp [ 300921.19097917 -787853.28360792       0.        ]
d1:1043955.88824, d2:0.05728, d3:359050.02234
transform [[ 0.43449354 -0.88061899  0.        ]
 [ 0.34091532  0.3550407   0.        ]
 [-0.83366191 -0.31377763  0.        ]]
planes
[[ 0.1890123   0.43449354 -0.88061899]
 [ 0.87047285  0.34091532  0.3550407 ]
 [ 0.4544794  -0.83366191 -0.31377763]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-750.95325  466.78302  286.34808]
[-146.47403043 -304.45048363   68.95629325]
[ 0.   0.  -9.8]
transform [[ 0.43449354 -0.88061899  0.        ]
 [ 0.34091532  0.3550407   0.        ]
 [-0.83366191 -0.31377763  0.        ]]
transform [[ 0.43449354 -0.88061899  0.        ]
 [ 0.34091532  0.3550407   0.        ]
 [-0.83366191 -0.31377763  0.        ]]
transform [[ 0.43449354 -0.88061899  0.        ]
 [ 0.34091532  0.3550407   0.        ]
 [-0.83366191 -0.31377763  0.        ]]
support
[0. 0. 0.]
[-737.34232737  -90.28449844  479.57505351]
[ 204.46285699 -158.02755389  217.6395704 ]
[0. 0. 0.]
transform [[ 0.43449354  0.34091532 -0.83366191]
 [-0.88061899  0.3550407  -0.31377763]
 [ 0.          0.          0.        ]]
zmp [-3739788.95258047 -2172372.17930167        0.        ]
d1:3668643.34870, d2:0.05490, d3:1781807.25398
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-265.4082679257557 steps:39[00m
[RDDPG] Resetting Environment
transform [[ 0.0354372  -0.10964029  0.        ]
 [-0.05959267  0.99196321  0.        ]
 [-0.99759358 -0.06315105  0.        ]]
planes
[[ 0.99333948  0.0354372  -0.10964029]
 [ 0.11161433 -0.05959267  0.99196321]
 [ 0.02861865 -0.99759358 -0.06315105]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-266.4403   779.74164 -280.709  ]
[-350.87408998   85.33715154 -122.14087047]
[ 0.   0.  -9.8]
transform [[ 0.0354372  -0.10964029  0.        ]
 [-0.05959267  0.99196321  0.        ]
 [-0.99759358 -0.06315105  0.        ]]
transform [[ 0.0354372  -0.10964029  0.        ]
 [-0.05959267  0.99196321  0.        ]
 [-0.99759358 -0.06315105  0.        ]]
transform [[ 0.0354372  -0.10964029  0.        ]
 [-0.05959267  0.99196321  0.        ]
 [-0.99759358 -0.06315105  0.        ]]
support
[0. 0. 0.]
[-94.93299525 789.35290539 216.55763441]
[-21.79038633 105.56083772 344.64060906]
[0. 0. 0.]
transform [[ 0.0354372  -0.05959267 -0.99759358]
 [-0.10964029  0.99196321 -0.06315105]
 [ 0.          0.          0.        ]]
zmp [24943197.18718684 -1454913.61333441        0.        ]
d1:18210695.84178, d2:0.00855, d3:11582861.49489
transform [[ 0.35926643 -0.53326601  0.        ]
 [ 0.18291242  0.84497947  0.        ]
 [-0.91513425 -0.04046107  0.        ]]
planes
[[ 0.76586878  0.35926643 -0.53326601]
 [ 0.50254631  0.18291242  0.84497947]
 [ 0.40111369 -0.91513425 -0.04046107]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-193.54512  -72.88915 -947.9448 ]
[  18.52996503 -117.61119414  -27.44009844]
[ 0.   0.  -9.8]
transform [[ 0.35926643 -0.53326601  0.        ]
 [ 0.18291242  0.84497947  0.        ]
 [-0.91513425 -0.04046107  0.        ]]
transform [[ 0.35926643 -0.53326601  0.        ]
 [ 0.18291242  0.84497947  0.        ]
 [-0.91513425 -0.04046107  0.        ]]
transform [[ 0.35926643 -0.53326601  0.        ]
 [ 0.18291242  0.84497947  0.        ]
 [-0.91513425 -0.04046107  0.        ]]
support
[0. 0. 0.]
[-30.66495703 -96.99164424 180.06894183]
[ 69.37524637 -95.98968308 -12.19873082]
[0. 0. 0.]
transform [[ 0.35926643  0.18291242 -0.91513425]
 [-0.53326601  0.84497947 -0.04046107]
 [ 0.          0.          0.        ]]
zmp [22157552.53900257 -1570269.19856118        0.        ]
d1:22659855.40038, d2:0.04005, d3:7130195.99401
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-439.07799985552776 steps:42[00m
[RDDPG] Resetting Environment
transform [[-0.27561533  0.94806886  0.        ]
 [ 0.65859044  0.3065353   0.        ]
 [-0.70021057 -0.08486173  0.        ]]
planes
[[ 0.15875015 -0.27561533  0.94806886]
 [-0.68723702  0.65859044  0.3065353 ]
 [-0.70887494 -0.70021057 -0.08486173]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-193.54512  -72.88915 -947.9448 ]
[  18.52996503 -117.61119414  -27.44009844]
[ 0.   0.  -9.8]
transform [[-0.27561533  0.94806886  0.        ]
 [ 0.65859044  0.3065353   0.        ]
 [-0.70021057 -0.08486173  0.        ]]
transform [[-0.27561533  0.94806886  0.        ]
 [ 0.65859044  0.3065353   0.        ]
 [-0.70021057 -0.08486173  0.        ]]
transform [[-0.27561533  0.94806886  0.        ]
 [ 0.65859044  0.3065353   0.        ]
 [-0.70021057 -0.08486173  0.        ]]
support
[0. 0. 0.]
[ -15.75993248 -149.81006362  141.70783847]
[-116.61065294  -23.84832535   -2.99418852]
[0. 0. 0.]
transform [[-0.27561533  0.65859044 -0.70021057]
 [ 0.94806886  0.3065353  -0.08486173]
 [ 0.          0.          0.        ]]
zmp [ -755621.07130643 -3858305.43054651        0.        ]
d1:4533268.23029, d2:0.05766, d3:1545959.23467
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-192.25493614032308 steps:44[00m
[RDDPG] Resetting Environment
transform [[ 0.6956501  -0.12027627  0.        ]
 [ 0.08656203  0.99273545  0.        ]
 [-0.71314651  0.00317325  0.        ]]
planes
[[ 0.70824051  0.6956501  -0.12027627]
 [ 0.08356713  0.08656203  0.99273545]
 [ 0.70100784 -0.71314651  0.00317325]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[755.15894 -74.4401  660.7997 ]
[  25.08894097 -344.38371764  -14.21567866]
[ 0.   0.  -9.8]
transform [[ 0.6956501  -0.12027627  0.        ]
 [ 0.08656203  0.99273545  0.        ]
 [-0.71314651  0.00317325  0.        ]]
transform [[ 0.6956501  -0.12027627  0.        ]
 [ 0.08656203  0.99273545  0.        ]
 [-0.71314651  0.00317325  0.        ]]
transform [[ 0.6956501  -0.12027627  0.        ]
 [ 0.08656203  0.99273545  0.        ]
 [-0.71314651  0.00317325  0.        ]]
support
[0. 0. 0.]
[ 534.2797675    -8.531237   -538.77517452]
[  58.87431411 -339.71017369  -18.98490531]
[0. 0. 0.]
transform [[ 0.6956501   0.08656203 -0.71314651]
 [-0.12027627  0.99273545  0.00317325]
 [ 0.          0.          0.        ]]
zmp [ 10188674.37045927 -14619377.98084818         0.        ]
d1:25244036.74180, d2:0.05858, d3:8146993.72621
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-231.7308126759081 steps:46[00m
[RDDPG] Resetting Environment
transform [[-0.2155219   0.95376778  0.        ]
 [ 0.6696521   0.30048266  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
planes
[[ 0.20946938 -0.2155219   0.95376778]
 [-0.67917317  0.6696521   0.30048266]
 [-0.70345318 -0.71071541 -0.00610508]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[755.15894 -74.4401  660.7997 ]
[  25.08894097 -344.38371764  -14.21567866]
[ 0.   0.  -9.8]
transform [[-0.2155219   0.95376778  0.        ]
 [ 0.6696521   0.30048266  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
transform [[-0.2155219   0.95376778  0.        ]
 [ 0.6696521   0.30048266  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
transform [[-0.2155219   0.95376778  0.        ]
 [ 0.6696521   0.30048266  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
support
[0. 0. 0.]
[-233.75186019  483.32581054 -536.24863217]
[-333.86930891  -86.6804736   -15.72860746]
[0. 0. 0.]
transform [[-0.2155219   0.6696521  -0.71071541]
 [ 0.95376778  0.30048266 -0.00610508]
 [ 0.          0.          0.        ]]
zmp [4592192.949722    301274.49275341       0.        ]
d1:4879507.94568, d2:0.05826, d3:1590305.34757
transform [[-0.69101954  0.19342963  0.        ]
 [ 0.13181667  0.98109519  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
planes
[[ 0.69647467 -0.69101954  0.19342963]
 [-0.14169215  0.13181667  0.98109519]
 [-0.70345318 -0.71071541 -0.00610508]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[755.15894 -74.4401  660.7997 ]
[  25.08894097 -344.38371764  -14.21567866]
[ 0.   0.  -9.8]
transform [[-0.69101954  0.19342963  0.        ]
 [ 0.13181667  0.98109519  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
transform [[-0.69101954  0.19342963  0.        ]
 [ 0.13181667  0.98109519  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
transform [[-0.69101954  0.19342963  0.        ]
 [ 0.13181667  0.98109519  0.        ]
 [-0.71071541 -0.00610508  0.        ]]
support
[0. 0. 0.]
[-536.22849815   26.50971043 -536.24863217]
[ -83.95096478 -334.56606989  -15.72860746]
[0. 0. 0.]
transform [[-0.69101954  0.13181667 -0.71071541]
 [ 0.19342963  0.98109519 -0.00610508]
 [ 0.          0.          0.        ]]
zmp [4114399.98022433  905905.13513796       0.        ]
d1:5005479.50557, d2:0.05031, d3:1629686.37475
transform [[-0.35134721 -0.84865439  0.        ]
 [-0.16179898  0.47100875  0.        ]
 [-0.92215848  0.2407001   0.        ]]
planes
[[ 0.39539969 -0.35134721 -0.84865439]
 [ 0.86716318 -0.16179898  0.47100875]
 [-0.30279902 -0.92215848  0.2407001 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[755.15894 -74.4401  660.7997 ]
[  25.08894097 -344.38371764  -14.21567866]
[ 0.   0.  -9.8]
transform [[-0.35134721 -0.84865439  0.        ]
 [-0.16179898  0.47100875  0.        ]
 [-0.92215848  0.2407001   0.        ]]
transform [[-0.35134721 -0.84865439  0.        ]
 [-0.16179898  0.47100875  0.        ]
 [-0.92215848  0.2407001   0.        ]]
transform [[-0.35134721 -0.84865439  0.        ]
 [-0.16179898  0.47100875  0.        ]
 [-0.92215848  0.2407001   0.        ]]
support
[0. 0. 0.]
[-202.14906463 -157.24588744 -714.29395553]
[ 283.44782424 -166.26710877 -106.02917352]
[0. 0. 0.]
transform [[-0.35134721 -0.16179898 -0.92215848]
 [-0.84865439  0.47100875  0.2407001 ]
 [ 0.          0.          0.        ]]
zmp [8299873.11949243 6851937.68053436       0.        ]
d1:5462983.23084, d2:0.05920, d3:3811098.23755
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-832.5331027160913 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-131.3902882031243 steps:51[00m
[RDDPG] Resetting Environment
transform [[ 0.72402436 -0.10266928  0.        ]
 [ 0.05831601  0.99443132  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
planes
[[ 0.68209082  0.72402436 -0.10266928]
 [ 0.08778205  0.05831601  0.99443132]
 [ 0.72597969 -0.68730497 -0.02377952]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 231.88544 -840.2816   717.1151 ]
[   6.62272028 -264.5168022   -38.01932442]
[ 0.   0.  -9.8]
transform [[ 0.72402436 -0.10266928  0.        ]
 [ 0.05831601  0.99443132  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
transform [[ 0.72402436 -0.10266928  0.        ]
 [ 0.05831601  0.99443132  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
transform [[ 0.72402436 -0.10266928  0.        ]
 [ 0.05831601  0.99443132  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
support
[0. 0. 0.]
[ 254.16180948 -822.07972044 -139.39452159]
[  31.95275943 -262.65758131    1.73825371]
[0. 0. 0.]
transform [[ 0.72402436  0.05831601 -0.68730497]
 [-0.10266928  0.99443132 -0.02377952]
 [ 0.          0.          0.        ]]
zmp [10285861.02832316 -8745286.63925142        0.        ]
d1:18356540.50872, d2:0.05932, d3:6173318.79574
transform [[ 0.69241446  0.28055808  0.        ]
 [-0.21948613  0.95954251  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
planes
[[ 0.66471756  0.69241446  0.28055808]
 [-0.17636369 -0.21948613  0.95954251]
 [ 0.72597969 -0.68730497 -0.02377952]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 231.88544 -840.2816   717.1151 ]
[   6.62272028 -264.5168022   -38.01932442]
[ 0.   0.  -9.8]
transform [[ 0.69241446  0.28055808  0.        ]
 [-0.21948613  0.95954251  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
transform [[ 0.69241446  0.28055808  0.        ]
 [-0.21948613  0.95954251  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
transform [[ 0.69241446  0.28055808  0.        ]
 [-0.21948613  0.95954251  0.        ]
 [-0.68730497 -0.02377952  0.        ]]
support
[0. 0. 0.]
[ -75.18696622 -857.18157126 -139.39452159]
[ -69.62665871 -255.26871234    1.73825371]
[0. 0. 0.]
transform [[ 0.69241446 -0.21948613 -0.68730497]
 [ 0.28055808  0.95954251 -0.02377952]
 [ 0.          0.          0.        ]]
zmp [12833506.70681805 -8425330.87955655        0.        ]
d1:20575019.95963, d2:0.05848, d3:6922974.86173
transform [[ 0.15467852 -0.03685512  0.        ]
 [ 0.03909181  0.99874973  0.        ]
 [-0.9871912   0.03377486  0.        ]]
planes
[[ 0.98727721  0.15467852 -0.03685512]
 [ 0.03115881  0.03909181  0.99874973]
 [ 0.15592587 -0.9871912   0.03377486]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 231.88544 -840.2816   717.1151 ]
[   6.62272028 -264.5168022   -38.01932442]
[ 0.   0.  -9.8]
transform [[ 0.15467852 -0.03685512  0.        ]
 [ 0.03909181  0.99874973  0.        ]
 [-0.9871912   0.03377486  0.        ]]
transform [[ 0.15467852 -0.03685512  0.        ]
 [ 0.03909181  0.99874973  0.        ]
 [-0.9871912   0.03377486  0.        ]]
transform [[ 0.15467852 -0.03685512  0.        ]
 [ 0.03909181  0.99874973  0.        ]
 [-0.9871912   0.03377486  0.        ]]
support
[0. 0. 0.]
[  66.83638014 -830.16621737 -257.295657  ]
[  10.77319212 -263.92719141  -15.4719092 ]
[0. 0. 0.]
transform [[ 0.15467852  0.03909181 -0.9871912 ]
 [-0.03685512  0.99874973  0.03377486]
 [ 0.          0.          0.        ]]
zmp [ 28158772.72049352 -14189555.37807386         0.        ]
d1:23023857.85326, d2:0.03466, d3:13115916.68963
transform [[ 0.6232428  -0.77276886  0.        ]
 [-0.20997503 -0.31315577  0.        ]
 [-0.75331271 -0.55205148  0.        ]]
planes
[[-0.1199868   0.6232428  -0.77276886]
 [ 0.92619866 -0.20997503 -0.31315577]
 [-0.35743409 -0.75331271 -0.55205148]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  131.80396 -1282.0409   2187.1477 ]
[-426.9870901   194.40347179 -174.70580811]
[ 0.   0.  -9.8]
transform [[ 0.6232428  -0.77276886  0.        ]
 [-0.20997503 -0.31315577  0.        ]
 [-0.75331271 -0.55205148  0.        ]]
transform [[ 0.6232428  -0.77276886  0.        ]
 [-0.20997503 -0.31315577  0.        ]
 [-0.75331271 -0.55205148  0.        ]]
transform [[ 0.6232428  -0.77276886  0.        ]
 [-0.20997503 -0.31315577  0.        ]
 [-0.75331271 -0.55205148  0.        ]]
support
[0. 0. 0.]
[1072.86713891  373.80296363  608.4629844 ]
[-416.34557599   28.7780598   214.33407546]
[0. 0. 0.]
transform [[ 0.6232428  -0.20997503 -0.75331271]
 [-0.77276886 -0.31315577 -0.55205148]
 [ 0.          0.          0.        ]]
zmp [-25033783.87435819 -20225594.66636527         0.        ]
d1:17838178.08898, d2:0.05669, d3:13227954.37492
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-866.9553207474385 steps:56[00m
[RDDPG] Resetting Environment
transform [[-0.24841988  0.92084014  0.        ]
 [ 0.68274504  0.38656622  0.        ]
 [-0.68712938  0.0511857   0.        ]]
planes
[[ 0.30056778 -0.24841988  0.92084014]
 [-0.62002081  0.68274504  0.38656622]
 [-0.72472978 -0.68712938  0.0511857 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  131.80396 -1282.0409   2187.1477 ]
[-426.9870901   194.40347179 -174.70580811]
[ 0.   0.  -9.8]
transform [[-0.24841988  0.92084014  0.        ]
 [ 0.68274504  0.38656622  0.        ]
 [-0.68712938  0.0511857   0.        ]]
transform [[-0.24841988  0.92084014  0.        ]
 [ 0.68274504  0.38656622  0.        ]
 [-0.68712938  0.0511857   0.        ]]
transform [[-0.24841988  0.92084014  0.        ]
 [ 0.68274504  0.38656622  0.        ]
 [-0.68712938  0.0511857   0.        ]]
support
[0. 0. 0.]
[-1213.29744405  -405.60520779  -156.18853639]
[ 285.08660304 -216.3735021   303.34605248]
[0. 0. 0.]
transform [[-0.24841988  0.68274504 -0.68712938]
 [ 0.92084014  0.38656622  0.0511857 ]
 [ 0.          0.          0.        ]]
zmp [8153546.31347925 5747318.77763608       0.        ]
d1:14287083.90757, d2:0.05909, d3:4453658.36399
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-282.38044105413246 steps:58[00m
[RDDPG] Resetting Environment
transform [[ 0.64329243  0.35671762  0.        ]
 [-0.26441947  0.93389595  0.        ]
 [-0.71851039 -0.02430937  0.        ]]
planes
[[ 0.6774419   0.64329243  0.35671762]
 [-0.24066725 -0.26441947  0.93389595]
 [ 0.69509131 -0.71851039 -0.02430937]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 183.35939 -375.75275 1336.9841 ]
[ -12.04056708 -491.58623844    8.08743671]
[ 0.   0.  -9.8]
transform [[ 0.64329243  0.35671762  0.        ]
 [-0.26441947  0.93389595  0.        ]
 [-0.71851039 -0.02430937  0.        ]]
transform [[ 0.64329243  0.35671762  0.        ]
 [-0.26441947  0.93389595  0.        ]
 [-0.71851039 -0.02430937  0.        ]]
transform [[ 0.64329243  0.35671762  0.        ]
 [-0.26441947  0.93389595  0.        ]
 [-0.71851039 -0.02430937  0.        ]]
support
[0. 0. 0.]
[ -16.0839169  -399.39775867 -122.61131619]
[-183.10307681 -455.90663464   20.60142188]
[0. 0. 0.]
transform [[ 0.64329243 -0.26441947 -0.71851039]
 [ 0.35671762  0.93389595 -0.02430937]
 [ 0.          0.          0.        ]]
zmp [ 7856982.32272944 -6931065.51567873        0.        ]
d1:14339516.85648, d2:0.05920, d3:4769983.22152
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-398.54026485551935 steps:60[00m
[RDDPG] Resetting Environment
transform [[ 0.67726958  0.09051881  0.        ]
 [-0.07808284  0.99564129  0.        ]
 [-0.73157978 -0.02246763  0.        ]]
planes
[[ 0.73014545  0.67726958  0.09051881]
 [-0.0510051  -0.07808284  0.99564129]
 [ 0.68138552 -0.73157978 -0.02246763]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-197.65678  440.38016  867.6114 ]
[  20.59589271 -418.14536527  -59.39005434]
[ 0.   0.  -9.8]
transform [[ 0.67726958  0.09051881  0.        ]
 [-0.07808284  0.99564129  0.        ]
 [-0.73157978 -0.02246763  0.        ]]
transform [[ 0.67726958  0.09051881  0.        ]
 [-0.07808284  0.99564129  0.        ]
 [-0.73157978 -0.02246763  0.        ]]
transform [[ 0.67726958  0.09051881  0.        ]
 [-0.07808284  0.99564129  0.        ]
 [-0.73157978 -0.02246763  0.        ]]
support
[0. 0. 0.]
[-94.00423899 453.89427253 134.70740992]
[ -23.90104925 -417.93097725   -5.67280488]
[0. 0. 0.]
transform [[ 0.67726958 -0.07808284 -0.73157978]
 [ 0.09051881  0.99564129 -0.02246763]
 [ 0.          0.          0.        ]]
zmp [-7396802.41014518  -271607.49488043        0.        ]
d1:8326065.05577, d2:0.03898, d3:2157779.71405
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-261.3593891552147 steps:62[00m
[RDDPG] Resetting Environment
transform [[-0.20342237 -0.95303923  0.        ]
 [-0.67249697  0.30254689  0.        ]
 [-0.71159488 -0.01348008  0.        ]]
planes
[[ 0.22435613 -0.20342237 -0.95303923]
 [ 0.67543566 -0.67249697  0.30254689]
 [-0.70246071 -0.71159488 -0.01348008]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-197.65678  440.38016  867.6114 ]
[  20.59589271 -418.14536527  -59.39005434]
[ 0.   0.  -9.8]
transform [[-0.20342237 -0.95303923  0.        ]
 [-0.67249697  0.30254689  0.        ]
 [-0.71159488 -0.01348008  0.        ]]
transform [[-0.20342237 -0.95303923  0.        ]
 [-0.67249697  0.30254689  0.        ]
 [-0.71159488 -0.01348008  0.        ]]
transform [[-0.20342237 -0.95303923  0.        ]
 [-0.67249697  0.30254689  0.        ]
 [-0.71159488 -0.01348008  0.        ]]
support
[0. 0. 0.]
[-379.49175473  266.1592357   134.71519435]
[ 394.31927123 -140.35925477   -9.01929753]
[0. 0. 0.]
transform [[-0.20342237 -0.67249697 -0.71159488]
 [-0.95303923  0.30254689 -0.01348008]
 [ 0.          0.          0.        ]]
zmp [-3848143.91083589  4319369.74098317        0.        ]
d1:7887252.29233, d2:0.05664, d3:191514.65289
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-261.2222514121393 steps:64[00m
[RDDPG] Resetting Environment
transform [[-0.21691009 -0.95569241  0.        ]
 [-0.6560818   0.29367095  0.        ]
 [-0.72284633  0.02023553  0.        ]]
planes
[[ 0.19900276 -0.21691009 -0.95569241]
 [ 0.69520801 -0.6560818   0.29367095]
 [-0.69071257 -0.72284633  0.02023553]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-197.65678  440.38016  867.6114 ]
[  20.59589271 -418.14536527  -59.39005434]
[ 0.   0.  -9.8]
transform [[-0.21691009 -0.95569241  0.        ]
 [-0.6560818   0.29367095  0.        ]
 [-0.72284633  0.02023553  0.        ]]
transform [[-0.21691009 -0.95569241  0.        ]
 [-0.6560818   0.29367095  0.        ]
 [-0.72284633  0.02023553  0.        ]]
transform [[-0.21691009 -0.95569241  0.        ]
 [-0.6560818   0.29367095  0.        ]
 [-0.72284633  0.02023553  0.        ]]
support
[0. 0. 0.]
[-377.9942226   259.00587804  151.78680714]
[ 395.15089503 -136.3097379   -23.34905896]
[0. 0. 0.]
transform [[-0.21691009 -0.6560818  -0.72284633]
 [-0.95569241  0.29367095  0.02023553]
 [ 0.          0.          0.        ]]
zmp [16392982.94331715 -1387752.6620462         0.        ]
d1:17226485.24555, d2:0.05799, d3:5278417.63637
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-114.80510242472829 steps:66[00m
[RDDPG] Resetting Environment
transform [[ 0.52728885 -0.68134743  0.        ]
 [ 0.46051806  0.73128176  0.        ]
 [-0.71406555 -0.03150751  0.        ]]
planes
[[ 0.50767332  0.52728885 -0.68134743]
 [ 0.50314027  0.46051806  0.73128176]
 [ 0.69936949 -0.71406555 -0.03150751]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[234.30745 148.0581  634.5457 ]
[-174.44383243 -290.38265018   88.36823316]
[ 0.   0.  -9.8]
transform [[ 0.52728885 -0.68134743  0.        ]
 [ 0.46051806  0.73128176  0.        ]
 [-0.71406555 -0.03150751  0.        ]]
transform [[ 0.52728885 -0.68134743  0.        ]
 [ 0.46051806  0.73128176  0.        ]
 [-0.71406555 -0.03150751  0.        ]]
transform [[ 0.52728885 -0.68134743  0.        ]
 [ 0.46051806  0.73128176  0.        ]
 [-0.71406555 -0.03150751  0.        ]]
support
[0. 0. 0.]
[  22.66869686  216.17500407 -171.97581988]
[ 105.86918383 -292.68607039  133.71356483]
[0. 0. 0.]
transform [[ 0.52728885  0.46051806 -0.71406555]
 [-0.68134743  0.73128176 -0.03150751]
 [ 0.          0.          0.        ]]
zmp [12028615.69056102 -3935635.52663303        0.        ]
d1:15447137.33554, d2:0.05631, d3:5208545.51040
transform [[ 0.56804556  0.59771764  0.        ]
 [ 0.81636328 -0.49633244  0.        ]
 [ 0.10428447  0.62959343  0.        ]]
planes
[[ 0.56573659  0.56804556  0.59771764]
 [-0.29530504  0.81636328 -0.49633244]
 [-0.76989412  0.10428447  0.62959343]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -178.1327  -1365.6173    600.57935]
[ 481.8892473  -827.84831833 -759.59612519]
[ 0.   0.  -9.8]
transform [[ 0.56804556  0.59771764  0.        ]
 [ 0.81636328 -0.49633244  0.        ]
 [ 0.10428447  0.62959343  0.        ]]
transform [[ 0.56804556  0.59771764  0.        ]
 [ 0.81636328 -0.49633244  0.        ]
 [ 0.10428447  0.62959343  0.        ]]
transform [[ 0.56804556  0.59771764  0.        ]
 [ 0.81636328 -0.49633244  0.        ]
 [ 0.10428447  0.62959343  0.        ]]
support
[0. 0. 0.]
[-917.44105116  532.37916799 -878.36016263]
[-221.08449974  804.28465727 -470.95430138]
[0. 0. 0.]
transform [[ 0.56804556  0.81636328  0.10428447]
 [ 0.59771764 -0.49633244  0.62959343]
 [ 0.          0.          0.        ]]
zmp [-36477443.95700035  31156164.72676944         0.        ]
d1:20476960.54928, d2:0.05929, d3:2874861.92538
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-414.111120715662 steps:69[00m
[RDDPG] Resetting Environment
transform [[ 0.26023388  0.93955934  0.        ]
 [-0.65697598  0.34117469  0.        ]
 [-0.70757395  0.0287766   0.        ]]
planes
[[ 0.22250082  0.26023388  0.93955934]
 [-0.67229635 -0.65697598  0.34117469]
 [ 0.70605314 -0.70757395  0.0287766 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[168.44588   206.5881      1.6962198]
[ 48.28602533 -87.47082477 -21.16920491]
[ 0.   0.  -9.8]
transform [[ 0.26023388  0.93955934  0.        ]
 [-0.65697598  0.34117469  0.        ]
 [-0.70757395  0.0287766   0.        ]]
transform [[ 0.26023388  0.93955934  0.        ]
 [-0.65697598  0.34117469  0.        ]
 [-0.70757395  0.0287766   0.        ]]
transform [[ 0.26023388  0.93955934  0.        ]
 [-0.65697598  0.34117469  0.        ]
 [-0.70757395  0.0287766   0.        ]]
support
[0. 0. 0.]
[ 237.93710699  -40.18226312 -113.24301198]
[-69.61837076 -61.56559072 -36.68304638]
[0. 0. 0.]
transform [[ 0.26023388 -0.65697598 -0.70757395]
 [ 0.93955934  0.34117469  0.0287766 ]
 [ 0.          0.          0.        ]]
zmp [5737527.49615716  606619.76081394       0.        ]
d1:6485388.84232, d2:0.05753, d3:1817829.05139
transform [[ 0.322216    0.92460114  0.        ]
 [ 0.21558549  0.137338    0.        ]
 [-0.92179161  0.35531828  0.        ]]
planes
[[ 0.20319846  0.322216    0.92460114]
 [-0.96677876  0.21558549  0.137338  ]
 [-0.15507808 -0.92179161  0.35531828]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[168.44588   206.5881      1.6962198]
[ 48.28602533 -87.47082477 -21.16920491]
[ 0.   0.  -9.8]
transform [[ 0.322216    0.92460114  0.        ]
 [ 0.21558549  0.137338    0.        ]
 [-0.92179161  0.35531828  0.        ]]
transform [[ 0.322216    0.92460114  0.        ]
 [ 0.21558549  0.137338    0.        ]
 [-0.92179161  0.35531828  0.        ]]
transform [[ 0.322216    0.92460114  0.        ]
 [ 0.21558549  0.137338    0.        ]
 [-0.92179161  0.35531828  0.        ]]
support
[0. 0. 0.]
[245.28755363  64.68688268 -81.86746728]
[-65.31709396  -1.60330172 -75.58963601]
[0. 0. 0.]
transform [[ 0.322216    0.21558549 -0.92179161]
 [ 0.92460114  0.137338    0.35531828]
 [ 0.          0.          0.        ]]
zmp [8026772.66822441 2895862.01768086       0.        ]
d1:7511814.01621, d2:0.05665, d3:4393651.83984
transform [[ 0.32651651  0.89740056  0.        ]
 [ 0.81954902 -0.11239126  0.        ]
 [-0.47087836  0.42666206  0.        ]]
planes
[[ 0.29674786  0.32651651  0.89740056]
 [-0.56187874  0.81954902 -0.11239126]
 [-0.7721613  -0.47087836  0.42666206]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-409.02823  421.76678 1238.5775 ]
[  889.50005469 -1289.43911899   -29.97765713]
[ 0.   0.  -9.8]
transform [[ 0.32651651  0.89740056  0.        ]
 [ 0.81954902 -0.11239126  0.        ]
 [-0.47087836  0.42666206  0.        ]]
transform [[ 0.32651651  0.89740056  0.        ]
 [ 0.81954902 -0.11239126  0.        ]
 [-0.47087836  0.42666206  0.        ]]
transform [[ 0.32651651  0.89740056  0.        ]
 [ 0.81954902 -0.11239126  0.        ]
 [-0.47087836  0.42666206  0.        ]]
support
[0. 0. 0.]
[ 244.93927854 -382.62158429  372.55442683]
[-866.70693222  873.91058362 -969.00107704]
[0. 0. 0.]
transform [[ 0.32651651  0.81954902 -0.47087836]
 [ 0.89740056 -0.11239126  0.42666206]
 [ 0.          0.          0.        ]]
zmp [ -931399.38385952 -1898046.80711018        0.        ]
d1:2971684.42274, d2:0.05380, d3:936259.96155
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-696.6112794348091 steps:73[00m
[RDDPG] Resetting Environment
transform [[-0.1799539  -0.97782058  0.        ]
 [-0.67803884  0.20222762  0.        ]
 [-0.71265697  0.05450651  0.        ]]
planes
[[ 0.10716138 -0.1799539  -0.97782058]
 [ 0.70665932 -0.67803884  0.20222762]
 [-0.69939196 -0.71265697  0.05450651]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-409.02823  421.76678 1238.5775 ]
[  889.50005469 -1289.43911899   -29.97765713]
[ 0.   0.  -9.8]
transform [[-0.1799539  -0.97782058  0.        ]
 [-0.67803884  0.20222762  0.        ]
 [-0.71265697  0.05450651  0.        ]]
transform [[-0.1799539  -0.97782058  0.        ]
 [-0.67803884  0.20222762  0.        ]
 [-0.71265697  0.05450651  0.        ]]
transform [[-0.1799539  -0.97782058  0.        ]
 [-0.67803884  0.20222762  0.        ]
 [-0.71265697  0.05450651  0.        ]]
support
[0. 0. 0.]
[-338.80601381  362.62991794  314.48585422]
[1100.77109454 -863.87578838 -704.19124012]
[0. 0. 0.]
transform [[-0.1799539  -0.67803884 -0.71265697]
 [-0.97782058  0.20222762  0.05450651]
 [ 0.          0.          0.        ]]
zmp [-3704043.8207101   -157150.16888837        0.        ]
d1:3880430.14815, d2:0.05911, d3:1227527.35682
transform [[-0.02814123  0.99395317  0.        ]
 [ 0.700948    0.09532163  0.        ]
 [-0.71265697  0.05450651  0.        ]]
planes
[[ 0.10613785 -0.02814123  0.99395317]
 [-0.70681375  0.700948    0.09532163]
 [-0.69939196 -0.71265697  0.05450651]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-409.02823  421.76678 1238.5775 ]
[  889.50005469 -1289.43911899   -29.97765713]
[ 0.   0.  -9.8]
transform [[-0.02814123  0.99395317  0.        ]
 [ 0.700948    0.09532163  0.        ]
 [-0.71265697  0.05450651  0.        ]]
transform [[-0.02814123  0.99395317  0.        ]
 [ 0.700948    0.09532163  0.        ]
 [-0.71265697  0.05450651  0.        ]]
transform [[-0.02814123  0.99395317  0.        ]
 [ 0.700948    0.09532163  0.        ]
 [-0.71265697  0.05450651  0.        ]]
support
[0. 0. 0.]
[ 430.72698878 -246.50402339  314.48585422]
[-1306.67372204   500.58185153  -704.19124012]
[0. 0. 0.]
transform [[-0.02814123  0.700948   -0.71265697]
 [ 0.99395317  0.09532163  0.05450651]
 [ 0.          0.          0.        ]]
zmp [-7743258.94619396   155990.66462572        0.        ]
d1:7848481.40619, d2:0.05906, d3:2411710.71893
transform [[ 0.58709401  0.08331891  0.        ]
 [-0.11585442  0.99309784  0.        ]
 [-0.80118567 -0.08255108  0.        ]]
planes
[[ 0.80521959  0.58709401  0.08331891]
 [-0.01828868 -0.11585442  0.99309784]
 [ 0.59269464 -0.80118567 -0.08255108]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  285.4091   -243.59787 -1164.5117 ]
[ 137.37377226 -363.0310766  -140.72405298]
[ 0.   0.  -9.8]
transform [[ 0.58709401  0.08331891  0.        ]
 [-0.11585442  0.99309784  0.        ]
 [-0.80118567 -0.08255108  0.        ]]
transform [[ 0.58709401  0.08331891  0.        ]
 [-0.11585442  0.99309784  0.        ]
 [-0.80118567 -0.08255108  0.        ]]
transform [[ 0.58709401  0.08331891  0.        ]
 [-0.11585442  0.99309784  0.        ]
 [-0.80118567 -0.08255108  0.        ]]
support
[0. 0. 0.]
[ 147.26565638 -274.98242313 -208.55640428]
[  50.40396454 -376.44073733  -80.09329106]
[0. 0. 0.]
transform [[ 0.58709401 -0.11585442 -0.80118567]
 [ 0.08331891  0.99309784 -0.08255108]
 [ 0.          0.          0.        ]]
zmp [  7640000.69501002 -21913410.99998193         0.        ]
d1:24523865.75811, d2:0.05686, d3:10071726.75495
transform [[-0.61311722  0.0194451   0.        ]
 [-0.13324958  0.98282808  0.        ]
 [-0.77867317 -0.18349618  0.        ]]
planes
[[ 0.78975266 -0.61311722  0.0194451 ]
 [-0.12764604 -0.13324958  0.98282808]
 [-0.5999977  -0.77867317 -0.18349618]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-234.02126  635.35767 1345.8005 ]
[ -293.70097001 -2285.88426588   466.9139019 ]
[ 0.   0.  -9.8]
transform [[-0.61311722  0.0194451   0.        ]
 [-0.13324958  0.98282808  0.        ]
 [-0.77867317 -0.18349618  0.        ]]
transform [[-0.61311722  0.0194451   0.        ]
 [-0.13324958  0.98282808  0.        ]
 [-0.77867317 -0.18349618  0.        ]]
transform [[-0.61311722  0.0194451   0.        ]
 [-0.13324958  0.98282808  0.        ]
 [-0.77867317 -0.18349618  0.        ]]
support
[0. 0. 0.]
[155.83705262 655.63058963  65.64037046]
[  135.62388021 -2207.49571448   648.14809024]
[0. 0. 0.]
transform [[-0.61311722 -0.13324958 -0.77867317]
 [ 0.0194451   0.98282808 -0.18349618]
 [ 0.          0.          0.        ]]
zmp [-29260829.28103336 -42361499.63303816         0.        ]
d1:70930032.23049, d2:0.05931, d3:24508478.19269
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-416.86072215795326 steps:78[00m
[RDDPG] Resetting Environment
transform [[ 0.7331624  -0.06126105  0.        ]
 [ 0.03998522  0.99809462  0.        ]
 [-0.67887712 -0.00737286  0.        ]]
planes
[[ 0.67728877  0.7331624  -0.06126105]
 [ 0.04699423  0.03998522  0.99809462]
 [ 0.73421496 -0.67887712 -0.00737286]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[380.0093  463.59106 348.4809 ]
[-90.39391603 -44.30111355  35.087052  ]
[ 0.   0.  -9.8]
transform [[ 0.7331624  -0.06126105  0.        ]
 [ 0.03998522  0.99809462  0.        ]
 [-0.67887712 -0.00737286  0.        ]]
transform [[ 0.7331624  -0.06126105  0.        ]
 [ 0.03998522  0.99809462  0.        ]
 [-0.67887712 -0.00737286  0.        ]]
transform [[ 0.7331624  -0.06126105  0.        ]
 [ 0.03998522  0.99809462  0.        ]
 [-0.67887712 -0.00737286  0.        ]]
support
[0. 0. 0.]
[ 250.20846179  477.90250406 -261.39761529]
[-63.55948796 -47.83112405  61.69298692]
[0. 0. 0.]
transform [[ 0.7331624   0.03998522 -0.67887712]
 [-0.06126105  0.99809462 -0.00737286]
 [ 0.          0.          0.        ]]
zmp [ -6021716.13857465 -33583430.44352208         0.        ]
d1:40848328.00390, d2:0.03212, d3:9597057.83143
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-256.44462231582884 steps:80[00m
[RDDPG] Resetting Environment
transform [[ 0.34921494  0.87981719  0.        ]
 [-0.62255973  0.47502786  0.        ]
 [-0.70033443  0.01643799  0.        ]]
planes
[[ 0.32244471  0.34921494  0.87981719]
 [-0.6219067  -0.62255973  0.47502786]
 [ 0.71362561 -0.70033443  0.01643799]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -300.24374  -255.34204 -1172.8275 ]
[  88.17292889 -136.63604613  -38.57193418]
[ 0.   0.  -9.8]
transform [[ 0.34921494  0.87981719  0.        ]
 [-0.62255973  0.47502786  0.        ]
 [-0.70033443  0.01643799  0.        ]]
transform [[ 0.34921494  0.87981719  0.        ]
 [-0.62255973  0.47502786  0.        ]
 [-0.70033443  0.01643799  0.        ]]
transform [[ 0.34921494  0.87981719  0.        ]
 [-0.62255973  0.47502786  0.        ]
 [-0.70033443  0.01643799  0.        ]]
support
[0. 0. 0.]
[-329.50391784   65.62507989  206.07372157]
[ -89.42343767 -119.79884296  -63.99655966]
[0. 0. 0.]
transform [[ 0.34921494 -0.62255973 -0.70033443]
 [ 0.87981719  0.47502786  0.01643799]
 [ 0.          0.          0.        ]]
zmp [13663480.22463462 -5182647.68660815        0.        ]
d1:19010522.48350, d2:0.05846, d3:6010707.47265
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-157.20756878787725 steps:82[00m
[RDDPG] Resetting Environment
transform [[ 0.72222561  0.13796698  0.        ]
 [-0.09462691  0.99039912  0.        ]
 [-0.68515396  0.00864752  0.        ]]
planes
[[ 0.67775762  0.72222561  0.13796698]
 [-0.10077408 -0.09462691  0.99039912]
 [ 0.72834694 -0.68515396  0.00864752]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[ 0.72222561  0.13796698  0.        ]
 [-0.09462691  0.99039912  0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.72222561  0.13796698  0.        ]
 [-0.09462691  0.99039912  0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.72222561  0.13796698  0.        ]
 [-0.09462691  0.99039912  0.        ]
 [-0.68515396  0.00864752  0.        ]]
support
[0. 0. 0.]
[ 217.96637176   22.35300663 -199.73413912]
[-32.89847948 -74.42412801  20.31610152]
[0. 0. 0.]
transform [[ 0.72222561 -0.09462691 -0.68515396]
 [ 0.13796698  0.99039912  0.00864752]
 [ 0.          0.          0.        ]]
zmp [-4018932.33536492  8844591.4946611         0.        ]
d1:12260555.56809, d2:0.05501, d3:4154322.80238
transform [[ 0.19339916  0.9661991   0.        ]
 [-0.70225412  0.25765207  0.        ]
 [-0.68515396  0.00864752  0.        ]]
planes
[[ 0.17045859  0.19339916  0.9661991 ]
 [-0.66366756 -0.70225412  0.25765207]
 [ 0.72834694 -0.68515396  0.00864752]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[ 0.19339916  0.9661991   0.        ]
 [-0.70225412  0.25765207  0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.19339916  0.9661991   0.        ]
 [-0.70225412  0.25765207  0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.19339916  0.9661991   0.        ]
 [-0.70225412  0.25765207  0.        ]
 [-0.68515396  0.00864752  0.        ]]
support
[0. 0. 0.]
[ 105.27937174 -192.15943855 -199.73413912]
[-81.35909291   1.39951916  20.31610152]
[0. 0. 0.]
transform [[ 0.19339916 -0.70225412 -0.68515396]
 [ 0.9661991   0.25765207  0.00864752]
 [ 0.          0.          0.        ]]
zmp [-9420638.05057744  2330591.18562355        0.        ]
d1:11429194.45705, d2:0.05898, d3:3768445.93685
transform [[ 0.72825122 -0.01196161  0.        ]
 [ 0.01463753  0.9998911   0.        ]
 [-0.68515396  0.00864752  0.        ]]
planes
[[ 0.68520594  0.72825122 -0.01196161]
 [ 0.00189798  0.01463753  0.9998911 ]
 [ 0.72834694 -0.68515396  0.00864752]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[ 0.72825122 -0.01196161  0.        ]
 [ 0.01463753  0.9998911   0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.72825122 -0.01196161  0.        ]
 [ 0.01463753  0.9998911   0.        ]
 [-0.68515396  0.00864752  0.        ]]
transform [[ 0.72825122 -0.01196161  0.        ]
 [ 0.01463753  0.9998911   0.        ]
 [-0.68515396  0.00864752  0.        ]]
support
[0. 0. 0.]
[ 212.15788306   54.75427228 -199.73413912]
[-21.37774294 -78.5127561   20.31610152]
[0. 0. 0.]
transform [[ 0.72825122  0.01463753 -0.68515396]
 [-0.01196161  0.9998911   0.00864752]
 [ 0.          0.          0.        ]]
zmp [-3047589.49214998  8928973.62767479        0.        ]
d1:11404407.57170, d2:0.05250, d3:3871094.46263
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-467.71837687512425 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-442.42160656248456 steps:87[00m
[RDDPG] Resetting Environment
transform [[-0.15336266 -0.9150874   0.        ]
 [-0.67164099  0.3733685   0.        ]
 [-0.72482991 -0.15235202  0.        ]]
planes
[[ 0.37295449 -0.15336266 -0.9150874 ]
 [ 0.63991755 -0.67164099  0.3733685 ]
 [-0.67187089 -0.72482991 -0.15235202]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[-0.15336266 -0.9150874   0.        ]
 [-0.67164099  0.3733685   0.        ]
 [-0.72482991 -0.15235202  0.        ]]
transform [[-0.15336266 -0.9150874   0.        ]
 [-0.67164099  0.3733685   0.        ]
 [-0.72482991 -0.15235202  0.        ]]
transform [[-0.15336266 -0.9150874   0.        ]
 [-0.67164099  0.3733685   0.        ]
 [-0.72482991 -0.15235202  0.        ]]
support
[0. 0. 0.]
[ -91.00224527 -177.37392857 -219.45343623]
[76.14205082 -8.57268897 34.10134903]
[0. 0. 0.]
transform [[-0.15336266 -0.67164099 -0.72482991]
 [-0.9150874   0.3733685  -0.15235202]
 [ 0.          0.          0.        ]]
zmp [ 27135004.78952639 -11655767.40193059         0.        ]
d1:34150245.28451, d2:0.05436, d3:9552062.54916
transform [[-0.67158234 -0.06120608  0.        ]
 [-0.15361895  0.98642933  0.        ]
 [-0.72482991 -0.15235202  0.        ]]
planes
[[ 0.7383976  -0.67158234 -0.06120608]
 [-0.05795293 -0.15361895  0.98642933]
 [-0.67187089 -0.72482991 -0.15235202]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[-0.67158234 -0.06120608  0.        ]
 [-0.15361895  0.98642933  0.        ]
 [-0.72482991 -0.15235202  0.        ]]
transform [[-0.67158234 -0.06120608  0.        ]
 [-0.15361895  0.98642933  0.        ]
 [-0.72482991 -0.15235202  0.        ]]
transform [[-0.67158234 -0.06120608  0.        ]
 [-0.15361895  0.98642933  0.        ]
 [-0.72482991 -0.15235202  0.        ]]
support
[0. 0. 0.]
[-199.29557511    4.91781989 -219.45343623]
[ 25.35397012 -72.30684139  34.10134903]
[0. 0. 0.]
transform [[-0.67158234 -0.15361895 -0.72482991]
 [-0.06120608  0.98642933 -0.15235202]
 [ 0.          0.          0.        ]]
zmp [  9658279.57425698 -32338855.73726608         0.        ]
d1:40455141.94755, d2:0.03083, d3:9357512.14656
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-422.9195728712308 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-161.54598791016232 steps:91[00m
[RDDPG] Resetting Environment
transform [[-0.61079544  0.18733296  0.        ]
 [ 0.06695356  0.98034841  0.        ]
 [-0.78895259 -0.06183426  0.        ]]
planes
[[ 0.76930839 -0.61079544  0.18733296]
 [-0.18556491  0.06695356  0.98034841]
 [-0.61133492 -0.78895259 -0.06183426]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 292.15433    50.483353 -499.05222 ]
[-30.63725599 -78.07280436  13.22773764]
[ 0.   0.  -9.8]
transform [[-0.61079544  0.18733296  0.        ]
 [ 0.06695356  0.98034841  0.        ]
 [-0.78895259 -0.06183426  0.        ]]
transform [[-0.61079544  0.18733296  0.        ]
 [ 0.06695356  0.98034841  0.        ]
 [-0.78895259 -0.06183426  0.        ]]
transform [[-0.61079544  0.18733296  0.        ]
 [ 0.06695356  0.98034841  0.        ]
 [-0.78895259 -0.06183426  0.        ]]
support
[0. 0. 0.]
[-168.98933467   69.05204735 -233.61751398]
[  4.08748682 -78.5898229   28.99891687]
[0. 0. 0.]
transform [[-0.61079544  0.06695356 -0.78895259]
 [ 0.18733296  0.98034841 -0.06183426]
 [ 0.          0.          0.        ]]
zmp [12783291.60070966 -3879186.37957346        0.        ]
d1:16331772.70828, d2:0.02416, d3:2866402.27621
transform [[ 0.50549102  0.79389489  0.        ]
 [-0.69726658  0.60656381  0.        ]
 [-0.50823045 -0.04255917  0.        ]]
planes
[[ 0.33794928  0.50549102  0.79389489]
 [-0.38196826 -0.69726658  0.60656381]
 [ 0.86016893 -0.50823045 -0.04255917]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -93.660286 -275.01587  1262.3785  ]
[-86.84118874 -54.17458088  50.3396142 ]
[ 0.   0.  -9.8]
transform [[ 0.50549102  0.79389489  0.        ]
 [-0.69726658  0.60656381  0.        ]
 [-0.50823045 -0.04255917  0.        ]]
transform [[ 0.50549102  0.79389489  0.        ]
 [-0.69726658  0.60656381  0.        ]
 [-0.50823045 -0.04255917  0.        ]]
transform [[ 0.50549102  0.79389489  0.        ]
 [-0.69726658  0.60656381  0.        ]
 [-0.50823045 -0.04255917  0.        ]]
support
[0. 0. 0.]
[-265.67812567 -101.5084853    59.30545496]
[-86.90636369  27.69111857  46.44096119]
[0. 0. 0.]
transform [[ 0.50549102 -0.69726658 -0.50823045]
 [ 0.79389489  0.60656381 -0.04255917]
 [ 0.          0.          0.        ]]
zmp [-18561794.78505933   6248819.65142103         0.        ]
d1:29547848.79877, d2:0.05864, d3:8999389.87166
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-308.77715134278606 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-158.52826671874757 steps:95[00m
[RDDPG] Resetting Environment
transform [[ 0.80978858 -0.07550002  0.        ]
 [ 0.10641053  0.9941389   0.        ]
 [-0.57699162  0.07738031  0.        ]]
planes
[[ 0.58184391  0.80978858 -0.07550002]
 [-0.01909881  0.10641053  0.9941389 ]
 [ 0.81307626 -0.57699162  0.07738031]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-204.86536  284.02386  749.0246 ]
[  13.60241026 -341.05585315  -13.07567628]
[ 0.   0.  -9.8]
transform [[ 0.80978858 -0.07550002  0.        ]
 [ 0.10641053  0.9941389   0.        ]
 [-0.57699162  0.07738031  0.        ]]
transform [[ 0.80978858 -0.07550002  0.        ]
 [ 0.10641053  0.9941389   0.        ]
 [-0.57699162  0.07738031  0.        ]]
transform [[ 0.80978858 -0.07550002  0.        ]
 [ 0.10641053  0.9941389   0.        ]
 [-0.57699162  0.07738031  0.        ]]
support
[0. 0. 0.]
[-187.34143421  260.55933966  140.18344728]
[  36.76479991 -337.60944976  -34.23948333]
[0. 0. 0.]
transform [[ 0.80978858  0.10641053 -0.57699162]
 [-0.07550002  0.9941389   0.07738031]
 [ 0.          0.          0.        ]]
zmp [9682418.7461965  -899665.97834831       0.        ]
d1:11508185.42639, d2:0.05129, d3:3703030.12091
transform [[ 0.81561053  0.00201953  0.        ]
 [ 0.04313005  0.99699968  0.        ]
 [-0.57699162  0.07738031  0.        ]]
planes
[[ 0.5785979   0.81561053  0.00201953]
 [-0.06427744  0.04313005  0.99699968]
 [ 0.81307626 -0.57699162  0.07738031]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-204.86536  284.02386  749.0246 ]
[  13.60241026 -341.05585315  -13.07567628]
[ 0.   0.  -9.8]
transform [[ 0.81561053  0.00201953  0.        ]
 [ 0.04313005  0.99699968  0.        ]
 [-0.57699162  0.07738031  0.        ]]
transform [[ 0.81561053  0.00201953  0.        ]
 [ 0.04313005  0.99699968  0.        ]
 [-0.57699162  0.07738031  0.        ]]
transform [[ 0.81561053  0.00201953  0.        ]
 [ 0.04313005  0.99699968  0.        ]
 [-0.57699162  0.07738031  0.        ]]
support
[0. 0. 0.]
[-166.51674684  274.3358492   140.18344728]
[  10.40549651 -339.44590414  -34.23948333]
[0. 0. 0.]
transform [[ 0.81561053  0.04313005 -0.57699162]
 [ 0.00201953  0.99699968  0.07738031]
 [ 0.          0.          0.        ]]
zmp [9657390.13974431 -898534.49561348       0.        ]
d1:11479420.74515, d2:0.05142, d3:3693865.91517
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-430.217843752353 steps:98[00m
[RDDPG] Resetting Environment
transform [[ 0.74432939  0.05634685  0.        ]
 [-0.03612959  0.9983725   0.        ]
 [-0.66683465  0.00880253  0.        ]]
planes
[[ 0.66543126  0.74432939  0.05634685]
 [-0.04412601 -0.03612959  0.9983725 ]
 [ 0.74515378 -0.66683465  0.00880253]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 678.3617   136.26265 -331.4531 ]
[  39.11347086 -166.58567341  -15.61825691]
[ 0.   0.  -9.8]
transform [[ 0.74432939  0.05634685  0.        ]
 [-0.03612959  0.9983725   0.        ]
 [-0.66683465  0.00880253  0.        ]]
transform [[ 0.74432939  0.05634685  0.        ]
 [-0.03612959  0.9983725   0.        ]
 [-0.66683465  0.00880253  0.        ]]
transform [[ 0.74432939  0.05634685  0.        ]
 [-0.03612959  0.9983725   0.        ]
 [-0.66683465  0.00880253  0.        ]]
support
[0. 0. 0.]
[ 512.602519    111.53194892 -451.15562919]
[  19.7267283  -167.72770824  -27.54859242]
[0. 0. 0.]
transform [[ 0.74432939 -0.03612959 -0.66683465]
 [ 0.05634685  0.9983725   0.00880253]
 [ 0.          0.          0.        ]]
zmp [14250350.59754025  4088290.96085021        0.        ]
d1:16376691.22562, d2:0.03178, d3:4064067.25725
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-247.3651465474998 steps:100[00m
[RDDPG] Resetting Environment
transform [[ 0.69729936  0.05135988  0.        ]
 [-0.06365187  0.99792594  0.        ]
 [-0.71394825 -0.03880762  0.        ]]
planes
[[ 0.71493763  0.69729936  0.05135988]
 [-0.00960777 -0.06365187  0.99792594]
 [ 0.69912225 -0.71394825 -0.03880762]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-249.86882  -25.67093  948.9835 ]
[ -68.90201114 -328.45324066  -17.1414473 ]
[ 0.   0.  -9.8]
transform [[ 0.69729936  0.05135988  0.        ]
 [-0.06365187  0.99792594  0.        ]
 [-0.71394825 -0.03880762  0.        ]]
transform [[ 0.69729936  0.05135988  0.        ]
 [-0.06365187  0.99792594  0.        ]
 [-0.71394825 -0.03880762  0.        ]]
transform [[ 0.69729936  0.05135988  0.        ]
 [-0.06365187  0.99792594  0.        ]
 [-0.71394825 -0.03880762  0.        ]]
support
[0. 0. 0.]
[-175.55182475   -9.71307078  179.38963457]
[ -64.91464884 -323.38626634   61.9389586 ]
[0. 0. 0.]
transform [[ 0.69729936 -0.06365187 -0.71394825]
 [ 0.05135988  0.99792594 -0.03880762]
 [ 0.          0.          0.        ]]
zmp [-1769310.53106338 12778375.21236925        0.        ]
d1:14304191.41673, d2:0.04784, d3:4852011.40936
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-260.28535312710494 steps:102[00m
[RDDPG] Resetting Environment
transform [[-0.22362094 -0.95190614  0.        ]
 [-0.63034153  0.30514374  0.        ]
 [-0.74341327  0.02760427  0.        ]]
planes
[[ 0.20944777 -0.22362094 -0.95190614]
 [ 0.71383256 -0.63034153  0.30514374]
 [-0.66826248 -0.74341327  0.02760427]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-249.86882  -25.67093  948.9835 ]
[ -68.90201114 -328.45324066  -17.1414473 ]
[ 0.   0.  -9.8]
transform [[-0.22362094 -0.95190614  0.        ]
 [-0.63034153  0.30514374  0.        ]
 [-0.74341327  0.02760427  0.        ]]
transform [[-0.22362094 -0.95190614  0.        ]
 [-0.63034153  0.30514374  0.        ]
 [-0.74341327  0.02760427  0.        ]]
transform [[-0.22362094 -0.95190614  0.        ]
 [-0.63034153  0.30514374  0.        ]
 [-0.74341327  0.02760427  0.        ]]
support
[0. 0. 0.]
[ 80.31221634 149.66937043 185.0471692 ]
[328.06459025 -56.79365239  42.15595659]
[0. 0. 0.]
transform [[-0.22362094 -0.63034153 -0.74341327]
 [-0.95190614  0.30514374  0.02760427]
 [ 0.          0.          0.        ]]
zmp [4813369.29457156 1469577.99568033       0.        ]
d1:6421974.33908, d2:0.05886, d3:2003449.71922
transform [[-0.40793109  0.06019802  0.        ]
 [ 0.19950728  0.97958738  0.        ]
 [-0.89094841  0.19179356  0.        ]]
planes
[[ 0.911026   -0.40793109  0.06019802]
 [ 0.02460522  0.19950728  0.97958738]
 [-0.41161409 -0.89094841  0.19179356]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-249.86882  -25.67093  948.9835 ]
[ -68.90201114 -328.45324066  -17.1414473 ]
[ 0.   0.  -9.8]
transform [[-0.40793109  0.06019802  0.        ]
 [ 0.19950728  0.97958738  0.        ]
 [-0.89094841  0.19179356  0.        ]]
transform [[-0.40793109  0.06019802  0.        ]
 [ 0.19950728  0.97958738  0.        ]
 [-0.89094841  0.19179356  0.        ]]
transform [[-0.40793109  0.06019802  0.        ]
 [ 0.19950728  0.97958738  0.        ]
 [-0.89094841  0.19179356  0.        ]]
support
[0. 0. 0.]
[100.38392081 -74.99756877 217.69671001]
[   8.33503765 -335.49510111   -1.60707904]
[0. 0. 0.]
transform [[-0.40793109  0.19950728 -0.89094841]
 [ 0.06019802  0.97958738  0.19179356]
 [ 0.          0.          0.        ]]
zmp [15462220.32438906 26228069.82876079        0.        ]
d1:21787166.05963, d2:0.05903, d3:9538090.36690
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-197.3469461650795 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-169.65355187501885 steps:106[00m
[RDDPG] Resetting Environment
transform [[ 0.66425472  0.31316489  0.        ]
 [-0.22967103  0.94959325  0.        ]
 [-0.71134871 -0.01416012  0.        ]]
planes
[[ 0.67874402  0.66425472  0.31316489]
 [-0.21336351 -0.22967103  0.94959325]
 [ 0.70269668 -0.71134871 -0.01416012]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-278.40005 -346.1222   189.624  ]
[ 119.70255598 -186.07724182  -56.70588359]
[ 0.   0.  -9.8]
transform [[ 0.66425472  0.31316489  0.        ]
 [-0.22967103  0.94959325  0.        ]
 [-0.71134871 -0.01416012  0.        ]]
transform [[ 0.66425472  0.31316489  0.        ]
 [-0.22967103  0.94959325  0.        ]
 [-0.71134871 -0.01416012  0.        ]]
transform [[ 0.66425472  0.31316489  0.        ]
 [-0.22967103  0.94959325  0.        ]
 [-0.71134871 -0.01416012  0.        ]]
support
[0. 0. 0.]
[-293.32187016 -264.73486846  202.94065237]
[  21.24012947 -204.18990153  -82.51538301]
[0. 0. 0.]
transform [[ 0.66425472 -0.22967103 -0.71134871]
 [ 0.31316489  0.94959325 -0.01416012]
 [ 0.          0.          0.        ]]
zmp [ 7679733.98688535 10423302.35150371        0.        ]
d1:18181800.15866, d2:0.02069, d3:934038.13727
transform [[ 0.0767272   0.27719089  0.        ]
 [-0.44322452  0.86993128  0.        ]
 [-0.89312094 -0.40790308  0.        ]]
planes
[[ 0.95774645  0.0767272   0.27719089]
 [-0.21626773 -0.44322452  0.86993128]
 [ 0.18960516 -0.89312094 -0.40790308]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-278.40005 -346.1222   189.624  ]
[ 119.70255598 -186.07724182  -56.70588359]
[ 0.   0.  -9.8]
transform [[ 0.0767272   0.27719089  0.        ]
 [-0.44322452  0.86993128  0.        ]
 [-0.89312094 -0.40790308  0.        ]]
transform [[ 0.0767272   0.27719089  0.        ]
 [-0.44322452  0.86993128  0.        ]
 [-0.89312094 -0.40790308  0.        ]]
transform [[ 0.0767272   0.27719089  0.        ]
 [-0.44322452  0.86993128  0.        ]
 [-0.89312094 -0.40790308  0.        ]]
support
[0. 0. 0.]
[-117.30277564 -177.70879149  389.82922668]
[ -42.39447545 -214.92952112  -31.00738069]
[0. 0. 0.]
transform [[ 0.0767272  -0.44322452 -0.89312094]
 [ 0.27719089  0.86993128 -0.40790308]
 [ 0.          0.          0.        ]]
zmp [  6859871.30935196 -17716540.56798054         0.        ]
d1:16238625.24781, d2:0.05712, d3:3060349.66043
transform [[ 0.73933661  0.49028033  0.        ]
 [ 0.16123413 -0.79439938  0.        ]
 [-0.65374696  0.35854533  0.        ]]
planes
[[-0.46152633  0.73933661  0.49028033]
 [-0.58560497  0.16123413 -0.79439938]
 [-0.66637844 -0.65374696  0.35854533]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-478.4347    605.7715    -22.158459]
[-32.75754814 -99.30682835  41.03973448]
[ 0.   0.  -9.8]
transform [[ 0.73933661  0.49028033  0.        ]
 [ 0.16123413 -0.79439938  0.        ]
 [-0.65374696  0.35854533  0.        ]]
transform [[ 0.73933661  0.49028033  0.        ]
 [ 0.16123413 -0.79439938  0.        ]
 [-0.65374696  0.35854533  0.        ]]
transform [[ 0.73933661  0.49028033  0.        ]
 [ 0.16123413 -0.79439938  0.        ]
 [-0.65374696  0.35854533  0.        ]]
support
[0. 0. 0.]
[ -56.72644012 -558.36449126  529.9717656 ]
[-72.90703918  73.60764831 -14.19085226]
[0. 0. 0.]
transform [[ 0.73933661  0.16123413 -0.65374696]
 [ 0.49028033 -0.79439938  0.35854533]
 [ 0.          0.          0.        ]]
zmp [-10158959.99162248 -12773008.91763913         0.        ]
d1:20469468.99851, d2:0.05682, d3:9382062.95210
transform [[ 0.72824132  0.05881383  0.        ]
 [-0.20561977 -0.93165779  0.        ]
 [-0.65374696  0.35854533  0.        ]]
planes
[[-0.68279243  0.72824132  0.05881383]
 [-0.29955691 -0.20561977 -0.93165779]
 [-0.66637844 -0.65374696  0.35854533]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-478.4347    605.7715    -22.158459]
[-32.75754814 -99.30682835  41.03973448]
[ 0.   0.  -9.8]
transform [[ 0.72824132  0.05881383  0.        ]
 [-0.20561977 -0.93165779  0.        ]
 [-0.65374696  0.35854533  0.        ]]
transform [[ 0.72824132  0.05881383  0.        ]
 [-0.20561977 -0.93165779  0.        ]
 [-0.65374696  0.35854533  0.        ]]
transform [[ 0.72824132  0.05881383  0.        ]
 [-0.20561977 -0.93165779  0.        ]
 [-0.65374696  0.35854533  0.        ]]
support
[0. 0. 0.]
[-312.78817129 -465.99609295  529.9717656 ]
[-29.69601543  99.25557977 -14.19085226]
[0. 0. 0.]
transform [[ 0.72824132 -0.20561977 -0.65374696]
 [ 0.05881383 -0.93165779  0.35854533]
 [ 0.          0.          0.        ]]
zmp [-19691658.25358706 -16339668.24375592         0.        ]
d1:26218434.64964, d2:0.05929, d3:15922082.94858
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-374.38820521382314 steps:111[00m
[RDDPG] Resetting Environment
transform [[ 0.29398343  0.91407156  0.        ]
 [-0.64947367  0.40548062  0.        ]
 [-0.70125443  0.00766186  0.        ]]
planes
[[ 0.27936891  0.29398343  0.91407156]
 [-0.64324921 -0.64947367  0.40548062]
 [ 0.71286994 -0.70125443  0.00766186]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-686.3576  496.5186 1078.5084]
[  73.79922414 -775.75840779  -44.49717194]
[ 0.   0.  -9.8]
transform [[ 0.29398343  0.91407156  0.        ]
 [-0.64947367  0.40548062  0.        ]
 [-0.70125443  0.00766186  0.        ]]
transform [[ 0.29398343  0.91407156  0.        ]
 [-0.64947367  0.40548062  0.        ]
 [-0.70125443  0.00766186  0.        ]]
transform [[ 0.29398343  0.91407156  0.        ]
 [-0.64947367  0.40548062  0.        ]
 [-0.70125443  0.00766186  0.        ]]
support
[0. 0. 0.]
[252.07575501 647.09985606 485.11556494]
[-687.40294889 -362.48565541  -57.6957846 ]
[0. 0. 0.]
transform [[ 0.29398343 -0.64947367 -0.70125443]
 [ 0.91407156  0.40548062  0.00766186]
 [ 0.          0.          0.        ]]
zmp [8368447.74839028 -107921.29170424       0.        ]
d1:8716354.51871, d2:0.05710, d3:2671134.07280
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-176.0144987591103 steps:113[00m
[RDDPG] Resetting Environment
transform [[-0.30715662  0.88192803  0.        ]
 [ 0.65894717  0.46818879  0.        ]
 [-0.68661743  0.05479265  0.        ]]
planes
[[ 0.35757202 -0.30715662  0.88192803]
 [-0.58871728  0.65894717  0.46818879]
 [-0.72495121 -0.68661743  0.05479265]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-686.3576  496.5186 1078.5084]
[  73.79922414 -775.75840779  -44.49717194]
[ 0.   0.  -9.8]
transform [[-0.30715662  0.88192803  0.        ]
 [ 0.65894717  0.46818879  0.        ]
 [-0.68661743  0.05479265  0.        ]]
transform [[-0.30715662  0.88192803  0.        ]
 [ 0.65894717  0.46818879  0.        ]
 [-0.68661743  0.05479265  0.        ]]
transform [[-0.30715662  0.88192803  0.        ]
 [ 0.65894717  0.46818879  0.        ]
 [-0.68661743  0.05479265  0.        ]]
support
[0. 0. 0.]
[ 648.71293977 -219.80896441  498.47066848]
[-706.83100218 -314.57160231  -93.17769576]
[0. 0. 0.]
transform [[-0.30715662  0.65894717 -0.68661743]
 [ 0.88192803  0.46818879  0.05479265]
 [ 0.          0.          0.        ]]
zmp [20000208.81401396 16031314.78444919        0.        ]
d1:36511530.44264, d2:0.05918, d3:11622079.73788
transform [[-0.68728513  0.27621922  0.        ]
 [ 0.23705626  0.95953155  0.        ]
 [-0.68661743  0.05479265  0.        ]]
planes
[[ 0.67182004 -0.68728513  0.27621922]
 [-0.15199876  0.23705626  0.95953155]
 [-0.72495121 -0.68661743  0.05479265]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-686.3576  496.5186 1078.5084]
[  73.79922414 -775.75840779  -44.49717194]
[ 0.   0.  -9.8]
transform [[-0.68728513  0.27621922  0.        ]
 [ 0.23705626  0.95953155  0.        ]
 [-0.68661743  0.05479265  0.        ]]
transform [[-0.68728513  0.27621922  0.        ]
 [ 0.23705626  0.95953155  0.        ]
 [-0.68661743  0.05479265  0.        ]]
transform [[-0.68728513  0.27621922  0.        ]
 [ 0.23705626  0.95953155  0.        ]
 [-0.68661743  0.05479265  0.        ]]
support
[0. 0. 0.]
[608.87134832 313.71988184 498.47066848]
[-265.00049052 -726.87009634  -93.17769576]
[0. 0. 0.]
transform [[-0.68728513  0.23705626 -0.68661743]
 [ 0.27621922  0.95953155  0.05479265]
 [ 0.          0.          0.        ]]
zmp [ 5719873.43891155 32662484.80240638        0.        ]
d1:38451668.80563, d2:0.04917, d3:12119664.47823
transform [[ 0.68218321  0.68367153  0.        ]
 [-0.43459362  0.66427934  0.        ]
 [-0.58800888  0.30220228  0.        ]]
planes
[[ 0.25926697  0.68218321  0.68367153]
 [-0.60816228 -0.43459362  0.66427934]
 [ 0.75027949 -0.58800888  0.30220228]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  54.807068 -418.9899    854.07166 ]
[  89.38391728 -423.78073982  -34.76576841]
[ 0.   0.  -9.8]
transform [[ 0.68218321  0.68367153  0.        ]
 [-0.43459362  0.66427934  0.        ]
 [-0.58800888  0.30220228  0.        ]]
transform [[ 0.68218321  0.68367153  0.        ]
 [-0.43459362  0.66427934  0.        ]
 [-0.58800888  0.30220228  0.        ]]
transform [[ 0.68218321  0.68367153  0.        ]
 [-0.43459362  0.66427934  0.        ]
 [-0.58800888  0.30220228  0.        ]]
support
[0. 0. 0.]
[-249.06300551 -302.14513599 -158.84674712]
[-228.75062124 -320.35447087 -180.62604477]
[0. 0. 0.]
transform [[ 0.68218321 -0.43459362 -0.58800888]
 [ 0.68367153  0.66427934  0.30220228]
 [ 0.          0.          0.        ]]
zmp [2070640.91021074 8486143.81477418       0.        ]
d1:11770555.30208, d2:0.04096, d3:2388931.16464
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-172.15935587015545 steps:117[00m
[RDDPG] Resetting Environment
transform [[-0.73081762 -0.10549553  0.        ]
 [-0.05200091  0.99371791  0.        ]
 [-0.6805892   0.0373555   0.        ]]
planes
[[ 0.67437112 -0.73081762 -0.10549553]
 [ 0.09909917 -0.05200091  0.99371791]
 [-0.7317124  -0.6805892   0.0373555 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  54.807068 -418.9899    854.07166 ]
[  89.38391728 -423.78073982  -34.76576841]
[ 0.   0.  -9.8]
transform [[-0.73081762 -0.10549553  0.        ]
 [-0.05200091  0.99371791  0.        ]
 [-0.6805892   0.0373555   0.        ]]
transform [[-0.73081762 -0.10549553  0.        ]
 [-0.05200091  0.99371791  0.        ]
 [-0.6805892   0.0373555   0.        ]]
transform [[-0.73081762 -0.10549553  0.        ]
 [-0.05200091  0.99371791  0.        ]
 [-0.6805892   0.0373555   0.        ]]
support
[0. 0. 0.]
[   4.14759277 -419.20778336  -52.95267609]
[ -20.61636553 -425.76655563  -76.66427061]
[0. 0. 0.]
transform [[-0.73081762 -0.05200091 -0.6805892 ]
 [-0.10549553  0.99371791  0.0373555 ]
 [ 0.          0.          0.        ]]
zmp [  2643849.22655273 -10059822.83153548         0.        ]
d1:12399938.81806, d2:0.02841, d3:2605774.23627
transform [[-0.73197943  0.00853407  0.        ]
 [ 0.03169379  0.99926567  0.        ]
 [-0.6805892   0.0373555   0.        ]]
planes
[[ 0.68127328 -0.73197943  0.00853407]
 [ 0.02153526  0.03169379  0.99926567]
 [-0.7317124  -0.6805892   0.0373555 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  54.807068 -418.9899    854.07166 ]
[  89.38391728 -423.78073982  -34.76576841]
[ 0.   0.  -9.8]
transform [[-0.73197943  0.00853407  0.        ]
 [ 0.03169379  0.99926567  0.        ]
 [-0.6805892   0.0373555   0.        ]]
transform [[-0.73197943  0.00853407  0.        ]
 [ 0.03169379  0.99926567  0.        ]
 [-0.6805892   0.0373555   0.        ]]
transform [[-0.73197943  0.00853407  0.        ]
 [ 0.03169379  0.99926567  0.        ]
 [-0.6805892   0.0373555   0.        ]]
support
[0. 0. 0.]
[ -43.69333545 -416.94517845  -52.95267609]
[ -69.04376334 -420.63663013  -76.66427061]
[0. 0. 0.]
transform [[-0.73197943  0.03169379 -0.6805892 ]
 [ 0.00853407  0.99926567  0.0373555 ]
 [ 0.          0.          0.        ]]
zmp [  1806312.2421124  -10115350.47972106         0.        ]
d1:11686042.12754, d2:0.03220, d3:2874384.39976
transform [[-0.35035607  0.31644979  0.        ]
 [ 0.31028211  0.92726243  0.        ]
 [-0.88372827  0.20010994  0.        ]]
planes
[[ 0.88153857 -0.35035607  0.31644979]
 [-0.20954588  0.31028211  0.92726243]
 [-0.42306077 -0.88372827  0.20010994]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  54.807068 -418.9899    854.07166 ]
[  89.38391728 -423.78073982  -34.76576841]
[ 0.   0.  -9.8]
transform [[-0.35035607  0.31644979  0.        ]
 [ 0.31028211  0.92726243  0.        ]
 [-0.88372827  0.20010994  0.        ]]
transform [[-0.35035607  0.31644979  0.        ]
 [ 0.31028211  0.92726243  0.        ]
 [-0.88372827  0.20010994  0.        ]]
transform [[-0.35035607  0.31644979  0.        ]
 [ 0.31028211  0.92726243  0.        ]
 [-0.88372827  0.20010994  0.        ]]
support
[0. 0. 0.]
[-151.79125498 -371.50793695 -132.2786001 ]
[-165.4215248  -365.2217261  -163.79383421]
[0. 0. 0.]
transform [[-0.35035607  0.31028211 -0.88372827]
 [ 0.31644979  0.92726243  0.20010994]
 [ 0.          0.          0.        ]]
zmp [-22114182.88947615 -24465757.99123935         0.        ]
d1:18668321.18649, d2:0.05605, d3:11369799.90143
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-561.9727011843283 steps:121[00m
[RDDPG] Resetting Environment
transform [[ 0.64484972 -0.38592398  0.        ]
 [ 0.27341503  0.92251855  0.        ]
 [-0.71373177  0.00471809  0.        ]]
planes
[[ 0.65972078  0.64484972 -0.38592398]
 [ 0.27240375  0.27341503  0.92251855]
 [ 0.70040327 -0.71373177  0.00471809]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-322.5536 -874.5285 1433.4524]
[  78.90535361 -485.61957067  -20.88660054]
[ 0.   0.  -9.8]
transform [[ 0.64484972 -0.38592398  0.        ]
 [ 0.27341503  0.92251855  0.        ]
 [-0.71373177  0.00471809  0.        ]]
transform [[ 0.64484972 -0.38592398  0.        ]
 [ 0.27341503  0.92251855  0.        ]
 [-0.71373177  0.00471809  0.        ]]
transform [[ 0.64484972 -0.38592398  0.        ]
 [ 0.27341503  0.92251855  0.        ]
 [-0.71373177  0.00471809  0.        ]]
support
[0. 0. 0.]
[ 129.50293142 -894.95976696  226.09064002]
[ 238.29433328 -426.4191533   -58.60845326]
[0. 0. 0.]
transform [[ 0.64484972  0.27341503 -0.71373177]
 [-0.38592398  0.92251855  0.00471809]
 [ 0.          0.          0.        ]]
zmp [ -794068.9124132  11634128.69196329        0.        ]
d1:12268670.07515, d2:0.04759, d3:4153973.98590
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-248.52915736005676 steps:123[00m
[RDDPG] Resetting Environment
transform [[-0.05160865  0.92620814  0.        ]
 [-0.11071534  0.36635041  0.        ]
 [-0.99251133 -0.08902767  0.        ]]
planes
[[ 0.37346366 -0.05160865  0.92620814]
 [-0.92386663 -0.11071534  0.36635041]
 [ 0.08363859 -0.99251133 -0.08902767]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-322.5536 -874.5285 1433.4524]
[  78.90535361 -485.61957067  -20.88660054]
[ 0.   0.  -9.8]
transform [[-0.05160865  0.92620814  0.        ]
 [-0.11071534  0.36635041  0.        ]
 [-0.99251133 -0.08902767  0.        ]]
transform [[-0.05160865  0.92620814  0.        ]
 [-0.11071534  0.36635041  0.        ]
 [-0.99251133 -0.08902767  0.        ]]
transform [[-0.05160865  0.92620814  0.        ]
 [-0.11071534  0.36635041  0.        ]
 [-0.99251133 -0.08902767  0.        ]]
support
[0. 0. 0.]
[-793.34886251 -284.67224853  397.99532326]
[-453.85699719 -186.64296279  -35.08088089]
[0. 0. 0.]
transform [[-0.05160865 -0.11071534 -0.99251133]
 [ 0.92620814  0.36635041 -0.08902767]
 [ 0.          0.          0.        ]]
zmp [-6788062.64107581 -3173344.65517274        0.        ]
d1:5579011.40785, d2:0.05635, d3:3497357.85629
transform [[-0.60922527 -0.05863643  0.        ]
 [ 0.09762306  0.9841311   0.        ]
 [-0.78696525  0.1674746   0.        ]]
planes
[[ 0.79082638 -0.60922527 -0.05863643]
 [ 0.14817458  0.09762306  0.9841311 ]
 [-0.59383327 -0.78696525  0.1674746 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-588.8577    74.431    356.55222]
[  24.75808315 -139.81197941  -20.76075825]
[ 0.   0.  -9.8]
transform [[-0.60922527 -0.05863643  0.        ]
 [ 0.09762306  0.9841311   0.        ]
 [-0.78696525  0.1674746   0.        ]]
transform [[-0.60922527 -0.05863643  0.        ]
 [ 0.09762306  0.9841311   0.        ]
 [-0.78696525  0.1674746   0.        ]]
transform [[-0.60922527 -0.05863643  0.        ]
 [ 0.09762306  0.9841311   0.        ]
 [-0.78696525  0.1674746   0.        ]]
support
[0. 0. 0.]
[354.38264117  15.76376966 475.87587069]
[  -6.88517402 -135.176357    -42.89870613]
[0. 0. 0.]
transform [[-0.60922527  0.09762306 -0.78696525]
 [-0.05863643  0.9841311   0.1674746 ]
 [ 0.          0.          0.        ]]
zmp [-11481914.4808412   11233712.17192245         0.        ]
d1:16085842.54969, d2:0.00780, d3:564802.87059
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-423.76053355227555 steps:126[00m
[RDDPG] Resetting Environment
transform [[-0.1123689  -0.99071068  0.        ]
 [-0.69361997  0.13339518  0.        ]
 [-0.7115227   0.02642152  0.        ]]
planes
[[ 0.07658721 -0.1123689  -0.99071068]
 [ 0.70788211 -0.69361997  0.13339518]
 [-0.7021662  -0.7115227   0.02642152]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-588.8577    74.431    356.55222]
[  24.75808315 -139.81197941  -20.76075825]
[ 0.   0.  -9.8]
transform [[-0.1123689  -0.99071068  0.        ]
 [-0.69361997  0.13339518  0.        ]
 [-0.7115227   0.02642152  0.        ]]
transform [[-0.1123689  -0.99071068  0.        ]
 [-0.69361997  0.13339518  0.        ]
 [-0.7115227   0.02642152  0.        ]]
transform [[-0.1123689  -0.99071068  0.        ]
 [-0.69361997  0.13339518  0.        ]
 [-0.7115227   0.02642152  0.        ]]
support
[0. 0. 0.]
[ -7.57028863 418.37221353 420.95221872]
[135.73118192 -35.82294498 -21.30998248]
[0. 0. 0.]
transform [[-0.1123689  -0.69361997 -0.7115227 ]
 [-0.99071068  0.13339518  0.02642152]
 [ 0.          0.          0.        ]]
zmp [9139064.21216195  -39858.26471949       0.        ]
d1:9392625.55140, d2:0.05922, d3:2919354.70497
transform [[-0.70173502  0.02462485  0.        ]
 [ 0.03610319  0.99934757  0.        ]
 [-0.7115227   0.02642152  0.        ]]
planes
[[ 0.71201235 -0.70173502  0.02462485]
 [ 0.00101976  0.03610319  0.99934757]
 [-0.7021662  -0.7115227   0.02642152]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-588.8577    74.431    356.55222]
[  24.75808315 -139.81197941  -20.76075825]
[ 0.   0.  -9.8]
transform [[-0.70173502  0.02462485  0.        ]
 [ 0.03610319  0.99934757  0.        ]
 [-0.7115227   0.02642152  0.        ]]
transform [[-0.70173502  0.02462485  0.        ]
 [ 0.03610319  0.99934757  0.        ]
 [-0.7115227   0.02642152  0.        ]]
transform [[-0.70173502  0.02462485  0.        ]
 [ 0.03610319  0.99934757  0.        ]
 [-0.7115227   0.02642152  0.        ]]
support
[0. 0. 0.]
[415.05494107  53.12279894 420.95221872]
[ -20.81646333 -138.82691587  -21.30998248]
[0. 0. 0.]
transform [[-0.70173502  0.03610319 -0.7115227 ]
 [ 0.02462485  0.99934757  0.02642152]
 [ 0.          0.          0.        ]]
zmp [11169560.3061772   2369701.74071574        0.        ]
d1:13745488.98096, d2:0.04957, d3:4334766.48292
transform [[ 0.78549308  0.59631008  0.        ]
 [-0.56174529  0.79926604  0.        ]
 [-0.25969788  0.07475428  0.        ]]
planes
[[ 0.16557482  0.78549308  0.59631008]
 [-0.21357943 -0.56174529  0.79926604]
 [ 0.96279222 -0.25969788  0.07475428]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[392.36276 180.60081 518.7472 ]
[ -89.61832288 -195.26140809  102.95338459]
[ 0.   0.  -9.8]
transform [[ 0.78549308  0.59631008  0.        ]
 [-0.56174529  0.79926604  0.        ]
 [-0.25969788  0.07475428  0.        ]]
transform [[ 0.78549308  0.59631008  0.        ]
 [-0.56174529  0.79926604  0.        ]
 [-0.25969788  0.07475428  0.        ]]
transform [[ 0.78549308  0.59631008  0.        ]
 [-0.56174529  0.79926604  0.        ]
 [-0.25969788  0.07475428  0.        ]]
support
[0. 0. 0.]
[415.8923193  -76.05983406 -88.39509625]
[-186.83091779 -105.72314206    8.67706378]
[0. 0. 0.]
transform [[ 0.78549308 -0.56174529 -0.25969788]
 [ 0.59631008  0.79926604  0.07475428]
 [ 0.          0.          0.        ]]
zmp [ 5934134.0839052 -4363192.4905479        0.       ]
d1:12113119.00990, d2:0.05603, d3:3401112.64438
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-487.63093500860134 steps:130[00m
[RDDPG] Resetting Environment
transform [[ 0.26303735 -0.93464732  0.        ]
 [ 0.65555507  0.35509712  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
planes
[[ 0.2392609   0.26303735 -0.93464732]
 [ 0.66644853  0.65555507  0.35509712]
 [ 0.70611656 -0.70785517 -0.01845216]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1556.0542   -675.46893   469.50592]
[  72.40198277 -142.85384103  -29.95268053]
[ 0.   0.  -9.8]
transform [[ 0.26303735 -0.93464732  0.        ]
 [ 0.65555507  0.35509712  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
transform [[ 0.26303735 -0.93464732  0.        ]
 [ 0.65555507  0.35509712  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
transform [[ 0.26303735 -0.93464732  0.        ]
 [ 0.65555507  0.35509712  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
support
[0. 0. 0.]
[  222.02485036 -1259.93628808  1113.92486407]
[152.56238586  -3.26349998 -48.61415526]
[0. 0. 0.]
transform [[ 0.26303735  0.65555507 -0.70785517]
 [-0.93464732  0.35509712 -0.01845216]
 [ 0.          0.          0.        ]]
zmp [  412402.4297909  -4217697.16521355        0.        ]
d1:4544528.35186, d2:0.05769, d3:1479433.59929
transform [[ 0.36750671  0.84408098  0.        ]
 [-0.60322458  0.53589809  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
planes
[[ 0.39046904  0.36750671  0.84408098]
 [-0.59070581 -0.60322458  0.53589809]
 [ 0.70611656 -0.70785517 -0.01845216]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1556.0542   -675.46893   469.50592]
[  72.40198277 -142.85384103  -29.95268053]
[ 0.   0.  -9.8]
transform [[ 0.36750671  0.84408098  0.        ]
 [-0.60322458  0.53589809  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
transform [[ 0.36750671  0.84408098  0.        ]
 [-0.60322458  0.53589809  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
transform [[ 0.36750671  0.84408098  0.        ]
 [-0.60322458  0.53589809  0.        ]
 [-0.70785517 -0.01845216  0.        ]]
support
[0. 0. 0.]
[-1142.01084562   576.6676231   1113.92486407]
[ -93.97199611 -120.22975579  -48.61415526]
[0. 0. 0.]
transform [[ 0.36750671 -0.60322458 -0.70785517]
 [ 0.84408098  0.53589809 -0.01845216]
 [ 0.          0.          0.        ]]
zmp [16159600.89610769 -6479498.11164396        0.        ]
d1:22047791.65035, d2:0.05787, d3:7279467.36225
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-280.5850544174374 steps:133[00m
[RDDPG] Resetting Environment
transform [[-0.71043146 -0.06006447  0.        ]
 [-0.02073445  0.99770522  0.        ]
 [-0.70346093  0.03125237  0.        ]]
planes
[[ 0.70119864 -0.71043146 -0.06006447]
 [ 0.06445567 -0.02073445  0.99770522]
 [-0.71004647 -0.70346093  0.03125237]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1556.0542   -675.46893   469.50592]
[  72.40198277 -142.85384103  -29.95268053]
[ 0.   0.  -9.8]
transform [[-0.71043146 -0.06006447  0.        ]
 [-0.02073445  0.99770522  0.        ]
 [-0.70346093  0.03125237  0.        ]]
transform [[-0.71043146 -0.06006447  0.        ]
 [-0.02073445  0.99770522  0.        ]
 [-0.70346093  0.03125237  0.        ]]
transform [[-0.71043146 -0.06006447  0.        ]
 [-0.02073445  0.99770522  0.        ]
 [-0.70346093  0.03125237  0.        ]]
support
[0. 0. 0.]
[1146.04153372 -641.65495934 1073.51333234]
[ -42.85620604 -144.02723807  -55.39648726]
[0. 0. 0.]
transform [[-0.71043146 -0.02073445 -0.70346093]
 [-0.06006447  0.99770522  0.03125237]
 [ 0.          0.          0.        ]]
zmp [  -69804.82915055 21412591.4756269         0.        ]
d1:21825081.08518, d2:0.04167, d3:7093550.22565
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-369.97830672119034 steps:135[00m
[RDDPG] Resetting Environment
transform [[ 0.6584214   0.18368232  0.        ]
 [-0.14763315  0.98244315  0.        ]
 [-0.73802829 -0.03265566  0.        ]]
planes
[[ 0.72989184  0.6584214   0.18368232]
 [-0.11406156 -0.14763315  0.98244315]
 [ 0.67397916 -0.73802829 -0.03265566]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 600.6419  -213.26274 1316.6035 ]
[  25.02190667 -285.99546107  -15.38514586]
[ 0.   0.  -9.8]
transform [[ 0.6584214   0.18368232  0.        ]
 [-0.14763315  0.98244315  0.        ]
 [-0.73802829 -0.03265566  0.        ]]
transform [[ 0.6584214   0.18368232  0.        ]
 [-0.14763315  0.98244315  0.        ]
 [-0.73802829 -0.03265566  0.        ]]
transform [[ 0.6584214   0.18368232  0.        ]
 [-0.14763315  0.98244315  0.        ]
 [-0.73802829 -0.03265566  0.        ]]
support
[0. 0. 0.]
[ 356.30288787 -298.1931768  -436.32648328]
[ -36.05735176 -284.66834567   -9.12750545]
[0. 0. 0.]
transform [[ 0.6584214  -0.14763315 -0.73802829]
 [ 0.18368232  0.98244315 -0.03265566]
 [ 0.          0.          0.        ]]
zmp [4266378.78804461 6271225.21376487       0.        ]
d1:10494917.44341, d2:0.01763, d3:875171.42784
transform [[ 0.05507342  0.20039733  0.        ]
 [-0.35384512  0.91999042  0.        ]
 [-0.93368119 -0.33683613  0.        ]]
planes
[[ 0.97816557  0.05507342  0.20039733]
 [-0.1685565  -0.35384512  0.91999042]
 [ 0.12157669 -0.93368119 -0.33683613]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 600.6419  -213.26274 1316.6035 ]
[  25.02190667 -285.99546107  -15.38514586]
[ 0.   0.  -9.8]
transform [[ 0.05507342  0.20039733  0.        ]
 [-0.35384512  0.91999042  0.        ]
 [-0.93368119 -0.33683613  0.        ]]
transform [[ 0.05507342  0.20039733  0.        ]
 [-0.35384512  0.91999042  0.        ]
 [-0.93368119 -0.33683613  0.        ]]
transform [[ 0.05507342  0.20039733  0.        ]
 [-0.35384512  0.91999042  0.        ]
 [-0.93368119 -0.33683613  0.        ]]
support
[0. 0. 0.]
[  -9.65788075 -408.73388607 -488.973454  ]
[ -55.93468417 -271.966964     72.97112055]
[0. 0. 0.]
transform [[ 0.05507342 -0.35384512 -0.93368119]
 [ 0.20039733  0.91999042 -0.33683613]
 [ 0.          0.          0.        ]]
zmp [ -3685078.43898426 -14785768.9793975          0.        ]
d1:24714445.85660, d2:0.05685, d3:1614066.67897
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-282.9837146114412 steps:138[00m
[RDDPG] Resetting Environment
transform [[ 0.15742648  0.97634846  0.        ]
 [-0.6686064   0.21581501  0.        ]
 [-0.72676158  0.01294484  0.        ]]
planes
[[ 0.14819106  0.15742648  0.97634846]
 [-0.71161044 -0.6686064   0.21581501]
 [ 0.68676782 -0.72676158  0.01294484]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-54.090916 225.82747  811.24023 ]
[  -1.09724955 -259.46909033    5.25541754]
[ 0.   0.  -9.8]
transform [[ 0.15742648  0.97634846  0.        ]
 [-0.6686064   0.21581501  0.        ]
 [-0.72676158  0.01294484  0.        ]]
transform [[ 0.15742648  0.97634846  0.        ]
 [-0.6686064   0.21581501  0.        ]
 [-0.72676158  0.01294484  0.        ]]
transform [[ 0.15742648  0.97634846  0.        ]
 [-0.6686064   0.21581501  0.        ]
 [-0.72676158  0.01294484  0.        ]]
support
[0. 0. 0.]
[211.97095913  84.90248936  42.23449975]
[-253.50498282  -55.26369565   -2.56134702]
[0. 0. 0.]
transform [[ 0.15742648 -0.6686064  -0.72676158]
 [ 0.97634846  0.21581501  0.01294484]
 [ 0.          0.          0.        ]]
zmp [-32032167.34341498   7331328.35663947         0.        ]
d1:36454595.98433, d2:0.05904, d3:13690831.35918
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-126.24265287259233 steps:140[00m
[RDDPG] Resetting Environment
transform [[ 0.00940229  0.99945813  0.        ]
 [-0.66442263  0.02982012  0.        ]
 [-0.747298   -0.01393817  0.        ]]
planes
[[ 0.03154535  0.00940229  0.99945813]
 [-0.74676198 -0.66442263  0.02982012]
 [ 0.66434294 -0.747298   -0.01393817]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 102.36544 -834.73627 1514.5151 ]
[ -68.21701087 -577.81235511    5.31394565]
[ 0.   0.  -9.8]
transform [[ 0.00940229  0.99945813  0.        ]
 [-0.66442263  0.02982012  0.        ]
 [-0.747298   -0.01393817  0.        ]]
transform [[ 0.00940229  0.99945813  0.        ]
 [-0.66442263  0.02982012  0.        ]
 [-0.747298   -0.01393817  0.        ]]
transform [[ 0.00940229  0.99945813  0.        ]
 [-0.66442263  0.02982012  0.        ]
 [-0.747298   -0.01393817  0.        ]]
support
[0. 0. 0.]
[-833.32148276  -92.90585086  -64.86279237]
[-578.14065427   28.09449211   59.03208327]
[0. 0. 0.]
transform [[ 0.00940229 -0.66442263 -0.747298  ]
 [ 0.99945813  0.02982012 -0.01393817]
 [ 0.          0.          0.        ]]
zmp [10550853.58737568   181596.96484237        0.        ]
d1:11074241.94829, d2:0.05937, d3:3996954.98912
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-336.90712152640276 steps:142[00m
[RDDPG] Resetting Environment
transform [[ 0.7149353  -0.21066815  0.        ]
 [ 0.15217926  0.97755384  0.        ]
 [-0.68242884 -0.00271185  0.        ]]
planes
[[ 0.66669822  0.7149353  -0.21066815]
 [ 0.14570479  0.15217926  0.97755384]
 [ 0.73094708 -0.68242884 -0.00271185]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 113.44986 -166.20016 2110.5227 ]
[ -41.69229702 -879.72957569   29.27147819]
[ 0.   0.  -9.8]
transform [[ 0.7149353  -0.21066815  0.        ]
 [ 0.15217926  0.97755384  0.        ]
 [-0.68242884 -0.00271185  0.        ]]
transform [[ 0.7149353  -0.21066815  0.        ]
 [ 0.15217926  0.97755384  0.        ]
 [-0.68242884 -0.00271185  0.        ]]
transform [[ 0.7149353  -0.21066815  0.        ]
 [ 0.15217926  0.97755384  0.        ]
 [-0.68242884 -0.00271185  0.        ]]
support
[0. 0. 0.]
[ 116.12239042 -145.2048948   -76.97074652]
[ 155.52370424 -866.32773154   30.83771671]
[0. 0. 0.]
transform [[ 0.7149353   0.15217926 -0.68242884]
 [-0.21066815  0.97755384 -0.00271185]
 [ 0.          0.          0.        ]]
zmp [ -9431841.51494951 -20443100.77633362         0.        ]
d1:30631343.09592, d2:0.02206, d3:3304958.07034
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-276.3764889179573 steps:144[00m
[RDDPG] Resetting Environment
transform [[ 0.66621512  0.31454691  0.        ]
 [-0.2224988   0.94923913  0.        ]
 [-0.71179467 -0.00231617  0.        ]]
planes
[[ 0.67617875  0.66621512  0.31454691]
 [-0.22234973 -0.2224988   0.94923913]
 [ 0.70238382 -0.71179467 -0.00231617]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-522.09576  -91.43188  507.11194]
[  72.9663198  -370.86466742   -9.86796598]
[ 0.   0.  -9.8]
transform [[ 0.66621512  0.31454691  0.        ]
 [-0.2224988   0.94923913  0.        ]
 [-0.71179467 -0.00231617  0.        ]]
transform [[ 0.66621512  0.31454691  0.        ]
 [-0.2224988   0.94923913  0.        ]
 [-0.71179467 -0.00231617  0.        ]]
transform [[ 0.66621512  0.31454691  0.        ]
 [-0.2224988   0.94923913  0.        ]
 [-0.71179467 -0.00231617  0.        ]]
support
[0. 0. 0.]
[-376.58770778   29.37496733  371.83675662]
[ -68.04307061 -368.27417494  -51.07805062]
[0. 0. 0.]
transform [[ 0.66621512 -0.2224988  -0.71179467]
 [ 0.31454691  0.94923913 -0.00231617]
 [ 0.          0.          0.        ]]
zmp [7937830.51820687 6115703.14031692       0.        ]
d1:14336209.02969, d2:0.01989, d3:792562.23557
transform [[ 0.35600629 -0.02957191  0.        ]
 [ 0.04202747  0.99899459  0.        ]
 [-0.93353808  0.03369699  0.        ]]
planes
[[ 0.93401557  0.35600629 -0.02957191]
 [ 0.01561016  0.04202747  0.99899459]
 [ 0.3568911  -0.93353808  0.03369699]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-522.09576  -91.43188  507.11194]
[  72.9663198  -370.86466742   -9.86796598]
[ 0.   0.  -9.8]
transform [[ 0.35600629 -0.02957191  0.        ]
 [ 0.04202747  0.99899459  0.        ]
 [-0.93353808  0.03369699  0.        ]]
transform [[ 0.35600629 -0.02957191  0.        ]
 [ 0.04202747  0.99899459  0.        ]
 [-0.93353808  0.03369699  0.        ]]
transform [[ 0.35600629 -0.02957191  0.        ]
 [ 0.04202747  0.99899459  0.        ]
 [-0.93353808  0.03369699  0.        ]]
support
[0. 0. 0.]
[-183.165563   -113.28231443  484.31529743]
[  36.94364619 -367.42520615  -80.61386258]
[0. 0. 0.]
transform [[ 0.35600629  0.04202747 -0.93353808]
 [-0.02957191  0.99899459  0.03369699]
 [ 0.          0.          0.        ]]
zmp [ -2935503.32587585 -14706871.05572052         0.        ]
d1:22774488.03420, d2:0.05030, d3:1763729.11469
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-304.8611398687032 steps:147[00m
[RDDPG] Resetting Environment
transform [[ 0.0762324   0.98473716  0.        ]
 [-0.17182876  0.16754879  0.        ]
 [-0.98217285  0.04711918  0.        ]]
planes
[[ 0.15646544  0.0762324   0.98473716]
 [-0.97077411 -0.17182876  0.16754879]
 [ 0.18197881 -0.98217285  0.04711918]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 649.3109  -643.6644   246.41571]
[ -901.74248313 -1381.74180128   327.99177471]
[ 0.   0.  -9.8]
transform [[ 0.0762324   0.98473716  0.        ]
 [-0.17182876  0.16754879  0.        ]
 [-0.98217285  0.04711918  0.        ]]
transform [[ 0.0762324   0.98473716  0.        ]
 [-0.17182876  0.16754879  0.        ]
 [-0.98217285  0.04711918  0.        ]]
transform [[ 0.0762324   0.98473716  0.        ]
 [-0.17182876  0.16754879  0.        ]
 [-0.98217285  0.04711918  0.        ]]
support
[0. 0. 0.]
[-584.34174859 -219.41548672 -668.06448907]
[-1429.39449108   -76.56387345   820.56043886]
[0. 0. 0.]
transform [[ 0.0762324  -0.17182876 -0.98217285]
 [ 0.98473716  0.16754879  0.04711918]
 [ 0.          0.          0.        ]]
zmp [25772457.51211258  -402583.64168603        0.        ]
d1:18410155.97174, d2:0.05868, d3:11922986.85354
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-130.6189100686077 steps:149[00m
[RDDPG] Resetting Environment
transform [[ 0.69773579  0.08519652  0.        ]
 [-0.04799855  0.99623144  0.        ]
 [-0.7147454   0.01626733  0.        ]]
planes
[[ 0.71127099  0.69773579  0.08519652]
 [-0.07224412 -0.04799855  0.99623144]
 [ 0.69919556 -0.7147454   0.01626733]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-510.98584  384.12213 1146.3478 ]
[   8.73421804 -188.63688539   -5.77007986]
[ 0.   0.  -9.8]
transform [[ 0.69773579  0.08519652  0.        ]
 [-0.04799855  0.99623144  0.        ]
 [-0.7147454   0.01626733  0.        ]]
transform [[ 0.69773579  0.08519652  0.        ]
 [-0.04799855  0.99623144  0.        ]
 [-0.7147454   0.01626733  0.        ]]
transform [[ 0.69773579  0.08519652  0.        ]
 [-0.04799855  0.99623144  0.        ]
 [-0.7147454   0.01626733  0.        ]]
support
[0. 0. 0.]
[-323.80723611  407.20112093  371.47342238]
[  -9.9770306  -188.34522513   -9.31136126]
[0. 0. 0.]
transform [[ 0.69773579 -0.04799855 -0.7147454 ]
 [ 0.08519652  0.99623144  0.01626733]
 [ 0.          0.          0.        ]]
zmp [11278909.17056507 13096483.49147546        0.        ]
d1:24014850.48102, d2:0.00709, d3:459700.93678
transform [[ 0.67339027 -0.25402009  0.        ]
 [ 0.18890375  0.96706218  0.        ]
 [-0.7147454   0.01626733  0.        ]]
planes
[[ 0.69427615  0.67339027 -0.25402009]
 [ 0.17060544  0.18890375  0.96706218]
 [ 0.69919556 -0.7147454   0.01626733]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-510.98584  384.12213 1146.3478 ]
[   8.73421804 -188.63688539   -5.77007986]
[ 0.   0.  -9.8]
transform [[ 0.67339027 -0.25402009  0.        ]
 [ 0.18890375  0.96706218  0.        ]
 [-0.7147454   0.01626733  0.        ]]
transform [[ 0.67339027 -0.25402009  0.        ]
 [ 0.18890375  0.96706218  0.        ]
 [-0.7147454   0.01626733  0.        ]]
transform [[ 0.67339027 -0.25402009  0.        ]
 [ 0.18890375  0.96706218  0.        ]
 [-0.7147454   0.01626733  0.        ]]
support
[0. 0. 0.]
[-441.66763254  274.94284309  371.47342238]
[  53.79909696 -180.77367019   -9.31136126]
[0. 0. 0.]
transform [[ 0.67339027  0.18890375 -0.7147454 ]
 [-0.25402009  0.96706218  0.01626733]
 [ 0.          0.          0.        ]]
zmp [14457762.38096255 12705078.27064662        0.        ]
d1:26726531.44452, d2:0.01535, d3:932695.75503
transform [[ 0.0351848  -0.99852878  0.        ]
 [ 0.44218954  0.05257858  0.        ]
 [-0.89623129 -0.01325924  0.        ]]
planes
[[ 0.04125946  0.0351848  -0.99852878]
 [ 0.89537925  0.44218954  0.05257858]
 [ 0.44338894 -0.89623129 -0.01325924]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-510.98584  384.12213 1146.3478 ]
[   8.73421804 -188.63688539   -5.77007986]
[ 0.   0.  -9.8]
transform [[ 0.0351848  -0.99852878  0.        ]
 [ 0.44218954  0.05257858  0.        ]
 [-0.89623129 -0.01325924  0.        ]]
transform [[ 0.0351848  -0.99852878  0.        ]
 [ 0.44218954  0.05257858  0.        ]
 [-0.89623129 -0.01325924  0.        ]]
transform [[ 0.0351848  -0.99852878  0.        ]
 [ 0.44218954  0.05257858  0.        ]
 [-0.89623129 -0.01325924  0.        ]]
support
[0. 0. 0.]
[-401.53593943 -205.75600109  452.86833153]
[188.66667051  -6.0560789   -5.32669719]
[0. 0. 0.]
transform [[ 0.0351848   0.44218954 -0.89623129]
 [-0.99852878  0.05257858 -0.01325924]
 [ 0.          0.          0.        ]]
zmp [-2066451.40098437   877887.46593232        0.        ]
d1:1067397.25808, d2:0.05938, d3:941009.71393
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-446.4982626134366 steps:153[00m
[RDDPG] Resetting Environment
transform [[ 0.45998868  0.72370386  0.        ]
 [-0.53600901  0.68823391  0.        ]
 [-0.70788753 -0.05086114  0.        ]]
planes
[[ 0.51445425  0.45998868  0.72370386]
 [-0.4889054  -0.53600901  0.68823391]
 [ 0.70449162 -0.70788753 -0.05086114]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-109.79402  594.23175 -182.56752]
[ 4.14611486 -5.59321934 -1.90239704]
[ 0.   0.  -9.8]
transform [[ 0.45998868  0.72370386  0.        ]
 [-0.53600901  0.68823391  0.        ]
 [-0.70788753 -0.05086114  0.        ]]
transform [[ 0.45998868  0.72370386  0.        ]
 [-0.53600901  0.68823391  0.        ]
 [-0.70788753 -0.05086114  0.        ]]
transform [[ 0.45998868  0.72370386  0.        ]
 [-0.53600901  0.68823391  0.        ]
 [-0.70788753 -0.05086114  0.        ]]
support
[0. 0. 0.]
[379.54380485 467.82102749  47.49851302]
[-2.14066852 -6.07179817 -2.65050548]
[0. 0. 0.]
transform [[ 0.45998868 -0.53600901 -0.70788753]
 [ 0.72370386  0.68823391 -0.05086114]
 [ 0.          0.          0.        ]]
zmp [ 5831805.42591943 -5656969.67151079        0.        ]
d1:11026069.88172, d2:0.05933, d3:3858893.41371
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-318.3261859448513 steps:155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-150.86168566406818 steps:156[00m
[RDDPG] Resetting Environment
transform [[-0.57887191  0.04476453  0.        ]
 [ 0.07958987  0.99682617  0.        ]
 [-0.81152493  0.06583202  0.        ]]
planes
[[ 0.8141889  -0.57887191  0.04476453]
 [ 0.00178078  0.07958987  0.99682617]
 [-0.58059746 -0.81152493  0.06583202]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-109.79402  594.23175 -182.56752]
[ 4.14611486 -5.59321934 -1.90239704]
[ 0.   0.  -9.8]
transform [[-0.57887191  0.04476453  0.        ]
 [ 0.07958987  0.99682617  0.        ]
 [-0.81152493  0.06583202  0.        ]]
transform [[-0.57887191  0.04476453  0.        ]
 [ 0.07958987  0.99682617  0.        ]
 [-0.81152493  0.06583202  0.        ]]
transform [[-0.57887191  0.04476453  0.        ]
 [ 0.07958987  0.99682617  0.        ]
 [-0.81152493  0.06583202  0.        ]]
support
[0. 0. 0.]
[ 90.15717729 583.60726875 128.22006124]
[-2.65044723 -5.24547867 -3.73288849]
[0. 0. 0.]
transform [[-0.57887191  0.07958987 -0.81152493]
 [ 0.04476453  0.99682617  0.06583202]
 [ 0.          0.          0.        ]]
zmp [ 7236040.74199087 -3157083.03069265        0.        ]
d1:11004806.84732, d2:0.01246, d3:998416.50699
transform [[ 0.42231467 -0.82576954  0.        ]
 [ 0.69246143  0.56003851  0.        ]
 [-0.58493376  0.06679472  0.        ]]
planes
[[ 0.37383822  0.42231467 -0.82576954]
 [ 0.45481208  0.69246143  0.56003851]
 [ 0.80832601 -0.58493376  0.06679472]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-52.601562 252.07077  102.765945]
[  532.31552685 -2669.00917465  -744.43791868]
[ 0.   0.  -9.8]
transform [[ 0.42231467 -0.82576954  0.        ]
 [ 0.69246143  0.56003851  0.        ]
 [-0.58493376  0.06679472  0.        ]]
transform [[ 0.42231467 -0.82576954  0.        ]
 [ 0.69246143  0.56003851  0.        ]
 [-0.58493376  0.06679472  0.        ]]
transform [[ 0.42231467 -0.82576954  0.        ]
 [ 0.69246143  0.56003851  0.        ]
 [-0.58493376  0.06679472  0.        ]]
support
[0. 0. 0.]
[-230.36677663  104.74478459   47.60542696]
[ 2428.79114615 -1126.13994182  -489.64505068]
[0. 0. 0.]
transform [[ 0.42231467  0.69246143 -0.58493376]
 [-0.82576954  0.56003851  0.06679472]
 [ 0.          0.          0.        ]]
zmp [5721778.51918082 1164464.88762173       0.        ]
d1:5861851.07620, d2:0.05303, d3:1989277.15693
transform [[-0.42307606 -0.31788215  0.        ]
 [ 0.81165886 -0.54920721  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
planes
[[ 0.84850317 -0.42307606 -0.31788215]
 [ 0.19895065  0.81165886 -0.54920721]
 [ 0.49036831  0.40276119  0.77286631]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-52.601562 252.07077  102.765945]
[  532.31552685 -2669.00917465  -744.43791868]
[ 0.   0.  -9.8]
transform [[-0.42307606 -0.31788215  0.        ]
 [ 0.81165886 -0.54920721  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
transform [[-0.42307606 -0.31788215  0.        ]
 [ 0.81165886 -0.54920721  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
transform [[-0.42307606 -0.31788215  0.        ]
 [ 0.81165886 -0.54920721  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
support
[0. 0. 0.]
[ -57.87433652 -181.13360881  173.63113777]
[  623.22041832  1897.897697   -1848.39123302]
[0. 0. 0.]
transform [[-0.42307606  0.81165886  0.40276119]
 [-0.31788215 -0.54920721  0.77286631]
 [ 0.          0.          0.        ]]
zmp [-15220161.84649738  16328243.65943737         0.        ]
d1:12179193.16676, d2:0.02731, d3:8573443.03767
transform [[-0.42094144 -0.31932446  0.        ]
 [ 0.81276792 -0.54836988  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
planes
[[ 0.8490231  -0.42094144 -0.31932446]
 [ 0.19671994  0.81276792 -0.54836988]
 [ 0.49036831  0.40276119  0.77286631]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-52.601562 252.07077  102.765945]
[  532.31552685 -2669.00917465  -744.43791868]
[ 0.   0.  -9.8]
transform [[-0.42094144 -0.31932446  0.        ]
 [ 0.81276792 -0.54836988  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
transform [[-0.42094144 -0.31932446  0.        ]
 [ 0.81276792 -0.54836988  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
transform [[-0.42094144 -0.31932446  0.        ]
 [ 0.81276792 -0.54836988  0.        ]
 [ 0.40276119  0.77286631  0.        ]]
support
[0. 0. 0.]
[ -58.35018592 -180.98088187  173.63113777]
[  628.20625745  1896.25323788 -1848.39123302]
[0. 0. 0.]
transform [[-0.42094144  0.81276792  0.40276119]
 [-0.31932446 -0.54836988  0.77286631]
 [ 0.          0.          0.        ]]
zmp [-15244132.7991287  16310145.7932904         0.       ]
d1:12163632.77289, d2:0.02740, d3:8583018.33524
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-1083.7251407662568 steps:161[00m
[RDDPG] Resetting Environment
transform [[ 0.30292377 -0.90803188  0.        ]
 [ 0.63882613  0.41876519  0.        ]
 [-0.70720464 -0.01067064  0.        ]]
planes
[[ 0.289336    0.30292377 -0.90803188]
 [ 0.64539677  0.63882613  0.41876519]
 [ 0.70692843 -0.70720464 -0.01067064]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -19.0964   435.6513  1000.43134]
[ -74.90214111 -306.52413987   49.12269134]
[ 0.   0.  -9.8]
transform [[ 0.30292377 -0.90803188  0.        ]
 [ 0.63882613  0.41876519  0.        ]
 [-0.70720464 -0.01067064  0.        ]]
transform [[ 0.30292377 -0.90803188  0.        ]
 [ 0.63882613  0.41876519  0.        ]
 [-0.70720464 -0.01067064  0.        ]]
transform [[ 0.30292377 -0.90803188  0.        ]
 [ 0.63882613  0.41876519  0.        ]
 [-0.70720464 -0.01067064  0.        ]]
support
[0. 0. 0.]
[-401.37002817  170.2363219     8.8563825 ]
[ 255.64405238 -176.21108391   56.24195149]
[0. 0. 0.]
transform [[ 0.30292377  0.63882613 -0.70720464]
 [-0.90803188  0.41876519 -0.01067064]
 [ 0.          0.          0.        ]]
zmp [20869396.89559754  6536210.55193586        0.        ]
d1:27909331.61559, d2:0.05526, d3:4896658.05607
transform [[ 0.31799108  0.88824224  0.        ]
 [-0.63146126  0.4592514   0.        ]
 [-0.70720464 -0.01067064  0.        ]]
planes
[[ 0.33152282  0.31799108  0.88824224]
 [-0.62477589 -0.63146126  0.4592514 ]
 [ 0.70692843 -0.70720464 -0.01067064]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -19.0964   435.6513  1000.43134]
[ -74.90214111 -306.52413987   49.12269134]
[ 0.   0.  -9.8]
transform [[ 0.31799108  0.88824224  0.        ]
 [-0.63146126  0.4592514   0.        ]
 [-0.70720464 -0.01067064  0.        ]]
transform [[ 0.31799108  0.88824224  0.        ]
 [-0.63146126  0.4592514   0.        ]
 [-0.70720464 -0.01067064  0.        ]]
transform [[ 0.31799108  0.88824224  0.        ]
 [-0.63146126  0.4592514   0.        ]
 [-0.70720464 -0.01067064  0.        ]]
support
[0. 0. 0.]
[380.89140949 212.13211034   8.8563825 ]
[-296.08590265  -93.47384093   56.24195149]
[0. 0. 0.]
transform [[ 0.31799108 -0.63146126 -0.70720464]
 [ 0.88824224  0.4592514  -0.01067064]
 [ 0.          0.          0.        ]]
zmp [1552944.87761865 7151858.57851494       0.        ]
d1:8946470.09557, d2:0.05492, d3:1816910.79167
transform [[ 0.3416658   0.87897193  0.        ]
 [ 0.70547974 -0.00599526  0.        ]
 [-0.62093711  0.47683597  0.        ]]
planes
[[ 0.3326754   0.3416658   0.87897193]
 [-0.70870483  0.70547974 -0.00599526]
 [-0.62214524 -0.62093711  0.47683597]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[  572.5053  1212.9535 -2585.3433]
[  86.29260485 -228.67093178 -105.69207491]
[ 0.   0.  -9.8]
transform [[ 0.3416658   0.87897193  0.        ]
 [ 0.70547974 -0.00599526  0.        ]
 [-0.62093711  0.47683597  0.        ]]
transform [[ 0.3416658   0.87897193  0.        ]
 [ 0.70547974 -0.00599526  0.        ]
 [-0.62093711  0.47683597  0.        ]]
transform [[ 0.3416658   0.87897193  0.        ]
 [ 0.70547974 -0.00599526  0.        ]
 [-0.62093711  0.47683597  0.        ]]
support
[0. 0. 0.]
[1261.75756368  396.61892796  222.89005772]
[-171.51209898   62.24862592 -162.62080526]
[0. 0. 0.]
transform [[ 0.3416658   0.70547974 -0.62093711]
 [ 0.87897193 -0.00599526  0.47683597]
 [ 0.          0.          0.        ]]
zmp [1744066.22808044 1840477.90422193       0.        ]
d1:4468197.45684, d2:0.05221, d3:1157736.27945
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-124.88724862062455 steps:165[00m
[RDDPG] Resetting Environment
transform [[ 0.10758757  0.98322368  0.        ]
 [-0.69484013  0.18032752  0.        ]
 [-0.71107113 -0.02744615  0.        ]]
planes
[[ 0.14729638  0.10758757  0.98322368]
 [-0.69618905 -0.69484013  0.18032752]
 [ 0.70258421 -0.71107113 -0.02744615]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[324.72363 385.45703 570.09534]
[ 263.21488223 -673.20581147 -102.12631051]
[ 0.   0.  -9.8]
transform [[ 0.10758757  0.98322368  0.        ]
 [-0.69484013  0.18032752  0.        ]
 [-0.71107113 -0.02744615  0.        ]]
transform [[ 0.10758757  0.98322368  0.        ]
 [-0.69484013  0.18032752  0.        ]
 [-0.71107113 -0.02744615  0.        ]]
transform [[ 0.10758757  0.98322368  0.        ]
 [-0.69484013  0.18032752  0.        ]
 [-0.71107113 -0.02744615  0.        ]]
support
[0. 0. 0.]
[ 413.92670554 -156.12250185 -241.48091278]
[-633.59324396 -304.28979811 -168.68759774]
[0. 0. 0.]
transform [[ 0.10758757 -0.69484013 -0.71107113]
 [ 0.98322368  0.18032752 -0.02744615]
 [ 0.          0.          0.        ]]
zmp [-5375739.01924658  1715132.62323759        0.        ]
d1:6812560.13722, d2:0.05905, d3:2289819.16589
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-162.19884487221955 steps:167[00m
[RDDPG] Resetting Environment
transform [[-0.68004549  0.23624796  0.        ]
 [ 0.19523129  0.97083324  0.        ]
 [-0.7066986   0.04086277  0.        ]]
planes
[[ 0.69406414 -0.68004549  0.23624796]
 [-0.13916756  0.19523129  0.97083324]
 [-0.70633376 -0.7066986   0.04086277]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[324.72363 385.45703 570.09534]
[ 263.21488223 -673.20581147 -102.12631051]
[ 0.   0.  -9.8]
transform [[-0.68004549  0.23624796  0.        ]
 [ 0.19523129  0.97083324  0.        ]
 [-0.7066986   0.04086277  0.        ]]
transform [[-0.68004549  0.23624796  0.        ]
 [ 0.19523129  0.97083324  0.        ]
 [-0.7066986   0.04086277  0.        ]]
transform [[-0.68004549  0.23624796  0.        ]
 [ 0.19523129  0.97083324  0.        ]
 [-0.7066986   0.04086277  0.        ]]
support
[0. 0. 0.]
[-129.76340448  437.61071257 -213.73089397]
[-338.04158981 -602.18279979 -213.52264133]
[0. 0. 0.]
transform [[-0.68004549  0.19523129 -0.7066986 ]
 [ 0.23624796  0.97083324  0.04086277]
 [ 0.          0.          0.        ]]
zmp [ 7255332.02719607 -9461735.64441879        0.        ]
d1:16199889.74012, d2:0.01622, d3:1120699.99657
transform [[-0.69813955 -0.20225757  0.        ]
 [-0.11479682  0.9784795   0.        ]
 [-0.7066986   0.04086277  0.        ]]
planes
[[ 0.68679923 -0.69813955 -0.20225757]
 [ 0.17146304 -0.11479682  0.9784795 ]
 [-0.70633376 -0.7066986   0.04086277]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[324.72363 385.45703 570.09534]
[ 263.21488223 -673.20581147 -102.12631051]
[ 0.   0.  -9.8]
transform [[-0.69813955 -0.20225757  0.        ]
 [-0.11479682  0.9784795   0.        ]
 [-0.7066986   0.04086277  0.        ]]
transform [[-0.69813955 -0.20225757  0.        ]
 [-0.11479682  0.9784795   0.        ]
 [-0.7066986   0.04086277  0.        ]]
transform [[-0.69813955 -0.20225757  0.        ]
 [-0.11479682  0.9784795   0.        ]
 [-0.7066986   0.04086277  0.        ]]
support
[0. 0. 0.]
[-304.6640142   339.88456543 -213.73089397]
[ -47.59974502 -688.93431964 -213.52264133]
[0. 0. 0.]
transform [[-0.69813955 -0.11479682 -0.7066986 ]
 [-0.20225757  0.9784795   0.04086277]
 [ 0.          0.          0.        ]]
zmp [10109705.83690096 -9532132.56319197        0.        ]
d1:19053918.23727, d2:0.01221, d3:578717.43140
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-192.04954775633848 steps:170[00m
[RDDPG] Resetting Environment
transform [[ 0.11729874 -0.99136484  0.        ]
 [ 0.69412047  0.12406071  0.        ]
 [-0.71023786 -0.04248262  0.        ]]
planes
[[ 0.05862456  0.11729874 -0.99136484]
 [ 0.70908797  0.69412047  0.12406071]
 [ 0.7026788  -0.71023786 -0.04248262]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 104.62255 -209.32985  750.1367 ]
[ -91.15340639 -408.86013252   45.61832787]
[ 0.   0.  -9.8]
transform [[ 0.11729874 -0.99136484  0.        ]
 [ 0.69412047  0.12406071  0.        ]
 [-0.71023786 -0.04248262  0.        ]]
transform [[ 0.11729874 -0.99136484  0.        ]
 [ 0.69412047  0.12406071  0.        ]
 [-0.71023786 -0.04248262  0.        ]]
transform [[ 0.11729874 -0.99136484  0.        ]
 [ 0.69412047  0.12406071  0.        ]
 [-0.71023786 -0.04248262  0.        ]]
support
[0. 0. 0.]
[219.7943457   46.65104517 -65.4140167 ]
[ 394.63737837 -113.9949214    82.11004927]
[0. 0. 0.]
transform [[ 0.11729874  0.69412047 -0.71023786]
 [-0.99136484  0.12406071 -0.04248262]
 [ 0.          0.          0.        ]]
zmp [9989843.91014418 1020608.17587054       0.        ]
d1:11048730.19333, d2:0.05925, d3:2901072.41777
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-244.02652501224853 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-49.91416027344683 steps:173[00m
[RDDPG] Resetting Environment
transform [[ 0.67907101  0.07775772  0.        ]
 [-0.06601615  0.99681365  0.        ]
 [-0.73109818 -0.01778527  0.        ]]
planes
[[ 0.72994268  0.67907101  0.07775772]
 [-0.04477107 -0.06601615  0.99681365]
 [ 0.68204045 -0.73109818 -0.01778527]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 831.26636  121.15557 -260.51584]
[ -28.29001769 -344.96909639   17.76630342]
[ 0.   0.  -9.8]
transform [[ 0.67907101  0.07775772  0.        ]
 [-0.06601615  0.99681365  0.        ]
 [-0.73109818 -0.01778527  0.        ]]
transform [[ 0.67907101  0.07775772  0.        ]
 [-0.06601615  0.99681365  0.        ]
 [-0.73109818 -0.01778527  0.        ]]
transform [[ 0.67907101  0.07775772  0.        ]
 [-0.06601615  0.99681365  0.        ]
 [-0.73109818 -0.01778527  0.        ]]
support
[0. 0. 0.]
[ 573.90966562   65.8925271  -609.89210163]
[ -46.03494252 -342.00230789   26.81814939]
[0. 0. 0.]
transform [[ 0.67907101 -0.06601615 -0.73109818]
 [ 0.07775772  0.99681365 -0.01778527]
 [ 0.          0.          0.        ]]
zmp [  2865841.10454219 -14056149.69943925         0.        ]
d1:16316760.55785, d2:0.05075, d3:5417270.20674
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-579.7294900216453 steps:175[00m
[RDDPG] Resetting Environment
transform [[ 0.60934103  0.15682586  0.        ]
 [-0.05437563  0.98620254  0.        ]
 [-0.79104161  0.05301245  0.        ]]
planes
[[ 0.77724463  0.60934103  0.15682586]
 [-0.15635845 -0.05437563  0.98620254]
 [ 0.60946119 -0.79104161  0.05301245]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -18.560616  471.8248   -208.83098 ]
[ -0.33640129 -77.33480868 -14.13502061]
[ 0.   0.  -9.8]
transform [[ 0.60934103  0.15682586  0.        ]
 [-0.05437563  0.98620254  0.        ]
 [-0.79104161  0.05301245  0.        ]]
transform [[ 0.60934103  0.15682586  0.        ]
 [-0.05437563  0.98620254  0.        ]
 [-0.79104161  0.05301245  0.        ]]
transform [[ 0.60934103  0.15682586  0.        ]
 [-0.05437563  0.98620254  0.        ]
 [-0.79104161  0.05301245  0.        ]]
support
[0. 0. 0.]
[ 62.68458312 466.32405902  39.69480922]
[-12.33308063 -76.24949257  -3.83360049]
[0. 0. 0.]
transform [[ 0.60934103 -0.05437563 -0.79104161]
 [ 0.15682586  0.98620254  0.05301245]
 [ 0.          0.          0.        ]]
zmp [13631547.22038033  1772094.56016582        0.        ]
d1:15789837.94027, d2:0.03136, d3:3810412.07334
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-555.0596194744809 steps:177[00m
[RDDPG] Resetting Environment
transform [[ 0.39199018 -0.85316581  0.        ]
 [ 0.61776638  0.52132386  0.        ]
 [-0.68169528 -0.01815522  0.        ]]
planes
[[ 0.34416828  0.39199018 -0.85316581]
 [ 0.58871579  0.61776638  0.52132386]
 [ 0.73141098 -0.68169528 -0.01815522]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-216.68237  195.37239  389.278  ]
[-47.95847552 -54.92097353  12.07895946]
[ 0.   0.  -9.8]
transform [[ 0.39199018 -0.85316581  0.        ]
 [ 0.61776638  0.52132386  0.        ]
 [-0.68169528 -0.01815522  0.        ]]
transform [[ 0.39199018 -0.85316581  0.        ]
 [ 0.61776638  0.52132386  0.        ]
 [-0.68169528 -0.01815522  0.        ]]
transform [[ 0.39199018 -0.85316581  0.        ]
 [ 0.61776638  0.52132386  0.        ]
 [-0.68169528 -0.01815522  0.        ]]
support
[0. 0. 0.]
[-251.62240654  -32.00679645  144.16432368]
[ 28.05744493 -58.25874772  33.69016861]
[0. 0. 0.]
transform [[ 0.39199018  0.61776638 -0.68169528]
 [-0.85316581  0.52132386 -0.01815522]
 [ 0.          0.          0.        ]]
zmp [-8191787.69016055 -4929999.71189945        0.        ]
d1:13496208.85229, d2:0.05154, d3:1002362.49138
transform [[ 0.24796514 -0.9110496   0.        ]
 [ 0.76687777  0.39235714  0.        ]
 [-0.5919559   0.12666723  0.        ]]
planes
[[ 0.32939643  0.24796514 -0.9110496 ]
 [ 0.50789213  0.76687777  0.39235714]
 [ 0.79595453 -0.5919559   0.12666723]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-216.68237  195.37239  389.278  ]
[-47.95847552 -54.92097353  12.07895946]
[ 0.   0.  -9.8]
transform [[ 0.24796514 -0.9110496   0.        ]
 [ 0.76687777  0.39235714  0.        ]
 [-0.5919559   0.12666723  0.        ]]
transform [[ 0.24796514 -0.9110496   0.        ]
 [ 0.76687777  0.39235714  0.        ]
 [-0.5919559   0.12666723  0.        ]]
transform [[ 0.24796514 -0.9110496   0.        ]
 [ 0.76687777  0.39235714  0.        ]
 [-0.5919559   0.12666723  0.        ]]
support
[0. 0. 0.]
[-231.72361473  -89.51314251  153.01368901]
[ 38.14370101 -58.32692492  21.43261489]
[0. 0. 0.]
transform [[ 0.24796514  0.76687777 -0.5919559 ]
 [-0.9110496   0.39235714  0.12666723]
 [ 0.          0.          0.        ]]
zmp [-13569125.04011685 -11220804.07720049         0.        ]
d1:20778710.47030, d2:0.05413, d3:7214066.14445
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-274.3009274607367 steps:180[00m
[RDDPG] Resetting Environment
transform [[ 0.65649205  0.20233424  0.        ]
 [-0.1452931   0.97923344  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
planes
[[ 0.72669053  0.65649205  0.20233424]
 [-0.14139265 -0.1452931   0.97923344]
 [ 0.67225677 -0.74020815 -0.01275996]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[150.11517 130.3051  -60.83095]
[ -66.61895425 -176.988605     33.25505989]
[ 0.   0.  -9.8]
transform [[ 0.65649205  0.20233424  0.        ]
 [-0.1452931   0.97923344  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
transform [[ 0.65649205  0.20233424  0.        ]
 [-0.1452931   0.97923344  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
transform [[ 0.65649205  0.20233424  0.        ]
 [-0.1452931   0.97923344  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
support
[0. 0. 0.]
[ 124.91460184  105.78841217 -112.77916187]
[ -79.54566904 -163.63388668   51.57025956]
[0. 0. 0.]
transform [[ 0.65649205 -0.1452931  -0.74020815]
 [ 0.20233424  0.97923344 -0.01275996]
 [ 0.          0.          0.        ]]
zmp [ 979643.96748247 7149020.09993268       0.        ]
d1:8257226.26993, d2:0.03935, d3:2033395.88246
transform [[ 0.67142844  0.03908364  0.        ]
 [-0.03571709  0.99915451  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
planes
[[ 0.74003804  0.67142844  0.03908364]
 [-0.02036263 -0.03571709  0.99915451]
 [ 0.67225677 -0.74020815 -0.01275996]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[150.11517 130.3051  -60.83095]
[ -66.61895425 -176.988605     33.25505989]
[ 0.   0.  -9.8]
transform [[ 0.67142844  0.03908364  0.        ]
 [-0.03571709  0.99915451  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
transform [[ 0.67142844  0.03908364  0.        ]
 [-0.03571709  0.99915451  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
transform [[ 0.67142844  0.03908364  0.        ]
 [-0.03571709  0.99915451  0.        ]
 [-0.74020815 -0.01275996  0.        ]]
support
[0. 0. 0.]
[ 105.8843942   124.83325006 -112.77916187]
[ -51.64721911 -174.45952722   51.57025956]
[0. 0. 0.]
transform [[ 0.67142844 -0.03571709 -0.74020815]
 [ 0.03908364  0.99915451 -0.01275996]
 [ 0.          0.          0.        ]]
zmp [1775692.24052233 7293742.62016837       0.        ]
d1:9186957.01595, d2:0.03336, d3:1834336.96885
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-369.3329104172308 steps:183[00m
[RDDPG] Resetting Environment
transform [[ 0.10171962  0.98541123  0.        ]
 [-0.69328952  0.16858409  0.        ]
 [-0.71344435 -0.02332616  0.        ]]
planes
[[ 0.13644715  0.10171962  0.98541123]
 [-0.70066333 -0.69328952  0.16858409]
 [ 0.70032358 -0.71344435 -0.02332616]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[177.74568 924.7068  183.39409]
[ 23.57145014 -48.50797508  -9.60929508]
[ 0.   0.  -9.8]
transform [[ 0.10171962  0.98541123  0.        ]
 [-0.69328952  0.16858409  0.        ]
 [-0.71344435 -0.02332616  0.        ]]
transform [[ 0.10171962  0.98541123  0.        ]
 [-0.69328952  0.16858409  0.        ]
 [-0.71344435 -0.02332616  0.        ]]
transform [[ 0.10171962  0.98541123  0.        ]
 [-0.69328952  0.16858409  0.        ]
 [-0.71344435 -0.02332616  0.        ]]
support
[0. 0. 0.]
[ 929.29667229   32.66163731 -148.38150988]
[-45.40262433 -24.51951232 -15.68541326]
[0. 0. 0.]
transform [[ 0.10171962 -0.69328952 -0.71344435]
 [ 0.98541123  0.16858409 -0.02332616]
 [ 0.          0.          0.        ]]
zmp [16203070.85645253  -925921.20603789        0.        ]
d1:16988546.45202, d2:0.05889, d3:5642562.57613
transform [[ 0.10202214  0.98507202  0.        ]
 [ 0.68004149  0.03266402  0.        ]
 [-0.72604072  0.16901541  0.        ]]
planes
[[ 0.13865289  0.10202214  0.98507202]
 [-0.73244566  0.68004149  0.03266402]
 [-0.66655743 -0.72604072  0.16901541]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 558.42554 -608.55615 -474.57983]
[ -33.76217104 -643.75390492    6.715969  ]
[ 0.   0.  -9.8]
transform [[ 0.10202214  0.98507202  0.        ]
 [ 0.68004149  0.03266402  0.        ]
 [-0.72604072  0.16901541  0.        ]]
transform [[ 0.10202214  0.98507202  0.        ]
 [ 0.68004149  0.03266402  0.        ]
 [-0.72604072  0.16901541  0.        ]]
transform [[ 0.10202214  0.98507202  0.        ]
 [ 0.68004149  0.03266402  0.        ]
 [-0.72604072  0.16901541  0.        ]]
support
[0. 0. 0.]
[-542.49986727  359.87464305 -508.29504567]
[-637.58844637  -43.98726974  -84.29161761]
[0. 0. 0.]
transform [[ 0.10202214  0.68004149 -0.72604072]
 [ 0.98507202  0.03266402  0.16901541]
 [ 0.          0.          0.        ]]
zmp [12677451.70684594  -211607.05395483        0.        ]
d1:14455795.50375, d2:0.05884, d3:4138701.56627
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-342.2735090999568 steps:186[00m
[RDDPG] Resetting Environment
transform [[-0.68841642 -0.18189247  0.        ]
 [-0.13125454  0.98330367  0.        ]
 [-0.71334076 -0.00539054  0.        ]]
planes
[[ 0.70213819 -0.68841642 -0.18189247]
 [ 0.12604037 -0.13125454  0.98330367]
 [-0.7007966  -0.71334076 -0.00539054]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 558.42554 -608.55615 -474.57983]
[ -33.76217104 -643.75390492    6.715969  ]
[ 0.   0.  -9.8]
transform [[-0.68841642 -0.18189247  0.        ]
 [-0.13125454  0.98330367  0.        ]
 [-0.71334076 -0.00539054  0.        ]]
transform [[-0.68841642 -0.18189247  0.        ]
 [-0.13125454  0.98330367  0.        ]
 [-0.71334076 -0.00539054  0.        ]]
transform [[-0.68841642 -0.18189247  0.        ]
 [-0.13125454  0.98330367  0.        ]
 [-0.71334076 -0.00539054  0.        ]]
support
[0. 0. 0.]
[-273.73752849 -671.69138202 -395.06724909]
[ 140.3364205  -628.57413659   27.55411524]
[0. 0. 0.]
transform [[-0.68841642 -0.13125454 -0.71334076]
 [-0.18189247  0.98330367 -0.00539054]
 [ 0.          0.          0.        ]]
zmp [   678143.69643866 -10678619.7552274          0.        ]
d1:11149694.40720, d2:0.04050, d3:3304396.43066
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-225.07069378658616 steps:188[00m
[RDDPG] Resetting Environment
transform [[-0.66913801  0.28114402  0.        ]
 [ 0.19449954  0.95966339  0.        ]
 [-0.71723384 -0.00204963  0.        ]]
planes
[[ 0.68790436 -0.66913801  0.28114402]
 [-0.20301747  0.19449954  0.95966339]
 [-0.69682968 -0.71723384 -0.00204963]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 558.42554 -608.55615 -474.57983]
[ -33.76217104 -643.75390492    6.715969  ]
[ 0.   0.  -9.8]
transform [[-0.66913801  0.28114402  0.        ]
 [ 0.19449954  0.95966339  0.        ]
 [-0.71723384 -0.00204963  0.        ]]
transform [[-0.66913801  0.28114402  0.        ]
 [ 0.19449954  0.95966339  0.        ]
 [-0.71723384 -0.00204963  0.        ]]
transform [[-0.66913801  0.28114402  0.        ]
 [ 0.19449954  0.95966339  0.        ]
 [-0.71723384 -0.00204963  0.        ]]
support
[0. 0. 0.]
[-544.7556799  -475.39555223 -399.27437266]
[-158.39601053 -624.35378208   25.53483181]
[0. 0. 0.]
transform [[-0.66913801  0.19449954 -0.71723384]
 [ 0.28114402  0.95966339 -0.00204963]
 [ 0.          0.          0.        ]]
zmp [ 5496184.17994265 -1368564.50908083        0.        ]
d1:6686342.08854, d2:0.03320, d3:1378111.44069
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-308.82989343069744 steps:190[00m
[RDDPG] Resetting Environment
transform [[ 0.69116026 -0.21888402  0.        ]
 [ 0.13941675  0.97551292  0.        ]
 [-0.70912659 -0.02154917  0.        ]]
planes
[[ 0.68875778  0.69116026 -0.21888402]
 [ 0.17011042  0.13941675  0.97551292]
 [ 0.70475185 -0.70912659 -0.02154917]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 85.31859  -12.882988 116.02031 ]
[ 126.94233302 -298.27224714  -60.87330273]
[ 0.   0.  -9.8]
transform [[ 0.69116026 -0.21888402  0.        ]
 [ 0.13941675  0.97551292  0.        ]
 [-0.70912659 -0.02154917  0.        ]]
transform [[ 0.69116026 -0.21888402  0.        ]
 [ 0.13941675  0.97551292  0.        ]
 [-0.70912659 -0.02154917  0.        ]]
transform [[ 0.69116026 -0.21888402  0.        ]
 [ 0.13941675  0.97551292  0.        ]
 [-0.70912659 -0.02154917  0.        ]]
support
[0. 0. 0.]
[ 61.78869799  -0.67268059 -60.22406196]
[ 153.02452492 -273.27054325  -83.59066379]
[0. 0. 0.]
transform [[ 0.69116026  0.13941675 -0.70912659]
 [-0.21888402  0.97551292 -0.02154917]
 [ 0.          0.          0.        ]]
zmp [5655534.92282625 3398942.85347037       0.        ]
d1:9252644.20211, d2:0.01919, d3:800249.95226
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-322.53276358304936 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-119.83245861328575 steps:193[00m
[RDDPG] Resetting Environment
transform [[ 3.06030121e-02 -9.66513038e-01  0.00000000e+00]
 [-2.87408504e-04  2.54897088e-01  0.00000000e+00]
 [-9.99531567e-01 -2.96653621e-02  0.00000000e+00]]
planes
[[ 2.54786193e-01  3.06030121e-02 -9.66513038e-01]
 [ 9.66968179e-01 -2.87408504e-04  2.54897088e-01]
 [ 7.52283307e-03 -9.99531567e-01 -2.96653621e-02]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 494.9228    22.38392 -364.11615]
[ 126.94233302 -298.27224714  -60.87330273]
[ 0.   0.  -9.8]
transform [[ 3.06030121e-02 -9.66513038e-01  0.00000000e+00]
 [-2.87408504e-04  2.54897088e-01  0.00000000e+00]
 [-9.99531567e-01 -2.96653621e-02  0.00000000e+00]]
transform [[ 3.06030121e-02 -9.66513038e-01  0.00000000e+00]
 [-2.87408504e-04  2.54897088e-01  0.00000000e+00]
 [-9.99531567e-01 -2.96653621e-02  0.00000000e+00]]
transform [[ 3.06030121e-02 -9.66513038e-01  0.00000000e+00]
 [-2.87408504e-04  2.54897088e-01  0.00000000e+00]
 [-9.99531567e-01 -2.96653621e-02  0.00000000e+00]]
support
[0. 0. 0.]
[  -6.48822303    5.56335117 -495.35497952]
[ 292.16883339  -76.06521148 -118.03451484]
[0. 0. 0.]
transform [[ 3.06030121e-02 -2.87408504e-04 -9.99531567e-01]
 [-9.66513038e-01  2.54897088e-01 -2.96653621e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]
zmp [ 9146664.44601736 -7876997.65798467        0.        ]
d1:8557320.96898, d2:0.05850, d3:4296352.59288
transform [[-0.765948   -0.0706617   0.        ]
 [-0.19731496  0.97180921  0.        ]
 [-0.61187452 -0.2249306   0.        ]]
planes
[[ 0.63900751 -0.765948   -0.0706617 ]
 [-0.12904905 -0.19731496  0.97180921]
 [-0.75829798 -0.61187452 -0.2249306 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-339.16068  256.228   -122.85016]
[-27.84961184 -13.91383425  12.52838148]
[ 0.   0.  -9.8]
transform [[-0.765948   -0.0706617   0.        ]
 [-0.19731496  0.97180921  0.        ]
 [-0.61187452 -0.2249306   0.        ]]
transform [[-0.765948   -0.0706617   0.        ]
 [-0.19731496  0.97180921  0.        ]
 [-0.61187452 -0.2249306   0.        ]]
transform [[-0.765948   -0.0706617   0.        ]
 [-0.19731496  0.97180921  0.        ]
 [-0.61187452 -0.2249306   0.        ]]
support
[0. 0. 0.]
[241.67393374 315.92620273 149.89025862]
[22.31452962 -8.02644712 20.17011498]
[0. 0. 0.]
transform [[-0.765948   -0.19731496 -0.61187452]
 [-0.0706617   0.97180921 -0.2249306 ]
 [ 0.          0.          0.        ]]
zmp [-2559980.60025511  1694829.65468757        0.        ]
d1:3370696.63573, d2:0.01749, d3:284216.07073
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-676.5819066706049 steps:196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-197.88523766600727 steps:197[00m
[RDDPG] Resetting Environment
transform [[ 0.28874531 -0.89635247  0.        ]
 [ 0.63885868  0.44210273  0.        ]
 [-0.71308196  0.03312886  0.        ]]
planes
[[ 0.33642012  0.28874531 -0.89635247]
 [ 0.6296069   0.63885868  0.44210273]
 [ 0.70029759 -0.71308196  0.03312886]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 401.56894   -14.872826 -128.39728 ]
[-121.57397809 -222.90252931   54.41806416]
[ 0.   0.  -9.8]
transform [[ 0.28874531 -0.89635247  0.        ]
 [ 0.63885868  0.44210273  0.        ]
 [-0.71308196  0.03312886  0.        ]]
transform [[ 0.28874531 -0.89635247  0.        ]
 [ 0.63885868  0.44210273  0.        ]
 [-0.71308196  0.03312886  0.        ]]
transform [[ 0.28874531 -0.89635247  0.        ]
 [ 0.63885868  0.44210273  0.        ]
 [-0.71308196  0.03312886  0.        ]]
support
[0. 0. 0.]
[ 129.28244338  249.97048399 -286.84428433]
[ 164.69531624 -176.21440747   79.30770393]
[0. 0. 0.]
transform [[ 0.28874531  0.63885868 -0.71308196]
 [-0.89635247  0.44210273  0.03312886]
 [ 0.          0.          0.        ]]
zmp [ 476786.57659977 4272775.95852838       0.        ]
d1:4675419.64337, d2:0.05619, d3:1279979.97318
transform [[ 0.22770296 -0.94617575  0.        ]
 [ 0.56037974  0.32050869  0.        ]
 [-0.79632026 -0.04500757  0.        ]]
planes
[[ 0.23000622  0.22770296 -0.94617575]
 [ 0.76370722  0.56037974  0.32050869]
 [ 0.60319853 -0.79632026 -0.04500757]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 401.56894   -14.872826 -128.39728 ]
[-121.57397809 -222.90252931   54.41806416]
[ 0.   0.  -9.8]
transform [[ 0.22770296 -0.94617575  0.        ]
 [ 0.56037974  0.32050869  0.        ]
 [-0.79632026 -0.04500757  0.        ]]
transform [[ 0.22770296 -0.94617575  0.        ]
 [ 0.56037974  0.32050869  0.        ]
 [-0.79632026 -0.04500757  0.        ]]
transform [[ 0.22770296 -0.94617575  0.        ]
 [ 0.56037974  0.32050869  0.        ]
 [-0.79632026 -0.04500757  0.        ]]
support
[0. 0. 0.]
[ 105.51074325  220.26422934 -319.1080922 ]
[ 183.22221404 -139.56979204  106.8441225 ]
[0. 0. 0.]
transform [[ 0.22770296  0.56037974 -0.79632026]
 [-0.94617575  0.32050869 -0.04500757]
 [ 0.          0.          0.        ]]
zmp [-11343571.95898565  -5929754.87524746         0.        ]
d1:8704515.59962, d2:0.05649, d3:5189917.29838
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-544.6828100909838 steps:200[00m
[RDDPG] Resetting Environment
transform [[ 2.24937901e-01  9.51296389e-01  0.00000000e+00]
 [-6.95580840e-01  3.08277130e-01  0.00000000e+00]
 [-6.82327151e-01 -6.58100180e-04  0.00000000e+00]]
planes
[[ 2.10803583e-01  2.24937901e-01  9.51296389e-01]
 [-6.48947299e-01 -6.95580840e-01  3.08277130e-01]
 [ 7.31046677e-01 -6.82327151e-01 -6.58100180e-04]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 487.6458   904.83435 1599.3069 ]
[  -3.89642861 -599.72370245   -2.93092508]
[ 0.   0.  -9.8]
transform [[ 2.24937901e-01  9.51296389e-01  0.00000000e+00]
 [-6.95580840e-01  3.08277130e-01  0.00000000e+00]
 [-6.82327151e-01 -6.58100180e-04  0.00000000e+00]]
transform [[ 2.24937901e-01  9.51296389e-01  0.00000000e+00]
 [-6.95580840e-01  3.08277130e-01  0.00000000e+00]
 [-6.82327151e-01 -6.58100180e-04  0.00000000e+00]]
transform [[ 2.24937901e-01  9.51296389e-01  0.00000000e+00]
 [-6.95580840e-01  3.08277130e-01  0.00000000e+00]
 [-6.82327151e-01 -6.58100180e-04  0.00000000e+00]]
support
[0. 0. 0.]
[ 970.45567601  -60.25734744 -333.32945007]
[-571.39144707 -182.17082078    3.05331731]
[0. 0. 0.]
transform [[ 2.24937901e-01 -6.95580840e-01 -6.82327151e-01]
 [ 9.51296389e-01  3.08277130e-01 -6.58100180e-04]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]
zmp [ 8693689.7466495  -4182601.69058405        0.        ]
d1:12167787.86086, d2:0.05915, d3:4451056.14252
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-418.27562014153864 steps:202[00m
[RDDPG] Resetting Environment
transform [[ 0.39020163 -0.81184167  0.        ]
 [ 0.54523617  0.58387387  0.        ]
 [-0.74193013  0.00211237  0.        ]]
planes
[[ 0.43434528  0.39020163 -0.81184167]
 [ 0.60150546  0.54523617  0.58387387]
 [ 0.67047399 -0.74193013  0.00211237]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[337.02573 -70.38819 557.6425 ]
[   6.01087008 -209.63879763   -1.96163937]
[ 0.   0.  -9.8]
transform [[ 0.39020163 -0.81184167  0.        ]
 [ 0.54523617  0.58387387  0.        ]
 [-0.74193013  0.00211237  0.        ]]
transform [[ 0.39020163 -0.81184167  0.        ]
 [ 0.54523617  0.58387387  0.        ]
 [-0.74193013  0.00211237  0.        ]]
transform [[ 0.39020163 -0.81184167  0.        ]
 [ 0.54523617  0.58387387  0.        ]
 [-0.74193013  0.00211237  0.        ]]
support
[0. 0. 0.]
[ 188.65205364  142.66079084 -250.19822598]
[ 172.53896216 -119.12527187   -4.9024806 ]
[0. 0. 0.]
transform [[ 0.39020163  0.54523617 -0.74193013]
 [-0.81184167  0.58387387  0.00211237]
 [ 0.          0.          0.        ]]
zmp [12687412.06540785  7557377.65937658        0.        ]
d1:19844767.95849, d2:0.04869, d3:2078782.19480
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-362.2205495694942 steps:204[00m
[RDDPG] Resetting Environment
transform [[ 0.67788208 -0.13496058  0.        ]
 [ 0.09349956  0.99084973  0.        ]
 [-0.72920078  0.0015862   0.        ]]
planes
[[ 0.72267669  0.67788208 -0.13496058]
 [ 0.09733811  0.09349956  0.99084973]
 [ 0.68429798 -0.72920078  0.0015862 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-470.41278   -56.795135  931.6118  ]
[  50.1684024  -300.15690547    8.3672946 ]
[ 0.   0.  -9.8]
transform [[ 0.67788208 -0.13496058  0.        ]
 [ 0.09349956  0.99084973  0.        ]
 [-0.72920078  0.0015862   0.        ]]
transform [[ 0.67788208 -0.13496058  0.        ]
 [ 0.09349956  0.99084973  0.        ]
 [-0.72920078  0.0015862   0.        ]]
transform [[ 0.67788208 -0.13496058  0.        ]
 [ 0.09349956  0.99084973  0.        ]
 [-0.72920078  0.0015862   0.        ]]
support
[0. 0. 0.]
[-311.21928782 -100.25883109  342.93527859]
[  74.51760985 -292.71966639  -37.05894601]
[0. 0. 0.]
transform [[ 0.67788208  0.09349956 -0.72920078]
 [-0.13496058  0.99084973  0.0015862 ]
 [ 0.          0.          0.        ]]
zmp [4381849.83698846 5538196.79252274       0.        ]
d1:10180287.58320, d2:0.01182, d3:395780.17938
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-339.0855644755572 steps:206[00m
[RDDPG] Resetting Environment
transform [[ 0.64589661  0.23030308  0.        ]
 [-0.1619568   0.9730469   0.        ]
 [-0.74604803 -0.01184852  0.        ]]
planes
[[ 0.72785854  0.64589661  0.23030308]
 [-0.16416423 -0.1619568   0.9730469 ]
 [ 0.6657868  -0.74604803 -0.01184852]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-290.97366 -618.3459   397.47772]
[ -45.39522513 -282.90336422  -34.06344513]
[ 0.   0.  -9.8]
transform [[ 0.64589661  0.23030308  0.        ]
 [-0.1619568   0.9730469   0.        ]
 [-0.74604803 -0.01184852  0.        ]]
transform [[ 0.64589661  0.23030308  0.        ]
 [-0.1619568   0.9730469   0.        ]
 [-0.74604803 -0.01184852  0.        ]]
transform [[ 0.64589661  0.23030308  0.        ]
 [-0.1619568   0.9730469   0.        ]
 [-0.74604803 -0.01184852  0.        ]]
support
[0. 0. 0.]
[-330.34586521 -554.55438303  224.40681085]
[ -94.47413799 -267.92617574   37.21900368]
[0. 0. 0.]
transform [[ 0.64589661 -0.1619568  -0.74604803]
 [ 0.23030308  0.9730469  -0.01184852]
 [ 0.          0.          0.        ]]
zmp [8853535.73927689 -448116.17070504       0.        ]
d1:9299157.05743, d2:0.04275, d3:2937486.43495
transform [[ 0.66014868 -0.14419816  0.        ]
 [ 0.08727093  0.98947793  0.        ]
 [-0.74604803 -0.01184852  0.        ]]
planes
[[ 0.73716396  0.66014868 -0.14419816]
 [ 0.11540054  0.08727093  0.98947793]
 [ 0.6657868  -0.74604803 -0.01184852]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-290.97366 -618.3459   397.47772]
[ -45.39522513 -282.90336422  -34.06344513]
[ 0.   0.  -9.8]
transform [[ 0.66014868 -0.14419816  0.        ]
 [ 0.08727093  0.98947793  0.        ]
 [-0.74604803 -0.01184852  0.        ]]
transform [[ 0.66014868 -0.14419816  0.        ]
 [ 0.08727093  0.98947793  0.        ]
 [-0.74604803 -0.01184852  0.        ]]
transform [[ 0.66014868 -0.14419816  0.        ]
 [ 0.08727093  0.98947793  0.        ]
 [-0.74604803 -0.01184852  0.        ]]
support
[0. 0. 0.]
[-102.9215381  -637.23315137  224.40681085]
[  10.82654785 -283.88831945   37.21900368]
[0. 0. 0.]
transform [[ 0.66014868  0.08727093 -0.74604803]
 [-0.14419816  0.98947793 -0.01184852]
 [ 0.          0.          0.        ]]
zmp [8703140.86752132 -458031.05462054       0.        ]
d1:9146004.76472, d2:0.04234, d3:2893276.07209
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-687.8920147092772 steps:209[00m
[RDDPG] Resetting Environment
transform [[ 0.03163457  0.21602075  0.        ]
 [ 0.07997973  0.97268683  0.        ]
 [-0.99629444  0.08494371  0.        ]]
planes
[[ 0.97587615  0.03163457  0.21602075]
 [-0.21790743  0.07997973  0.97268683]
 [ 0.01349323 -0.99629444  0.08494371]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-290.97366 -618.3459   397.47772]
[ -45.39522513 -282.90336422  -34.06344513]
[ 0.   0.  -9.8]
transform [[ 0.03163457  0.21602075  0.        ]
 [ 0.07997973  0.97268683  0.        ]
 [-0.99629444  0.08494371  0.        ]]
transform [[ 0.03163457  0.21602075  0.        ]
 [ 0.07997973  0.97268683  0.        ]
 [-0.99629444  0.08494371  0.        ]]
transform [[ 0.03163457  0.21602075  0.        ]
 [ 0.07997973  0.97268683  0.        ]
 [-0.99629444  0.08494371  0.        ]]
support
[0. 0. 0.]
[-142.78036844 -624.72889181  237.3708479 ]
[ -62.54905492 -278.80707338   21.19614852]
[0. 0. 0.]
transform [[ 0.03163457  0.07997973 -0.99629444]
 [ 0.21602075  0.97268683  0.08494371]
 [ 0.          0.          0.        ]]
zmp [ 2622144.61234027 -8835563.71571988        0.        ]
d1:12576184.62007, d2:0.05755, d3:1369501.21033
transform [[-0.61114198  0.10336459  0.        ]
 [-0.11531886  0.96923023  0.        ]
 [-0.78307545 -0.22340243  0.        ]]
planes
[[ 0.78474283 -0.61114198  0.10336459]
 [-0.21747288 -0.11531886  0.96923023]
 [-0.58041728 -0.78307545 -0.22340243]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-442.66086  389.9179  -291.1172 ]
[-20.60778264 -16.42894998  10.96971209]
[ 0.   0.  -9.8]
transform [[-0.61114198  0.10336459  0.        ]
 [-0.11531886  0.96923023  0.        ]
 [-0.78307545 -0.22340243  0.        ]]
transform [[-0.61114198  0.10336459  0.        ]
 [-0.11531886  0.96923023  0.        ]
 [-0.78307545 -0.22340243  0.        ]]
transform [[-0.61114198  0.10336459  0.        ]
 [-0.11531886  0.96923023  0.        ]
 [-0.78307545 -0.22340243  0.        ]]
support
[0. 0. 0.]
[310.83233661 428.96737274 259.52824513]
[ 10.89610945 -13.54696895  19.80771598]
[0. 0. 0.]
transform [[-0.61114198 -0.11531886 -0.78307545]
 [ 0.10336459  0.96923023 -0.22340243]
 [ 0.          0.          0.        ]]
zmp [ 4034398.01589981 -6937509.5349762         0.        ]
d1:8841427.10854, d2:0.02289, d3:879125.74459
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-420.5586054595004 steps:212[00m
[RDDPG] Resetting Environment
transform [[ 0.7158435  -0.04796935  0.        ]
 [ 0.0201288   0.9986406   0.        ]
 [-0.69797063 -0.02039787  0.        ]]
planes
[[ 0.69661117  0.7158435  -0.04796935]
 [ 0.04808289  0.0201288   0.9986406 ]
 [ 0.71583581 -0.69797063 -0.02039787]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[332.6904  423.2249  371.98602]
[ -22.64202277 -387.90318442   -6.12560766]
[ 0.   0.  -9.8]
transform [[ 0.7158435  -0.04796935  0.        ]
 [ 0.0201288   0.9986406   0.        ]
 [-0.69797063 -0.02039787  0.        ]]
transform [[ 0.7158435  -0.04796935  0.        ]
 [ 0.0201288   0.9986406   0.        ]
 [-0.69797063 -0.02039787  0.        ]]
transform [[ 0.7158435  -0.04796935  0.        ]
 [ 0.0201288   0.9986406   0.        ]
 [-0.69797063 -0.02039787  0.        ]]
support
[0. 0. 0.]
[ 217.85243423  429.34623903 -240.84101382]
[   2.39931977 -387.83162432   23.71586555]
[0. 0. 0.]
transform [[ 0.7158435   0.0201288  -0.69797063]
 [-0.04796935  0.9986406  -0.02039787]
 [ 0.          0.          0.        ]]
zmp [   172031.96569731 -13602213.58428781         0.        ]
d1:13830393.80054, d2:0.04201, d3:4322794.06207
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-126.87144279699204 steps:214[00m
[RDDPG] Resetting Environment
transform [[-0.19494289  0.9559409   0.        ]
 [ 0.65037149  0.29349452  0.        ]
 [-0.73417586  0.00616554  0.        ]]
planes
[[ 0.21948649 -0.19494289  0.9559409 ]
 [-0.70062679  0.65037149  0.29349452]
 [-0.67893136 -0.73417586  0.00616554]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[332.6904  423.2249  371.98602]
[ -22.64202277 -387.90318442   -6.12560766]
[ 0.   0.  -9.8]
transform [[-0.19494289  0.9559409   0.        ]
 [ 0.65037149  0.29349452  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.19494289  0.9559409   0.        ]
 [ 0.65037149  0.29349452  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.19494289  0.9559409   0.        ]
 [ 0.65037149  0.29349452  0.        ]
 [-0.73417586  0.00616554  0.        ]]
support
[0. 0. 0.]
[ 339.72237824  340.58654549 -241.64384995]
[-366.39861871 -128.57318605   14.23159384]
[0. 0. 0.]
transform [[-0.19494289  0.65037149 -0.73417586]
 [ 0.9559409   0.29349452  0.00616554]
 [ 0.          0.          0.        ]]
zmp [3767548.7225385  2015504.26161622       0.        ]
d1:5700275.52637, d2:0.05909, d3:1860968.31117
transform [[-0.09100219  0.99004263  0.        ]
 [ 0.67283314  0.14063314  0.        ]
 [-0.73417586  0.00616554  0.        ]]
planes
[[ 0.10739784 -0.09100219  0.99004263]
 [-0.72630435  0.67283314  0.14063314]
 [-0.67893136 -0.73417586  0.00616554]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[332.6904  423.2249  371.98602]
[ -22.64202277 -387.90318442   -6.12560766]
[ 0.   0.  -9.8]
transform [[-0.09100219  0.99004263  0.        ]
 [ 0.67283314  0.14063314  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.09100219  0.99004263  0.        ]
 [ 0.67283314  0.14063314  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.09100219  0.99004263  0.        ]
 [ 0.67283314  0.14063314  0.        ]
 [-0.73417586  0.00616554  0.        ]]
support
[0. 0. 0.]
[ 388.7351517   283.36457445 -241.64384995]
[-381.98021405  -69.78634469   14.23159384]
[0. 0. 0.]
transform [[-0.09100219  0.67283314 -0.73417586]
 [ 0.99004263  0.14063314  0.00616554]
 [ 0.          0.          0.        ]]
zmp [3921357.80112122  968765.13652481       0.        ]
d1:4800224.44140, d2:0.05920, d3:1577963.71098
transform [[-0.1063146   0.9865799   0.        ]
 [ 0.67058408  0.16316289  0.        ]
 [-0.73417586  0.00616554  0.        ]]
planes
[[ 0.12392478 -0.1063146   0.9865799 ]
 [-0.72366768  0.67058408  0.16316289]
 [-0.67893136 -0.73417586  0.00616554]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[332.6904  423.2249  371.98602]
[ -22.64202277 -387.90318442   -6.12560766]
[ 0.   0.  -9.8]
transform [[-0.1063146   0.9865799   0.        ]
 [ 0.67058408  0.16316289  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.1063146   0.9865799   0.        ]
 [ 0.67058408  0.16316289  0.        ]
 [-0.73417586  0.00616554  0.        ]]
transform [[-0.1063146   0.9865799   0.        ]
 [ 0.67058408  0.16316289  0.        ]
 [-0.73417586  0.00616554  0.        ]]
support
[0. 0. 0.]
[ 382.17534522  292.15148507 -241.64384995]
[-380.29030538  -78.47478356   14.23159384]
[0. 0. 0.]
transform [[-0.1063146   0.67058408 -0.73417586]
 [ 0.9865799   0.16316289  0.00616554]
 [ 0.          0.          0.        ]]
zmp [3905957.06139806 1123040.66988418       0.        ]
d1:4939807.20841, d2:0.05916, d3:1622028.83433
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-542.9333326384615 steps:218[00m
[RDDPG] Resetting Environment
transform [[-0.05194204  0.99405593  0.        ]
 [-0.8462984   0.00704927  0.        ]
 [-0.5301708  -0.10864251  0.        ]]
planes
[[ 0.09568129 -0.05194204  0.99405593]
 [-0.53266251 -0.8462984   0.00704927]
 [ 0.84090179 -0.5301708  -0.10864251]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 48.92133 410.3334  985.9993 ]
[ -38.0053481  -443.84786286   30.16415815]
[ 0.   0.  -9.8]
transform [[-0.05194204  0.99405593  0.        ]
 [-0.8462984   0.00704927  0.        ]
 [-0.5301708  -0.10864251  0.        ]]
transform [[-0.05194204  0.99405593  0.        ]
 [-0.8462984   0.00704927  0.        ]
 [-0.5301708  -0.10864251  0.        ]]
transform [[-0.05194204  0.99405593  0.        ]
 [-0.8462984   0.00704927  0.        ]
 [-0.5301708  -0.10864251  0.        ]]
support
[0. 0. 0.]
[405.35327895 -38.50949177 -70.51631176]
[-439.23552325   29.03506175   68.3700721 ]
[0. 0. 0.]
transform [[-0.05194204 -0.8462984  -0.5301708 ]
 [ 0.99405593  0.00704927 -0.10864251]
 [ 0.          0.          0.        ]]
zmp [9151945.61211027   27090.06378433       0.        ]
d1:10334107.71789, d2:0.05913, d3:3183237.44537
transform [[-0.0491467   0.9929117   0.        ]
 [ 0.95066082  0.07973179  0.        ]
 [-0.3063145   0.08814328  0.        ]]
planes
[[ 0.10821736 -0.0491467   0.9929117 ]
 [-0.29981127  0.95066082  0.07973179]
 [-0.94784081 -0.3063145   0.08814328]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-271.10577 -465.29285  861.7269 ]
[ -11.65989281 -137.64044544  -90.88924557]
[ 0.   0.  -9.8]
transform [[-0.0491467   0.9929117   0.        ]
 [ 0.95066082  0.07973179  0.        ]
 [-0.3063145   0.08814328  0.        ]]
transform [[-0.0491467   0.9929117   0.        ]
 [ 0.95066082  0.07973179  0.        ]
 [-0.3063145   0.08814328  0.        ]]
transform [[-0.0491467   0.9929117   0.        ]
 [ 0.95066082  0.07973179  0.        ]
 [-0.3063145   0.08814328  0.        ]]
support
[0. 0. 0.]
[-448.67075441 -294.82827121   42.03119067]
[-136.09176288  -22.05892271   -8.56048633]
[0. 0. 0.]
transform [[-0.0491467   0.95066082 -0.3063145 ]
 [ 0.9929117   0.07973179  0.08814328]
 [ 0.          0.          0.        ]]
zmp [8970743.14873762   13508.59173981       0.        ]
d1:10885181.68400, d2:0.05905, d3:2584555.40501
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-317.2594176086533 steps:221[00m
[RDDPG] Resetting Environment
transform [[-0.2703281  -0.91951144  0.        ]
 [-0.64836472  0.39296621  0.        ]
 [-0.71172041 -0.00873323  0.        ]]
planes
[[ 0.28534436 -0.2703281  -0.91951144]
 [ 0.65207422 -0.64836472  0.39296621]
 [-0.70240861 -0.71172041 -0.00873323]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-271.10577 -465.29285  861.7269 ]
[ -11.65989281 -137.64044544  -90.88924557]
[ 0.   0.  -9.8]
transform [[-0.2703281  -0.91951144  0.        ]
 [-0.64836472  0.39296621  0.        ]
 [-0.71172041 -0.00873323  0.        ]]
transform [[-0.2703281  -0.91951144  0.        ]
 [-0.64836472  0.39296621  0.        ]
 [-0.71172041 -0.00873323  0.        ]]
transform [[-0.2703281  -0.91951144  0.        ]
 [-0.64836472  0.39296621  0.        ]
 [-0.71172041 -0.00873323  0.        ]]
support
[0. 0. 0.]
[501.12960425  -7.06894695 197.01501977]
[129.71396056 -46.52818113   9.5006289 ]
[0. 0. 0.]
transform [[-0.2703281  -0.64836472 -0.71172041]
 [-0.91951144  0.39296621 -0.00873323]
 [ 0.          0.          0.        ]]
zmp [3706110.77275427 4219554.74459066       0.        ]
d1:7921300.63494, d2:0.05939, d3:2706067.80796
transform [[-0.28524029 -0.89536995  0.        ]
 [ 0.69123805  0.05499279  0.        ]
 [-0.66394883  0.44191459  0.        ]]
planes
[[ 0.34198058 -0.28524029 -0.89536995]
 [ 0.7205317   0.69123805  0.05499279]
 [ 0.60322756 -0.66394883  0.44191459]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-216.79965  279.2171   331.65808]
[   5.64725248 -253.50639738   15.94053818]
[ 0.   0.  -9.8]
transform [[-0.28524029 -0.89536995  0.        ]
 [ 0.69123805  0.05499279  0.        ]
 [-0.66394883  0.44191459  0.        ]]
transform [[-0.28524029 -0.89536995  0.        ]
 [ 0.69123805  0.05499279  0.        ]
 [-0.66394883  0.44191459  0.        ]]
transform [[-0.28524029 -0.89536995  0.        ]
 [ 0.69123805  0.05499279  0.        ]
 [-0.66394883  0.44191459  0.        ]]
support
[0. 0. 0.]
[-188.16260566 -134.50523897  267.33398689]
[ 225.37118563  -10.03742957 -115.77766191]
[0. 0. 0.]
transform [[-0.28524029  0.69123805 -0.66394883]
 [-0.89536995  0.05499279  0.44191459]
 [ 0.          0.          0.        ]]
zmp [21760442.65952604  2822885.99650844        0.        ]
d1:25764242.15571, d2:0.05662, d3:6173650.83741
transform [[-0.22251543 -0.81317377  0.        ]
 [-0.67732286  0.52571154  0.        ]
 [-0.70122796 -0.24975151  0.        ]]
planes
[[ 0.53780597 -0.22251543 -0.81317377]
 [ 0.51464659 -0.67732286  0.52571154]
 [-0.66776007 -0.70122796 -0.24975151]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-491.93942 1161.3895  1128.2834 ]
[118.12104974 -76.33318191 -10.34176615]
[ 0.   0.  -9.8]
transform [[-0.22251543 -0.81317377  0.        ]
 [-0.67732286  0.52571154  0.        ]
 [-0.70122796 -0.24975151  0.        ]]
transform [[-0.22251543 -0.81317377  0.        ]
 [-0.67732286  0.52571154  0.        ]
 [-0.70122796 -0.24975151  0.        ]]
transform [[-0.22251543 -0.81317377  0.        ]
 [-0.67732286  0.52571154  0.        ]
 [-0.70122796 -0.24975151  0.        ]]
support
[0. 0. 0.]
[-834.94738651  943.75769117   54.90289336]
[  35.78838473 -120.13532211  -63.76545578]
[0. 0. 0.]
transform [[-0.22251543 -0.67732286 -0.70122796]
 [-0.81317377  0.52571154 -0.24975151]
 [ 0.          0.          0.        ]]
zmp [ 25305523.65373551 -10844804.45705093         0.        ]
d1:37897575.16418, d2:0.04830, d3:11805770.41735
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-615.91929886083 steps:225[00m
[RDDPG] Resetting Environment
transform [[-0.13407147 -0.97835207  0.        ]
 [-0.69934624  0.20611998  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
planes
[[ 0.15764543 -0.13407147 -0.97835207]
 [ 0.6844191  -0.69934624  0.20611998]
 [-0.71184164 -0.7020967  -0.01848768]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-491.93942 1161.3895  1128.2834 ]
[118.12104974 -76.33318191 -10.34176615]
[ 0.   0.  -9.8]
transform [[-0.13407147 -0.97835207  0.        ]
 [-0.69934624  0.20611998  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
transform [[-0.13407147 -0.97835207  0.        ]
 [-0.69934624  0.20611998  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
transform [[-0.13407147 -0.97835207  0.        ]
 [-0.69934624  0.20611998  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
support
[0. 0. 0.]
[-1070.29280583   583.42157868   323.91765113]
[ 58.84406382 -98.34130678 -81.52117609]
[0. 0. 0.]
transform [[-0.13407147 -0.69934624 -0.7020967 ]
 [-0.97835207  0.20611998 -0.01848768]
 [ 0.          0.          0.        ]]
zmp [5334299.20045384 2336028.07165756       0.        ]
d1:7814159.00032, d2:0.05916, d3:2498786.37452
transform [[-0.23332947 -0.93849999  0.        ]
 [-0.67276865  0.34478399  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
planes
[[ 0.25450966 -0.23332947 -0.93849999]
 [ 0.65460396 -0.67276865  0.34478399]
 [-0.71184164 -0.7020967  -0.01848768]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-491.93942 1161.3895  1128.2834 ]
[118.12104974 -76.33318191 -10.34176615]
[ 0.   0.  -9.8]
transform [[-0.23332947 -0.93849999  0.        ]
 [-0.67276865  0.34478399  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
transform [[-0.23332947 -0.93849999  0.        ]
 [-0.67276865  0.34478399  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
transform [[-0.23332947 -0.93849999  0.        ]
 [-0.67276865  0.34478399  0.        ]
 [-0.7020967  -0.01848768  0.        ]]
support
[0. 0. 0.]
[-975.18008837  731.3899391   323.91765113]
[  44.07756773 -105.78659861  -81.52117609]
[0. 0. 0.]
transform [[-0.23332947 -0.67276865 -0.7020967 ]
 [-0.93849999  0.34478399 -0.01848768]
 [ 0.          0.          0.        ]]
zmp [5594181.90181902 3691921.32779904       0.        ]
d1:9425580.90382, d2:0.05919, d3:3019552.68895
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-687.7641476286301 steps:228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-231.0810858104957 steps:229[00m
[RDDPG] Resetting Environment
transform [[-0.8000375  -0.07227432  0.        ]
 [-0.04702435  0.99721742  0.        ]
 [-0.5981043   0.01827218  0.        ]]
planes
[[ 0.59558076 -0.8000375  -0.07227432]
 [ 0.05784601 -0.04702435  0.99721742]
 [-0.80120993 -0.5981043   0.01827218]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-491.93942 1161.3895  1128.2834 ]
[118.12104974 -76.33318191 -10.34176615]
[ 0.   0.  -9.8]
transform [[-0.8000375  -0.07227432  0.        ]
 [-0.04702435  0.99721742  0.        ]
 [-0.5981043   0.01827218  0.        ]]
transform [[-0.8000375  -0.07227432  0.        ]
 [-0.04702435  0.99721742  0.        ]
 [-0.5981043   0.01827218  0.        ]]
transform [[-0.8000375  -0.07227432  0.        ]
 [-0.04702435  0.99721742  0.        ]
 [-0.5981043   0.01827218  0.        ]]
support
[0. 0. 0.]
[ 309.63134934 1181.2909934   315.45219735]
[-88.98434091 -81.67534369 -72.04348091]
[0. 0. 0.]
transform [[-0.8000375  -0.04702435 -0.5981043 ]
 [-0.07227432  0.99721742  0.01827218]
 [ 0.          0.          0.        ]]
zmp [  1581247.45946817 -10667495.96481111         0.        ]
d1:11673772.76014, d2:0.02835, d3:2988380.02500
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-384.5799980090246 steps:231[00m
[RDDPG] Resetting Environment
transform [[ 0.02127765  0.14990762  0.        ]
 [ 0.03274023  0.98806018  0.        ]
 [-0.99923736  0.03556611  0.        ]]
planes
[[ 0.98847109  0.02127765  0.14990762]
 [-0.15055007  0.03274023  0.98806018]
 [ 0.01611558 -0.99923736  0.03556611]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-491.93942 1161.3895  1128.2834 ]
[118.12104974 -76.33318191 -10.34176615]
[ 0.   0.  -9.8]
transform [[ 0.02127765  0.14990762  0.        ]
 [ 0.03274023  0.98806018  0.        ]
 [-0.99923736  0.03556611  0.        ]]
transform [[ 0.02127765  0.14990762  0.        ]
 [ 0.03274023  0.98806018  0.        ]
 [-0.99923736  0.03556611  0.        ]]
transform [[ 0.02127765  0.14990762  0.        ]
 [ 0.03274023  0.98806018  0.        ]
 [-0.99923736  0.03556611  0.        ]]
support
[0. 0. 0.]
[ 163.63382383 1131.41653146  532.87036139]
[  -8.92958726  -71.55446709 -120.74584038]
[0. 0. 0.]
transform [[ 0.02127765  0.03274023 -0.99923736]
 [ 0.14990762  0.98806018  0.03556611]
 [ 0.          0.          0.        ]]
zmp [15287010.61383751 -7983029.76517682        0.        ]
d1:12584064.07550, d2:0.02967, d3:6994303.90761
transform [[ 0.69965404 -0.10515098  0.        ]
 [ 0.03748246  0.99315095  0.        ]
 [-0.71349794 -0.05093719  0.        ]]
planes
[[ 0.70670187  0.69965404 -0.10515098]
 [ 0.11066341  0.03748246  0.99315095]
 [ 0.69880337 -0.71349794 -0.05093719]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ 350.15173 -430.96942  125.02264]
[ 73.35851511 -78.19572734 -35.43089138]
[ 0.   0.  -9.8]
transform [[ 0.69965404 -0.10515098  0.        ]
 [ 0.03748246  0.99315095  0.        ]
 [-0.71349794 -0.05093719  0.        ]]
transform [[ 0.69965404 -0.10515098  0.        ]
 [ 0.03748246  0.99315095  0.        ]
 [-0.71349794 -0.05093719  0.        ]]
transform [[ 0.69965404 -0.10515098  0.        ]
 [ 0.03748246  0.99315095  0.        ]
 [-0.71349794 -0.05093719  0.        ]]
support
[0. 0. 0.]
[ 290.30193403 -414.89314333 -227.88016934]
[ 59.54793924 -74.91050359 -48.35807879]
[0. 0. 0.]
transform [[ 0.69965404  0.03748246 -0.71349794]
 [-0.10515098  0.99315095 -0.05093719]
 [ 0.          0.          0.        ]]
zmp [-11173143.2942605   -5344968.52310285         0.        ]
d1:8184336.72348, d2:0.02036, d3:2007854.36169
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-543.3350093986334 steps:234[00m
[RDDPG] Resetting Environment
transform [[ 0.73262775  0.03422538  0.        ]
 [-0.00609273  0.99902475  0.        ]
 [-0.68060231  0.02789833  0.        ]]
planes
[[ 0.67976856  0.73262775  0.03422538]
 [-0.04373296 -0.00609273  0.99902475]
 [ 0.73212171 -0.68060231  0.02789833]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-101.42962    44.083614   29.503601]
[ 35.63201739 -53.82139308 -21.01598815]
[ 0.   0.  -9.8]
transform [[ 0.73262775  0.03422538  0.        ]
 [-0.00609273  0.99902475  0.        ]
 [-0.68060231  0.02789833  0.        ]]
transform [[ 0.73262775  0.03422538  0.        ]
 [-0.00609273  0.99902475  0.        ]
 [-0.68060231  0.02789833  0.        ]]
transform [[ 0.73262775  0.03422538  0.        ]
 [-0.00609273  0.99902475  0.        ]
 [-0.68060231  0.02789833  0.        ]]
support
[0. 0. 0.]
[-72.80137484  44.6586055   70.26309241]
[ 24.26294697 -53.98600013 -25.75276052]
[0. 0. 0.]
transform [[ 0.73262775 -0.00609273 -0.68060231]
 [ 0.03422538  0.99902475  0.02789833]
 [ 0.          0.          0.        ]]
zmp [ 12597039.85648873 -16981383.89169452         0.        ]
d1:25202993.47094, d2:0.05839, d3:10277064.24353
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-55.355601830666174 steps:236[00m
[RDDPG] Resetting Environment
transform [[-0.68846375  0.06453008  0.        ]
 [ 0.01332777  0.9969914   0.        ]
 [-0.72514832 -0.04294147  0.        ]]
planes
[[ 0.72239441 -0.68846375  0.06453008]
 [-0.07635752  0.01332777  0.9969914 ]
 [-0.68725246 -0.72514832 -0.04294147]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-101.42962    44.083614   29.503601]
[ 35.63201739 -53.82139308 -21.01598815]
[ 0.   0.  -9.8]
transform [[-0.68846375  0.06453008  0.        ]
 [ 0.01332777  0.9969914   0.        ]
 [-0.72514832 -0.04294147  0.        ]]
transform [[-0.68846375  0.06453008  0.        ]
 [ 0.01332777  0.9969914   0.        ]
 [-0.72514832 -0.04294147  0.        ]]
transform [[-0.68846375  0.06453008  0.        ]
 [ 0.01332777  0.9969914   0.        ]
 [-0.72514832 -0.04294147  0.        ]]
support
[0. 0. 0.]
[72.67533474 42.59915321 71.65850236]
[-28.00445113 -53.18457035 -23.52732763]
[0. 0. 0.]
transform [[-0.68846375  0.01332777 -0.72514832]
 [ 0.06453008  0.9969914  -0.04294147]
 [ 0.          0.          0.        ]]
zmp [9903883.41941981 1321303.70719474       0.        ]
d1:11127911.12171, d2:0.04637, d3:4065878.87472
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-317.8780827663404 steps:238[00m
[RDDPG] Resetting Environment
transform [[-0.71429396  0.03392433  0.        ]
 [ 0.00911276  0.99919063  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
planes
[[ 0.69902307 -0.71429396  0.03392433]
 [-0.03917995  0.00911276  0.99919063]
 [-0.71402502 -0.69978642 -0.02161597]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-101.42962    44.083614   29.503601]
[ 35.63201739 -53.82139308 -21.01598815]
[ 0.   0.  -9.8]
transform [[-0.71429396  0.03392433  0.        ]
 [ 0.00911276  0.99919063  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
transform [[-0.71429396  0.03392433  0.        ]
 [ 0.00911276  0.99919063  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
transform [[-0.71429396  0.03392433  0.        ]
 [ 0.00911276  0.99919063  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
support
[0. 0. 0.]
[73.94607102 43.12363051 70.02616019]
[-27.27758959 -53.45312554 -23.77140038]
[0. 0. 0.]
transform [[-0.71429396  0.00911276 -0.69978642]
 [ 0.03392433  0.99919063 -0.02161597]
 [ 0.          0.          0.        ]]
zmp [  6788166.29065749 -21966619.77309749         0.        ]
d1:27889491.64155, d2:0.02722, d3:5109939.36402
transform [[-0.06430557 -0.99357778  0.        ]
 [-0.71145189  0.11106744  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
planes
[[ 0.09310221 -0.06430557 -0.99357778]
 [ 0.69390219 -0.71145189  0.11106744]
 [-0.71402502 -0.69978642 -0.02161597]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-101.42962    44.083614   29.503601]
[ 35.63201739 -53.82139308 -21.01598815]
[ 0.   0.  -9.8]
transform [[-0.06430557 -0.99357778  0.        ]
 [-0.71145189  0.11106744  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
transform [[-0.06430557 -0.99357778  0.        ]
 [-0.71145189  0.11106744  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
transform [[-0.06430557 -0.99357778  0.        ]
 [-0.71145189  0.11106744  0.        ]
 [-0.69978642 -0.02161597  0.        ]]
support
[0. 0. 0.]
[-37.27801053  77.0585482   70.02616019]
[ 51.18440311 -31.32827061 -23.77140038]
[0. 0. 0.]
transform [[-0.06430557 -0.71145189 -0.69978642]
 [-0.99357778  0.11106744 -0.02161597]
 [ 0.          0.          0.        ]]
zmp [22785075.53797408 -2249823.68024364        0.        ]
d1:24023428.15969, d2:0.05911, d3:7098471.77664
transform [[ 0.41496035  0.73686934  0.        ]
 [-0.3355732   0.66917986  0.        ]
 [-0.84569412  0.09603088  0.        ]]
planes
[[ 0.53369612  0.41496035  0.73686934]
 [-0.66301507 -0.3355732   0.66917986]
 [ 0.5249567  -0.84569412  0.09603088]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-655.7251    -5.41802  220.19205]
[-60.05244459 -48.2474161   12.19172521]
[ 0.   0.  -9.8]
transform [[ 0.41496035  0.73686934  0.        ]
 [-0.3355732   0.66917986  0.        ]
 [-0.84569412  0.09603088  0.        ]]
transform [[ 0.41496035  0.73686934  0.        ]
 [-0.3355732   0.66917986  0.        ]
 [-0.84569412  0.09603088  0.        ]]
transform [[ 0.41496035  0.73686934  0.        ]
 [-0.3355732   0.66917986  0.        ]
 [-0.84569412  0.09603088  0.        ]]
support
[0. 0. 0.]
[-276.09229165  216.41813729  554.02256532]
[-60.47142513 -12.13420822  46.15275793]
[0. 0. 0.]
transform [[ 0.41496035 -0.3355732  -0.84569412]
 [ 0.73686934  0.66917986  0.09603088]
 [ 0.          0.          0.        ]]
zmp [-10777610.70167693   8892895.71497921         0.        ]
d1:22040876.71725, d2:0.05875, d3:6442637.88637
transform [[ 0.44514903  0.77076316  0.        ]
 [ 0.89542532 -0.37890062  0.        ]
 [-0.00747213  0.51220936  0.        ]]
planes
[[ 0.45581406  0.44514903  0.77076316]
 [-0.23376875  0.89542532 -0.37890062]
 [-0.85882813 -0.00747213  0.51220936]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-314.2143 -615.5782  554.4561]
[ 345.01953843  -25.7903332  -111.15054367]
[ 0.   0.  -9.8]
transform [[ 0.44514903  0.77076316  0.        ]
 [ 0.89542532 -0.37890062  0.        ]
 [-0.00747213  0.51220936  0.        ]]
transform [[ 0.44514903  0.77076316  0.        ]
 [ 0.89542532 -0.37890062  0.        ]
 [-0.00747213  0.51220936  0.        ]]
transform [[ 0.44514903  0.77076316  0.        ]
 [ 0.89542532 -0.37890062  0.        ]
 [-0.00747213  0.51220936  0.        ]]
support
[0. 0. 0.]
[-614.33717687  -48.11248032 -312.95705725]
[133.70687565 318.71120367 -15.78807952]
[0. 0. 0.]
transform [[ 0.44514903  0.89542532 -0.00747213]
 [ 0.77076316 -0.37890062  0.51220936]
 [ 0.          0.          0.        ]]
zmp [-9324800.00484303 11375233.22628461        0.        ]
d1:17776780.25989, d2:0.05931, d3:1756019.72457
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-325.9818696966503 steps:243[00m
[RDDPG] Resetting Environment
transform [[ 0.68330812 -0.22783294  0.        ]
 [ 0.15535758  0.97368062  0.        ]
 [-0.71341014 -0.00618358  0.        ]]
planes
[[ 0.69367296  0.68330812 -0.22783294]
 [ 0.16676363  0.15535758  0.97368062]
 [ 0.70071942 -0.71341014 -0.00618358]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-119.04014 -417.19397 -227.67522]
[  50.5560367  -467.72679121  -24.31169964]
[ 0.   0.  -9.8]
transform [[ 0.68330812 -0.22783294  0.        ]
 [ 0.15535758  0.97368062  0.        ]
 [-0.71341014 -0.00618358  0.        ]]
transform [[ 0.68330812 -0.22783294  0.        ]
 [ 0.15535758  0.97368062  0.        ]
 [-0.71341014 -0.00618358  0.        ]]
transform [[ 0.68330812 -0.22783294  0.        ]
 [ 0.15535758  0.97368062  0.        ]
 [-0.71341014 -0.00618358  0.        ]]
support
[0. 0. 0.]
[  13.7094364  -424.70746951   87.50419582]
[ 141.10892207 -447.56224618  -33.17496095]
[0. 0. 0.]
transform [[ 0.68330812  0.15535758 -0.71341014]
 [-0.22783294  0.97368062 -0.00618358]
 [ 0.          0.          0.        ]]
zmp [-1228946.360777     291093.57976459        0.        ]
d1:1447918.24090, d2:0.05083, d3:506965.47360
transform [[ 0.30084604 -0.37909922  0.        ]
 [ 0.40733993  0.88076264  0.        ]
 [-0.86230266  0.2837975   0.        ]]
planes
[[ 0.87508601  0.30084604 -0.37909922]
 [ 0.2415189   0.40733993  0.88076264]
 [ 0.41939613 -0.86230266  0.2837975 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-119.04014 -417.19397 -227.67522]
[  50.5560367  -467.72679121  -24.31169964]
[ 0.   0.  -9.8]
transform [[ 0.30084604 -0.37909922  0.        ]
 [ 0.40733993  0.88076264  0.        ]
 [-0.86230266  0.2837975   0.        ]]
transform [[ 0.30084604 -0.37909922  0.        ]
 [ 0.40733993  0.88076264  0.        ]
 [-0.86230266  0.2837975   0.        ]]
transform [[ 0.30084604 -0.37909922  0.        ]
 [ 0.40733993  0.88076264  0.        ]
 [-0.86230266  0.2837975   0.        ]]
support
[0. 0. 0.]
[ 122.34515431 -415.93866242  -15.74997871]
[ 192.52444519 -391.36278939 -176.33430017]
[0. 0. 0.]
transform [[ 0.30084604  0.40733993 -0.86230266]
 [-0.37909922  0.88076264  0.2837975 ]
 [ 0.          0.          0.        ]]
zmp [-14618095.12740136  13816009.28263855         0.        ]
d1:9092156.12521, d2:0.05365, d3:7055307.18418
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-988.018202302994 steps:246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-121.75286168944554 steps:247[00m
[RDDPG] Resetting Environment
transform [[-0.72186726  0.04307606  0.        ]
 [ 0.04688541  0.99881184  0.        ]
 [-0.69044155  0.02278906  0.        ]]
planes
[[ 0.69068962 -0.72186726  0.04307606]
 [-0.01329082  0.04688541  0.99881184]
 [-0.7230292  -0.69044155  0.02278906]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-119.04014 -417.19397 -227.67522]
[  50.5560367  -467.72679121  -24.31169964]
[ 0.   0.  -9.8]
transform [[-0.72186726  0.04307606  0.        ]
 [ 0.04688541  0.99881184  0.        ]
 [-0.69044155  0.02278906  0.        ]]
transform [[-0.72186726  0.04307606  0.        ]
 [ 0.04688541  0.99881184  0.        ]
 [-0.69044155  0.02278906  0.        ]]
transform [[-0.72186726  0.04307606  0.        ]
 [ 0.04688541  0.99881184  0.        ]
 [-0.69044155  0.02278906  0.        ]]
support
[0. 0. 0.]
[  67.9601076  -422.27952247   72.68279935]
[ -56.64257377 -464.80071699  -45.56504182]
[0. 0. 0.]
transform [[-0.72186726  0.04688541 -0.69044155]
 [ 0.04307606  0.99881184  0.02278906]
 [ 0.          0.          0.        ]]
zmp [14408840.30088898  6172416.47441251        0.        ]
d1:20988595.15748, d2:0.05563, d3:6672041.73364
transform [[-0.71507102 -0.17263092  0.        ]
 [-0.10937986  0.98472291  0.        ]
 [-0.69044155  0.02278906  0.        ]]
planes
[[ 0.67740095 -0.71507102 -0.17263092]
 [ 0.13548735 -0.10937986  0.98472291]
 [-0.7230292  -0.69044155  0.02278906]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-119.04014 -417.19397 -227.67522]
[  50.5560367  -467.72679121  -24.31169964]
[ 0.   0.  -9.8]
transform [[-0.71507102 -0.17263092  0.        ]
 [-0.10937986  0.98472291  0.        ]
 [-0.69044155  0.02278906  0.        ]]
transform [[-0.71507102 -0.17263092  0.        ]
 [-0.10937986  0.98472291  0.        ]
 [-0.69044155  0.02278906  0.        ]]
transform [[-0.71507102 -0.17263092  0.        ]
 [-0.10937986  0.98472291  0.        ]
 [-0.69044155  0.02278906  0.        ]]
support
[0. 0. 0.]
[ 157.14273261 -397.79986748   72.68279935]
[  44.59294989 -466.11110011  -45.56504182]
[0. 0. 0.]
transform [[-0.71507102 -0.10937986 -0.69044155]
 [-0.17263092  0.98472291  0.02278906]
 [ 0.          0.          0.        ]]
zmp [13370359.07878166  6078786.61081559        0.        ]
d1:19835142.09792, d2:0.05626, d3:6304769.65277
transform [[ 0.48432064  0.7983036   0.        ]
 [-0.78192073  0.57851136  0.        ]
 [-0.39247105 -0.1674394   0.        ]]
planes
[[ 0.35797331  0.48432064  0.7983036 ]
 [-0.23221669 -0.78192073  0.57851136]
 [ 0.9043951  -0.39247105 -0.1674394 ]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-165.06413 -249.54713  -70.85377]
[  38.3983246  -333.49107083 -184.47097332]
[ 0.   0.  -9.8]
transform [[ 0.48432064  0.7983036   0.        ]
 [-0.78192073  0.57851136  0.        ]
 [-0.39247105 -0.1674394   0.        ]]
transform [[ 0.48432064  0.7983036   0.        ]
 [-0.78192073  0.57851136  0.        ]
 [-0.39247105 -0.1674394   0.        ]]
transform [[ 0.48432064  0.7983036   0.        ]
 [-0.78192073  0.57851136  0.        ]
 [-0.39247105 -0.1674394   0.        ]]
support
[0. 0. 0.]
[-279.15834327  -15.29878413  106.56691543]
[-247.63002262 -222.95281808   40.7693146 ]
[0. 0. 0.]
transform [[ 0.48432064 -0.78192073 -0.39247105]
 [ 0.7983036   0.57851136 -0.1674394 ]
 [ 0.          0.          0.        ]]
zmp [18521670.71836071 -8506958.94822056        0.        ]
d1:33522184.06428, d2:0.05895, d3:8799690.03967
transform [[-0.05588755  0.72204506  0.        ]
 [ 0.99626184 -0.00523766  0.        ]
 [ 0.06587119  0.69182622  0.        ]]
planes
[[ 0.68958503 -0.05588755  0.72204506]
 [ 0.08622645  0.99626184 -0.00523766]
 [-0.71905315  0.06587119  0.69182622]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-165.06413 -249.54713  -70.85377]
[  38.3983246  -333.49107083 -184.47097332]
[ 0.   0.  -9.8]
transform [[-0.05588755  0.72204506  0.        ]
 [ 0.99626184 -0.00523766  0.        ]
 [ 0.06587119  0.69182622  0.        ]]
transform [[-0.05588755  0.72204506  0.        ]
 [ 0.99626184 -0.00523766  0.        ]
 [ 0.06587119  0.69182622  0.        ]]
transform [[-0.05588755  0.72204506  0.        ]
 [ 0.99626184 -0.00523766  0.        ]
 [ 0.06587119  0.69182622  0.        ]]
support
[0. 0. 0.]
[-170.95924602 -163.14005226 -183.51622206]
[-242.94157001   40.00149877 -228.18852518]
[0. 0. 0.]
transform [[-0.05588755  0.99626184  0.06587119]
 [ 0.72204506 -0.00523766  0.69182622]
 [ 0.          0.          0.        ]]
zmp [-16870921.17423915   8962724.64311849         0.        ]
d1:11727559.39657, d2:0.04588, d3:10880028.93416
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-631.406818268375 steps:252[00m
[RDDPG] Resetting Environment
transform [[ 0.66482949  0.24206379  0.        ]
 [-0.15780747  0.97020113  0.        ]
 [-0.73013604  0.01071875  0.        ]]
planes
[[ 0.70668733  0.66482949  0.24206379]
 [-0.18386562 -0.15780747  0.97020113]
 [ 0.68321782 -0.73013604  0.01071875]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-558.2277  -688.8148  -211.04018]
[ -79.94046526 -242.56963767   67.98011839]
[ 0.   0.  -9.8]
transform [[ 0.66482949  0.24206379  0.        ]
 [-0.15780747  0.97020113  0.        ]
 [-0.73013604  0.01071875  0.        ]]
transform [[ 0.66482949  0.24206379  0.        ]
 [-0.15780747  0.97020113  0.        ]
 [-0.73013604  0.01071875  0.        ]]
transform [[ 0.66482949  0.24206379  0.        ]
 [-0.15780747  0.97020113  0.        ]
 [-0.73013604  0.01071875  0.        ]]
support
[0. 0. 0.]
[-537.86337943 -580.19641514  400.19894044]
[-111.86410492 -222.72613518   55.76737032]
[0. 0. 0.]
transform [[ 0.66482949 -0.15780747 -0.73013604]
 [ 0.24206379  0.97020113  0.01071875]
 [ 0.          0.          0.        ]]
zmp [ 4547941.74969923 -5751000.73879314        0.        ]
d1:9554628.79935, d2:0.05919, d3:3335350.29781
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-496.8697241164217 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-125.91872692380713 steps:255[00m
[RDDPG] Resetting Environment
transform [[ 5.59568889e-02  2.26905468e-04  0.00000000e+00]
 [-4.30273600e-02  9.99071538e-01  0.00000000e+00]
 [-9.97505665e-01 -4.30821776e-02  0.00000000e+00]]
planes
[[ 9.98433173e-01  5.59568889e-02  2.26905468e-04]
 [ 2.18440476e-03 -4.30273600e-02  9.99071538e-01]
 [ 5.59145845e-02 -9.97505665e-01 -4.30821776e-02]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -53.826508 -969.67004  -112.19961 ]
[ -79.94046526 -242.56963767   67.98011839]
[ 0.   0.  -9.8]
transform [[ 5.59568889e-02  2.26905468e-04  0.00000000e+00]
 [-4.30273600e-02  9.99071538e-01  0.00000000e+00]
 [-9.97505665e-01 -4.30821776e-02  0.00000000e+00]]
transform [[ 5.59568889e-02  2.26905468e-04  0.00000000e+00]
 [-4.30273600e-02  9.99071538e-01  0.00000000e+00]
 [-9.97505665e-01 -4.30821776e-02  0.00000000e+00]]
transform [[ 5.59568889e-02  2.26905468e-04  0.00000000e+00]
 [-4.30273600e-02  9.99071538e-01  0.00000000e+00]
 [-9.97505665e-01 -4.30821776e-02  0.00000000e+00]]
support
[0. 0. 0.]
[  -3.23198734 -966.45373007   95.4677433 ]
[  -4.52826011 -238.90479391   90.19149517]
[0. 0. 0.]
transform [[ 5.59568889e-02 -4.30273600e-02 -9.97505665e-01]
 [ 2.26905468e-04  9.99071538e-01 -4.30821776e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]
zmp [ 21900237.55725446 -12684580.84611971         0.        ]
d1:18662001.16492, d2:0.03260, d3:10786407.63685
transform [[ 0.72828454  0.13504627  0.        ]
 [-0.10564316  0.99079537  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
planes
[[ 0.67183644  0.72828454  0.13504627]
 [-0.08464105 -0.10564316  0.99079537]
 [ 0.73584765 -0.67708284 -0.00933215]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -40.930607 -129.11636  -161.36816 ]
[ -6.08853265 -11.90494079   1.83448439]
[ 0.   0.  -9.8]
transform [[ 0.72828454  0.13504627  0.        ]
 [-0.10564316  0.99079537  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
transform [[ 0.72828454  0.13504627  0.        ]
 [-0.10564316  0.99079537  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
transform [[ 0.72828454  0.13504627  0.        ]
 [-0.10564316  0.99079537  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
support
[0. 0. 0.]
[ -47.24581182 -123.603857     28.91834529]
[ -6.04190207 -11.15214843   4.23353971]
[0. 0. 0.]
transform [[ 0.72828454 -0.10564316 -0.67708284]
 [ 0.13504627  0.99079537 -0.00933215]
 [ 0.          0.          0.        ]]
zmp [ 15906312.81823439 -13293061.5937981          0.        ]
d1:29906164.04407, d2:0.05933, d3:10118239.85984
transform [[ 0.42078087  0.81542766  0.        ]
 [-0.60374027  0.57878375  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
planes
[[ 0.39751872  0.42078087  0.81542766]
 [-0.54818529 -0.60374027  0.57878375]
 [ 0.73584765 -0.67708284 -0.00933215]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -40.930607 -129.11636  -161.36816 ]
[ -6.08853265 -11.90494079   1.83448439]
[ 0.   0.  -9.8]
transform [[ 0.42078087  0.81542766  0.        ]
 [-0.60374027  0.57878375  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
transform [[ 0.42078087  0.81542766  0.        ]
 [-0.60374027  0.57878375  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
transform [[ 0.42078087  0.81542766  0.        ]
 [-0.60374027  0.57878375  0.        ]
 [-0.67708284 -0.00933215  0.        ]]
support
[0. 0. 0.]
[-122.50787055  -50.01899731   28.91834529]
[-12.26955607  -3.21449391   4.23353971]
[0. 0. 0.]
transform [[ 0.42078087 -0.60374027 -0.67708284]
 [ 0.81542766  0.57878375 -0.00933215]
 [ 0.          0.          0.        ]]
zmp [22689307.30298739 -7682363.59554734        0.        ]
d1:32077285.22253, d2:0.05764, d3:10780529.05817
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-352.3674105345187 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-126.14881432616657 steps:260[00m
[RDDPG] Resetting Environment
transform [[-0.17093475  0.97723639  0.        ]
 [ 0.62898564  0.20639828  0.        ]
 [-0.75839198 -0.04908027  0.        ]]
planes
[[ 0.12566002 -0.17093475  0.97723639]
 [-0.74951774  0.62898564  0.20639828]
 [-0.6499483  -0.75839198 -0.04908027]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -40.930607 -129.11636  -161.36816 ]
[ -6.08853265 -11.90494079   1.83448439]
[ 0.   0.  -9.8]
transform [[-0.17093475  0.97723639  0.        ]
 [ 0.62898564  0.20639828  0.        ]
 [-0.75839198 -0.04908027  0.        ]]
transform [[-0.17093475  0.97723639  0.        ]
 [ 0.62898564  0.20639828  0.        ]
 [-0.75839198 -0.04908027  0.        ]]
transform [[-0.17093475  0.97723639  0.        ]
 [ 0.62898564  0.20639828  0.        ]
 [-0.75839198 -0.04908027  0.        ]]
support
[0. 0. 0.]
[-119.18074588  -52.39415923   37.37851045]
[-10.59319955  -6.28675891   5.20179208]
[0. 0. 0.]
transform [[-0.17093475  0.62898564 -0.75839198]
 [ 0.97723639  0.20639828 -0.04908027]
 [ 0.          0.          0.        ]]
zmp [22386139.2808619  1881945.4089634        0.       ]
d1:23155892.87227, d2:0.05903, d3:7687352.67858
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-195.49695178762363 steps:262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-118.1359764354947 steps:263[00m
[RDDPG] Resetting Environment
transform [[-0.29971576  0.91840053  0.        ]
 [ 0.66000539  0.39509204  0.        ]
 [-0.68888563 -0.02104305  0.        ]]
planes
[[ 0.25828469 -0.29971576  0.91840053]
 [-0.63897985  0.66000539  0.39509204]
 [-0.72456455 -0.68888563 -0.02104305]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[ -40.930607 -129.11636  -161.36816 ]
[ -6.08853265 -11.90494079   1.83448439]
[ 0.   0.  -9.8]
transform [[-0.29971576  0.91840053  0.        ]
 [ 0.66000539  0.39509204  0.        ]
 [-0.68888563 -0.02104305  0.        ]]
transform [[-0.29971576  0.91840053  0.        ]
 [ 0.66000539  0.39509204  0.        ]
 [-0.68888563 -0.02104305  0.        ]]
transform [[-0.29971576  0.91840053  0.        ]
 [ 0.66000539  0.39509204  0.        ]
 [-0.68888563 -0.02104305  0.        ]]
support
[0. 0. 0.]
[-106.31298835  -78.02726866   30.91350859]
[-9.10867471 -8.72201171  4.44481888]
[0. 0. 0.]
transform [[-0.29971576  0.66000539 -0.68888563]
 [ 0.91840053  0.39509204 -0.02104305]
 [ 0.          0.          0.        ]]
zmp [-2269149.02649531 -2381750.24235349        0.        ]
d1:4589378.22328, d2:0.05936, d3:1481240.43588
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-128.4845761253875 steps:265[00m
[RDDPG] Resetting Environment
transform [[ 0.69813865 -0.0970542   0.        ]
 [ 0.08518887  0.9949916   0.        ]
 [-0.71087652  0.02392108  0.        ]]
planes
[[ 0.70935392  0.69813865 -0.0970542 ]
 [ 0.05229332  0.08518887  0.9949916 ]
 [ 0.70291001 -0.71087652  0.02392108]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[212.78264   395.6218     -5.5635676]
[ -81.29681053 -105.95984122   51.85685972]
[ 0.   0.  -9.8]
transform [[ 0.69813865 -0.0970542   0.        ]
 [ 0.08518887  0.9949916   0.        ]
 [-0.71087652  0.02392108  0.        ]]
transform [[ 0.69813865 -0.0970542   0.        ]
 [ 0.08518887  0.9949916   0.        ]
 [-0.71087652  0.02392108  0.        ]]
transform [[ 0.69813865 -0.0970542   0.        ]
 [ 0.08518887  0.9949916   0.        ]
 [-0.71087652  0.02392108  0.        ]]
support
[0. 0. 0.]
[ 110.15502868  411.76707685 -141.79848122]
[ -46.47259845 -112.35473568   55.25732009]
[0. 0. 0.]
transform [[ 0.69813865  0.08518887 -0.71087652]
 [-0.0970542   0.9949916   0.02392108]
 [ 0.          0.          0.        ]]
zmp [6702858.51339826 5854399.60129911       0.        ]
d1:12591136.09382, d2:0.00675, d3:465192.61285
transform [[ 0.70147473 -0.04817349  0.        ]
 [ 0.05087106  0.9985525   0.        ]
 [-0.71087652  0.02392108  0.        ]]
planes
[[ 0.71106434  0.70147473 -0.04817349]
 [ 0.01746537  0.05087106  0.9985525 ]
 [ 0.70291001 -0.71087652  0.02392108]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[212.78264   395.6218     -5.5635676]
[ -81.29681053 -105.95984122   51.85685972]
[ 0.   0.  -9.8]
transform [[ 0.70147473 -0.04817349  0.        ]
 [ 0.05087106  0.9985525   0.        ]
 [-0.71087652  0.02392108  0.        ]]
transform [[ 0.70147473 -0.04817349  0.        ]
 [ 0.05087106  0.9985525   0.        ]
 [-0.71087652  0.02392108  0.        ]]
transform [[ 0.70147473 -0.04817349  0.        ]
 [ 0.05087106  0.9985525   0.        ]
 [-0.71087652  0.02392108  0.        ]]
support
[0. 0. 0.]
[ 130.20316014  405.87361101 -141.79848122]
[ -51.92320246 -109.94211904   55.25732009]
[0. 0. 0.]
transform [[ 0.70147473  0.05087106 -0.71087652]
 [-0.04817349  0.9985525   0.02392108]
 [ 0.          0.          0.        ]]
zmp [6493759.87882598 5876096.25585515       0.        ]
d1:12400087.79715, d2:0.00384, d3:388871.94163
transform [[ 0.01357154  0.99884796  0.        ]
 [ 0.92107511  0.00542679  0.        ]
 [-0.38914838  0.04767946  0.        ]]
planes
[[ 0.04602819  0.01357154  0.99884796]
 [-0.38934717  0.92107511  0.00542679]
 [-0.91994035 -0.38914838  0.04767946]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 0.]]
inertial
[0.        0.        1.2181312]
[-1192.4264    960.54095   216.10728]
[-82.1892815   98.14163439 106.061205  ]
[ 0.   0.  -9.8]
transform [[ 0.01357154  0.99884796  0.        ]
 [ 0.92107511  0.00542679  0.        ]
 [-0.38914838  0.04767946  0.        ]]
transform [[ 0.01357154  0.99884796  0.        ]
 [ 0.92107511  0.00542679  0.        ]
 [-0.38914838  0.04767946  0.        ]]
transform [[ 0.01357154  0.99884796  0.        ]
 [ 0.92107511  0.00542679  0.        ]
 [-0.38914838  0.04767946  0.        ]]
support
[0. 0. 0.]
[  943.25131535 -1093.10160871   509.82887923]
[ 96.91313656 -75.16990691  36.66316639]
[0. 0. 0.]
transform [[ 0.01357154  0.92107511 -0.38914838]
 [ 0.99884796  0.00542679  0.04767946]
 [ 0.          0.          0.        ]]
zmp [-1.82223348e+07  4.12724283e+03  0.00000000e+00]
d1:17708228.48027, d2:0.05934, d3:6024115.86686
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-663.894738861753 steps:269[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620122738.579907371, 149.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620122738.579961029, 149.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620122739.585276074, 149.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620122739.585405016, 149.806000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620122741.266740483, 149.806000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620122741.266927556, 149.806000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 959, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:35:58.831258: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:35:58.831292: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620122765.965780172, 1.358000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620122765.968903070, 1.361000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620122765.969009394, 1.361000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620122767.481606294, 2.421000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620122768.521184933, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620122769.673403452, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620122770.752907393, 4.800000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[ 0.7118513  -0.70232511  0.0026784 ]
 [ 0.01215127  0.01612892  0.99979615]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.7118513  -0.70232511  0.0026784 ]
 [ 0.01215127  0.01612892  0.99979615]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.7118513  -0.70232511  0.0026784 ]
 [ 0.01215127  0.01612892  0.99979615]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.7118513  -0.70232511  0.0026784 ]
 [ 0.01215127  0.01612892  0.99979615]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.7118513  -0.70232511  0.0026784 ]
 [ 0.01215127  0.01612892  0.99979615]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.00326264 1.21788289 0.02438154]
[ 1.22045882e-10  1.02807634e-08 -1.39388323e-08]
[ 1.22045882e-10  1.02807634e-08 -1.39388323e-08]
[-0.02624827 -9.79800229 -0.19615222]
transform [[ 0.7118513   0.01215127 -0.70222515]
 [-0.70232511  0.01612892 -0.71167362]
 [ 0.0026784   0.99979615  0.02001553]]
zmp [18987884.20519296 19243462.53447876  -516155.65530218]
d1:39322767.74931, d2:0.05940, d3:12493040.20003
transform [[ 0.71193796 -0.70212507  0.0128334 ]
 [ 0.00492022  0.02326175  0.99971735]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.71193796 -0.70212507  0.0128334 ]
 [ 0.00492022  0.02326175  0.99971735]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71193796 -0.70212507  0.0128334 ]
 [ 0.00492022  0.02326175  0.99971735]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71193796 -0.70212507  0.0128334 ]
 [ 0.00492022  0.02326175  0.99971735]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71193796 -0.70212507  0.0128334 ]
 [ 0.00492022  0.02326175  0.99971735]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.01563276 1.2177869  0.02438154]
[ 2.26462912e-10  1.02789932e-08 -1.39388323e-08]
[ 2.26462912e-10  1.02789932e-08 -1.39388323e-08]
[-0.12576732 -9.79723008 -0.19615222]
transform [[ 0.71193796  0.00492022 -0.70222515]
 [-0.70212507  0.02326175 -0.71167362]
 [ 0.0128334   0.99971735  0.02001553]]
zmp [18987703.04800006 19243641.23108905  -516157.62938587]
d1:39322767.86339, d2:0.05940, d3:12493042.49439
transform [[ 0.71179026 -0.70118058  0.04123687]
 [-0.01531269  0.04320443  0.99894887]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.71179026 -0.70118058  0.04123687]
 [-0.01531269  0.04320443  0.99894887]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71179026 -0.70118058  0.04123687]
 [-0.01531269  0.04320443  0.99894887]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71179026 -0.70118058  0.04123687]
 [-0.01531269  0.04320443  0.99894887]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71179026 -0.70118058  0.04123687]
 [-0.01531269  0.04320443  0.99894887]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.05023192 1.21685079 0.02438154]
[ 5.18465601e-10  1.02684061e-08 -1.39388323e-08]
[ 5.18465601e-10  1.02684061e-08 -1.39388323e-08]
[-0.40412136 -9.78969895 -0.19615222]
transform [[ 0.71179026 -0.01531269 -0.70222515]
 [-0.70118058  0.04320443 -0.71167362]
 [ 0.04123687  0.99894887  0.02001553]]
zmp [18987196.15960157 19244140.84838185  -516176.88193234]
d1:39322769.72372, d2:0.05940, d3:12493057.52504
transform [[ 0.71188414 -0.70148134  0.03383616]
 [-0.01003978  0.03800934  0.99922693]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.71188414 -0.70148134  0.03383616]
 [-0.01003978  0.03800934  0.99922693]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71188414 -0.70148134  0.03383616]
 [-0.01003978  0.03800934  0.99922693]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71188414 -0.70148134  0.03383616]
 [-0.01003978  0.03800934  0.99922693]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71188414 -0.70148134  0.03383616]
 [-0.01003978  0.03800934  0.99922693]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.04121689 1.2171895  0.02438154]
[ 4.42389622e-10  1.02719649e-08 -1.39388323e-08]
[ 4.42389622e-10  1.02719649e-08 -1.39388323e-08]
[-0.3315944  -9.79242389 -0.19615222]
transform [[ 0.71188414 -0.01003978 -0.70222515]
 [-0.70148134  0.03800934 -0.71167362]
 [ 0.03383616  0.99922693  0.02001553]]
zmp [18987328.26007596 19244010.69760952  -516169.91589422]
d1:39322769.02011, d2:0.05940, d3:12493052.38569
transform [[ 0.71085525 -0.6993013   0.07525013]
 [-0.03955664  0.06707068  0.99696386]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.71085525 -0.6993013   0.07525013]
 [-0.03955664  0.06707068  0.99696386]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71085525 -0.6993013   0.07525013]
 [-0.03955664  0.06707068  0.99696386]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71085525 -0.6993013   0.07525013]
 [-0.03955664  0.06707068  0.99696386]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.71085525 -0.6993013   0.07525013]
 [-0.03955664  0.06707068  0.99696386]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.09166453 1.21443278 0.02438154]
[ 8.68040696e-10  1.02447790e-08 -1.39388323e-08]
[ 8.68040696e-10  1.02447790e-08 -1.39388323e-08]
[-0.73745124 -9.77024581 -0.19615222]
transform [[ 0.71085525 -0.03955664 -0.70222515]
 [-0.6993013   0.06707068 -0.71167362]
 [ 0.07525013  0.99696386  0.02001553]]
zmp [18986588.78379316 19244738.76180179  -516226.61182898]
d1:39322774.94608, d2:0.05940, d3:12493092.25727
transform [[ 0.70859349 -0.69590473  0.11666992]
 [-0.069102    0.09611142  0.9929691 ]
 [-0.70222515 -0.71167362  0.02001553]]
planes
[[ 0.70859349 -0.69590473  0.11666992]
 [-0.069102    0.09611142  0.9929691 ]
 [-0.70222515 -0.71167362  0.02001553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.70859349 -0.69590473  0.11666992]
 [-0.069102    0.09611142  0.9929691 ]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.70859349 -0.69590473  0.11666992]
 [-0.069102    0.09611142  0.9929691 ]
 [-0.70222515 -0.71167362  0.02001553]]
transform [[ 0.70859349 -0.69590473  0.11666992]
 [-0.069102    0.09611142  0.9929691 ]
 [-0.70222515 -0.71167362  0.02001553]]
support
[0.14211927 1.20956664 0.02438154]
[ 1.29358679e-09  1.01997852e-08 -1.39388323e-08]
[ 1.29358679e-09  1.01997852e-08 -1.39388323e-08]
[-1.14336525 -9.73109714 -0.19615222]
transform [[ 0.70859349 -0.069102   -0.70222515]
 [-0.69590473  0.09611142 -0.71167362]
 [ 0.11666992  0.9929691   0.02001553]]
zmp [18985848.59343081 19245466.31016752  -516326.69132344]
d1:39322785.74289, d2:0.05940, d3:12493159.34355
transform [[ 0.66447651  0.74044031 -0.10109021]
 [ 0.00838586  0.12787592  0.99175477]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.66447651  0.74044031 -0.10109021]
 [ 0.00838586  0.12787592  0.99175477]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.66447651  0.74044031 -0.10109021]
 [ 0.00838586  0.12787592  0.99175477]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.66447651  0.74044031 -0.10109021]
 [ 0.00838586  0.12787592  0.99175477]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.66447651  0.74044031 -0.10109021]
 [ 0.00838586  0.12787592  0.99175477]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[-0.12314114  1.20808743  0.0959416 ]
[ 40.97836079 351.11466599  49.78149582]
[ 43.77109653  49.39649419 -76.46485433]
[ 0.99068404 -9.71919675 -0.77186076]
transform [[ 0.66447651  0.00838586  0.74726224]
 [ 0.74044031  0.12787592 -0.65984535]
 [-0.10109021  0.99175477  0.0787613 ]]
zmp [-3566045.80266323  3090134.43576387  -806141.76750991]
d1:7053719.74969, d2:0.05940, d3:2635721.72135
transform [[ 0.048638    0.17251192  0.98380589]
 [-0.66274697 -0.73133022  0.1610052 ]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.048638    0.17251192  0.98380589]
 [-0.66274697 -0.73133022  0.1610052 ]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.048638    0.17251192  0.98380589]
 [-0.66274697 -0.73133022  0.1610052 ]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.048638    0.17251192  0.98380589]
 [-0.66274697 -0.73133022  0.1610052 ]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.048638    0.17251192  0.98380589]
 [-0.66274697 -0.73133022  0.1610052 ]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[1.19840466 0.19612546 0.0959416 ]
[352.95265238 -19.62533625  49.78149582]
[ 51.95825666 -40.69721216 -76.46485433]
[-9.64129777 -1.57785095 -0.77186076]
transform [[ 0.048638   -0.66274697  0.74726224]
 [ 0.17251192 -0.73133022 -0.65984535]
 [ 0.98380589  0.1610052   0.0787613 ]]
zmp [-3274608.27268005  3463244.45907856  -445393.22748632]
d1:6966754.35233, d2:0.05940, d3:2424777.77322
transform [[ 0.03466041  0.15706146  0.98698044]
 [-0.66362482 -0.73480332  0.14023662]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.03466041  0.15706146  0.98698044]
 [-0.66362482 -0.73480332  0.14023662]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.03466041  0.15706146  0.98698044]
 [-0.66362482 -0.73480332  0.14023662]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.03466041  0.15706146  0.98698044]
 [-0.66362482 -0.73480332  0.14023662]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.03466041  0.15706146  0.98698044]
 [-0.66362482 -0.73480332  0.14023662]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[1.20227167 0.1708266  0.0959416 ]
[352.46067706 -27.05914023  49.78149582]
[ 51.08905785 -41.78314521 -76.46485433]
[-9.67240829 -1.37431884 -0.77186076]
transform [[ 0.03466041 -0.66362482  0.74726224]
 [ 0.15706146 -0.73480332 -0.65984535]
 [ 0.98698044  0.14023662  0.0787613 ]]
zmp [-3274227.06766877  3464752.65282227  -436374.49123918]
d1:6965489.61807, d2:0.05940, d3:2419377.05356
transform [[ 0.66449261  0.74070776 -0.09900292]
 [ 0.00698751  0.12631744  0.99196529]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.66449261  0.74070776 -0.09900292]
 [ 0.00698751  0.12631744  0.99196529]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.66449261  0.74070776 -0.09900292]
 [ 0.00698751  0.12631744  0.99196529]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.66449261  0.74070776 -0.09900292]
 [ 0.00698751  0.12631744  0.99196529]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.66449261  0.74070776 -0.09900292]
 [ 0.00698751  0.12631744  0.99196529]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[-0.12059855  1.20834387  0.0959416 ]
[ 41.71715472 351.02764732  49.78149582]
[ 43.87495098  49.30427107 -76.46485433]
[ 0.97022862 -9.72125988 -0.77186076]
transform [[ 0.66449261  0.00698751  0.74726224]
 [ 0.74070776  0.12631744 -0.65984535]
 [-0.09900292  0.99196529  0.0787613 ]]
zmp [-3565438.5959379   3090811.20923802  -806233.25588235]
d1:7053752.87500, d2:0.05940, d3:2635787.76791
transform [[ 0.01508927 -0.10164314 -0.99470651]
 [ 0.66435796  0.74449503 -0.06599749]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.01508927 -0.10164314 -0.99470651]
 [ 0.66435796  0.74449503 -0.06599749]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.01508927 -0.10164314 -0.99470651]
 [ 0.66435796  0.74449503 -0.06599749]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.01508927 -0.10164314 -0.99470651]
 [ 0.66435796  0.74449503 -0.06599749]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.01508927 -0.10164314 -0.99470651]
 [ 0.66435796  0.74449503 -0.06599749]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[-1.21168304 -0.0803936   0.0959416 ]
[-349.44817959   53.35446001   49.78149582]
[-47.81963817  45.48851996 -76.46485433]
[ 9.74812381  0.64677539 -0.77186076]
transform [[ 0.01508927  0.66435796  0.74726224]
 [-0.10164314  0.74449503 -0.65984535]
 [-0.99470651 -0.06599749  0.0787613 ]]
zmp [-3850902.94183761  2822368.08432722  -346817.47181592]
d1:6949124.08967, d2:0.05940, d3:2355063.93628
transform [[ 0.08588358 -0.02163271 -0.99607033]
 [ 0.65895617  0.75109005  0.04050457]
 [ 0.74726224 -0.65984535  0.0787613 ]]
planes
[[ 0.08588358 -0.02163271 -0.99607033]
 [ 0.65895617  0.75109005  0.04050457]
 [ 0.74726224 -0.65984535  0.0787613 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 67.373375  42.393047 347.99796 ]
[-27.64019705  89.18148629  38.54190287]
[ 0.   0.  -9.8]
transform [[ 0.08588358 -0.02163271 -0.99607033]
 [ 0.65895617  0.75109005  0.04050457]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.08588358 -0.02163271 -0.99607033]
 [ 0.65895617  0.75109005  0.04050457]
 [ 0.74726224 -0.65984535  0.0787613 ]]
transform [[ 0.08588358 -0.02163271 -0.99607033]
 [ 0.65895617  0.75109005  0.04050457]
 [ 0.74726224 -0.65984535  0.0787613 ]]
support
[-1.21334434  0.04933988  0.0959416 ]
[-341.76124646   90.33260505   49.78149582]
[-42.69352208  50.33077183 -76.46485433]
[ 9.76148919 -0.3969448  -0.77186076]
transform [[ 0.08588358  0.65895617  0.74726224]
 [-0.02163271  0.75109005 -0.65984535]
 [-0.99607033  0.04050457  0.0787613 ]]
zmp [-3848557.23852438  2819504.2046808   -393065.99330288]
d1:6954259.14062, d2:0.05940, d3:2382838.22211
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.68753505  0.72387189  0.05749065]
 [-0.01522556 -0.06478371  0.99778318]
 [ 0.72599155 -0.68688625 -0.03351972]]
planes
[[ 0.68753505  0.72387189  0.05749065]
 [-0.01522556 -0.06478371  0.99778318]
 [ 0.72599155 -0.68688625 -0.03351972]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-260.658    395.01535 1357.9027 ]
[ -14.99432729 -513.24180679   29.2181431 ]
[ 0.   0.  -9.8]
transform [[ 0.68753505  0.72387189  0.05749065]
 [-0.01522556 -0.06478371  0.99778318]
 [ 0.72599155 -0.68688625 -0.03351972]]
transform [[ 0.68753505  0.72387189  0.05749065]
 [-0.01522556 -0.06478371  0.99778318]
 [ 0.72599155 -0.68688625 -0.03351972]]
transform [[ 0.68753505  0.72387189  0.05749065]
 [-0.01522556 -0.06478371  0.99778318]
 [ 0.72599155 -0.68688625 -0.03351972]]
support
[ 0.07003116  1.21543083 -0.04083141]
[ 184.795719   1333.27059496 -506.08262207]
[-380.15067039   62.63137587  340.67360181]
[-0.56340841 -9.7782752   0.32849321]
transform [[ 0.68753505 -0.01522556  0.72599155]
 [ 0.72387189 -0.06478371 -0.68688625]
 [ 0.05749065  0.99778318 -0.03351972]]
zmp [ 6058786.08333559 -5071243.37693646 -8604840.74518973]
d1:19016884.41034, d2:0.05940, d3:9010920.90887
transform [[ 0.07479738  0.114053   -0.990655  ]
 [ 0.6971724  -0.71628284 -0.02982626]
 [-0.71299094 -0.68842638 -0.13309067]]
planes
[[ 0.07479738  0.114053   -0.990655  ]
 [ 0.6971724  -0.71628284 -0.02982626]
 [-0.71299094 -0.68842638 -0.13309067]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 436.31458  436.46265 1080.0757 ]
[ 19.74729233 174.49125071   8.35838019]
[ 0.   0.  -9.8]
transform [[ 0.07479738  0.114053   -0.990655  ]
 [ 0.6971724  -0.71628284 -0.02982626]
 [-0.71299094 -0.68842638 -0.13309067]]
transform [[ 0.07479738  0.114053   -0.990655  ]
 [ 0.6971724  -0.71628284 -0.02982626]
 [-0.71299094 -0.68842638 -0.13309067]]
transform [[ 0.07479738  0.114053   -0.990655  ]
 [ 0.6971724  -0.71628284 -0.02982626]
 [-0.71299094 -0.68842638 -0.13309067]]
support
[-1.20674777 -0.0363323  -0.1621219 ]
[-987.56732345  -40.65884632 -755.3087383 ]
[  13.09802443 -111.4671214  -135.31644224]
[9.70841905 0.29229738 1.30428861]
transform [[ 0.07479738  0.6971724  -0.71299094]
 [ 0.114053   -0.71628284 -0.68842638]
 [-0.990655   -0.02982626 -0.13309067]]
zmp [  9305878.49255378 -18843172.8054509   -1466771.97773722]
d1:13207381.25813, d2:0.05940, d3:3787526.92673
transform [[ 0.65124756  0.75813138 -0.03336919]
 [-0.22328198  0.23345809  0.94638389]
 [ 0.72527355 -0.60887957  0.32131609]]
planes
[[ 0.65124756  0.75813138 -0.03336919]
 [-0.22328198  0.23345809  0.94638389]
 [ 0.72527355 -0.60887957  0.32131609]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[121.138054 -30.3487   305.20627 ]
[-20.45922874 166.47830143  -9.67137951]
[ 0.   0.  -9.8]
transform [[ 0.65124756  0.75813138 -0.03336919]
 [-0.22328198  0.23345809  0.94638389]
 [ 0.72527355 -0.60887957  0.32131609]]
transform [[ 0.65124756  0.75813138 -0.03336919]
 [-0.22328198  0.23345809  0.94638389]
 [ 0.72527355 -0.60887957  0.32131609]]
transform [[ 0.65124756  0.75813138 -0.03336919]
 [-0.22328198  0.23345809  0.94638389]
 [ 0.72527355 -0.60887957  0.32131609]]
support
[-0.04064805  1.15281975  0.39140516]
[ 45.69807539 254.70920271 204.40461512]
[ 113.21112847   34.28104505 -119.31134328]
[ 0.32701804 -9.27456216 -3.14889771]
transform [[ 0.65124756 -0.22328198  0.72527355]
 [ 0.75813138  0.23345809 -0.60887957]
 [-0.03336919  0.94638389  0.32131609]]
zmp [  188093.48810033  -576690.04901722 -9431208.8522622 ]
d1:17438094.49638, d2:0.05940, d3:6167701.34083
transform [[ 0.05174838 -0.83876348 -0.54203141]
 [ 0.02117072 -0.5417152   0.84029543]
 [-0.9984358  -0.05495912 -0.01027566]]
planes
[[ 0.05174838 -0.83876348 -0.54203141]
 [ 0.02117072 -0.5417152   0.84029543]
 [-0.9984358  -0.05495912 -0.01027566]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-46.61619 204.44402 508.7794 ]
[-20.28734704 300.63286959  36.79784476]
[ 0.   0.  -9.8]
transform [[ 0.05174838 -0.83876348 -0.54203141]
 [ 0.02117072 -0.5417152   0.84029543]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05174838 -0.83876348 -0.54203141]
 [ 0.02117072 -0.5417152   0.84029543]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05174838 -0.83876348 -0.54203141]
 [ 0.02117072 -0.5417152   0.84029543]
 [-0.9984358  -0.05495912 -0.01027566]]
support
[-0.66026537  1.02359009 -0.0125171 ]
[-449.66689316  315.78766693   30.07916912]
[-273.15529538 -132.36583331    3.35497397]
[ 5.31190779 -8.23489525  0.10070144]
transform [[ 0.05174838  0.02117072 -0.9984358 ]
 [-0.83876348 -0.5417152  -0.05495912]
 [-0.54203141  0.84029543 -0.01027566]]
zmp [-7567520.88935968 -2510542.40861464  3162445.00057284]
d1:8761429.30764, d2:0.05940, d3:5522675.37610
transform [[ 0.05277534 -0.98706478  0.15138684]
 [-0.01846283  0.15060775  0.98842126]
 [-0.9984358  -0.05495912 -0.01027566]]
planes
[[ 0.05277534 -0.98706478  0.15138684]
 [-0.01846283  0.15060775  0.98842126]
 [-0.9984358  -0.05495912 -0.01027566]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-46.61619 204.44402 508.7794 ]
[-20.28734704 300.63286959  36.79784476]
[ 0.   0.  -9.8]
transform [[ 0.05277534 -0.98706478  0.15138684]
 [-0.01846283  0.15060775  0.98842126]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05277534 -0.98706478  0.15138684]
 [-0.01846283  0.15060775  0.98842126]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05277534 -0.98706478  0.15138684]
 [-0.01846283  0.15060775  0.98842126]
 [-0.9984358  -0.05495912 -0.01027566]]
support
[ 0.18440904  1.20402678 -0.0125171 ]
[-127.23716728  534.5398846    30.07916912]
[-292.24407901   82.0239739     3.35497397]
[-1.48359105 -9.68652836  0.10070144]
transform [[ 0.05277534 -0.01846283 -0.9984358 ]
 [-0.98706478  0.15060775 -0.05495912]
 [ 0.15138684  0.98842126 -0.01027566]]
zmp [-7720393.68465273   159870.25119408  3733793.98306762]
d1:9477558.62411, d2:0.05940, d3:5444256.34316
transform [[ 0.05161226 -0.97663623  0.2086097 ]
 [-0.02150058  0.20775302  0.97794503]
 [-0.9984358  -0.05495912 -0.01027566]]
planes
[[ 0.05161226 -0.97663623  0.2086097 ]
 [-0.02150058  0.20775302  0.97794503]
 [-0.9984358  -0.05495912 -0.01027566]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-46.61619 204.44402 508.7794 ]
[-20.28734704 300.63286959  36.79784476]
[ 0.   0.  -9.8]
transform [[ 0.05161226 -0.97663623  0.2086097 ]
 [-0.02150058  0.20775302  0.97794503]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05161226 -0.97663623  0.2086097 ]
 [-0.02150058  0.20775302  0.97794503]
 [-0.9984358  -0.05495912 -0.01027566]]
transform [[ 0.05161226 -0.97663623  0.2086097 ]
 [-0.02150058  0.20775302  0.97794503]
 [-0.9984358  -0.05495912 -0.01027566]]
support
[ 0.25411398  1.19126535 -0.0125171 ]
[-95.93708397 541.03441053  30.07916912]
[-286.97964108   98.87984499    3.35497397]
[-2.04437506 -9.58386129  0.10070144]
transform [[ 0.05161226 -0.02150058 -0.9984358 ]
 [-0.97663623  0.20775302 -0.05495912]
 [ 0.2086097   0.97794503 -0.01027566]]
zmp [-7732110.53066659   380289.91019665  3693385.89700044]
d1:9508755.57902, d2:0.05940, d3:5384833.04561
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.66758859  0.6427201   0.3758142 ]
 [-0.29426521 -0.23589411  0.92615443]
 [ 0.68391043 -0.72887915  0.03164995]]
planes
[[ 0.66758859  0.6427201   0.3758142 ]
 [-0.29426521 -0.23589411  0.92615443]
 [ 0.68391043 -0.72887915  0.03164995]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-622.7084   165.63628  575.836  ]
[  18.72841934 -476.02722795  -21.7932857 ]
[ 0.   0.  -9.8]
transform [[ 0.66758859  0.6427201   0.3758142 ]
 [-0.29426521 -0.23589411  0.92615443]
 [ 0.68391043 -0.72887915  0.03164995]]
transform [[ 0.66758859  0.6427201   0.3758142 ]
 [-0.29426521 -0.23589411  0.92615443]
 [ 0.68391043 -0.72887915  0.03164995]]
transform [[ 0.66758859  0.6427201   0.3758142 ]
 [-0.29426521 -0.23589411  0.92615443]
 [ 0.68391043 -0.72887915  0.03164995]]
support
[0.457791   1.12817761 0.0385538 ]
[ -92.847897    677.48185194 -528.38039715]
[-301.63961623   86.59695061  359.08512787]
[-3.68297915 -9.07631346 -0.31016956]
transform [[ 0.66758859 -0.29426521  0.68391043]
 [ 0.6427201  -0.23589411 -0.72887915]
 [ 0.3758142   0.92615443  0.03164995]]
zmp [-7238788.38601406  -185458.00199789 13176005.77471384]
d1:27987089.82976, d2:0.05940, d3:10386611.02863
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:215.61932325018333[00m
[RDDPG] Resetting Environment
transform [[ 0.66696942 -0.63072515  0.39665803]
 [-0.17786869  0.3821916   0.90680337]
 [-0.72354305 -0.67536318  0.14272384]]
planes
[[ 0.66696942 -0.63072515  0.39665803]
 [-0.17786869  0.3821916   0.90680337]
 [-0.72354305 -0.67536318  0.14272384]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-622.7084   165.63628  575.836  ]
[  18.72841934 -476.02722795  -21.7932857 ]
[ 0.   0.  -9.8]
transform [[ 0.66696942 -0.63072515  0.39665803]
 [-0.17786869  0.3821916   0.90680337]
 [-0.72354305 -0.67536318  0.14272384]]
transform [[ 0.66696942 -0.63072515  0.39665803]
 [-0.17786869  0.3821916   0.90680337]
 [-0.72354305 -0.67536318  0.14272384]]
transform [[ 0.66696942 -0.63072515  0.39665803]
 [-0.17786869  0.3821916   0.90680337]
 [-0.72354305 -0.67536318  0.14272384]]
support
[0.48318153 1.10460548 0.17385637]
[-291.38843196  696.23514221  420.87719906]
[ 304.08914365 -205.02703153  304.83002477]
[-3.88724872 -8.88667302 -1.39869367]
transform [[ 0.66696942 -0.17786869 -0.72354305]
 [-0.63072515  0.3821916  -0.67536318]
 [ 0.39665803  0.90680337  0.14272384]]
zmp [  799967.18677853  7458770.17031106 10515053.17979757]
d1:23960608.95473, d2:0.05940, d3:9371337.05117
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-387.96185329876454 steps:2[00m
[RDDPG] Resetting Environment
transform [[ 0.22162111 -0.20482126  0.95337945]
 [-0.69613254  0.65141004  0.30176893]
 [-0.68284965 -0.73055679  0.00178348]]
planes
[[ 0.22162111 -0.20482126  0.95337945]
 [-0.69613254  0.65141004  0.30176893]
 [-0.68284965 -0.73055679  0.00178348]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-622.7084   165.63628  575.836  ]
[  18.72841934 -476.02722795  -21.7932857 ]
[ 0.   0.  -9.8]
transform [[ 0.22162111 -0.20482126  0.95337945]
 [-0.69613254  0.65141004  0.30176893]
 [-0.68284965 -0.73055679  0.00178348]]
transform [[ 0.22162111 -0.20482126  0.95337945]
 [-0.69613254  0.65141004  0.30176893]
 [-0.68284965 -0.73055679  0.00178348]]
transform [[ 0.22162111 -0.20482126  0.95337945]
 [-0.69613254  0.65141004  0.30176893]
 [-0.68284965 -0.73055679  0.00178348]]
support
[1.16134126 0.36759415 0.00217252]
[377.05905655 715.15410882 305.23648079]
[  80.87383836 -329.70291576  334.93735926]
[-9.34311863 -2.9573355  -0.01747814]
transform [[ 0.22162111 -0.69613254 -0.68284965]
 [-0.20482126  0.65141004 -0.73055679]
 [ 0.95337945  0.30176893  0.00178348]]
zmp [21222863.88190167 10939999.56994803 -2583116.52404126]
d1:32703898.64221, d2:0.05940, d3:11848139.64207
transform [[ 0.82410133  0.47748438  0.30473876]
 [-0.07286848 -0.444152    0.89298338]
 [ 0.56173593 -0.75811458 -0.33123267]]
planes
[[ 0.82410133  0.47748438  0.30473876]
 [-0.07286848 -0.444152    0.89298338]
 [ 0.56173593 -0.75811458 -0.33123267]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 413.60883 -546.44214  237.20453]
[-387.87844748 -288.88933034 -139.86419712]
[ 0.   0.  -9.8]
transform [[ 0.82410133  0.47748438  0.30473876]
 [-0.07286848 -0.444152    0.89298338]
 [ 0.56173593 -0.75811458 -0.33123267]]
transform [[ 0.82410133  0.47748438  0.30473876]
 [-0.07286848 -0.444152    0.89298338]
 [ 0.56173593 -0.75811458 -0.33123267]]
transform [[ 0.82410133  0.47748438  0.30473876]
 [-0.07286848 -0.444152    0.89298338]
 [ 0.56173593 -0.75811458 -0.33123267]]
support
[ 0.37121179  1.08777091 -0.40348485]
[152.22341366 424.38402164 568.03479931]
[-500.21332741   31.67848348   47.45354363]
[-2.98643985 -8.75123709  3.24608014]
transform [[ 0.82410133 -0.07286848  0.56173593]
 [ 0.47748438 -0.444152   -0.75811458]
 [ 0.30473876  0.89298338 -0.33123267]]
zmp [ 2567086.07040896 -1418863.44581617 -4718972.36332551]
d1:9197442.83527, d2:0.05940, d3:4280422.98505
transform [[ 0.97515112 -0.15246832 -0.16072887]
 [ 0.01158529 -0.68941623  0.72427279]
 [-0.22123767 -0.70813751 -0.67051864]]
planes
[[ 0.97515112 -0.15246832 -0.16072887]
 [ 0.01158529 -0.68941623  0.72427279]
 [-0.22123767 -0.70813751 -0.67051864]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 330.8869  -529.7826   430.49652]
[-387.87844748 -288.88933034 -139.86419712]
[ 0.   0.  -9.8]
transform [[ 0.97515112 -0.15246832 -0.16072887]
 [ 0.01158529 -0.68941623  0.72427279]
 [-0.22123767 -0.70813751 -0.67051864]]
transform [[ 0.97515112 -0.15246832 -0.16072887]
 [ 0.01158529 -0.68941623  0.72427279]
 [-0.22123767 -0.70813751 -0.67051864]]
transform [[ 0.97515112 -0.15246832 -0.16072887]
 [ 0.01158529 -0.68941623  0.72427279]
 [-0.22123767 -0.70813751 -0.67051864]]
support
[-0.19578885  0.88225928 -0.81677967]
[334.24657718 680.87105511  13.29833825]
[-311.71341657   93.37147505  384.16824812]
[ 1.57514294 -7.09787332  6.57108264]
transform [[ 0.97515112  0.01158529 -0.22123767]
 [-0.15246832 -0.68941623 -0.70813751]
 [-0.16072887  0.72427279 -0.67051864]]
zmp [  -605248.5262023   18323693.99615249 -21054037.79568791]
d1:53312035.97662, d2:0.05940, d3:14383353.51273
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-487.99256308924913 steps:6[00m
[RDDPG] Resetting Environment
transform [[ 1.88298628e-01 -1.81118235e-01 -9.65266705e-01]
 [ 6.96995854e-01 -6.67785048e-01  2.61266053e-01]
 [-6.91910744e-01 -7.21982956e-01  4.95646673e-04]]
planes
[[ 1.88298628e-01 -1.81118235e-01 -9.65266705e-01]
 [ 6.96995854e-01 -6.67785048e-01  2.61266053e-01]
 [-6.91910744e-01 -7.21982956e-01  4.95646673e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 330.8869  -529.7826   430.49652]
[-387.87844748 -288.88933034 -139.86419712]
[ 0.   0.  -9.8]
transform [[ 1.88298628e-01 -1.81118235e-01 -9.65266705e-01]
 [ 6.96995854e-01 -6.67785048e-01  2.61266053e-01]
 [-6.91910744e-01 -7.21982956e-01  4.95646673e-04]]
transform [[ 1.88298628e-01 -1.81118235e-01 -9.65266705e-01]
 [ 6.96995854e-01 -6.67785048e-01  2.61266053e-01]
 [-6.91910744e-01 -7.21982956e-01  4.95646673e-04]]
transform [[ 1.88298628e-01 -1.81118235e-01 -9.65266705e-01]
 [ 6.96995854e-01 -6.67785048e-01  2.61266053e-01]
 [-6.91910744e-01 -7.21982956e-01  4.95646673e-04]]
support
[-1.17582149e+00  3.18256330e-01  6.03762676e-04]
[-257.28512046  696.88182001  153.76317415]
[ 114.29239887 -113.97546113  476.8811145 ]
[ 9.45961370e+00 -2.56040732e+00 -4.85733739e-03]
transform [[ 1.88298628e-01  6.96995854e-01 -6.91910744e-01]
 [-1.81118235e-01 -6.67785048e-01 -7.21982956e-01]
 [-9.65266705e-01  2.61266053e-01  4.95646673e-04]]
zmp [3188653.95865971 1641545.82323756  314011.97800319]
d1:4464797.45112, d2:0.05940, d3:1731574.98888
transform [[ 0.16531242 -0.30695206 -0.93725789]
 [ 0.18112573  0.9436183  -0.27708834]
 [ 0.96946651 -0.12395536  0.21158876]]
planes
[[ 0.16531242 -0.30695206 -0.93725789]
 [ 0.18112573  0.9436183  -0.27708834]
 [ 0.96946651 -0.12395536  0.21158876]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 291.37607 -448.4063   548.42   ]
[  41.42330277 -246.81221606 -148.08182601]
[ 0.   0.  -9.8]
transform [[ 0.16531242 -0.30695206 -0.93725789]
 [ 0.18112573  0.9436183  -0.27708834]
 [ 0.96946651 -0.12395536  0.21158876]]
transform [[ 0.16531242 -0.30695206 -0.93725789]
 [ 0.18112573  0.9436183  -0.27708834]
 [ 0.96946651 -0.12395536  0.21158876]]
transform [[ 0.16531242 -0.30695206 -0.93725789]
 [ 0.18112573  0.9436183  -0.27708834]
 [ 0.96946651 -0.12395536  0.21158876]]
support
[-1.14170307 -0.33752996  0.25774286]
[-328.20362902 -522.30948165  454.10120705]
[ 221.39816376 -184.36194922   39.4197529 ]
[ 9.18512728  2.71546577 -2.0735698 ]
transform [[ 0.16531242  0.18112573  0.96946651]
 [-0.30695206  0.9436183  -0.12395536]
 [-0.93725789 -0.27708834  0.21158876]]
zmp [  631757.74699791 -8799846.49004755  2993379.29792196]
d1:10449650.15682, d2:0.05940, d3:4847894.05282
transform [[ 0.16707236 -0.29772767 -0.93991762]
 [ 0.17950365  0.94656926 -0.2679275 ]
 [ 0.96946651 -0.12395536  0.21158876]]
planes
[[ 0.16707236 -0.29772767 -0.93991762]
 [ 0.17950365  0.94656926 -0.2679275 ]
 [ 0.96946651 -0.12395536  0.21158876]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 291.37607 -448.4063   548.42   ]
[  41.42330277 -246.81221606 -148.08182601]
[ 0.   0.  -9.8]
transform [[ 0.16707236 -0.29772767 -0.93991762]
 [ 0.17950365  0.94656926 -0.2679275 ]
 [ 0.96946651 -0.12395536  0.21158876]]
transform [[ 0.16707236 -0.29772767 -0.93991762]
 [ 0.17950365  0.94656926 -0.2679275 ]
 [ 0.96946651 -0.12395536  0.21158876]]
transform [[ 0.16707236 -0.29772767 -0.93991762]
 [ 0.17950365  0.94656926 -0.2679275 ]
 [ 0.96946651 -0.12395536  0.21158876]]
support
[-1.14494298 -0.32637084  0.25774286]
[-333.28575308 -519.08135785  454.10120705]
[ 219.5882339  -186.51403058   39.4197529 ]
[ 9.21119272  2.62568948 -2.0735698 ]
transform [[ 0.16707236  0.17950365  0.96946651]
 [-0.29772767  0.94656926 -0.12395536]
 [-0.93991762 -0.2679275   0.21158876]]
zmp [  646386.81926375 -8826460.39501238  2910760.3885207 ]
d1:10405107.37541, d2:0.05940, d3:4808364.29487
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-666.2289098640979 steps:10[00m
[RDDPG] Resetting Environment
transform [[ 6.56030774e-01  6.88337207e-01  3.09540927e-01]
 [-2.13232204e-01 -2.24383116e-01  9.50886011e-01]
 [ 7.23986030e-01 -6.89814568e-01 -4.26560553e-04]]
planes
[[ 6.56030774e-01  6.88337207e-01  3.09540927e-01]
 [-2.13232204e-01 -2.24383116e-01  9.50886011e-01]
 [ 7.23986030e-01 -6.89814568e-01 -4.26560553e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-929.039   -338.9482   436.27805]
[  72.11621627 -242.64126406  -21.45850553]
[ 0.   0.  -9.8]
transform [[ 6.56030774e-01  6.88337207e-01  3.09540927e-01]
 [-2.13232204e-01 -2.24383116e-01  9.50886011e-01]
 [ 7.23986030e-01 -6.89814568e-01 -4.26560553e-04]]
transform [[ 6.56030774e-01  6.88337207e-01  3.09540927e-01]
 [-2.13232204e-01 -2.24383116e-01  9.50886011e-01]
 [ 7.23986030e-01 -6.89814568e-01 -4.26560553e-04]]
transform [[ 6.56030774e-01  6.88337207e-01  3.09540927e-01]
 [-2.13232204e-01 -2.24383116e-01  9.50886011e-01]
 [ 7.23986030e-01 -6.89814568e-01 -4.26560553e-04]]
support
[ 3.77061461e-01  1.15830392e+00 -5.19606718e-04]
[-707.74292974  689.00598057 -438.98594298]
[-126.35083848   18.66251035  219.59776509]
[-3.03350109e+00 -9.31868291e+00  4.18029342e-03]
transform [[ 6.56030774e-01 -2.13232204e-01  7.23986030e-01]
 [ 6.88337207e-01 -2.24383116e-01 -6.89814568e-01]
 [ 3.09540927e-01  9.50886011e-01 -4.26560553e-04]]
zmp [-9778928.01216807  8292969.26179511  2283762.13025739]
d1:18582434.71015, d2:0.05940, d3:7240927.33104
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-252.96640468080423 steps:12[00m
[RDDPG] Resetting Environment
transform [[ 0.71417451 -0.69887102 -0.03916807]
 [ 0.00118477 -0.05474997  0.99849945]
 [-0.69996673 -0.71314919 -0.03827303]]
planes
[[ 0.71417451 -0.69887102 -0.03916807]
 [ 0.00118477 -0.05474997  0.99849945]
 [-0.69996673 -0.71314919 -0.03827303]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-929.039   -338.9482   436.27805]
[  72.11621627 -242.64126406  -21.45850553]
[ 0.   0.  -9.8]
transform [[ 0.71417451 -0.69887102 -0.03916807]
 [ 0.00118477 -0.05474997  0.99849945]
 [-0.69996673 -0.71314919 -0.03827303]]
transform [[ 0.71417451 -0.69887102 -0.03916807]
 [ 0.00118477 -0.05474997  0.99849945]
 [-0.69996673 -0.71314919 -0.03827303]]
transform [[ 0.71417451 -0.69887102 -0.03916807]
 [ 0.00118477 -0.05474997  0.99849945]
 [-0.69996673 -0.71314919 -0.03827303]]
support
[-0.04771185  1.21630334 -0.04662157]
[-443.70306262  453.08009587  875.31935096]
[221.91899856  -8.05626307 123.38175093]
[ 0.38384713 -9.78529464  0.37507568]
transform [[ 0.71417451  0.00118477 -0.69996673]
 [-0.69887102 -0.05474997 -0.71314919]
 [-0.03916807  0.99849945 -0.03827303]]
zmp [8572341.02502735 8675352.98594519 1511294.73418669]
d1:17088700.26765, d2:0.05940, d3:6447464.68996
transform [[ 0.67523342 -0.678303    0.28976697]
 [-0.2326078   0.176984    0.95633173]
 [-0.69996673 -0.71314919 -0.03827303]]
planes
[[ 0.67523342 -0.678303    0.28976697]
 [-0.2326078   0.176984    0.95633173]
 [-0.69996673 -0.71314919 -0.03827303]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-929.039   -338.9482   436.27805]
[  72.11621627 -242.64126406  -21.45850553]
[ 0.   0.  -9.8]
transform [[ 0.67523342 -0.678303    0.28976697]
 [-0.2326078   0.176984    0.95633173]
 [-0.69996673 -0.71314919 -0.03827303]]
transform [[ 0.67523342 -0.678303    0.28976697]
 [-0.2326078   0.176984    0.95633173]
 [-0.69996673 -0.71314919 -0.03827303]]
transform [[ 0.67523342 -0.678303    0.28976697]
 [-0.2326078   0.176984    0.95633173]
 [-0.69996673 -0.71314919 -0.03827303]]
support
[ 0.35297418  1.16493752 -0.04662157]
[-270.98962959  573.33984402  875.31935096]
[207.06161169 -80.2398647  123.38175093]
[-2.83971628 -9.37205095  0.37507568]
transform [[ 0.67523342 -0.2326078  -0.69996673]
 [-0.678303    0.176984   -0.71314919]
 [ 0.28976697  0.95633173 -0.03827303]]
zmp [8328211.75502299 8917330.4822853  1467263.66958935]
d1:17083888.68413, d2:0.05940, d3:6424282.44167
transform [[ 0.6702773   0.57775605 -0.46575356]
 [ 0.14276174  0.51549804  0.84491479]
 [ 0.72824961 -0.63281894  0.26304516]]
planes
[[ 0.6702773   0.57775605 -0.46575356]
 [ 0.14276174  0.51549804  0.84491479]
 [ 0.72824961 -0.63281894  0.26304516]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[785.5377  851.7209  196.18623]
[-607.78998366   38.99300856  178.64118672]
[ 0.   0.  -9.8]
transform [[ 0.6702773   0.57775605 -0.46575356]
 [ 0.14276174  0.51549804  0.84491479]
 [ 0.72824961 -0.63281894  0.26304516]]
transform [[ 0.6702773   0.57775605 -0.46575356]
 [ 0.14276174  0.51549804  0.84491479]
 [ 0.72824961 -0.63281894  0.26304516]]
transform [[ 0.6702773   0.57775605 -0.46575356]
 [ 0.14276174  0.51549804  0.84491479]
 [ 0.72824961 -0.63281894  0.26304516]]
support
[-0.56734894  1.02921707  0.32042352]
[927.24055669 716.96582978  84.68827108]
[-468.06214903   84.26824717 -420.30763259]
[ 4.56438484 -8.28016498 -2.57784259]
transform [[ 0.6702773   0.14276174  0.72824961]
 [ 0.57775605  0.51549804 -0.63281894]
 [-0.46575356  0.84491479  0.26304516]]
zmp [-4227034.03393005 37317618.43458917 40208378.00680801]
d1:88659942.81082, d2:0.05940, d3:38109698.03374
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-515.4790724166483 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-109.99062023437914 steps:17[00m
[RDDPG] Resetting Environment
transform [[ 0.05747396  0.00186681 -0.99834526]
 [ 0.99831903 -0.00759658  0.05745824]
 [-0.00747675 -0.99996942 -0.00230028]]
planes
[[ 0.05747396  0.00186681 -0.99834526]
 [ 0.99831903 -0.00759658  0.05745824]
 [-0.00747675 -0.99996942 -0.00230028]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[785.5377  851.7209  196.18623]
[-607.78998366   38.99300856  178.64118672]
[ 0.   0.  -9.8]
transform [[ 0.05747396  0.00186681 -0.99834526]
 [ 0.99831903 -0.00759658  0.05745824]
 [-0.00747675 -0.99996942 -0.00230028]]
transform [[ 0.05747396  0.00186681 -0.99834526]
 [ 0.99831903 -0.00759658  0.05745824]
 [-0.00747675 -0.99996942 -0.00230028]]
transform [[ 0.05747396  0.00186681 -0.99834526]
 [ 0.99831903 -0.00759658  0.05745824]
 [-0.00747675 -0.99996942 -0.00230028]]
support
[-1.2161155   0.06999168 -0.00280204]
[-149.12363019  789.01960193 -858.0193944 ]
[-213.20488431 -596.80011215  -34.8584484 ]
[ 9.78378351 -0.56309076  0.02254275]
transform [[ 0.05747396  0.99831903 -0.00747675]
 [ 0.00186681 -0.00759658 -0.99996942]
 [-0.99834526  0.05745824 -0.00230028]]
zmp [-9166472.11160895 -7316752.03564194  -541388.27843521]
d1:8477149.08696, d2:0.05940, d3:4803079.38708
transform [[ 0.72045541 -0.69317812 -0.02116903]
 [-0.00876549 -0.03962436  0.9991762 ]
 [-0.69344586 -0.71967632 -0.03462363]]
planes
[[ 0.72045541 -0.69317812 -0.02116903]
 [-0.00876549 -0.03962436  0.9991762 ]
 [-0.69344586 -0.71967632 -0.03462363]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-588.60645    34.535515  452.4197  ]
[ -82.25611652 -106.58882122   41.73895954]
[ 0.   0.  -9.8]
transform [[ 0.72045541 -0.69317812 -0.02116903]
 [-0.00876549 -0.03962436  0.9991762 ]
 [-0.69344586 -0.71967632 -0.03462363]]
transform [[ 0.72045541 -0.69317812 -0.02116903]
 [-0.00876549 -0.03962436  0.9991762 ]
 [-0.69344586 -0.71967632 -0.03462363]]
transform [[ 0.72045541 -0.69317812 -0.02116903]
 [-0.00876549 -0.03962436  0.9991762 ]
 [-0.69344586 -0.71967632 -0.03462363]]
support
[-0.02578665  1.21712771 -0.04217612]
[-457.58124508  455.8379858   367.64790033]
[ 13.73960125  46.64910406 132.30445957]
[ 0.20745647 -9.7919268   0.33931154]
transform [[ 0.72045541 -0.00876549 -0.69344586]
 [-0.69317812 -0.03962436 -0.71967632]
 [-0.02116903  0.9991762  -0.03462363]]
zmp [  5579514.17388814   6155286.12790614 -11664139.08410665]
d1:25819497.43450, d2:0.05940, d3:11160325.82555
transform [[-0.71158504 -0.67108595  0.20806351]
 [-0.25128111 -0.03346714 -0.96733546]
 [ 0.65612841 -0.74062389 -0.14481647]]
planes
[[-0.71158504 -0.67108595  0.20806351]
 [-0.25128111 -0.03346714 -0.96733546]
 [ 0.65612841 -0.74062389 -0.14481647]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-568.7645   194.23872 1666.9984 ]
[-214.70685236   10.73822199    7.08989327]
[ 0.   0.  -9.8]
transform [[-0.71158504 -0.67108595  0.20806351]
 [-0.25128111 -0.03346714 -0.96733546]
 [ 0.65612841 -0.74062389 -0.14481647]]
transform [[-0.71158504 -0.67108595  0.20806351]
 [-0.25128111 -0.03346714 -0.96733546]
 [ 0.65612841 -0.74062389 -0.14481647]]
transform [[-0.71158504 -0.67108595  0.20806351]
 [-0.25128111 -0.03346714 -0.96733546]
 [ 0.65612841 -0.74062389 -0.14481647]]
support
[ 0.25344866 -1.17834151 -0.17640546]
[  621.21499789 -1476.12751342  -758.4492327 ]
[ 147.05106333   46.7340939  -149.854982  ]
[-2.03902243  9.47988753  1.41920144]
transform [[-0.71158504 -0.25128111  0.65612841]
 [-0.67108595 -0.03346714 -0.74062389]
 [ 0.20806351 -0.96733546 -0.14481647]]
zmp [15034698.16796881 -9522826.04353743 20704413.93184612]
d1:47190323.58013, d2:0.05940, d3:20920818.05169
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-371.49127243711723 steps:21[00m
[RDDPG] Resetting Environment
transform [[ 0.28619093  0.27794239  0.91697484]
 [-0.66002953 -0.63655758  0.39894307]
 [ 0.69459045 -0.71940434  0.00127319]]
planes
[[ 0.28619093  0.27794239  0.91697484]
 [-0.66002953 -0.63655758  0.39894307]
 [ 0.69459045 -0.71940434  0.00127319]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-895.25635 -335.9102   116.09586]
[  28.42420044 -153.45156691  -27.249552  ]
[ 0.   0.  -9.8]
transform [[ 0.28619093  0.27794239  0.91697484]
 [-0.66002953 -0.63655758  0.39894307]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.28619093  0.27794239  0.91697484]
 [-0.66002953 -0.63655758  0.39894307]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.28619093  0.27794239  0.91697484]
 [-0.66002953 -0.63655758  0.39894307]
 [ 0.69459045 -0.71940434  0.00127319]]
support
[1.11699567 0.485965   0.00155091]
[-243.12093794  851.03744185 -380.03345105]
[-59.50310052  68.04892642 130.1022076 ]
[-8.98635346 -3.90964205 -0.01247722]
transform [[ 0.28619093 -0.66002953  0.69459045]
 [ 0.27794239 -0.63655758 -0.71940434]
 [ 0.91697484  0.39894307  0.00127319]]
zmp [3381678.9094463  -443159.63812693 -921108.00583736]
d1:4589943.82695, d2:0.05940, d3:1806680.67788
transform [[ 0.71929234  0.69451147  0.0165041 ]
 [-0.01275736 -0.0105478   0.99986303]
 [ 0.69459045 -0.71940434  0.00127319]]
planes
[[ 0.71929234  0.69451147  0.0165041 ]
 [-0.01275736 -0.0105478   0.99986303]
 [ 0.69459045 -0.71940434  0.00127319]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-895.25635 -335.9102   116.09586]
[  28.42420044 -153.45156691  -27.249552  ]
[ 0.   0.  -9.8]
transform [[ 0.71929234  0.69451147  0.0165041 ]
 [-0.01275736 -0.0105478   0.99986303]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.71929234  0.69451147  0.0165041 ]
 [-0.01275736 -0.0105478   0.99986303]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.71929234  0.69451147  0.0165041 ]
 [-0.01275736 -0.0105478   0.99986303]
 [ 0.69459045 -0.71940434  0.00127319]]
support
[0.02010416 1.21796435 0.00155091]
[-875.32845678  131.04418292 -380.03345105]
[-86.57829334 -25.98986153 130.1022076 ]
[-0.16174016 -9.79865768 -0.01247722]
transform [[ 0.71929234 -0.01275736  0.69459045]
 [ 0.69451147 -0.0105478  -0.71940434]
 [ 0.0165041   0.99986303  0.00127319]]
zmp [ 1881704.26406278 -1893864.03961288 -2313671.73770224]
d1:5879188.52109, d2:0.05940, d3:2661111.33656
transform [[ 0.71527731  0.69079304  0.10575143]
 [-0.07695755 -0.07254324  0.9943918 ]
 [ 0.69459045 -0.71940434  0.00127319]]
planes
[[ 0.71527731  0.69079304  0.10575143]
 [-0.07695755 -0.07254324  0.9943918 ]
 [ 0.69459045 -0.71940434  0.00127319]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-895.25635 -335.9102   116.09586]
[  28.42420044 -153.45156691  -27.249552  ]
[ 0.   0.  -9.8]
transform [[ 0.71527731  0.69079304  0.10575143]
 [-0.07695755 -0.07254324  0.9943918 ]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.71527731  0.69079304  0.10575143]
 [-0.07695755 -0.07254324  0.9943918 ]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.71527731  0.69079304  0.10575143]
 [-0.07695755 -0.07254324  0.9943918 ]
 [ 0.69459045 -0.71940434  0.00127319]]
support
[0.12881912 1.21129968 0.00155091]
[-860.12367022  208.70951978 -380.03345105]
[-88.55376741 -18.15231374 130.1022076 ]
[-1.03636404 -9.74503963 -0.01247722]
transform [[ 0.71527731 -0.07695755  0.69459045]
 [ 0.69079304 -0.07254324 -0.71940434]
 [ 0.10575143  0.9943918   0.00127319]]
zmp [ 2030480.71120476 -1750196.74045717 -2300992.77457382]
d1:5878574.19089, d2:0.05940, d3:2655888.15777
transform [[ 0.7193799   0.6945498  -0.00965311]
 [ 0.0060602   0.00762086  0.99995267]
 [ 0.69459045 -0.71940434  0.00127319]]
planes
[[ 0.7193799   0.6945498  -0.00965311]
 [ 0.0060602   0.00762086  0.99995267]
 [ 0.69459045 -0.71940434  0.00127319]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-895.25635 -335.9102   116.09586]
[  28.42420044 -153.45156691  -27.249552  ]
[ 0.   0.  -9.8]
transform [[ 0.7193799   0.6945498  -0.00965311]
 [ 0.0060602   0.00762086  0.99995267]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.7193799   0.6945498  -0.00965311]
 [ 0.0060602   0.00762086  0.99995267]
 [ 0.69459045 -0.71940434  0.00127319]]
transform [[ 0.7193799   0.6945498  -0.00965311]
 [ 0.0060602   0.00762086  0.99995267]
 [ 0.69459045 -0.71940434  0.00127319]]
support
[-0.01175876  1.21807355  0.00155091]
[-878.4564627   108.10501034 -380.03345105]
[-85.86891342 -28.24543957 130.1022076 ]
[ 0.09460051 -9.7995362  -0.01247722]
transform [[ 0.7193799   0.0060602   0.69459045]
 [ 0.6945498   0.00762086 -0.71940434]
 [-0.00965311  0.99995267  0.00127319]]
zmp [ 1838096.75545702 -1935967.81652491 -2313879.48495246]
d1:5875734.51568, d2:0.05940, d3:2660418.06816
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-881.801761110959 steps:26[00m
[RDDPG] Resetting Environment
transform [[ 0.33906394  0.34397525 -0.87562364]
 [ 0.64683062  0.59061104  0.48248184]
 [ 0.68311483 -0.72997236 -0.02223885]]
planes
[[ 0.33906394  0.34397525 -0.87562364]
 [ 0.64683062  0.59061104  0.48248184]
 [ 0.68311483 -0.72997236 -0.02223885]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-234.02774    16.044788  973.9868  ]
[ 565.02101927 -667.02370396  -41.11697301]
[ 0.   0.  -9.8]
transform [[ 0.33906394  0.34397525 -0.87562364]
 [ 0.64683062  0.59061104  0.48248184]
 [ 0.68311483 -0.72997236 -0.02223885]]
transform [[ 0.33906394  0.34397525 -0.87562364]
 [ 0.64683062  0.59061104  0.48248184]
 [ 0.68311483 -0.72997236 -0.02223885]]
transform [[ 0.33906394  0.34397525 -0.87562364]
 [ 0.64683062  0.59061104  0.48248184]
 [ 0.68311483 -0.72997236 -0.02223885]]
support
[-1.06662448  0.58772618 -0.02708984]
[-926.67724311  328.03086972 -193.24042055]
[ -1.85839456 -48.31686129 873.79749898]
[ 8.58111171 -4.72832201  0.21794075]
transform [[ 0.33906394  0.64683062  0.68311483]
 [ 0.34397525  0.59061104 -0.72997236]
 [-0.87562364  0.48248184 -0.02223885]]
zmp [-11009942.83106995   5533063.2609464   -2089753.07921375]
d1:16361296.78986, d2:0.05940, d3:6649502.71748
transform [[ 0.95459253 -0.1897727   0.22965062]
 [-0.29693046 -0.66867477  0.68169385]
 [ 0.02419467 -0.71893013 -0.6946612 ]]
planes
[[ 0.95459253 -0.1897727   0.22965062]
 [-0.29693046 -0.66867477  0.68169385]
 [ 0.02419467 -0.71893013 -0.6946612 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-234.02774    16.044788  973.9868  ]
[ 565.02101927 -667.02370396  -41.11697301]
[ 0.   0.  -9.8]
transform [[ 0.95459253 -0.1897727   0.22965062]
 [-0.29693046 -0.66867477  0.68169385]
 [ 0.02419467 -0.71893013 -0.6946612 ]]
transform [[ 0.95459253 -0.1897727   0.22965062]
 [-0.29693046 -0.66867477  0.68169385]
 [ 0.02419467 -0.71893013 -0.6946612 ]]
transform [[ 0.95459253 -0.1897727   0.22965062]
 [-0.29693046 -0.66867477  0.68169385]
 [ 0.02419467 -0.71893013 -0.6946612 ]]
support
[ 0.27974458  0.83039255 -0.84618848]
[  -2.76932167  722.72204463 -693.78815526]
[656.50518993 250.22077977 521.77629526]
[-2.25057604 -6.68059975  6.80767976]
transform [[ 0.95459253 -0.29693046  0.02419467]
 [-0.1897727  -0.66867477 -0.71893013]
 [ 0.22965062  0.68169385 -0.6946612 ]]
zmp [ -8473029.19945306 -12909129.63855188  24552474.48836993]
d1:55584761.86116, d2:0.05940, d3:15407666.36589
transform [[ 0.1542611   0.31574523  0.93622035]
 [-0.60631752 -0.71791321  0.34202299]
 [ 0.78011703 -0.62040758  0.08069585]]
planes
[[ 0.1542611   0.31574523  0.93622035]
 [-0.60631752 -0.71791321  0.34202299]
 [ 0.78011703 -0.62040758  0.08069585]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-355.67004  377.8243   960.81494]
[271.91475645 307.68696853 103.56542541]
[ 0.   0.  -9.8]
transform [[ 0.1542611   0.31574523  0.93622035]
 [-0.60631752 -0.71791321  0.34202299]
 [ 0.78011703 -0.62040758  0.08069585]]
transform [[ 0.1542611   0.31574523  0.93622035]
 [-0.60631752 -0.71791321  0.34202299]
 [ 0.78011703 -0.62040758  0.08069585]]
transform [[ 0.1542611   0.31574523  0.93622035]
 [-0.60631752 -0.71791321  0.34202299]
 [ 0.78011703 -0.62040758  0.08069585]]
support
[1.14043922 0.41662887 0.09829814]
[ 963.96467289  273.02470996 -434.33554569]
[ 236.05662134 -350.33746423   29.5913059 ]
[-9.17495941 -3.35182526 -0.79081936]
transform [[ 0.1542611  -0.60631752  0.78011703]
 [ 0.31574523 -0.71791321 -0.62040758]
 [ 0.93622035  0.34202299  0.08069585]]
zmp [ 5578251.65817731 20138516.2727385  -7710950.04996934]
d1:31342374.02499, d2:0.05940, d3:14338633.36557
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-455.9911797068355 steps:30[00m
[RDDPG] Resetting Environment
transform [[ 0.96870166 -0.14558209 -0.20105469]
 [ 0.18388802 -0.12319624  0.9751963 ]
 [-0.16674031 -0.98164588 -0.09256962]]
planes
[[ 0.96870166 -0.14558209 -0.20105469]
 [ 0.18388802 -0.12319624  0.9751963 ]
 [-0.16674031 -0.98164588 -0.09256962]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 456.209   288.3451 1346.8629]
[-1130.90695498  9818.7505221   -740.30373513]
[ 0.   0.  -9.8]
transform [[ 0.96870166 -0.14558209 -0.20105469]
 [ 0.18388802 -0.12319624  0.9751963 ]
 [-0.16674031 -0.98164588 -0.09256962]]
transform [[ 0.96870166 -0.14558209 -0.20105469]
 [ 0.18388802 -0.12319624  0.9751963 ]
 [-0.16674031 -0.98164588 -0.09256962]]
transform [[ 0.96870166 -0.14558209 -0.20105469]
 [ 0.18388802 -0.12319624  0.9751963 ]
 [-0.16674031 -0.98164588 -0.09256962]]
support
[-0.24491099  1.18791704 -0.11276194]
[ 129.15943878 1361.82407309 -483.79979442]
[-2376.10417487 -2139.5348909  -9381.43860282]
[ 1.97033598 -9.55692376  0.90718227]
transform [[ 0.96870166  0.18388802 -0.16674031]
 [-0.14558209 -0.12319624 -0.98164588]
 [-0.20105469  0.9751963  -0.09256962]]
zmp [ -3886664.05700325  -9900990.13585624 -11557109.16615243]
d1:25603438.09592, d2:0.05940, d3:8029712.45877
transform [[ 0.84729654 -0.4733049  -0.2409796 ]
 [ 0.27090582 -0.00512885  0.96259224]
 [-0.45683554 -0.88088375  0.12387539]]
planes
[[ 0.84729654 -0.4733049  -0.2409796 ]
 [ 0.27090582 -0.00512885  0.96259224]
 [-0.45683554 -0.88088375  0.12387539]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[170.80925 413.01624 201.44641]
[ -96.1418043  -339.54060945  -19.66109218]
[ 0.   0.  -9.8]
transform [[ 0.84729654 -0.4733049  -0.2409796 ]
 [ 0.27090582 -0.00512885  0.96259224]
 [-0.45683554 -0.88088375  0.12387539]]
transform [[ 0.84729654 -0.4733049  -0.2409796 ]
 [ 0.27090582 -0.00512885  0.96259224]
 [-0.45683554 -0.88088375  0.12387539]]
transform [[ 0.84729654 -0.4733049  -0.2409796 ]
 [ 0.27090582 -0.00512885  0.96259224]
 [-0.45683554 -0.88088375  0.12387539]]
support
[-0.29354477  1.17256365  0.15089647]
[ -99.30099619  238.06567354 -416.89677502]
[ 83.98353769 -43.22953538 340.58127395]
[ 2.36160005 -9.43340399 -1.21397879]
transform [[ 0.84729654  0.27090582 -0.45683554]
 [-0.4733049  -0.00512885 -0.88088375]
 [-0.2409796   0.96259224  0.12387539]]
zmp [ 7709685.7301836   2088215.2409149  23006212.54454317]
d1:46572093.65708, d2:0.05940, d3:17792839.77699
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-247.4812337402234 steps:33[00m
[RDDPG] Resetting Environment
transform [[ 0.74264866  0.63653481 -0.20807794]
 [ 0.15946776  0.13368404  0.97810972]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
planes
[[ 0.74264866  0.63653481 -0.20807794]
 [ 0.15946776  0.13368404  0.97810972]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[626.25525 621.03766 634.8323 ]
[  33.938561   -184.40562692  -24.5082367 ]
[ 0.   0.  -9.8]
transform [[ 0.74264866  0.63653481 -0.20807794]
 [ 0.15946776  0.13368404  0.97810972]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
transform [[ 0.74264866  0.63653481 -0.20807794]
 [ 0.15946776  0.13368404  0.97810972]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
transform [[ 0.74264866  0.63653481 -0.20807794]
 [ 0.15946776  0.13368404  0.97810972]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
support
[-0.25346623  1.19146596 -0.00271217]
[728.3051199  803.82595983 -65.80983409]
[-87.07655048 -43.21172732 162.19844576]
[ 2.03916379 -9.58547523  0.02181967]
transform [[ 0.74264866  0.15946776  0.65041757]
 [ 0.63653481  0.13368404 -0.75957358]
 [-0.20807794  0.97810972 -0.0022265 ]]
zmp [ -1819845.42776147  -3380807.90059598 -16837477.27620908]
d1:33901213.38042, d2:0.05940, d3:11353091.95646
transform [[ 0.17703028  0.14873797  0.97290152]
 [-0.73865914 -0.6331864   0.23120929]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
planes
[[ 0.17703028  0.14873797  0.97290152]
 [-0.73865914 -0.6331864   0.23120929]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[626.25525 621.03766 634.8323 ]
[  33.938561   -184.40562692  -24.5082367 ]
[ 0.   0.  -9.8]
transform [[ 0.17703028  0.14873797  0.97290152]
 [-0.73865914 -0.6331864   0.23120929]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
transform [[ 0.17703028  0.14873797  0.97290152]
 [-0.73865914 -0.6331864   0.23120929]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
transform [[ 0.17703028  0.14873797  0.97290152]
 [-0.73865914 -0.6331864   0.23120929]
 [ 0.65041757 -0.75957358 -0.0022265 ]]
support
[ 1.1851217   0.28164325 -0.00271217]
[ 820.86730867 -709.04264358  -65.80983409]
[-45.2640659   86.02757456 162.19844576]
[-9.53443493 -2.26585107  0.02181967]
transform [[ 0.17703028 -0.73865914  0.65041757]
 [ 0.14873797 -0.6331864  -0.75957358]
 [ 0.97290152  0.23120929 -0.0022265 ]]
zmp [13637876.88255643  9817850.2812336  -3982524.24257425]
d1:25232060.75646, d2:0.05940, d3:3004330.60611
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-361.8865914723949 steps:36[00m
[RDDPG] Resetting Environment
transform [[ 0.07171129  0.00564803 -0.99740946]
 [ 0.9964906  -0.04369092  0.07139782]
 [-0.04317448 -0.99902916 -0.00876134]]
planes
[[ 0.07171129  0.00564803 -0.99740946]
 [ 0.9964906  -0.04369092  0.07139782]
 [-0.04317448 -0.99902916 -0.00876134]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[626.25525 621.03766 634.8323 ]
[  33.938561   -184.40562692  -24.5082367 ]
[ 0.   0.  -9.8]
transform [[ 0.07171129  0.00564803 -0.99740946]
 [ 0.9964906  -0.04369092  0.07139782]
 [-0.04317448 -0.99902916 -0.00876134]]
transform [[ 0.07171129  0.00564803 -0.99740946]
 [ 0.9964906  -0.04369092  0.07139782]
 [-0.04317448 -0.99902916 -0.00876134]]
transform [[ 0.07171129  0.00564803 -0.99740946]
 [ 0.9964906  -0.04369092  0.07139782]
 [-0.04317448 -0.99902916 -0.00876134]]
support
[-1.21497559  0.08697191 -0.01067246]
[-584.77051231  642.24940281 -653.034951  ]
[ 25.83699735  40.12647309 182.97604381]
[ 9.77461274 -0.69969862  0.08586109]
transform [[ 0.07171129  0.9964906  -0.04317448]
 [ 0.00564803 -0.04369092 -0.99902916]
 [-0.99740946  0.07139782 -0.00876134]]
zmp [-21050738.96953748   6476606.31754167  -1476821.3932482 ]
d1:17739107.68679, d2:0.05940, d3:10349871.17297
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-277.0822738997921 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-181.06819494140314 steps:39[00m
[RDDPG] Resetting Environment
transform [[ 0.73173702  0.63245869 -0.25408074]
 [ 0.19996239  0.15717304  0.96711516]
 [ 0.651595   -0.75848049 -0.01145863]]
planes
[[ 0.73173702  0.63245869 -0.25408074]
 [ 0.19996239  0.15717304  0.96711516]
 [ 0.651595   -0.75848049 -0.01145863]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 428.98218  287.0825  -507.06387]
[ 103.67516822 -336.49174478  -67.24863001]
[ 0.   0.  -9.8]
transform [[ 0.73173702  0.63245869 -0.25408074]
 [ 0.19996239  0.15717304  0.96711516]
 [ 0.651595   -0.75848049 -0.01145863]]
transform [[ 0.73173702  0.63245869 -0.25408074]
 [ 0.19996239  0.15717304  0.96711516]
 [ 0.651595   -0.75848049 -0.01145863]]
transform [[ 0.73173702  0.63245869 -0.25408074]
 [ 0.19996239  0.15717304  0.96711516]
 [ 0.651595   -0.75848049 -0.01145863]]
support
[-0.30950368  1.17807316 -0.01395811]
[ 624.30511884 -359.48723148   67.58643009]
[-119.86758678  -97.19346479  323.5472211 ]
[ 2.48999128 -9.47772861  0.11229455]
transform [[ 0.73173702  0.19996239  0.651595  ]
 [ 0.63245869  0.15717304 -0.75848049]
 [-0.25408074  0.96711516 -0.01145863]]
zmp [ -8670812.47999435   5115960.60181819 -12236742.23011511]
d1:28115495.73252, d2:0.05940, d3:11821045.04687
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-219.73343057969063 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-191.35738415039782 steps:42[00m
[RDDPG] Resetting Environment
transform [[ 0.11548159 -0.32272872  0.93942016]
 [-0.93260264  0.2903308   0.21438386]
 [-0.34193039 -0.90086305 -0.2674498 ]]
planes
[[ 0.11548159 -0.32272872  0.93942016]
 [-0.93260264  0.2903308   0.21438386]
 [-0.34193039 -0.90086305 -0.2674498 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 428.98218  287.0825  -507.06387]
[ 103.67516822 -336.49174478  -67.24863001]
[ 0.   0.  -9.8]
transform [[ 0.11548159 -0.32272872  0.93942016]
 [-0.93260264  0.2903308   0.21438386]
 [-0.34193039 -0.90086305 -0.2674498 ]]
transform [[ 0.11548159 -0.32272872  0.93942016]
 [-0.93260264  0.2903308   0.21438386]
 [-0.34193039 -0.90086305 -0.2674498 ]]
transform [[ 0.11548159 -0.32272872  0.93942016]
 [-0.93260264  0.2903308   0.21438386]
 [-0.34193039 -0.90086305 -0.2674498 ]]
support
[ 1.14433701  0.26114766 -0.32578894]
[-519.45624685 -425.42733333 -269.68992057]
[  57.39340573 -208.79867316  285.66892173]
[-9.2063176  -2.10096178  2.621008  ]
transform [[ 0.11548159 -0.93260264 -0.34193039]
 [-0.32272872  0.2903308  -0.90086305]
 [ 0.93942016  0.21438386 -0.2674498 ]]
zmp [14905352.15295452 -2531089.19438742 -2701824.92390813]
d1:12838569.12127, d2:0.05940, d3:7673170.04225
transform [[ 0.60250783 -0.76994157 -0.21017712]
 [ 0.08187436 -0.2023267   0.97588962]
 [-0.7939024  -0.6051892  -0.05886494]]
planes
[[ 0.60250783 -0.76994157 -0.21017712]
 [ 0.08187436 -0.2023267   0.97588962]
 [-0.7939024  -0.6051892  -0.05886494]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -17.183598 -137.92094   358.47397 ]
[ 29.12540233 -24.27397794  -8.64600562]
[ 0.   0.  -9.8]
transform [[ 0.60250783 -0.76994157 -0.21017712]
 [ 0.08187436 -0.2023267   0.97588962]
 [-0.7939024  -0.6051892  -0.05886494]]
transform [[ 0.60250783 -0.76994157 -0.21017712]
 [ 0.08187436 -0.2023267   0.97588962]
 [-0.7939024  -0.6051892  -0.05886494]]
transform [[ 0.60250783 -0.76994157 -0.21017712]
 [ 0.08187436 -0.2023267   0.97588962]
 [-0.7939024  -0.6051892  -0.05886494]]
support
[-0.25602331  1.1887616  -0.07170522]
[ 20.49478846 376.32921945  76.0088158 ]
[38.05502019 -1.14164954 -7.9234307 ]
[ 2.05973581 -9.56371831  0.57687645]
transform [[ 0.60250783  0.08187436 -0.7939024 ]
 [-0.76994157 -0.2023267  -0.6051892 ]
 [-0.21017712  0.97588962 -0.05886494]]
zmp [ 13653382.52091591  16929416.88829239 -22877809.23543748]
d1:52960095.07936, d2:0.05940, d3:24128297.39769
transform [[-0.88181436 -0.44520897 -0.15553936]
 [ 0.20260844 -0.05982373 -0.97743082]
 [ 0.4258559  -0.89342612  0.14295648]]
planes
[[-0.88181436 -0.44520897 -0.15553936]
 [ 0.20260844 -0.05982373 -0.97743082]
 [ 0.4258559  -0.89342612  0.14295648]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -90.08582  -481.7766    -86.919044]
[ 2462.29667044 -4726.79645756  -790.5477804 ]
[ 0.   0.  -9.8]
transform [[-0.88181436 -0.44520897 -0.15553936]
 [ 0.20260844 -0.05982373 -0.97743082]
 [ 0.4258559  -0.89342612  0.14295648]]
transform [[-0.88181436 -0.44520897 -0.15553936]
 [ 0.20260844 -0.05982373 -0.97743082]
 [ 0.4258559  -0.89342612  0.14295648]]
transform [[-0.88181436 -0.44520897 -0.15553936]
 [ 0.20260844 -0.05982373 -0.97743082]
 [ 0.4258559  -0.89342612  0.14295648]]
support
[-0.18946735 -1.19063898  0.17413975]
[307.44957265  95.52687871 379.64258833]
[  56.0849014 1554.3624346 5158.6130687]
[ 1.52428576  9.57882204 -1.40097351]
transform [[-0.88181436  0.20260844  0.4258559 ]
 [-0.44520897 -0.05982373 -0.89342612]
 [-0.15553936 -0.97743082  0.14295648]]
zmp [ 14849888.39725273 -15565524.24896252 -39635853.47083645]
d1:84521183.98252, d2:0.05940, d3:24117547.05817
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-137.3614701562725 steps:46[00m
[RDDPG] Resetting Environment
transform [[ 0.68379498  0.72405332  0.0903955 ]
 [-0.06089894 -0.06682231  0.99590468]
 [ 0.72712845 -0.68649966 -0.00159869]]
planes
[[ 0.68379498  0.72405332  0.0903955 ]
 [-0.06089894 -0.06682231  0.99590468]
 [ 0.72712845 -0.68649966 -0.00159869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-377.77286 -713.8664  -423.65823]
[ 103.88218094 -152.57921766  -12.70721757]
[ 0.   0.  -9.8]
transform [[ 0.68379498  0.72405332  0.0903955 ]
 [-0.06089894 -0.06682231  0.99590468]
 [ 0.72712845 -0.68649966 -0.00159869]]
transform [[ 0.68379498  0.72405332  0.0903955 ]
 [-0.06089894 -0.06682231  0.99590468]
 [ 0.72712845 -0.68649966 -0.00159869]]
transform [[ 0.68379498  0.72405332  0.0903955 ]
 [-0.06089894 -0.06682231  0.99590468]
 [ 0.72712845 -0.68649966 -0.00159869]]
support
[ 0.11011358  1.21314257 -0.00194742]
[-813.49331587 -351.2150503   216.05694206]
[-40.59005158  -8.78579572 180.30158408]
[-0.88587593 -9.7598659   0.0156672 ]
transform [[ 0.68379498 -0.06089894  0.72712845]
 [ 0.72405332 -0.06682231 -0.68649966]
 [ 0.0903955   0.99590468 -0.00159869]]
zmp [ 5076656.37775074 -3869070.45336935 -7411645.21906782]
d1:16278634.78789, d2:0.05940, d3:7547779.76775
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-456.89260934668243 steps:48[00m
[RDDPG] Resetting Environment
transform [[ 0.27282801  0.28375006 -0.91926646]
 [ 0.65398073  0.64610088  0.39352617]
 [ 0.70560199 -0.70854753 -0.00929261]]
planes
[[ 0.27282801  0.28375006 -0.91926646]
 [ 0.65398073  0.64610088  0.39352617]
 [ 0.70560199 -0.70854753 -0.00929261]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-251.26791 -706.5633   582.83545]
[ -65.22878582 -412.252953     11.98982616]
[ 0.   0.  -9.8]
transform [[ 0.27282801  0.28375006 -0.91926646]
 [ 0.65398073  0.64610088  0.39352617]
 [ 0.70560199 -0.70854753 -0.00929261]]
transform [[ 0.27282801  0.28375006 -0.91926646]
 [ 0.65398073  0.64610088  0.39352617]
 [ 0.70560199 -0.70854753 -0.00929261]]
transform [[ 0.27282801  0.28375006 -0.91926646]
 [ 0.65398073  0.64610088  0.39352617]
 [ 0.70560199 -0.70854753 -0.00929261]]
support
[-1.11978716  0.4793665  -0.01131961]
[-804.82138205 -391.47453883  317.9224783 ]
[-145.79488409 -304.29705396  245.96383482]
[ 9.00881133 -3.85655643  0.09106753]
transform [[ 0.27282801  0.65398073  0.70560199]
 [ 0.28375006  0.64610088 -0.70854753]
 [-0.91926646  0.39352617 -0.00929261]]
zmp [-7724118.690654   11219005.69003247  1170538.79272632]
d1:18312825.82406, d2:0.05940, d3:6797488.86616
transform [[ 0.27127358  0.28221428 -0.9201988 ]
 [ 0.65462703  0.64677322  0.39134115]
 [ 0.70560199 -0.70854753 -0.00929261]]
planes
[[ 0.27127358  0.28221428 -0.9201988 ]
 [ 0.65462703  0.64677322  0.39134115]
 [ 0.70560199 -0.70854753 -0.00929261]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-251.26791 -706.5633   582.83545]
[ -65.22878582 -412.252953     11.98982616]
[ 0.   0.  -9.8]
transform [[ 0.27127358  0.28221428 -0.9201988 ]
 [ 0.65462703  0.64677322  0.39134115]
 [ 0.70560199 -0.70854753 -0.00929261]]
transform [[ 0.27127358  0.28221428 -0.9201988 ]
 [ 0.65462703  0.64677322  0.39134115]
 [ 0.70560199 -0.70854753 -0.00929261]]
transform [[ 0.27127358  0.28221428 -0.9201988 ]
 [ 0.65462703  0.64677322  0.39134115]
 [ 0.70560199 -0.70854753 -0.00929261]]
support
[-1.12092287  0.47670486 -0.01131961]
[-803.88908115 -393.3854879   317.9224783 ]
[-145.07154202 -304.64258316  245.96383482]
[ 9.01794822 -3.83514327  0.09106753]
transform [[ 0.27127358  0.65462703  0.70560199]
 [ 0.28221428  0.64677322 -0.70854753]
 [-0.9201988   0.39134115 -0.00929261]]
zmp [-7722400.95694585 11220792.65278729  1164731.40559603]
d1:18312127.03405, d2:0.05940, d3:6793842.50632
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-493.51253830260913 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-166.57203258788482 steps:52[00m
[RDDPG] Resetting Environment
transform [[ 0.314583   -0.32683265  0.8911891 ]
 [-0.63623422  0.62414616  0.45348382]
 [-0.7044456  -0.70966333 -0.01159638]]
planes
[[ 0.314583   -0.32683265  0.8911891 ]
 [-0.63623422  0.62414616  0.45348382]
 [-0.7044456  -0.70966333 -0.01159638]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-251.26791 -706.5633   582.83545]
[ -65.22878582 -412.252953     11.98982616]
[ 0.   0.  -9.8]
transform [[ 0.314583   -0.32683265  0.8911891 ]
 [-0.63623422  0.62414616  0.45348382]
 [-0.7044456  -0.70966333 -0.01159638]]
transform [[ 0.314583   -0.32683265  0.8911891 ]
 [-0.63623422  0.62414616  0.45348382]
 [-0.7044456  -0.70966333 -0.01159638]]
transform [[ 0.314583   -0.32683265  0.8911891 ]
 [-0.63623422  0.62414616  0.45348382]
 [-0.7044456  -0.70966333 -0.01159638]]
support
[ 1.08558525  0.55240279 -0.01412592]
[671.29993853 -16.82707681 671.66785325]
[ 124.90306097 -210.36812091  338.37189662]
[-8.73365316 -4.44414144  0.11364457]
transform [[ 0.314583   -0.63623422 -0.7044456 ]
 [-0.32683265  0.62414616 -0.70966333]
 [ 0.8911891   0.45348382 -0.01159638]]
zmp [ 9586171.59840908 10251678.73828779   375831.80032359]
d1:19989920.04922, d2:0.05940, d3:6622032.10299
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-408.8064591205472 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-179.6734998730406 steps:55[00m
[RDDPG] Resetting Environment
transform [[ 0.37316     0.38174215  0.84559131]
 [-0.59699398 -0.59886765  0.53381258]
 [ 0.71017599 -0.70401031  0.00442428]]
planes
[[ 0.37316     0.38174215  0.84559131]
 [-0.59699398 -0.59886765  0.53381258]
 [ 0.71017599 -0.70401031  0.00442428]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 501.43298  295.1208  1212.5476 ]
[ -48.8265569  -379.29197148   29.97559037]
[ 0.   0.  -9.8]
transform [[ 0.37316     0.38174215  0.84559131]
 [-0.59699398 -0.59886765  0.53381258]
 [ 0.71017599 -0.70401031  0.00442428]]
transform [[ 0.37316     0.38174215  0.84559131]
 [-0.59699398 -0.59886765  0.53381258]
 [ 0.71017599 -0.70401031  0.00442428]]
transform [[ 0.37316     0.38174215  0.84559131]
 [-0.59699398 -0.59886765  0.53381258]
 [ 0.71017599 -0.70401031  0.00442428]]
support
[1.03004115 0.65025376 0.00538935]
[1325.0944944   171.18240131  153.70224002]
[-137.66475208  272.29620143  232.48262958]
[-8.28679481 -5.23136331 -0.04335795]
transform [[ 0.37316    -0.59699398  0.71017599]
 [ 0.38174215 -0.59886765 -0.70401031]
 [ 0.84559131  0.53381258  0.00442428]]
zmp [-16079410.99708662   2345040.14953897   6037186.14530235]
d1:22281723.35936, d2:0.05940, d3:9228855.18690
transform [[ 0.18066899  0.20957275  0.96095681]
 [-0.74384111 -0.61010116  0.27290469]
 [ 0.64347428 -0.7641046   0.04566246]]
planes
[[ 0.18066899  0.20957275  0.96095681]
 [-0.74384111 -0.61010116  0.27290469]
 [ 0.64347428 -0.7641046   0.04566246]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 501.43298  295.1208  1212.5476 ]
[ -48.8265569  -379.29197148   29.97559037]
[ 0.   0.  -9.8]
transform [[ 0.18066899  0.20957275  0.96095681]
 [-0.74384111 -0.61010116  0.27290469]
 [ 0.64347428 -0.7641046   0.04566246]]
transform [[ 0.18066899  0.20957275  0.96095681]
 [-0.74384111 -0.61010116  0.27290469]
 [ 0.64347428 -0.7641046   0.04566246]]
transform [[ 0.18066899  0.20957275  0.96095681]
 [-0.74384111 -0.61010116  0.27290469]
 [ 0.64347428 -0.7641046   0.04566246]]
support
[1.17057147 0.33243372 0.05562287]
[1317.64855063 -222.13007038  152.52398027]
[-59.50545771 275.90615275 259.76886752]
[-9.41737676 -2.674466   -0.4474921 ]
transform [[ 0.18066899 -0.74384111  0.64347428]
 [ 0.20957275 -0.61010116 -0.7641046 ]
 [ 0.96095681  0.27290469  0.04566246]]
zmp [18346961.83018073  2978559.67246518 -4098990.07691101]
d1:13207307.67319, d2:0.05940, d3:10326857.29137
transform [[-0.00627936 -0.87536228 -0.48342675]
 [-0.23588108 -0.46849751  0.85139316]
 [-0.9717617   0.11937721 -0.20353964]]
planes
[[-0.00627936 -0.87536228 -0.48342675]
 [-0.23588108 -0.46849751  0.85139316]
 [-0.9717617   0.11937721 -0.20353964]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[539.53406 513.48975 426.7173 ]
[ 97.61367298 515.57646576   8.62708815]
[ 0.   0.  -9.8]
transform [[-0.00627936 -0.87536228 -0.48342675]
 [-0.23588108 -0.46849751  0.85139316]
 [-0.9717617   0.11937721 -0.20353964]]
transform [[-0.00627936 -0.87536228 -0.48342675]
 [-0.23588108 -0.46849751  0.85139316]
 [-0.9717617   0.11937721 -0.20353964]]
transform [[-0.00627936 -0.87536228 -0.48342675]
 [-0.23588108 -0.46849751  0.85139316]
 [-0.9717617   0.11937721 -0.20353964]]
support
[-0.58887721  1.03710858 -0.24793799]
[-659.16403369   -4.53036433 -549.85344377]
[-456.09970591 -257.22646713  -35.06510315]
[ 4.73758215 -8.343653    1.99468847]
transform [[-0.00627936 -0.23588108 -0.9717617 ]
 [-0.87536228 -0.46849751  0.11937721]
 [-0.48342675  0.85139316 -0.20353964]]
zmp [ 24644674.43388001 -15352507.48551801  27479366.00997753]
d1:56401832.59892, d2:0.05940, d3:20612326.64235
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-137.82641214534874 steps:59[00m
[RDDPG] Resetting Environment
transform [[ 0.10280381  0.07788929 -0.99164748]
 [ 0.69803035  0.70458829  0.12770674]
 [ 0.70865017 -0.70532876  0.01806528]]
planes
[[ 0.10280381  0.07788929 -0.99164748]
 [ 0.69803035  0.70458829  0.12770674]
 [ 0.70865017 -0.70532876  0.01806528]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-541.90936  -809.2079    -56.496986]
[  -2.9753305  -290.54844441   20.83626934]
[ 0.   0.  -9.8]
transform [[ 0.10280381  0.07788929 -0.99164748]
 [ 0.69803035  0.70458829  0.12770674]
 [ 0.70865017 -0.70532876  0.01806528]]
transform [[ 0.10280381  0.07788929 -0.99164748]
 [ 0.69803035  0.70458829  0.12770674]
 [ 0.70865017 -0.70532876  0.01806528]]
transform [[ 0.10280381  0.07788929 -0.99164748]
 [ 0.69803035  0.70458829  0.12770674]
 [ 0.70865017 -0.70532876  0.01806528]]
support
[-1.20795674  0.15556356  0.02200588]
[ -62.71387809 -955.64263306  185.71279982]
[ -43.59872022 -204.13297183  203.20011931]
[ 9.71814532 -1.25152602 -0.17703974]
transform [[ 0.10280381  0.69803035  0.70865017]
 [ 0.07788929  0.70458829 -0.70532876]
 [-0.99164748  0.12770674  0.01806528]]
zmp [-1646027.43480282  3557365.95199457   108771.30510027]
d1:4992494.95331, d2:0.05940, d3:1724780.98296
transform [[ 0.70544785  0.70784837 -0.03597393]
 [ 0.01258596  0.03823704  0.99918944]
 [ 0.70865017 -0.70532876  0.01806528]]
planes
[[ 0.70544785  0.70784837 -0.03597393]
 [ 0.01258596  0.03823704  0.99918944]
 [ 0.70865017 -0.70532876  0.01806528]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-541.90936  -809.2079    -56.496986]
[  -2.9753305  -290.54844441   20.83626934]
[ 0.   0.  -9.8]
transform [[ 0.70544785  0.70784837 -0.03597393]
 [ 0.01258596  0.03823704  0.99918944]
 [ 0.70865017 -0.70532876  0.01806528]]
transform [[ 0.70544785  0.70784837 -0.03597393]
 [ 0.01258596  0.03823704  0.99918944]
 [ 0.70865017 -0.70532876  0.01806528]]
transform [[ 0.70544785  0.70784837 -0.03597393]
 [ 0.01258596  0.03823704  0.99918944]
 [ 0.70865017 -0.70532876  0.01806528]]
support
[-0.04382096  1.21714383  0.02200588]
[-953.05286091  -94.21335673  185.71279982]
[-208.51274571    9.67222062  203.20011931]
[ 0.35254447 -9.79205648 -0.17703974]
transform [[ 0.70544785  0.01258596  0.70865017]
 [ 0.70784837  0.03823704 -0.70532876]
 [-0.03597393  0.99918944  0.01806528]]
zmp [-2586040.47442544  2643535.95333572  1303891.41308464]
d1:5717235.70551, d2:0.05940, d3:2492678.44293
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-623.9842590484349 steps:62[00m
[RDDPG] Resetting Environment
transform [[ 0.70178634  0.69884294 -0.13825512]
 [ 0.09250167  0.10303733  0.99036705]
 [ 0.70635641 -0.70781493  0.00766606]]
planes
[[ 0.70178634  0.69884294 -0.13825512]
 [ 0.09250167  0.10303733  0.99036705]
 [ 0.70635641 -0.70781493  0.00766606]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 352.38132  228.86664 1105.8229 ]
[ -31.93432037 -318.10814661   -9.17702712]
[ 0.   0.  -9.8]
transform [[ 0.70178634  0.69884294 -0.13825512]
 [ 0.09250167  0.10303733  0.99036705]
 [ 0.70635641 -0.70781493  0.00766606]]
transform [[ 0.70178634  0.69884294 -0.13825512]
 [ 0.09250167  0.10303733  0.99036705]
 [ 0.70635641 -0.70781493  0.00766606]]
transform [[ 0.70178634  0.69884294 -0.13825512]
 [ 0.09250167  0.10303733  0.99036705]
 [ 0.70635641 -0.70781493  0.00766606]]
support
[-0.16841287  1.20639701  0.00933827]
[ 254.35255583 1151.34821208   95.38888371]
[-243.44993209  -44.81961658  202.53433269]
[ 1.35490017 -9.70559714 -0.07512741]
transform [[ 0.70178634  0.09250167  0.70635641]
 [ 0.69884294  0.10303733 -0.70781493]
 [-0.13825512  0.99036705  0.00766606]]
zmp [-7342998.6243052   5808232.3813421  -7914169.95241581]
d1:19337326.95226, d2:0.05940, d3:9242542.33639
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-302.46230536219866 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-262.03480993164266 steps:65[00m
[RDDPG] Resetting Environment
transform [[ 0.70824206  0.70383644  0.05484107]
 [-0.02341658 -0.0542182   0.99825454]
 [ 0.70558119 -0.70829004 -0.02191817]]
planes
[[ 0.70824206  0.70383644  0.05484107]
 [-0.02341658 -0.0542182   0.99825454]
 [ 0.70558119 -0.70829004 -0.02191817]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-682.8252   411.2647  -301.03696]
[   3.70041189 -187.53963325   -1.83221285]
[ 0.   0.  -9.8]
transform [[ 0.70824206  0.70383644  0.05484107]
 [-0.02341658 -0.0542182   0.99825454]
 [ 0.70558119 -0.70829004 -0.02191817]]
transform [[ 0.70824206  0.70383644  0.05484107]
 [-0.02341658 -0.0542182   0.99825454]
 [ 0.70558119 -0.70829004 -0.02191817]]
transform [[ 0.70824206  0.70383644  0.05484107]
 [-0.02341658 -0.0542182   0.99825454]
 [ 0.70558119 -0.70829004 -0.02191817]]
support
[ 0.06680362  1.216005   -0.02669921]
[-210.65162077 -306.82011104 -766.48513057]
[-129.4769212     8.25239472  135.4835542 ]
[-0.53744246 -9.78289447  0.21479809]
transform [[ 0.70824206 -0.02341658  0.70558119]
 [ 0.70383644 -0.0542182  -0.70829004]
 [ 0.05484107  0.99825454 -0.02191817]]
zmp [-19979463.25656426  20609856.95342936  -6485464.17954444]
d1:42238575.39212, d2:0.05940, d3:17038462.98166
transform [[ 0.14509083  0.25447261 -0.95613408]
 [ 0.92301601  0.3132396   0.22343317]
 [ 0.35635671 -0.91494519 -0.18943414]]
planes
[[ 0.14509083  0.25447261 -0.95613408]
 [ 0.92301601  0.3132396   0.22343317]
 [ 0.35635671 -0.91494519 -0.18943414]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-682.8252   411.2647  -301.03696]
[   3.70041189 -187.53963325   -1.83221285]
[ 0.   0.  -9.8]
transform [[ 0.14509083  0.25447261 -0.95613408]
 [ 0.92301601  0.3132396   0.22343317]
 [ 0.35635671 -0.91494519 -0.18943414]]
transform [[ 0.14509083  0.25447261 -0.95613408]
 [ 0.92301601  0.3132396   0.22343317]
 [ 0.35635671 -0.91494519 -0.18943414]]
transform [[ 0.14509083  0.25447261 -0.95613408]
 [ 0.92301601  0.3132396   0.22343317]
 [ 0.35635671 -0.91494519 -0.18943414]]
support
[-1.16469676  0.27217091 -0.23075564]
[ 293.41562279 -568.69583421 -562.58732871]
[-45.43496359 -55.7386782  173.25423474]
[ 9.37011399 -2.18964503  1.85645458]
transform [[ 0.14509083  0.92301601  0.35635671]
 [ 0.25447261  0.3132396  -0.91494519]
 [-0.95613408  0.22343317 -0.18943414]]
zmp [ 18445359.9195162  -17602845.40329757  -1885917.7933532 ]
d1:19435005.22486, d2:0.05940, d3:9352316.26613
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-136.77589791793278 steps:68[00m
[RDDPG] Resetting Environment
transform [[ 0.25862414  0.20884387 -0.94313192]
 [ 0.58073378  0.74659359  0.32457098]
 [ 0.77192092 -0.63165051  0.07180442]]
planes
[[ 0.25862414  0.20884387 -0.94313192]
 [ 0.58073378  0.74659359  0.32457098]
 [ 0.77192092 -0.63165051  0.07180442]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-353.36108 -697.4292   719.3314 ]
[   3.98663443 -379.45593989   -0.51128721]
[ 0.   0.  -9.8]
transform [[ 0.25862414  0.20884387 -0.94313192]
 [ 0.58073378  0.74659359  0.32457098]
 [ 0.77192092 -0.63165051  0.07180442]]
transform [[ 0.25862414  0.20884387 -0.94313192]
 [ 0.58073378  0.74659359  0.32457098]
 [ 0.77192092 -0.63165051  0.07180442]]
transform [[ 0.25862414  0.20884387 -0.94313192]
 [ 0.58073378  0.74659359  0.32457098]
 [ 0.77192092 -0.63165051  0.07180442]]
support
[-1.14885842  0.39537004  0.0874672 ]
[-915.46594633 -492.43078257  219.41586962]
[ -77.73379654 -281.15014986  242.72419082]
[ 9.24269285 -3.18079564 -0.70368331]
transform [[ 0.25862414  0.58073378  0.77192092]
 [ 0.20884387  0.74659359 -0.63165051]
 [-0.94313192  0.32457098  0.07180442]]
zmp [ 2613934.17383748 11169142.17279627  3190044.97078426]
d1:15796216.93771, d2:0.05940, d3:5173616.19202
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-352.6941768615467 steps:70[00m
[RDDPG] Resetting Environment
transform [[ 0.70581198  0.70740932 -0.0374379 ]
 [ 0.03524651  0.01771442  0.99922168]
 [ 0.70752186 -0.70658213 -0.01243066]]
planes
[[ 0.70581198  0.70740932 -0.0374379 ]
 [ 0.03524651  0.01771442  0.99922168]
 [ 0.70752186 -0.70658213 -0.01243066]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[231.3088   93.22566 426.08475]
[  39.16495953 -317.79650211  -43.56945255]
[ 0.   0.  -9.8]
transform [[ 0.70581198  0.70740932 -0.0374379 ]
 [ 0.03524651  0.01771442  0.99922168]
 [ 0.70752186 -0.70658213 -0.01243066]]
transform [[ 0.70581198  0.70740932 -0.0374379 ]
 [ 0.03524651  0.01771442  0.99922168]
 [ 0.70752186 -0.70658213 -0.01243066]]
transform [[ 0.70581198  0.70740932 -0.0374379 ]
 [ 0.03524651  0.01771442  0.99922168]
 [ 0.70752186 -0.70658213 -0.01243066]]
support
[-0.04560427  1.21718311 -0.01514218]
[213.2575123  435.55738593  92.48793456]
[-195.53796196  -47.78469481  252.80099101]
[ 0.36689139 -9.79237249  0.12182048]
transform [[ 0.70581198  0.03524651  0.70752186]
 [ 0.70740932  0.01771442 -0.70658213]
 [-0.0374379   0.99922168 -0.01243066]]
zmp [ -7433252.55977457   6765865.65462628 -12293487.35454586]
d1:27693533.44074, d2:0.05940, d3:12344675.52902
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-511.9888529454329 steps:72[00m
[RDDPG] Resetting Environment
transform [[ 0.9989382   0.0236487  -0.03953732]
 [ 0.03753384  0.07987932  0.99609768]
 [ 0.0267146  -0.99652404  0.07890688]]
planes
[[ 0.9989382   0.0236487  -0.03953732]
 [ 0.03753384  0.07987932  0.99609768]
 [ 0.0267146  -0.99652404  0.07890688]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-481.3567   603.0588  -247.15668]
[  39.16495953 -317.79650211  -43.56945255]
[ 0.   0.  -9.8]
transform [[ 0.9989382   0.0236487  -0.03953732]
 [ 0.03753384  0.07987932  0.99609768]
 [ 0.0267146  -0.99652404  0.07890688]]
transform [[ 0.9989382   0.0236487  -0.03953732]
 [ 0.03753384  0.07987932  0.99609768]
 [ 0.0267146  -0.99652404  0.07890688]]
transform [[ 0.9989382   0.0236487  -0.03953732]
 [ 0.03753384  0.07987932  0.99609768]
 [ 0.0267146  -0.99652404  0.07890688]]
support
[-0.04816164  1.21337767  0.09611893]
[-456.81211932 -216.08743399 -633.32417722]
[ 33.33052013 -67.31478823 314.30019941]
[ 0.38746572 -9.7617573  -0.77328741]
transform [[ 0.9989382   0.03753384  0.0267146 ]
 [ 0.0236487   0.07987932 -0.99652404]
 [-0.03953732  0.99609768  0.07890688]]
zmp [  826526.4161704   1519748.48414522 21791789.17762849]
d1:43585091.41585, d2:0.05940, d3:10254566.98592
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-204.54196066203292 steps:74[00m
[RDDPG] Resetting Environment
transform [[ 0.72316182  0.68383116 -0.09701584]
 [ 0.0806502   0.05589757  0.99517393]
 [ 0.68595386 -0.72749609 -0.01472813]]
planes
[[ 0.72316182  0.68383116 -0.09701584]
 [ 0.0806502   0.05589757  0.99517393]
 [ 0.68595386 -0.72749609 -0.01472813]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[182.01456 582.13074 559.22943]
[  50.78208212 -290.56395373  -32.01511305]
[ 0.   0.  -9.8]
transform [[ 0.72316182  0.68383116 -0.09701584]
 [ 0.0806502   0.05589757  0.99517393]
 [ 0.68595386 -0.72749609 -0.01472813]]
transform [[ 0.72316182  0.68383116 -0.09701584]
 [ 0.0806502   0.05589757  0.99517393]
 [ 0.68595386 -0.72749609 -0.01472813]]
transform [[ 0.72316182  0.68383116 -0.09701584]
 [ 0.0806502   0.05589757  0.99517393]
 [ 0.68595386 -0.72749609 -0.01472813]]
support
[-0.11817803  1.21225241 -0.01794079]
[ 475.45099765  603.74975313 -306.88064889]
[-158.86704824  -44.00683925  246.6898272 ]
[ 0.95075526 -9.75270452  0.14433565]
transform [[ 0.72316182  0.0806502   0.68595386]
 [ 0.68383116  0.05589757 -0.72749609]
 [-0.09701584  0.99517393 -0.01472813]]
zmp [-14485693.70077634  15255857.61889715   -443944.63659393]
d1:27708234.39100, d2:0.05940, d3:9911434.53212
transform [[ 0.17353705  0.17139786  0.96979773]
 [-0.92065847 -0.32140985  0.22154859]
 [ 0.34967548 -0.93129939  0.10202239]]
planes
[[ 0.17353705  0.17139786  0.96979773]
 [-0.92065847 -0.32140985  0.22154859]
 [ 0.34967548 -0.93129939  0.10202239]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[182.01456 582.13074 559.22943]
[  50.78208212 -290.56395373  -32.01511305]
[ 0.   0.  -9.8]
transform [[ 0.17353705  0.17139786  0.96979773]
 [-0.92065847 -0.32140985  0.22154859]
 [ 0.34967548 -0.93129939  0.10202239]]
transform [[ 0.17353705  0.17139786  0.96979773]
 [-0.92065847 -0.32140985  0.22154859]
 [ 0.34967548 -0.93129939  0.10202239]]
transform [[ 0.17353705  0.17139786  0.96979773]
 [-0.92065847 -0.32140985  0.22154859]
 [ 0.34967548 -0.93129939  0.10202239]]
support
[1.18134087 0.26987525 0.12427666]
[ 673.70166703 -230.77930671 -421.43804705]
[-72.03765273  39.54426012 285.09302268]
[-9.50401776 -2.17117615 -0.99981947]
transform [[ 0.17353705 -0.92065847  0.34967548]
 [ 0.17139786 -0.32140985 -0.93129939]
 [ 0.96979773  0.22154859  0.10202239]]
zmp [-18806421.41259803  10494771.01419411   1510448.34324715]
d1:14538940.04123, d2:0.05940, d3:10440874.90909
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-423.06043088303306 steps:77[00m
[RDDPG] Resetting Environment
transform [[ 0.37676066  0.35275725  0.85651261]
 [-0.58969051 -0.62174505  0.51545918]
 [ 0.71436447 -0.69928211 -0.02623148]]
planes
[[ 0.37676066  0.35275725  0.85651261]
 [-0.58969051 -0.62174505  0.51545918]
 [ 0.71436447 -0.69928211 -0.02623148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-342.38922  183.41609  514.38824]
[ -4.79834525 -13.63135386   3.8743893 ]
[ 0.   0.  -9.8]
transform [[ 0.37676066  0.35275725  0.85651261]
 [-0.58969051 -0.62174505  0.51545918]
 [ 0.71436447 -0.69928211 -0.02623148]]
transform [[ 0.37676066  0.35275725  0.85651261]
 [-0.58969051 -0.62174505  0.51545918]
 [ 0.71436447 -0.69928211 -0.02623148]]
transform [[ 0.37676066  0.35275725  0.85651261]
 [-0.58969051 -0.62174505  0.51545918]
 [ 0.71436447 -0.69928211 -0.02623148]]
support
[ 1.04334473  0.62789691 -0.03195338]
[ 376.2825818   353.01176873 -386.34345031]
[-3.29792329 13.30185496  6.00276357]
[-8.39382354 -5.05149996  0.25706849]
transform [[ 0.37676066 -0.58969051  0.71436447]
 [ 0.35275725 -0.62174505 -0.69928211]
 [ 0.85651261  0.51545918 -0.02623148]]
zmp [11527553.3930139   3942130.12289193 -6694290.18868325]
d1:20482144.10250, d2:0.05940, d3:6852941.64866
transform [[ 0.69881517  0.71092278  0.07903263]
 [-0.03661755 -0.07478905  0.9965269 ]
 [ 0.71436447 -0.69928211 -0.02623148]]
planes
[[ 0.69881517  0.71092278  0.07903263]
 [-0.03661755 -0.07478905  0.9965269 ]
 [ 0.71436447 -0.69928211 -0.02623148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-342.38922  183.41609  514.38824]
[ -4.79834525 -13.63135386   3.8743893 ]
[ 0.   0.  -9.8]
transform [[ 0.69881517  0.71092278  0.07903263]
 [-0.03661755 -0.07478905  0.9965269 ]
 [ 0.71436447 -0.69928211 -0.02623148]]
transform [[ 0.69881517  0.71092278  0.07903263]
 [-0.03661755 -0.07478905  0.9965269 ]
 [ 0.71436447 -0.69928211 -0.02623148]]
transform [[ 0.69881517  0.71092278  0.07903263]
 [-0.03661755 -0.07478905  0.9965269 ]
 [ 0.71436447 -0.69928211 -0.02623148]]
support
[ 0.09627211  1.2139005  -0.03195338]
[ -68.21864756  511.42165989 -386.34345031]
[-12.73779321   5.05611287   6.00276357]
[-0.77451977 -9.76596359  0.25706849]
transform [[ 0.69881517 -0.03661755  0.71436447]
 [ 0.71092278 -0.07478905 -0.69928211]
 [ 0.07903263  0.9965269  -0.02623148]]
zmp [  4503900.30236238  -3003839.34477733 -12803521.79851884]
d1:26047027.57142, d2:0.05940, d3:10535383.82373
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-392.5804523206616 steps:80[00m
[RDDPG] Resetting Environment
transform [[ 0.71151274 -0.70122176 -0.0451413 ]
 [ 0.03864104 -0.02509872  0.9989379 ]
 [-0.70160991 -0.71250135  0.00923787]]
planes
[[ 0.71151274 -0.70122176 -0.0451413 ]
 [ 0.03864104 -0.02509872  0.9989379 ]
 [-0.70160991 -0.71250135  0.00923787]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-342.38922  183.41609  514.38824]
[ -4.79834525 -13.63135386   3.8743893 ]
[ 0.   0.  -9.8]
transform [[ 0.71151274 -0.70122176 -0.0451413 ]
 [ 0.03864104 -0.02509872  0.9989379 ]
 [-0.70160991 -0.71250135  0.00923787]]
transform [[ 0.71151274 -0.70122176 -0.0451413 ]
 [ 0.03864104 -0.02509872  0.9989379 ]
 [-0.70160991 -0.71250135  0.00923787]]
transform [[ 0.71151274 -0.70122176 -0.0451413 ]
 [ 0.03864104 -0.02509872  0.9989379 ]
 [-0.70160991 -0.71250135  0.00923787]]
support
[-0.05498803  1.21683743  0.01125294]
[-395.44980509  496.00813137  114.29130901]
[ 5.96962322  4.0269909  13.11471566]
[ 0.44238476 -9.78959147 -0.09053111]
transform [[ 0.71151274  0.03864104 -0.70160991]
 [-0.70122176 -0.02509872 -0.71250135]
 [-0.0451413   0.9989379   0.00923787]]
zmp [12205564.13590504 12368410.49983177   252909.63820406]
d1:24802745.05027, d2:0.05940, d3:7980495.45660
transform [[ 0.25742793 -0.26553896 -0.92909634]
 [ 0.66443545 -0.64948511  0.36972252]
 [-0.70160991 -0.71250135  0.00923787]]
planes
[[ 0.25742793 -0.26553896 -0.92909634]
 [ 0.66443545 -0.64948511  0.36972252]
 [-0.70160991 -0.71250135  0.00923787]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-342.38922  183.41609  514.38824]
[ -4.79834525 -13.63135386   3.8743893 ]
[ 0.   0.  -9.8]
transform [[ 0.25742793 -0.26553896 -0.92909634]
 [ 0.66443545 -0.64948511  0.36972252]
 [-0.70160991 -0.71250135  0.00923787]]
transform [[ 0.25742793 -0.26553896 -0.92909634]
 [ 0.66443545 -0.64948511  0.36972252]
 [-0.70160991 -0.71250135  0.00923787]]
transform [[ 0.25742793 -0.26553896 -0.92909634]
 [ 0.66443545 -0.64948511  0.36972252]
 [-0.70160991 -0.71250135  0.00923787]]
support
[-1.13176124  0.45037053  0.01125294]
[-614.76090318 -156.44064017  114.29130901]
[-1.21525348  7.09761967 13.11471566]
[ 9.10514414 -3.62328065 -0.09053111]
transform [[ 0.25742793  0.66443545 -0.70160991]
 [-0.26553896 -0.64948511 -0.71250135]
 [-0.92909634  0.36972252  0.00923787]]
zmp [ 1.24645461e+07  1.21100115e+07 -7.48835193e+03]
d1:24803918.41448, d2:0.05940, d3:7827414.03550
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-463.32154090646867 steps:83[00m
[RDDPG] Resetting Environment
transform [[ 0.68958437  0.7191878  -0.08510165]
 [ 0.04094392  0.07860597  0.9960646 ]
 [ 0.72304696 -0.690355    0.02475908]]
planes
[[ 0.68958437  0.7191878  -0.08510165]
 [ 0.04094392  0.07860597  0.9960646 ]
 [ 0.72304696 -0.690355    0.02475908]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 376.0033   498.86752 -139.25212]
[ -60.5861239  -115.15209813   16.22994147]
[ 0.   0.  -9.8]
transform [[ 0.68958437  0.7191878  -0.08510165]
 [ 0.04094392  0.07860597  0.9960646 ]
 [ 0.72304696 -0.690355    0.02475908]]
transform [[ 0.68958437  0.7191878  -0.08510165]
 [ 0.04094392  0.07860597  0.9960646 ]
 [ 0.72304696 -0.690355    0.02475908]]
transform [[ 0.68958437  0.7191878  -0.08510165]
 [ 0.04094392  0.07860597  0.9960646 ]
 [ 0.72304696 -0.690355    0.02475908]]
support
[-0.10366497  1.21333737  0.03015981]
[629.91601729 -84.09509147 -75.9754059 ]
[-125.97642281    4.63379391   36.09105292]
[ 0.83399616 -9.76143311 -0.24263902]
transform [[ 0.68958437  0.04094392  0.72304696]
 [ 0.7191878   0.07860597 -0.690355  ]
 [-0.08510165  0.9960646   0.02475908]]
zmp [ 8059474.53952857 -6956613.45039782  6516638.54274263]
d1:19632966.42752, d2:0.05940, d3:8930074.05994
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-388.22841504109977 steps:85[00m
[RDDPG] Resetting Environment
transform [[ 0.17248331  0.19920957 -0.96465802]
 [ 0.69724905  0.6670661   0.26242438]
 [ 0.69576818 -0.71787071 -0.02384089]]
planes
[[ 0.17248331  0.19920957 -0.96465802]
 [ 0.69724905  0.6670661   0.26242438]
 [ 0.69576818 -0.71787071 -0.02384089]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -97.88077  731.44556 -434.63394]
[-70.23005971 -94.2268067   42.70927075]
[ 0.   0.  -9.8]
transform [[ 0.17248331  0.19920957 -0.96465802]
 [ 0.69724905  0.6670661   0.26242438]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.17248331  0.19920957 -0.96465802]
 [ 0.69724905  0.6670661   0.26242438]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.17248331  0.19920957 -0.96465802]
 [ 0.69724905  0.6670661   0.26242438]
 [ 0.69576818 -0.71787071 -0.02384089]]
support
[-1.17508003  0.31966732 -0.02904134]
[ 548.10127505  305.61671748 -582.82360486]
[ -72.08423554 -100.61539708   17.76059703]
[ 9.45364861 -2.57175892  0.23364075]
transform [[ 0.17248331  0.69724905  0.69576818]
 [ 0.19920957  0.6670661  -0.71787071]
 [-0.96465802  0.26242438 -0.02384089]]
zmp [3460338.35206533 8408381.51862831 2355115.14015966]
d1:12434335.39394, d2:0.05940, d3:2788516.53475
transform [[ 0.27862048  0.30033782 -0.91223234]
 [ 0.66202515  0.62805963  0.40897894]
 [ 0.69576818 -0.71787071 -0.02384089]]
planes
[[ 0.27862048  0.30033782 -0.91223234]
 [ 0.66202515  0.62805963  0.40897894]
 [ 0.69576818 -0.71787071 -0.02384089]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -97.88077  731.44556 -434.63394]
[-70.23005971 -94.2268067   42.70927075]
[ 0.   0.  -9.8]
transform [[ 0.27862048  0.30033782 -0.91223234]
 [ 0.66202515  0.62805963  0.40897894]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.27862048  0.30033782 -0.91223234]
 [ 0.66202515  0.62805963  0.40897894]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.27862048  0.30033782 -0.91223234]
 [ 0.66202515  0.62805963  0.40897894]
 [ 0.69576818 -0.71787071 -0.02384089]]
support
[-1.11121867  0.49819001 -0.02904134]
[ 588.89631555  216.83576378 -582.82360486]
[-86.82818485 -88.20692677  17.76059703]
[ 8.93987693 -4.0079936   0.23364075]
transform [[ 0.27862048  0.66202515  0.69576818]
 [ 0.30033782  0.62805963 -0.71787071]
 [-0.91223234  0.40897894 -0.02384089]]
zmp [3156014.35637458 8071376.98559371 3621303.11328045]
d1:13119234.14256, d2:0.05940, d3:3598404.81395
transform [[ 0.70996475  0.69237959 -0.12868819]
 [ 0.10888842  0.07261094  0.99139851]
 [ 0.69576818 -0.71787071 -0.02384089]]
planes
[[ 0.70996475  0.69237959 -0.12868819]
 [ 0.10888842  0.07261094  0.99139851]
 [ 0.69576818 -0.71787071 -0.02384089]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -97.88077  731.44556 -434.63394]
[-70.23005971 -94.2268067   42.70927075]
[ 0.   0.  -9.8]
transform [[ 0.70996475  0.69237959 -0.12868819]
 [ 0.10888842  0.07261094  0.99139851]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.70996475  0.69237959 -0.12868819]
 [ 0.10888842  0.07261094  0.99139851]
 [ 0.69576818 -0.71787071 -0.02384089]]
transform [[ 0.70996475  0.69237959 -0.12868819]
 [ 0.10888842  0.07261094  0.99139851]
 [ 0.69576818 -0.71787071 -0.02384089]]
support
[-0.15675909  1.20765346 -0.02904134]
[ 492.87833606 -388.44257277 -582.82360486]
[-120.59776369   27.85277004   17.76059703]
[ 1.26114423 -9.71570543  0.23364075]
transform [[ 0.70996475  0.10888842  0.69576818]
 [ 0.69237959  0.07261094 -0.71787071]
 [-0.12868819  0.99139851 -0.02384089]]
zmp [-1622922.45387927  3272464.09115484  8653235.91302879]
d1:17876130.74802, d2:0.05940, d3:7018835.82878
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-388.3604107170959 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-172.41884923828772 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-136.21484630859885 steps:91[00m
[RDDPG] Resetting Environment
transform [[ 0.70288664 -0.7106421  -0.0306301 ]
 [ 0.01191615 -0.03129174  0.9994393 ]
 [-0.71120203 -0.70285761 -0.01352643]]
planes
[[ 0.70288664 -0.7106421  -0.0306301 ]
 [ 0.01191615 -0.03129174  0.9994393 ]
 [-0.71120203 -0.70285761 -0.01352643]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -97.88077  731.44556 -434.63394]
[-70.23005971 -94.2268067   42.70927075]
[ 0.   0.  -9.8]
transform [[ 0.70288664 -0.7106421  -0.0306301 ]
 [ 0.01191615 -0.03129174  0.9994393 ]
 [-0.71120203 -0.70285761 -0.01352643]]
transform [[ 0.70288664 -0.7106421  -0.0306301 ]
 [ 0.01191615 -0.03129174  0.9994393 ]
 [-0.71120203 -0.70285761 -0.01352643]]
transform [[ 0.70288664 -0.7106421  -0.0306301 ]
 [ 0.01191615 -0.03129174  0.9994393 ]
 [-0.71120203 -0.70285761 -0.01352643]]
support
[-0.03731148  1.21744819 -0.01647697]
[-575.28220956 -458.44480633 -438.61003152]
[ 16.28957579  44.79697257 115.59808514]
[ 0.30017497 -9.79450513  0.13255904]
transform [[ 0.70288664  0.01191615 -0.71120203]
 [-0.7106421  -0.03129174 -0.70285761]
 [-0.0306301   0.9994393  -0.01352643]]
zmp [  7868709.76579337   8860592.63928259 -25004742.11104316]
d1:52762306.31345, d2:0.05940, d3:21232628.87573
transform [[ 0.70199728 -0.71108955  0.0393906 ]
 [-0.03730448  0.01851916  0.99913239]
 [-0.71120203 -0.70285761 -0.01352643]]
planes
[[ 0.70199728 -0.71108955  0.0393906 ]
 [-0.03730448  0.01851916  0.99913239]
 [-0.71120203 -0.70285761 -0.01352643]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -97.88077  731.44556 -434.63394]
[-70.23005971 -94.2268067   42.70927075]
[ 0.   0.  -9.8]
transform [[ 0.70199728 -0.71108955  0.0393906 ]
 [-0.03730448  0.01851916  0.99913239]
 [-0.71120203 -0.70285761 -0.01352643]]
transform [[ 0.70199728 -0.71108955  0.0393906 ]
 [-0.03730448  0.01851916  0.99913239]
 [-0.71120203 -0.70285761 -0.01352643]]
transform [[ 0.70199728 -0.71108955  0.0393906 ]
 [-0.03730448  0.01851916  0.99913239]
 [-0.71120203 -0.70285761 -0.01352643]]
support
[ 0.04798292  1.21707434 -0.01647697]
[-605.95581784 -417.05970537 -438.61003152]
[ 19.38473066  43.54711116 115.59808514]
[-0.38602789 -9.79149747  0.13255904]
transform [[ 0.70199728 -0.03730448 -0.71120203]
 [-0.71108955  0.01851916 -0.70285761]
 [ 0.0393906   0.99913239 -0.01352643]]
zmp [  9107800.68175779   7606642.3504064  -24997016.10881793]
d1:52696825.17824, d2:0.05940, d3:21199221.94321
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-274.9931884118452 steps:94[00m
[RDDPG] Resetting Environment
transform [[ 0.68359363  0.70110178  0.20286973]
 [-0.13866161 -0.14814018  0.97919738]
 [ 0.71657014 -0.69750333 -0.00405179]]
planes
[[ 0.68359363  0.70110178  0.20286973]
 [-0.13866161 -0.14814018  0.97919738]
 [ 0.71657014 -0.69750333 -0.00405179]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 188.53125 1655.5907   391.12585]
[-160.39469068 -423.71019423   81.30547401]
[ 0.   0.  -9.8]
transform [[ 0.68359363  0.70110178  0.20286973]
 [-0.13866161 -0.14814018  0.97919738]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.68359363  0.70110178  0.20286973]
 [-0.13866161 -0.14814018  0.97919738]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.68359363  0.70110178  0.20286973]
 [-0.13866161 -0.14814018  0.97919738]
 [ 0.71657014 -0.69750333 -0.00405179]]
support
[ 0.24712195  1.19279088 -0.00493562]
[ 1368.96394289   111.58786752 -1021.26891968]
[-390.2143409   164.62319633  180.27579192]
[-1.98812334 -9.59613435  0.03970758]
transform [[ 0.68359363 -0.13866161  0.71657014]
 [ 0.70110178 -0.14814018 -0.69750333]
 [ 0.20286973  0.97919738 -0.00405179]]
zmp [ -850368.98172516  1342393.6669214  -1773786.95151654]
d1:4173395.26977, d2:0.05940, d3:1840049.13278
transform [[ 0.33587107  0.3399497   0.87842184]
 [-0.61132473 -0.63081169  0.47786894]
 [ 0.71657014 -0.69750333 -0.00405179]]
planes
[[ 0.33587107  0.3399497   0.87842184]
 [-0.61132473 -0.63081169  0.47786894]
 [ 0.71657014 -0.69750333 -0.00405179]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 188.53125 1655.5907   391.12585]
[-160.39469068 -423.71019423   81.30547401]
[ 0.   0.  -9.8]
transform [[ 0.33587107  0.3399497   0.87842184]
 [-0.61132473 -0.63081169  0.47786894]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.33587107  0.3399497   0.87842184]
 [-0.61132473 -0.63081169  0.47786894]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.33587107  0.3399497   0.87842184]
 [-0.61132473 -0.63081169  0.47786894]
 [ 0.71657014 -0.69750333 -0.00405179]]
support
[ 1.07003305  0.58210707 -0.00493562]
[  969.7132434   -972.71288425 -1021.26891968]
[-126.49158441  404.18794586  180.27579192]
[-8.60853406 -4.68311566  0.03970758]
transform [[ 0.33587107 -0.61132473  0.71657014]
 [ 0.3399497  -0.63081169 -0.69750333]
 [ 0.87842184  0.47786894 -0.00405179]]
zmp [   8855.83818732 2219810.33071885 -862453.69614648]
d1:3324225.05104, d2:0.05940, d3:1335150.43949
transform [[ 0.68245929  0.69989079  0.21071848]
 [-0.14414102 -0.15375973  0.97753841]
 [ 0.71657014 -0.69750333 -0.00405179]]
planes
[[ 0.68245929  0.69989079  0.21071848]
 [-0.14414102 -0.15375973  0.97753841]
 [ 0.71657014 -0.69750333 -0.00405179]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 188.53125 1655.5907   391.12585]
[-160.39469068 -423.71019423   81.30547401]
[ 0.   0.  -9.8]
transform [[ 0.68245929  0.69989079  0.21071848]
 [-0.14414102 -0.15375973  0.97753841]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.68245929  0.69989079  0.21071848]
 [-0.14414102 -0.15375973  0.97753841]
 [ 0.71657014 -0.69750333 -0.00405179]]
transform [[ 0.68245929  0.69989079  0.21071848]
 [-0.14414102 -0.15375973  0.97753841]
 [ 0.71657014 -0.69750333 -0.00405179]]
support
[ 0.25668276  1.19077003 -0.00493562]
[ 1369.81503617   100.60227485 -1021.26891968]
[-388.88114495  167.74824386  180.27579192]
[-2.06504113 -9.57987639  0.03970758]
transform [[ 0.68245929 -0.14414102  0.71657014]
 [ 0.69989079 -0.15375973 -0.69750333]
 [ 0.21071848  0.97753841 -0.00405179]]
zmp [ -840408.30390403  1352609.0931052  -1770771.20514144]
d1:4171304.15799, d2:0.05940, d3:1839000.96471
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-425.5668102541664 steps:98[00m
[RDDPG] Resetting Environment
transform [[ 0.62112689 -0.78368688  0.0060341 ]
 [ 0.03515563  0.03555331  0.99874926]
 [-0.78292114 -0.62013787  0.04963413]]
planes
[[ 0.62112689 -0.78368688  0.0060341 ]
 [ 0.03515563  0.03555331  0.99874926]
 [-0.78292114 -0.62013787  0.04963413]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 188.53125 1655.5907   391.12585]
[-160.39469068 -423.71019423   81.30547401]
[ 0.   0.  -9.8]
transform [[ 0.62112689 -0.78368688  0.0060341 ]
 [ 0.03515563  0.03555331  0.99874926]
 [-0.78292114 -0.62013787  0.04963413]]
transform [[ 0.62112689 -0.78368688  0.0060341 ]
 [ 0.03515563  0.03555331  0.99874926]
 [-0.78292114 -0.62013787  0.04963413]]
transform [[ 0.62112689 -0.78368688  0.0060341 ]
 [ 0.03515563  0.03555331  0.99874926]
 [-0.78292114 -0.62013787  0.04963413]]
support
[0.00735033 1.21660763 0.06046088]
[-1178.00277939   456.126327   -1154.88640044]
[232.92126889  60.50070354 392.37065689]
[-0.05913423 -9.78774271 -0.48641443]
transform [[ 0.62112689  0.03515563 -0.78292114]
 [-0.78368688  0.03555331 -0.62013787]
 [ 0.0060341   0.99874926  0.04963413]]
zmp [   183787.80618313    -97800.91851983 -31620418.57326282]
d1:63075011.88662, d2:0.05940, d3:20129857.07158
transform [[ 0.86293519 -0.46265444  0.20320866]
 [-0.09279954  0.25020677  0.96373487]
 [-0.49672031 -0.85049838  0.17297812]]
planes
[[ 0.86293519 -0.46265444  0.20320866]
 [-0.09279954  0.25020677  0.96373487]
 [-0.49672031 -0.85049838  0.17297812]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 188.53125 1655.5907   391.12585]
[-160.39469068 -423.71019423   81.30547401]
[ 0.   0.  -9.8]
transform [[ 0.86293519 -0.46265444  0.20320866]
 [-0.09279954  0.25020677  0.96373487]
 [-0.49672031 -0.85049838  0.17297812]]
transform [[ 0.86293519 -0.46265444  0.20320866]
 [-0.09279954  0.25020677  0.96373487]
 [-0.49672031 -0.85049838  0.17297812]]
transform [[ 0.86293519 -0.46265444  0.20320866]
 [-0.09279954  0.25020677  0.96373487]
 [-0.49672031 -0.85049838  0.17297812]]
support
[0.2475348  1.17395551 0.21071004]
[ -523.79598195   773.68600855 -1434.06829141]
[ 74.14315719 -12.77368544 454.10020206]
[-1.99144482 -9.44460168 -1.69518556]
transform [[ 0.86293519 -0.09279954 -0.49672031]
 [-0.46265444  0.25020677 -0.85049838]
 [ 0.20320866  0.96373487  0.17297812]]
zmp [ -3736795.82937796 -14688838.99023293 -17574268.1542684 ]
d1:41653195.07849, d2:0.05940, d3:9911662.59100
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-199.76738548759025 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-279.77477892575564 steps:102[00m
[RDDPG] Resetting Environment
transform [[ 0.72254235  0.67528099 -0.14808157]
 [ 0.10642463  0.10299743  0.98897189]
 [ 0.68308592 -0.73033363  0.00255348]]
planes
[[ 0.72254235  0.67528099 -0.14808157]
 [ 0.10642463  0.10299743  0.98897189]
 [ 0.68308592 -0.73033363  0.00255348]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 159.23318 -429.54074 -467.30847]
[-19.02027134 -29.39805993   8.98896158]
[ 0.   0.  -9.8]
transform [[ 0.72254235  0.67528099 -0.14808157]
 [ 0.10642463  0.10299743  0.98897189]
 [ 0.68308592 -0.73033363  0.00255348]]
transform [[ 0.72254235  0.67528099 -0.14808157]
 [ 0.10642463  0.10299743  0.98897189]
 [ 0.68308592 -0.73033363  0.00255348]]
transform [[ 0.72254235  0.67528099 -0.14808157]
 [ 0.10642463  0.10299743  0.98897189]
 [ 0.68308592 -0.73033363  0.00255348]]
support
[-0.18038278  1.20469751  0.00311047]
[-105.80820463 -489.45020152  421.28473034]
[-34.92600198   3.83768037   8.50086533]
[ 1.45119939 -9.69192451 -0.02502411]
transform [[ 0.72254235  0.10642463  0.68308592]
 [ 0.67528099  0.10299743 -0.73033363]
 [-0.14808157  0.98897189  0.00255348]]
zmp [-1991556.42123874   717133.24499276 -6447240.41307206]
d1:13114647.66158, d2:0.05940, d3:4991125.23485
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-363.77650205004005 steps:104[00m
[RDDPG] Resetting Environment
transform [[ 0.12045623 -0.10666792 -0.98697126]
 [ 0.6924206  -0.70340896  0.16052905]
 [-0.71136773 -0.70273596 -0.01087093]]
planes
[[ 0.12045623 -0.10666792 -0.98697126]
 [ 0.6924206  -0.70340896  0.16052905]
 [-0.71136773 -0.70273596 -0.01087093]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 159.23318 -429.54074 -467.30847]
[-19.02027134 -29.39805993   8.98896158]
[ 0.   0.  -9.8]
transform [[ 0.12045623 -0.10666792 -0.98697126]
 [ 0.6924206  -0.70340896  0.16052905]
 [-0.71136773 -0.70273596 -0.01087093]]
transform [[ 0.12045623 -0.10666792 -0.98697126]
 [ 0.6924206  -0.70340896  0.16052905]
 [-0.71136773 -0.70273596 -0.01087093]]
transform [[ 0.12045623 -0.10666792 -0.98697126]
 [ 0.6924206  -0.70340896  0.16052905]
 [-0.71136773 -0.70273596 -0.01087093]]
support
[-1.20226048  0.19554544 -0.01324222]
[526.21887701 337.38255832 193.66045326]
[-8.02712691  8.95182037 34.0917627 ]
[ 9.67231834 -1.57318466  0.10653509]
transform [[ 0.12045623  0.6924206  -0.71136773]
 [-0.10666792 -0.70340896 -0.70273596]
 [-0.98697126  0.16052905 -0.01087093]]
zmp [30527397.54614257 -7625991.01678243  4549944.18055632]
d1:39441093.15077, d2:0.05940, d3:10438072.84583
transform [[ 0.24259008 -0.23099416 -0.94222701]
 [ 0.65962565 -0.67290711  0.33479857]
 [-0.71136773 -0.70273596 -0.01087093]]
planes
[[ 0.24259008 -0.23099416 -0.94222701]
 [ 0.65962565 -0.67290711  0.33479857]
 [-0.71136773 -0.70273596 -0.01087093]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 159.23318 -429.54074 -467.30847]
[-19.02027134 -29.39805993   8.98896158]
[ 0.   0.  -9.8]
transform [[ 0.24259008 -0.23099416 -0.94222701]
 [ 0.65962565 -0.67290711  0.33479857]
 [-0.71136773 -0.70273596 -0.01087093]]
transform [[ 0.24259008 -0.23099416 -0.94222701]
 [ 0.65962565 -0.67290711  0.33479857]
 [-0.71136773 -0.70273596 -0.01087093]]
transform [[ 0.24259008 -0.23099416 -0.94222701]
 [ 0.65962565 -0.67290711  0.33479857]
 [-0.71136773 -0.70273596 -0.01087093]]
support
[-1.14775611  0.40782859 -0.01324222]
[578.16045869 237.62110316 193.66045326]
[-6.29299129 10.24539635 34.0917627 ]
[ 9.23382466 -3.28102603  0.10653509]
transform [[ 0.24259008  0.65962565 -0.71136773]
 [-0.23099416 -0.67290711 -0.70273596]
 [-0.94222701  0.33479857 -0.01087093]]
zmp [29634312.70287932 -6795352.95000484  9295719.3421151 ]
d1:42291346.72909, d2:0.05940, d3:13426584.90008
transform [[ 0.92804426  0.37045258  0.03871439]
 [-0.11184458  0.17801899  0.97765028]
 [ 0.3552812  -0.91163266  0.20664261]]
planes
[[ 0.92804426  0.37045258  0.03871439]
 [-0.11184458  0.17801899  0.97765028]
 [ 0.3552812  -0.91163266  0.20664261]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 159.23318 -429.54074 -467.30847]
[-19.02027134 -29.39805993   8.98896158]
[ 0.   0.  -9.8]
transform [[ 0.92804426  0.37045258  0.03871439]
 [-0.11184458  0.17801899  0.97765028]
 [ 0.3552812  -0.91163266  0.20664261]]
transform [[ 0.92804426  0.37045258  0.03871439]
 [-0.11184458  0.17801899  0.97765028]
 [ 0.3552812  -0.91163266  0.20664261]]
transform [[ 0.92804426  0.37045258  0.03871439]
 [-0.11184458  0.17801899  0.97765028]
 [ 0.3552812  -0.91163266  0.20664261]]
support
[0.0471592  1.19090631 0.25171781]
[ -29.44059463 -551.14003625  351.59008104]
[-28.19423873   5.6819622   21.90018909]
[-0.37940099 -9.58097279 -2.02509761]
transform [[ 0.92804426 -0.11184458  0.3552812 ]
 [ 0.37045258  0.17801899 -0.91163266]
 [ 0.03871439  0.97765028  0.20664261]]
zmp [-3768639.86465048  9501489.09603645  -578262.90609217]
d1:15683416.24157, d2:0.05940, d3:2051820.59413
transform [[ 0.42776528  0.77064478 -0.47235954]
 [-0.07744958  0.5519132   0.83029723]
 [ 0.90056562 -0.31858823  0.29577538]]
planes
[[ 0.42776528  0.77064478 -0.47235954]
 [-0.07744958  0.5519132   0.83029723]
 [ 0.90056562 -0.31858823  0.29577538]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-415.40338  882.01697 1371.7986 ]
[-4082.7257346   4575.8350608   1187.49630025]
[ 0.   0.  -9.8]
transform [[ 0.42776528  0.77064478 -0.47235954]
 [-0.07744958  0.5519132   0.83029723]
 [ 0.90056562 -0.31858823  0.29577538]]
transform [[ 0.42776528  0.77064478 -0.47235954]
 [-0.07744958  0.5519132   0.83029723]
 [ 0.90056562 -0.31858823  0.29577538]]
transform [[ 0.42776528  0.77064478 -0.47235954]
 [-0.07744958  0.5519132   0.83029723]
 [ 0.90056562 -0.31858823  0.29577538]]
support
[-0.57539589  1.01141096  0.36029322]
[-145.95551362 1657.9701908  -249.35397486]
[ 1218.96990101  3827.64404333 -4783.33745513]
[ 4.62912347 -8.13691287 -2.89859876]
transform [[ 0.42776528 -0.07744958  0.90056562]
 [ 0.77064478  0.5519132  -0.31858823]
 [-0.47235954  0.83029723  0.29577538]]
zmp [-17481883.60748465   7593247.72021538  -3443236.2671857 ]
d1:23961793.91928, d2:0.05940, d3:10101750.20749
transform [[ 0.35039136  0.12924665 -0.92764282]
 [ 0.2573081   0.93904042  0.22802565]
 [ 0.90056562 -0.31858823  0.29577538]]
planes
[[ 0.35039136  0.12924665 -0.92764282]
 [ 0.2573081   0.93904042  0.22802565]
 [ 0.90056562 -0.31858823  0.29577538]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-415.40338  882.01697 1371.7986 ]
[-4082.7257346   4575.8350608   1187.49630025]
[ 0.   0.  -9.8]
transform [[ 0.35039136  0.12924665 -0.92764282]
 [ 0.2573081   0.93904042  0.22802565]
 [ 0.90056562 -0.31858823  0.29577538]]
transform [[ 0.35039136  0.12924665 -0.92764282]
 [ 0.2573081   0.93904042  0.22802565]
 [ 0.90056562 -0.31858823  0.29577538]]
transform [[ 0.35039136  0.12924665 -0.92764282]
 [ 0.2573081   0.93904042  0.22802565]
 [ 0.90056562 -0.31858823  0.29577538]]
support
[-1.12999066  0.27776515  0.36029322]
[-1304.09512479  1034.16818996  -249.35397486]
[-1940.71287215  3517.15531431 -4783.33745513]
[ 9.09089966 -2.23465132 -2.89859876]
transform [[ 0.35039136  0.2573081   0.90056562]
 [ 0.12924665  0.93904042 -0.31858823]
 [-0.92764282  0.22802565  0.29577538]]
zmp [-16582738.25732348   8633046.08880468  -5060843.5157698 ]
d1:24081731.14247, d2:0.05940, d3:11189112.08346
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-582.2081150034107 steps:110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-90.69304699216966 steps:111[00m
[RDDPG] Resetting Environment
transform [[ 0.22249213  0.2191512  -0.94998419]
 [ 0.68644595  0.65671957  0.31226805]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
planes
[[ 0.22249213  0.2191512  -0.94998419]
 [ 0.68644595  0.65671957  0.31226805]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-632.87885    57.016026  828.3113  ]
[ -17.22157806 -230.00822936    4.66551619]
[ 0.   0.  -9.8]
transform [[ 0.22249213  0.2191512  -0.94998419]
 [ 0.68644595  0.65671957  0.31226805]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
transform [[ 0.22249213  0.2191512  -0.94998419]
 [ 0.68644595  0.65671957  0.31226805]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
transform [[ 0.22249213  0.2191512  -0.94998419]
 [ 0.68644595  0.65671957  0.31226805]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
support
[-1.15720538  0.38038345 -0.00526294]
[-915.19805316 -138.33843479 -482.86748353]
[ -58.67041141 -161.41569532  154.02886849]
[ 9.30984509 -3.06022688  0.04234094]
transform [[ 0.22249213  0.68644595  0.69230717]
 [ 0.2191512   0.65671957 -0.72159004]
 [-0.94998419  0.31226805 -0.0043205 ]]
zmp [-13228632.69708652   4504632.63195113  -2059056.63660671]
d1:17735207.83874, d2:0.05940, d3:7078265.19678
transform [[ 0.72093785  0.6919136  -0.03878553]
 [ 0.03097667  0.02373669  0.99923825]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
planes
[[ 0.72093785  0.6919136  -0.03878553]
 [ 0.03097667  0.02373669  0.99923825]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-632.87885    57.016026  828.3113  ]
[ -17.22157806 -230.00822936    4.66551619]
[ 0.   0.  -9.8]
transform [[ 0.72093785  0.6919136  -0.03878553]
 [ 0.03097667  0.02373669  0.99923825]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
transform [[ 0.72093785  0.6919136  -0.03878553]
 [ 0.03097667  0.02373669  0.99923825]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
transform [[ 0.72093785  0.6919136  -0.03878553]
 [ 0.03097667  0.02373669  0.99923825]
 [ 0.69230717 -0.72159004 -0.0043205 ]]
support
[-0.04724587  1.21720329 -0.00526294]
[-448.94264274  809.42921014 -482.86748353]
[-171.74246505   -1.33113783  154.02886849]
[ 0.38009821 -9.79253488  0.04234094]
transform [[ 0.72093785  0.03097667  0.69230717]
 [ 0.6919136   0.02373669 -0.72159004]
 [-0.03878553  0.99923825 -0.0043205 ]]
zmp [-8794095.87229832  8787040.10004724 -6706710.74068895]
d1:21133293.78586, d2:0.05940, d3:9856970.84405
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-295.20249994071446 steps:114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-163.96583263673594 steps:115[00m
[RDDPG] Resetting Environment
transform [[ 0.30403763  0.26271453  0.91571951]
 [-0.63999265 -0.65568757  0.40060353]
 [ 0.7056703  -0.7078523  -0.03121831]]
planes
[[ 0.30403763  0.26271453  0.91571951]
 [-0.63999265 -0.65568757  0.40060353]
 [ 0.7056703  -0.7078523  -0.03121831]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 227.84848 -172.09354  804.35895]
[  22.95493162 -522.71586864    8.11506915]
[ 0.   0.  -9.8]
transform [[ 0.30403763  0.26271453  0.91571951]
 [-0.63999265 -0.65568757  0.40060353]
 [ 0.7056703  -0.7078523  -0.03121831]]
transform [[ 0.30403763  0.26271453  0.91571951]
 [-0.63999265 -0.65568757  0.40060353]
 [ 0.7056703  -0.7078523  -0.03121831]]
transform [[ 0.30403763  0.26271453  0.91571951]
 [-0.63999265 -0.65568757  0.40060353]
 [ 0.7056703  -0.7078523  -0.03121831]]
support
[ 1.1154665   0.48798766 -0.038028  ]
[760.63021947 289.24727524 257.49198183]
[-122.91476621  331.29823577  385.9509066 ]
[-8.97405119 -3.92591462  0.30593946]
transform [[ 0.30403763 -0.63999265  0.7056703 ]
 [ 0.26271453 -0.65568757 -0.7078523 ]
 [ 0.91571951  0.40060353 -0.03121831]]
zmp [-2502263.51422381  7115302.84451203 -1210535.75516032]
d1:9760099.10039, d2:0.05940, d3:3781615.11000
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-355.90475624349654 steps:117[00m
[RDDPG] Resetting Environment
transform [[ 0.05673408  0.08634701  0.99464846]
 [-0.72303021 -0.68345624  0.10057307]
 [ 0.68848282 -0.72486675  0.02365623]]
planes
[[ 0.05673408  0.08634701  0.99464846]
 [-0.72303021 -0.68345624  0.10057307]
 [ 0.68848282 -0.72486675  0.02365623]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  90.72836 -489.72137  625.30145]
[  25.36728962 -127.97378755  -12.77368124]
[ 0.   0.  -9.8]
transform [[ 0.05673408  0.08634701  0.99464846]
 [-0.72303021 -0.68345624  0.10057307]
 [ 0.68848282 -0.72486675  0.02365623]]
transform [[ 0.05673408  0.08634701  0.99464846]
 [-0.72303021 -0.68345624  0.10057307]
 [ 0.68848282 -0.72486675  0.02365623]]
transform [[ 0.05673408  0.08634701  0.99464846]
 [-0.72303021 -0.68345624  0.10057307]
 [ 0.68848282 -0.72486675  0.02365623]]
support
[1.21161232 0.12251119 0.02881639]
[584.8165405  331.99226994 432.23993467]
[-22.31628589  67.83847885 109.92670916]
[-9.74755487 -0.98561609 -0.23183106]
transform [[ 0.05673408 -0.72303021  0.68848282]
 [ 0.08634701 -0.68345624 -0.72486675]
 [ 0.99464846  0.10057307  0.02365623]]
zmp [1568412.92093064 6700968.56500557 -671182.87014781]
d1:8321970.99472, d2:0.05940, d3:2087000.85521
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-226.87479632308754 steps:119[00m
[RDDPG] Resetting Environment
transform [[ 0.68986928 -0.72254241 -0.04486499]
 [ 0.01250837 -0.05006774  0.99866748]
 [-0.72382593 -0.68951124 -0.02550237]]
planes
[[ 0.68986928 -0.72254241 -0.04486499]
 [ 0.01250837 -0.05006774  0.99866748]
 [-0.72382593 -0.68951124 -0.02550237]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  90.72836 -489.72137  625.30145]
[  25.36728962 -127.97378755  -12.77368124]
[ 0.   0.  -9.8]
transform [[ 0.68986928 -0.72254241 -0.04486499]
 [ 0.01250837 -0.05006774  0.99866748]
 [-0.72382593 -0.68951124 -0.02550237]]
transform [[ 0.68986928 -0.72254241 -0.04486499]
 [ 0.01250837 -0.05006774  0.99866748]
 [-0.72382593 -0.68951124 -0.02550237]]
transform [[ 0.68986928 -0.72254241 -0.04486499]
 [ 0.01250837 -0.05006774  0.99866748]
 [-0.72382593 -0.68951124 -0.02550237]]
support
[-0.05465144  1.21650801 -0.03106523]
[388.38102738 650.12233196 256.05018064]
[110.53969327  -6.03199814  70.20362199]
[ 0.4396769  -9.78694129  0.24992323]
transform [[ 0.68986928  0.01250837 -0.72382593]
 [-0.72254241 -0.05006774 -0.68951124]
 [-0.04486499  0.99866748 -0.02550237]]
zmp [14529772.04567351 13300472.92988028  9216265.62388415]
d1:32712129.36345, d2:0.05940, d3:14728581.96685
transform [[ 0.68883258 -0.71999234 -0.08438437]
 [ 0.03982246 -0.07864646  0.99610692]
 [-0.72382593 -0.68951124 -0.02550237]]
planes
[[ 0.68883258 -0.71999234 -0.08438437]
 [ 0.03982246 -0.07864646  0.99610692]
 [-0.72382593 -0.68951124 -0.02550237]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  90.72836 -489.72137  625.30145]
[  25.36728962 -127.97378755  -12.77368124]
[ 0.   0.  -9.8]
transform [[ 0.68883258 -0.71999234 -0.08438437]
 [ 0.03982246 -0.07864646  0.99610692]
 [-0.72382593 -0.68951124 -0.02550237]]
transform [[ 0.68883258 -0.71999234 -0.08438437]
 [ 0.03982246 -0.07864646  0.99610692]
 [-0.72382593 -0.68951124 -0.02550237]]
transform [[ 0.68883258 -0.71999234 -0.08438437]
 [ 0.03982246 -0.07864646  0.99610692]
 [-0.72382593 -0.68951124 -0.02550237]]
support
[-0.10279124  1.21338892 -0.03106523]
[362.32661883 664.99498442 256.05018064]
[110.69186139  -1.64907917  70.20362199]
[ 0.82696687 -9.76184784  0.24992323]
transform [[ 0.68883258  0.03982246 -0.72382593]
 [-0.71999234 -0.07864646 -0.68951124]
 [-0.08438437  0.99610692 -0.02550237]]
zmp [14767945.5712308  13051272.07418206  9193938.15573801]
d1:32693776.40298, d2:0.05940, d3:14715179.69682
transform [[ 0.56500959  0.06696048  0.82236272]
 [-0.79055947 -0.24136738  0.56281221]
 [ 0.23617771 -0.96812093 -0.08343866]]
planes
[[ 0.56500959  0.06696048  0.82236272]
 [-0.79055947 -0.24136738  0.56281221]
 [ 0.23617771 -0.96812093 -0.08343866]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 757.6011  -320.91507  677.64197]
[ 17.96524118 283.45476813  48.74692148]
[ 0.   0.  -9.8]
transform [[ 0.56500959  0.06696048  0.82236272]
 [-0.79055947 -0.24136738  0.56281221]
 [ 0.23617771 -0.96812093 -0.08343866]]
transform [[ 0.56500959  0.06696048  0.82236272]
 [-0.79055947 -0.24136738  0.56281221]
 [ 0.23617771 -0.96812093 -0.08343866]]
transform [[ 0.56500959  0.06696048  0.82236272]
 [-0.79055947 -0.24136738  0.56281221]
 [ 0.23617771 -0.96812093 -0.08343866]]
support
[ 1.00174569  0.68557911 -0.10163923]
[ 963.83073948 -140.08510023  433.0715494 ]
[  69.21845302  -55.18396508 -274.24288257]
[-8.05915467 -5.51555965  0.81769884]
transform [[ 0.56500959 -0.79055947  0.23617771]
 [ 0.06696048 -0.24136738 -0.96812093]
 [ 0.82236272  0.56281221 -0.08343866]]
zmp [-33027669.77231808  18808238.87612078  21160422.31574218]
d1:66583466.20537, d2:0.05940, d3:29995323.30942
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-299.89833212792644 steps:123[00m
[RDDPG] Resetting Environment
transform [[ 0.56341738  0.57338059  0.59480715]
 [-0.37638795 -0.46275783  0.80261284]
 [ 0.73545432 -0.67608428 -0.04491224]]
planes
[[ 0.56341738  0.57338059  0.59480715]
 [-0.37638795 -0.46275783  0.80261284]
 [ 0.73545432 -0.67608428 -0.04491224]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -71.44419 -310.83664 -894.961  ]
[-27.8586033  -49.45313029  11.73301289]
[ 0.   0.  -9.8]
transform [[ 0.56341738  0.57338059  0.59480715]
 [-0.37638795 -0.46275783  0.80261284]
 [ 0.73545432 -0.67608428 -0.04491224]]
transform [[ 0.56341738  0.57338059  0.59480715]
 [-0.37638795 -0.46275783  0.80261284]
 [ 0.73545432 -0.67608428 -0.04491224]]
transform [[ 0.56341738  0.57338059  0.59480715]
 [-0.37638795 -0.46275783  0.80261284]
 [ 0.73545432 -0.67608428 -0.04491224]]
support
[ 0.72455314  0.97768774 -0.054709  ]
[-750.80979317 -547.57436944  197.802531  ]
[-37.07260621  42.78753256  12.41879791]
[-5.82911005 -7.86560584  0.44013997]
transform [[ 0.56341738 -0.37638795  0.73545432]
 [ 0.57338059 -0.46275783 -0.67608428]
 [ 0.59480715  0.80261284 -0.04491224]]
zmp [-12597094.65988715    308163.46887019  11635244.66947088]
d1:27448022.67902, d2:0.05940, d3:10978452.80499
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-110.30248234284747 steps:125[00m
[RDDPG] Resetting Environment
transform [[ 0.53289819 -0.38776726 -0.75210112]
 [ 0.4806349  -0.59281117  0.64619273]
 [-0.69642633 -0.70584095 -0.1295335 ]]
planes
[[ 0.53289819 -0.38776726 -0.75210112]
 [ 0.4806349  -0.59281117  0.64619273]
 [-0.69642633 -0.70584095 -0.1295335 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -71.44419 -310.83664 -894.961  ]
[-27.8586033  -49.45313029  11.73301289]
[ 0.   0.  -9.8]
transform [[ 0.53289819 -0.38776726 -0.75210112]
 [ 0.4806349  -0.59281117  0.64619273]
 [-0.69642633 -0.70584095 -0.1295335 ]]
transform [[ 0.53289819 -0.38776726 -0.75210112]
 [ 0.4806349  -0.59281117  0.64619273]
 [-0.69642633 -0.70584095 -0.1295335 ]]
transform [[ 0.53289819 -0.38776726 -0.75210112]
 [ 0.4806349  -0.59281117  0.64619273]
 [-0.69642633 -0.70584095 -0.1295335 ]]
support
[-0.91615784  0.78714752 -0.1577888 ]
[ 755.56096296 -428.38843083  385.08427328]
[-4.49390679 23.50833856 52.78769092]
[ 7.37059101 -6.33268875  1.26942829]
transform [[ 0.53289819  0.4806349  -0.69642633]
 [-0.38776726 -0.59281117 -0.70584095]
 [-0.75210112  0.64619273 -0.1295335 ]]
zmp [-1330893.59195128 11559723.61439615 -6902946.63902141]
d1:20941885.27171, d2:0.05940, d3:7890168.91846
transform [[ 0.17455383 -0.55084854 -0.81614763]
 [ 0.9303844   0.3636317  -0.04644237]
 [ 0.32235983 -0.75122428  0.57597417]]
planes
[[ 0.17455383 -0.55084854 -0.81614763]
 [ 0.9303844   0.3636317  -0.04644237]
 [ 0.32235983 -0.75122428  0.57597417]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1668.2383  1453.8984  2648.8804]
[ 274.76880793 -275.37670067 -119.90220955]
[ 0.   0.  -9.8]
transform [[ 0.17455383 -0.55084854 -0.81614763]
 [ 0.9303844   0.3636317  -0.04644237]
 [ 0.32235983 -0.75122428  0.57597417]]
transform [[ 0.17455383 -0.55084854 -0.81614763]
 [ 0.9303844   0.3636317  -0.04644237]
 [ 0.32235983 -0.75122428  0.57597417]]
transform [[ 0.17455383 -0.55084854 -0.81614763]
 [ 0.9303844   0.3636317  -0.04644237]
 [ 0.32235983 -0.75122428  0.57597417]]
support
[-0.99417489 -0.05657291  0.7016121 ]
[-3253.95263729 -1146.4396087   -104.2901514 ]
[297.51070494 161.07345858 226.38351458]
[ 7.99824673  0.45513527 -5.64454683]
transform [[ 0.17455383  0.9303844   0.32235983]
 [-0.55084854  0.3636317  -0.75122428]
 [-0.81614763 -0.04644237  0.57597417]]
zmp [35677025.67091316  -489211.0217648   7960621.8382997 ]
d1:47114111.15150, d2:0.05940, d3:14457565.14468
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-388.36786786585117 steps:128[00m
[RDDPG] Resetting Environment
transform [[ 0.20572434 -0.08774834  0.97466803]
 [-0.97729218 -0.07009145  0.19996797]
 [ 0.05076903 -0.99367374 -0.1001753 ]]
planes
[[ 0.20572434 -0.08774834  0.97466803]
 [-0.97729218 -0.07009145  0.19996797]
 [ 0.05076903 -0.99367374 -0.1001753 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1668.2383  1453.8984  2648.8804]
[ 274.76880793 -275.37670067 -119.90220955]
[ 0.   0.  -9.8]
transform [[ 0.20572434 -0.08774834  0.97466803]
 [-0.97729218 -0.07009145  0.19996797]
 [ 0.05076903 -0.99367374 -0.1001753 ]]
transform [[ 0.20572434 -0.08774834  0.97466803]
 [-0.97729218 -0.07009145  0.19996797]
 [ 0.05076903 -0.99367374 -0.1001753 ]]
transform [[ 0.20572434 -0.08774834  0.97466803]
 [-0.97729218 -0.07009145  0.19996797]
 [ 0.05076903 -0.99367374 -0.1001753 ]]
support
[ 1.18727353  0.24358722 -0.12202666]
[ 2111.0046006   2058.14159758 -1794.74793045]
[ -36.17436851 -273.20445632  299.59558339]
[-9.55174665 -1.95968606  0.98171793]
transform [[ 0.20572434 -0.97729218  0.05076903]
 [-0.08774834 -0.07009145 -0.99367374]
 [ 0.97466803  0.19996797 -0.1001753 ]]
zmp [-2819549.08728606  5479873.95968731  1088472.96684601]
d1:7516371.46937, d2:0.05940, d3:1757582.22170
transform [[ 0.57485044 -0.81809372  0.01642239]
 [ 0.0662      0.0665022   0.99558783]
 [-0.8155762  -0.57122689  0.09238663]]
planes
[[ 0.57485044 -0.81809372  0.01642239]
 [ 0.0662      0.0665022   0.99558783]
 [-0.8155762  -0.57122689  0.09238663]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 335.56693  441.7347  -562.30115]
[ -38.16829642 -132.38743771   22.55431702]
[ 0.   0.  -9.8]
transform [[ 0.57485044 -0.81809372  0.01642239]
 [ 0.0662      0.0665022   0.99558783]
 [-0.8155762  -0.57122689  0.09238663]]
transform [[ 0.57485044 -0.81809372  0.01642239]
 [ 0.0662      0.0665022   0.99558783]
 [-0.8155762  -0.57122689  0.09238663]]
transform [[ 0.57485044 -0.81809372  0.01642239]
 [ 0.0662      0.0665022   0.99558783]
 [-0.8155762  -0.57122689  0.09238663]]
support
[0.02000463 1.21275659 0.11253903]
[-177.71392619 -508.22931593 -577.96024892]
[ 86.73466483  11.12400644 108.83613619]
[-0.16093943 -9.75676069 -0.90538893]
transform [[ 0.57485044  0.0662     -0.8155762 ]
 [-0.81809372  0.0665022  -0.57122689]
 [ 0.01642239  0.99558783  0.09238663]]
zmp [-11718952.5291314   -8417424.4807558   -9109330.19691882]
d1:26904496.19341, d2:0.05940, d3:12257047.69834
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-411.3049191752292 steps:131[00m
[RDDPG] Resetting Environment
transform [[ 0.22551449  0.22690193 -0.94744855]
 [ 0.64706659  0.69213396  0.31977403]
 [ 0.72831869 -0.68517596  0.00926558]]
planes
[[ 0.22551449  0.22690193 -0.94744855]
 [ 0.64706659  0.69213396  0.31977403]
 [ 0.72831869 -0.68517596  0.00926558]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[59.714085 30.183796 82.43282 ]
[ -81.64605705 -159.05521414   35.06576278]
[ 0.   0.  -9.8]
transform [[ 0.22551449  0.22690193 -0.94744855]
 [ 0.64706659  0.69213396  0.31977403]
 [ 0.72831869 -0.68517596  0.00926558]]
transform [[ 0.22551449  0.22690193 -0.94744855]
 [ 0.64706659  0.69213396  0.31977403]
 [ 0.72831869 -0.68517596  0.00926558]]
transform [[ 0.22551449  0.22690193 -0.94744855]
 [ 0.64706659  0.69213396  0.31977403]
 [ 0.72831869 -0.68517596  0.00926558]]
support
[-1.15411664  0.38952672  0.01128669]
[-57.78570615  85.89009581  23.57346069]
[ -87.72531041 -151.70483136   49.84136352]
[ 9.28499581 -3.13378551 -0.09080269]
transform [[ 0.22551449  0.64706659  0.72831869]
 [ 0.22690193  0.69213396 -0.68517596]
 [-0.94744855  0.31977403  0.00926558]]
zmp [  1445831.90720954 -18883145.5683926   -4178133.49595472]
d1:22701990.72752, d2:0.05940, d3:9209220.56227
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-141.26607146298244 steps:133[00m
[RDDPG] Resetting Environment
transform [[ 0.71527708  0.69583756 -0.06472167]
 [ 0.06159156  0.02948327  0.99766588]
 [ 0.69612157 -0.71759379 -0.02176901]]
planes
[[ 0.71527708  0.69583756 -0.06472167]
 [ 0.06159156  0.02948327  0.99766588]
 [ 0.69612157 -0.71759379 -0.02176901]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[393.96146 215.87975 713.4718 ]
[  38.06677127 -339.18990304   24.93308794]
[ 0.   0.  -9.8]
transform [[ 0.71527708  0.69583756 -0.06472167]
 [ 0.06159156  0.02948327  0.99766588]
 [ 0.69612157 -0.71759379 -0.02176901]]
transform [[ 0.71527708  0.69583756 -0.06472167]
 [ 0.06159156  0.02948327  0.99766588]
 [ 0.69612157 -0.71759379 -0.02176901]]
transform [[ 0.71527708  0.69583756 -0.06472167]
 [ 0.06159156  0.02948327  0.99766588]
 [ 0.69612157 -0.71759379 -0.02176901]]
support
[-0.07883948  1.21528794 -0.02651751]
[385.83174935 742.43601748 103.79952718]
[-210.40649576   17.21905435  269.35689974]
[ 0.63427233 -9.77712564  0.21333633]
transform [[ 0.71527708  0.06159156  0.69612157]
 [ 0.69583756  0.02948327 -0.71759379]
 [-0.06472167  0.99766588 -0.02176901]]
zmp [-15880506.18904322  16286309.50534352   -406907.43107201]
d1:31726952.58864, d2:0.05940, d3:10671836.62247
transform [[ 0.11746306  0.14375706 -0.98261708]
 [ 0.70824939  0.68146396  0.18436317]
 [ 0.69612157 -0.71759379 -0.02176901]]
planes
[[ 0.11746306  0.14375706 -0.98261708]
 [ 0.70824939  0.68146396  0.18436317]
 [ 0.69612157 -0.71759379 -0.02176901]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[393.96146 215.87975 713.4718 ]
[  38.06677127 -339.18990304   24.93308794]
[ 0.   0.  -9.8]
transform [[ 0.11746306  0.14375706 -0.98261708]
 [ 0.70824939  0.68146396  0.18436317]
 [ 0.69612157 -0.71759379 -0.02176901]]
transform [[ 0.11746306  0.14375706 -0.98261708]
 [ 0.70824939  0.68146396  0.18436317]
 [ 0.69612157 -0.71759379 -0.02176901]]
transform [[ 0.11746306  0.14375706 -0.98261708]
 [ 0.70824939  0.68146396  0.18436317]
 [ 0.69612157 -0.71759379 -0.02176901]]
support
[-1.19695652  0.22457853 -0.02651751]
[-623.75942303  557.67515083  103.79952718]
[ -68.78918195 -199.58818274  269.35689974]
[ 9.62964739 -1.80675908  0.21333633]
transform [[ 0.11746306  0.70824939  0.69612157]
 [ 0.14375706  0.68146396 -0.71759379]
 [-0.98261708  0.18436317 -0.02176901]]
zmp [-16465013.91159031  15696990.46124778    328227.85864319]
d1:31671590.71070, d2:0.05940, d3:10669592.37988
transform [[ 0.98654646  0.16210988  0.02113111]
 [-0.01186431 -0.05792033  0.99825078]
 [ 0.16305049 -0.98507136 -0.05521776]]
planes
[[ 0.98654646  0.16210988  0.02113111]
 [-0.01186431 -0.05792033  0.99825078]
 [ 0.16305049 -0.98507136 -0.05521776]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[393.96146 215.87975 713.4718 ]
[  38.06677127 -339.18990304   24.93308794]
[ 0.   0.  -9.8]
transform [[ 0.98654646  0.16210988  0.02113111]
 [-0.01186431 -0.05792033  0.99825078]
 [ 0.16305049 -0.98507136 -0.05521776]]
transform [[ 0.98654646  0.16210988  0.02113111]
 [-0.01186431 -0.05792033  0.99825078]
 [ 0.16305049 -0.98507136 -0.05521776]]
transform [[ 0.98654646  0.16210988  0.02113111]
 [-0.01186431 -0.05792033  0.99825078]
 [ 0.16305049 -0.98507136 -0.05521776]]
support
[ 0.02574047  1.21600042 -0.06726248]
[ 438.73397088  695.04587946 -187.81766297]
[-16.90453286  44.08382828 338.95631577]
[-0.20708489 -9.78285767  0.54113406]
transform [[ 0.98654646 -0.01186431  0.16305049]
 [ 0.16210988 -0.05792033 -0.98507136]
 [ 0.02113111  0.99825078 -0.05521776]]
zmp [  588338.76338518 -2344292.21874294 -9483165.06126304]
d1:19272984.00418, d2:0.05940, d3:4550325.54759
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-373.3442431972324 steps:137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-226.92975548831873 steps:138[00m
[RDDPG] Resetting Environment
transform [[ 0.67830777  0.71028829  0.18812007]
 [-0.1130183  -0.1521212   0.98187882]
 [ 0.72603399 -0.68727708 -0.02290944]]
planes
[[ 0.67830777  0.71028829  0.18812007]
 [-0.1130183  -0.1521212   0.98187882]
 [ 0.72603399 -0.68727708 -0.02290944]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 909.164   -439.5868   626.22736]
[ -65.99053299 -177.85362461 -109.65573557]
[ 0.   0.  -9.8]
transform [[ 0.67830777  0.71028829  0.18812007]
 [-0.1130183  -0.1521212   0.98187882]
 [ 0.72603399 -0.68727708 -0.02290944]]
transform [[ 0.67830777  0.71028829  0.18812007]
 [-0.1130183  -0.1521212   0.98187882]
 [ 0.72603399 -0.68727708 -0.02290944]]
transform [[ 0.67830777  0.71028829  0.18812007]
 [-0.1130183  -0.1521212   0.98187882]
 [ 0.72603399 -0.68727708 -0.02290944]]
support
[ 0.22915492  1.19605722 -0.02790671]
[422.26559104 578.9976727  947.8553705 ]
[-191.71768194  -73.15519879   76.83550158]
[-1.84357666 -9.62241241  0.22451253]
transform [[ 0.67830777 -0.1130183   0.72603399]
 [ 0.71028829 -0.1521212  -0.68727708]
 [ 0.18812007  0.98187882 -0.02290944]]
zmp [-11895313.97673318  12198029.87187344  -3165171.80769005]
d1:23843273.23168, d2:0.05940, d3:9568525.14007
transform [[ 0.11492494  0.08842446  0.98943084]
 [-0.6779874  -0.72099334  0.14318445]
 [ 0.72603399 -0.68727708 -0.02290944]]
planes
[[ 0.11492494  0.08842446  0.98943084]
 [-0.6779874  -0.72099334  0.14318445]
 [ 0.72603399 -0.68727708 -0.02290944]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 909.164   -439.5868   626.22736]
[ -65.99053299 -177.85362461 -109.65573557]
[ 0.   0.  -9.8]
transform [[ 0.11492494  0.08842446  0.98943084]
 [-0.6779874  -0.72099334  0.14318445]
 [ 0.72603399 -0.68727708 -0.02290944]]
transform [[ 0.11492494  0.08842446  0.98943084]
 [-0.6779874  -0.72099334  0.14318445]
 [ 0.72603399 -0.68727708 -0.02290944]]
transform [[ 0.11492494  0.08842446  0.98943084]
 [-0.6779874  -0.72099334  0.14318445]
 [ 0.72603399 -0.68727708 -0.02290944]]
support
[ 1.20525658  0.17441745 -0.02790671]
[ 685.22405356 -209.79656358  947.8553705 ]
[-131.80733551  157.27103197   76.83550158]
[-9.69642228 -1.40320764  0.22451253]
transform [[ 0.11492494 -0.6779874   0.72603399]
 [ 0.08842446 -0.72099334 -0.68727708]
 [ 0.98943084  0.14318445 -0.02290944]]
zmp [-9850687.79177796 14256782.30159374  -129931.85377523]
d1:22723940.57720, d2:0.05940, d3:8408883.38304
transform [[ 0.96413505 -0.2638478   0.02877413]
 [-0.02378679  0.02207823  0.99947327]
 [-0.26434413 -0.96431166  0.0150103 ]]
planes
[[ 0.96413505 -0.2638478   0.02877413]
 [-0.02378679  0.02207823  0.99947327]
 [-0.26434413 -0.96431166  0.0150103 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 909.164   -439.5868   626.22736]
[ -65.99053299 -177.85362461 -109.65573557]
[ 0.   0.  -9.8]
transform [[ 0.96413505 -0.2638478   0.02877413]
 [-0.02378679  0.02207823  0.99947327]
 [-0.26434413 -0.96431166  0.0150103 ]]
transform [[ 0.96413505 -0.2638478   0.02877413]
 [-0.02378679  0.02207823  0.99947327]
 [-0.26434413 -0.96431166  0.0150103 ]]
transform [[ 0.96413505 -0.2638478   0.02877413]
 [-0.02378679  0.02207823  0.99947327]
 [-0.26434413 -0.96431166  0.0150103 ]]
support
[0.03505066 1.21748958 0.01828452]
[1010.56003356  594.56611306  192.96636833]
[ -19.85274674 -111.95496742  187.30456772]
[-0.28198645 -9.79483808 -0.14710098]
transform [[ 0.96413505 -0.02378679 -0.26434413]
 [-0.2638478   0.02207823 -0.96431166]
 [ 0.02877413  0.99947327  0.0150103 ]]
zmp [ -4044029.71277461 -13612932.88513062  10677930.23706052]
d1:30561270.42185, d2:0.05940, d3:7619885.79954
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-518.7762716826812 steps:142[00m
[RDDPG] Resetting Environment
transform [[ 0.70740122  0.70676982 -0.00775117]
 [ 0.03023657 -0.0193036   0.99935639]
 [ 0.70616531 -0.7071802  -0.03502569]]
planes
[[ 0.70740122  0.70676982 -0.00775117]
 [ 0.03023657 -0.0193036   0.99935639]
 [ 0.70616531 -0.7071802  -0.03502569]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 91.49644 405.82993 555.7238 ]
[  49.70058508 -314.28126856   -8.31479619]
[ 0.   0.  -9.8]
transform [[ 0.70740122  0.70676982 -0.00775117]
 [ 0.03023657 -0.0193036   0.99935639]
 [ 0.70616531 -0.7071802  -0.03502569]]
transform [[ 0.70740122  0.70676982 -0.00775117]
 [ 0.03023657 -0.0193036   0.99935639]
 [ 0.70616531 -0.7071802  -0.03502569]]
transform [[ 0.70740122  0.70676982 -0.00775117]
 [ 0.03023657 -0.0193036   0.99935639]
 [ 0.70616531 -0.7071802  -0.03502569]]
support
[-0.00944195  1.2173472  -0.04266588]
[ 347.24552402  550.29870554 -241.84788643]
[-186.90181312   -0.73990909  257.64155168]
[ 0.0759615  -9.79369261  0.34325172]
transform [[ 0.70740122  0.03023657  0.70616531]
 [ 0.70676982 -0.0193036  -0.7071802 ]
 [-0.00775117  0.99935639 -0.03502569]]
zmp [-10815074.17295046  10716078.10709145  -9907534.18525136]
d1:29095806.68698, d2:0.05940, d3:13132730.57085
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-241.91061922317925 steps:144[00m
[RDDPG] Resetting Environment
transform [[ 0.09216011  0.0201313   0.99554074]
 [-0.99574339  0.00318205  0.09211452]
 [-0.00131348 -0.99979228  0.02033886]]
planes
[[ 0.09216011  0.0201313   0.99554074]
 [-0.99574339  0.00318205  0.09211452]
 [-0.00131348 -0.99979228  0.02033886]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 91.49644 405.82993 555.7238 ]
[  49.70058508 -314.28126856   -8.31479619]
[ 0.   0.  -9.8]
transform [[ 0.09216011  0.0201313   0.99554074]
 [-0.99574339  0.00318205  0.09211452]
 [-0.00131348 -0.99979228  0.02033886]]
transform [[ 0.09216011  0.0201313   0.99554074]
 [-0.99574339  0.00318205  0.09211452]
 [-0.00131348 -0.99979228  0.02033886]]
transform [[ 0.09216011  0.0201313   0.99554074]
 [-0.99574339  0.00318205  0.09211452]
 [-0.00131348 -0.99979228  0.02033886]]
support
[1.21269923 0.11220757 0.0247754 ]
[ 569.84790212  -38.62536663 -394.56301352]
[-10.02419685 -51.25500207 313.98159127]
[-9.75629923 -0.90272233 -0.19932086]
transform [[ 0.09216011 -0.99574339 -0.00131348]
 [ 0.0201313   0.00318205 -0.99979228]
 [ 0.99554074  0.09211452  0.02033886]]
zmp [ 3553898.80171566 -7295261.06432304  -181473.86139303]
d1:9613443.67527, d2:0.05940, d3:2024727.96840
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-132.67346094231473 steps:146[00m
[RDDPG] Resetting Environment
transform [[ 0.27472338  0.06381277  0.95940351]
 [-0.96143359  0.00459915  0.27499878]
 [ 0.01313599 -0.99795133  0.06261524]]
planes
[[ 0.27472338  0.06381277  0.95940351]
 [-0.96143359  0.00459915  0.27499878]
 [ 0.01313599 -0.99795133  0.06261524]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-115.394356  896.562    -406.7251  ]
[  67.66782588 -272.11989982  -22.54296668]
[ 0.   0.  -9.8]
transform [[ 0.27472338  0.06381277  0.95940351]
 [-0.96143359  0.00459915  0.27499878]
 [ 0.01313599 -0.99795133  0.06261524]]
transform [[ 0.27472338  0.06381277  0.95940351]
 [-0.96143359  0.00459915  0.27499878]
 [ 0.01313599 -0.99795133  0.06261524]]
transform [[ 0.27472338  0.06381277  0.95940351]
 [-0.96143359  0.00459915  0.27499878]
 [ 0.01313599 -0.99795133  0.06261524]]
support
[1.16867935 0.3349846  0.07627358]
[-364.70291042    3.21852746 -921.70825897]
[-20.40259214 -72.50892997 271.03976633]
[-9.40215445 -2.69498808 -0.61362933]
transform [[ 0.27472338 -0.96143359  0.01313599]
 [ 0.06381277  0.00459915 -0.99795133]
 [ 0.95940351  0.27499878  0.06261524]]
zmp [ 6963572.30598358  7108595.27855796 -2466819.50703075]
d1:7747443.62691, d2:0.05940, d3:4131553.06256
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-238.04498423795712 steps:148[00m
[RDDPG] Resetting Environment
transform [[ 0.15127555 -0.16158992 -0.97519457]
 [ 0.68389481 -0.6952129   0.22128502]
 [-0.71372521 -0.70040548  0.0053418 ]]
planes
[[ 0.15127555 -0.16158992 -0.97519457]
 [ 0.68389481 -0.6952129   0.22128502]
 [-0.71372521 -0.70040548  0.0053418 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-115.394356  896.562    -406.7251  ]
[  67.66782588 -272.11989982  -22.54296668]
[ 0.   0.  -9.8]
transform [[ 0.15127555 -0.16158992 -0.97519457]
 [ 0.68389481 -0.6952129   0.22128502]
 [-0.71372521 -0.70040548  0.0053418 ]]
transform [[ 0.15127555 -0.16158992 -0.97519457]
 [ 0.68389481 -0.6952129   0.22128502]
 [-0.71372521 -0.70040548  0.0053418 ]]
transform [[ 0.15127555 -0.16158992 -0.97519457]
 [ 0.68389481 -0.6952129   0.22128502]
 [-0.71372521 -0.70040548  0.0053418 ]]
support
[-1.18791494  0.26955418  0.00650702]
[ 234.30437978 -792.22124762 -547.7697297 ]
[ 76.19209903 230.47051927 142.17761535]
[ 9.55690682 -2.16859315 -0.05234968]
transform [[ 0.15127555  0.68389481 -0.71372521]
 [-0.16158992 -0.6952129  -0.70040548]
 [-0.97519457  0.22128502  0.0053418 ]]
zmp [5896171.81705995 1583629.81617813  652226.70176831]
d1:7782355.56799, d2:0.05940, d3:2859183.15018
transform [[ 0.61659211  0.74924028 -0.24177112]
 [ 0.00774854  0.30130541  0.95349622]
 [ 0.78724468 -0.5897916   0.17997701]]
planes
[[ 0.61659211  0.74924028 -0.24177112]
 [ 0.00774854  0.30130541  0.95349622]
 [ 0.78724468 -0.5897916   0.17997701]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1201.2446  -151.62689 1102.4098 ]
[  469.43378048 -3381.82341699  -534.32689886]
[ 0.   0.  -9.8]
transform [[ 0.61659211  0.74924028 -0.24177112]
 [ 0.00774854  0.30130541  0.95349622]
 [ 0.78724468 -0.5897916   0.17997701]]
transform [[ 0.61659211  0.74924028 -0.24177112]
 [ 0.00774854  0.30130541  0.95349622]
 [ 0.78724468 -0.5897916   0.17997701]]
transform [[ 0.61659211  0.74924028 -0.24177112]
 [ 0.00774854  0.30130541  0.95349622]
 [ 0.78724468 -0.5897916   0.17997701]]
support
[-0.29450894  1.16148349  0.21923562]
[ 360.54213828 1014.76545893 1233.51013015]
[-2115.1643452  -1524.80295087  2267.96371531]
[ 2.36935695 -9.34426293 -1.76377474]
transform [[ 0.61659211  0.00774854  0.78724468]
 [ 0.74924028  0.30130541 -0.5897916 ]
 [-0.24177112  0.95349622  0.17997701]]
zmp [-7300351.90738714  8916281.72042128  9013061.64059921]
d1:23981219.25514, d2:0.05940, d3:10904067.22531
transform [[ 0.18722072  0.32569399 -0.9267534 ]
 [-0.41093141  0.88288593  0.22726192]
 [ 0.89223534  0.33828393  0.29913241]]
planes
[[ 0.18722072  0.32569399 -0.9267534 ]
 [-0.41093141  0.88288593  0.22726192]
 [ 0.89223534  0.33828393  0.29913241]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1201.2446  -151.62689 1102.4098 ]
[  469.43378048 -3381.82341699  -534.32689886]
[ 0.   0.  -9.8]
transform [[ 0.18722072  0.32569399 -0.9267534 ]
 [-0.41093141  0.88288593  0.22726192]
 [ 0.89223534  0.33828393  0.29913241]]
transform [[ 0.18722072  0.32569399 -0.9267534 ]
 [-0.41093141  0.88288593  0.22726192]
 [ 0.89223534  0.33828393  0.29913241]]
transform [[ 0.18722072  0.32569399 -0.9267534 ]
 [-0.41093141  0.88288593  0.22726192]
 [ 0.89223534  0.33828393  0.29913241]]
support
[-1.12890723  0.27683483  0.36438252]
[-846.148104   -376.96263639 1350.26646161]
[ -518.36257557 -3300.10156175  -885.00558649]
[ 9.08218334 -2.22716677 -2.93149759]
transform [[ 0.18722072 -0.41093141  0.89223534]
 [ 0.32569399  0.88288593  0.33828393]
 [-0.9267534   0.22726192  0.29913241]]
zmp [ 5960429.12156638 -7683915.91834574 -1496287.23348914]
d1:6979475.75727, d2:0.05940, d3:5019204.55395
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-667.8533621088161 steps:152[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 131, in train
    state, reward, done, info = self.env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1023, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
2021-05-04 15:40:02.958546: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:40:02.958587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620123009.633560159, 1.118000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620123009.636378640, 1.119000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620123009.636559024, 1.119000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620123011.223549067, 2.262000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620123012.186367290, 3.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620123013.261930266, 3.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620123014.470299525, 4.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[ 0.71150649 -0.702438   -0.01842487]
 [ 0.0026614  -0.02352678  0.99971974]
 [-0.70267457 -0.71135598 -0.01486998]]
planes
[[ 0.71150649 -0.702438   -0.01842487]
 [ 0.0026614  -0.02352678  0.99971974]
 [-0.70267457 -0.71135598 -0.01486998]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71150649 -0.702438   -0.01842487]
 [ 0.0026614  -0.02352678  0.99971974]
 [-0.70267457 -0.71135598 -0.01486998]]
transform [[ 0.71150649 -0.702438   -0.01842487]
 [ 0.0026614  -0.02352678  0.99971974]
 [-0.70267457 -0.71135598 -0.01486998]]
transform [[ 0.71150649 -0.702438   -0.01842487]
 [ 0.0026614  -0.02352678  0.99971974]
 [-0.70267457 -0.71135598 -0.01486998]]
support
[-0.02244391  1.21778981 -0.01811359]
[-9.35638323e-11  9.78854360e-09 -1.42890054e-08]
[-9.35638323e-11  9.78854360e-09 -1.42890054e-08]
[ 0.18056375 -9.79725344  0.14572585]
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 88, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 44, in step
    self.stability += 5e-6 * self.quadruped.get_stability_reward()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1193, in get_stability_reward
    self.compute_reward.stability_reward(
  File "/home/shandilya/Desktop/CNS/DDP/src/reward/__init__.py", line 22, in stability_reward
    zmp = self.zmp(com, force, torque, v_real, v_exp, eta)
  File "/home/shandilya/Desktop/CNS/DDP/src/reward/zmp.py", line 75, in __call__
    print('zmp_s {}'.format(zmp))
NameError: name 'zmp' is not defined
2021-05-04 15:45:14.687000: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:45:14.687037: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620123321.339574785, 0.934000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620123321.341488149, 0.936000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620123321.341885416, 0.936000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620123322.953747370, 2.032000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620123323.979786586, 2.800000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620123325.155108089, 3.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620123326.277309204, 4.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[ 0.71168083 -0.70242715 -0.01032113]
 [ 0.01850159  0.00405444  0.99982065]
 [-0.7022593  -0.71174413  0.01588148]]
planes
[[ 0.71168083 -0.70242715 -0.01032113]
 [ 0.01850159  0.00405444  0.99982065]
 [-0.7022593  -0.71174413  0.01588148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71168083 -0.70242715 -0.01032113]
 [ 0.01850159  0.00405444  0.99982065]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71168083 -0.70242715 -0.01032113]
 [ 0.01850159  0.00405444  0.99982065]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71168083 -0.70242715 -0.01032113]
 [ 0.01850159  0.00405444  0.99982065]
 [-0.7022593  -0.71174413  0.01588148]]
support
[-0.01257249  1.21791273  0.01934573]
[-1.06744654e-11  1.02237668e-08 -1.39812195e-08]
[-1.06744654e-11  1.02237668e-08 -1.39812195e-08]
[ 0.10114705 -9.79824237 -0.15563855]
zmp_s [ 0.00000000e+00  1.54741193e+04 -3.09507708e+07]
transform [[ 0.71168083  0.01850159 -0.7022593 ]
 [-0.70242715  0.00405444 -0.71174413]
 [-0.01032113  0.99982065  0.01588148]]
zmp [21735752.98585429 22029092.15140199  -476072.83855064]
d1:45130642.46077, d2:0.05940, d3:14228411.22629
transform [[ 0.71171236 -0.70241898 -0.00855656]
 [ 0.01724554  0.00529412  0.99983728]
 [-0.7022593  -0.71174413  0.01588148]]
planes
[[ 0.71171236 -0.70241898 -0.00855656]
 [ 0.01724554  0.00529412  0.99983728]
 [-0.7022593  -0.71174413  0.01588148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71171236 -0.70241898 -0.00855656]
 [ 0.01724554  0.00529412  0.99983728]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71171236 -0.70241898 -0.00855656]
 [ 0.01724554  0.00529412  0.99983728]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71171236 -0.70241898 -0.00855656]
 [ 0.01724554  0.00529412  0.99983728]
 [-0.7022593  -0.71174413  0.01588148]]
support
[-0.01042301  1.21793298  0.01934573]
[ 7.36817718e-12  1.02237694e-08 -1.39812195e-08]
[ 7.36817718e-12  1.02237694e-08 -1.39812195e-08]
[ 0.08385428 -9.79840534 -0.15563855]
zmp_s [ 0.00000000e+00  1.54741193e+04 -3.09507708e+07]
transform [[ 0.71171236  0.01724554 -0.7022593 ]
 [-0.70241898  0.00529412 -0.71174413]
 [-0.00855656  0.99983728  0.01588148]]
zmp [21735733.54957836 22029111.33443363  -476072.58122072]
d1:45130642.20377, d2:0.05940, d3:14228410.97823
transform [[ 0.71077013 -0.69968128  0.07247042]
 [-0.04046842  0.06218111  0.99724418]
 [-0.7022593  -0.71174413  0.01588148]]
planes
[[ 0.71077013 -0.69968128  0.07247042]
 [-0.04046842  0.06218111  0.99724418]
 [-0.7022593  -0.71174413  0.01588148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71077013 -0.69968128  0.07247042]
 [-0.04046842  0.06218111  0.99724418]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71077013 -0.69968128  0.07247042]
 [-0.04046842  0.06218111  0.99724418]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71077013 -0.69968128  0.07247042]
 [-0.04046842  0.06218111  0.99724418]
 [-0.7022593  -0.71174413  0.01588148]]
support
[0.08827848 1.21477425 0.01934573]
[ 8.35592672e-10  1.01895687e-08 -1.39812195e-08]
[ 8.35592672e-10  1.01895687e-08 -1.39812195e-08]
[-0.71021011 -9.77299296 -0.15563855]
zmp_s [ 0.00000000e+00  1.54741193e+04 -3.09507708e+07]
transform [[ 0.71077013 -0.04046842 -0.7022593 ]
 [-0.69968128  0.06218111 -0.71174413]
 [ 0.07247042  0.99724418  0.01588148]]
zmp [21734840.47697302 22029991.61045394  -476112.70716073]
d1:45130636.31190, d2:0.05940, d3:14228432.27070
transform [[ 0.71131235 -0.70056164  0.0569926 ]
 [-0.02943819  0.05132028  0.99824834]
 [-0.7022593  -0.71174413  0.01588148]]
planes
[[ 0.71131235 -0.70056164  0.0569926 ]
 [-0.02943819  0.05132028  0.99824834]
 [-0.7022593  -0.71174413  0.01588148]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71131235 -0.70056164  0.0569926 ]
 [-0.02943819  0.05132028  0.99824834]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71131235 -0.70056164  0.0569926 ]
 [-0.02943819  0.05132028  0.99824834]
 [-0.7022593  -0.71174413  0.01588148]]
transform [[ 0.71131235 -0.70056164  0.0569926 ]
 [-0.02943819  0.05132028  0.99824834]
 [-0.7022593  -0.71174413  0.01588148]]
support
[0.06942447 1.21599745 0.01934573]
[ 6.77433126e-10  1.02013043e-08 -1.39812195e-08]
[ 6.77433126e-10  1.02013043e-08 -1.39812195e-08]
[-0.5585275  -9.78283372 -0.15563855]
zmp_s [ 0.00000000e+00  1.54741193e+04 -3.09507708e+07]
transform [[ 0.71131235 -0.02943819 -0.7022593 ]
 [-0.70056164  0.05132028 -0.71174413]
 [ 0.0569926   0.99824834  0.01588148]]
zmp [21735011.16002057 22029823.5486665   -476097.16867762]
d1:45130636.54141, d2:0.05940, d3:14228423.24909
transform [[ 0.64300728  0.7091518   0.28921503]
 [-0.26595885 -0.14737059  0.95265305]
 [ 0.71819741 -0.68948221  0.09384482]]
planes
[[ 0.64300728  0.7091518   0.28921503]
 [-0.26595885 -0.14737059  0.95265305]
 [ 0.71819741 -0.68948221  0.09384482]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 74.95689 433.08157 280.72556]
[-19.6398757   44.50646255  14.6681375 ]
[ 0.   0.  -9.8]
transform [[ 0.64300728  0.7091518   0.28921503]
 [-0.26595885 -0.14737059  0.95265305]
 [ 0.71819741 -0.68948221  0.09384482]]
transform [[ 0.64300728  0.7091518   0.28921503]
 [-0.26595885 -0.14737059  0.95265305]
 [ 0.71819741 -0.68948221  0.09384482]]
transform [[ 0.64300728  0.7091518   0.28921503]
 [-0.26595885 -0.14737059  0.95265305]
 [ 0.71819741 -0.68948221  0.09384482]]
support
[0.35230185 1.1604564  0.11431531]
[ 436.50845222  183.67512199 -218.42355983]
[ 23.17550101  12.63810088 -43.41519324]
[-2.83430728 -9.33599989 -0.91967927]
zmp_s [       0.         -5238991.38106049  9841610.32164408]
transform [[ 0.64300728 -0.26595885  0.71819741]
 [ 0.7091518  -0.14737059 -0.68948221]
 [ 0.28921503  0.95265305  0.09384482]]
zmp [ 8461575.0972511  -6013541.99481438 -4067356.93632852]
d1:19028691.80207, d2:0.05940, d3:7181064.21679
transform [[ 0.91202712  0.1851562   0.36595601]
 [-0.22734791 -0.51441061  0.82685828]
 [ 0.34134957 -0.83731657 -0.42706156]]
planes
[[ 0.91202712  0.1851562   0.36595601]
 [-0.22734791 -0.51441061  0.82685828]
 [ 0.34134957 -0.83731657 -0.42706156]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 68.01817 438.24042 344.55338]
[-19.6398757   44.50646255  14.6681375 ]
[ 0.   0.  -9.8]
transform [[ 0.91202712  0.1851562   0.36595601]
 [-0.22734791 -0.51441061  0.82685828]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91202712  0.1851562   0.36595601]
 [-0.22734791 -0.51441061  0.82685828]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91202712  0.1851562   0.36595601]
 [-0.22734791 -0.51441061  0.82685828]
 [ 0.34134957 -0.83731657 -0.42706156]]
support
[ 0.44578243  1.00722187 -0.52021701]
[ 269.26872535   43.99749973 -490.87349122]
[ -4.30355891  -6.30104109 -50.23425949]
[-3.58636888 -8.10321116  4.18520327]
zmp_s [       0.          5536010.63607204 -1851969.47733016]
transform [[ 0.91202712 -0.22734791  0.34134957]
 [ 0.1851562  -0.51441061 -0.83731657]
 [ 0.36595601  0.82685828 -0.42706156]]
zmp [-1890769.43842511 -1297097.90032715  5368401.21410094]
d1:10463017.23189, d2:0.05940, d3:3229497.19760
transform [[ 0.91235912  0.18590952  0.3647444 ]
 [-0.22601172 -0.51413882  0.82739353]
 [ 0.34134957 -0.83731657 -0.42706156]]
planes
[[ 0.91235912  0.18590952  0.3647444 ]
 [-0.22601172 -0.51413882  0.82739353]
 [ 0.34134957 -0.83731657 -0.42706156]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 68.01817 438.24042 344.55338]
[-19.6398757   44.50646255  14.6681375 ]
[ 0.   0.  -9.8]
transform [[ 0.91235912  0.18590952  0.3647444 ]
 [-0.22601172 -0.51413882  0.82739353]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91235912  0.18590952  0.3647444 ]
 [-0.22601172 -0.51413882  0.82739353]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91235912  0.18590952  0.3647444 ]
 [-0.22601172 -0.51413882  0.82739353]
 [ 0.34134957 -0.83731657 -0.42706156]]
support
[ 0.44430653  1.00787388 -0.52021701]
[ 269.20398062   44.39191934 -490.87349122]
[ -4.29432345  -6.30733579 -50.23425949]
[-3.57449507 -8.10845661  4.18520327]
zmp_s [       0.          5536010.63629817 -1851969.4799002 ]
transform [[ 0.91235912 -0.22601172  0.34134957]
 [ 0.18590952 -0.51413882 -0.83731657]
 [ 0.3647444   0.82739353 -0.42706156]]
zmp [-1883372.29322186 -1295593.22621116  5371364.36347359]
d1:10470172.86542, d2:0.05940, d3:3228523.47526
transform [[ 0.91231316  0.18580504  0.36491251]
 [-0.22619711 -0.51417661  0.82731938]
 [ 0.34134957 -0.83731657 -0.42706156]]
planes
[[ 0.91231316  0.18580504  0.36491251]
 [-0.22619711 -0.51417661  0.82731938]
 [ 0.34134957 -0.83731657 -0.42706156]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 68.01817 438.24042 344.55338]
[-19.6398757   44.50646255  14.6681375 ]
[ 0.   0.  -9.8]
transform [[ 0.91231316  0.18580504  0.36491251]
 [-0.22619711 -0.51417661  0.82731938]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91231316  0.18580504  0.36491251]
 [-0.22619711 -0.51417661  0.82731938]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91231316  0.18580504  0.36491251]
 [-0.22619711 -0.51417661  0.82731938]
 [ 0.34134957 -0.83731657 -0.42706156]]
support
[ 0.44451131  1.00778355 -0.52021701]
[ 269.21298899   44.33720095 -490.87349122]
[ -4.29560531  -6.30646433 -50.23425949]
[-3.5761426  -8.10772996  4.18520327]
zmp_s [       0.          5536010.63626667 -1851969.47954362]
transform [[ 0.91231316 -0.22619711  0.34134957]
 [ 0.18580504 -0.51417661 -0.83731657]
 [ 0.36491251  0.82731938 -0.42706156]]
zmp [-1884398.58834257 -1295802.42870822  5370953.87819261]
d1:10469181.38114, d2:0.05940, d3:3228658.82724
transform [[ 0.91239846  0.18599902  0.36460039]
 [-0.22585294 -0.51410651  0.82745701]
 [ 0.34134957 -0.83731657 -0.42706156]]
planes
[[ 0.91239846  0.18599902  0.36460039]
 [-0.22585294 -0.51410651  0.82745701]
 [ 0.34134957 -0.83731657 -0.42706156]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 68.01817 438.24042 344.55338]
[-19.6398757   44.50646255  14.6681375 ]
[ 0.   0.  -9.8]
transform [[ 0.91239846  0.18599902  0.36460039]
 [-0.22585294 -0.51410651  0.82745701]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91239846  0.18599902  0.36460039]
 [-0.22585294 -0.51410651  0.82745701]
 [ 0.34134957 -0.83731657 -0.42706156]]
transform [[ 0.91239846  0.18599902  0.36460039]
 [-0.22585294 -0.51410651  0.82745701]
 [ 0.34134957 -0.83731657 -0.42706156]]
support
[ 0.44413111  1.0079512  -0.52021701]
[ 269.19625997   44.43874929 -490.87349122]
[ -4.29322518  -6.30808542 -50.23425949]
[-3.57308382 -8.10907871  4.18520327]
zmp_s [       0.          5536010.63632525 -1851969.48020566]
transform [[ 0.91239846 -0.22585294  0.34134957]
 [ 0.18599902 -0.51410651 -0.83731657]
 [ 0.36460039  0.82745701 -0.42706156]]
zmp [-1882493.24806423 -1295414.3811738   5371715.78375047]
d1:10471021.81536, d2:0.05940, d3:3228407.40791
transform [[ 0.605744   -0.700284    0.3777256 ]
 [ 0.00791924  0.4800154   0.87722433]
 [-0.79562032 -0.52838194  0.29631209]]
planes
[[ 0.605744   -0.700284    0.3777256 ]
 [ 0.00791924  0.4800154   0.87722433]
 [-0.79562032 -0.52838194  0.29631209]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[ 0.605744   -0.700284    0.3777256 ]
 [ 0.00791924  0.4800154   0.87722433]
 [-0.79562032 -0.52838194  0.29631209]]
transform [[ 0.605744   -0.700284    0.3777256 ]
 [ 0.00791924  0.4800154   0.87722433]
 [-0.79562032 -0.52838194  0.29631209]]
transform [[ 0.605744   -0.700284    0.3777256 ]
 [ 0.00791924  0.4800154   0.87722433]
 [-0.79562032 -0.52838194  0.29631209]]
support
[0.46011934 1.06857432 0.36094701]
[ 106.69948721  237.26094559 -227.48318139]
[-48.33945324  28.55649105 -26.54283938]
[-3.70171089 -8.5967984  -2.90385852]
zmp_s [       0.         -2491615.44522816   661659.97990263]
transform [[ 0.605744    0.00791924 -0.79562032]
 [-0.700284    0.4800154  -0.52838194]
 [ 0.3777256   0.87722433  0.29631209]]
zmp [ -546161.81968271 -1545622.96354276 -1989647.82593923]
d1:4479079.27260, d2:0.05940, d3:1306443.34111
transform [[-0.44588843  0.6163938   0.64903182]
 [-0.77757597  0.09240949 -0.62196147]
 [-0.4433499  -0.78199691  0.43808869]]
planes
[[-0.44588843  0.6163938   0.64903182]
 [-0.77757597  0.09240949 -0.62196147]
 [-0.4433499  -0.78199691  0.43808869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[-0.44588843  0.6163938   0.64903182]
 [-0.77757597  0.09240949 -0.62196147]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44588843  0.6163938   0.64903182]
 [-0.77757597  0.09240949 -0.62196147]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44588843  0.6163938   0.64903182]
 [-0.77757597  0.09240949 -0.62196147]
 [-0.4433499  -0.78199691  0.43808869]]
support
[ 0.79060591 -0.75763068  0.5336495 ]
[ 105.36772394 -290.31689318 -155.04795103]
[ 40.80209645  12.53037639 -45.10961051]
[-6.36051182  6.09522245 -4.29326912]
zmp_s [       0.         -4012626.53240555  -169110.786147  ]
transform [[-0.44588843 -0.77757597 -0.4433499 ]
 [ 0.6163938   0.09240949 -0.78199691]
 [ 0.64903182 -0.62196147  0.43808869]]
zmp [3195097.21672887 -238560.66609052 2421613.5924175 ]
d1:6993230.30064, d2:0.05940, d3:2213929.96205
transform [[-0.44684997  0.61650771  0.64826179]
 [-0.77702379  0.09164688 -0.62276393]
 [-0.4433499  -0.78199691  0.43808869]]
planes
[[-0.44684997  0.61650771  0.64826179]
 [-0.77702379  0.09164688 -0.62276393]
 [-0.4433499  -0.78199691  0.43808869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[-0.44684997  0.61650771  0.64826179]
 [-0.77702379  0.09164688 -0.62276393]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44684997  0.61650771  0.64826179]
 [-0.77702379  0.09164688 -0.62276393]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44684997  0.61650771  0.64826179]
 [-0.77702379  0.09164688 -0.62276393]
 [-0.4433499  -0.78199691  0.43808869]]
support
[ 0.78966791 -0.75860818  0.5336495 ]
[ 105.00849569 -290.44703083 -155.04795103]
[ 40.8175697   12.47989075 -45.10961051]
[-6.3529655   6.10308653 -4.29326912]
zmp_s [       0.         -4012626.52539193  -169110.78318681]
transform [[-0.44684997 -0.77702379 -0.4433499 ]
 [ 0.61650771  0.09164688 -0.78199691]
 [ 0.64826179 -0.62276393  0.43808869]]
zmp [3192881.52816372 -235500.59211186 2424833.55093045]
d1:6994714.64060, d2:0.05940, d3:2214239.28696
transform [[-0.44299799  0.61604649  0.65133679]
 [-0.77922636  0.09469769 -0.61954719]
 [-0.4433499  -0.78199691  0.43808869]]
planes
[[-0.44299799  0.61604649  0.65133679]
 [-0.77922636  0.09469769 -0.61954719]
 [-0.4433499  -0.78199691  0.43808869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[-0.44299799  0.61604649  0.65133679]
 [-0.77922636  0.09469769 -0.61954719]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44299799  0.61604649  0.65133679]
 [-0.77922636  0.09469769 -0.61954719]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44299799  0.61604649  0.65133679]
 [-0.77922636  0.09469769 -0.61954719]
 [-0.4433499  -0.78199691  0.43808869]]
support
[ 0.79341366 -0.75468976  0.5336495 ]
[ 106.44502617 -289.92365091 -155.04795103]
[ 40.75529104  12.68179966 -45.10961051]
[-6.38310053  6.07156245 -4.29326912]
zmp_s [       0.         -4012626.55314535  -169110.79490838]
transform [[-0.44299799 -0.77922636 -0.4433499 ]
 [ 0.61604649  0.09469769 -0.78199691]
 [ 0.65133679 -0.61954719  0.43808869]]
zmp [3201719.64755178 -247742.35307886 2411925.97281987]
d1:6988787.12652, d2:0.05940, d3:2212980.93798
transform [[-0.44359308  0.61611867  0.65086323]
 [-0.77888763  0.09422705 -0.62004459]
 [-0.4433499  -0.78199691  0.43808869]]
planes
[[-0.44359308  0.61611867  0.65086323]
 [-0.77888763  0.09422705 -0.62004459]
 [-0.4433499  -0.78199691  0.43808869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[-0.44359308  0.61611867  0.65086323]
 [-0.77888763  0.09422705 -0.62004459]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44359308  0.61611867  0.65086323]
 [-0.77888763  0.09422705 -0.62004459]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44359308  0.61611867  0.65086323]
 [-0.77888763  0.09422705 -0.62004459]
 [-0.4433499  -0.78199691  0.43808869]]
support
[ 0.79283681 -0.75529566  0.5336495 ]
[ 106.2235155  -290.00486281 -155.04795103]
[ 40.76496797  12.65066099 -45.10961051]
[-6.37845966  6.07643697 -4.29326912]
zmp_s [       0.         -4012626.54891711  -169110.79312126]
transform [[-0.44359308 -0.77888763 -0.4433499 ]
 [ 0.61611867  0.09422705 -0.78199691]
 [ 0.65086323 -0.62004459  0.43808869]]
zmp [3200360.4336484  -245853.82854179 2413921.85448083]
d1:6989699.64405, d2:0.05940, d3:2213178.68109
transform [[-0.44543341  0.61633968  0.64939547]
 [-0.77783674  0.09277009 -0.62158173]
 [-0.4433499  -0.78199691  0.43808869]]
planes
[[-0.44543341  0.61633968  0.64939547]
 [-0.77783674  0.09277009 -0.62158173]
 [-0.4433499  -0.78199691  0.43808869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[247.5017  159.36699 181.02817]
[-7.93715998 61.58366111 -1.07356604]
[ 0.   0.  -9.8]
transform [[-0.44543341  0.61633968  0.64939547]
 [-0.77783674  0.09277009 -0.62158173]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44543341  0.61633968  0.64939547]
 [-0.77783674  0.09277009 -0.62158173]
 [-0.4433499  -0.78199691  0.43808869]]
transform [[-0.44543341  0.61633968  0.64939547]
 [-0.77783674  0.09277009 -0.62158173]
 [-0.4433499  -0.78199691  0.43808869]]
support
[ 0.79104888 -0.7571681   0.5336495 ]
[ 105.53754803 -290.25522258 -155.04795103]
[ 40.7947615   12.5542456  -45.10961051]
[-6.36407557  6.09150099 -4.29326912]
zmp_s [       0.         -4012626.53570442  -169110.78753989]
transform [[-0.44543341 -0.77783674 -0.4433499 ]
 [ 0.61633968  0.09277009 -0.78199691]
 [ 0.64939547 -0.62158173  0.43808869]]
zmp [3196143.59382087 -240007.62104436 2420089.83427589]
d1:6992529.72905, d2:0.05940, d3:2213782.70431
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.69798821  0.71565771 -0.02542672]
 [ 0.00405461  0.03155668  0.99949378]
 [ 0.71609783 -0.69773787  0.01912448]]
planes
[[ 0.69798821  0.71565771 -0.02542672]
 [ 0.00405461  0.03155668  0.99949378]
 [ 0.71609783 -0.69773787  0.01912448]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[107.66508 627.9337  653.8202 ]
[  20.29718815 -473.74598381   -0.63081265]
[ 0.   0.  -9.8]
transform [[ 0.69798821  0.71565771 -0.02542672]
 [ 0.00405461  0.03155668  0.99949378]
 [ 0.71609783 -0.69773787  0.01912448]]
transform [[ 0.69798821  0.71565771 -0.02542672]
 [ 0.00405461  0.03155668  0.99949378]
 [ 0.71609783 -0.69773787  0.01912448]]
transform [[ 0.69798821  0.71565771 -0.02542672]
 [ 0.00405461  0.03155668  0.99949378]
 [ 0.71609783 -0.69773787  0.01912448]]
support
[-0.03097309  1.21751455  0.02329612]
[ 507.91005436  673.74125819 -348.53043797]
[-324.85672882  -15.49804869  345.07322336]
[ 0.2491819  -9.79503902 -0.18741987]
zmp_s [        0.         -18297663.42108204   8526912.97154282]
transform [[ 0.69798821  0.00405461  0.71609783]
 [ 0.71565771  0.03155668 -0.69773787]
 [-0.02542672  0.99949378  0.01912448]]
zmp [  6031913.99837746  -6526963.70871651 -18125327.99225344]
d1:36909134.60733, d2:0.05940, d3:15373474.94834
transform [[ 0.14993772  0.13834545  0.97896844]
 [-0.98858392  0.03585161  0.14634396]
 [-0.01485158 -0.98973495  0.14214155]]
planes
[[ 0.14993772  0.13834545  0.97896844]
 [-0.98858392  0.03585161  0.14634396]
 [-0.01485158 -0.98973495  0.14214155]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[107.66508 627.9337  653.8202 ]
[  20.29718815 -473.74598381   -0.63081265]
[ 0.   0.  -9.8]
transform [[ 0.14993772  0.13834545  0.97896844]
 [-0.98858392  0.03585161  0.14634396]
 [-0.01485158 -0.98973495  0.14214155]]
transform [[ 0.14993772  0.13834545  0.97896844]
 [-0.98858392  0.03585161  0.14634396]
 [-0.01485158 -0.98973495  0.14214155]]
transform [[ 0.14993772  0.13834545  0.97896844]
 [-0.98858392  0.03585161  0.14634396]
 [-0.01485158 -0.98973495  0.14214155]]
support
[1.192512   0.17826615 0.17314706]
[ 743.08416153   11.75910639 -530.15192422]
[-63.11483297 -37.14234526 468.49184648]
[-9.59389073 -1.43417082 -1.3929872 ]
zmp_s [      0.         9363298.52276399  -11672.7603728 ]
transform [[ 0.14993772 -0.98858392 -0.01485158]
 [ 0.13834545  0.03585161 -0.98973495]
 [ 0.97896844  0.14634396  0.14214155]]
zmp [-9256233.02115691   347242.2561078   1368603.01293818]
d1:6929218.74433, d2:0.05940, d3:5194259.42702
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.1801828  -0.15254153 -0.97173315]
 [ 0.80116576 -0.55039048  0.23495513]
 [-0.57067305 -0.82085413  0.02304014]]
planes
[[ 0.1801828  -0.15254153 -0.97173315]
 [ 0.80116576 -0.55039048  0.23495513]
 [-0.57067305 -0.82085413  0.02304014]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[107.66508 627.9337  653.8202 ]
[  20.29718815 -473.74598381   -0.63081265]
[ 0.   0.  -9.8]
transform [[ 0.1801828  -0.15254153 -0.97173315]
 [ 0.80116576 -0.55039048  0.23495513]
 [-0.57067305 -0.82085413  0.02304014]]
transform [[ 0.1801828  -0.15254153 -0.97173315]
 [ 0.80116576 -0.55039048  0.23495513]
 [-0.57067305 -0.82085413  0.02304014]]
transform [[ 0.1801828  -0.15254153 -0.97173315]
 [ 0.80116576 -0.55039048  0.23495513]
 [-0.57067305 -0.82085413  0.02304014]]
support
[-1.18369847  0.28620618  0.02806592]
[-711.72533172 -105.73275797 -561.81943023]
[ 76.53612443 276.85847985 377.2787539 ]
[ 9.5229849  -2.30256029 -0.22579339]
zmp_s [        0.         -14787562.99440005 -15373934.41876932]
transform [[ 0.1801828   0.80116576 -0.57067305]
 [-0.15254153 -0.55039048 -0.82085413]
 [-0.97173315  0.23495513  0.02304014]]
zmp [-3073799.11636037 20758691.44546933 -3828631.44614826]
d1:24184054.40579, d2:0.05940, d3:7789069.25836
transform [[ 0.6144318   0.7886498   0.0224756 ]
 [-0.15588303  0.09342317  0.98334765]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.6144318   0.7886498   0.0224756 ]
 [-0.15588303  0.09342317  0.98334765]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.6144318   0.7886498   0.0224756 ]
 [-0.15588303  0.09342317  0.98334765]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.6144318   0.7886498   0.0224756 ]
 [-0.15588303  0.09342317  0.98334765]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.6144318   0.7886498   0.0224756 ]
 [-0.15588303  0.09342317  0.98334765]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[0.02737823 1.19784646 0.21967688]
[-147.89749962  368.76940934   29.54266069]
[  -7.71206041 -196.76895472  416.19963597]
[-0.22026085 -9.63680701 -1.76732477]
zmp_s [       0.          2669979.32415277 -4628375.44672616]
transform [[ 0.6144318  -0.15588303  0.77341706]
 [ 0.7886498   0.09342317 -0.60770375]
 [ 0.0224756   0.98334765  0.18033926]]
zmp [-3995868.97494201  3062119.01389561  1790840.09373912]
d1:8069621.00783, d2:0.05940, d3:3374092.39031
transform [[ 0.45874625  0.34025168 -0.82084149]
 [ 0.43746769  0.71758276  0.5419383 ]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.45874625  0.34025168 -0.82084149]
 [ 0.43746769  0.71758276  0.5419383 ]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.45874625  0.34025168 -0.82084149]
 [ 0.43746769  0.71758276  0.5419383 ]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.45874625  0.34025168 -0.82084149]
 [ 0.43746769  0.71758276  0.5419383 ]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.45874625  0.34025168 -0.82084149]
 [ 0.43746769  0.71758276  0.5419383 ]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[-0.99989263  0.66015196  0.21967688]
[-390.95509041   70.842608     29.54266069]
[ 162.54190292 -111.16487769  416.19963597]
[ 8.04424661 -5.31099539 -1.76732477]
zmp_s [       0.          2669976.82596582 -4628376.56253737]
transform [[ 0.45874625  0.43746769  0.77341706]
 [ 0.34025168  0.71758276 -0.60770375]
 [-0.82084149  0.5419383   0.18033926]]
zmp [-2411636.76739431  4728611.11791119   612284.70215474]
d1:7134974.36031, d2:0.05940, d3:2512569.15673
transform [[ 0.48424962  0.38283268 -0.78672832]
 [ 0.40905797  0.69579834  0.59036964]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.48424962  0.38283268 -0.78672832]
 [ 0.40905797  0.69579834  0.59036964]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.48424962  0.38283268 -0.78672832]
 [ 0.40905797  0.69579834  0.59036964]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.48424962  0.38283268 -0.78672832]
 [ 0.40905797  0.69579834  0.59036964]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.48424962  0.38283268 -0.78672832]
 [ 0.40905797  0.69579834  0.59036964]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[-0.95833832  0.71914768  0.21967688]
[-385.98133362   94.24941783   29.54266069]
[ 155.55505656 -120.74820591  416.19963597]
[ 7.70993756 -5.78562249 -1.76732477]
zmp_s [       0.          2669976.84529479 -4628376.53148052]
transform [[ 0.48424962  0.40905797  0.77341706]
 [ 0.38283268  0.69579834 -0.60770375]
 [-0.78672832  0.59036964  0.18033926]]
zmp [-2487490.02807726  4670447.20315249   741595.26628617]
d1:7231803.51272, d2:0.05940, d3:2605234.62910
transform [[ 0.46064505  0.3433702  -0.81847608]
 [ 0.43546787  0.71609575  0.54550409]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.46064505  0.3433702  -0.81847608]
 [ 0.43546787  0.71609575  0.54550409]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.46064505  0.3433702  -0.81847608]
 [ 0.43546787  0.71609575  0.54550409]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.46064505  0.3433702  -0.81847608]
 [ 0.43546787  0.71609575  0.54550409]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.46064505  0.3433702  -0.81847608]
 [ 0.43546787  0.71609575  0.54550409]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[-0.99701125  0.66449556  0.21967688]
[-390.64319259   72.54271629   29.54266069]
[ 162.05675611 -111.8709254   416.19963597]
[ 8.02106559 -5.34594011 -1.76732477]
zmp_s [       0.          2669976.82715499 -4628376.56031858]
transform [[ 0.46064505  0.43546787  0.77341706]
 [ 0.3433702   0.71609575 -0.60770375]
 [-0.81847608  0.54550409  0.18033926]]
zmp [-2416976.25220501  4724640.81734468   621805.27524822]
d1:7141946.06084, d2:0.05940, d3:2519387.03111
transform [[ 0.31018344  0.11470956 -0.94373089]
 [ 0.55282217  0.7858358   0.27721795]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.31018344  0.11470956 -0.94373089]
 [ 0.55282217  0.7858358   0.27721795]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.31018344  0.11470956 -0.94373089]
 [ 0.55282217  0.7858358   0.27721795]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.31018344  0.11470956 -0.94373089]
 [ 0.55282217  0.7858358   0.27721795]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.31018344  0.11470956 -0.94373089]
 [ 0.55282217  0.7858358   0.27721795]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[-1.14958804  0.33768784  0.21967688]
[-394.53255249  -46.9958882    29.54266069]
[188.00630835 -58.57578481 416.19963597]
[ 9.24856273 -2.71673595 -1.76732477]
zmp_s [       0.          2669976.81625868 -4628376.71116481]
transform [[ 0.31018344  0.55282217  0.77341706]
 [ 0.11470956  0.7858358  -0.60770375]
 [-0.94373089  0.27721795  0.18033926]]
zmp [-2103643.10372113  4910845.23654376   -94512.52854663]
d1:6718152.99268, d2:0.05940, d3:2100258.31290
transform [[ 0.35834619  0.18447788 -0.91518086]
 [ 0.52289027  0.77244037  0.36044666]
 [ 0.77341706 -0.60770375  0.18033926]]
planes
[[ 0.35834619  0.18447788 -0.91518086]
 [ 0.52289027  0.77244037  0.36044666]
 [ 0.77341706 -0.60770375  0.18033926]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.35834619  0.18447788 -0.91518086]
 [ 0.52289027  0.77244037  0.36044666]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.35834619  0.18447788 -0.91518086]
 [ 0.52289027  0.77244037  0.36044666]
 [ 0.77341706 -0.60770375  0.18033926]]
transform [[ 0.35834619  0.18447788 -0.91518086]
 [ 0.52289027  0.77244037  0.36044666]
 [ 0.77341706 -0.60770375  0.18033926]]
support
[-1.11481036  0.43907132  0.21967688]
[-397.15381694  -11.54987241   29.54266069]
[182.01940237 -75.1428691  416.19963597]
[ 8.96877245 -3.53237728 -1.76732477]
zmp_s [       0.          2669976.80455346 -4628376.66651493]
transform [[ 0.35834619  0.52289027  0.77341706]
 [ 0.18447788  0.77244037 -0.60770375]
 [-0.91518086  0.36044666  0.18033926]]
zmp [-2183560.56207932  4875079.71640883   127706.19426071]
d1:6823442.06377, d2:0.05940, d3:2166381.36277
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:181.6507704212048[00m
[RDDPG] Resetting Environment
transform [[ 0.72180724 -0.6833021  -0.10996643]
 [ 0.09239868 -0.06232568  0.99376965]
 [-0.68589854 -0.72747087  0.01814908]]
planes
[[ 0.72180724 -0.6833021  -0.10996643]
 [ 0.09239868 -0.06232568  0.99376965]
 [-0.68589854 -0.72747087  0.01814908]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-125.509026 -100.140884  364.63214 ]
[ 347.83033153 -277.39090391 -118.60848218]
[ 0.   0.  -9.8]
transform [[ 0.72180724 -0.6833021  -0.10996643]
 [ 0.09239868 -0.06232568  0.99376965]
 [-0.68589854 -0.72747087  0.01814908]]
transform [[ 0.72180724 -0.6833021  -0.10996643]
 [ 0.09239868 -0.06232568  0.99376965]
 [-0.68589854 -0.72747087  0.01814908]]
transform [[ 0.72180724 -0.6833021  -0.10996643]
 [ 0.09239868 -0.06232568  0.99376965]
 [-0.68589854 -0.72747087  0.01814908]]
support
[-0.13395354  1.21054181  0.02210796]
[-62.26414295 357.00483426 165.55377161]
[453.65119239 -68.44186815 -38.93514846]
[ 1.07767106 -9.73894253 -0.17786096]
zmp_s [        0.            781928.75144804 -10016799.22136568]
transform [[ 0.72180724  0.09239868 -0.68589854]
 [-0.6833021  -0.06232568 -0.72747087]
 [-0.10996643  0.99376965  0.01814908]]
zmp [6942757.1705616  7238195.44903301  595261.38898193]
d1:14051115.70160, d2:0.05940, d3:4884835.57861
transform [[ 0.43379903  0.21901688  0.87398517]
 [-0.6450718  -0.60172379  0.47096816]
 [ 0.62904763 -0.76808864 -0.11974558]]
planes
[[ 0.43379903  0.21901688  0.87398517]
 [-0.6450718  -0.60172379  0.47096816]
 [ 0.62904763 -0.76808864 -0.11974558]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1160.1122    70.76696 1159.1826 ]
[-56.04097087 135.331732    39.70008022]
[ 0.   0.  -9.8]
transform [[ 0.43379903  0.21901688  0.87398517]
 [-0.6450718  -0.60172379  0.47096816]
 [ 0.62904763 -0.76808864 -0.11974558]]
transform [[ 0.43379903  0.21901688  0.87398517]
 [-0.6450718  -0.60172379  0.47096816]
 [ 0.62904763 -0.76808864 -0.11974558]]
transform [[ 0.43379903  0.21901688  0.87398517]
 [-0.6450718  -0.60172379  0.47096816]
 [ 0.62904763 -0.76808864 -0.11974558]]
support
[ 1.06462861  0.57370101 -0.14586583]
[1531.86311473 -244.99972166  536.60352596]
[  40.02669637  -26.58439889 -143.95311507]
[-8.56505468 -4.61548794  1.17350671]
zmp_s [       0.         17655302.84265731 19209035.46083149]
transform [[ 0.43379903 -0.6450718   0.62904763]
 [ 0.21901688 -0.60172379 -0.76808864]
 [ 0.87398517  0.47096816 -0.11974558]]
zmp [   694460.209695   -25377857.64249593   6014888.30453056]
d1:33582046.58731, d2:0.05940, d3:11684301.24899
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-316.3596487952578 steps:3[00m
[RDDPG] Resetting Environment
transform [[ 0.20657453  0.18472487 -0.96083492]
 [ 0.66529369  0.69354391  0.27637166]
 [ 0.71743387 -0.6963287   0.0203722 ]]
planes
[[ 0.20657453  0.18472487 -0.96083492]
 [ 0.66529369  0.69354391  0.27637166]
 [ 0.71743387 -0.6963287   0.0203722 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[158.01851 192.28996 510.86447]
[  41.98255345 -263.69041913  -22.08619228]
[ 0.   0.  -9.8]
transform [[ 0.20657453  0.18472487 -0.96083492]
 [ 0.66529369  0.69354391  0.27637166]
 [ 0.71743387 -0.6963287   0.0203722 ]]
transform [[ 0.20657453  0.18472487 -0.96083492]
 [ 0.66529369  0.69354391  0.27637166]
 [ 0.71743387 -0.6963287   0.0203722 ]]
transform [[ 0.20657453  0.18472487 -0.96083492]
 [ 0.66529369  0.69354391  0.27637166]
 [ 0.71743387 -0.6963287   0.0203722 ]]
support
[-1.17042299  0.33665694  0.02481602]
[-422.69308677  379.67871117  -10.12175389]
[ -18.81646667 -161.05415409  213.28496801]
[ 9.41618222 -2.70844225 -0.1996476 ]
zmp_s [       0.         13973148.78513882 -5282161.55625285]
transform [[ 0.20657453  0.66529369  0.71743387]
 [ 0.18472487  0.69354391 -0.6963287 ]
 [-0.96083492  0.27637166  0.0203722 ]]
zmp [ 5506646.15926785 13369112.94463712  3754173.01977671]
d1:20751158.07271, d2:0.05940, d3:6033527.31606
transform [[ 0.24245828  0.21361598 -0.94635206]
 [ 0.89192748 -0.43284404  0.13081051]
 [-0.38167965 -0.87579352 -0.29547659]]
planes
[[ 0.24245828  0.21361598 -0.94635206]
 [ 0.89192748 -0.43284404  0.13081051]
 [-0.38167965 -0.87579352 -0.29547659]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-143.60178 -203.14659  720.2373 ]
[  71.69423475 -433.77257016    3.00489913]
[ 0.   0.  -9.8]
transform [[ 0.24245828  0.21361598 -0.94635206]
 [ 0.89192748 -0.43284404  0.13081051]
 [-0.38167965 -0.87579352 -0.29547659]]
transform [[ 0.24245828  0.21361598 -0.94635206]
 [ 0.89192748 -0.43284404  0.13081051]
 [-0.38167965 -0.87579352 -0.29547659]]
transform [[ 0.24245828  0.21361598 -0.94635206]
 [ 0.89192748 -0.43284404  0.13081051]
 [-0.38167965 -0.87579352 -0.29547659]]
support
[-1.15278098  0.15934437 -0.35992925]
[-759.81085942   54.0630335    19.9110841 ]
[-78.12158566 252.0950035  351.64309659]
[ 9.27425023 -1.28194304  2.89567054]
zmp_s [      0.         -695566.8907021   628619.70665454]
transform [[ 0.24245828  0.89192748 -0.38167965]
 [ 0.21361598 -0.43284404 -0.87579352]
 [-0.94635206  0.13081051 -0.29547659]]
zmp [-860326.57669041 -249469.07852357 -276729.86713831]
d1:1055098.07260, d2:0.05940, d3:520575.15071
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-264.7834207950223 steps:6[00m
[RDDPG] Resetting Environment
transform [[ 0.67729294  0.65562278 -0.33381596]
 [ 0.21194576  0.26062009  0.9418897 ]
 [ 0.70452344 -0.70868611  0.03755967]]
planes
[[ 0.67729294  0.65562278 -0.33381596]
 [ 0.21194576  0.26062009  0.9418897 ]
 [ 0.70452344 -0.70868611  0.03755967]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1146.0153   413.07675 1586.889  ]
[   9.07799484 -640.01704109   22.20164995]
[ 0.   0.  -9.8]
transform [[ 0.67729294  0.65562278 -0.33381596]
 [ 0.21194576  0.26062009  0.9418897 ]
 [ 0.70452344 -0.70868611  0.03755967]]
transform [[ 0.67729294  0.65562278 -0.33381596]
 [ 0.21194576  0.26062009  0.9418897 ]
 [ 0.70452344 -0.70868611  0.03755967]]
transform [[ 0.67729294  0.65562278 -0.33381596]
 [ 0.21194576  0.26062009  0.9418897 ]
 [ 0.70452344 -0.70868611  0.03755967]]
support
[-0.40663164  1.14734523  0.04575261]
[ 517.28168483 1845.22361621  574.25588726]
[-420.87255523 -143.9657492   460.80073616]
[ 3.27139643 -9.23051909 -0.36808476]
zmp_s [      0.         2927051.44632315  187546.10810877]
transform [[ 0.67729294  0.21194576  0.70452344]
 [ 0.65562278  0.26062009 -0.70868611]
 [-0.33381596  0.9418897   0.03755967]]
zmp [ 752506.76538534  629937.08129071 2764003.78807436]
d1:5721060.37809, d2:0.05940, d3:1875992.87017
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-443.94791995468654 steps:8[00m
[RDDPG] Resetting Environment
transform [[ 0.3347522  -0.3255077   0.88429958]
 [-0.66980159  0.57788891  0.4662728 ]
 [-0.66280228 -0.74839109 -0.02457597]]
planes
[[ 0.3347522  -0.3255077   0.88429958]
 [-0.66980159  0.57788891  0.4662728 ]
 [-0.66280228 -0.74839109 -0.02457597]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1146.0153   413.07675 1586.889  ]
[   9.07799484 -640.01704109   22.20164995]
[ 0.   0.  -9.8]
transform [[ 0.3347522  -0.3255077   0.88429958]
 [-0.66980159  0.57788891  0.4662728 ]
 [-0.66280228 -0.74839109 -0.02457597]]
transform [[ 0.3347522  -0.3255077   0.88429958]
 [-0.66980159  0.57788891  0.4662728 ]
 [-0.66280228 -0.74839109 -0.02457597]]
transform [[ 0.3347522  -0.3255077   0.88429958]
 [-0.66980159  0.57788891  0.4662728 ]
 [-0.66280228 -0.74839109 -0.02457597]]
support
[ 1.0771929   0.56798145 -0.02993676]
[ 1652.45677188   211.03282332 -1107.72383151]
[ 231.0022637  -365.58717759  472.42050931]
[-8.66613585 -4.56947345  0.24084455]
zmp_s [       0.          -426091.38596312 -8749939.52659673]
transform [[ 0.3347522  -0.66980159 -0.66280228]
 [-0.3255077   0.57788891 -0.74839109]
 [ 0.88429958  0.4662728  -0.02457597]]
zmp [6084876.54830913 6302143.31080888   16363.46915577]
d1:11402047.20264, d2:0.05940, d3:3948158.48220
transform [[ 0.72404283 -0.1791091   0.66609454]
 [-0.65320706 -0.48822761  0.57875246]
 [ 0.22154589 -0.85413921 -0.47049299]]
planes
[[ 0.72404283 -0.1791091   0.66609454]
 [-0.65320706 -0.48822761  0.57875246]
 [ 0.22154589 -0.85413921 -0.47049299]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  70.508965  747.0662   1043.7687  ]
[ 169.55601986 -914.20554061  -67.19867868]
[ 0.   0.  -9.8]
transform [[ 0.72404283 -0.1791091   0.66609454]
 [-0.65320706 -0.48822761  0.57875246]
 [ 0.22154589 -0.85413921 -0.47049299]]
transform [[ 0.72404283 -0.1791091   0.66609454]
 [-0.65320706 -0.48822761  0.57875246]
 [ 0.22154589 -0.85413921 -0.47049299]]
transform [[ 0.72404283 -0.1791091   0.66609454]
 [-0.65320706 -0.48822761  0.57875246]
 [ 0.22154589 -0.85413921 -0.47049299]]
support
[ 0.81139054  0.70499643 -0.57312219]
[  612.49377238   193.28838015 -1113.56342582]
[241.74767629 296.69379199 850.03974363]
[-6.52772651 -5.67177409  4.61083129]
zmp_s [        0.         -30230248.94900728   2165392.65139016]
transform [[ 0.72404283 -0.65320706  0.22154589]
 [-0.1791091  -0.48822761 -0.85413921]
 [ 0.66609454  0.57875246 -0.47049299]]
zmp [ 20226345.9922377   12909695.30172144 -18514632.94861031]
d1:41397050.23402, d2:0.05940, d3:15085222.69543
transform [[ 0.7372098  -0.169118    0.65415663]
 [-0.6383096  -0.49177775  0.59221238]
 [ 0.22154589 -0.85413921 -0.47049299]]
planes
[[ 0.7372098  -0.169118    0.65415663]
 [-0.6383096  -0.49177775  0.59221238]
 [ 0.22154589 -0.85413921 -0.47049299]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  70.508965  747.0662   1043.7687  ]
[ 169.55601986 -914.20554061  -67.19867868]
[ 0.   0.  -9.8]
transform [[ 0.7372098  -0.169118    0.65415663]
 [-0.6383096  -0.49177775  0.59221238]
 [ 0.22154589 -0.85413921 -0.47049299]]
transform [[ 0.7372098  -0.169118    0.65415663]
 [-0.6383096  -0.49177775  0.59221238]
 [ 0.22154589 -0.85413921 -0.47049299]]
transform [[ 0.7372098  -0.169118    0.65415663]
 [-0.6383096  -0.49177775  0.59221238]
 [ 0.22154589 -0.85413921 -0.47049299]]
support
[ 0.79684859  0.72139238 -0.57312219]
[  608.42574752   205.73563763 -1113.56342582]
[235.64851259 301.56081762 850.03974363]
[-6.41073493 -5.80368131  4.61083129]
zmp_s [        0.         -30230248.95523565   2165392.64564621]
transform [[ 0.7372098  -0.6383096   0.22154589]
 [-0.169118   -0.49177775 -0.85413921]
 [ 0.65415663  0.59221238 -0.47049299]]
zmp [ 19775991.89794298  13017016.98766002 -18921529.70872877]
d1:41949818.80244, d2:0.05940, d3:15156145.21206
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-779.3340293001614 steps:12[00m
[RDDPG] Resetting Environment
transform [[ 0.3033824  -0.2751379   0.91228187]
 [-0.65451115  0.63563848  0.40936404]
 [-0.69251305 -0.72129256  0.01276069]]
planes
[[ 0.3033824  -0.2751379   0.91228187]
 [-0.65451115  0.63563848  0.40936404]
 [-0.69251305 -0.72129256  0.01276069]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  70.508965  747.0662   1043.7687  ]
[ 169.55601986 -914.20554061  -67.19867868]
[ 0.   0.  -9.8]
transform [[ 0.3033824  -0.2751379   0.91228187]
 [-0.65451115  0.63563848  0.40936404]
 [-0.69251305 -0.72129256  0.01276069]]
transform [[ 0.3033824  -0.2751379   0.91228187]
 [-0.65451115  0.63563848  0.40936404]
 [-0.69251305 -0.72129256  0.01276069]]
transform [[ 0.3033824  -0.2751379   0.91228187]
 [-0.65451115  0.63563848  0.40936404]
 [-0.69251305 -0.72129256  0.01276069]]
support
[1.11127901 0.49865911 0.0155442 ]
[ 768.05618704  855.9964986  -574.36247025]
[ 241.66876918 -719.58924512  541.13239247]
[-8.94036233 -4.01176764 -0.1250548 ]
zmp_s [        0.          10848249.53858255 -10557120.0913872 ]
transform [[ 0.3033824  -0.65451115 -0.69251305]
 [-0.2751379   0.63563848 -0.72129256]
 [ 0.91228187  0.40936404  0.01276069]]
zmp [  210643.0983373  14510336.92532503  4306167.12819159]
d1:18661731.40472, d2:0.05940, d3:7357777.42128
transform [[ 0.08790713 -0.42155442  0.90253216]
 [-0.85197502 -0.50128812 -0.15115863]
 [ 0.51615018 -0.75564688 -0.40322062]]
planes
[[ 0.08790713 -0.42155442  0.90253216]
 [-0.85197502 -0.50128812 -0.15115863]
 [ 0.51615018 -0.75564688 -0.40322062]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -74.95891  819.90283 1504.0579 ]
[  46.80715437 -345.53053728   13.59481494]
[ 0.   0.  -9.8]
transform [[ 0.08790713 -0.42155442  0.90253216]
 [-0.85197502 -0.50128812 -0.15115863]
 [ 0.51615018 -0.75564688 -0.40322062]]
transform [[ 0.08790713 -0.42155442  0.90253216]
 [-0.85197502 -0.50128812 -0.15115863]
 [ 0.51615018 -0.75564688 -0.40322062]]
transform [[ 0.08790713 -0.42155442  0.90253216]
 [-0.85197502 -0.50128812 -0.15115863]
 [ 0.51615018 -0.75564688 -0.40322062]]
support
[ 1.09940258 -0.18413104 -0.49117562]
[ 1005.23750857  -574.4957555  -1264.71422318]
[162.04436421 131.27685197 279.7768852 ]
[-8.84481517  1.48135458  3.95156211]
zmp_s [       0.           245746.51108342 13585952.03168036]
transform [[ 0.08790713 -0.85197502  0.51615018]
 [-0.42155442 -0.50128812 -0.75564688]
 [ 0.90253216 -0.15115863 -0.40322062]]
zmp [  6803021.64979766 -10389372.13045848  -5515282.75835296]
d1:14140932.03931, d2:0.05940, d3:8975271.15168
transform [[ 0.12482909 -0.42501381  0.89653832]
 [-0.23398036  0.86551028  0.44288281]
 [-0.96419442 -0.265057    0.00859598]]
planes
[[ 0.12482909 -0.42501381  0.89653832]
 [-0.23398036  0.86551028  0.44288281]
 [-0.96419442 -0.265057    0.00859598]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-449.72928 -747.92    -230.57922]
[ -25.45401795 -518.87517935  -45.96014397]
[ 0.   0.  -9.8]
transform [[ 0.12482909 -0.42501381  0.89653832]
 [-0.23398036  0.86551028  0.44288281]
 [-0.96419442 -0.265057    0.00859598]]
transform [[ 0.12482909 -0.42501381  0.89653832]
 [-0.23398036  0.86551028  0.44288281]
 [-0.96419442 -0.265057    0.00859598]]
transform [[ 0.12482909 -0.42501381  0.89653832]
 [-0.23398036  0.86551028  0.44288281]
 [-0.96419442 -0.265057    0.00859598]]
support
[1.0921013  0.53948936 0.01047103]
[  55.01391557 -644.22419363  629.88583049]
[ 176.14668503 -463.49102161  161.67904671]
[-8.78607551 -4.3402515  -0.08424059]
zmp_s [        0.         -18948557.63605542 -33647956.8943948 ]
transform [[ 0.12482909 -0.23398036 -0.96419442]
 [-0.42501381  0.86551028 -0.265057  ]
 [ 0.89653832  0.44288281  0.00859598]]
zmp [36876762.4736039  -7481545.0903357  -8681227.50221034]
d1:46825592.79665, d2:0.05940, d3:17071241.04323
transform [[ 0.32472089  0.84835255  0.41815582]
 [ 0.09737951 -0.4697524   0.87741101]
 [ 0.94078356 -0.24419382 -0.23515056]]
planes
[[ 0.32472089  0.84835255  0.41815582]
 [ 0.09737951 -0.4697524   0.87741101]
 [ 0.94078356 -0.24419382 -0.23515056]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 761.65204    68.789116 1024.5623  ]
[  60.18391956 -208.59365556  -59.27178681]
[ 0.   0.  -9.8]
transform [[ 0.32472089  0.84835255  0.41815582]
 [ 0.09737951 -0.4697524   0.87741101]
 [ 0.94078356 -0.24419382 -0.23515056]]
transform [[ 0.32472089  0.84835255  0.41815582]
 [ 0.09737951 -0.4697524   0.87741101]
 [ 0.94078356 -0.24419382 -0.23515056]]
transform [[ 0.32472089  0.84835255  0.41815582]
 [ 0.09737951 -0.4697524   0.87741101]
 [ 0.94078356 -0.24419382 -0.23515056]]
support
[ 0.50936865  1.06880172 -0.28644423]
[734.10841871 940.81764817 458.82545043]
[-182.2028266    51.84233269  121.49511804]
[-4.09792703 -8.59862788  2.3044755 ]
zmp_s [       0.         14246569.25191174 15145672.46281581]
transform [[ 0.32472089  0.09737951  0.94078356]
 [ 0.84835255 -0.4697524  -0.24419382]
 [ 0.41815582  0.87741101 -0.23515056]]
zmp [ 15636123.53307861 -10390839.76137371   8938583.31380381]
d1:32367887.40297, d2:0.05940, d3:11338248.57612
transform [[ 0.191523   -0.86366481 -0.46626395]
 [ 0.20417875 -0.42960554  0.87963074]
 [-0.96001565 -0.26367062  0.09406269]]
planes
[[ 0.191523   -0.86366481 -0.46626395]
 [ 0.20417875 -0.42960554  0.87963074]
 [-0.96001565 -0.26367062  0.09406269]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-196.07089 -564.6078  1262.592  ]
[ 390.38613846  187.71503746 -177.97391059]
[ 0.   0.  -9.8]
transform [[ 0.191523   -0.86366481 -0.46626395]
 [ 0.20417875 -0.42960554  0.87963074]
 [-0.96001565 -0.26367062  0.09406269]]
transform [[ 0.191523   -0.86366481 -0.46626395]
 [ 0.20417875 -0.42960554  0.87963074]
 [-0.96001565 -0.26367062  0.09406269]]
transform [[ 0.191523   -0.86366481 -0.46626395]
 [ 0.20417875 -0.42960554  0.87963074]
 [-0.96001565 -0.26367062  0.09406269]]
support
[-0.56797066  1.07150565  0.1145807 ]
[-138.62136205 1313.1399029   455.86442152]
[  -4.37212824 -157.48619021 -441.01245057]
[ 4.56938671 -8.6203813  -0.9218144 ]
zmp_s [        0.         -15386416.74553167  -2400328.38817109]
transform [[ 0.191523    0.20417875 -0.96001565]
 [-0.86366481 -0.42960554 -0.26367062]
 [-0.46626395  0.87963074  0.09406269]]
zmp [  -837226.5172671    7242986.01246664 -13760146.56967828]
d1:30917587.54055, d2:0.05940, d3:11166824.28009
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-474.7974392932236 steps:18[00m
[RDDPG] Resetting Environment
transform [[ 0.12192141 -0.0889212  -0.98854852]
 [ 0.71949178 -0.67816645  0.14973956]
 [-0.68371546 -0.729509   -0.01870492]]
planes
[[ 0.12192141 -0.0889212  -0.98854852]
 [ 0.71949178 -0.67816645  0.14973956]
 [-0.68371546 -0.729509   -0.01870492]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-196.07089 -564.6078  1262.592  ]
[ 390.38613846  187.71503746 -177.97391059]
[ 0.   0.  -9.8]
transform [[ 0.12192141 -0.0889212  -0.98854852]
 [ 0.71949178 -0.67816645  0.14973956]
 [-0.68371546 -0.729509   -0.01870492]]
transform [[ 0.12192141 -0.0889212  -0.98854852]
 [ 0.71949178 -0.67816645  0.14973956]
 [-0.68371546 -0.729509   -0.01870492]]
transform [[ 0.12192141 -0.0889212  -0.98854852]
 [ 0.71949178 -0.67816645  0.14973956]
 [-0.68371546 -0.729509   -0.01870492]]
support
[-1.20418179  0.18240243 -0.02278505]
[-1221.8331285    430.88664453   522.32647711]
[ 206.84042621  126.9278415  -400.52385986]
[ 9.68777547 -1.46744772  0.18330823]
zmp_s [        0.           6305723.92537883 -14589858.64657543]
transform [[ 0.12192141  0.71949178 -0.68371546]
 [-0.0889212  -0.67816645 -0.729509  ]
 [-0.98854852  0.14973956 -0.01870492]]
zmp [14512228.48507162  6367102.72989877  1217118.50140755]
d1:21062695.00445, d2:0.05940, d3:7270266.84444
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-281.14752025866017 steps:20[00m
[RDDPG] Resetting Environment
transform [[ 0.69189847  0.72037786  0.04829391]
 [-0.01497455 -0.05255696  0.99850565]
 [ 0.72183955 -0.69158775 -0.02557675]]
planes
[[ 0.69189847  0.72037786  0.04829391]
 [-0.01497455 -0.05255696  0.99850565]
 [ 0.72183955 -0.69158775 -0.02557675]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1093.2092   -579.1751   -663.98785]
[ 101.59760599 -394.89083774  -61.92632427]
[ 0.   0.  -9.8]
transform [[ 0.69189847  0.72037786  0.04829391]
 [-0.01497455 -0.05255696  0.99850565]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.69189847  0.72037786  0.04829391]
 [-0.01497455 -0.05255696  0.99850565]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.69189847  0.72037786  0.04829391]
 [-0.01497455 -0.05255696  0.99850565]
 [ 0.72183955 -0.69158775 -0.02557675]]
support
[ 0.05882832  1.21631089 -0.03115583]
[-1205.68128273  -616.18562533  -371.58859686]
[-217.1660541   -42.6009005   348.02270822]
[-0.47328029 -9.78535539  0.25065211]
zmp_s [        0.         -27565158.52568081 -19641324.01394766]
transform [[ 0.69189847 -0.01497455  0.72183955]
 [ 0.72037786 -0.05255696 -0.69158775]
 [ 0.04829391  0.99850565 -0.02557675]]
zmp [-13765108.60338507  15032439.98902837 -27021605.42761242]
d1:61035622.11698, d2:0.05940, d3:26361083.87296
transform [[ 0.68898177  0.7146551   0.12071568]
 [-0.06520693 -0.10475926  0.99235761]
 [ 0.72183955 -0.69158775 -0.02557675]]
planes
[[ 0.68898177  0.7146551   0.12071568]
 [-0.06520693 -0.10475926  0.99235761]
 [ 0.72183955 -0.69158775 -0.02557675]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1093.2092   -579.1751   -663.98785]
[ 101.59760599 -394.89083774  -61.92632427]
[ 0.   0.  -9.8]
transform [[ 0.68898177  0.7146551   0.12071568]
 [-0.06520693 -0.10475926  0.99235761]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.68898177  0.7146551   0.12071568]
 [-0.06520693 -0.10475926  0.99235761]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.68898177  0.7146551   0.12071568]
 [-0.06520693 -0.10475926  0.99235761]
 [ 0.72183955 -0.69158775 -0.02557675]]
support
[ 0.14704753  1.20882177 -0.03115583]
[-1247.26542146  -526.95462678  -371.58859686]
[-219.6873313   -26.7094549   348.02270822]
[-1.18301364 -9.72510459  0.25065211]
zmp_s [        0.         -27565158.57562646 -19641324.05349946]
transform [[ 0.68898177 -0.06520693  0.72183955]
 [ 0.7146551  -0.10475926 -0.69158775]
 [ 0.12071568  0.99235761 -0.02557675]]
zmp [-12380445.09352902  16471404.67549404 -26852133.77082053]
d1:60882699.99904, d2:0.05940, d3:26278959.79447
transform [[ 0.20146352  0.24534564 -0.9482711 ]
 [ 0.66208774  0.67934674  0.31642985]
 [ 0.72183955 -0.69158775 -0.02557675]]
planes
[[ 0.20146352  0.24534564 -0.9482711 ]
 [ 0.66208774  0.67934674  0.31642985]
 [ 0.72183955 -0.69158775 -0.02557675]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1093.2092   -579.1751   -663.98785]
[ 101.59760599 -394.89083774  -61.92632427]
[ 0.   0.  -9.8]
transform [[ 0.20146352  0.24534564 -0.9482711 ]
 [ 0.66208774  0.67934674  0.31642985]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.20146352  0.24534564 -0.9482711 ]
 [ 0.66208774  0.67934674  0.31642985]
 [ 0.72183955 -0.69158775 -0.02557675]]
transform [[ 0.20146352  0.24534564 -0.9482711 ]
 [ 0.66208774  0.67934674  0.31642985]
 [ 0.72183955 -0.69158775 -0.02557675]]
support
[-1.15511861  0.38545308 -0.03115583]
[  267.30062365 -1327.36672808  -371.58859686]
[ -17.69358946 -220.5966119   348.02270822]
[ 9.29305674 -3.10101256  0.25065211]
zmp_s [        0.         -27565166.4291305  -19641326.37949575]
transform [[ 0.20146352  0.66208774  0.72183955]
 [ 0.24534564  0.67934674 -0.69158775]
 [-0.9482711   0.31642985 -0.02557675]]
zmp [-32428444.84216727  -5142605.31590207  -8220080.35549687]
d1:42874131.93685, d2:0.05940, d3:13799920.85308
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:256.7736373274634 steps:24[00m
[RDDPG] Resetting Environment
transform [[ 0.72896731  0.67697906 -0.1015188 ]
 [ 0.05087588  0.09431221  0.99424189]
 [ 0.68265533 -0.72993469  0.03430862]]
planes
[[ 0.72896731  0.67697906 -0.1015188 ]
 [ 0.05087588  0.09431221  0.99424189]
 [ 0.68265533 -0.72993469  0.03430862]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 630.9128  -601.48676 -232.06256]
[   7.1162617  -273.76927658    8.35518428]
[ 0.   0.  -9.8]
transform [[ 0.72896731  0.67697906 -0.1015188 ]
 [ 0.05087588  0.09431221  0.99424189]
 [ 0.68265533 -0.72993469  0.03430862]]
transform [[ 0.72896731  0.67697906 -0.1015188 ]
 [ 0.05087588  0.09431221  0.99424189]
 [ 0.68265533 -0.72993469  0.03430862]]
transform [[ 0.72896731  0.67697906 -0.1015188 ]
 [ 0.05087588  0.09431221  0.99424189]
 [ 0.68265533 -0.72993469  0.03430862]]
support
[-0.12366322  1.21111707  0.0417924 ]
[  76.27956404 -255.35562444  861.78027895]
[-180.99675503  -17.15066611  204.97830154]
[ 0.99488426 -9.74357055 -0.33622447]
zmp_s [       0.          7258817.63427438 -9163274.80157327]
transform [[ 0.72896731  0.05087588  0.68265533]
 [ 0.67697906  0.09431221 -0.72993469]
 [-0.1015188   0.99424189  0.03430862]]
zmp [-5886059.69090601  7373187.33097974  6902641.27649378]
d1:18915525.70902, d2:0.05940, d3:8634890.54063
transform [[ 0.85512602  0.26386282 -0.44624642]
 [ 0.28304243  0.48353893  0.82829773]
 [ 0.43433449 -0.83460563  0.33880237]]
planes
[[ 0.85512602  0.26386282 -0.44624642]
 [ 0.28304243  0.48353893  0.82829773]
 [ 0.43433449 -0.83460563  0.33880237]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 630.9128  -601.48676 -232.06256]
[   7.1162617  -273.76927658    8.35518428]
[ 0.   0.  -9.8]
transform [[ 0.85512602  0.26386282 -0.44624642]
 [ 0.28304243  0.48353893  0.82829773]
 [ 0.43433449 -0.83460563  0.33880237]]
transform [[ 0.85512602  0.26386282 -0.44624642]
 [ 0.28304243  0.48353893  0.82829773]
 [ 0.43433449 -0.83460563  0.33880237]]
transform [[ 0.85512602  0.26386282 -0.44624642]
 [ 0.28304243  0.48353893  0.82829773]
 [ 0.43433449 -0.83460563  0.33880237]]
support
[-0.54358668  1.00897531  0.41270573]
[ 484.35703271 -304.48406586  697.40806866]
[ -69.8807034  -123.44331766  234.4109748 ]
[ 4.37321487 -8.1173178  -3.3202632 ]
zmp_s [       0.         19062012.18165405 15473199.93212022]
transform [[ 0.85512602  0.28304243  0.43433449]
 [ 0.26386282  0.48353893 -0.83460563]
 [-0.44624642  0.82829773  0.33880237]]
zmp [12115902.61579438 -3696794.95164286 21031378.26952228]
d1:42696160.48055, d2:0.05940, d3:15518835.37384
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-416.91636193331124 steps:27[00m
[RDDPG] Resetting Environment
transform [[ 0.12667036  0.09725712  0.98716551]
 [-0.70571417 -0.69051999  0.15858643]
 [ 0.69708115 -0.7167449  -0.01883269]]
planes
[[ 0.12667036  0.09725712  0.98716551]
 [-0.70571417 -0.69051999  0.15858643]
 [ 0.69708115 -0.7167449  -0.01883269]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 101.62549  277.93393 -226.7369 ]
[ 152.50413637 -419.86333027  -94.90504188]
[ 0.   0.  -9.8]
transform [[ 0.12667036  0.09725712  0.98716551]
 [-0.70571417 -0.69051999  0.15858643]
 [ 0.69708115 -0.7167449  -0.01883269]]
transform [[ 0.12667036  0.09725712  0.98716551]
 [-0.70571417 -0.69051999  0.15858643]
 [ 0.69708115 -0.7167449  -0.01883269]]
transform [[ 0.12667036  0.09725712  0.98716551]
 [-0.70571417 -0.69051999  0.15858643]
 [ 0.69708115 -0.7167449  -0.01883269]]
support
[ 1.20249711  0.19317908 -0.02294068]
[-183.92284903 -299.59487431 -124.09644972]
[-115.20392949  167.24904101  409.02997591]
[-9.674222   -1.55414699  0.18456032]
zmp_s [       0.         12683374.43543041 -5099640.15650222]
transform [[ 0.12667036 -0.70571417  0.69708115]
 [ 0.09725712 -0.69051999 -0.7167449 ]
 [ 0.98716551  0.15858643 -0.01883269]]
zmp [-12505700.0317164   -5102982.49702977   2107450.96009241]
d1:18438095.25148, d2:0.05940, d3:3837677.75446
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-107.5134209857342 steps:29[00m
[RDDPG] Resetting Environment
transform [[ 0.68057883  0.70887274  0.18523483]
 [-0.13021538 -0.131768    0.98269081]
 [ 0.72101068 -0.69291896  0.00262761]]
planes
[[ 0.68057883  0.70887274  0.18523483]
 [-0.13021538 -0.131768    0.98269081]
 [ 0.72101068 -0.69291896  0.00262761]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-592.26715 -692.0305   276.0484 ]
[  69.87270673 -389.24557282  -28.98528307]
[ 0.   0.  -9.8]
transform [[ 0.68057883  0.70887274  0.18523483]
 [-0.13021538 -0.131768    0.98269081]
 [ 0.72101068 -0.69291896  0.00262761]]
transform [[ 0.68057883  0.70887274  0.18523483]
 [-0.13021538 -0.131768    0.98269081]
 [ 0.72101068 -0.69291896  0.00262761]]
transform [[ 0.68057883  0.70887274  0.18523483]
 [-0.13021538 -0.131768    0.98269081]
 [ 0.72101068 -0.69291896  0.00262761]]
support
[0.22564033 1.19704634 0.00320077]
[-842.51227082  439.57999648   53.21546626]
[-233.74077311   13.70803969  320.01844229]
[-1.81530133 -9.63036995 -0.02575054]
zmp_s [        0.          17087861.69096887 -12414295.99882012]
transform [[ 0.68057883 -0.13021538  0.72101068]
 [ 0.70887274 -0.131768   -0.69291896]
 [ 0.18523483  0.98269081  0.00262761]]
zmp [-11175942.4071364    6350467.61407788  16759464.78691663]
d1:37011489.39379, d2:0.05940, d3:16256575.76064
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-262.29976867418657 steps:31[00m
[RDDPG] Resetting Environment
transform [[ 0.21936314  0.18284601  0.9583565 ]
 [-0.67955118 -0.67619318  0.2845577 ]
 [ 0.7000643  -0.71367377 -0.02407861]]
planes
[[ 0.21936314  0.18284601  0.9583565 ]
 [-0.67955118 -0.67619318  0.2845577 ]
 [ 0.7000643  -0.71367377 -0.02407861]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[312.11484   86.760284 -73.08114 ]
[   4.73701791 -276.3545714     3.83875858]
[ 0.   0.  -9.8]
transform [[ 0.21936314  0.18284601  0.9583565 ]
 [-0.67955118 -0.67619318  0.2845577 ]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.21936314  0.18284601  0.9583565 ]
 [-0.67955118 -0.67619318  0.2845577 ]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.21936314  0.18284601  0.9583565 ]
 [-0.67955118 -0.67619318  0.2845577 ]
 [ 0.7000643  -0.71367377 -0.02407861]]
support
[ 1.16740395  0.34662861 -0.02933091]
[  14.29247785 -291.56052067  158.34160882]
[-45.8123043 184.742378  200.4507941]
[-9.3918937  -2.78866546  0.23597039]
zmp_s [        0.          -7039833.93775036 -10844330.10722261]
transform [[ 0.21936314 -0.67955118  0.7000643 ]
 [ 0.18284601 -0.67619318 -0.71367377]
 [ 0.9583565   0.2845577  -0.02407861]]
zmp [-2807800.89283778 12499601.63623224 -1742122.54552205]
d1:15471134.64305, d2:0.05940, d3:5999804.04106
transform [[ 0.09543103  0.06008748  0.99362087]
 [-0.70767432 -0.6978963   0.11017172]
 [ 0.7000643  -0.71367377 -0.02407861]]
planes
[[ 0.09543103  0.06008748  0.99362087]
 [-0.70767432 -0.6978963   0.11017172]
 [ 0.7000643  -0.71367377 -0.02407861]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[312.11484   86.760284 -73.08114 ]
[   4.73701791 -276.3545714     3.83875858]
[ 0.   0.  -9.8]
transform [[ 0.09543103  0.06008748  0.99362087]
 [-0.70767432 -0.6978963   0.11017172]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.09543103  0.06008748  0.99362087]
 [-0.70767432 -0.6978963   0.11017172]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.09543103  0.06008748  0.99362087]
 [-0.70767432 -0.6978963   0.11017172]
 [ 0.7000643  -0.71367377 -0.02407861]]
support
[ 1.21036059  0.13420361 -0.02933091]
[ -37.61629784 -289.47681331  158.34160882]
[-12.33911951 189.93749004 200.4507941 ]
[-9.73748455 -1.07968286  0.23597039]
zmp_s [        0.          -7039866.55936043 -10844329.98712601]
transform [[ 0.09543103 -0.70767432  0.7000643 ]
 [ 0.06008748 -0.6978963  -0.71367377]
 [ 0.99362087  0.11017172 -0.02407861]]
zmp [-2609795.48551952 12652410.70624001  -514477.80372866]
d1:15004323.27542, d2:0.05940, d3:5204962.74685
transform [[ 0.70263213  0.69446319 -0.15501288]
 [ 0.12735033  0.09160057  0.98761904]
 [ 0.7000643  -0.71367377 -0.02407861]]
planes
[[ 0.70263213  0.69446319 -0.15501288]
 [ 0.12735033  0.09160057  0.98761904]
 [ 0.7000643  -0.71367377 -0.02407861]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[312.11484   86.760284 -73.08114 ]
[   4.73701791 -276.3545714     3.83875858]
[ 0.   0.  -9.8]
transform [[ 0.70263213  0.69446319 -0.15501288]
 [ 0.12735033  0.09160057  0.98761904]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.70263213  0.69446319 -0.15501288]
 [ 0.12735033  0.09160057  0.98761904]
 [ 0.7000643  -0.71367377 -0.02407861]]
transform [[ 0.70263213  0.69446319 -0.15501288]
 [ 0.12735033  0.09160057  0.98761904]
 [ 0.7000643  -0.71367377 -0.02407861]]
support
[-0.18882602  1.20304957 -0.02933091]
[290.88225457 -24.48110455 158.34160882]
[-189.1847542   -20.91974565  200.4507941 ]
[ 1.51912618 -9.67866662  0.23597039]
zmp_s [        0.          -7039863.00454301 -10844329.99846981]
transform [[ 0.70263213  0.12735033  0.7000643 ]
 [ 0.69446319  0.09160057 -0.71367377]
 [-0.15501288  0.98761904 -0.02407861]]
zmp [-8488257.18478121  7094458.38177957 -6691586.3524757 ]
d1:19885716.14942, d2:0.05940, d3:9213245.16932
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-318.4330989021415 steps:35[00m
[RDDPG] Resetting Environment
transform [[ 0.6861614   0.6670832  -0.29014227]
 [ 0.21792318  0.19203426  0.95688677]
 [ 0.69404042 -0.71980745 -0.01360642]]
planes
[[ 0.6861614   0.6670832  -0.29014227]
 [ 0.21792318  0.19203426  0.95688677]
 [ 0.69404042 -0.71980745 -0.01360642]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-310.39496  137.39597 1018.3654 ]
[  -8.06716201 -209.65143101    1.89534056]
[ 0.   0.  -9.8]
transform [[ 0.6861614   0.6670832  -0.29014227]
 [ 0.21792318  0.19203426  0.95688677]
 [ 0.69404042 -0.71980745 -0.01360642]]
transform [[ 0.6861614   0.6670832  -0.29014227]
 [ 0.21792318  0.19203426  0.95688677]
 [ 0.69404042 -0.71980745 -0.01360642]]
transform [[ 0.6861614   0.6670832  -0.29014227]
 [ 0.21792318  0.19203426  0.95688677]
 [ 0.69404042 -0.71980745 -0.01360642]]
support
[-0.35343135  1.16561363 -0.0165744 ]
[-416.79734985  933.20286964 -328.18159118]
[-145.94024185  -40.20465258  145.28393582]
[ 2.84339423 -9.37749033  0.1333429 ]
zmp_s [       0.          1599806.8528236  -2291777.38936533]
transform [[ 0.6861614   0.21792318  0.69404042]
 [ 0.6670832   0.19203426 -0.71980745]
 [-0.29014227  0.95688677 -0.01360642]]
zmp [-1241951.14094114  1956856.15367303  1562016.89031712]
d1:4201734.45860, d2:0.05940, d3:2014037.41783
transform [[ 0.70847273  0.68622655 -0.16480173]
 [ 0.1279626   0.10473929  0.98623288]
 [ 0.69404042 -0.71980745 -0.01360642]]
planes
[[ 0.70847273  0.68622655 -0.16480173]
 [ 0.1279626   0.10473929  0.98623288]
 [ 0.69404042 -0.71980745 -0.01360642]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-310.39496  137.39597 1018.3654 ]
[  -8.06716201 -209.65143101    1.89534056]
[ 0.   0.  -9.8]
transform [[ 0.70847273  0.68622655 -0.16480173]
 [ 0.1279626   0.10473929  0.98623288]
 [ 0.69404042 -0.71980745 -0.01360642]]
transform [[ 0.70847273  0.68622655 -0.16480173]
 [ 0.1279626   0.10473929  0.98623288]
 [ 0.69404042 -0.71980745 -0.01360642]]
transform [[ 0.70847273  0.68622655 -0.16480173]
 [ 0.1279626   0.10473929  0.98623288]
 [ 0.69404042 -0.71980745 -0.01360642]]
support
[-0.20075013  1.20136104 -0.0165744 ]
[-293.44998854  979.01726342 -328.18159118]
[-149.89609721  -21.12178908  145.28393582]
[ 1.61505697 -9.66508219  0.1333429 ]
zmp_s [       0.          1599807.15738318 -2291777.46853771]
transform [[ 0.70847273  0.1279626   0.69404042]
 [ 0.68622655  0.10473929 -0.71980745]
 [-0.16480173  0.98623288 -0.01360642]]
zmp [-1385870.70145268  1817201.14584606  1608965.2971416 ]
d1:4249862.55796, d2:0.05940, d3:2044394.60268
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-295.7815023911219 steps:38[00m
[RDDPG] Resetting Environment
transform [[ 0.10644919  0.1164927  -0.98747057]
 [ 0.70143139  0.69509119  0.15761468]
 [ 0.70474297 -0.70942074 -0.00771975]]
planes
[[ 0.10644919  0.1164927  -0.98747057]
 [ 0.70143139  0.69509119  0.15761468]
 [ 0.70474297 -0.70942074 -0.00771975]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -81.5321  -438.4645   254.95267]
[ -43.76704432 -179.19114126   19.20888822]
[ 0.   0.  -9.8]
transform [[ 0.10644919  0.1164927  -0.98747057]
 [ 0.70143139  0.69509119  0.15761468]
 [ 0.70474297 -0.70942074 -0.00771975]]
transform [[ 0.10644919  0.1164927  -0.98747057]
 [ 0.70143139  0.69509119  0.15761468]
 [ 0.70474297 -0.70942074 -0.00771975]]
transform [[ 0.10644919  0.1164927  -0.98747057]
 [ 0.70143139  0.69509119  0.15761468]
 [ 0.70474297 -0.70942074 -0.00771975]]
support
[-1.20286871  0.19199536 -0.00940367]
[-311.51519691 -321.77770552  251.62847359]
[ -44.50163885 -152.22615941   96.12910763]
[ 9.67721156 -1.54462385  0.07565354]
zmp_s [        0.         -12920862.20103851  -5444172.0081509 ]
transform [[ 0.10644919  0.70143139  0.70474297]
 [ 0.1164927   0.69509119 -0.70942074]
 [-0.98747057  0.15761468 -0.00771975]]
zmp [-12899840.32026527  -5118968.91870898  -1994489.89763635]
d1:17672908.35788, d2:0.05940, d3:3928187.05585
transform [[ 0.70078444  0.69777799 -0.14834766]
 [ 0.11062758  0.09913709  0.98890513]
 [ 0.70474297 -0.70942074 -0.00771975]]
planes
[[ 0.70078444  0.69777799 -0.14834766]
 [ 0.11062758  0.09913709  0.98890513]
 [ 0.70474297 -0.70942074 -0.00771975]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -81.5321  -438.4645   254.95267]
[ -43.76704432 -179.19114126   19.20888822]
[ 0.   0.  -9.8]
transform [[ 0.70078444  0.69777799 -0.14834766]
 [ 0.11062758  0.09913709  0.98890513]
 [ 0.70474297 -0.70942074 -0.00771975]]
transform [[ 0.70078444  0.69777799 -0.14834766]
 [ 0.11062758  0.09913709  0.98890513]
 [ 0.70474297 -0.70942074 -0.00771975]]
transform [[ 0.70078444  0.69777799 -0.14834766]
 [ 0.11062758  0.09913709  0.98890513]
 [ 0.70474297 -0.70942074 -0.00771975]]
support
[-0.18070691  1.20461619 -0.00940367]
[-400.90893865  199.63620724  251.62847359]
[-158.55649125   -3.61056224   96.12910763]
[ 1.45380708 -9.69127029  0.07565354]
zmp_s [        0.         -12920862.64066119  -5444171.61423174]
transform [[ 0.70078444  0.11062758  0.70474297]
 [ 0.69777799  0.09913709 -0.70942074]
 [-0.14834766  0.98890513 -0.00771975]]
zmp [ -5266145.38508731   2581271.53416743 -12735479.73636241]
d1:26652298.11794, d2:0.05940, d3:10620486.16442
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-262.0410502537524 steps:41[00m
[RDDPG] Resetting Environment
transform [[ 0.64771891  0.63445467 -0.42181468]
 [ 0.31895202  0.27699074  0.90639168]
 [ 0.69190311 -0.72162569 -0.02294843]]
planes
[[ 0.64771891  0.63445467 -0.42181468]
 [ 0.31895202  0.27699074  0.90639168]
 [ 0.69190311 -0.72162569 -0.02294843]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 178.58406 -558.47473  797.4208 ]
[  27.39843539 -349.87401297  -39.03127063]
[ 0.   0.  -9.8]
transform [[ 0.64771891  0.63445467 -0.42181468]
 [ 0.31895202  0.27699074  0.90639168]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.64771891  0.63445467 -0.42181468]
 [ 0.31895202  0.27699074  0.90639168]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.64771891  0.63445467 -0.42181468]
 [ 0.31895202  0.27699074  0.90639168]
 [ 0.69190311 -0.72162569 -0.02294843]]
support
[-0.51382562  1.10410399 -0.02795419]
[-575.01841729  625.04297498  508.27302768]
[-187.76875305 -123.55069483  272.33084349]
[ 4.13378386 -8.88263847  0.22489457]
zmp_s [       0.         27459845.02656095 -5199914.76920883]
transform [[ 0.64771891  0.31895202  0.69190311]
 [ 0.63445467  0.27699074 -0.72162569]
 [-0.42181468  0.90639168 -0.02294843]]
zmp [ 5160535.92647302 11358514.89601321 25008704.92822795]
d1:51975822.41042, d2:0.05940, d3:17634115.05867
transform [[ 0.69600821  0.65821642  0.28692111]
 [-0.19194458 -0.21449387  0.95767927]
 [ 0.69190311 -0.72162569 -0.02294843]]
planes
[[ 0.69600821  0.65821642  0.28692111]
 [-0.19194458 -0.21449387  0.95767927]
 [ 0.69190311 -0.72162569 -0.02294843]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 178.58406 -558.47473  797.4208 ]
[  27.39843539 -349.87401297  -39.03127063]
[ 0.   0.  -9.8]
transform [[ 0.69600821  0.65821642  0.28692111]
 [-0.19194458 -0.21449387  0.95767927]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.69600821  0.65821642  0.28692111]
 [-0.19194458 -0.21449387  0.95767927]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.69600821  0.65821642  0.28692111]
 [-0.19194458 -0.21449387  0.95767927]
 [ 0.69190311 -0.72162569 -0.02294843]]
support
[ 0.34950756  1.166579   -0.02795419]
[-14.50440778 849.18451192 508.27302768]
[-222.42217896   32.40741119  272.33084349]
[-2.81182691 -9.38525686  0.22489457]
zmp_s [       0.         27459877.84383491 -5199906.13603414]
transform [[ 0.69600821 -0.19194458  0.69190311]
 [ 0.65821642 -0.21449387 -0.72162569]
 [ 0.28692111  0.95767927 -0.02294843]]
zmp [-8868606.08599075 -2137589.65769023 26417085.47173807]
d1:54075699.10745, d2:0.05940, d3:19105229.62276
transform [[ 0.71864402  0.69140488 -0.07423002]
 [ 0.06943294  0.03486823  0.99697709]
 [ 0.69190311 -0.72162569 -0.02294843]]
planes
[[ 0.71864402  0.69140488 -0.07423002]
 [ 0.06943294  0.03486823  0.99697709]
 [ 0.69190311 -0.72162569 -0.02294843]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 178.58406 -558.47473  797.4208 ]
[  27.39843539 -349.87401297  -39.03127063]
[ 0.   0.  -9.8]
transform [[ 0.71864402  0.69140488 -0.07423002]
 [ 0.06943294  0.03486823  0.99697709]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.71864402  0.69140488 -0.07423002]
 [ 0.06943294  0.03486823  0.99697709]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.71864402  0.69140488 -0.07423002]
 [ 0.06943294  0.03486823  0.99697709]
 [ 0.69190311 -0.72162569 -0.02294843]]
support
[-0.09042191  1.2144489  -0.02795419]
[-316.98634873  787.93683455  508.27302768]
[-219.3175857   -49.21041739  272.33084349]
[ 0.72745422 -9.77037549  0.22489457]
zmp_s [       0.         27459845.85306351 -5199914.51773767]
transform [[ 0.71864402  0.06943294  0.69190311]
 [ 0.69140488  0.03486823 -0.72162569]
 [-0.07423002  0.99697709 -0.02294843]]
zmp [-1691219.31261154  4709868.18016513 27496167.08306564]
d1:54886621.67108, d2:0.05940, d3:19479875.41156
transform [[ 0.70422286  0.68154299 -0.19892047]
 [ 0.15918644  0.12147288  0.97974694]
 [ 0.69190311 -0.72162569 -0.02294843]]
planes
[[ 0.70422286  0.68154299 -0.19892047]
 [ 0.15918644  0.12147288  0.97974694]
 [ 0.69190311 -0.72162569 -0.02294843]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 178.58406 -558.47473  797.4208 ]
[  27.39843539 -349.87401297  -39.03127063]
[ 0.   0.  -9.8]
transform [[ 0.70422286  0.68154299 -0.19892047]
 [ 0.15918644  0.12147288  0.97974694]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.70422286  0.68154299 -0.19892047]
 [ 0.15918644  0.12147288  0.97974694]
 [ 0.69190311 -0.72162569 -0.02294843]]
transform [[ 0.70422286  0.68154299 -0.19892047]
 [ 0.15918644  0.12147288  0.97974694]
 [ 0.69190311 -0.72162569 -0.02294843]]
support
[-0.24231124  1.19346031 -0.02795419]
[-413.48488055  741.85919003  508.27302768]
[-211.39545852  -76.37951263  272.33084349]
[ 1.94942064 -9.60151999  0.22489457]
zmp_s [       0.         27459845.42405182 -5199914.6417603 ]
transform [[ 0.70422286  0.15918644  0.69190311]
 [ 0.68154299  0.12147288 -0.72162569]
 [-0.19892047  0.97974694 -0.02294843]]
zmp [  773397.83873586  7088018.48362088 27023029.31788301]
d1:54285770.07644, d2:0.05940, d3:19080044.22481
transform [[ 0.9924022   0.01364085  0.12227814]
 [-0.11318763 -0.28839922  0.95079678]
 [ 0.04823455 -0.95741308 -0.28466403]]
planes
[[ 0.9924022   0.01364085  0.12227814]
 [-0.11318763 -0.28839922  0.95079678]
 [ 0.04823455 -0.95741308 -0.28466403]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 178.58406 -558.47473  797.4208 ]
[  27.39843539 -349.87401297  -39.03127063]
[ 0.   0.  -9.8]
transform [[ 0.9924022   0.01364085  0.12227814]
 [-0.11318763 -0.28839922  0.95079678]
 [ 0.04823455 -0.95741308 -0.28466403]]
transform [[ 0.9924022   0.01364085  0.12227814]
 [-0.11318763 -0.28839922  0.95079678]
 [ 0.04823455 -0.95741308 -0.28466403]]
transform [[ 0.9924022   0.01364085  0.12227814]
 [-0.11318763 -0.28839922  0.95079678]
 [ 0.04823455 -0.95741308 -0.28466403]]
support
[ 0.14895082  1.15819523 -0.34675814]
[267.1162741  899.03527964 316.30791711]
[ 17.64501841  60.69142186 347.40630559]
[-1.19832576 -9.31780847  2.78970754]
zmp_s [       0.         -5618388.6466113    165657.10898671]
transform [[ 0.9924022  -0.11318763  0.04823455]
 [ 0.01364085 -0.28839922 -0.95741308]
 [ 0.12227814  0.95079678 -0.28466403]]
zmp [  643922.46872348  1461736.61810245 -5389102.47172026]
d1:11157647.21892, d2:0.05940, d3:2729485.87546
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-453.8825470707484 steps:47[00m
[RDDPG] Resetting Environment
transform [[ 0.12849598  0.11068952  0.98551339]
 [-0.70528233 -0.68841964  0.16927905]
 [ 0.69718415 -0.71681684 -0.0103918 ]]
planes
[[ 0.12849598  0.11068952  0.98551339]
 [-0.70528233 -0.68841964  0.16927905]
 [ 0.69718415 -0.71681684 -0.0103918 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[843.774   108.3585  124.01328]
[  36.75552796 -131.64561939  -22.68726495]
[ 0.   0.  -9.8]
transform [[ 0.12849598  0.11068952  0.98551339]
 [-0.70528233 -0.68841964  0.16927905]
 [ 0.69718415 -0.71681684 -0.0103918 ]]
transform [[ 0.12849598  0.11068952  0.98551339]
 [-0.70528233 -0.68841964  0.16927905]
 [ 0.69718415 -0.71681684 -0.0103918 ]]
transform [[ 0.12849598  0.11068952  0.98551339]
 [-0.70528233 -0.68841964  0.16927905]
 [ 0.69718415 -0.71681684 -0.0103918 ]]
support
[ 1.20048461  0.2062041  -0.01265858]
[ 242.63246302 -648.70215061  509.30392839]
[-32.20745645  60.86392676 120.22693014]
[-9.65803121 -1.65893473  0.10183966]
zmp_s [        0.          -8670889.95862838 -11785702.3763079 ]
transform [[ 0.12849598 -0.70528233  0.69718415]
 [ 0.11068952 -0.68841964 -0.71681684]
 [ 0.98551339  0.16927905 -0.0103918 ]]
zmp [-2101379.36211803 14417400.90904535 -1345325.36710305]
d1:16120970.42417, d2:0.05940, d3:6093483.30249
transform [[ 0.14755856  0.1020427   0.98377526]
 [-0.42851073  0.90305835 -0.02939706]
 [-0.89140624 -0.41722047  0.17698041]]
planes
[[ 0.14755856  0.1020427   0.98377526]
 [-0.42851073  0.90305835 -0.02939706]
 [-0.89140624 -0.41722047  0.17698041]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 343.9552 1396.0103  910.4455]
[-117.04282693   42.53851081  -59.15096042]
[ 0.   0.  -9.8]
transform [[ 0.14755856  0.1020427   0.98377526]
 [-0.42851073  0.90305835 -0.02939706]
 [-0.89140624 -0.41722047  0.17698041]]
transform [[ 0.14755856  0.1020427   0.98377526]
 [-0.42851073  0.90305835 -0.02939706]
 [-0.89140624 -0.41722047  0.17698041]]
transform [[ 0.14755856  0.1020427   0.98377526]
 [-0.42851073  0.90305835 -0.02939706]
 [-0.89140624 -0.41722047  0.17698041]]
support
[ 1.19836734 -0.03580947  0.21558535]
[1088.87994699 1086.52580576 -727.91685643]
[-71.12117707  90.30772824  76.11620744]
[-9.64099753  0.28809116 -1.73440798]
zmp_s [       0.          4323459.68688444 10088292.1094541 ]
transform [[ 0.14755856 -0.42851073 -0.89140624]
 [ 0.1020427   0.90305835 -0.41722047]
 [ 0.98377526 -0.02939706  0.17698041]]
zmp [-10845415.36502033   -304705.63708695   1658333.04139155]
d1:11317879.27369, d2:0.05940, d3:4599881.91310
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-242.47609197169157 steps:50[00m
[RDDPG] Resetting Environment
transform [[ 0.68375939 -0.6855495  -0.24999015]
 [ 0.21190543 -0.14127973  0.96702439]
 [-0.69826156 -0.71418625  0.04867031]]
planes
[[ 0.68375939 -0.6855495  -0.24999015]
 [ 0.21190543 -0.14127973  0.96702439]
 [-0.69826156 -0.71418625  0.04867031]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 343.9552 1396.0103  910.4455]
[-117.04282693   42.53851081  -59.15096042]
[ 0.   0.  -9.8]
transform [[ 0.68375939 -0.6855495  -0.24999015]
 [ 0.21190543 -0.14127973  0.96702439]
 [-0.69826156 -0.71418625  0.04867031]]
transform [[ 0.68375939 -0.6855495  -0.24999015]
 [ 0.21190543 -0.14127973  0.96702439]
 [-0.69826156 -0.71418625  0.04867031]]
transform [[ 0.68375939 -0.6855495  -0.24999015]
 [ 0.21190543 -0.14127973  0.96702439]
 [-0.69826156 -0.71418625  0.04867031]]
support
[-0.3045208   1.17796258  0.05928682]
[ -949.45393621   756.08102467 -1192.87036254]
[-94.40422932 -88.01226151  48.46719185]
[ 2.44990347 -9.47683898 -0.47696901]
zmp_s [        0.           8289961.98906231 -17902285.46404008]
transform [[ 0.68375939  0.21190543 -0.69826156]
 [-0.6855495  -0.14127973 -0.71418625]
 [-0.24999015  0.96702439  0.04867031]]
zmp [14257165.75712277 11614362.57433796  7145285.67586046]
d1:29617148.26122, d2:0.05940, d3:12799314.33291
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-277.8244142687491 steps:52[00m
[RDDPG] Resetting Environment
transform [[ 0.70035797  0.69118273 -0.17822789]
 [ 0.11494787  0.13722067  0.98384833]
 [ 0.70447552 -0.70953292  0.01665359]]
planes
[[ 0.70035797  0.69118273 -0.17822789]
 [ 0.11494787  0.13722067  0.98384833]
 [ 0.70447552 -0.70953292  0.01665359]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-624.89825  582.41534  791.34595]
[  -0.56942175 -356.35730076   15.47020085]
[ 0.   0.  -9.8]
transform [[ 0.70035797  0.69118273 -0.17822789]
 [ 0.11494787  0.13722067  0.98384833]
 [ 0.70447552 -0.70953292  0.01665359]]
transform [[ 0.70035797  0.69118273 -0.17822789]
 [ 0.11494787  0.13722067  0.98384833]
 [ 0.70447552 -0.70953292  0.01665359]]
transform [[ 0.70035797  0.69118273 -0.17822789]
 [ 0.11494787  0.13722067  0.98384833]
 [ 0.70447552 -0.70953292  0.01665359]]
support
[-0.21710495  1.19845635  0.02028626]
[-176.13696173  786.6530891  -840.289628  ]
[-249.46403318  -33.74470857  252.7037257 ]
[ 1.74663329 -9.64171367 -0.16320522]
zmp_s [       0.         14707848.68019585 -1398278.36490199]
transform [[ 0.70035797  0.11494787  0.70447552]
 [ 0.69118273  0.13722067 -0.70953292]
 [-0.17822789  0.98384833  0.01665359]]
zmp [  705583.00249412  3010345.31495776 14447006.05163346]
d1:29109457.06897, d2:0.05940, d3:9986473.30685
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-286.8597266231385 steps:54[00m
[RDDPG] Resetting Environment
transform [[ 0.68962175  0.69676012 -0.1973507 ]
 [ 0.11113393  0.16746537  0.97959411]
 [ 0.71559149 -0.69748175  0.03805407]]
planes
[[ 0.68962175  0.69676012 -0.1973507 ]
 [ 0.11113393  0.16746537  0.97959411]
 [ 0.71559149 -0.69748175  0.03805407]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-109.35804  516.4047  -368.7444 ]
[ 19.37735339 -39.67480163  -6.63911467]
[ 0.   0.  -9.8]
transform [[ 0.68962175  0.69676012 -0.1973507 ]
 [ 0.11113393  0.16746537  0.97959411]
 [ 0.71559149 -0.69748175  0.03805407]]
transform [[ 0.68962175  0.69676012 -0.1973507 ]
 [ 0.11113393  0.16746537  0.97959411]
 [ 0.71559149 -0.69748175  0.03805407]]
transform [[ 0.68962175  0.69676012 -0.1973507 ]
 [ 0.11113393  0.16746537  0.97959411]
 [ 0.71559149 -0.69748175  0.03805407]]
support
[-0.24039904  1.19327415  0.04635485]
[ 357.16649495 -286.89330683 -452.47077928]
[-12.97054128 -10.99431163  41.28607397]
[ 1.93403682 -9.60002229 -0.3729299 ]
zmp_s [       0.         14097367.87981657  5331276.2125834 ]
transform [[ 0.68962175  0.11113393  0.71559149]
 [ 0.69676012  0.16746537 -0.69748175]
 [-0.1973507   0.97959411  0.03805407]]
zmp [ 5381711.82837761 -1357646.88754479 14012575.32737758]
d1:27957941.30536, d2:0.05940, d3:11177238.99736
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-411.3068582589408 steps:56[00m
[RDDPG] Resetting Environment
transform [[ 0.18803045 -0.02860484 -0.98174661]
 [ 0.98107165  0.05258356  0.18636908]
 [ 0.04629267 -0.99820679  0.03795071]]
planes
[[ 0.18803045 -0.02860484 -0.98174661]
 [ 0.98107165  0.05258356  0.18636908]
 [ 0.04629267 -0.99820679  0.03795071]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-109.35804  516.4047  -368.7444 ]
[ 19.37735339 -39.67480163  -6.63911467]
[ 0.   0.  -9.8]
transform [[ 0.18803045 -0.02860484 -0.98174661]
 [ 0.98107165  0.05258356  0.18636908]
 [ 0.04629267 -0.99820679  0.03795071]]
transform [[ 0.18803045 -0.02860484 -0.98174661]
 [ 0.98107165  0.05258356  0.18636908]
 [ 0.04629267 -0.99820679  0.03795071]]
transform [[ 0.18803045 -0.02860484 -0.98174661]
 [ 0.98107165  0.05258356  0.18636908]
 [ 0.04629267 -0.99820679  0.03795071]]
support
[-1.19589618  0.22702199  0.04622894]
[ 326.6792346  -148.85622414 -534.5352895 ]
[11.29635224 15.68700408 40.24872689]
[ 9.62111682 -1.82641695 -0.37191692]
zmp_s [        0.          -3936333.92849181 -19098747.80927457]
transform [[ 0.18803045  0.98107165  0.04629267]
 [-0.02860484  0.05258356 -0.99820679]
 [-0.98174661  0.18636908  0.03795071]]
zmp [-4745957.65714792 18857513.37243609 -1458421.87659418]
d1:29598205.74240, d2:0.05940, d3:2914459.59186
transform [[ 0.3702139   0.31127143 -0.8752439 ]
 [ 0.54634756  0.68904769  0.47614878]
 [ 0.75129628 -0.65446419  0.08503266]]
planes
[[ 0.3702139   0.31127143 -0.8752439 ]
 [ 0.54634756  0.68904769  0.47614878]
 [ 0.75129628 -0.65446419  0.08503266]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-885.76776 -123.78506 -288.67294]
[-50.10157481 -42.13070646  28.3016083 ]
[ 0.   0.  -9.8]
transform [[ 0.3702139   0.31127143 -0.8752439 ]
 [ 0.54634756  0.68904769  0.47614878]
 [ 0.75129628 -0.65446419  0.08503266]]
transform [[ 0.3702139   0.31127143 -0.8752439 ]
 [ 0.54634756  0.68904769  0.47614878]
 [ 0.75129628 -0.65446419  0.08503266]]
transform [[ 0.3702139   0.31127143 -0.8752439 ]
 [ 0.54634756  0.68904769  0.47614878]
 [ 0.75129628 -0.65446419  0.08503266]]
support
[-1.0661619   0.58001169  0.10358094]
[-113.79505228 -706.68213278 -609.00776849]
[-56.4331945  -42.92716283  -7.66152724]
[ 8.57739024 -4.66625808 -0.83332011]
zmp_s [       0.         -8460118.28476962 -1733008.80896515]
transform [[ 0.3702139   0.54634756  0.75129628]
 [ 0.31127143  0.68904769 -0.65446419]
 [-0.8752439   0.47614878  0.08503266]]
zmp [-5924168.04401883 -4695232.79866309 -4175637.3913247 ]
d1:11961748.21029, d2:0.05940, d3:3186394.54278
transform [[ 0.61862826  0.65348625 -0.4361822 ]
 [ 0.22989795  0.38030568  0.89583182]
 [ 0.75129628 -0.65446419  0.08503266]]
planes
[[ 0.61862826  0.65348625 -0.4361822 ]
 [ 0.22989795  0.38030568  0.89583182]
 [ 0.75129628 -0.65446419  0.08503266]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-885.76776 -123.78506 -288.67294]
[-50.10157481 -42.13070646  28.3016083 ]
[ 0.   0.  -9.8]
transform [[ 0.61862826  0.65348625 -0.4361822 ]
 [ 0.22989795  0.38030568  0.89583182]
 [ 0.75129628 -0.65446419  0.08503266]]
transform [[ 0.61862826  0.65348625 -0.4361822 ]
 [ 0.22989795  0.38030568  0.89583182]
 [ 0.75129628 -0.65446419  0.08503266]]
transform [[ 0.61862826  0.65348625 -0.4361822 ]
 [ 0.22989795  0.38030568  0.89583182]
 [ 0.75129628 -0.65446419  0.08503266]]
support
[-0.53132715  1.09124069  0.10358094]
[-502.93880528 -509.31475804 -609.00776849]
[-70.87074547  -2.18731465  -7.66152724]
[ 4.27458557 -8.77915187 -0.83332011]
zmp_s [       0.         -8460124.37209391 -1733014.74224652]
transform [[ 0.61862826  0.22989795  0.75129628]
 [ 0.65348625  0.38030568 -0.65446419]
 [-0.4361822   0.89583182  0.08503266]]
zmp [-3246972.74923794 -2083237.2510628  -7726211.50271158]
d1:16022137.99727, d2:0.05940, d3:5355035.49519
transform [[ 0.94965488 -0.27232921  0.15489502]
 [ 0.11269569  0.75823736  0.64216501]
 [-0.29232752 -0.59237909  0.75075412]]
planes
[[ 0.94965488 -0.27232921  0.15489502]
 [ 0.11269569  0.75823736  0.64216501]
 [-0.29232752 -0.59237909  0.75075412]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-141.09305  338.54398  654.4017 ]
[  61.76432998 -479.49026905  -54.5837833 ]
[ 0.   0.  -9.8]
transform [[ 0.94965488 -0.27232921  0.15489502]
 [ 0.11269569  0.75823736  0.64216501]
 [-0.29232752 -0.59237909  0.75075412]]
transform [[ 0.94965488 -0.27232921  0.15489502]
 [ 0.11269569  0.75823736  0.64216501]
 [-0.29232752 -0.59237909  0.75075412]]
transform [[ 0.94965488 -0.27232921  0.15489502]
 [ 0.11269569  0.75823736  0.64216501]
 [-0.29232752 -0.59237909  0.75075412]]
support
[0.18868246 0.78224123 0.91451701]
[-124.8215534   661.02996549  331.99375822]
[ 180.77924762 -391.65865812  225.00559707]
[-1.51797122 -6.29321705 -7.35739036]
zmp_s [       0.         -5755838.4589789  -5846827.00060448]
transform [[ 0.94965488  0.11269569 -0.29232752]
 [-0.27232921  0.75823736 -0.59237909]
 [ 0.15489502  0.64216501  0.75075412]]
zmp [ 1060530.24633754  -900753.69216361 -8085727.48171804]
d1:13965803.75209, d2:0.05940, d3:4291604.57287
transform [[-0.08150338 -0.99500912  0.05756784]
 [ 0.64536941 -0.00867151  0.76382142]
 [-0.7595101   0.09940653  0.64285517]]
planes
[[-0.08150338 -0.99500912  0.05756784]
 [ 0.64536941 -0.00867151  0.76382142]
 [-0.7595101   0.09940653  0.64285517]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 772.166   -235.42757  151.43286]
[ -718.39989283 -1019.88331718  -311.08859926]
[ 0.   0.  -9.8]
transform [[-0.08150338 -0.99500912  0.05756784]
 [ 0.64536941 -0.00867151  0.76382142]
 [-0.7595101   0.09940653  0.64285517]]
transform [[-0.08150338 -0.99500912  0.05756784]
 [ 0.64536941 -0.00867151  0.76382142]
 [-0.7595101   0.09940653  0.64285517]]
transform [[-0.08150338 -0.99500912  0.05756784]
 [ 0.64536941 -0.00867151  0.76382142]
 [-0.7595101   0.09940653  0.64285517]]
support
[0.07012518 0.93043471 0.78308194]
[ 180.0361025   616.04150203 -512.52152839]
[1055.43652372 -692.40552542  244.26399624]
[-0.56416485 -7.48544995 -6.29998064]
zmp_s [        0.           8254357.33163823 -16434243.87221415]
transform [[-0.08150338  0.64536941 -0.7595101 ]
 [-0.99500912 -0.00867151  0.09940653]
 [ 0.05756784  0.76382142  0.64285517]]
zmp [17809083.93026476 -1705248.93192552 -4259983.6319365 ]
d1:16268642.15656, d2:0.05940, d3:12139604.79140
transform [[-0.28299952  0.94423252  0.16833377]
 [-0.42721182  0.03303938 -0.90354776]
 [-0.85872084 -0.32761768  0.39403719]]
planes
[[-0.28299952  0.94423252  0.16833377]
 [-0.42721182  0.03303938 -0.90354776]
 [-0.85872084 -0.32761768  0.39403719]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 710.9511  -286.85922  238.82234]
[ -718.39989283 -1019.88331718  -311.08859926]
[ 0.   0.  -9.8]
transform [[-0.28299952  0.94423252  0.16833377]
 [-0.42721182  0.03303938 -0.90354776]
 [-0.85872084 -0.32761768  0.39403719]]
transform [[-0.28299952  0.94423252  0.16833377]
 [-0.42721182  0.03303938 -0.90354776]
 [-0.85872084 -0.32761768  0.39403719]]
transform [[-0.28299952  0.94423252  0.16833377]
 [-0.42721182  0.03303938 -0.90354776]
 [-0.85872084 -0.32761768  0.39403719]]
support
[ 0.20505262 -1.10063972  0.47998899]
[-431.85876249 -528.9917615  -422.42349906]
[-812.06689293  554.29602616  828.45628335]
[-1.64967093  8.85476809 -3.86156443]
zmp_s [        0.         -34453683.43561829  -6944551.00027493]
transform [[-0.28299952 -0.42721182 -0.85872084]
 [ 0.94423252  0.03303938 -0.32761768]
 [ 0.16833377 -0.90354776  0.39403719]]
zmp [20682451.50501682  1136829.44666179 28394137.28195179]
d1:67261256.22143, d2:0.05940, d3:9556316.98137
transform [[-0.3736527  -0.68870747  0.62134188]
 [-0.69032317 -0.24094376 -0.6822024 ]
 [ 0.61954629 -0.68383342 -0.3854014 ]]
planes
[[-0.3736527  -0.68870747  0.62134188]
 [-0.69032317 -0.24094376 -0.6822024 ]
 [ 0.61954629 -0.68383342 -0.3854014 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 609.993   -375.1773  -207.33058]
[ 4.83625886e+01  3.89174130e+02 -2.60433290e-01]
[ 0.   0.  -9.8]
transform [[-0.3736527  -0.68870747  0.62134188]
 [-0.69032317 -0.24094376 -0.6822024 ]
 [ 0.61954629 -0.68383342 -0.3854014 ]]
transform [[-0.3736527  -0.68870747  0.62134188]
 [-0.69032317 -0.24094376 -0.6822024 ]
 [ 0.61954629 -0.68383342 -0.3854014 ]]
transform [[-0.3736527  -0.68870747  0.62134188]
 [-0.69032317 -0.24094376 -0.6822024 ]
 [ 0.61954629 -0.68383342 -0.3854014 ]]
support
[ 0.75687593 -0.83101203 -0.46946947]
[ -98.36128217 -189.25423965  714.383168  ]
[-286.25976078 -126.97722558 -236.06704271]
[-6.08915046  6.68558351  3.7769337 ]
zmp_s [       0.         12891202.58595959 24530883.95018153]
transform [[-0.3736527  -0.69032317  0.61954629]
 [-0.68870747 -0.24094376 -0.68383342]
 [ 0.62134188 -0.6822024  -0.3854014 ]]
zmp [  6298922.35927409 -19881093.091917   -18248646.29445165]
d1:42805973.17371, d2:0.05940, d3:20761604.77956
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-738.3413776128316 steps:64[00m
[RDDPG] Resetting Environment
transform [[ 0.70619822  0.70750391 -0.02687612]
 [ 0.03972937 -0.00169886  0.99920911]
 [ 0.70689863 -0.70670742 -0.02930841]]
planes
[[ 0.70619822  0.70750391 -0.02687612]
 [ 0.03972937 -0.00169886  0.99920911]
 [ 0.70689863 -0.70670742 -0.02930841]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 889.72327  -187.02017   -25.225847]
[  50.22308827 -561.687006     -4.68252907]
[ 0.   0.  -9.8]
transform [[ 0.70619822  0.70750391 -0.02687612]
 [ 0.03972937 -0.00169886  0.99920911]
 [ 0.70689863 -0.70670742 -0.02930841]]
transform [[ 0.70619822  0.70750391 -0.02687612]
 [ 0.03972937 -0.00169886  0.99920911]
 [ 0.70689863 -0.70670742 -0.02930841]]
transform [[ 0.70619822  0.70750391 -0.02687612]
 [ 0.03972937 -0.00169886  0.99920911]
 [ 0.70689863 -0.70670742 -0.02930841]]
support
[-0.03273864  1.21716779 -0.03570149]
[496.68145212  10.45997063 761.85203046]
[-361.80245213   -1.72926795  432.58824349]
[ 0.26338597 -9.79224924  0.28722246]
zmp_s [       0.         -1467936.02828372  5542268.01102831]
transform [[ 0.70619822  0.03972937  0.70689863]
 [ 0.70750391 -0.00169886 -0.70670742]
 [-0.02687612  0.99920911 -0.02930841]]
zmp [ 3859501.48618323 -3914268.10209184 -1629210.13228698]
d1:7884222.16736, d2:0.05940, d3:3510497.23198
transform [[ 0.59282321 -0.80416518 -0.04334804]
 [-0.00895962 -0.06040873  0.99813354]
 [-0.80528277 -0.59132838 -0.04301671]]
planes
[[ 0.59282321 -0.80416518 -0.04334804]
 [-0.00895962 -0.06040873  0.99813354]
 [-0.80528277 -0.59132838 -0.04301671]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-442.57962  601.4556  1377.7648 ]
[160.71743486  87.60147312 155.08506953]
[ 0.   0.  -9.8]
transform [[ 0.59282321 -0.80416518 -0.04334804]
 [-0.00895962 -0.06040873  0.99813354]
 [-0.80528277 -0.59132838 -0.04301671]]
transform [[ 0.59282321 -0.80416518 -0.04334804]
 [-0.00895962 -0.06040873  0.99813354]
 [-0.80528277 -0.59132838 -0.04301671]]
transform [[ 0.59282321 -0.80416518 -0.04334804]
 [-0.00895962 -0.06040873  0.99813354]
 [-0.80528277 -0.59132838 -0.04301671]]
support
[-0.0528036   1.21585761 -0.0524    ]
[-805.76454352 1342.8253991   -58.52295185]
[  18.10833713  148.06374867 -187.89546873]
[ 0.42481076 -9.78170869  0.42156379]
zmp_s [       0.         11183360.89514207 27665573.767557  ]
transform [[ 0.59282321 -0.00895962 -0.80528277]
 [-0.80416518 -0.06040873 -0.59132838]
 [-0.04334804  0.99813354 -0.04301671]]
zmp [-22378808.55669491 -17035011.65782231   9972405.55122813]
d1:54983034.37415, d2:0.05940, d3:18808978.33769
transform [[-0.42296305 -0.67799491 -0.60118645]
 [ 0.74666637  0.11513437 -0.65515918]
 [ 0.51341176 -0.72599381  0.45753837]]
planes
[[-0.42296305 -0.67799491 -0.60118645]
 [ 0.74666637  0.11513437 -0.65515918]
 [ 0.51341176 -0.72599381  0.45753837]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -38.106274    2.738197 -326.33722 ]
[-38.36899902  46.9561586  132.68980293]
[ 0.   0.  -9.8]
transform [[-0.42296305 -0.67799491 -0.60118645]
 [ 0.74666637  0.11513437 -0.65515918]
 [ 0.51341176 -0.72599381  0.45753837]]
transform [[-0.42296305 -0.67799491 -0.60118645]
 [ 0.74666637  0.11513437 -0.65515918]
 [ 0.51341176 -0.72599381  0.45753837]]
transform [[-0.42296305 -0.67799491 -0.60118645]
 [ 0.74666637  0.11513437 -0.65515918]
 [ 0.51341176 -0.72599381  0.45753837]]
support
[-0.73232398 -0.79806983  0.55734176]
[ 210.4505779   185.66541095 -170.86392134]
[ -95.37867955 -110.17551562    6.92169975]
[ 5.89162725  6.42055992 -4.48387599]
zmp_s [       0.         36036267.82015195 14110650.45451991]
transform [[-0.42296305  0.74666637  0.51341176]
 [-0.67799491  0.11513437 -0.72599381]
 [-0.60118645 -0.65515918  0.45753837]]
zmp [ 34151643.23655082  -6095232.07115102 -17153327.55275708]
d1:68669592.87643, d2:0.05940, d3:22619989.47222
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-437.0321269794863 steps:68[00m
[RDDPG] Resetting Environment
transform [[ 0.71124911  0.70232052 -0.029506  ]
 [ 0.02804263  0.01359262  0.99951434]
 [ 0.70238048 -0.71173108 -0.01002717]]
planes
[[ 0.71124911  0.70232052 -0.029506  ]
 [ 0.02804263  0.01359262  0.99951434]
 [ 0.70238048 -0.71173108 -0.01002717]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-189.2496  -152.33856  851.4939 ]
[  37.65398438 -471.89127966  -36.79045846]
[ 0.   0.  -9.8]
transform [[ 0.71124911  0.70232052 -0.029506  ]
 [ 0.02804263  0.01359262  0.99951434]
 [ 0.70238048 -0.71173108 -0.01002717]]
transform [[ 0.71124911  0.70232052 -0.029506  ]
 [ 0.02804263  0.01359262  0.99951434]
 [ 0.70238048 -0.71173108 -0.01002717]]
transform [[ 0.71124911  0.70232052 -0.029506  ]
 [ 0.02804263  0.01359262  0.99951434]
 [ 0.70238048 -0.71173108 -0.01002717]]
support
[-0.03594218  1.2175396  -0.01221441]
[-266.71829026  843.70262375  -33.03921557]
[-303.55202476  -42.13091397  362.67601623]
[ 0.28915882 -9.79524055  0.0982663 ]
zmp_s [       0.         11081242.46629031  1977858.15036122]
transform [[ 0.71124911  0.02804263  0.70238048]
 [ 0.70232052  0.01359262 -0.71173108]
 [-0.029506    0.99951434 -0.01002717]]
zmp [ 1699956.14980633 -1257079.9671818  11056028.43744605]
d1:22024565.98162, d2:0.05940, d3:7980247.05871
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-104.00926456431571 steps:70[00m
[RDDPG] Resetting Environment
transform [[ 0.67791539  0.67924559  0.28116941]
 [-0.21362048 -0.18395254  0.95944136]
 [ 0.7034182  -0.71048361  0.02039653]]
planes
[[ 0.67791539  0.67924559  0.28116941]
 [-0.21362048 -0.18395254  0.95944136]
 [ 0.7034182  -0.71048361  0.02039653]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-391.47168 -276.05582  743.3163 ]
[ -17.68677131 -383.22628035   -1.08474432]
[ 0.   0.  -9.8]
transform [[ 0.67791539  0.67924559  0.28116941]
 [-0.21362048 -0.18395254  0.95944136]
 [ 0.7034182  -0.71048361  0.02039653]]
transform [[ 0.67791539  0.67924559  0.28116941]
 [-0.21362048 -0.18395254  0.95944136]
 [ 0.7034182  -0.71048361  0.02039653]]
transform [[ 0.67791539  0.67924559  0.28116941]
 [-0.21362048 -0.18395254  0.95944136]
 [ 0.7034182  -0.71048361  0.02039653]]
support
[0.34250124 1.16872546 0.02484565]
[-243.89657004  847.57592777  -64.07409848]
[-272.59989282   73.23295581  259.81266958]
[-2.75546026 -9.40252537 -0.19988596]
zmp_s [      0.         8073079.88597093 2331228.38868675]
transform [[ 0.67791539 -0.21362048  0.7034182 ]
 [ 0.67924559 -0.18395254 -0.71048361]
 [ 0.28116941  0.95944136  0.02039653]]
zmp [  -84746.76572473 -3141363.11473011  7793195.73850176]
d1:15904010.06937, d2:0.05940, d3:5866070.75957
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-456.31210904095406 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-201.01051867187633 steps:73[00m
[RDDPG] Resetting Environment
transform [[ 0.76796204 -0.64044112  0.00834107]
 [-0.04849821 -0.04515957  0.9978019 ]
 [-0.63865662 -0.76667845 -0.06574108]]
planes
[[ 0.76796204 -0.64044112  0.00834107]
 [-0.04849821 -0.04515957  0.9978019 ]
 [-0.63865662 -0.76667845 -0.06574108]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-391.47168 -276.05582  743.3163 ]
[ -17.68677131 -383.22628035   -1.08474432]
[ 0.   0.  -9.8]
transform [[ 0.76796204 -0.64044112  0.00834107]
 [-0.04849821 -0.04515957  0.9978019 ]
 [-0.63865662 -0.76667845 -0.06574108]]
transform [[ 0.76796204 -0.64044112  0.00834107]
 [-0.04849821 -0.04515957  0.9978019 ]
 [-0.63865662 -0.76667845 -0.06574108]]
transform [[ 0.76796204 -0.64044112  0.00834107]
 [-0.04849821 -0.04515957  0.9978019 ]
 [-0.63865662 -0.76667845 -0.06574108]]
support
[ 0.01016052  1.21545363 -0.08008126]
[-117.63784018  773.13463837  412.79561148]
[231.8420512   17.08175117 305.17841735]
[-0.08174248 -9.77845862  0.64426256]
zmp_s [        0.          -5828985.12624175 -13545987.18950221]
transform [[ 0.76796204 -0.04849821 -0.63865662]
 [-0.64044112 -0.04515957 -0.76667845]
 [ 0.00834107  0.9978019  -0.06574108]]
zmp [ 8933929.68389304 10648650.96284568 -4925644.64575809]
d1:21836702.54260, d2:0.05940, d3:9344882.59943
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-305.92288312022566 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-66.19524401366623 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-90.85760851561874 steps:77[00m
[RDDPG] Resetting Environment
transform [[ 0.01044777 -0.00463776 -0.99993467]
 [ 0.99921316  0.0383128   0.01026253]
 [ 0.0382627  -0.99925506  0.00503439]]
planes
[[ 0.01044777 -0.00463776 -0.99993467]
 [ 0.99921316  0.0383128   0.01026253]
 [ 0.0382627  -0.99925506  0.00503439]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-391.47168 -276.05582  743.3163 ]
[ -17.68677131 -383.22628035   -1.08474432]
[ 0.   0.  -9.8]
transform [[ 0.01044777 -0.00463776 -0.99993467]
 [ 0.99921316  0.0383128   0.01026253]
 [ 0.0382627  -0.99925506  0.00503439]]
transform [[ 0.01044777 -0.00463776 -0.99993467]
 [ 0.99921316  0.0383128   0.01026253]
 [ 0.0382627  -0.99925506  0.00503439]]
transform [[ 0.01044777 -0.00463776 -0.99993467]
 [ 0.99921316  0.0383128   0.01026253]
 [ 0.0382627  -0.99925506  0.00503439]]
support
[-1.21805162  0.01250111  0.00613255]
[-746.07745171 -394.11181473  264.61355644]
[  2.67719767 -32.36645736 382.25859558]
[ 9.7993598  -0.10057284 -0.04933707]
zmp_s [        0.          11129921.18383793 -20710922.3875861 ]
transform [[ 0.01044777  0.99921316  0.0382627 ]
 [-0.00463776  0.0383128  -0.99925506]
 [-0.99993467  0.01026253  0.00503439]]
zmp [1.03287079e+07 2.11219124e+07 9.95425013e+03]
d1:27354199.67884, d2:0.05940, d3:5511426.58526
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-26.45795770022942 steps:79[00m
[RDDPG] Resetting Environment
transform [[ 0.52596623  0.49145997 -0.69413739]
 [ 0.50328076  0.47807115  0.71983087]
 [ 0.68561512 -0.72795272  0.00410692]]
planes
[[ 0.52596623  0.49145997 -0.69413739]
 [ 0.50328076  0.47807115  0.71983087]
 [ 0.68561512 -0.72795272  0.00410692]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-187.78313 -292.40457 -596.32025]
[-39.65715907 -70.91238833  16.90636346]
[ 0.   0.  -9.8]
transform [[ 0.52596623  0.49145997 -0.69413739]
 [ 0.50328076  0.47807115  0.71983087]
 [ 0.68561512 -0.72795272  0.00410692]]
transform [[ 0.52596623  0.49145997 -0.69413739]
 [ 0.50328076  0.47807115  0.71983087]
 [ 0.68561512 -0.72795272  0.00410692]]
transform [[ 0.52596623  0.49145997 -0.69413739]
 [ 0.50328076  0.47807115  0.71983087]
 [ 0.68561512 -0.72795272  0.00410692]]
support
[-0.84555042  0.87684844  0.00500277]
[ 171.45546217 -663.54755106   81.66071276]
[-67.44426536 -41.69013005  24.50075097]
[ 6.80254647 -7.05434253 -0.0402478 ]
zmp_s [        0.         -12617116.44153521  -6375563.3417133 ]
transform [[ 0.52596623  0.50328076  0.68561512]
 [ 0.49145997  0.47807115 -0.72795272]
 [-0.69413739  0.71983087  0.00410692]]
zmp [-10721134.57766878  -1390770.73874231  -9108373.83100844]
d1:23223444.82255, d2:0.05940, d3:9162467.68709
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-79.83601781308298 steps:81[00m
[RDDPG] Resetting Environment
transform [[ 0.18440017 -0.16924176 -0.96817034]
 [ 0.70592535 -0.66259378  0.25027755]
 [-0.68386108 -0.72960722 -0.00271037]]
planes
[[ 0.18440017 -0.16924176 -0.96817034]
 [ 0.70592535 -0.66259378  0.25027755]
 [-0.68386108 -0.72960722 -0.00271037]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-187.78313 -292.40457 -596.32025]
[-39.65715907 -70.91238833  16.90636346]
[ 0.   0.  -9.8]
transform [[ 0.18440017 -0.16924176 -0.96817034]
 [ 0.70592535 -0.66259378  0.25027755]
 [-0.68386108 -0.72960722 -0.00271037]]
transform [[ 0.18440017 -0.16924176 -0.96817034]
 [ 0.70592535 -0.66259378  0.25027755]
 [-0.68386108 -0.72960722 -0.00271037]]
transform [[ 0.18440017 -0.16924176 -0.96817034]
 [ 0.70592535 -0.66259378  0.25027755]
 [-0.68386108 -0.72960722 -0.00271037]]
support
[-1.1793585   0.30487089 -0.00330158]
[592.19940599 -88.06098873 343.3743068 ]
[-11.67968952  23.22239707  78.81235587]
[ 9.48806938 -2.45271998  0.02656161]
zmp_s [        0.          -1084760.50352919 -12064672.2916113 ]
transform [[ 0.18440017  0.70592535 -0.68386108]
 [-0.16924176 -0.66259378 -0.72960722]
 [-0.96817034  0.25027755 -0.00271037]]
zmp [7484799.85181157 9521227.62929659 -238791.492554  ]
d1:17262865.52293, d2:0.05940, d3:5579758.23601
transform [[ 0.67337483 -0.63257587  0.38264096]
 [-0.28089213  0.25984818  0.92389315]
 [-0.68386108 -0.72960722 -0.00271037]]
planes
[[ 0.67337483 -0.63257587  0.38264096]
 [-0.28089213  0.25984818  0.92389315]
 [-0.68386108 -0.72960722 -0.00271037]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-187.78313 -292.40457 -596.32025]
[-39.65715907 -70.91238833  16.90636346]
[ 0.   0.  -9.8]
transform [[ 0.67337483 -0.63257587  0.38264096]
 [-0.28089213  0.25984818  0.92389315]
 [-0.68386108 -0.72960722 -0.00271037]]
transform [[ 0.67337483 -0.63257587  0.38264096]
 [-0.28089213  0.25984818  0.92389315]
 [-0.68386108 -0.72960722 -0.00271037]]
transform [[ 0.67337483 -0.63257587  0.38264096]
 [-0.28089213  0.25984818  0.92389315]
 [-0.68386108 -0.72960722 -0.00271037]]
support
[ 0.46610689  1.12542308 -0.00330158]
[-169.65690752 -574.17018954  343.3743068 ]
[24.62240001  8.33260262 78.81235587]
[-3.74988139 -9.05415291  0.02656161]
zmp_s [        0.          -1084760.48775438 -12064672.1283133 ]
transform [[ 0.67337483 -0.28089213 -0.68386108]
 [-0.63257587  0.25984818 -0.72960722]
 [ 0.38264096  0.92389315 -0.00271037]]
zmp [8555260.36126379 8520598.90991755 -969503.08089574]
d1:17311274.69094, d2:0.05940, d3:6048881.94610
transform [[ 0.473726    0.72340137 -0.50226897]
 [-0.29140618  0.66695637  0.68574899]
 [ 0.83106327 -0.17849286  0.52675819]]
planes
[[ 0.473726    0.72340137 -0.50226897]
 [-0.29140618  0.66695637  0.68574899]
 [ 0.83106327 -0.17849286  0.52675819]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-455.19092  336.71387 1162.1416 ]
[   4.62298418 -314.96857003   23.31628641]
[ 0.   0.  -9.8]
transform [[ 0.473726    0.72340137 -0.50226897]
 [-0.29140618  0.66695637  0.68574899]
 [ 0.83106327 -0.17849286  0.52675819]]
transform [[ 0.473726    0.72340137 -0.50226897]
 [-0.29140618  0.66695637  0.68574899]
 [ 0.83106327 -0.17849286  0.52675819]]
transform [[ 0.473726    0.72340137 -0.50226897]
 [-0.29140618  0.66695637  0.68574899]
 [ 0.83106327 -0.17849286  0.52675819]]
support
[-0.6118295   0.83533225  0.64166059]
[-555.76416798 1154.1563401   173.77413733]
[-237.36971367 -195.42833881   72.34367783]
[ 4.92223591 -6.72034014 -5.1622303 ]
zmp_s [        0.          -1704116.30781152 -18618899.19083836]
transform [[ 0.473726   -0.29140618  0.83106327]
 [ 0.72340137  0.66695637 -0.17849286]
 [-0.50226897  0.68574899  0.52675819]]
zmp [-14976893.22483717   2186769.32973583 -10976253.75580834]
d1:21957573.95127, d2:0.05940, d3:12556176.74249
transform [[ 0.26350218  0.9604246  -0.09028438]
 [-0.48979637  0.21383397  0.84520686]
 [ 0.83106327 -0.17849286  0.52675819]]
planes
[[ 0.26350218  0.9604246  -0.09028438]
 [-0.48979637  0.21383397  0.84520686]
 [ 0.83106327 -0.17849286  0.52675819]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-455.19092  336.71387 1162.1416 ]
[   4.62298418 -314.96857003   23.31628641]
[ 0.   0.  -9.8]
transform [[ 0.26350218  0.9604246  -0.09028438]
 [-0.48979637  0.21383397  0.84520686]
 [ 0.83106327 -0.17849286  0.52675819]]
transform [[ 0.26350218  0.9604246  -0.09028438]
 [-0.48979637  0.21383397  0.84520686]
 [ 0.83106327 -0.17849286  0.52675819]]
transform [[ 0.26350218  0.9604246  -0.09028438]
 [-0.48979637  0.21383397  0.84520686]
 [ 0.83106327 -0.17849286  0.52675819]]
support
[-0.10997823  1.02957284  0.64166059]
[  98.5212429  1277.20177345  173.77413733]
[-303.39049368  -49.90821636   72.34367783]
[ 0.88478697 -8.2830272  -5.1622303 ]
zmp_s [        0.          -1704114.2943137  -18618899.67385928]
transform [[ 0.26350218 -0.48979637  0.83106327]
 [ 0.9604246   0.21383397 -0.17849286]
 [-0.09028438  0.84520686  0.52675819]]
zmp [-14638814.66147431   2958943.10465338 -11247987.0521071 ]
d1:22130932.32984, d2:0.05940, d3:12856997.50399
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-569.5187845768187 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-399.98270177734014 steps:87[00m
[RDDPG] Resetting Environment
transform [[ 0.43976375  0.42034706 -0.79367262]
 [ 0.58524048  0.53620321  0.60825956]
 [ 0.68124992 -0.73197985 -0.01020141]]
planes
[[ 0.43976375  0.42034706 -0.79367262]
 [ 0.58524048  0.53620321  0.60825956]
 [ 0.68124992 -0.73197985 -0.01020141]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  13.363407  258.52625  -460.2765  ]
[-36.95856136 -54.73819929  18.53830643]
[ 0.   0.  -9.8]
transform [[ 0.43976375  0.42034706 -0.79367262]
 [ 0.58524048  0.53620321  0.60825956]
 [ 0.68124992 -0.73197985 -0.01020141]]
transform [[ 0.43976375  0.42034706 -0.79367262]
 [ 0.58524048  0.53620321  0.60825956]
 [ 0.68124992 -0.73197985 -0.01020141]]
transform [[ 0.43976375  0.42034706 -0.79367262]
 [ 0.58524048  0.53620321  0.60825956]
 [ 0.68124992 -0.73197985 -0.01020141]]
support
[-0.96679738  0.74093995 -0.01242665]
[ 479.85633812 -133.52416602 -175.43671326]
[-53.97542337 -39.70434215  14.70012508]
[ 7.77799169 -5.96094368  0.09997379]
zmp_s [       0.          2361001.18424709 13927182.55852348]
transform [[ 0.43976375  0.58524048  0.68124992]
 [ 0.42034706  0.53620321 -0.73197985]
 [-0.79367262  0.60825956 -0.01020141]]
zmp [10869645.4299223  -8928440.55430885  1294024.67241767]
d1:19442972.84253, d2:0.05940, d3:7365559.14659
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-264.272446338741 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-140.43578478514905 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-214.24374279296464 steps:91[00m
[RDDPG] Resetting Environment
transform [[ 0.32515243  0.29529011 -0.89837611]
 [ 0.64028758  0.63036835  0.4389393 ]
 [ 0.69592232 -0.71794122  0.01589523]]
planes
[[ 0.32515243  0.29529011 -0.89837611]
 [ 0.64028758  0.63036835  0.4389393 ]
 [ 0.69592232 -0.71794122  0.01589523]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -90.93995 -954.87006  795.42395]
[ -12.25120224 -245.20469768   11.45732593]
[ 0.   0.  -9.8]
transform [[ 0.32515243  0.29529011 -0.89837611]
 [ 0.64028758  0.63036835  0.4389393 ]
 [ 0.69592232 -0.71794122  0.01589523]]
transform [[ 0.32515243  0.29529011 -0.89837611]
 [ 0.64028758  0.63036835  0.4389393 ]
 [ 0.69592232 -0.71794122  0.01589523]]
transform [[ 0.32515243  0.29529011 -0.89837611]
 [ 0.64028758  0.63036835  0.4389393 ]
 [ 0.69592232 -0.71794122  0.01589523]]
support
[-1.09433997  0.53468566  0.01936248]
[-1026.1229034   -311.00474892   634.89688771]
[ -86.68301877 -157.38450311  167.69879278]
[ 8.80408585 -4.30160517 -0.1557733 ]
zmp_s [        0.         -15388312.96129227 -19405688.50872966]
transform [[ 0.32515243  0.64028758  0.69592232]
 [ 0.29529011  0.63036835 -0.71794122]
 [-0.89837611  0.4389393   0.01589523]]
zmp [-23357797.31062811   4231838.29118877  -7062993.33597836]
d1:31413574.88562, d2:0.05940, d3:13752050.05916
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-348.1166902467867 steps:93[00m
[RDDPG] Resetting Environment
transform [[ 0.13072148 -0.08242309 -0.98798704]
 [ 0.98931199  0.07578266  0.1245746 ]
 [ 0.06460445 -0.99371195  0.09144857]]
planes
[[ 0.13072148 -0.08242309 -0.98798704]
 [ 0.98931199  0.07578266  0.1245746 ]
 [ 0.06460445 -0.99371195  0.09144857]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -90.93995 -954.87006  795.42395]
[ -12.25120224 -245.20469768   11.45732593]
[ 0.   0.  -9.8]
transform [[ 0.13072148 -0.08242309 -0.98798704]
 [ 0.98931199  0.07578266  0.1245746 ]
 [ 0.06460445 -0.99371195  0.09144857]]
transform [[ 0.13072148 -0.08242309 -0.98798704]
 [ 0.98931199  0.07578266  0.1245746 ]
 [ 0.06460445 -0.99371195  0.09144857]]
transform [[ 0.13072148 -0.08242309 -0.98798704]
 [ 0.98931199  0.07578266  0.1245746 ]
 [ 0.06460445 -0.99371195  0.09144857]]
support
[-1.20349784  0.15174821  0.11139635]
[-719.0530185   -63.24095013 1015.73103928]
[  7.28934426 -29.27523291 243.91911171]
[ 9.68227301 -1.2208311  -0.89619596]
zmp_s [       0.          8438349.60496499 -4548018.56907372]
transform [[ 0.13072148  0.98931199  0.06460445]
 [-0.08242309  0.07578266 -0.99371195]
 [-0.98798704  0.1245746   0.09144857]]
zmp [8054338.21108323 5158900.94458112  635294.25611946]
d1:7754982.61550, d2:0.05940, d3:4100621.02488
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-208.28360579116833 steps:95[00m
[RDDPG] Resetting Environment
transform [[ 0.39890784  0.35289779  0.84636623]
 [-0.59792846 -0.5996775   0.53185391]
 [ 0.6952368  -0.71822709 -0.02820841]]
planes
[[ 0.39890784  0.35289779  0.84636623]
 [-0.59792846 -0.5996775   0.53185391]
 [ 0.6952368  -0.71822709 -0.02820841]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 907.17993 -321.39362  754.1982 ]
[  61.81966424 -432.13603634  -28.04071052]
[ 0.   0.  -9.8]
transform [[ 0.39890784  0.35289779  0.84636623]
 [-0.59792846 -0.5996775   0.53185391]
 [ 0.6952368  -0.71822709 -0.02820841]]
transform [[ 0.39890784  0.35289779  0.84636623]
 [-0.59792846 -0.5996775   0.53185391]
 [ 0.6952368  -0.71822709 -0.02820841]]
transform [[ 0.39890784  0.35289779  0.84636623]
 [-0.59792846 -0.5996775   0.53185391]
 [ 0.6952368  -0.71822709 -0.02820841]]
support
[ 1.03098511  0.64786785 -0.03436154]
[886.78995831  51.42707229 840.26374649]
[-151.57221514  207.26496071  354.14209664]
[-8.29438902 -5.21216836  0.27644239]
zmp_s [        0.         -10736815.80949243   5116903.71512875]
transform [[ 0.39890784 -0.59792846  0.6952368 ]
 [ 0.35289779 -0.5996775  -0.71822709]
 [ 0.84636623  0.53185391 -0.02820841]]
zmp [ 9977307.56521722  2763528.03877442 -5854757.2157212 ]
d1:17671495.99536, d2:0.05940, d3:6070864.63223
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-283.79425277821804 steps:97[00m
[RDDPG] Resetting Environment
transform [[ 0.27234823 -0.08304141 -0.95860869]
 [ 0.96186978  0.04954697  0.26898262]
 [ 0.02515946 -0.99531364  0.09336904]]
planes
[[ 0.27234823 -0.08304141 -0.95860869]
 [ 0.96186978  0.04954697  0.26898262]
 [ 0.02515946 -0.99531364  0.09336904]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 534.85547   -69.340675 1093.7362  ]
[  61.81966424 -432.13603634  -28.04071052]
[ 0.   0.  -9.8]
transform [[ 0.27234823 -0.08304141 -0.95860869]
 [ 0.96186978  0.04954697  0.26898262]
 [ 0.02515946 -0.99531364  0.09336904]]
transform [[ 0.27234823 -0.08304141 -0.95860869]
 [ 0.96186978  0.04954697  0.26898262]
 [ 0.02515946 -0.99531364  0.09336904]]
transform [[ 0.27234823 -0.08304141 -0.95860869]
 [ 0.96186978  0.04954697  0.26898262]
 [ 0.02515946 -0.99531364  0.09336904]]
support
[-1.16771115  0.32765612  0.11373574]
[-897.03994346  805.22171881  184.59349202]
[ 79.60172908  30.5089708  429.04810853]
[ 9.39436513 -2.63602967 -0.91501656]
zmp_s [       0.         -3714573.99480226 -9481143.16226673]
transform [[ 0.27234823  0.96186978  0.02515946]
 [-0.08304141  0.04954697 -0.99531364]
 [-0.95860869  0.26898262  0.09336904]]
zmp [-3811476.9128847   9252665.26059623 -1884401.04766075]
d1:12898910.56002, d2:0.05940, d3:2892797.37553
transform [[ 0.38522071  0.07822193 -0.91950333]
 [ 0.56630379  0.76668829  0.30247173]
 [ 0.72863233 -0.63723654  0.25104684]]
planes
[[ 0.38522071  0.07822193 -0.91950333]
 [ 0.56630379  0.76668829  0.30247173]
 [ 0.72863233 -0.63723654  0.25104684]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-581.0556 -663.7689   96.7725]
[ 19.40129129 -88.67635011  -8.80635731]
[ 0.   0.  -9.8]
transform [[ 0.38522071  0.07822193 -0.91950333]
 [ 0.56630379  0.76668829  0.30247173]
 [ 0.72863233 -0.63723654  0.25104684]]
transform [[ 0.38522071  0.07822193 -0.91950333]
 [ 0.56630379  0.76668829  0.30247173]
 [ 0.72863233 -0.63723654  0.25104684]]
transform [[ 0.38522071  0.07822193 -0.91950333]
 [ 0.56630379  0.76668829  0.30247173]
 [ 0.72863233 -0.63723654  0.25104684]]
support
[-1.1200757   0.36845025  0.30580798]
[-364.7385726  -808.68690213   23.89633889]
[  8.63481859 -59.66376831  68.43341008]
[ 9.01113265 -2.96422293 -2.460259  ]
zmp_s [      0.         -263426.3522854  9486242.40603567]
transform [[ 0.38522071  0.56630379  0.72863233]
 [ 0.07822193  0.76668829 -0.63723654]
 [-0.91950333  0.30247173  0.25104684]]
zmp [ 6762803.57415589 -6246946.14505409  2301812.12138485]
d1:13153014.42899, d2:0.05940, d3:5607617.09230
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-746.5978714451128 steps:100[00m
[RDDPG] Resetting Environment
transform [[ 0.6885708   0.66999996  0.27743548]
 [-0.20397028 -0.18819307  0.96071821]
 [ 0.69589263 -0.71811104  0.00707585]]
planes
[[ 0.6885708   0.66999996  0.27743548]
 [-0.20397028 -0.18819307  0.96071821]
 [ 0.69589263 -0.71811104  0.00707585]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-26.342386 263.2916   741.95276 ]
[   3.31993058 -350.72613268   14.69397061]
[ 0.   0.  -9.8]
transform [[ 0.6885708   0.66999996  0.27743548]
 [-0.20397028 -0.18819307  0.96071821]
 [ 0.69589263 -0.71811104  0.00707585]]
transform [[ 0.6885708   0.66999996  0.27743548]
 [-0.20397028 -0.18819307  0.96071821]
 [ 0.69589263 -0.71811104  0.00707585]]
transform [[ 0.6885708   0.66999996  0.27743548]
 [-0.20397028 -0.18819307  0.96071821]
 [ 0.69589263 -0.71811104  0.00707585]]
support
[0.33795282 1.17028083 0.00861931]
[ 364.11078068  668.63094056 -202.15412675]
[-228.62385779   79.44382494  254.27459483]
[-2.71886772 -9.4150385  -0.06934333]
zmp_s [        0.         -12804728.14977767 -12727455.58244565]
transform [[ 0.6885708  -0.20397028  0.69589263]
 [ 0.66999996 -0.18819307 -0.71811104]
 [ 0.27743548  0.96071821  0.00707585]]
zmp [ -6245158.53612392  11549487.41629461 -12391793.13686234]
d1:29393911.98671, d2:0.05940, d3:13438428.82608
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-255.79600404461794 steps:102[00m
[RDDPG] Resetting Environment
transform [[ 0.6954363   0.67373776 -0.24989177]
 [ 0.16831654  0.18535285  0.96814972]
 [ 0.69859713 -0.71534735  0.0154999 ]]
planes
[[ 0.6954363   0.67373776 -0.24989177]
 [ 0.16831654  0.18535285  0.96814972]
 [ 0.69859713 -0.71534735  0.0154999 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 476.64084 -410.7283   491.63333]
[  16.67882538 -544.95386875  -20.14995891]
[ 0.   0.  -9.8]
transform [[ 0.6954363   0.67373776 -0.24989177]
 [ 0.16831654  0.18535285  0.96814972]
 [ 0.69859713 -0.71534735  0.0154999 ]]
transform [[ 0.6954363   0.67373776 -0.24989177]
 [ 0.16831654  0.18535285  0.96814972]
 [ 0.69859713 -0.71534735  0.0154999 ]]
transform [[ 0.6954363   0.67373776 -0.24989177]
 [ 0.16831654  0.18535285  0.96814972]
 [ 0.69859713 -0.71534735  0.0154999 ]]
support
[-0.30440097  1.17933338  0.01888091]
[-68.10495202 480.07155098 634.41359136]
[-350.52163166 -117.70960592  401.17076301]
[ 2.44893937 -9.48786727 -0.15189898]
zmp_s [       0.         15086486.10775707   732683.55857643]
transform [[ 0.6954363   0.16831654  0.69859713]
 [ 0.67373776  0.18535285 -0.71534735]
 [-0.24989177  0.96814972  0.0154999 ]]
zmp [ 3051155.8227527   2272199.90924326 14617333.84471607]
d1:29451964.48664, d2:0.05940, d3:9747325.80832
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-142.0606463780078 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-84.56064953123338 steps:105[00m
[RDDPG] Resetting Environment
transform [[ 0.20703742 -0.17906472  0.9618063 ]
 [-0.68713397  0.6731903   0.27324325]
 [-0.69640684 -0.71746135  0.01633412]]
planes
[[ 0.20703742 -0.17906472  0.9618063 ]
 [-0.68713397  0.6731903   0.27324325]
 [-0.69640684 -0.71746135  0.01633412]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 476.64084 -410.7283   491.63333]
[  16.67882538 -544.95386875  -20.14995891]
[ 0.   0.  -9.8]
transform [[ 0.20703742 -0.17906472  0.9618063 ]
 [-0.68713397  0.6731903   0.27324325]
 [-0.69640684 -0.71746135  0.01633412]]
transform [[ 0.20703742 -0.17906472  0.9618063 ]
 [-0.68713397  0.6731903   0.27324325]
 [-0.69640684 -0.71746135  0.01633412]]
transform [[ 0.20703742 -0.17906472  0.9618063 ]
 [-0.68713397  0.6731903   0.27324325]
 [-0.69640684 -0.71746135  0.01633412]]
support
[1.17160626 0.33284613 0.0198971 ]
[ 645.08547181 -469.67892927  -29.22386097]
[  81.65479598 -383.82408373  379.03895705]
[-9.42570171 -2.67778383 -0.1600744 ]
zmp_s [        0.          -4955370.89282925 -13800053.52976436]
transform [[ 0.20703742 -0.68713397 -0.69640684]
 [-0.17906472  0.6731903  -0.71746135]
 [ 0.9618063   0.27324325  0.01633412]]
zmp [13015455.35202072  6565097.40551191 -1579433.398702  ]
d1:19986139.76508, d2:0.05940, d3:7212780.28637
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-326.2065492120182 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-108.6659437207072 steps:108[00m
[RDDPG] Resetting Environment
transform [[ 0.10934379  0.12870502 -0.98563635]
 [ 0.69454676  0.69946438  0.16838761]
 [ 0.71108985 -0.70298266 -0.01290957]]
planes
[[ 0.10934379  0.12870502 -0.98563635]
 [ 0.69454676  0.69946438  0.16838761]
 [ 0.71108985 -0.70298266 -0.01290957]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-115.79519 -273.64    -923.24945]
[-134.27831167 -189.24896597   16.54429181]
[ 0.   0.  -9.8]
transform [[ 0.10934379  0.12870502 -0.98563635]
 [ 0.69454676  0.69946438  0.16838761]
 [ 0.71108985 -0.70298266 -0.01290957]]
transform [[ 0.10934379  0.12870502 -0.98563635]
 [ 0.69454676  0.69946438  0.16838761]
 [ 0.71108985 -0.70298266 -0.01290957]]
transform [[ 0.10934379  0.12870502 -0.98563635]
 [ 0.69454676  0.69946438  0.16838761]
 [ 0.71108985 -0.70298266 -0.01290957]]
support
[-1.20063439  0.2051182  -0.01572556]
[ 862.10789232 -427.29038199  121.94216056]
[ -55.34644774 -222.84962327   37.34121808]
[ 9.65923626 -1.65019855  0.12651383]
zmp_s [       0.         12558496.57152923  3581621.1467628 ]
transform [[ 0.10934379  0.69454676  0.71108985]
 [ 0.12870502  0.69946438 -0.70298266]
 [-0.98563635  0.16838761 -0.01290957]]
zmp [11269317.53540035  6266403.45186631  2068457.97714318]
d1:18472246.35290, d2:0.05940, d3:3014305.20010
transform [[ 0.08807995  0.08651516 -0.99234927]
 [-0.03720202 -0.99524045 -0.09006923]
 [-0.99541849  0.04485068 -0.08444218]]
planes
[[ 0.08807995  0.08651516 -0.99234927]
 [-0.03720202 -0.99524045 -0.09006923]
 [-0.99541849  0.04485068 -0.08444218]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  149.1005 -2029.2035  1092.2911]
[-191.06309266 -285.78202878  -65.63818338]
[ 0.   0.  -9.8]
transform [[ 0.08807995  0.08651516 -0.99234927]
 [-0.03720202 -0.99524045 -0.09006923]
 [-0.99541849  0.04485068 -0.08444218]]
transform [[ 0.08807995  0.08651516 -0.99234927]
 [-0.03720202 -0.99524045 -0.09006923]
 [-0.99541849  0.04485068 -0.08444218]]
transform [[ 0.08807995  0.08651516 -0.99234927]
 [-0.03720202 -0.99524045 -0.09006923]
 [-0.99541849  0.04485068 -0.08444218]]
support
[-1.2088116  -0.10971614 -0.10286166]
[-1246.358407    1915.61673015  -331.66400336]
[ 23.5826977  297.44174796 182.91284685]
[9.72502282 0.8826785  0.8275334 ]
zmp_s [        0.         -10068849.8351862   15723243.98000625]
transform [[ 0.08807995 -0.03720202 -0.99541849]
 [ 0.08651516 -0.99524045  0.04485068]
 [-0.99234927 -0.09006923 -0.08444218]]
zmp [-15276626.25660281  10726124.8982467    -420811.45576153]
d1:9879090.35257, d2:0.05940, d3:1819218.35376
transform [[-0.05559131  0.9646619   0.25755975]
 [ 0.29620692  0.26227957 -0.91840667]
 [-0.95350468  0.02523553 -0.30032003]]
planes
[[-0.05559131  0.9646619   0.25755975]
 [ 0.29620692  0.26227957 -0.91840667]
 [-0.95350468  0.02523553 -0.30032003]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  149.1005 -2029.2035  1092.2911]
[-191.06309266 -285.78202878  -65.63818338]
[ 0.   0.  -9.8]
transform [[-0.05559131  0.9646619   0.25755975]
 [ 0.29620692  0.26227957 -0.91840667]
 [-0.95350468  0.02523553 -0.30032003]]
transform [[-0.05559131  0.9646619   0.25755975]
 [ 0.29620692  0.26227957 -0.91840667]
 [-0.95350468  0.02523553 -0.30032003]]
transform [[-0.05559131  0.9646619   0.25755975]
 [ 0.29620692  0.26227957 -0.91840667]
 [-0.95350468  0.02523553 -0.30032003]]
support
[ 0.31374156 -1.11873981 -0.3658292 ]
[-1684.45375113 -1491.22148225  -521.41295897]
[-281.9673398   -71.26645299  194.68015246]
[-2.52408552  9.00038532  2.94313629]
zmp_s [        0.         -19650001.27899931 -16250542.42000838]
transform [[-0.05559131  0.29620692 -0.95350468]
 [ 0.9646619   0.26227957  0.02523553]
 [ 0.25755975 -0.91840667 -0.30032003]]
zmp [ 9674501.89264921 -5563884.99908897 22927055.52332809]
d1:45518663.06052, d2:0.05940, d3:17171967.74954
transform [[-0.05508721  0.96510679  0.25599661]
 [ 0.29630113  0.26063776 -0.91884369]
 [-0.95350468  0.02523553 -0.30032003]]
planes
[[-0.05508721  0.96510679  0.25599661]
 [ 0.29630113  0.26063776 -0.91884369]
 [-0.95350468  0.02523553 -0.30032003]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  149.1005 -2029.2035  1092.2911]
[-191.06309266 -285.78202878  -65.63818338]
[ 0.   0.  -9.8]
transform [[-0.05508721  0.96510679  0.25599661]
 [ 0.29630113  0.26063776 -0.91884369]
 [-0.95350468  0.02523553 -0.30032003]]
transform [[-0.05508721  0.96510679  0.25599661]
 [ 0.29630113  0.26063776 -0.91884369]
 [-0.95350468  0.02523553 -0.30032003]]
transform [[-0.05508721  0.96510679  0.25599661]
 [ 0.29630113  0.26063776 -0.91884369]
 [-0.95350468  0.02523553 -0.30032003]]
support
[ 0.31183746 -1.11927216 -0.3658292 ]
[-1686.98875411 -1488.3532242   -521.41295897]
[-282.08819608  -70.78656706  194.68015246]
[-2.50876682  9.00466813  2.94313629]
zmp_s [        0.         -19650001.27709195 -16250542.41962729]
transform [[-0.05508721  0.29630113 -0.95350468]
 [ 0.96510679  0.26063776  0.02523553]
 [ 0.25599661 -0.91884369 -0.30032003]]
zmp [ 9672650.76170852 -5531623.43115471 22935642.98969048]
d1:45528641.92157, d2:0.05940, d3:17182265.39541
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-411.7713402774265 steps:113[00m
[RDDPG] Resetting Environment
transform [[ 0.98942322  0.03935521  0.13961683]
 [-0.14232004  0.07726542  0.98680043]
 [ 0.02804818 -0.99623352  0.08204923]]
planes
[[ 0.98942322  0.03935521  0.13961683]
 [-0.14232004  0.07726542  0.98680043]
 [ 0.02804818 -0.99623352  0.08204923]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 156.89632 -642.08386  332.2579 ]
[ -11.99363973 -211.09059415   31.11325396]
[ 0.   0.  -9.8]
transform [[ 0.98942322  0.03935521  0.13961683]
 [-0.14232004  0.07726542  0.98680043]
 [ 0.02804818 -0.99623352  0.08204923]]
transform [[ 0.98942322  0.03935521  0.13961683]
 [-0.14232004  0.07726542  0.98680043]
 [ 0.02804818 -0.99623352  0.08204923]]
transform [[ 0.98942322  0.03935521  0.13961683]
 [-0.14232004  0.07726542  0.98680043]
 [ 0.02804818 -0.99623352  0.08204923]]
support
[0.17007162 1.20205239 0.09994672]
[176.35630575 255.93187507 671.32762946]
[-15.83036728  16.09950449 212.51194492]
[-1.36824495 -9.67064424 -0.80408244]
zmp_s [        0.         -13407519.25172674 -19623016.45973444]
transform [[ 0.98942322 -0.14232004  0.02804818]
 [ 0.03935521  0.07726542 -0.99623352]
 [ 0.13961683  0.98680043  0.08204923]]
zmp [  1357768.66271946  18513169.22382941 -14840599.14888098]
d1:42632263.24761, d2:0.05940, d3:7034677.96346
transform [[ 0.94600159  0.24110162  0.21668187]
 [-0.13077709 -0.32776964  0.93566263]
 [ 0.29661149 -0.91347533 -0.27854002]]
planes
[[ 0.94600159  0.24110162  0.21668187]
 [-0.13077709 -0.32776964  0.93566263]
 [ 0.29661149 -0.91347533 -0.27854002]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-739.74023 -401.32373 -168.62042]
[  71.87323825  -10.97082028 -220.71747865]
[ 0.   0.  -9.8]
transform [[ 0.94600159  0.24110162  0.21668187]
 [-0.13077709 -0.32776964  0.93566263]
 [ 0.29661149 -0.91347533 -0.27854002]]
transform [[ 0.94600159  0.24110162  0.21668187]
 [-0.13077709 -0.32776964  0.93566263]
 [ 0.29661149 -0.91347533 -0.27854002]]
transform [[ 0.94600159  0.24110162  0.21668187]
 [-0.13077709 -0.32776964  0.93566263]
 [ 0.29661149 -0.91347533 -0.27854002]]
support
[ 0.26394694  1.13975984 -0.33929828]
[-833.09222806   70.5109819   194.15141245]
[  17.52163951 -212.32056717   92.81865172]
[-2.1234823  -9.16949375  2.72969215]
zmp_s [        0.         -43096502.72972352   8344893.97713103]
transform [[ 0.94600159 -0.13077709  0.29661149]
 [ 0.24110162 -0.32776964 -0.91347533]
 [ 0.21668187  0.93566263 -0.27854002]]
zmp [  8111226.66876175   6502870.24200779 -42648173.86349836]
d1:85814805.53654, d2:0.05940, d3:23435448.37840
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-55.07079863156193 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-110.89877624025262 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-346.59833068360683 steps:118[00m
[RDDPG] Resetting Environment
transform [[ 0.68092334  0.65170175 -0.33410811]
 [ 0.23877499  0.23372477  0.94252813]
 [ 0.69233662 -0.72156602  0.00353857]]
planes
[[ 0.68092334  0.65170175 -0.33410811]
 [ 0.23877499  0.23372477  0.94252813]
 [ 0.69233662 -0.72156602  0.00353857]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[471.15308   10.205437 223.97809 ]
[  22.45172565 -201.11835709  -45.97106281]
[ 0.   0.  -9.8]
transform [[ 0.68092334  0.65170175 -0.33410811]
 [ 0.23877499  0.23372477  0.94252813]
 [ 0.69233662 -0.72156602  0.00353857]]
transform [[ 0.68092334  0.65170175 -0.33410811]
 [ 0.23877499  0.23372477  0.94252813]
 [ 0.69233662 -0.72156602  0.00353857]]
transform [[ 0.68092334  0.65170175 -0.33410811]
 [ 0.23877499  0.23372477  0.94252813]
 [ 0.69233662 -0.72156602  0.00353857]]
support
[-0.40698752  1.14812292  0.00431044]
[252.63713176 325.9904806  319.62519361]
[-100.42197576  -84.97445169  160.50165275]
[ 3.27425952 -9.23677566 -0.03467799]
zmp_s [       0.         19117105.02469407 -1402010.81947662]
transform [[ 0.68092334  0.23877499  0.69233662]
 [ 0.65170175  0.23372477 -0.72156602]
 [-0.33410811  0.94252813  0.00353857]]
zmp [ 3594023.0365304   5479784.40000732 18013448.10969292]
d1:36891948.79154, d2:0.05940, d3:12017752.91282
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-323.11574025887694 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-216.04361437500813 steps:121[00m
[RDDPG] Resetting Environment
transform [[ 0.69831544 -0.69009417  0.1900676 ]
 [-0.15809959  0.11027441  0.98124617]
 [-0.69811183 -0.71526897 -0.03209728]]
planes
[[ 0.69831544 -0.69009417  0.1900676 ]
 [-0.15809959  0.11027441  0.98124617]
 [-0.69811183 -0.71526897 -0.03209728]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[471.15308   10.205437 223.97809 ]
[  22.45172565 -201.11835709  -45.97106281]
[ 0.   0.  -9.8]
transform [[ 0.69831544 -0.69009417  0.1900676 ]
 [-0.15809959  0.11027441  0.98124617]
 [-0.69811183 -0.71526897 -0.03209728]]
transform [[ 0.69831544 -0.69009417  0.1900676 ]
 [-0.15809959  0.11027441  0.98124617]
 [-0.69811183 -0.71526897 -0.03209728]]
transform [[ 0.69831544 -0.69009417  0.1900676 ]
 [-0.15809959  0.11027441  0.98124617]
 [-0.69811183 -0.71526897 -0.03209728]]
support
[ 0.23152728  1.19528658 -0.03909869]
[ 364.5417347   146.41393169 -343.40625601]
[145.73138324 -70.83674665 129.6554506 ]
[-1.86266252 -9.6162125   0.31455331]
zmp_s [        0.          -2152936.24953604 -25605728.01539084]
transform [[ 0.69831544 -0.15809959 -0.69811183]
 [-0.69009417  0.11027441 -0.71526897]
 [ 0.1900676   0.98124617 -0.03209728]]
zmp [18216040.04022779 18077568.91335645 -1290686.32941465]
d1:35585518.14547, d2:0.05940, d3:12366602.36600
transform [[ 0.48706406 -0.32179424 -0.81192183]
 [ 0.87302899  0.20522316  0.44238424]
 [ 0.02426845 -0.92430079  0.38089254]]
planes
[[ 0.48706406 -0.32179424 -0.81192183]
 [ 0.87302899  0.20522316  0.44238424]
 [ 0.02426845 -0.92430079  0.38089254]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[471.15308   10.205437 223.97809 ]
[  22.45172565 -201.11835709  -45.97106281]
[ 0.   0.  -9.8]
transform [[ 0.48706406 -0.32179424 -0.81192183]
 [ 0.87302899  0.20522316  0.44238424]
 [ 0.02426845 -0.92430079  0.38089254]]
transform [[ 0.48706406 -0.32179424 -0.81192183]
 [ 0.87302899  0.20522316  0.44238424]
 [ 0.02426845 -0.92430079  0.38089254]]
transform [[ 0.48706406 -0.32179424 -0.81192183]
 [ 0.87302899  0.20522316  0.44238424]
 [ 0.02426845 -0.92430079  0.38089254]]
support
[-0.98902732  0.53888205  0.46397709]
[ 44.34498056 512.50906495  87.31284499]
[112.9790676  -42.01001075 168.92868974]
[ 7.95683398 -4.33536558 -3.73274694]
zmp_s [       0.         12397958.91856476  1020759.86625394]
transform [[ 0.48706406  0.87302899  0.02426845]
 [-0.32179424  0.20522316 -0.92430079]
 [-0.81192183  0.44238424  0.38089254]]
zmp [10848549.85554496  1600859.13143726  5873461.49435246]
d1:11133013.50717, d2:0.05940, d3:7611175.27410
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-284.75636077548415 steps:124[00m
[RDDPG] Resetting Environment
transform [[ 0.7594949  -0.64875609  0.04778253]
 [ 0.0012787   0.07494232  0.99718702]
 [-0.65051216 -0.75729734  0.05774787]]
planes
[[ 0.7594949  -0.64875609  0.04778253]
 [ 0.0012787   0.07494232  0.99718702]
 [-0.65051216 -0.75729734  0.05774787]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[471.15308   10.205437 223.97809 ]
[  22.45172565 -201.11835709  -45.97106281]
[ 0.   0.  -9.8]
transform [[ 0.7594949  -0.64875609  0.04778253]
 [ 0.0012787   0.07494232  0.99718702]
 [-0.65051216 -0.75729734  0.05774787]]
transform [[ 0.7594949  -0.64875609  0.04778253]
 [ 0.0012787   0.07494232  0.99718702]
 [-0.65051216 -0.75729734  0.05774787]]
transform [[ 0.7594949  -0.64875609  0.04778253]
 [ 0.0012787   0.07494232  0.99718702]
 [-0.65051216 -0.75729734  0.05774787]]
support
[0.05820539 1.21470462 0.07034449]
[ 361.91975999  224.71532565 -301.28509626]
[145.33211566 -60.88531438 135.04654457]
[-0.46826882 -9.77243278 -0.56592917]
zmp_s [      0.         8595983.80646898 -882135.23699443]
transform [[ 0.7594949   0.0012787  -0.65051216]
 [-0.64875609  0.07494232 -0.75729734]
 [ 0.04778253  0.99718702  0.05774787]]
zmp [ 584831.39957612 1312241.64006847 8520862.02726228]
d1:17157605.73809, d2:0.05940, d3:6025754.72830
transform [[ 0.43587315  0.82930124  0.34967706]
 [-0.16040549 -0.31072488  0.93686724]
 [ 0.88559854 -0.46444538 -0.00241216]]
planes
[[ 0.43587315  0.82930124  0.34967706]
 [-0.16040549 -0.31072488  0.93686724]
 [ 0.88559854 -0.46444538 -0.00241216]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-705.64056 -113.23535  882.7287 ]
[ -21.52922292 -295.46240869  -32.41227948]
[ 0.   0.  -9.8]
transform [[ 0.43587315  0.82930124  0.34967706]
 [-0.16040549 -0.31072488  0.93686724]
 [ 0.88559854 -0.46444538 -0.00241216]]
transform [[ 0.43587315  0.82930124  0.34967706]
 [-0.16040549 -0.31072488  0.93686724]
 [ 0.88559854 -0.46444538 -0.00241216]]
transform [[ 0.43587315  0.82930124  0.34967706]
 [-0.16040549 -0.31072488  0.93686724]
 [ 0.88559854 -0.46444538 -0.00241216]]
support
[ 0.42595253  1.14122721 -0.00293833]
[ -92.80602052  975.37325677 -574.45189904]
[-265.74518202   64.89492551  118.23808655]
[-3.42683515 -9.18129892  0.02363916]
zmp_s [        0.          -1380181.10348051 -25577545.21986559]
transform [[ 0.43587315 -0.16040549  0.88559854]
 [ 0.82930124 -0.31072488 -0.46444538]
 [ 0.34967706  0.93686724 -0.00241216]]
zmp [-22430048.08951952  12308229.38303768  -1231349.35726403]
d1:39603325.01040, d2:0.05940, d3:12289898.15359
transform [[ 0.82980418  0.46115732  0.31425938]
 [-0.04638365 -0.50419027  0.86234611]
 [ 0.55612379 -0.73015493 -0.39698899]]
planes
[[ 0.82980418  0.46115732  0.31425938]
 [-0.04638365 -0.50419027  0.86234611]
 [ 0.55612379 -0.73015493 -0.39698899]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-705.64056 -113.23535  882.7287 ]
[ -21.52922292 -295.46240869  -32.41227948]
[ 0.   0.  -9.8]
transform [[ 0.82980418  0.46115732  0.31425938]
 [-0.04638365 -0.50419027  0.86234611]
 [ 0.55612379 -0.73015493 -0.39698899]]
transform [[ 0.82980418  0.46115732  0.31425938]
 [-0.04638365 -0.50419027  0.86234611]
 [ 0.55612379 -0.73015493 -0.39698899]]
transform [[ 0.82980418  0.46115732  0.31425938]
 [-0.04638365 -0.50419027  0.86234611]
 [ 0.55612379 -0.73015493 -0.39698899]]
support
[ 0.38280916  1.05045071 -0.48358467]
[-360.35702882  851.04001093 -660.17772937]
[-164.30555519  122.01727126  216.6277397 ]
[-3.07974193 -8.4509919   3.89049208]
zmp_s [       0.          3745585.53400596 11047935.48941403]
transform [[ 0.82980418 -0.04638365  0.55612379]
 [ 0.46115732 -0.50419027 -0.73015493]
 [ 0.31425938  0.86234611 -0.39698899]]
zmp [ 5970285.85149773 -9955192.34820149 -1155917.60343669]
d1:16214693.60144, d2:0.05940, d3:5056427.86640
transform [[ 0.67528564 -0.63152611 -0.38100418]
 [-0.16373287  0.37532845 -0.91231585]
 [ 0.71915329  0.67845631  0.15005213]]
planes
[[ 0.67528564 -0.63152611 -0.38100418]
 [-0.16373287  0.37532845 -0.91231585]
 [ 0.71915329  0.67845631  0.15005213]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -173.2173   943.8029 -1076.6711]
[  31.91217542 -157.02016003  -56.38254403]
[ 0.   0.  -9.8]
transform [[ 0.67528564 -0.63152611 -0.38100418]
 [-0.16373287  0.37532845 -0.91231585]
 [ 0.71915329  0.67845631  0.15005213]]
transform [[ 0.67528564 -0.63152611 -0.38100418]
 [-0.16373287  0.37532845 -0.91231585]
 [ 0.71915329  0.67845631  0.15005213]]
transform [[ 0.67528564 -0.63152611 -0.38100418]
 [-0.16373287  0.37532845 -0.91231585]
 [ 0.71915329  0.67845631  0.15005213]]
support
[-0.46411308 -1.1113204   0.18278318]
[-302.79113198 1364.86159717  354.20245231]
[142.19415018 -12.72051729 -92.04189286]
[ 3.73384101  8.94069529 -1.47051088]
zmp_s [        0.         -28088875.55112552  33965479.6779067 ]
transform [[ 0.67528564 -0.16373287  0.71915329]
 [-0.63152611  0.37532845  0.67845631]
 [-0.38100418 -0.91231585  0.15005213]]
zmp [29025458.53662382 12501539.72729872 30722518.82696732]
d1:78973292.35396, d2:0.05940, d3:23895432.84304
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-28.83336159677856 steps:129[00m
[RDDPG] Resetting Environment
transform [[ 0.7118839  -0.700333   -0.0524887 ]
 [ 0.0713857  -0.00219372  0.99744636]
 [-0.69865972 -0.71381301  0.04843209]]
planes
[[ 0.7118839  -0.700333   -0.0524887 ]
 [ 0.0713857  -0.00219372  0.99744636]
 [-0.69865972 -0.71381301  0.04843209]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -173.2173   943.8029 -1076.6711]
[  31.91217542 -157.02016003  -56.38254403]
[ 0.   0.  -9.8]
transform [[ 0.7118839  -0.700333   -0.0524887 ]
 [ 0.0713857  -0.00219372  0.99744636]
 [-0.69865972 -0.71381301  0.04843209]]
transform [[ 0.7118839  -0.700333   -0.0524887 ]
 [ 0.0713857  -0.00219372  0.99744636]
 [-0.69865972 -0.71381301  0.04843209]]
transform [[ 0.7118839  -0.700333   -0.0524887 ]
 [ 0.0713857  -0.00219372  0.99744636]
 [-0.69865972 -0.71381301  0.04843209]]
support
[-0.06393813  1.21502053  0.05899663]
[ -727.77386356 -1088.35738739  -604.82427717]
[135.64361021 -53.61603201  87.05655688]
[ 0.51438929 -9.77497431 -0.47463444]
zmp_s [        0.         -21248250.56873054   5471322.1859358 ]
transform [[ 0.7118839   0.0713857  -0.69865972]
 [-0.700333   -0.00219372 -0.71381301]
 [-0.0524887   0.99744636  0.04843209]]
zmp [ -5339413.74092545  -3858888.2519402  -20929002.60318441]
d1:42682773.26761, d2:0.05940, d3:16201964.79590
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-370.6267136708168 steps:131[00m
[RDDPG] Resetting Environment
transform [[ 0.36758578 -0.27938682  0.88703084]
 [-0.6195659   0.63774842  0.45761895]
 [-0.69355524 -0.71778828  0.06132874]]
planes
[[ 0.36758578 -0.27938682  0.88703084]
 [-0.6195659   0.63774842  0.45761895]
 [-0.69355524 -0.71778828  0.06132874]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -173.2173   943.8029 -1076.6711]
[  31.91217542 -157.02016003  -56.38254403]
[ 0.   0.  -9.8]
transform [[ 0.36758578 -0.27938682  0.88703084]
 [-0.6195659   0.63774842  0.45761895]
 [-0.69355524 -0.71778828  0.06132874]]
transform [[ 0.36758578 -0.27938682  0.88703084]
 [-0.6195659   0.63774842  0.45761895]
 [-0.69355524 -0.71778828  0.06132874]]
transform [[ 0.36758578 -0.27938682  0.88703084]
 [-0.6195659   0.63774842  0.45761895]
 [-0.69355524 -0.71778828  0.06132874]]
support
[1.08051994 0.55743992 0.07470645]
[-1282.39881842   216.52323329  -623.34578968]
[   5.58676939 -145.71277552   87.11650377]
[-8.69290223 -4.48466573 -0.60102164]
zmp_s [        0.          -4535045.69762906 -14800216.33461706]
transform [[ 0.36758578 -0.6195659  -0.69355524]
 [-0.27938682  0.63774842 -0.71778828]
 [ 0.88703084  0.45761895  0.06132874]]
zmp [13074527.2187447   7731203.58311709 -2983001.46216401]
d1:22293425.14037, d2:0.05940, d3:8602460.18174
transform [[ 0.71506089 -0.67556411  0.17972507]
 [-0.08757304  0.16850303  0.9818033 ]
 [-0.69355524 -0.71778828  0.06132874]]
planes
[[ 0.71506089 -0.67556411  0.17972507]
 [-0.08757304  0.16850303  0.9818033 ]
 [-0.69355524 -0.71778828  0.06132874]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -173.2173   943.8029 -1076.6711]
[  31.91217542 -157.02016003  -56.38254403]
[ 0.   0.  -9.8]
transform [[ 0.71506089 -0.67556411  0.17972507]
 [-0.08757304  0.16850303  0.9818033 ]
 [-0.69355524 -0.71778828  0.06132874]]
transform [[ 0.71506089 -0.67556411  0.17972507]
 [-0.08757304  0.16850303  0.9818033 ]
 [-0.69355524 -0.71778828  0.06132874]]
transform [[ 0.71506089 -0.67556411  0.17972507]
 [-0.08757304  0.16850303  0.9818033 ]
 [-0.69355524 -0.71778828  0.06132874]]
support
[0.21892871 1.19596523 0.07470645]
[-954.96508715 -882.87645998 -623.34578968]
[118.76297682 -84.60958693  87.11650377]
[-1.76130565 -9.62167232 -0.60102164]
zmp_s [        0.         -4535045.4172092 -14800215.9796354]
transform [[ 0.71506089 -0.08757304 -0.69355524]
 [-0.67556411  0.16850303 -0.71778828]
 [ 0.17972507  0.9818033   0.06132874]]
zmp [10661915.01644799  9859252.65855488 -5360201.12907072]
d1:23477085.87640, d2:0.05940, d3:9949026.39687
transform [[ 0.17105451 -0.08696912 -0.98141569]
 [ 0.18593146  0.98104841 -0.05452991]
 [ 0.96755874 -0.17314847  0.18398309]]
planes
[[ 0.17105451 -0.08696912 -0.98141569]
 [ 0.18593146  0.98104841 -0.05452991]
 [ 0.96755874 -0.17314847  0.18398309]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  63.142834 -369.90897   209.60179 ]
[-89.71536743  -7.32831289 -29.21793033]
[ 0.   0.  -9.8]
transform [[ 0.17105451 -0.08696912 -0.98141569]
 [ 0.18593146  0.98104841 -0.05452991]
 [ 0.96755874 -0.17314847  0.18398309]]
transform [[ 0.17105451 -0.08696912 -0.98141569]
 [ 0.18593146  0.98104841 -0.05452991]
 [ 0.96755874 -0.17314847  0.18398309]]
transform [[ 0.17105451 -0.08696912 -0.98141569]
 [ 0.18593146  0.98104841 -0.05452991]
 [ 0.96755874 -0.17314847  0.18398309]]
support
[-1.19549307 -0.06642458  0.22411554]
[-162.73496177 -362.58792785  163.70675628]
[ 13.96605375 -22.27708787 -90.91160689]
[ 9.61787375  0.53439307 -1.80303426]
zmp_s [      0.         9048358.16664352 4520987.60550956]
transform [[ 0.17105451  0.18593146  0.96755874]
 [-0.08696912  0.98104841 -0.17314847]
 [-0.98141569 -0.05452991  0.18398309]]
zmp [6056695.51434344 8094075.27043718  338379.14426883]
d1:4186338.82884, d2:0.05940, d3:1175256.61421
transform [[ 0.25262508  0.65361917 -0.71341616]
 [ 0.00327203  0.73675072  0.67615652]
 [ 0.96755874 -0.17314847  0.18398309]]
planes
[[ 0.25262508  0.65361917 -0.71341616]
 [ 0.00327203  0.73675072  0.67615652]
 [ 0.96755874 -0.17314847  0.18398309]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  63.142834 -369.90897   209.60179 ]
[-89.71536743  -7.32831289 -29.21793033]
[ 0.   0.  -9.8]
transform [[ 0.25262508  0.65361917 -0.71341616]
 [ 0.00327203  0.73675072  0.67615652]
 [ 0.96755874 -0.17314847  0.18398309]]
transform [[ 0.25262508  0.65361917 -0.71341616]
 [ 0.00327203  0.73675072  0.67615652]
 [ 0.96755874 -0.17314847  0.18398309]]
transform [[ 0.25262508  0.65361917 -0.71341616]
 [ 0.00327203  0.73675072  0.67615652]
 [ 0.96755874 -0.17314847  0.18398309]]
support
[-0.86903448  0.82364735  0.22411554]
[-375.36143311 -130.60047426  163.70675628]
[ -6.60973385 -25.44858569 -90.91160689]
[ 6.99147836 -6.6263339  -1.80303426]
zmp_s [      0.         9048356.90058963 4520988.4112471 ]
transform [[ 0.25262508  0.00327203  0.96755874]
 [ 0.65361917  0.73675072 -0.17314847]
 [-0.71341616  0.67615652  0.18398309]]
zmp [4403928.39132114 5883581.26093129 6949890.92788533]
d1:14994982.54439, d2:0.05940, d3:5111596.38866
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-553.195730377826 steps:136[00m
[RDDPG] Resetting Environment
transform [[ 0.7018683  -0.70546335  0.09850086]
 [-0.09951881  0.03980971  0.99423903]
 [-0.70532054 -0.70762748 -0.04226571]]
planes
[[ 0.7018683  -0.70546335  0.09850086]
 [-0.09951881  0.03980971  0.99423903]
 [-0.70532054 -0.70762748 -0.04226571]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  63.142834 -369.90897   209.60179 ]
[-89.71536743  -7.32831289 -29.21793033]
[ 0.   0.  -9.8]
transform [[ 0.7018683  -0.70546335  0.09850086]
 [-0.09951881  0.03980971  0.99423903]
 [-0.70532054 -0.70762748 -0.04226571]]
transform [[ 0.7018683  -0.70546335  0.09850086]
 [-0.09951881  0.03980971  0.99423903]
 [-0.70532054 -0.70762748 -0.04226571]]
transform [[ 0.7018683  -0.70546335  0.09850086]
 [-0.09951881  0.03980971  0.99423903]
 [-0.70532054 -0.70762748 -0.04226571]]
support
[ 0.11998697  1.21111359 -0.05148518]
[325.92112712 187.38441321 208.36284192]
[-60.676507   -20.41297791  69.69872325]
[-0.96530838 -9.74354252  0.41420395]
zmp_s [       0.          9536128.93103455 -4598666.6913919 ]
transform [[ 0.7018683  -0.09951881 -0.70532054]
 [-0.70546335  0.03980971 -0.70762748]
 [ 0.09850086  0.99423903 -0.04226571]]
zmp [2294509.82700131 3633773.43984903 9675557.51039746]
d1:20008881.64784, d2:0.05940, d3:8015661.94744
transform [[ 0.57938975  0.79710579  0.17008813]
 [-0.17869145 -0.07937853  0.98069799]
 [ 0.79522133 -0.59859967  0.09644486]]
planes
[[ 0.57938975  0.79710579  0.17008813]
 [-0.17869145 -0.07937853  0.98069799]
 [ 0.79522133 -0.59859967  0.09644486]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 366.77682 -652.84155  436.13477]
[ -57.91040724 -608.07777593   43.26906556]
[ 0.   0.  -9.8]
transform [[ 0.57938975  0.79710579  0.17008813]
 [-0.17869145 -0.07937853  0.98069799]
 [ 0.79522133 -0.59859967  0.09644486]]
transform [[ 0.57938975  0.79710579  0.17008813]
 [-0.17869145 -0.07937853  0.98069799]
 [ 0.79522133 -0.59859967  0.09644486]]
transform [[ 0.57938975  0.79710579  0.17008813]
 [-0.17869145 -0.07937853  0.98069799]
 [ 0.79522133 -0.59859967  0.09644486]]
support
[0.20718965 1.19461882 0.11748249]
[-233.69570232  413.99820932  724.52245008]
[-510.89545757  101.05030027  322.1166454 ]
[-1.66686365 -9.6108403  -0.94515963]
zmp_s [       0.         16591392.91919861 23656824.32510867]
transform [[ 0.57938975 -0.17869145  0.79522133]
 [ 0.79710579 -0.07937853 -0.59859967]
 [ 0.17008813  0.98069799  0.09644486]]
zmp [ 15847671.26862543 -15477967.67601755  18552724.79072514]
d1:42481415.80549, d2:0.05940, d3:21748311.82524
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-259.15828367506475 steps:139[00m
[RDDPG] Resetting Environment
transform [[ 0.71222389 -0.6991474   0.06269053]
 [-0.0620954   0.02620643  0.99772614]
 [-0.69920057 -0.71449715 -0.02474899]]
planes
[[ 0.71222389 -0.6991474   0.06269053]
 [-0.0620954   0.02620643  0.99772614]
 [-0.69920057 -0.71449715 -0.02474899]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 366.77682 -652.84155  436.13477]
[ -57.91040724 -608.07777593   43.26906556]
[ 0.   0.  -9.8]
transform [[ 0.71222389 -0.6991474   0.06269053]
 [-0.0620954   0.02620643  0.99772614]
 [-0.69920057 -0.71449715 -0.02474899]]
transform [[ 0.71222389 -0.6991474   0.06269053]
 [-0.0620954   0.02620643  0.99772614]
 [-0.69920057 -0.71449715 -0.02474899]]
transform [[ 0.71222389 -0.6991474   0.06269053]
 [-0.0620954   0.02620643  0.99772614]
 [-0.69920057 -0.71449715 -0.02474899]]
support
[ 0.0763653   1.21536134 -0.03014751]
[745.00121363 395.25925472 199.20896861]
[386.60338345  30.8310978  473.88996145]
[-0.61436723 -9.7777162   0.24254009]
zmp_s [       0.         18365880.53919763 -4940337.00919077]
transform [[ 0.71222389 -0.0620954  -0.69920057]
 [-0.6991474   0.02620643 -0.71449715]
 [ 0.06269053  0.99772614 -0.02474899]]
zmp [ 2313849.75825873  4011160.94015377 18446387.48584906]
d1:37062525.75494, d2:0.05940, d3:13706391.09579
transform [[ 0.18935396 -0.22137822 -0.95662785]
 [ 0.97385955 -0.08215053  0.21177568]
 [-0.12547    -0.97172165  0.20003577]]
planes
[[ 0.18935396 -0.22137822 -0.95662785]
 [ 0.97385955 -0.08215053  0.21177568]
 [-0.12547    -0.97172165  0.20003577]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 366.77682 -652.84155  436.13477]
[ -57.91040724 -608.07777593   43.26906556]
[ 0.   0.  -9.8]
transform [[ 0.18935396 -0.22137822 -0.95662785]
 [ 0.97385955 -0.08215053  0.21177568]
 [-0.12547    -0.97172165  0.20003577]]
transform [[ 0.18935396 -0.22137822 -0.95662785]
 [ 0.97385955 -0.08215053  0.21177568]
 [-0.12547    -0.97172165  0.20003577]]
transform [[ 0.18935396 -0.22137822 -0.95662785]
 [ 0.97385955 -0.08215053  0.21177568]
 [-0.12547    -0.97172165  0.20003577]]
support
[-1.16529823  0.25797056  0.24366981]
[-203.24311562  503.18312978  675.60333477]
[ 82.25721916   2.72064641 606.80371857]
[ 9.37495289 -2.07540162 -1.9603505 ]
zmp_s [       0.        21478466.3759052 -7809308.3194812]
transform [[ 0.18935396  0.97385955 -0.12547   ]
 [-0.22137822 -0.08215053 -0.97172165]
 [-0.95662785  0.21177568  0.20003577]]
zmp [21896843.46430653  5824006.48119643  2986475.75385823]
d1:14905956.31203, d2:0.05940, d3:11303202.75367
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-392.06742192828096 steps:142[00m
[RDDPG] Resetting Environment
transform [[ 0.35854021 -0.28737319 -0.88818109]
 [ 0.72346306 -0.51574731  0.45891827]
 [-0.58995777 -0.80710679  0.02298773]]
planes
[[ 0.35854021 -0.28737319 -0.88818109]
 [ 0.72346306 -0.51574731  0.45891827]
 [-0.58995777 -0.80710679  0.02298773]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 366.77682 -652.84155  436.13477]
[ -57.91040724 -608.07777593   43.26906556]
[ 0.   0.  -9.8]
transform [[ 0.35854021 -0.28737319 -0.88818109]
 [ 0.72346306 -0.51574731  0.45891827]
 [-0.58995777 -0.80710679  0.02298773]]
transform [[ 0.35854021 -0.28737319 -0.88818109]
 [ 0.72346306 -0.51574731  0.45891827]
 [-0.58995777 -0.80710679  0.02298773]]
transform [[ 0.35854021 -0.28737319 -0.88818109]
 [ 0.72346306 -0.51574731  0.45891827]
 [-0.58995777 -0.80710679  0.02298773]]
support
[-1.0819211   0.55902267  0.02800207]
[-68.25325647 802.20097104 320.55575979]
[115.55127206 291.57540096 525.94305598]
[ 8.70417469 -4.49739908 -0.22527973]
zmp_s [        0.         -13079832.10200951 -16352823.68832951]
transform [[ 0.35854021  0.72346306 -0.58995777]
 [-0.28737319 -0.51574731 -0.80710679]
 [-0.88818109  0.45891827  0.02298773]]
zmp [  184700.1198218  19944363.28765062 -6378488.21312252]
d1:27360962.68322, d2:0.05940, d3:10299082.83725
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-364.5643047976548 steps:144[00m
[RDDPG] Resetting Environment
transform [[ 0.11343979 -0.08461265  0.98993546]
 [-0.99246085 -0.05618165  0.10892718]
 [ 0.0463996  -0.99482882 -0.09034796]]
planes
[[ 0.11343979 -0.08461265  0.98993546]
 [-0.99246085 -0.05618165  0.10892718]
 [ 0.0463996  -0.99482882 -0.09034796]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-826.4693   449.04703  480.5008 ]
[343.32320249 278.77545615 120.87471949]
[ 0.   0.  -9.8]
transform [[ 0.11343979 -0.08461265  0.98993546]
 [-0.99246085 -0.05618165  0.10892718]
 [ 0.0463996  -0.99482882 -0.09034796]]
transform [[ 0.11343979 -0.08461265  0.98993546]
 [-0.99246085 -0.05618165  0.10892718]
 [ 0.0463996  -0.99482882 -0.09034796]]
transform [[ 0.11343979 -0.08461265  0.98993546]
 [-0.99246085 -0.05618165  0.10892718]
 [ 0.0463996  -0.99482882 -0.09034796]]
support
[ 1.20587127  0.13268759 -0.11005567]
[ 343.91521157  847.34981006 -528.48503392]
[ 135.0167543  -343.23036085 -272.32458428]
[-9.70136749 -1.06748632  0.88541001]
zmp_s [        0.         -19175252.10594784   3241794.01658924]
transform [[ 0.11343979 -0.99246085  0.0463996 ]
 [-0.08461265 -0.05618165 -0.99482882]
 [ 0.98993546  0.10892718 -0.09034796]]
zmp [19181104.88078946 -2147732.73136256 -2381595.52759042]
d1:13549080.65559, d2:0.05940, d3:10210313.12767
transform [[ 0.13744041  0.09594309 -0.98585248]
 [ 0.98942268  0.03332569  0.14118141]
 [ 0.0463996  -0.99482882 -0.09034796]]
planes
[[ 0.13744041  0.09594309 -0.98585248]
 [ 0.98942268  0.03332569  0.14118141]
 [ 0.0463996  -0.99482882 -0.09034796]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-826.4693   449.04703  480.5008 ]
[343.32320249 278.77545615 120.87471949]
[ 0.   0.  -9.8]
transform [[ 0.13744041  0.09594309 -0.98585248]
 [ 0.98942268  0.03332569  0.14118141]
 [ 0.0463996  -0.99482882 -0.09034796]]
transform [[ 0.13744041  0.09594309 -0.98585248]
 [ 0.98942268  0.03332569  0.14118141]
 [ 0.0463996  -0.99482882 -0.09034796]]
transform [[ 0.13744041  0.09594309 -0.98585248]
 [ 0.98942268  0.03332569  0.14118141]
 [ 0.0463996  -0.99482882 -0.09034796]]
support
[-1.20089766  0.17197748 -0.11005567]
[-544.21022335 -734.92488492 -528.48503392]
[ -45.23158162  366.04741169 -272.32458428]
[ 9.6613543  -1.38357781  0.88541001]
zmp_s [        0.         -19175248.68330674   3241793.64045188]
transform [[ 0.13744041  0.98942268  0.0463996 ]
 [ 0.09594309  0.03332569 -0.99482882]
 [-0.98585248  0.14118141 -0.09034796]]
zmp [-18822008.00299208  -3864058.2223635   -3000078.07799086]
d1:16086898.22831, d2:0.05940, d3:10370955.77343
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-432.89078282839944 steps:147[00m
[RDDPG] Resetting Environment
transform [[ 7.14861035e-01  6.99248433e-01  5.03074424e-03]
 [-6.76532276e-03 -2.77960702e-04  9.99977112e-01]
 [ 6.99233830e-01 -7.14878678e-01  4.53193812e-03]]
planes
[[ 7.14861035e-01  6.99248433e-01  5.03074424e-03]
 [-6.76532276e-03 -2.77960702e-04  9.99977112e-01]
 [ 6.99233830e-01 -7.14878678e-01  4.53193812e-03]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-323.42905 -212.36371  731.0652 ]
[  -7.02654176 -244.54996279  -18.71692294]
[ 0.   0.  -9.8]
transform [[ 7.14861035e-01  6.99248433e-01  5.03074424e-03]
 [-6.76532276e-03 -2.77960702e-04  9.99977112e-01]
 [ 6.99233830e-01 -7.14878678e-01  4.53193812e-03]]
transform [[ 7.14861035e-01  6.99248433e-01  5.03074424e-03]
 [-6.76532276e-03 -2.77960702e-04  9.99977112e-01]
 [ 6.99233830e-01 -7.14878678e-01  4.53193812e-03]]
transform [[ 7.14861035e-01  6.99248433e-01  5.03074424e-03]
 [-6.76532276e-03 -2.77960702e-04  9.99977112e-01]
 [ 6.99233830e-01 -7.14878678e-01  4.53193812e-03]]
support
[0.00612811 1.21810332 0.0055205 ]
[-376.02401158  733.29558345  -71.02510157]
[-176.11833927  -18.60098244  169.82553454]
[-0.04930129 -9.7997757  -0.04441299]
zmp_s [       0.          5333132.68146827 -5709875.44617653]
transform [[ 7.14861035e-01 -6.76532276e-03  6.99233830e-01]
 [ 6.99248433e-01 -2.77960702e-04 -7.14878678e-01]
 [ 5.03074424e-03  9.99977112e-01  4.53193812e-03]]
zmp [-4028618.44082165  4080385.81104057  5307133.8135705 ]
d1:12532127.66714, d2:0.05940, d3:5929691.72023
transform [[ 0.9305039   0.33886346  0.13904712]
 [-0.0851608  -0.16906661  0.98191863]
 [ 0.35624459 -0.92552042 -0.12845924]]
planes
[[ 0.9305039   0.33886346  0.13904712]
 [-0.0851608  -0.16906661  0.98191863]
 [ 0.35624459 -0.92552042 -0.12845924]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-323.42905 -212.36371  731.0652 ]
[  -7.02654176 -244.54996279  -18.71692294]
[ 0.   0.  -9.8]
transform [[ 0.9305039   0.33886346  0.13904712]
 [-0.0851608  -0.16906661  0.98191863]
 [ 0.35624459 -0.92552042 -0.12845924]]
transform [[ 0.9305039   0.33886346  0.13904712]
 [-0.0851608  -0.16906661  0.98191863]
 [ 0.35624459 -0.92552042 -0.12845924]]
transform [[ 0.9305039   0.33886346  0.13904712]
 [-0.0851608  -0.16906661  0.98191863]
 [ 0.35624459 -0.92552042 -0.12845924]]
support
[ 0.16937763  1.19610572 -0.15648021]
[-271.26178664  781.2936156   -12.58498242]
[-92.00980577  23.56512321 226.23717857]
[-1.36266174 -9.6228026   1.2589006 ]
zmp_s [       0.         -5699374.99461716  -293136.34370499]
transform [[ 0.9305039  -0.0851608   0.35624459]
 [ 0.33886346 -0.16906661 -0.92552042]
 [ 0.13904712  0.98191863 -0.12845924]]
zmp [  380935.09248332  1234877.66975197 -5558666.43019401]
d1:11268785.39962, d2:0.05940, d3:2671117.84522
transform [[ 0.41051477 -0.81143188 -0.41600001]
 [-0.40836373 -0.57150471  0.71177351]
 [-0.8153016  -0.12231424 -0.56597042]]
planes
[[ 0.41051477 -0.81143188 -0.41600001]
 [-0.40836373 -0.57150471  0.71177351]
 [-0.8153016  -0.12231424 -0.56597042]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-710.0857   162.21617  318.26172]
[-4451.18595575 -2441.51565747  -852.36367531]
[ 0.   0.  -9.8]
transform [[ 0.41051477 -0.81143188 -0.41600001]
 [-0.40836373 -0.57150471  0.71177351]
 [-0.8153016  -0.12231424 -0.56597042]]
transform [[ 0.41051477 -0.81143188 -0.41600001]
 [-0.40836373 -0.57150471  0.71177351]
 [-0.8153016  -0.12231424 -0.56597042]]
transform [[ 0.41051477 -0.81143188 -0.41600001]
 [-0.40836373 -0.57150471  0.71177351]
 [-0.8153016  -0.12231424 -0.56597042]]
support
[-0.50674259  0.86703353 -0.68942623]
[-555.52491779  423.79619806  378.96593255]
[ 508.42936039 2606.35071244 4410.10378991]
[ 4.07680008 -6.97538044  5.54651012]
zmp_s [        0.         -28612141.51868184  21402998.23085828]
transform [[ 0.41051477 -0.40836373 -0.8153016 ]
 [-0.81143188 -0.57150471 -0.12231424]
 [-0.41600001  0.71177351 -0.56597042]]
zmp [ -5765737.81502832  13734082.14250658 -32478828.44910951]
d1:60972661.16603, d2:0.05940, d3:20060448.45304
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-559.7641699366723 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-84.42869250000008 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-197.0034205273414 steps:153[00m
[RDDPG] Resetting Environment
transform [[ 0.32949662  0.26440424 -0.90637875]
 [ 0.64273357  0.6403923   0.4204655 ]
 [ 0.69161081 -0.721102    0.0410656 ]]
planes
[[ 0.32949662  0.26440424 -0.90637875]
 [ 0.64273357  0.6403923   0.4204655 ]
 [ 0.69161081 -0.721102    0.0410656 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-304.249   -248.9362    70.02799]
[ -5.44019967 -45.1193162    8.42790421]
[ 0.   0.  -9.8]
transform [[ 0.32949662  0.26440424 -0.90637875]
 [ 0.64273357  0.6403923   0.4204655 ]
 [ 0.69161081 -0.721102    0.0410656 ]]
transform [[ 0.32949662  0.26440424 -0.90637875]
 [ 0.64273357  0.6403923   0.4204655 ]
 [ 0.69161081 -0.721102    0.0410656 ]]
transform [[ 0.32949662  0.26440424 -0.90637875]
 [ 0.64273357  0.6403923   0.4204655 ]
 [ 0.69161081 -0.721102    0.0410656 ]]
support
[-1.10408823  0.51218214  0.05002329]
[-229.54068613 -325.52351632  -28.03775795]
[-21.36113905 -28.84701886  29.11922517]
[ 8.88251171 -4.12056189 -0.40244291]
zmp_s [       0.         18656530.29355903 13668796.32305877]
transform [[ 0.32949662  0.64273357  0.69161081]
 [ 0.26440424  0.6403923  -0.721102  ]
 [-0.90637875  0.4204655   0.0410656 ]]
zmp [21444665.73205366  2090902.05304278  8405744.69257663]
d1:29842995.94030, d2:0.05940, d3:11575476.32085
transform [[ 0.19434288  0.13103281 -0.97214264]
 [ 0.69563305  0.68032521  0.23076475]
 [ 0.69161081 -0.721102    0.0410656 ]]
planes
[[ 0.19434288  0.13103281 -0.97214264]
 [ 0.69563305  0.68032521  0.23076475]
 [ 0.69161081 -0.721102    0.0410656 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-304.249   -248.9362    70.02799]
[ -5.44019967 -45.1193162    8.42790421]
[ 0.   0.  -9.8]
transform [[ 0.19434288  0.13103281 -0.97214264]
 [ 0.69563305  0.68032521  0.23076475]
 [ 0.69161081 -0.721102    0.0410656 ]]
transform [[ 0.19434288  0.13103281 -0.97214264]
 [ 0.69563305  0.68032521  0.23076475]
 [ 0.69161081 -0.721102    0.0410656 ]]
transform [[ 0.19434288  0.13103281 -0.97214264]
 [ 0.69563305  0.68032521  0.23076475]
 [ 0.69161081 -0.721102    0.0410656 ]]
support
[-1.18419728  0.28110174  0.05002329]
[-159.82463309 -364.84323877  -28.03775795]
[-15.16249987 -32.53532781  29.11922517]
[ 9.52699784 -2.26149452 -0.40244291]
zmp_s [       0.         18656531.36726906 13668796.49057671]
transform [[ 0.19434288  0.69563305  0.69161081]
 [ 0.13103281  0.68032521 -0.721102  ]
 [-0.97214264  0.23076475  0.0410656 ]]
zmp [22431587.34345313  2835912.14492597  4866587.11156429]
d1:26120839.30268, d2:0.05940, d3:9405763.65812
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-380.714660865838 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-274.7767415722645 steps:157[00m
[RDDPG] Resetting Environment
transform [[ 0.2617501  -0.3220394   0.90982282]
 [-0.62462533  0.66211492  0.41406175]
 [-0.73575139 -0.67667907 -0.02784532]]
planes
[[ 0.2617501  -0.3220394   0.90982282]
 [-0.62462533  0.66211492  0.41406175]
 [-0.73575139 -0.67667907 -0.02784532]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-304.249   -248.9362    70.02799]
[ -5.44019967 -45.1193162    8.42790421]
[ 0.   0.  -9.8]
transform [[ 0.2617501  -0.3220394   0.90982282]
 [-0.62462533  0.66211492  0.41406175]
 [-0.73575139 -0.67667907 -0.02784532]]
transform [[ 0.2617501  -0.3220394   0.90982282]
 [-0.62462533  0.66211492  0.41406175]
 [-0.73575139 -0.67667907 -0.02784532]]
transform [[ 0.2617501  -0.3220394   0.90982282]
 [-0.62462533  0.66211492  0.41406175]
 [-0.73575139 -0.67667907 -0.02784532]]
support
[ 1.10828357  0.50438154 -0.03391926]
[ 64.24312491  54.21316581 390.35158704]
[ 20.77412409 -22.98641306  34.2992539 ]
[-8.91626365 -4.0578052   0.27288417]
zmp_s [       0.          6669716.87975268 -4914532.77420407]
transform [[ 0.2617501  -0.62462533 -0.73575139]
 [-0.3220394   0.66211492 -0.67667907]
 [ 0.90982282  0.41406175 -0.02784532]]
zmp [-550199.75295917 7741680.5370148  2898521.42910967]
d1:10534904.83486, d2:0.05940, d3:4130173.38759
transform [[ 0.65046281 -0.69460166 -0.30728948]
 [ 0.18859492 -0.24420097  0.95120859]
 [-0.73575139 -0.67667907 -0.02784532]]
planes
[[ 0.65046281 -0.69460166 -0.30728948]
 [ 0.18859492 -0.24420097  0.95120859]
 [-0.73575139 -0.67667907 -0.02784532]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-304.249   -248.9362    70.02799]
[ -5.44019967 -45.1193162    8.42790421]
[ 0.   0.  -9.8]
transform [[ 0.65046281 -0.69460166 -0.30728948]
 [ 0.18859492 -0.24420097  0.95120859]
 [-0.73575139 -0.67667907 -0.02784532]]
transform [[ 0.65046281 -0.69460166 -0.30728948]
 [ 0.18859492 -0.24420097  0.95120859]
 [-0.73575139 -0.67667907 -0.02784532]]
transform [[ 0.65046281 -0.69460166 -0.30728948]
 [ 0.18859492 -0.24420097  0.95120859]
 [-0.73575139 -0.67667907 -0.02784532]]
support
[-0.3743189   1.15869686 -0.03391926]
[-46.51002053  70.02187606 390.35158704]
[25.21149785 18.00888186 34.2992539 ]
[ 3.01143692 -9.3218442   0.27288417]
zmp_s [       0.          6669719.42486839 -4914528.30937566]
transform [[ 0.65046281  0.18859492 -0.73575139]
 [-0.69460166 -0.24420097 -0.67667907]
 [-0.30728948  0.95120859 -0.02784532]]
zmp [4873746.25458283 1696806.48474375 6481141.04815915]
d1:14527012.97169, d2:0.05940, d3:6214393.21976
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-517.6833345588553 steps:160[00m
[RDDPG] Resetting Environment
transform [[ 0.12720148  0.13857868 -0.98214859]
 [ 0.6991924   0.6898039   0.18788442]
 [ 0.70352668 -0.71060997 -0.00914908]]
planes
[[ 0.12720148  0.13857868 -0.98214859]
 [ 0.6991924   0.6898039   0.18788442]
 [ 0.70352668 -0.71060997 -0.00914908]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  97.57065    17.492552 -500.69046 ]
[ 61.07228203 -32.01990206 -25.48952198]
[ 0.   0.  -9.8]
transform [[ 0.12720148  0.13857868 -0.98214859]
 [ 0.6991924   0.6898039   0.18788442]
 [ 0.70352668 -0.71060997 -0.00914908]]
transform [[ 0.12720148  0.13857868 -0.98214859]
 [ 0.6991924   0.6898039   0.18788442]
 [ 0.70352668 -0.71060997 -0.00914908]]
transform [[ 0.12720148  0.13857868 -0.98214859]
 [ 0.6991924   0.6898039   0.18788442]
 [ 0.70352668 -0.71060997 -0.00914908]]
support
[-1.19638584  0.22886787 -0.01114478]
[506.58765427 -13.78485022  60.7940273 ]
[28.36570698 15.82473841 65.95284686]
[ 9.62505616 -1.84126732  0.08966095]
zmp_s [        0.         -10051962.93511048  -8507124.83938395]
transform [[ 0.12720148  0.6991924   0.70352668]
 [ 0.13857868  0.6898039  -0.71060997]
 [-0.98214859  0.18788442 -0.00914908]]
zmp [-13013245.3950541    -888635.47058046  -1810774.89225242]
d1:14327669.78578, d2:0.05940, d3:4692684.74311
transform [[ 0.13145652  0.13215914 -0.98247296]
 [ 0.24604076 -0.96441281 -0.09680909]
 [-0.96030372 -0.22900222 -0.15929489]]
planes
[[ 0.13145652  0.13215914 -0.98247296]
 [ 0.24604076 -0.96441281 -0.09680909]
 [-0.96030372 -0.22900222 -0.15929489]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[196.81145 495.71378 206.23352]
[  967.14409668 -2858.97973595   908.38781527]
[ 0.   0.  -9.8]
transform [[ 0.13145652  0.13215914 -0.98247296]
 [ 0.24604076 -0.96441281 -0.09680909]
 [-0.96030372 -0.22900222 -0.15929489]]
transform [[ 0.13145652  0.13215914 -0.98247296]
 [ 0.24604076 -0.96441281 -0.09680909]
 [-0.96030372 -0.22900222 -0.15929489]]
transform [[ 0.13145652  0.13215914 -0.98247296]
 [ 0.24604076 -0.96441281 -0.09680909]
 [-0.96030372 -0.22900222 -0.15929489]]
support
[-1.19678096 -0.11792617 -0.19404207]
[-111.2335997  -449.61435549 -335.37026751]
[-1143.16937466  2907.25334934  -418.74089976]
[9.62823497 0.94872907 1.56108991]
zmp_s [      0.         3803732.04553188 6076513.6246147 ]
transform [[ 0.13145652  0.24604076 -0.96030372]
 [ 0.13215914 -0.96441281 -0.22900222]
 [-0.98247296 -0.09680909 -0.15929489]]
zmp [-4899425.53259895 -5059903.02909678 -1336193.39438267]
d1:8837065.57493, d2:0.05940, d3:4018252.10641
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-469.3502957529513 steps:163[00m
[RDDPG] Resetting Environment
transform [[ 0.39006904  0.35468009  0.84973425]
 [-0.58883458 -0.61338997  0.52633321]
 [ 0.70789832 -0.70565915 -0.03041657]]
planes
[[ 0.39006904  0.35468009  0.84973425]
 [-0.58883458 -0.61338997  0.52633321]
 [ 0.70789832 -0.70565915 -0.03041657]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -39.132458 -218.5913     86.8871  ]
[ 154.91290784 -234.3124091   -89.13540241]
[ 0.   0.  -9.8]
transform [[ 0.39006904  0.35468009  0.84973425]
 [-0.58883458 -0.61338997  0.52633321]
 [ 0.70789832 -0.70565915 -0.03041657]]
transform [[ 0.39006904  0.35468009  0.84973425]
 [-0.58883458 -0.61338997  0.52633321]
 [ 0.70789832 -0.70565915 -0.03041657]]
transform [[ 0.39006904  0.35468009  0.84973425]
 [-0.58883458 -0.61338997  0.52633321]
 [ 0.70789832 -0.70565915 -0.03041657]]
support
[ 1.0350878   0.64114291 -0.03705137]
[-18.96339532 202.85581769 123.90633832]
[-98.42062176   5.59188099 277.71847547]
[-8.32739562 -5.15806549  0.29808234]
zmp_s [       0.          4769022.81571334 -6817593.03111383]
transform [[ 0.39006904 -0.58883458  0.70789832]
 [ 0.35468009 -0.61338997 -0.70565915]
 [ 0.84973425  0.52633321 -0.03041657]]
zmp [-7634328.20939603  1885626.15424551  2717462.86244407]
d1:10434299.91314, d2:0.05940, d3:4689596.57262
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-476.7106218951847 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-243.54657726561024 steps:166[00m
[RDDPG] Resetting Environment
transform [[ 0.76460725 -0.61110646  0.20475553]
 [-0.2440569   0.01949921  0.96956486]
 [-0.59649992 -0.79130822 -0.13423552]]
planes
[[ 0.76460725 -0.61110646  0.20475553]
 [-0.2440569   0.01949921  0.96956486]
 [-0.59649992 -0.79130822 -0.13423552]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -39.132458 -218.5913     86.8871  ]
[ 154.91290784 -234.3124091   -89.13540241]
[ 0.   0.  -9.8]
transform [[ 0.76460725 -0.61110646  0.20475553]
 [-0.2440569   0.01949921  0.96956486]
 [-0.59649992 -0.79130822 -0.13423552]]
transform [[ 0.76460725 -0.61110646  0.20475553]
 [-0.2440569   0.01949921  0.96956486]
 [-0.59649992 -0.79130822 -0.13423552]]
transform [[ 0.76460725 -0.61110646  0.20475553]
 [-0.2440569   0.01949921  0.96956486]
 [-0.59649992 -0.79130822 -0.13423552]]
support
[ 0.2494191   1.1810572  -0.16351647]
[121.45220375  89.5308672  184.65226131]
[ 243.38639179 -128.79902388  104.97293599]
[-2.00660419 -9.50173558  1.31550806]
zmp_s [        0.         -22007123.86488949  -3159845.63015014]
transform [[ 0.76460725 -0.2440569  -0.59649992]
 [-0.61110646  0.01949921 -0.79130822]
 [ 0.20475553  0.96956486 -0.13423552]]
zmp [  7255837.99185715   2071290.29050464 -20913170.35195567]
d1:43615647.18874, d2:0.05940, d3:16309873.76106
transform [[ 0.32211247 -0.45236826  0.83162886]
 [-0.89284825  0.14689375  0.4257279 ]
 [-0.31474686 -0.87965059 -0.35657987]]
planes
[[ 0.32211247 -0.45236826  0.83162886]
 [-0.89284825  0.14689375  0.4257279 ]
 [-0.31474686 -0.87965059 -0.35657987]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -39.132458 -218.5913     86.8871  ]
[ 154.91290784 -234.3124091   -89.13540241]
[ 0.   0.  -9.8]
transform [[ 0.32211247 -0.45236826  0.83162886]
 [-0.89284825  0.14689375  0.4257279 ]
 [-0.31474686 -0.87965059 -0.35657987]]
transform [[ 0.32211247 -0.45236826  0.83162886]
 [-0.89284825  0.14689375  0.4257279 ]
 [-0.31474686 -0.87965059 -0.35657987]]
transform [[ 0.32211247 -0.45236826  0.83162886]
 [-0.89284825  0.14689375  0.4257279 ]
 [-0.31474686 -0.87965059 -0.35657987]]
support
[ 1.01303306  0.51859244 -0.43436106]
[158.53653026  39.81991378 173.61858793]
[  81.76730318 -210.68017672  189.13858897]
[-8.14996282 -4.17213346  3.49448273]
zmp_s [      0.         2536204.77077935  310339.0341468 ]
transform [[ 0.32211247 -0.89284825 -0.31474686]
 [-0.45236826  0.14689375 -0.87965059]
 [ 0.83162886  0.4257279  -0.35657987]]
zmp [-2362124.23498072    99562.72586052   969072.48833281]
d1:3192717.54492, d2:0.05940, d3:1548530.28141
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-427.29471825132595 steps:169[00m
[RDDPG] Resetting Environment
transform [[ 0.68804234  0.71561944 -0.12036012]
 [ 0.0977073   0.0729925   0.99253482]
 [ 0.71906263 -0.69466609 -0.01969931]]
planes
[[ 0.68804234  0.71561944 -0.12036012]
 [ 0.0977073   0.0729925   0.99253482]
 [ 0.71906263 -0.69466609 -0.01969931]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-369.84695 -233.4878   692.03723]
[   6.42012356 -334.88237271   34.42296953]
[ 0.   0.  -9.8]
transform [[ 0.68804234  0.71561944 -0.12036012]
 [ 0.0977073   0.0729925   0.99253482]
 [ 0.71906263 -0.69466609 -0.01969931]]
transform [[ 0.68804234  0.71561944 -0.12036012]
 [ 0.0977073   0.0729925   0.99253482]
 [ 0.71906263 -0.69466609 -0.01969931]]
transform [[ 0.68804234  0.71561944 -0.12036012]
 [ 0.0977073   0.0729925   0.99253482]
 [ 0.71906263 -0.69466609 -0.01969931]]
support
[-0.14661442  1.20903763 -0.02399635]
[-504.85245468  633.69144169 -117.37972984]
[-239.37417358   10.34938837  236.56978966]
[ 1.17952919 -9.7268412   0.19305328]
zmp_s [       0.         -7433580.50290325  4991091.48956775]
transform [[ 0.68804234  0.0977073   0.71906263]
 [ 0.71561944  0.0729925  -0.69466609]
 [-0.12036012  0.99253482 -0.01969931]]
zmp [ 2862592.26438419 -4009737.59460297 -7476408.5401371 ]
d1:15783693.50950, d2:0.05940, d3:6938922.87680
transform [[ 0.6797418   0.70894581 -0.18800807]
 [ 0.14456856  0.12179912  0.98196995]
 [ 0.71906263 -0.69466609 -0.01969931]]
planes
[[ 0.6797418   0.70894581 -0.18800807]
 [ 0.14456856  0.12179912  0.98196995]
 [ 0.71906263 -0.69466609 -0.01969931]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-369.84695 -233.4878   692.03723]
[   6.42012356 -334.88237271   34.42296953]
[ 0.   0.  -9.8]
transform [[ 0.6797418   0.70894581 -0.18800807]
 [ 0.14456856  0.12179912  0.98196995]
 [ 0.71906263 -0.69466609 -0.01969931]]
transform [[ 0.6797418   0.70894581 -0.18800807]
 [ 0.14456856  0.12179912  0.98196995]
 [ 0.71906263 -0.69466609 -0.01969931]]
transform [[ 0.6797418   0.70894581 -0.18800807]
 [ 0.14456856  0.12179912  0.98196995]
 [ 0.71906263 -0.69466609 -0.01969931]]
support
[-0.2290185   1.19616824 -0.02399635]
[-547.03921135  597.65291737 -117.37972984]
[-239.52122496   -6.05790811  236.56978966]
[ 1.84247909 -9.62330554  0.19305328]
zmp_s [       0.         -7433580.61692651  4991091.53634118]
transform [[ 0.6797418   0.14456856  0.71906263]
 [ 0.70894581  0.12179912 -0.69466609]
 [-0.18800807  0.98196995 -0.01969931]]
zmp [ 2514245.32446023 -4372545.5993361  -7397873.88834511]
d1:15702056.28003, d2:0.05940, d3:6890244.83074
transform [[ 0.92249942  0.38299003  0.0480984 ]
 [-0.01134121 -0.09766078  0.99515516]
 [ 0.38583189 -0.91857553 -0.08574844]]
planes
[[ 0.92249942  0.38299003  0.0480984 ]
 [-0.01134121 -0.09766078  0.99515516]
 [ 0.38583189 -0.91857553 -0.08574844]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-303.06564  -72.49965  705.66943]
[   6.42012356 -334.88237271   34.42296953]
[ 0.   0.  -9.8]
transform [[ 0.92249942  0.38299003  0.0480984 ]
 [-0.01134121 -0.09766078  0.99515516]
 [ 0.38583189 -0.91857553 -0.08574844]]
transform [[ 0.92249942  0.38299003  0.0480984 ]
 [-0.01134121 -0.09766078  0.99515516]
 [ 0.38583189 -0.91857553 -0.08574844]]
transform [[ 0.92249942  0.38299003  0.0480984 ]
 [-0.01134121 -0.09766078  0.99515516]
 [ 0.38583189 -0.91857553 -0.08574844]]
support
[ 0.05859016  1.21222954 -0.10445285]
[-273.40295437  712.76807855 -110.84604166]
[-120.6783609    66.88825734  307.14012385]
[-0.47136429 -9.75252053  0.84033473]
zmp_s [        0.          20694208.48409    -20116322.37221622]
transform [[ 0.92249942 -0.01134121  0.38583189]
 [ 0.38299003 -0.09766078 -0.91857553]
 [ 0.0480984   0.99515516 -0.08574844]]
zmp [-7996216.10443045 16457348.84877076 22318891.55769683]
d1:49522658.66936, d2:0.05940, d3:14302015.88622
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-553.1505124246497 steps:173[00m
[RDDPG] Resetting Environment
transform [[ 0.67908216  0.69845545 -0.22584835]
 [ 0.18394187  0.13594243  0.97349119]
 [ 0.71064252 -0.70262355 -0.0361591 ]]
planes
[[ 0.67908216  0.69845545 -0.22584835]
 [ 0.18394187  0.13594243  0.97349119]
 [ 0.71064252 -0.70262355 -0.0361591 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[412.619   348.06027 510.53903]
[  54.75571097 -340.87466854  -51.99921432]
[ 0.   0.  -9.8]
transform [[ 0.67908216  0.69845545 -0.22584835]
 [ 0.18394187  0.13594243  0.97349119]
 [ 0.71064252 -0.70262355 -0.0361591 ]]
transform [[ 0.67908216  0.69845545 -0.22584835]
 [ 0.18394187  0.13594243  0.97349119]
 [ 0.71064252 -0.70262355 -0.0361591 ]]
transform [[ 0.67908216  0.69845545 -0.22584835]
 [ 0.18394187  0.13594243  0.97349119]
 [ 0.71064252 -0.70262355 -0.0361591 ]]
support
[-0.27511292  1.18583999 -0.04404653]
[408.00239033 620.21931833  30.20862046]
[-189.15820819  -86.88823973  280.29854952]
[ 2.2133138  -9.54021368  0.3543592 ]
zmp_s [        0.          -6333841.08790096 -12272565.23536044]
transform [[ 0.67908216  0.18394187  0.71064252]
 [ 0.69845545  0.13594243 -0.70262355]
 [-0.22584835  0.97349119 -0.0361591 ]]
zmp [-9886465.22402178  7761955.56138547 -5722173.57314172]
d1:20912224.68700, d2:0.05940, d3:9275113.98825
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-279.02798915675635 steps:175[00m
[RDDPG] Resetting Environment
transform [[ 0.23423345  0.25674334 -0.93766606]
 [ 0.67117536  0.65505558  0.34702426]
 [ 0.70331955 -0.71062303 -0.01888389]]
planes
[[ 0.23423345  0.25674334 -0.93766606]
 [ 0.67117536  0.65505558  0.34702426]
 [ 0.70331955 -0.71062303 -0.01888389]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-477.1465   364.54193  527.3417 ]
[-102.49689775 -280.57854195   40.26345415]
[ 0.   0.  -9.8]
transform [[ 0.23423345  0.25674334 -0.93766606]
 [ 0.67117536  0.65505558  0.34702426]
 [ 0.70331955 -0.71062303 -0.01888389]]
transform [[ 0.23423345  0.25674334 -0.93766606]
 [ 0.67117536  0.65505558  0.34702426]
 [ 0.70331955 -0.71062303 -0.01888389]]
transform [[ 0.23423345  0.25674334 -0.93766606]
 [ 0.67117536  0.65505558  0.34702426]
 [ 0.70331955 -0.71062303 -0.01888389]]
support
[-1.14220028  0.42272108 -0.02300306]
[-512.64035232  101.54659833 -604.59662503]
[-133.7985492  -238.6155371   126.53716983]
[ 9.18912737 -3.40083777  0.18506214]
zmp_s [        0.          -2700031.54860672 -10553145.17779036]
transform [[ 0.23423345  0.67117536  0.70331955]
 [ 0.25674334  0.65505558 -0.71062303]
 [-0.93766606  0.34702426 -0.01888389]]
zmp [-9234427.96137306  5730637.22003781  -737692.00789626]
d1:14417657.88888, d2:0.05940, d3:5240240.92004
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-328.3618249938318 steps:177[00m
[RDDPG] Resetting Environment
transform [[ 0.7012431   0.69637781  0.15269609]
 [-0.08469397 -0.13129337  0.98771912]
 [ 0.70787358 -0.70556366 -0.03308957]]
planes
[[ 0.7012431   0.69637781  0.15269609]
 [-0.08469397 -0.13129337  0.98771912]
 [ 0.70787358 -0.70556366 -0.03308957]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 212.14331  -193.3247      9.532892]
[ 138.83631665 -299.50246866  -79.32025676]
[ 0.   0.  -9.8]
transform [[ 0.7012431   0.69637781  0.15269609]
 [-0.08469397 -0.13129337  0.98771912]
 [ 0.70787358 -0.70556366 -0.03308957]]
transform [[ 0.7012431   0.69637781  0.15269609]
 [-0.08469397 -0.13129337  0.98771912]
 [ 0.70787358 -0.70556366 -0.03308957]]
transform [[ 0.7012431   0.69637781  0.15269609]
 [-0.08469397 -0.13129337  0.98771912]
 [ 0.70787358 -0.70556366 -0.03308957]]
support
[ 0.18600387  1.20317148 -0.04030744]
[ 15.59263178  16.83081364 286.25809468]
[-123.32075783  -50.78204387  312.22129373]
[-1.49642166 -9.67964736  0.32427783]
zmp_s [        0.          -1550649.29049797 -11796726.42438252]
transform [[ 0.7012431  -0.08469397  0.70787358]
 [ 0.69637781 -0.13129337 -0.70556366]
 [ 0.15269609  0.98771912 -0.03308957]]
zmp [-8219260.35796283  8526931.49742443 -1141257.29345317]
d1:16318327.55617, d2:0.05940, d3:6055168.65928
transform [[ 0.28665975  0.24415192  0.92639953]
 [-0.64555496 -0.66525918  0.37508538]
 [ 0.70787358 -0.70556366 -0.03308957]]
planes
[[ 0.28665975  0.24415192  0.92639953]
 [-0.64555496 -0.66525918  0.37508538]
 [ 0.70787358 -0.70556366 -0.03308957]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 212.14331  -193.3247      9.532892]
[ 138.83631665 -299.50246866  -79.32025676]
[ 0.   0.  -9.8]
transform [[ 0.28665975  0.24415192  0.92639953]
 [-0.64555496 -0.66525918  0.37508538]
 [ 0.70787358 -0.70556366 -0.03308957]]
transform [[ 0.28665975  0.24415192  0.92639953]
 [-0.64555496 -0.66525918  0.37508538]
 [ 0.70787358 -0.70556366 -0.03308957]]
transform [[ 0.28665975  0.24415192  0.92639953]
 [-0.64555496 -0.66525918  0.37508538]
 [ 0.70787358 -0.70556366 -0.03308957]]
support
[ 1.12847617  0.45690321 -0.04030744]
[ 22.44361625  -4.76348122 286.25809468]
[-106.80756784   79.86842569  312.22129373]
[-9.07871538 -3.67583676  0.32427783]
zmp_s [        0.          -1550650.44180384 -11796737.2621375 ]
transform [[ 0.28665975 -0.64555496  0.70787358]
 [ 0.24415192 -0.66525918 -0.70556366]
 [ 0.92639953  0.37508538 -0.03308957]]
zmp [-7349568.58798876  9354933.6162515   -191277.30025235]
d1:16049354.34136, d2:0.05940, d3:5664770.08718
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-408.61874296371116 steps:180[00m
[RDDPG] Resetting Environment
transform [[ 0.72820538  0.68309945 -0.05560657]
 [ 0.001394    0.07965852  0.99682128]
 [ 0.68535757 -0.72596818  0.05705553]]
planes
[[ 0.72820538  0.68309945 -0.05560657]
 [ 0.001394    0.07965852  0.99682128]
 [ 0.68535757 -0.72596818  0.05705553]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -5.1348705  471.47403   -422.58133  ]
[  -4.89400298 -149.0105284     3.39682985]
[ 0.   0.  -9.8]
transform [[ 0.72820538  0.68309945 -0.05560657]
 [ 0.001394    0.07965852  0.99682128]
 [ 0.68535757 -0.72596818  0.05705553]]
transform [[ 0.72820538  0.68309945 -0.05560657]
 [ 0.001394    0.07965852  0.99682128]
 [ 0.68535757 -0.72596818  0.05705553]]
transform [[ 0.72820538  0.68309945 -0.05560657]
 [ 0.001394    0.07965852  0.99682128]
 [ 0.68535757 -0.72596818  0.05705553]]
support
[-0.0677361   1.21425911  0.06950112]
[ 341.8227076  -383.68830006 -369.90496632]
[-105.54173516   -8.49074748  105.01656833]
[ 0.54494439 -9.76884859 -0.55914415]
zmp_s [       0.         33051804.82967891  6694212.47140616]
transform [[ 0.72820538  0.001394    0.68535757]
 [ 0.68309945  0.07965852 -0.72596818]
 [-0.05560657  0.99682128  0.05705553]]
zmp [ 4634003.53270596 -2226927.54273457 33328684.34880164]
d1:65876447.51123, d2:0.05940, d3:23426988.17311
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-89.57817979781174 steps:182[00m
[RDDPG] Resetting Environment
transform [[ 0.75879562  0.65129489  0.00665084]
 [-0.00616002 -0.00303471  0.99997646]
 [ 0.65129972 -0.75881863  0.00170927]]
planes
[[ 0.75879562  0.65129489  0.00665084]
 [-0.00616002 -0.00303471  0.99997646]
 [ 0.65129972 -0.75881863  0.00170927]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-173.31157  228.71704 -867.8264 ]
[ -12.46238599 -215.14438586    2.08089273]
[ 0.   0.  -9.8]
transform [[ 0.75879562  0.65129489  0.00665084]
 [-0.00616002 -0.00303471  0.99997646]
 [ 0.65129972 -0.75881863  0.00170927]]
transform [[ 0.75879562  0.65129489  0.00665084]
 [-0.00616002 -0.00303471  0.99997646]
 [ 0.65129972 -0.75881863  0.00170927]]
transform [[ 0.75879562  0.65129489  0.00665084]
 [-0.00616002 -0.00303471  0.99997646]
 [ 0.65129972 -0.75881863  0.00170927]]
support
[0.0081016  1.21810252 0.00208211]
[  11.68240254 -867.43247045 -287.91587403]
[-149.56500269    2.81051261  155.14237572]
[-0.06517826 -9.79976927 -0.01675082]
zmp_s [      0.          818394.72535195 1031654.00730641]
transform [[ 0.75879562 -0.00616002  0.65129972]
 [ 0.65129489 -0.00303471 -0.75881863]
 [ 0.00665084  0.99997646  0.00170927]]
zmp [ 666874.63204573 -785321.86546108  820138.82986473]
d1:2160334.73306, d2:0.05940, d3:981808.24620
transform [[ 0.7390129   0.63378572 -0.22841974]
 [ 0.17224585  0.15003289  0.97356129]
 [ 0.65129972 -0.75881863  0.00170927]]
planes
[[ 0.7390129   0.63378572 -0.22841974]
 [ 0.17224585  0.15003289  0.97356129]
 [ 0.65129972 -0.75881863  0.00170927]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-173.31157  228.71704 -867.8264 ]
[ -12.46238599 -215.14438586    2.08089273]
[ 0.   0.  -9.8]
transform [[ 0.7390129   0.63378572 -0.22841974]
 [ 0.17224585  0.15003289  0.97356129]
 [ 0.65129972 -0.75881863  0.00170927]]
transform [[ 0.7390129   0.63378572 -0.22841974]
 [ 0.17224585  0.15003289  0.97356129]
 [ 0.65129972 -0.75881863  0.00170927]]
transform [[ 0.7390129   0.63378572 -0.22841974]
 [ 0.17224585  0.15003289  0.97356129]
 [ 0.65129972 -0.75881863  0.00170927]]
support
[-0.27824521  1.18592538  0.00208211]
[ 215.10679159 -840.41932083 -287.91587403]
[-146.04062144  -32.39945219  155.14237572]
[ 2.23851341 -9.54090061 -0.01675082]
zmp_s [      0.          818405.63400132 1031653.04690208]
transform [[ 0.7390129   0.17224585  0.65129972]
 [ 0.63378572  0.15003289 -0.75881863]
 [-0.22841974  0.97356129  0.00170927]]
zmp [ 812882.30561353 -660049.7832035   798531.41328735]
d1:2154867.24236, d2:0.05940, d3:976469.65693
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-547.7274333282407 steps:185[00m
[RDDPG] Resetting Environment
transform [[ 0.73650974  0.67634767  0.01035867]
 [ 0.00324192 -0.0188431   0.99981725]
 [ 0.67641926 -0.73634148 -0.01607079]]
planes
[[ 0.73650974  0.67634767  0.01035867]
 [ 0.00324192 -0.0188431   0.99981725]
 [ 0.67641926 -0.73634148 -0.01607079]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 652.4133  -173.23978 -150.50122]
[ -51.95164305 -129.24510172   19.23583671]
[ 0.   0.  -9.8]
transform [[ 0.73650974  0.67634767  0.01035867]
 [ 0.00324192 -0.0188431   0.99981725]
 [ 0.67641926 -0.73634148 -0.01607079]]
transform [[ 0.73650974  0.67634767  0.01035867]
 [ 0.00324192 -0.0188431   0.99981725]
 [ 0.67641926 -0.73634148 -0.01607079]]
transform [[ 0.73650974  0.67634767  0.01035867]
 [ 0.00324192 -0.0188431   0.99981725]
 [ 0.67641926 -0.73634148 -0.01607079]]
support
[ 0.01261822  1.21790859 -0.01957633]
[ 361.77945998 -145.094269    571.28724721]
[-125.47825722   21.4992765    59.71830206]
[-0.10151497 -9.79820907  0.15749375]
zmp_s [        0.          14373574.0581979  -16557435.98006975]
transform [[ 0.73650974  0.00324192  0.67641926]
 [ 0.67634767 -0.0188431  -0.73634148]
 [ 0.01035867  0.99981725 -0.01607079]]
zmp [-11153170.54585879  11921084.16984388  14637038.4048971 ]
d1:34854900.19323, d2:0.05940, d3:16660127.50248
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-309.7452153296156 steps:187[00m
[RDDPG] Resetting Environment
transform [[ 0.28702092 -0.3410731  -0.89514703]
 [ 0.65092874 -0.61613339  0.44347653]
 [-0.70278788 -0.70996392  0.04517111]]
planes
[[ 0.28702092 -0.3410731  -0.89514703]
 [ 0.65092874 -0.61613339  0.44347653]
 [-0.70278788 -0.70996392  0.04517111]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 652.4133  -173.23978 -150.50122]
[ -51.95164305 -129.24510172   19.23583671]
[ 0.   0.  -9.8]
transform [[ 0.28702092 -0.3410731  -0.89514703]
 [ 0.65092874 -0.61613339  0.44347653]
 [-0.70278788 -0.70996392  0.04517111]]
transform [[ 0.28702092 -0.3410731  -0.89514703]
 [ 0.65092874 -0.61613339  0.44347653]
 [-0.70278788 -0.70996392  0.04517111]]
transform [[ 0.28702092 -0.3410731  -0.89514703]
 [ 0.65092874 -0.61613339  0.44347653]
 [-0.70278788 -0.70996392  0.04517111]]
support
[-1.09040652  0.5402126   0.05502434]
[ 381.06442232  464.66963648 -342.31249556]
[ 11.95191647  54.34604765 129.13924778]
[ 8.77244085 -4.34606997 -0.4426769 ]
zmp_s [        0.         -11411473.50348849   9515887.23571643]
transform [[ 0.28702092  0.65092874 -0.70278788]
 [-0.3410731  -0.61613339 -0.70996392]
 [-0.89514703  0.44347653  0.04517111]]
zmp [-14115706.2003504     275053.29322489  -4630877.44147304]
d1:18513777.69746, d2:0.05940, d3:7218381.22694
transform [[ 0.25787869 -0.43469903 -0.86286467]
 [ 0.91426384 -0.17901124  0.36342338]
 [-0.31244224 -0.88260514  0.35126641]]
planes
[[ 0.25787869 -0.43469903 -0.86286467]
 [ 0.91426384 -0.17901124  0.36342338]
 [-0.31244224 -0.88260514  0.35126641]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 612.8238  -236.1979   135.72371]
[ -51.95164305 -129.24510172   19.23583671]
[ 0.   0.  -9.8]
transform [[ 0.25787869 -0.43469903 -0.86286467]
 [ 0.91426384 -0.17901124  0.36342338]
 [-0.31244224 -0.88260514  0.35126641]]
transform [[ 0.25787869 -0.43469903 -0.86286467]
 [ 0.91426384 -0.17901124  0.36342338]
 [-0.31244224 -0.88260514  0.35126641]]
transform [[ 0.25787869 -0.43469903 -0.86286467]
 [ 0.91426384 -0.17901124  0.36342338]
 [-0.31244224 -0.88260514  0.35126641]]
support
[-1.05108238  0.44269735  0.42788858]
[143.59800379 651.88988462  64.67262579]
[ 26.18757452 -17.37043016 137.06118178]
[ 8.4560738  -3.5615491  -3.44241086]
zmp_s [        0.          20929236.0229059  -10868677.26309261]
transform [[ 0.25787869  0.91426384 -0.31244224]
 [-0.43469903 -0.17901124 -0.88260514]
 [-0.86286467  0.36342338  0.35126641]]
zmp [22530677.69214369  5846181.86255167  3788372.35290251]
d1:16489397.20703, d2:0.05940, d3:13313461.34405
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-496.38660344794243 steps:190[00m
[RDDPG] Resetting Environment
transform [[ 0.65674984 -0.7102133  -0.25352859]
 [ 0.16829851 -0.18967815  0.96731484]
 [-0.73508865 -0.67795229 -0.00504324]]
planes
[[ 0.65674984 -0.7102133  -0.25352859]
 [ 0.16829851 -0.18967815  0.96731484]
 [-0.73508865 -0.67795229 -0.00504324]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 612.8238  -236.1979   135.72371]
[ -51.95164305 -129.24510172   19.23583671]
[ 0.   0.  -9.8]
transform [[ 0.65674984 -0.7102133  -0.25352859]
 [ 0.16829851 -0.18967815  0.96731484]
 [-0.73508865 -0.67795229 -0.00504324]]
transform [[ 0.65674984 -0.7102133  -0.25352859]
 [ 0.16829851 -0.18967815  0.96731484]
 [-0.73508865 -0.67795229 -0.00504324]]
transform [[ 0.65674984 -0.7102133  -0.25352859]
 [ 0.16829851 -0.18967815  0.96731484]
 [-0.73508865 -0.67795229 -0.00504324]]
support
[-0.30883109  1.17831639 -0.00614333]
[ 535.812984    279.22647186 -291.03338773]
[ 52.79552251  34.3786975  125.71406457]
[ 2.48458023 -9.47968543  0.0494238 ]
zmp_s [        0.         -20693894.90046508 -24620632.10922052]
transform [[ 0.65674984  0.16829851 -0.73508865]
 [-0.7102133  -0.18967815 -0.67795229]
 [-0.25352859  0.96731484 -0.00504324]]
zmp [ 14615595.39731131  20616793.5573236  -19893343.75507655]
d1:53049939.56885, d2:0.05940, d3:23970274.29415
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-89.73939401142765 steps:192[00m
[RDDPG] Resetting Environment
transform [[ 0.69096601  0.6885342   0.22019695]
 [-0.1429151  -0.16848285  0.97528911]
 [ 0.70861924 -0.70536107 -0.018014  ]]
planes
[[ 0.69096601  0.6885342   0.22019695]
 [-0.1429151  -0.16848285  0.97528911]
 [ 0.70861924 -0.70536107 -0.018014  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 150.25917  239.6214  -714.6589 ]
[-14.59373315 -47.32029973  11.75370623]
[ 0.   0.  -9.8]
transform [[ 0.69096601  0.6885342   0.22019695]
 [-0.1429151  -0.16848285  0.97528911]
 [ 0.70861924 -0.70536107 -0.018014  ]]
transform [[ 0.69096601  0.6885342   0.22019695]
 [-0.1429151  -0.16848285  0.97528911]
 [ 0.70861924 -0.70536107 -0.018014  ]]
transform [[ 0.69096601  0.6885342   0.22019695]
 [-0.1429151  -0.16848285  0.97528911]
 [ 0.70861924 -0.70536107 -0.018014  ]]
support
[ 0.26822877  1.18803009 -0.02194342]
[ 111.44580516 -758.84541684  -49.66920034]
[-40.07728806  21.52158567  22.82476583]
[-2.15793009 -9.55783324  0.17653723]
zmp_s [       0.         -9437853.13490286 -5645589.20354632]
transform [[ 0.69096601 -0.1429151   0.70861924]
 [ 0.6885342  -0.16848285 -0.70536107]
 [ 0.22019695  0.97528911 -0.018014  ]]
zmp [-2651761.39029671  5572295.27239083 -9102935.69143895]
d1:19607248.39759, d2:0.05940, d3:8385849.53273
transform [[ 0.6244821   0.75530571  0.1988351 ]
 [-0.25239134  0.43607053 -0.86379462]
 [-0.73913515  0.48923996  0.46295086]]
planes
[[ 0.6244821   0.75530571  0.1988351 ]
 [-0.25239134  0.43607053 -0.86379462]
 [-0.73913515  0.48923996  0.46295086]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[331.5476   -13.146096 714.172   ]
[ -30.67683585 -205.86508558   49.76190107]
[ 0.   0.  -9.8]
transform [[ 0.6244821   0.75530571  0.1988351 ]
 [-0.25239134  0.43607053 -0.86379462]
 [-0.73913515  0.48923996  0.46295086]]
transform [[ 0.6244821   0.75530571  0.1988351 ]
 [-0.25239134  0.43607053 -0.86379462]
 [-0.73913515  0.48923996  0.46295086]]
transform [[ 0.6244821   0.75530571  0.1988351 ]
 [-0.25239134  0.43607053 -0.86379462]
 [-0.73913515  0.48923996  0.46295086]]
support
[ 0.24220724 -1.05221518  0.56393488]
[ 339.11868686 -706.31030179   79.13645214]
[-164.75379602 -125.01319231  -55.0057842 ]
[-1.94858403  8.46518732 -4.53691838]
zmp_s [       0.         -7322561.3877763   1660159.88957418]
transform [[ 0.6244821  -0.25239134 -0.73913515]
 [ 0.75530571  0.43607053  0.48923996]
 [ 0.1988351  -0.86379462  0.46295086]]
zmp [  621068.54620117 -2380936.67761234  7093761.60770355]
d1:13442752.30451, d2:0.05940, d3:5100127.73202
transform [[-0.0134639  -0.8535254   0.52087736]
 [-0.19157459 -0.50907236 -0.83913326]
 [ 0.98138577 -0.11108485 -0.15665968]]
planes
[[-0.0134639  -0.8535254   0.52087736]
 [-0.19157459 -0.50907236 -0.83913326]
 [ 0.98138577 -0.11108485 -0.15665968]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 453.65005 -315.56342  845.4251 ]
[  2.09819159 -79.87727354 -60.65890094]
[ 0.   0.  -9.8]
transform [[-0.0134639  -0.8535254   0.52087736]
 [-0.19157459 -0.50907236 -0.83913326]
 [ 0.98138577 -0.11108485 -0.15665968]]
transform [[-0.0134639  -0.8535254   0.52087736]
 [-0.19157459 -0.50907236 -0.83913326]
 [ 0.98138577 -0.11108485 -0.15665968]]
transform [[-0.0134639  -0.8535254   0.52087736]
 [-0.19157459 -0.50907236 -0.83913326]
 [ 0.98138577 -0.11108485 -0.15665968]]
support
[ 0.63449697 -1.02217441 -0.19083204]
[ 703.59629217 -635.68753957  347.8159964 ]
[36.55318376 91.16225368 20.43509407]
[-5.10459814  8.22350597  1.53526484]
zmp_s [       0.         -7272405.48145369  5120136.62233673]
transform [[-0.0134639  -0.19157459  0.98138577]
 [-0.8535254  -0.50907236 -0.11108485]
 [ 0.52087736 -0.83913326 -0.15665968]]
zmp [6418037.29552966 3133411.04415627 5300398.38620193]
d1:14546214.29712, d2:0.05940, d3:6069362.68666
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-1001.8439214234359 steps:196[00m
[RDDPG] Resetting Environment
transform [[ 0.30356228 -0.24915859  0.91965753]
 [-0.64295542  0.65875673  0.39070183]
 [-0.70317733 -0.70990115  0.03977583]]
planes
[[ 0.30356228 -0.24915859  0.91965753]
 [-0.64295542  0.65875673  0.39070183]
 [-0.70317733 -0.70990115  0.03977583]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 453.65005 -315.56342  845.4251 ]
[  2.09819159 -79.87727354 -60.65890094]
[ 0.   0.  -9.8]
transform [[ 0.30356228 -0.24915859  0.91965753]
 [-0.64295542  0.65875673  0.39070183]
 [-0.70317733 -0.70990115  0.03977583]]
transform [[ 0.30356228 -0.24915859  0.91965753]
 [-0.64295542  0.65875673  0.39070183]
 [-0.70317733 -0.70990115  0.03977583]]
transform [[ 0.30356228 -0.24915859  0.91965753]
 [-0.64295542  0.65875673  0.39070183]
 [-0.70317733 -0.70990115  0.03977583]]
support
[1.12026353 0.47592609 0.04845218]
[ 993.83794957 -169.24714946  -61.35011443]
[-35.24637415 -77.66827904  52.81680956]
[-9.01264378 -3.82887794 -0.38980317]
zmp_s [       0.         -2482189.13082622 -8299347.96018214]
transform [[ 0.30356228 -0.64295542 -0.70317733]
 [-0.24915859  0.65875673 -0.70990115]
 [ 0.91965753  0.39070183  0.03977583]]
zmp [ 7431850.32435889  4256557.8923596  -1299909.31929992]
d1:12052568.55789, d2:0.05940, d3:4604846.67424
transform [[ 0.59965497  0.1713454   0.7816999 ]
 [-0.40902245 -0.77395713  0.48341611]
 [ 0.68783325 -0.60961562 -0.39402312]]
planes
[[ 0.59965497  0.1713454   0.7816999 ]
 [-0.40902245 -0.77395713  0.48341611]
 [ 0.68783325 -0.60961562 -0.39402312]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -8.522007 -532.27484   213.99634 ]
[  18.29897567 -580.29513205 -285.03449728]
[ 0.   0.  -9.8]
transform [[ 0.59965497  0.1713454   0.7816999 ]
 [-0.40902245 -0.77395713  0.48341611]
 [ 0.68783325 -0.60961562 -0.39402312]]
transform [[ 0.59965497  0.1713454   0.7816999 ]
 [-0.40902245 -0.77395713  0.48341611]
 [ 0.68783325 -0.60961562 -0.39402312]]
transform [[ 0.59965497  0.1713454   0.7816999 ]
 [-0.40902245 -0.77395713  0.48341611]
 [ 0.68783325 -0.60961562 -0.39402312]]
support
[ 0.95221303  0.58886425 -0.47997186]
[ 70.96780674 518.89287976 234.30183493]
[-311.26926535  303.84859702  478.65380494]
[-7.66065898 -4.73747788  3.86142658]
zmp_s [       0.         -5974022.2054479  -3486499.01263008]
transform [[ 0.59965497 -0.40902245  0.68783325]
 [ 0.1713454  -0.77395713 -0.60961562]
 [ 0.7816999   0.48341611 -0.39402312]]
zmp [   45379.25602134  6749061.37134698 -1514177.35702761]
d1:9717601.32105, d2:0.05940, d3:2962335.86933
transform [[ 0.91584557 -0.3595174  -0.17881313]
 [-0.36465394 -0.5582819  -0.74521738]
 [ 0.16809055  0.74770892 -0.64239943]]
planes
[[ 0.91584557 -0.3595174  -0.17881313]
 [-0.36465394 -0.5582819  -0.74521738]
 [ 0.16809055  0.74770892 -0.64239943]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -8.522007 -532.27484   213.99634 ]
[  18.29897567 -580.29513205 -285.03449728]
[ 0.   0.  -9.8]
transform [[ 0.91584557 -0.3595174  -0.17881313]
 [-0.36465394 -0.5582819  -0.74521738]
 [ 0.16809055  0.74770892 -0.64239943]]
transform [[ 0.91584557 -0.3595174  -0.17881313]
 [-0.36465394 -0.5582819  -0.74521738]
 [ 0.16809055  0.74770892 -0.64239943]]
transform [[ 0.91584557 -0.3595174  -0.17881313]
 [-0.36465394 -0.5582819  -0.74521738]
 [ 0.16809055  0.74770892 -0.64239943]]
support
[-0.21781785 -0.90777254 -0.78252679]
[ 145.29186735  140.79320152 -536.89023936]
[ 276.35314087  529.70813645 -247.70996094]
[1.75236867 7.30313035 6.29551442]
zmp_s [        0.         -13193859.00380138  10415430.03387149]
transform [[ 0.91584557 -0.36465394  0.16809055]
 [-0.3595174  -0.5582819   0.74770892]
 [-0.17881313 -0.74521738 -0.64239943]]
zmp [ 6561928.11976815 15153602.56038125  3141426.75744048]
d1:29323949.38337, d2:0.05940, d3:1918334.39264
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-703.4471148658743 steps:200[00m
[RDDPG] Resetting Environment
transform [[ 0.31628498  0.40125042  0.85962892]
 [-0.64298081 -0.57559133  0.50524294]
 [ 0.69752389 -0.71252567  0.07594542]]
planes
[[ 0.31628498  0.40125042  0.85962892]
 [-0.64298081 -0.57559133  0.50524294]
 [ 0.69752389 -0.71252567  0.07594542]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.01324  310.94666  839.3976 ]
[   6.13007488 -201.65296191   -4.14052663]
[ 0.   0.  -9.8]
transform [[ 0.31628498  0.40125042  0.85962892]
 [-0.64298081 -0.57559133  0.50524294]
 [ 0.69752389 -0.71252567  0.07594542]]
transform [[ 0.31628498  0.40125042  0.85962892]
 [-0.64298081 -0.57559133  0.50524294]
 [ 0.69752389 -0.71252567  0.07594542]]
transform [[ 0.31628498  0.40125042  0.85962892]
 [-0.64298081 -0.57559133  0.50524294]
 [ 0.69752389 -0.71252567  0.07594542]]
support
[1.0471408  0.61545219 0.09251149]
[ 700.84262896  540.90119875 -478.67929758]
[-82.53380184 110.03620329 147.64433058]
[-8.42436337 -4.95138085 -0.74426514]
zmp_s [        0.         -22864242.40829211   8165309.97645723]
transform [[ 0.31628498 -0.64298081  0.69752389]
 [ 0.40125042 -0.57559133 -0.71252567]
 [ 0.85962892  0.50524294  0.07594542]]
zmp [ 20396767.98828115   7342466.67317201 -10931879.22893472]
d1:36549928.94329, d2:0.05940, d3:10056091.79395
transform [[ 0.88404506  0.21807404 -0.41341034]
 [ 0.2472707   0.53236842  0.8095932 ]
 [ 0.39663777 -0.81794113  0.41671437]]
planes
[[ 0.88404506  0.21807404 -0.41341034]
 [ 0.2472707   0.53236842  0.8095932 ]
 [ 0.39663777 -0.81794113  0.41671437]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.01324  310.94666  839.3976 ]
[   6.13007488 -201.65296191   -4.14052663]
[ 0.   0.  -9.8]
transform [[ 0.88404506  0.21807404 -0.41341034]
 [ 0.2472707   0.53236842  0.8095932 ]
 [ 0.39663777 -0.81794113  0.41671437]]
transform [[ 0.88404506  0.21807404 -0.41341034]
 [ 0.2472707   0.53236842  0.8095932 ]
 [ 0.39663777 -0.81794113  0.41671437]]
transform [[ 0.88404506  0.21807404 -0.41341034]
 [ 0.2472707   0.53236842  0.8095932 ]
 [ 0.39663777 -0.81794113  0.41671437]]
support
[-0.50358803  0.98619074  0.50761278]
[-685.87868223  731.3609574   -87.00564954]
[ -36.84427686 -109.19002331  165.64625364]
[ 4.05142129 -7.93401337 -4.08380083]
zmp_s [       0.         38477640.69482237  6678953.2350334 ]
transform [[ 0.88404506  0.2472707   0.39663777]
 [ 0.21807404  0.53236842 -0.81794113]
 [-0.41341034  0.8095932   0.41671437]]
zmp [12163518.3772756  15021290.29085825 33934452.07614537]
d1:74774145.41196, d2:0.05940, d3:21557175.33344
transform [[ 0.88406557  0.21811825 -0.41334307]
 [ 0.24719727  0.5323503   0.80962747]
 [ 0.39663777 -0.81794113  0.41671437]]
planes
[[ 0.88406557  0.21811825 -0.41334307]
 [ 0.24719727  0.5323503   0.80962747]
 [ 0.39663777 -0.81794113  0.41671437]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.01324  310.94666  839.3976 ]
[   6.13007488 -201.65296191   -4.14052663]
[ 0.   0.  -9.8]
transform [[ 0.88406557  0.21811825 -0.41334307]
 [ 0.24719727  0.5323503   0.80962747]
 [ 0.39663777 -0.81794113  0.41671437]]
transform [[ 0.88406557  0.21811825 -0.41334307]
 [ 0.24719727  0.5323503   0.80962747]
 [ 0.39663777 -0.81794113  0.41671437]]
transform [[ 0.88406557  0.21811825 -0.41334307]
 [ 0.24719727  0.5323503   0.80962747]
 [ 0.39663777 -0.81794113  0.41671437]]
support
[-0.50350609  0.98623249  0.50761278]
[-685.81790574  731.41787161  -87.00564954]
[ -36.85334511 -109.18696145  165.64625364]
[ 4.0507621  -7.93434924 -4.08380083]
zmp_s [       0.         38477640.69488358  6678953.23503801]
transform [[ 0.88406557  0.24719727  0.39663777]
 [ 0.21811825  0.5323503  -0.81794113]
 [-0.41334307  0.80962747  0.41671437]]
zmp [12160692.8516907  15020593.08327102 33935770.80770747]
d1:74775705.40089, d2:0.05940, d3:21556469.84519
transform [[ 0.10720275  0.30961379 -0.9447999 ]
 [ 0.99380869 -0.06126711  0.09268617]
 [-0.02918825 -0.94888657 -0.31426477]]
planes
[[ 0.10720275  0.30961379 -0.9447999 ]
 [ 0.99380869 -0.06126711  0.09268617]
 [-0.02918825 -0.94888657 -0.31426477]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-542.1013   552.89185 -453.3492 ]
[ 100.96654169 -236.4778095    58.32614486]
[ 0.   0.  -9.8]
transform [[ 0.10720275  0.30961379 -0.9447999 ]
 [ 0.99380869 -0.06126711  0.09268617]
 [-0.02918825 -0.94888657 -0.31426477]]
transform [[ 0.10720275  0.30961379 -0.9447999 ]
 [ 0.99380869 -0.06126711  0.09268617]
 [-0.02918825 -0.94888657 -0.31426477]]
transform [[ 0.10720275  0.30961379 -0.9447999 ]
 [ 0.99380869 -0.06126711  0.09268617]
 [-0.02918825 -0.94888657 -0.31426477]]
support
[-1.15089024  0.11290391 -0.38281573]
[ 541.3924789  -614.63828728 -366.33697046]
[-117.49943638  120.23576542  203.11372861]
[ 9.25903902 -0.90832445  3.07979479]
zmp_s [        0.           5289260.95751882 -20830966.92369024]
transform [[ 0.10720275  0.99380869 -0.02918825]
 [ 0.30961379 -0.06126711 -0.94888657]
 [-0.9447999   0.09268617 -0.31426477]]
zmp [ 5864533.01848199 19442167.08247687  7036680.45339067]
d1:33771707.71203, d2:0.05940, d3:12020821.73525
transform [[ 0.65526688 -0.25558373  0.71084619]
 [-0.75483334 -0.18517892  0.62923396]
 [-0.02918825 -0.94888657 -0.31426477]]
planes
[[ 0.65526688 -0.25558373  0.71084619]
 [-0.75483334 -0.18517892  0.62923396]
 [-0.02918825 -0.94888657 -0.31426477]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-542.1013   552.89185 -453.3492 ]
[ 100.96654169 -236.4778095    58.32614486]
[ 0.   0.  -9.8]
transform [[ 0.65526688 -0.25558373  0.71084619]
 [-0.75483334 -0.18517892  0.62923396]
 [-0.02918825 -0.94888657 -0.31426477]]
transform [[ 0.65526688 -0.25558373  0.71084619]
 [-0.75483334 -0.18517892  0.62923396]
 [-0.02918825 -0.94888657 -0.31426477]]
transform [[ 0.65526688 -0.25558373  0.71084619]
 [-0.75483334 -0.18517892  0.62923396]
 [-0.02918825 -0.94888657 -0.31426477]]
support
[ 0.86590392  0.76648951 -0.38281573]
[-818.7927607    21.54951522 -366.33697046]
[168.06082986   4.27858444 203.11372861]
[-6.96629262 -6.16649277  3.07979479]
zmp_s [        0.           5289263.52859254 -20830966.7689143 ]
transform [[ 0.65526688 -0.75483334 -0.02918825]
 [-0.25558373 -0.18517892 -0.94888657]
 [ 0.71084619  0.62923396 -0.31426477]]
zmp [-3384492.93085526 18786764.56505217  9874623.28675771]
d1:36039455.60315, d2:0.05940, d3:11662115.83708
transform [[ 0.33385792  0.241216    0.91123748]
 [-0.80243593 -0.43451357  0.40901658]
 [ 0.49460641 -0.8677631   0.04849461]]
planes
[[ 0.33385792  0.241216    0.91123748]
 [-0.80243593 -0.43451357  0.40901658]
 [ 0.49460641 -0.8677631   0.04849461]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-508.22812  324.75006 -294.17184]
[ 100.96654169 -236.4778095    58.32614486]
[ 0.   0.  -9.8]
transform [[ 0.33385792  0.241216    0.91123748]
 [-0.80243593 -0.43451357  0.40901658]
 [ 0.49460641 -0.8677631   0.04849461]]
transform [[ 0.33385792  0.241216    0.91123748]
 [-0.80243593 -0.43451357  0.40901658]
 [ 0.49460641 -0.8677631   0.04849461]]
transform [[ 0.33385792  0.241216    0.91123748]
 [-0.80243593 -0.43451357  0.40901658]
 [ 0.49460641 -0.8677631   0.04849461]]
support
[1.1100068  0.49823586 0.0590728 ]
[-359.40148232  146.39103595 -547.44475366]
[ 29.81521692  45.58999599 257.97391972]
[-8.93012729 -4.00836248 -0.47524722]
zmp_s [        0.          -6321240.37229373 -26964125.7159172 ]
transform [[ 0.33385792 -0.80243593  0.49460641]
 [ 0.241216   -0.43451357 -0.8677631 ]
 [ 0.91123748  0.40901658  0.04849461]]
zmp [-8264238.87209186 26145138.08933656 -3893107.000832  ]
d1:25325654.55199, d2:0.05940, d3:12784410.86154
transform [[ 0.15810615  0.4374392  -0.88523972]
 [-0.95458406 -0.16156825 -0.25032979]
 [-0.25253072  0.88461441  0.39202756]]
planes
[[ 0.15810615  0.4374392  -0.88523972]
 [-0.95458406 -0.16156825 -0.25032979]
 [-0.25253072  0.88461441  0.39202756]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  787.9021 -1076.8447  -290.9633]
[  15.49635749 -346.47175934 -143.00771874]
[ 0.   0.  -9.8]
transform [[ 0.15810615  0.4374392  -0.88523972]
 [-0.95458406 -0.16156825 -0.25032979]
 [-0.25253072  0.88461441  0.39202756]]
transform [[ 0.15810615  0.4374392  -0.88523972]
 [-0.95458406 -0.16156825 -0.25032979]
 [-0.25253072  0.88461441  0.39202756]]
transform [[ 0.15810615  0.4374392  -0.88523972]
 [-0.95458406 -0.16156825 -0.25032979]
 [-0.25253072  0.88461441  0.39202756]]
support
[-1.07833812 -0.30493453  0.477541  ]
[  -88.90967394  -505.29808488 -1265.62747451]
[ -22.51414802   76.98535398 -366.47018325]
[ 8.67534926  2.45323197 -3.84187006]
zmp_s [        0.           7763408.88573128 -14971615.4204747 ]
transform [[ 0.15810615 -0.95458406 -0.25253072]
 [ 0.4374392  -0.16156825  0.88461441]
 [-0.88523972 -0.25032979  0.39202756]]
zmp [ -3630033.51114001 -14498427.13278947  -7812698.35153253]
d1:24685649.25598, d2:0.05940, d3:8100156.82029
transform [[-0.2938827   0.39659527  0.869681  ]
 [-0.57233268 -0.80173558  0.17220783]
 [ 0.76555109 -0.44713807  0.46260044]]
planes
[[-0.2938827   0.39659527  0.869681  ]
 [-0.57233268 -0.80173558  0.17220783]
 [ 0.76555109 -0.44713807  0.46260044]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-307.9394     -9.114267  310.54675 ]
[   4.35802211 -431.91659049  -54.80784119]
[ 0.   0.  -9.8]
transform [[-0.2938827   0.39659527  0.869681  ]
 [-0.57233268 -0.80173558  0.17220783]
 [ 0.76555109 -0.44713807  0.46260044]]
transform [[-0.2938827   0.39659527  0.869681  ]
 [-0.57233268 -0.80173558  0.17220783]
 [ 0.76555109 -0.44713807  0.46260044]]
transform [[-0.2938827   0.39659527  0.869681  ]
 [-0.57233268 -0.80173558  0.17220783]
 [ 0.76555109 -0.44713807  0.46260044]]
support
[1.05938556 0.20977173 0.56350803]
[356.95999485 237.0295932  -88.00893694]
[-220.24216204  334.35032017  171.10850827]
[-8.52287381 -1.68763676 -4.53348431]
zmp_s [       0.         28103555.00316557 13582260.80444477]
transform [[-0.2938827  -0.57233268  0.76555109]
 [ 0.39659527 -0.80173558 -0.44713807]
 [ 0.869681    0.17220783  0.46260044]]
zmp [ -5686668.39204971 -28604765.86634718  11122812.10947933]
d1:44057925.95590, d2:0.05940, d3:20539451.39896
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-1063.0966777348756 steps:209[00m
[RDDPG] Resetting Environment
transform [[ 0.07055747 -0.04115792  0.99665833]
 [-0.99640322 -0.04991511  0.06847812]
 [ 0.04692988 -0.99790508 -0.04453177]]
planes
[[ 0.07055747 -0.04115792  0.99665833]
 [-0.99640322 -0.04991511  0.06847812]
 [ 0.04692988 -0.99790508 -0.04453177]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-828.1236   916.28406 1106.71   ]
[ 194.75153808 -482.74495719  224.60997144]
[ 0.   0.  -9.8]
transform [[ 0.07055747 -0.04115792  0.99665833]
 [-0.99640322 -0.04991511  0.06847812]
 [ 0.04692988 -0.99790508 -0.04453177]]
transform [[ 0.07055747 -0.04115792  0.99665833]
 [-0.99640322 -0.04991511  0.06847812]
 [ 0.04692988 -0.99790508 -0.04453177]]
transform [[ 0.07055747 -0.04115792  0.99665833]
 [-0.99640322 -0.04991511  0.06847812]
 [ 0.04692988 -0.99790508 -0.04453177]]
support
[ 1.2140606   0.08341534 -0.05424553]
[ 1006.86904303   855.19402065 -1002.51200292]
[ 257.46935339 -154.57392474  480.87103072]
[-9.76725159 -0.6710856   0.43641131]
zmp_s [        0.          7771028.0606885 -10962095.9891521]
transform [[ 0.07055747 -0.99640322  0.04692988]
 [-0.04115792 -0.04991511 -0.99790508]
 [ 0.99665833  0.06847812 -0.04453177]]
zmp [-8257527.22154622 10551239.54382318  1020306.90737645]
d1:12149911.08909, d2:0.05940, d3:4669825.01617
transform [[ 0.90587908  0.42271492  0.02636651]
 [ 0.04411398 -0.15608461  0.98675811]
 [ 0.4212327  -0.8927204  -0.16004142]]
planes
[[ 0.90587908  0.42271492  0.02636651]
 [ 0.04411398 -0.15608461  0.98675811]
 [ 0.4212327  -0.8927204  -0.16004142]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  285.47968 -1189.879     375.7541 ]
[ 270.33866256 -227.85766415   67.58294582]
[ 0.   0.  -9.8]
transform [[ 0.90587908  0.42271492  0.02636651]
 [ 0.04411398 -0.15608461  0.98675811]
 [ 0.4212327  -0.8927204  -0.16004142]]
transform [[ 0.90587908  0.42271492  0.02636651]
 [ 0.04411398 -0.15608461  0.98675811]
 [ 0.4212327  -0.8927204  -0.16004142]]
transform [[ 0.90587908  0.42271492  0.02636651]
 [ 0.04411398 -0.15608461  0.98675811]
 [ 0.4212327  -0.8927204  -0.16004142]]
support
[ 0.03211787  1.20200084 -0.19495145]
[-234.46222814  569.09384693 1122.34643951]
[150.35723125 114.17880919 306.47259949]
[-0.25839177 -9.67022951  1.56840593]
zmp_s [      0.         1429459.95924026 -519838.02760677]
transform [[ 0.90587908  0.04411398  0.4212327 ]
 [ 0.42271492 -0.15608461 -0.8927204 ]
 [ 0.02636651  0.98675811 -0.16004142]]
zmp [-155913.60985564  240953.30948482 1493726.8288235 ]
d1:2944913.36902, d2:0.05940, d3:759286.51824
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-570.5104556238936 steps:212[00m
[RDDPG] Resetting Environment
transform [[ 0.73043609  0.67974198 -0.06643772]
 [ 0.04226205  0.05210552  0.997747  ]
 [ 0.68167228 -0.7315982   0.00933247]]
planes
[[ 0.73043609  0.67974198 -0.06643772]
 [ 0.04226205  0.05210552  0.997747  ]
 [ 0.68167228 -0.7315982   0.00933247]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 85.294716 479.90445  638.5989  ]
[  65.55123025 -310.82152229   -3.63239857]
[ 0.   0.  -9.8]
transform [[ 0.73043609  0.67974198 -0.06643772]
 [ 0.04226205  0.05210552  0.997747  ]
 [ 0.68167228 -0.7315982   0.00933247]]
transform [[ 0.73043609  0.67974198 -0.06643772]
 [ 0.04226205  0.05210552  0.997747  ]
 [ 0.68167228 -0.7315982   0.00933247]]
transform [[ 0.73043609  0.67974198 -0.06643772]
 [ 0.04226205  0.05210552  0.997747  ]
 [ 0.68167228 -0.7315982   0.00933247]]
support
[-0.08092986  1.21538676  0.01136817]
[ 346.08648434  665.77051823 -286.99448534]
[-163.15612418  -17.04940376  272.04702276]
[ 0.65108967 -9.77792064 -0.09145817]
zmp_s [       0.         10042635.58390736 -6475069.60480969]
transform [[ 0.73043609  0.04226205  0.68167228]
 [ 0.67974198  0.05210552 -0.7315982 ]
 [-0.06643772  0.997747    0.00933247]]
zmp [-3989453.08635803  5260426.04336726  9959581.19988909]
d1:21012697.93754, d2:0.05940, d3:9306121.57868
transform [[ 0.42446139  0.40582025  0.80940872]
 [-0.59594923 -0.54779023  0.58717161]
 [ 0.68167228 -0.7315982   0.00933247]]
planes
[[ 0.42446139  0.40582025  0.80940872]
 [-0.59594923 -0.54779023  0.58717161]
 [ 0.68167228 -0.7315982   0.00933247]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 85.294716 479.90445  638.5989  ]
[  65.55123025 -310.82152229   -3.63239857]
[ 0.   0.  -9.8]
transform [[ 0.42446139  0.40582025  0.80940872]
 [-0.59594923 -0.54779023  0.58717161]
 [ 0.68167228 -0.7315982   0.00933247]]
transform [[ 0.42446139  0.40582025  0.80940872]
 [-0.59594923 -0.54779023  0.58717161]
 [ 0.68167228 -0.7315982   0.00933247]]
transform [[ 0.42446139  0.40582025  0.80940872]
 [-0.59594923 -0.54779023  0.58717161]
 [ 0.68167228 -0.7315982   0.00933247]]
support
[0.98596602 0.71525206 0.01136817]
[ 747.84676029   61.24884449 -286.99448534]
[-101.25379652  129.06694628  272.04702276]
[-7.9322055  -5.75428182 -0.09145817]
zmp_s [       0.         10042635.27362975 -6475068.93164329]
transform [[ 0.42446139 -0.59594923  0.68167228]
 [ 0.40582025 -0.54779023 -0.7315982 ]
 [ 0.80940872  0.58717161  0.00933247]]
zmp [-10398775.75422808   -764108.71452833   5836322.00387982]
d1:17358238.40560, d2:0.05940, d3:6367610.55092
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-360.8188915087637 steps:215[00m
[RDDPG] Resetting Environment
transform [[ 0.71039659 -0.70204806 -0.04965159]
 [ 0.01189492 -0.05856117  0.99821293]
 [-0.70370108 -0.70971775 -0.03325086]]
planes
[[ 0.71039659 -0.70204806 -0.04965159]
 [ 0.01189492 -0.05856117  0.99821293]
 [-0.70370108 -0.70971775 -0.03325086]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 85.294716 479.90445  638.5989  ]
[  65.55123025 -310.82152229   -3.63239857]
[ 0.   0.  -9.8]
transform [[ 0.71039659 -0.70204806 -0.04965159]
 [ 0.01189492 -0.05856117  0.99821293]
 [-0.70370108 -0.70971775 -0.03325086]]
transform [[ 0.71039659 -0.70204806 -0.04965159]
 [ 0.01189492 -0.05856117  0.99821293]
 [-0.70370108 -0.70971775 -0.03325086]]
transform [[ 0.71039659 -0.70204806 -0.04965159]
 [ 0.01189492 -0.05856117  0.99821293]
 [-0.70370108 -0.70971775 -0.03325086]]
support
[-0.06048215  1.21595432 -0.04050391]
[-308.03036331  610.36846635 -421.85264997]
[264.95937241  15.35589067 174.58786054]
[ 0.48658557 -9.78248675  0.3258584 ]
zmp_s [       0.          7410420.16552651 -7555456.00753639]
transform [[ 0.71039659  0.01189492 -0.70370108]
 [-0.70204806 -0.05856117 -0.70971775]
 [-0.04965159  0.99821293 -0.03325086]]
zmp [5404928.86388004 4928278.37725092 7648402.6405656 ]
d1:18158324.02530, d2:0.05940, d3:8158077.44894
transform [[ 0.25032672 -0.20386243 -0.94645476]
 [ 0.66493714 -0.67434478  0.32111952]
 [-0.70370108 -0.70971775 -0.03325086]]
planes
[[ 0.25032672 -0.20386243 -0.94645476]
 [ 0.66493714 -0.67434478  0.32111952]
 [-0.70370108 -0.70971775 -0.03325086]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 85.294716 479.90445  638.5989  ]
[  65.55123025 -310.82152229   -3.63239857]
[ 0.   0.  -9.8]
transform [[ 0.25032672 -0.20386243 -0.94645476]
 [ 0.66493714 -0.67434478  0.32111952]
 [-0.70370108 -0.70971775 -0.03325086]]
transform [[ 0.25032672 -0.20386243 -0.94645476]
 [ 0.66493714 -0.67434478  0.32111952]
 [-0.70370108 -0.70971775 -0.03325086]]
transform [[ 0.25032672 -0.20386243 -0.94645476]
 [ 0.66493714 -0.67434478  0.32111952]
 [-0.70370108 -0.70971775 -0.03325086]]
support
[-1.15290608  0.3911657  -0.04050391]
[-680.88788889  -61.83887217 -421.85264997]
[ 83.21195599 252.02188387 174.58786054]
[ 9.27525668 -3.14697127  0.3258584 ]
zmp_s [       0.          7410419.26267514 -7555455.69214995]
transform [[ 0.25032672  0.66493714 -0.70370108]
 [-0.20386243 -0.67434478 -0.70971775]
 [-0.94645476  0.32111952 -0.03325086]]
zmp [10244245.30211887   365063.48518071  2630855.63293137]
d1:12932417.71472, d2:0.05940, d3:5261372.67810
transform [[ 0.28539726 -0.06114595 -0.95645678]
 [ 0.95694828 -0.03690269  0.28790313]
 [-0.05289994 -0.99744648  0.0479816 ]]
planes
[[ 0.28539726 -0.06114595 -0.95645678]
 [ 0.95694828 -0.03690269  0.28790313]
 [-0.05289994 -0.99744648  0.0479816 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 85.294716 479.90445  638.5989  ]
[  65.55123025 -310.82152229   -3.63239857]
[ 0.   0.  -9.8]
transform [[ 0.28539726 -0.06114595 -0.95645678]
 [ 0.95694828 -0.03690269  0.28790313]
 [-0.05289994 -0.99744648  0.0479816 ]]
transform [[ 0.28539726 -0.06114595 -0.95645678]
 [ 0.95694828 -0.03690269  0.28790313]
 [-0.05289994 -0.99744648  0.0479816 ]]
transform [[ 0.28539726 -0.06114595 -0.95645678]
 [ 0.95694828 -0.03690269  0.28790313]
 [-0.05289994 -0.99744648  0.0479816 ]]
support
[-1.16508985  0.35070379  0.05844788]
[-615.79356283  247.76748104 -452.55009353]
[ 41.18785229  73.1535091  306.38588821]
[ 9.37327645 -2.82145067 -0.47021966]
zmp_s [       0.          2555890.88533613 -1817464.9418149 ]
transform [[ 0.28539726  0.95694828 -0.05289994]
 [-0.06114595 -0.03690269 -0.99744648]
 [-0.95645678  0.28790313  0.0479816 ]]
zmp [2541999.17032361 1718504.74947623  648644.11468806]
d1:2007443.43061, d2:0.05940, d3:1468489.06685
transform [[ 0.39244547  0.87631261 -0.27939722]
 [-0.08946246  0.33869419  0.93663377]
 [ 0.91541415 -0.34258208  0.21131606]]
planes
[[ 0.39244547  0.87631261 -0.27939722]
 [-0.08946246  0.33869419  0.93663377]
 [ 0.91541415 -0.34258208  0.21131606]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[724.49567  413.98972  -34.171993]
[-139.2218302    66.0282366    45.03805234]
[ 0.   0.  -9.8]
transform [[ 0.39244547  0.87631261 -0.27939722]
 [-0.08946246  0.33869419  0.93663377]
 [ 0.91541415 -0.34258208  0.21131606]]
transform [[ 0.39244547  0.87631261 -0.27939722]
 [-0.08946246  0.33869419  0.93663377]
 [ 0.91541415 -0.34258208  0.21131606]]
transform [[ 0.39244547  0.87631261 -0.27939722]
 [-0.08946246  0.33869419  0.93663377]
 [ 0.91541415 -0.34258208  0.21131606]]
support
[-0.34034247  1.14094281  0.25741069]
[656.65701539  43.39410268 514.16704037]
[  -9.35910727   77.00266763 -140.54846046]
[ 2.73809275 -9.1790109  -2.07089743]
zmp_s [       0.         10191542.37175027 10265642.6385035 ]
transform [[ 0.39244547 -0.08946246  0.91541415]
 [ 0.87631261  0.33869419 -0.34258208]
 [-0.27939722  0.93663377  0.21131606]]
zmp [ 8485554.13415848   -65009.03697957 11715037.90671834]
d1:23881710.67579, d2:0.05940, d3:10055861.24024
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-1206.3685987066806 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-159.8318580273593 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-252.6281133983952 steps:222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-129.36782018557426 steps:223[00m
[RDDPG] Resetting Environment
transform [[ 0.67366391 -0.73807037  0.03780419]
 [ 0.07348625  0.11779783  0.9903149 ]
 [-0.73537529 -0.66436124  0.13359416]]
planes
[[ 0.67366391 -0.73807037  0.03780419]
 [ 0.07348625  0.11779783  0.9903149 ]
 [-0.73537529 -0.66436124  0.13359416]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[724.49567  413.98972  -34.171993]
[-139.2218302    66.0282366    45.03805234]
[ 0.   0.  -9.8]
transform [[ 0.67366391 -0.73807037  0.03780419]
 [ 0.07348625  0.11779783  0.9903149 ]
 [-0.73537529 -0.66436124  0.13359416]]
transform [[ 0.67366391 -0.73807037  0.03780419]
 [ 0.07348625  0.11779783  0.9903149 ]
 [-0.73537529 -0.66436124  0.13359416]]
transform [[ 0.67366391 -0.73807037  0.03780419]
 [ 0.07348625  0.11779783  0.9903149 ]
 [-0.73537529 -0.66436124  0.13359416]]
support
[0.04605046 1.20633348 0.16273521]
[ 181.22119995   68.16652259 -812.38010608]
[-140.81958093   42.14894759   64.5305126 ]
[-0.37048106 -9.70508603 -1.30922272]
zmp_s [        0.          22256280.83463084 -12006697.39701374]
transform [[ 0.67366391  0.07348625 -0.73537529]
 [-0.73807037  0.11779783 -0.66436124]
 [ 0.03780419  0.9903149   0.13359416]]
zmp [10464959.05423366 10598525.92135453 20436701.95175979]
d1:45500995.53485, d2:0.05940, d3:19623547.84852
transform [[ 0.13424857 -0.33605647 -0.93222499]
 [ 0.66422933 -0.66760039  0.33631718]
 [-0.73537529 -0.66436124  0.13359416]]
planes
[[ 0.13424857 -0.33605647 -0.93222499]
 [ 0.66422933 -0.66760039  0.33631718]
 [-0.73537529 -0.66436124  0.13359416]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[724.49567  413.98972  -34.171993]
[-139.2218302    66.0282366    45.03805234]
[ 0.   0.  -9.8]
transform [[ 0.13424857 -0.33605647 -0.93222499]
 [ 0.66422933 -0.66760039  0.33631718]
 [-0.73537529 -0.66436124  0.13359416]]
transform [[ 0.13424857 -0.33605647 -0.93222499]
 [ 0.66422933 -0.66760039  0.33631718]
 [-0.73537529 -0.66436124  0.13359416]]
transform [[ 0.13424857 -0.33605647 -0.93222499]
 [ 0.66422933 -0.66760039  0.33631718]
 [-0.73537529 -0.66436124  0.13359416]]
support
[-1.13557234  0.40967845  0.16273521]
[ -10.00542984  193.35894821 -812.38010608]
[ -82.86514558 -121.40862937   64.5305126 ]
[ 9.13580489 -3.29590838 -1.30922272]
zmp_s [        0.          22256106.42683816 -12005495.69635826]
transform [[ 0.13424857  0.66422933 -0.73537529]
 [-0.33605647 -0.66760039 -0.66436124]
 [-0.93222499  0.33631718  0.13359416]]
zmp [23611703.55705432 -6882199.41438469  5881246.92992756]
d1:33454323.20314, d2:0.05940, d3:9612081.27463
transform [[ 0.70199823  0.62643731 -0.33878437]
 [ 0.03933961  0.44086623  0.89671028]
 [ 0.71109134 -0.64281672  0.28484356]]
planes
[[ 0.70199823  0.62643731 -0.33878437]
 [ 0.03933961  0.44086623  0.89671028]
 [ 0.71109134 -0.64281672  0.28484356]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-625.2465   248.25822 1055.0872 ]
[ 393.57742148 -122.19728157 -163.60532649]
[ 0.   0.  -9.8]
transform [[ 0.70199823  0.62643731 -0.33878437]
 [ 0.03933961  0.44086623  0.89671028]
 [ 0.71109134 -0.64281672  0.28484356]]
transform [[ 0.70199823  0.62643731 -0.33878437]
 [ 0.03933961  0.44086623  0.89671028]
 [ 0.71109134 -0.64281672  0.28484356]]
transform [[ 0.70199823  0.62643731 -0.33878437]
 [ 0.03933961  0.44086623  0.89671028]
 [ 0.71109134 -0.64281672  0.28484356]]
support
[-0.41268381  1.09231077  0.34697683]
[-640.85077484 1030.95920917 -303.65713785]
[ 255.16864577 -185.09604913  311.81802761]
[ 3.3200868  -8.78776071 -2.79146693]
zmp_s [        0.         -20396735.08025438 -20572531.16432132]
transform [[ 0.70199823  0.03933961  0.71109134]
 [ 0.62643731  0.44086623 -0.64281672]
 [-0.33878437  0.89671028  0.28484356]]
zmp [-15431348.41233311   4232135.31610935 -24149915.05366298]
d1:49267931.50679, d2:0.05940, d3:21898738.89207
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-195.86964357128954 steps:227[00m
[RDDPG] Resetting Environment
transform [[ 0.12322105 -0.20098472 -0.97181362]
 [ 0.70331478 -0.67318738  0.22840136]
 [-0.70011783 -0.71163476  0.05840468]]
planes
[[ 0.12322105 -0.20098472 -0.97181362]
 [ 0.70331478 -0.67318738  0.22840136]
 [-0.70011783 -0.71163476  0.05840468]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-625.2465   248.25822 1055.0872 ]
[ 393.57742148 -122.19728157 -163.60532649]
[ 0.   0.  -9.8]
transform [[ 0.12322105 -0.20098472 -0.97181362]
 [ 0.70331478 -0.67318738  0.22840136]
 [-0.70011783 -0.71163476  0.05840468]]
transform [[ 0.12322105 -0.20098472 -0.97181362]
 [ 0.70331478 -0.67318738  0.22840136]
 [-0.70011783 -0.71163476  0.05840468]]
transform [[ 0.12322105 -0.20098472 -0.97181362]
 [ 0.70331478 -0.67318738  0.22840136]
 [-0.70011783 -0.71163476  0.05840468]]
support
[-1.18379649  0.27822283  0.07114456]
[-1152.28770965  -365.88607768   322.6990827 ]
[ 232.05069247  321.70280574 -198.14605312]
[ 9.52377347 -2.23833336 -0.57236587]
zmp_s [      0.         -649315.20132667 -245682.91906148]
transform [[ 0.12322105  0.70331478 -0.70011783]
 [-0.20098472 -0.67318738 -0.71163476]
 [-0.97181362  0.22840136  0.05840468]]
zmp [-284665.98745162  611947.29992035 -162653.50928523]
d1:798250.88084, d2:0.05940, d3:184786.59833
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-294.5173853004073 steps:229[00m
[RDDPG] Resetting Environment
transform [[ 0.33182314 -0.27733931 -0.90165198]
 [ 0.62335646 -0.65293145  0.43024099]
 [-0.7080397  -0.70481449 -0.0437765 ]]
planes
[[ 0.33182314 -0.27733931 -0.90165198]
 [ 0.62335646 -0.65293145  0.43024099]
 [-0.7080397  -0.70481449 -0.0437765 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-625.2465   248.25822 1055.0872 ]
[ 393.57742148 -122.19728157 -163.60532649]
[ 0.   0.  -9.8]
transform [[ 0.33182314 -0.27733931 -0.90165198]
 [ 0.62335646 -0.65293145  0.43024099]
 [-0.7080397  -0.70481449 -0.0437765 ]]
transform [[ 0.33182314 -0.27733931 -0.90165198]
 [ 0.62335646 -0.65293145  0.43024099]
 [-0.7080397  -0.70481449 -0.0437765 ]]
transform [[ 0.33182314 -0.27733931 -0.90165198]
 [ 0.62335646 -0.65293145  0.43024099]
 [-0.7080397  -0.70481449 -0.0437765 ]]
support
[-1.09833041  0.52408997 -0.05332552]
[-1227.64445233   -97.9053197    221.53534098]
[ 312.00327199  254.73575982 -185.37995595]
[ 8.83618939 -4.21636169  0.42900971]
zmp_s [       0.          6884219.46401768 -6435343.96235291]
transform [[ 0.33182314  0.62335646 -0.7080397 ]
 [-0.27733931 -0.65293145 -0.70481449]
 [-0.90165198  0.43024099 -0.0437765 ]]
zmp [8847801.70029103   40800.28719541 3243590.23005384]
d1:12365027.58537, d2:0.05940, d3:4967428.67781
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-282.45482252692415 steps:231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-310.78153722654656 steps:232[00m
[RDDPG] Resetting Environment
transform [[ 0.99747992  0.01258989  0.06982413]
 [-0.06938191 -0.03267903  0.99705476]
 [ 0.01483459 -0.99938667 -0.03172316]]
planes
[[ 0.99747992  0.01258989  0.06982413]
 [-0.06938191 -0.03267903  0.99705476]
 [ 0.01483459 -0.99938667 -0.03172316]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-667.40607   -52.485485 1084.502   ]
[ 393.57742148 -122.19728157 -163.60532649]
[ 0.   0.  -9.8]
transform [[ 0.99747992  0.01258989  0.06982413]
 [-0.06938191 -0.03267903  0.99705476]
 [ 0.01483459 -0.99938667 -0.03172316]]
transform [[ 0.99747992  0.01258989  0.06982413]
 [-0.06938191 -0.03267903  0.99705476]
 [ 0.01483459 -0.99938667 -0.03172316]]
transform [[ 0.99747992  0.01258989  0.06982413]
 [-0.06938191 -0.03267903  0.99705476]
 [ 0.01483459 -0.99938667 -0.03172316]]
support
[ 0.08505495  1.21454351 -0.03864297]
[-590.66052896 1129.32891045    8.14877047]
[ 379.62352375 -186.43733309  133.15097114]
[-0.68427647 -9.77113661  0.31088697]
zmp_s [        0.           2478846.60073934 -13870399.72214933]
transform [[ 0.99747992 -0.06938191  0.01483459]
 [ 0.01258989 -0.03267903 -0.99938667]
 [ 0.06982413  0.99705476 -0.03172316]]
zmp [ -377748.77649551 13780886.2747496   2911558.70565223]
d1:23907127.21165, d2:0.05940, d3:1126713.49137
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-66.4364215588016 steps:234[00m
[RDDPG] Resetting Environment
transform [[ 0.62443113 -0.78069383  0.0245565 ]
 [ 0.00784586  0.03770681  0.99925804]
 [-0.78104049 -0.62377518  0.02967052]]
planes
[[ 0.62443113 -0.78069383  0.0245565 ]
 [ 0.00784586  0.03770681  0.99925804]
 [-0.78104049 -0.62377518  0.02967052]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-667.40607   -52.485485 1084.502   ]
[ 393.57742148 -122.19728157 -163.60532649]
[ 0.   0.  -9.8]
transform [[ 0.62443113 -0.78069383  0.0245565 ]
 [ 0.00784586  0.03770681  0.99925804]
 [-0.78104049 -0.62377518  0.02967052]]
transform [[ 0.62443113 -0.78069383  0.0245565 ]
 [ 0.00784586  0.03770681  0.99925804]
 [-0.78104049 -0.62377518  0.02967052]]
transform [[ 0.62443113 -0.78069383  0.0245565 ]
 [ 0.00784586  0.03770681  0.99925804]
 [-0.78104049 -0.62377518  0.02967052]]
support
[0.02991304 1.2172274  0.03614259]
[-349.14246129 1076.48186317  586.18804508]
[ 337.14308494 -165.00365539 -236.03052586]
[-0.24065369 -9.79272881 -0.29077113]
zmp_s [       0.          -847700.24200981 -2341000.9414234 ]
transform [[ 0.62443113  0.00784586 -0.78104049]
 [-0.78069383  0.03770681 -0.62377518]
 [ 0.0245565   0.99925804  0.02967052]]
zmp [1821765.58500594 1428294.21739029 -916530.00690785]
d1:3759572.00359, d2:0.05940, d3:1613416.56728
transform [[ 0.07868946 -0.10165366 -0.99170285]
 [ 0.89076382 -0.43948457  0.11572915]
 [-0.44760236 -0.89247966  0.05596659]]
planes
[[ 0.07868946 -0.10165366 -0.99170285]
 [ 0.89076382 -0.43948457  0.11572915]
 [-0.44760236 -0.89247966  0.05596659]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-831.07166  373.9791   397.28748]
[-91.81058792 -74.15444024  45.9894469 ]
[ 0.   0.  -9.8]
transform [[ 0.07868946 -0.10165366 -0.99170285]
 [ 0.89076382 -0.43948457  0.11572915]
 [-0.44760236 -0.89247966  0.05596659]]
transform [[ 0.07868946 -0.10165366 -0.99170285]
 [ 0.89076382 -0.43948457  0.11572915]
 [-0.44760236 -0.89247966  0.05596659]]
transform [[ 0.07868946 -0.10165366 -0.99170285]
 [ 0.89076382 -0.43948457  0.11572915]
 [-0.44760236 -0.89247966  0.05596659]]
support
[-1.20802419  0.14097329  0.06817465]
[-497.4040431  -858.66885921   60.45572526]
[-45.29432089 -43.86949818 109.84983794]
[ 9.71868798 -1.1341457  -0.54847258]
zmp_s [       0.         12327533.49600129   193965.88473551]
transform [[ 0.07868946  0.89076382 -0.44760236]
 [-0.10165366 -0.43948457 -0.89247966]
 [-0.99170285  0.11572915  0.05596659]]
zmp [10894101.23038547 -5590871.32038646  1437510.62106528]
d1:8051201.47244, d2:0.05940, d3:6088995.06668
transform [[ 0.31716079  0.94524926  0.07689573]
 [-0.16228631 -0.02579172  0.98640662]
 [ 0.93438333 -0.32532862  0.14522088]]
planes
[[ 0.31716079  0.94524926  0.07689573]
 [-0.16228631 -0.02579172  0.98640662]
 [ 0.93438333 -0.32532862  0.14522088]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 588.2817   262.15472 -113.22841]
[-1.53495874e-01 -2.02116504e+02  4.45106209e+01]
[ 0.   0.  -9.8]
transform [[ 0.31716079  0.94524926  0.07689573]
 [-0.16228631 -0.02579172  0.98640662]
 [ 0.93438333 -0.32532862  0.14522088]]
transform [[ 0.31716079  0.94524926  0.07689573]
 [-0.16228631 -0.02579172  0.98640662]
 [ 0.93438333 -0.32532862  0.14522088]]
transform [[ 0.31716079  0.94524926  0.07689573]
 [-0.16228631 -0.02579172  0.98640662]
 [ 0.93438333 -0.32532862  0.14522088]]
support
[0.09366909 1.20157268 0.17689808]
[ 425.67465651 -213.92073612  447.95103131]
[-187.6764824    49.14341307   72.07473049]
[-0.75357814 -9.66678492 -1.42316458]
zmp_s [       0.         17012733.08124095 -3247564.30588094]
transform [[ 0.31716079 -0.16228631  0.93438333]
 [ 0.94524926 -0.02579172 -0.32532862]
 [ 0.07689573  0.98640662  0.14522088]]
zmp [-5795403.65776535   617738.0313012  16309858.47655375]
d1:33575437.92753, d2:0.05940, d3:12085302.50809
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-574.7865769565633 steps:238[00m
[RDDPG] Resetting Environment
transform [[ 0.99653155  0.08155757 -0.01652941]
 [ 0.00599931  0.12770446  0.99179411]
 [ 0.08299909 -0.98845333  0.12677224]]
planes
[[ 0.99653155  0.08155757 -0.01652941]
 [ 0.00599931  0.12770446  0.99179411]
 [ 0.08299909 -0.98845333  0.12677224]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  432.5816  -256.3853 -1325.9526]
[ -235.90208975 -1363.22247765   270.2595165 ]
[ 0.   0.  -9.8]
transform [[ 0.99653155  0.08155757 -0.01652941]
 [ 0.00599931  0.12770446  0.99179411]
 [ 0.08299909 -0.98845333  0.12677224]]
transform [[ 0.99653155  0.08155757 -0.01652941]
 [ 0.00599931  0.12770446  0.99179411]
 [ 0.08299909 -0.98845333  0.12677224]]
transform [[ 0.99653155  0.08155757 -0.01652941]
 [ 0.00599931  0.12770446  0.99179411]
 [ 0.08299909 -0.98845333  0.12677224]]
support
[-0.02013499  1.20813535  0.15442522]
[  432.08826217 -1345.21836973   121.23481089]
[-350.73221909   92.53696074 1362.16354163]
[ 0.16198819 -9.71958227 -1.24236795]
zmp_s [     0.         255647.44681409 837564.3115966 ]
transform [[ 0.99653155  0.00599931  0.08299909]
 [ 0.08155757  0.12770446 -0.98845333]
 [-0.01652941  0.99179411  0.12677224]]
zmp [  71050.78264061 -795245.9134843   359729.53558039]
d1:1447423.90164, d2:0.05940, d3:207298.22791
transform [[ 0.21629527  0.12183712 -0.96869606]
 [ 0.70046234  0.67180395  0.24089842]
 [ 0.68012422 -0.73064029  0.0599657 ]]
planes
[[ 0.21629527  0.12183712 -0.96869606]
 [ 0.70046234  0.67180395  0.24089842]
 [ 0.68012422 -0.73064029  0.0599657 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 125.10798 -414.81598 -260.11816]
[  23.34060017 -126.52880226  -24.10698791]
[ 0.   0.  -9.8]
transform [[ 0.21629527  0.12183712 -0.96869606]
 [ 0.70046234  0.67180395  0.24089842]
 [ 0.68012422 -0.73064029  0.0599657 ]]
transform [[ 0.21629527  0.12183712 -0.96869606]
 [ 0.70046234  0.67180395  0.24089842]
 [ 0.68012422 -0.73064029  0.0599657 ]]
transform [[ 0.21629527  0.12183712 -0.96869606]
 [ 0.70046234  0.67180395  0.24089842]
 [ 0.68012422 -0.73064029  0.0599657 ]]
support
[-1.17999889  0.29344588  0.07304609]
[ 228.49572154 -253.70363953  372.57206627]
[ 12.98490116 -74.46067305 106.87595611]
[ 9.49322137 -2.36080447 -0.5876639 ]
zmp_s [      0.         -541537.23775463  411899.72954796]
transform [[ 0.21629527  0.70046234  0.68012422]
 [ 0.12183712  0.67180395 -0.73064029]
 [-0.96869606  0.24089842  0.0599657 ]]
zmp [ -99183.45785501 -664757.39482054 -105755.60537026]
d1:799386.79180, d2:0.05940, d3:270182.40518
transform [[ 0.92127544 -0.3599413  -0.14728832]
 [ 0.0334302  -0.30402574  0.95207709]
 [-0.38747129 -0.88204908 -0.26805854]]
planes
[[ 0.92127544 -0.3599413  -0.14728832]
 [ 0.0334302  -0.30402574  0.95207709]
 [-0.38747129 -0.88204908 -0.26805854]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-823.18945  673.22296 1387.2008 ]
[-2421.21309242  3922.21021232   -84.88437144]
[ 0.   0.  -9.8]
transform [[ 0.92127544 -0.3599413  -0.14728832]
 [ 0.0334302  -0.30402574  0.95207709]
 [-0.38747129 -0.88204908 -0.26805854]]
transform [[ 0.92127544 -0.3599413  -0.14728832]
 [ 0.0334302  -0.30402574  0.95207709]
 [-0.38747129 -0.88204908 -0.26805854]]
transform [[ 0.92127544 -0.3599413  -0.14728832]
 [ 0.0334302  -0.30402574  0.95207709]
 [-0.38747129 -0.88204908 -0.26805854]]
support
[-0.1794165   1.15975481 -0.32653047]
[-1205.02345306  1088.52561363  -646.70443871]
[-3629.86713015 -1354.21095449 -2498.67738683]
[ 1.44342556 -9.33035549  2.62697368]
zmp_s [        0.          -7394663.07715737 -18852475.10536607]
transform [[ 0.92127544  0.0334302  -0.38747129]
 [-0.3599413  -0.30402574 -0.88204908]
 [-0.14728832  0.95207709 -0.26805854]]
zmp [ 7057587.78083505 18876976.30222709 -1986722.38684172]
d1:21888506.57858, d2:0.05940, d3:4514293.91002
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-432.51296399939815 steps:242[00m
[RDDPG] Resetting Environment
transform [[ 0.25006032 -0.24665415 -0.93628609]
 [ 0.71444803 -0.60564786  0.3503637 ]
 [-0.65347832 -0.75653982  0.02477311]]
planes
[[ 0.25006032 -0.24665415 -0.93628609]
 [ 0.71444803 -0.60564786  0.3503637 ]
 [-0.65347832 -0.75653982  0.02477311]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-823.18945  673.22296 1387.2008 ]
[-2421.21309242  3922.21021232   -84.88437144]
[ 0.   0.  -9.8]
transform [[ 0.25006032 -0.24665415 -0.93628609]
 [ 0.71444803 -0.60564786  0.3503637 ]
 [-0.65347832 -0.75653982  0.02477311]]
transform [[ 0.25006032 -0.24665415 -0.93628609]
 [ 0.71444803 -0.60564786  0.3503637 ]
 [-0.65347832 -0.75653982  0.02477311]]
transform [[ 0.25006032 -0.24665415 -0.93628609]
 [ 0.71444803 -0.60564786  0.3503637 ]
 [-0.65347832 -0.75653982  0.02477311]]
support
[-1.1405193   0.42678896  0.03017689]
[-1670.71707811  -509.83732512    62.98175792]
[-1493.40270135 -4135.04956745 -1387.20078925]
[ 9.1756037  -3.43356428 -0.24277644]
zmp_s [       0.         -2235443.55577825 -7106531.52420582]
transform [[ 0.25006032  0.71444803 -0.65347832]
 [-0.24665415 -0.60564786 -0.75653982]
 [-0.93628609  0.3503637   0.02477311]]
zmp [3046856.05757817 6730265.70177726 -959269.13747201]
d1:10133666.66810, d2:0.05940, d3:3718250.24813
transform [[ 0.37998056 -0.13810179 -0.91462708]
 [ 0.6843943   0.70716256  0.17755446]
 [ 0.62226945 -0.69343281  0.36322406]]
planes
[[ 0.37998056 -0.13810179 -0.91462708]
 [ 0.6843943   0.70716256  0.17755446]
 [ 0.62226945 -0.69343281  0.36322406]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1313.0446   838.93353 3057.8386 ]
[ 4305.38923265 -8499.60896485 -2546.65477469]
[ 0.   0.  -9.8]
transform [[ 0.37998056 -0.13810179 -0.91462708]
 [ 0.6843943   0.70716256  0.17755446]
 [ 0.62226945 -0.69343281  0.36322406]]
transform [[ 0.37998056 -0.13810179 -0.91462708]
 [ 0.6843943   0.70716256  0.17755446]
 [ 0.62226945 -0.69343281  0.36322406]]
transform [[ 0.37998056 -0.13810179 -0.91462708]
 [ 0.6843943   0.70716256  0.17755446]
 [ 0.62226945 -0.69343281  0.36322406]]
support
[-1.11413578  0.21628463  0.44245456]
[-2413.70880476  2034.8354739   1346.00403783]
[ 5139.01481901 -3516.19128552  7648.01362254]
[ 8.96334534 -1.74003369 -3.55959578]
zmp_s [        0.            104411.35315831 -10056218.717321  ]
transform [[ 0.37998056  0.6843943   0.62226945]
 [-0.13810179  0.70716256 -0.69343281]
 [-0.91462708  0.17755446  0.36322406]]
zmp [-6186219.1716248   7047147.7819248  -3634121.88289107]
d1:9134408.94499, d2:0.05940, d3:6474657.87480
transform [[ 0.39640844 -0.11419789 -0.91094416]
 [ 0.61718953 -0.7014122   0.35650805]
 [-0.67965984 -0.70354795 -0.20756397]]
planes
[[ 0.39640844 -0.11419789 -0.91094416]
 [ 0.61718953 -0.7014122   0.35650805]
 [-0.67965984 -0.70354795 -0.20756397]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-659.9347  -448.41547 1679.489  ]
[  34.50019439 -372.89683841   92.3763281 ]
[ 0.   0.  -9.8]
transform [[ 0.39640844 -0.11419789 -0.91094416]
 [ 0.61718953 -0.7014122   0.35650805]
 [-0.67965984 -0.70354795 -0.20756397]]
transform [[ 0.39640844 -0.11419789 -0.91094416]
 [ 0.61718953 -0.7014122   0.35650805]
 [-0.67965984 -0.70354795 -0.20756397]]
transform [[ 0.39640844 -0.11419789 -0.91094416]
 [ 0.61718953 -0.7014122   0.35650805]
 [-0.67965984 -0.70354795 -0.20756397]]
support
[-1.10964951  0.43427357 -0.25284014]
[-1740.3162939    505.970646     415.41149243]
[-27.88947479 315.78045506 219.72841413]
[ 8.92725281 -3.49377885  2.03412687]
zmp_s [        0.           -746614.13585576 -20904930.7027672 ]
transform [[ 0.39640844  0.61718953 -0.67965984]
 [-0.11419789 -0.7014122  -0.70354795]
 [-0.91094416  0.35650805 -0.20756397]]
zmp [13747439.50363739 15231305.50041067  4072936.389359  ]
d1:31308124.07347, d2:0.05940, d3:13421934.79742
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-674.7477794331417 steps:246[00m
[RDDPG] Resetting Environment
transform [[ 0.71108419  0.69808763  0.08386321]
 [-0.03777693 -0.08117009  0.99598408]
 [ 0.70209146 -0.71139657 -0.03134716]]
planes
[[ 0.71108419  0.69808763  0.08386321]
 [-0.03777693 -0.08117009  0.99598408]
 [ 0.70209146 -0.71139657 -0.03134716]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-371.63324  811.5178   805.9882 ]
[-159.3749362  -504.20978192   74.06241957]
[ 0.   0.  -9.8]
transform [[ 0.71108419  0.69808763  0.08386321]
 [-0.03777693 -0.08117009  0.99598408]
 [ 0.70209146 -0.71139657 -0.03134716]]
transform [[ 0.71108419  0.69808763  0.08386321]
 [-0.03777693 -0.08117009  0.99598408]
 [ 0.70209146 -0.71139657 -0.03134716]]
transform [[ 0.71108419  0.69808763  0.08386321]
 [-0.03777693 -0.08117009  0.99598408]
 [ 0.70209146 -0.71139657 -0.03134716]]
support
[ 0.10215639  1.21323928 -0.03818495]
[ 369.84079156  750.91962194 -863.49695961]
[-459.100498    120.71243933  244.47568482]
[-0.82185942 -9.76064396  0.30720212]
zmp_s [       0.         -9048166.65443926 -2836493.97210888]
transform [[ 0.71108419 -0.03777693  0.70209146]
 [ 0.69808763 -0.08117009 -0.71139657]
 [ 0.08386321  0.99598408 -0.03134716]]
zmp [-1649666.23746921  2752312.59423243 -8922913.90014838]
d1:18398058.13808, d2:0.05940, d3:7090792.71341
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-397.8612543456572 steps:248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-261.59041906253856 steps:249[00m
[RDDPG] Resetting Environment
transform [[ 0.37840533  0.33283326  0.86373115]
 [-0.63571101 -0.58480525  0.5038594 ]
 [ 0.67281568 -0.73974651 -0.00970767]]
planes
[[ 0.37840533  0.33283326  0.86373115]
 [-0.63571101 -0.58480525  0.5038594 ]
 [ 0.67281568 -0.73974651 -0.00970767]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 659.44244 -393.6642   294.97308]
[  24.24133136 -260.12014014  -76.96047864]
[ 0.   0.  -9.8]
transform [[ 0.37840533  0.33283326  0.86373115]
 [-0.63571101 -0.58480525  0.5038594 ]
 [ 0.67281568 -0.73974651 -0.00970767]]
transform [[ 0.37840533  0.33283326  0.86373115]
 [-0.63571101 -0.58480525  0.5038594 ]
 [ 0.67281568 -0.73974651 -0.00970767]]
transform [[ 0.37840533  0.33283326  0.86373115]
 [-0.63571101 -0.58480525  0.5038594 ]
 [ 0.67281568 -0.73974651 -0.00970767]]
support
[ 1.05213786  0.61376686 -0.01182522]
[373.28943251 -40.37296396 732.03144495]
[-143.87674766   97.93188163  209.48002087]
[-8.46456523 -4.93782213  0.09513516]
zmp_s [        0.          20377704.17024767 -15382645.85480871]
transform [[ 0.37840533 -0.63571101  0.67281568]
 [ 0.33283326 -0.58480525 -0.73974651]
 [ 0.86373115  0.5038594  -0.00970767]]
zmp [-23304016.32533088   -537729.7843537   10416827.45735925]
d1:34373120.22432, d2:0.05940, d3:14043108.89700
transform [[ 0.36371985  0.34218067 -0.86638349]
 [ 0.6442259   0.57938552  0.49928498]
 [ 0.67281568 -0.73974651 -0.00970767]]
planes
[[ 0.36371985  0.34218067 -0.86638349]
 [ 0.6442259   0.57938552  0.49928498]
 [ 0.67281568 -0.73974651 -0.00970767]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 659.44244 -393.6642   294.97308]
[  24.24133136 -260.12014014  -76.96047864]
[ 0.   0.  -9.8]
transform [[ 0.36371985  0.34218067 -0.86638349]
 [ 0.6442259   0.57938552  0.49928498]
 [ 0.67281568 -0.73974651 -0.00970767]]
transform [[ 0.36371985  0.34218067 -0.86638349]
 [ 0.6442259   0.57938552  0.49928498]
 [ 0.67281568 -0.73974651 -0.00970767]]
transform [[ 0.36371985  0.34218067 -0.86638349]
 [ 0.6442259   0.57938552  0.49928498]
 [ 0.67281568 -0.73974651 -0.00970767]]
support
[-1.05536876  0.60819462 -0.01182522]
[-150.41178773  344.02218416  732.03144495]
[ -13.51374192 -173.51816025  209.48002087]
[ 8.49055823 -4.89299283  0.09513516]
zmp_s [        0.          20377703.56235859 -15382648.23350062]
transform [[ 0.36371985  0.6442259   0.67281568]
 [ 0.34218067  0.57938552 -0.73974651]
 [-0.86638349  0.49928498 -0.00970767]]
zmp [ 2778157.38458037 23185806.71547335 10323611.03880155]
d1:34551033.92698, d2:0.05940, d3:12874196.98528
transform [[ 0.36398453  0.35035089 -0.86300033]
 [ 0.88441259 -0.42059839  0.20226584]
 [-0.2921125  -0.83686996 -0.462946  ]]
planes
[[ 0.36398453  0.35035089 -0.86300033]
 [ 0.88441259 -0.42059839  0.20226584]
 [-0.2921125  -0.83686996 -0.462946  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-153.0008  -535.19073 1070.8353 ]
[  99.73590608 -640.31956392   -6.47835475]
[ 0.   0.  -9.8]
transform [[ 0.36398453  0.35035089 -0.86300033]
 [ 0.88441259 -0.42059839  0.20226584]
 [-0.2921125  -0.83686996 -0.462946  ]]
transform [[ 0.36398453  0.35035089 -0.86300033]
 [ 0.88441259 -0.42059839  0.20226584]
 [-0.2921125  -0.83686996 -0.462946  ]]
transform [[ 0.36398453  0.35035089 -0.86300033]
 [ 0.88441259 -0.42059839  0.20226584]
 [-0.2921125  -0.83686996 -0.462946  ]]
support
[-1.05124763  0.24638633 -0.56392896]
[-1167.32571386   306.37794366    -3.16043848]
[-182.44337818  356.214717    509.72922827]
[ 8.45740327 -1.98220527  4.53687078]
zmp_s [        0.        -18442845.5898902 -16924178.8725591]
transform [[ 0.36398453  0.88441259 -0.2921125 ]
 [ 0.35035089 -0.42059839 -0.83686996]
 [-0.86300033  0.20226584 -0.462946  ]]
zmp [-11367320.58202719  21920367.93259799   4104623.14929142]
d1:27919573.04345, d2:0.05940, d3:5316444.12673
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-638.5696975990111 steps:253[00m
[RDDPG] Resetting Environment
transform [[ 0.1254531  -0.20292002 -0.97112566]
 [ 0.62204504 -0.74646258  0.23633367]
 [-0.77286577 -0.63373268  0.03257935]]
planes
[[ 0.1254531  -0.20292002 -0.97112566]
 [ 0.62204504 -0.74646258  0.23633367]
 [-0.77286577 -0.63373268  0.03257935]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-153.0008  -535.19073 1070.8353 ]
[  99.73590608 -640.31956392   -6.47835475]
[ 0.   0.  -9.8]
transform [[ 0.1254531  -0.20292002 -0.97112566]
 [ 0.62204504 -0.74646258  0.23633367]
 [-0.77286577 -0.63373268  0.03257935]]
transform [[ 0.1254531  -0.20292002 -0.97112566]
 [ 0.62204504 -0.74646258  0.23633367]
 [-0.77286577 -0.63373268  0.03257935]]
transform [[ 0.1254531  -0.20292002 -0.97112566]
 [ 0.62204504 -0.74646258  0.23633367]
 [-0.77286577 -0.63373268  0.03257935]]
support
[-1.18295847  0.28788541  0.03968593]
[-950.50917568  557.40091487  492.30405744]
[148.73713359 538.48376833 328.49790237]
[ 9.51703149 -2.31606995 -0.31927768]
zmp_s [        0.          -2458698.56083632 -15727719.15105869]
transform [[ 0.1254531   0.62204504 -0.77286577]
 [-0.20292002 -0.74646258 -0.63373268]
 [-0.97112566  0.23633367  0.03257935]]
zmp [10625994.56242733 11802496.03280832 -1093472.19460709]
d1:22102877.63622, d2:0.05940, d3:7839828.36812
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-148.5825282436146 steps:255[00m
[RDDPG] Resetting Environment
transform [[ 0.24042383  0.24014398 -0.94049311]
 [ 0.67560011  0.65430588  0.33977705]
 [ 0.69696552 -0.71708775 -0.0049306 ]]
planes
[[ 0.24042383  0.24014398 -0.94049311]
 [ 0.67560011  0.65430588  0.33977705]
 [ 0.69696552 -0.71708775 -0.0049306 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  97.82083 -241.2957  -119.26269]
[-124.19113855 -124.19866035   68.20877959]
[ 0.   0.  -9.8]
transform [[ 0.24042383  0.24014398 -0.94049311]
 [ 0.67560011  0.65430588  0.33977705]
 [ 0.69696552 -0.71708775 -0.0049306 ]]
transform [[ 0.24042383  0.24014398 -0.94049311]
 [ 0.67560011  0.65430588  0.33977705]
 [ 0.69696552 -0.71708775 -0.0049306 ]]
transform [[ 0.24042383  0.24014398 -0.94049311]
 [ 0.67560011  0.65430588  0.33977705]
 [ 0.69696552 -0.71708775 -0.0049306 ]]
support
[-1.145644    0.41389303 -0.00600612]
[  77.73848355 -132.31615419  241.79597229]
[-123.83395718 -141.99168214    2.16808628]
[ 9.21683245 -3.32981511  0.04831988]
zmp_s [       0.          2358995.85181202 -5104869.95261312]
transform [[ 0.24042383  0.67560011  0.69696552]
 [ 0.24014398  0.65430588 -0.71708775]
 [-0.94049311  0.33977705 -0.0049306 ]]
zmp [-1964180.45818741  5204144.53189216   826702.72686717]
d1:6860136.75772, d2:0.05940, d3:2899158.53588
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-290.4055031038686 steps:257[00m
[RDDPG] Resetting Environment
transform [[ 0.07791448  0.09946624 -0.9919858 ]
 [ 0.70962399  0.69335705  0.12525946]
 [ 0.70025939 -0.71369642 -0.01656107]]
planes
[[ 0.07791448  0.09946624 -0.9919858 ]
 [ 0.70962399  0.69335705  0.12525946]
 [ 0.70025939 -0.71369642 -0.01656107]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  20.778011 -309.86548   114.67709 ]
[ 188.77011812 -899.7291516  -330.25140956]
[ 0.   0.  -9.8]
transform [[ 0.07791448  0.09946624 -0.9919858 ]
 [ 0.70962399  0.69335705  0.12525946]
 [ 0.70025939 -0.71369642 -0.01656107]]
transform [[ 0.07791448  0.09946624 -0.9919858 ]
 [ 0.70962399  0.69335705  0.12525946]
 [ 0.70025939 -0.71369642 -0.01656107]]
transform [[ 0.07791448  0.09946624 -0.9919858 ]
 [ 0.70962399  0.69335705  0.12525946]
 [ 0.70025939 -0.71369642 -0.01656107]]
support
[-1.20836885  0.15258246 -0.02017356]
[-142.96029487 -185.73844817  233.80070439]
[ 252.81995549 -531.24485876  779.79084003]
[ 9.72146082 -1.2275427   0.16229853]
zmp_s [       0.         10786854.70079261 -4191084.15486713]
transform [[ 0.07791448  0.70962399  0.70025939]
 [ 0.09946624  0.69335705 -0.71369642]
 [-0.9919858   0.12525946 -0.01656107]]
zmp [ 4719764.87546047 10470303.5166934   1420564.43992808]
d1:15745856.79909, d2:0.05940, d3:2731522.52852
transform [[ 0.06541276  0.11213013 -0.99153823]
 [ 0.62369663 -0.78024679 -0.04708993]
 [-0.77892476 -0.61533874 -0.12097327]]
planes
[[ 0.06541276  0.11213013 -0.99153823]
 [ 0.62369663 -0.78024679 -0.04708993]
 [-0.77892476 -0.61533874 -0.12097327]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -27.245901   910.10266  -1110.0923  ]
[-68.11261376 343.97290997  12.84976757]
[ 0.   0.  -9.8]
transform [[ 0.06541276  0.11213013 -0.99153823]
 [ 0.62369663 -0.78024679 -0.04708993]
 [-0.77892476 -0.61533874 -0.12097327]]
transform [[ 0.06541276  0.11213013 -0.99153823]
 [ 0.62369663 -0.78024679 -0.04708993]
 [-0.77892476 -0.61533874 -0.12097327]]
transform [[ 0.06541276  0.11213013 -0.99153823]
 [ 0.62369663 -0.78024679 -0.04708993]
 [-0.77892476 -0.61533874 -0.12097327]]
support
[-1.20782365 -0.05736171 -0.14736131]
[1200.96663395 -674.82369578 -404.50743016]
[  21.37325658 -311.47046226 -160.15973477]
[9.71707462 0.46148128 1.18553801]
zmp_s [        0.         -34378168.59784218   7508263.69300135]
transform [[ 0.06541276  0.62369663 -0.77892476]
 [ 0.11213013 -0.78024679 -0.61533874]
 [-0.99153823 -0.04708993 -0.12097327]]
zmp [-27289920.25528909  22203330.29879187    710566.26028018]
d1:42609307.82867, d2:0.05940, d3:1851153.54968
transform [[-0.2610448  -0.63723624 -0.72511071]
 [ 0.69243073  0.39977008 -0.60060269]
 [ 0.67260343 -0.65887314  0.33688411]]
planes
[[-0.2610448  -0.63723624 -0.72511071]
 [ 0.69243073  0.39977008 -0.60060269]
 [ 0.67260343 -0.65887314  0.33688411]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 96.94107 161.2457  958.05096]
[-13.84589021  -7.69285942  61.78623756]
[ 0.   0.  -9.8]
transform [[-0.2610448  -0.63723624 -0.72511071]
 [ 0.69243073  0.39977008 -0.60060269]
 [ 0.67260343 -0.65887314  0.33688411]]
transform [[-0.2610448  -0.63723624 -0.72511071]
 [ 0.69243073  0.39977008 -0.60060269]
 [ 0.67260343 -0.65887314  0.33688411]]
transform [[-0.2610448  -0.63723624 -0.72511071]
 [ 0.69243073  0.39977008 -0.60060269]
 [ 0.67260343 -0.65887314  0.33688411]]
support
[-0.88327998 -0.73161287  0.41036905]
[-822.75057835 -443.82180084  281.71458515]
[-36.28529613 -49.77167522  16.57062694]
[ 7.10608495  5.88590633 -3.30146429]
zmp_s [       0.         37319635.76295386  6998690.16989043]
transform [[-0.2610448   0.69243073  0.67260343]
 [-0.63723624  0.39977008 -0.65887314]
 [-0.72511071 -0.60060269  0.33688411]]
zmp [ 30548605.80995468  10308024.83965517 -20056525.97768323]
d1:58194687.98138, d2:0.05940, d3:19653843.00367
transform [[ 0.84831518  0.20613964  0.48771691]
 [-0.36604327 -0.43723646  0.82148439]
 [ 0.38258812 -0.87540317 -0.29545832]]
planes
[[ 0.84831518  0.20613964  0.48771691]
 [-0.36604327 -0.43723646  0.82148439]
 [ 0.38258812 -0.87540317 -0.29545832]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 96.94107 161.2457  958.05096]
[-13.84589021  -7.69285942  61.78623756]
[ 0.   0.  -9.8]
transform [[ 0.84831518  0.20613964  0.48771691]
 [-0.36604327 -0.43723646  0.82148439]
 [ 0.38258812 -0.87540317 -0.29545832]]
transform [[ 0.84831518  0.20613964  0.48771691]
 [-0.36604327 -0.43723646  0.82148439]
 [ 0.38258812 -0.87540317 -0.29545832]]
transform [[ 0.84831518  0.20613964  0.48771691]
 [-0.36604327 -0.43723646  0.82148439]
 [ 0.38258812 -0.87540317 -0.29545832]]
support
[ 0.59410319  1.00067576 -0.35990699]
[ 582.73337048  681.03678522 -387.13061722]
[ 16.80271096  59.18822301 -16.81817735]
[-4.77962575 -8.05054699  2.8954915 ]
zmp_s [        0.           -652902.41201584 -15888309.86252543]
transform [[ 0.84831518 -0.36604327  0.38258812]
 [ 0.20613964 -0.43723646 -0.87540317]
 [ 0.48771691  0.82148439 -0.29545832]]
zmp [-5839688.03985881 14194149.49123105  4157984.1511719 ]
d1:26303679.79970, d2:0.05940, d3:6551678.84583
transform [[ 0.01343142  0.11094452 -0.99373585]
 [ 0.776366    0.62514788  0.08028735]
 [ 0.63013929 -0.7725811  -0.07773696]]
planes
[[ 0.01343142  0.11094452 -0.99373585]
 [ 0.776366    0.62514788  0.08028735]
 [ 0.63013929 -0.7725811  -0.07773696]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-412.85477 -444.5706   337.38693]
[  38.65758561 -114.09357629  150.86972882]
[ 0.   0.  -9.8]
transform [[ 0.01343142  0.11094452 -0.99373585]
 [ 0.776366    0.62514788  0.08028735]
 [ 0.63013929 -0.7725811  -0.07773696]]
transform [[ 0.01343142  0.11094452 -0.99373585]
 [ 0.776366    0.62514788  0.08028735]
 [ 0.63013929 -0.7725811  -0.07773696]]
transform [[ 0.01343142  0.11094452 -0.99373585]
 [ 0.776366    0.62514788  0.08028735]
 [ 0.63013929 -0.7725811  -0.07773696]]
support
[-1.21050064  0.09780053 -0.09469381]
[-390.14138756 -571.36085823   57.08338919]
[-162.06348953  -29.19999125  100.77805043]
[ 9.73861133 -0.78681605  0.7618222 ]
zmp_s [       0.         -4330521.81661223 -5020952.70200553]
transform [[ 0.01343142  0.776366    0.63013929]
 [ 0.11094452  0.62514788 -0.7725811 ]
 [-0.99373585  0.08028735 -0.07773696]]
zmp [-6525969.45801098  1171876.63473847    42627.46332174]
d1:8235107.54847, d2:0.05940, d3:3868157.53455
transform [[-0.66205335 -0.48226669 -0.57367599]
 [ 0.40572128  0.41296178 -0.8153851 ]
 [ 0.63013929 -0.7725811  -0.07773696]]
planes
[[-0.66205335 -0.48226669 -0.57367599]
 [ 0.40572128  0.41296178 -0.8153851 ]
 [ 0.63013929 -0.7725811  -0.07773696]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-412.85477 -444.5706   337.38693]
[  38.65758561 -114.09357629  150.86972882]
[ 0.   0.  -9.8]
transform [[-0.66205335 -0.48226669 -0.57367599]
 [ 0.40572128  0.41296178 -0.8153851 ]
 [ 0.63013929 -0.7725811  -0.07773696]]
transform [[-0.66205335 -0.48226669 -0.57367599]
 [ 0.40572128  0.41296178 -0.8153851 ]
 [ 0.63013929 -0.7725811  -0.07773696]]
transform [[-0.66205335 -0.48226669 -0.57367599]
 [ 0.40572128  0.41296178 -0.8153851 ]
 [ 0.63013929 -0.7725811  -0.07773696]]
support
[-0.69881262 -0.99324603 -0.09469381]
[ 294.18268504 -626.19490336   57.08338919]
[ -57.12019311 -154.44901088  100.77805043]
[5.6220247  7.99077401 0.7618222 ]
zmp_s [       0.         -4330526.77035921 -5020952.97502822]
transform [[-0.66205335  0.40572128  0.63013929]
 [-0.48226669  0.41296178 -0.7725811 ]
 [-0.57367599 -0.8153851  -0.07773696]]
zmp [-4920886.60061338  2090751.32696094  3921360.63253558]
d1:9950276.67338, d2:0.05940, d3:4919496.31364
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-1126.7866463750906 steps:264[00m
[RDDPG] Resetting Environment
transform [[ 0.71659547 -0.6839208   0.13690655]
 [-0.08807626  0.10598499  0.99045944]
 [-0.6919058  -0.7218169   0.01571117]]
planes
[[ 0.71659547 -0.6839208   0.13690655]
 [-0.08807626  0.10598499  0.99045944]
 [-0.6919058  -0.7218169   0.01571117]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-412.85477 -444.5706   337.38693]
[  38.65758561 -114.09357629  150.86972882]
[ 0.   0.  -9.8]
transform [[ 0.71659547 -0.6839208   0.13690655]
 [-0.08807626  0.10598499  0.99045944]
 [-0.6919058  -0.7218169   0.01571117]]
transform [[ 0.71659547 -0.6839208   0.13690655]
 [-0.08807626  0.10598499  0.99045944]
 [-0.6919058  -0.7218169   0.01571117]]
transform [[ 0.71659547 -0.6839208   0.13690655]
 [-0.08807626  0.10598499  0.99045944]
 [-0.6919058  -0.7218169   0.01571117]]
support
[0.16677014 1.20650955 0.01913826]
[ 54.39169657 323.41297074 611.85591092]
[126.38787479 133.93332568  57.97760332]
[-1.34168418 -9.70650253 -0.15396944]
zmp_s [        0.           1134295.25244359 -10780925.37917087]
transform [[ 0.71659547 -0.08807626 -0.6919058 ]
 [-0.6839208   0.10598499 -0.7218169 ]
 [ 0.13690655  0.99045944  0.01571117]]
zmp [7359480.27405319 7902072.37446619  954092.51499063]
d1:15791562.74208, d2:0.05940, d3:5465636.67147
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-524.0088202564625 steps:266[00m
[RDDPG] Resetting Environment
transform [[ 0.09170717  0.08369981 -0.99226213]
 [ 0.6994316   0.70385772  0.12401527]
 [ 0.70879138 -0.7053926   0.0060065 ]]
planes
[[ 0.09170717  0.08369981 -0.99226213]
 [ 0.6994316   0.70385772  0.12401527]
 [ 0.70879138 -0.7053926   0.0060065 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 182.5137  549.7535 -593.4791]
[  27.75103912 -186.58378734  -10.73633736]
[ 0.   0.  -9.8]
transform [[ 0.09170717  0.08369981 -0.99226213]
 [ 0.6994316   0.70385772  0.12401527]
 [ 0.70879138 -0.7053926   0.0060065 ]]
transform [[ 0.09170717  0.08369981 -0.99226213]
 [ 0.6994316   0.70385772  0.12401527]
 [ 0.70879138 -0.7053926   0.0060065 ]]
transform [[ 0.09170717  0.08369981 -0.99226213]
 [ 0.6994316   0.70385772  0.12401527]
 [ 0.70879138 -0.7053926   0.0060065 ]]
support
[-1.20870545  0.15106687  0.00731671]
[ 651.6389383   441.00360576 -261.9926312 ]
[  -2.41879829 -113.24995528  151.22003205]
[ 9.72416883 -1.21534966 -0.05886372]
zmp_s [       0.         12222576.72617369  3826072.85715491]
transform [[ 0.09170717  0.6994316   0.70879138]
 [ 0.08369981  0.70385772 -0.7053926 ]
 [-0.99226213  0.12401527  0.0060065 ]]
zmp [11260743.81543071  5904071.50868892  1538767.48948553]
d1:18092546.00901, d2:0.05940, d3:3614912.02871
transform [[ 0.68059832  0.68158931 -0.2687414 ]
 [ 0.18547422  0.1945696   0.96319366]
 [ 0.70879138 -0.7053926   0.0060065 ]]
planes
[[ 0.68059832  0.68158931 -0.2687414 ]
 [ 0.18547422  0.1945696   0.96319366]
 [ 0.70879138 -0.7053926   0.0060065 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 182.5137  549.7535 -593.4791]
[  27.75103912 -186.58378734  -10.73633736]
[ 0.   0.  -9.8]
transform [[ 0.68059832  0.68158931 -0.2687414 ]
 [ 0.18547422  0.1945696   0.96319366]
 [ 0.70879138 -0.7053926   0.0060065 ]]
transform [[ 0.68059832  0.68158931 -0.2687414 ]
 [ 0.18547422  0.1945696   0.96319366]
 [ 0.70879138 -0.7053926   0.0060065 ]]
transform [[ 0.68059832  0.68158931 -0.2687414 ]
 [ 0.18547422  0.1945696   0.96319366]
 [ 0.70879138 -0.7053926   0.0060065 ]]
support
[-0.32736228  1.17329624  0.00731671]
[ 658.41702148 -430.81842655 -261.9926312 ]
[-105.40090513  -41.49760313  151.22003205]
[ 2.63366571 -9.43929782 -0.05886372]
zmp_s [       0.         12222576.72651688  3826073.31476963]
transform [[ 0.68059832  0.18547422  0.70879138]
 [ 0.68158931  0.1945696  -0.7053926 ]
 [-0.2687414   0.96319366  0.0060065 ]]
zmp [ 4978860.61355495  -320741.90334233 11795689.67001107]
d1:23943697.87850, d2:0.05940, d3:9389185.39086
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-269.99744879148056 steps:269[00m
[RDDPG] Resetting Environment
transform [[ 0.04102892 -0.01143521 -0.99909252]
 [ 0.72402376 -0.68874866  0.03761604]
 [-0.68855375 -0.72491008 -0.01997925]]
planes
[[ 0.04102892 -0.01143521 -0.99909252]
 [ 0.72402376 -0.68874866  0.03761604]
 [-0.68855375 -0.72491008 -0.01997925]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 182.5137  549.7535 -593.4791]
[  27.75103912 -186.58378734  -10.73633736]
[ 0.   0.  -9.8]
transform [[ 0.04102892 -0.01143521 -0.99909252]
 [ 0.72402376 -0.68874866  0.03761604]
 [-0.68855375 -0.72491008 -0.01997925]]
transform [[ 0.04102892 -0.01143521 -0.99909252]
 [ 0.72402376 -0.68874866  0.03761604]
 [-0.68855375 -0.72491008 -0.01997925]]
transform [[ 0.04102892 -0.01143521 -0.99909252]
 [ 0.72402376 -0.68874866  0.03761604]
 [-0.68855375 -0.72491008 -0.01997925]]
support
[-1.21702577  0.04582127 -0.02433735]
[ 594.14234742 -268.82204645 -512.33506534]
[ 13.99881479 148.19788629 116.36289019]
[ 9.79110669 -0.36863716  0.19579665]
zmp_s [        0.          -3705273.68931749 -12088569.81099488]
transform [[ 0.04102892  0.72402376 -0.68855375]
 [-0.01143521 -0.68874866 -0.72491008]
 [-0.99909252  0.03761604 -0.01997925]]
zmp [ 5640923.89570656 11315128.39394807   102142.8430293 ]
d1:17034162.95821, d2:0.05940, d3:5508255.68235
transform [[ 0.68391752 -0.65828538  0.31451094]
 [-0.2411442   0.20289353  0.94904357]
 [-0.68855375 -0.72491008 -0.01997925]]
planes
[[ 0.68391752 -0.65828538  0.31451094]
 [-0.2411442   0.20289353  0.94904357]
 [-0.68855375 -0.72491008 -0.01997925]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 182.5137  549.7535 -593.4791]
[  27.75103912 -186.58378734  -10.73633736]
[ 0.   0.  -9.8]
transform [[ 0.68391752 -0.65828538  0.31451094]
 [-0.2411442   0.20289353  0.94904357]
 [-0.68855375 -0.72491008 -0.01997925]]
transform [[ 0.68391752 -0.65828538  0.31451094]
 [-0.2411442   0.20289353  0.94904357]
 [-0.68855375 -0.72491008 -0.01997925]]
transform [[ 0.68391752 -0.65828538  0.31451094]
 [-0.2411442   0.20289353  0.94904357]
 [-0.68855375 -0.72491008 -0.01997925]]
support
[ 0.38311559  1.15605959 -0.02433735]
[-423.72603703 -495.70824804 -512.33506534]
[138.42810559 -54.73789634 116.36289019]
[-3.08220723 -9.30062701  0.19579665]
zmp_s [        0.          -3705272.02461613 -12088569.35579918]
transform [[ 0.68391752 -0.2411442  -0.68855375]
 [-0.65828538  0.20289353 -0.72491008]
 [ 0.31451094  0.94904357 -0.01997925]]
zmp [ 9217134.6086655   8011350.08053136 -3274944.05177834]
d1:18410570.51629, d2:0.05940, d3:7560039.99312
transform [[ 0.38708413  0.16018432 -0.9080236 ]
 [ 0.41061538  0.85180342  0.32530898]
 [ 0.82556701 -0.49877042  0.26394546]]
planes
[[ 0.38708413  0.16018432 -0.9080236 ]
 [ 0.41061538  0.85180342  0.32530898]
 [ 0.82556701 -0.49877042  0.26394546]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 586.42676  825.55225 1138.828  ]
[ -50.35834375 -194.65483209   79.24986806]
[ 0.   0.  -9.8]
transform [[ 0.38708413  0.16018432 -0.9080236 ]
 [ 0.41061538  0.85180342  0.32530898]
 [ 0.82556701 -0.49877042  0.26394546]]
transform [[ 0.38708413  0.16018432 -0.9080236 ]
 [ 0.41061538  0.85180342  0.32530898]
 [ 0.82556701 -0.49877042  0.26394546]]
transform [[ 0.38708413  0.16018432 -0.9080236 ]
 [ 0.41061538  0.85180342  0.32530898]
 [ 0.82556701 -0.49877042  0.26394546]]
support
[-1.10609187  0.39626902  0.3215202 ]
[-674.84568065 1314.47505131  372.96202773]
[-122.63431831 -160.70486914   76.43152731]
[ 8.89863124 -3.18802799 -2.58666551]
zmp_s [       0.         26134066.33308337 25953595.9476702 ]
transform [[ 0.38708413  0.41061538  0.82556701]
 [ 0.16018432  0.85180342 -0.49877042]
 [-0.9080236   0.32530898  0.26394546]]
zmp [32157482.22705212  9316201.29073909 15351980.25372618]
d1:39934121.05235, d2:0.05940, d3:16995345.47743
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-482.4135534012354 steps:273[00m
[RDDPG] Resetting Environment
transform [[ 0.15812694 -0.15045719  0.97588861]
 [-0.72090298  0.65778208  0.2182239 ]
 [-0.67475533 -0.73802805 -0.00445199]]
planes
[[ 0.15812694 -0.15045719  0.97588861]
 [-0.72090298  0.65778208  0.2182239 ]
 [-0.67475533 -0.73802805 -0.00445199]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 586.42676  825.55225 1138.828  ]
[ -50.35834375 -194.65483209   79.24986806]
[ 0.   0.  -9.8]
transform [[ 0.15812694 -0.15045719  0.97588861]
 [-0.72090298  0.65778208  0.2182239 ]
 [-0.67475533 -0.73802805 -0.00445199]]
transform [[ 0.15812694 -0.15045719  0.97588861]
 [-0.72090298  0.65778208  0.2182239 ]
 [-0.67475533 -0.73802805 -0.00445199]]
transform [[ 0.15812694 -0.15045719  0.97588861]
 [-0.72090298  0.65778208  0.2182239 ]
 [-0.67475533 -0.73802805 -0.00445199]]
support
[ 1.18876036  0.26582534 -0.00542311]
[ 1079.88887281   368.79616264 -1010.04535093]
[ 98.66325177 -74.44276461 177.28746734]
[-9.56370838 -2.13859422  0.04362953]
zmp_s [        0.         -10035337.30704305   -623505.51571273]
transform [[ 0.15812694 -0.72090298 -0.67475533]
 [-0.15045719  0.65778208 -0.73802805]
 [ 0.97588861  0.2182239  -0.00445199]]
zmp [ 7655218.23670784 -6140900.4655487  -2187174.59912115]
d1:14106305.44681, d2:0.05940, d3:2107702.54495
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-356.2080935708765 steps:275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-149.46218712891186 steps:276[00m
[RDDPG] Resetting Environment
transform [[ 0.12010809  0.16548112 -0.97887182]
 [ 0.68885416  0.69612718  0.20220508]
 [ 0.71488047 -0.6985864  -0.03038185]]
planes
[[ 0.12010809  0.16548112 -0.97887182]
 [ 0.68885416  0.69612718  0.20220508]
 [ 0.71488047 -0.6985864  -0.03038185]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-144.0941 -438.2052  519.6721]
[  33.5681817  -221.39072702  -29.31379566]
[ 0.   0.  -9.8]
transform [[ 0.12010809  0.16548112 -0.97887182]
 [ 0.68885416  0.69612718  0.20220508]
 [ 0.71488047 -0.6985864  -0.03038185]]
transform [[ 0.12010809  0.16548112 -0.97887182]
 [ 0.68885416  0.69612718  0.20220508]
 [ 0.71488047 -0.6985864  -0.03038185]]
transform [[ 0.12010809  0.16548112 -0.97887182]
 [ 0.68885416  0.69612718  0.20220508]
 [ 0.71488047 -0.6985864  -0.03038185]]
support
[-1.19239431  0.24631231 -0.03700908]
[-598.51394906 -299.22602845  187.32553622]
[  -3.90972676 -136.91991843  179.5483967 ]
[ 9.59294386 -1.98160975  0.29774214]
zmp_s [       0.         -7774055.33895266 -8812219.18439898]
transform [[ 0.12010809  0.68885416  0.71488047]
 [ 0.16548112  0.69612718 -0.6985864 ]
 [-0.97887182  0.20220508 -0.03038185]]
zmp [-11654873.7052752     744365.32275372  -1304221.92762361]
d1:12818076.74300, d2:0.05940, d3:4742731.42725
transform [[ 0.06722052  0.14474078 -0.98718363]
 [ 0.98206466  0.16508764  0.0910771 ]
 [ 0.17615439 -0.97560042 -0.13104753]]
planes
[[ 0.06722052  0.14474078 -0.98718363]
 [ 0.98206466  0.16508764  0.0910771 ]
 [ 0.17615439 -0.97560042 -0.13104753]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-144.0941 -438.2052  519.6721]
[  33.5681817  -221.39072702  -29.31379566]
[ 0.   0.  -9.8]
transform [[ 0.06722052  0.14474078 -0.98718363]
 [ 0.98206466  0.16508764  0.0910771 ]
 [ 0.17615439 -0.97560042 -0.13104753]]
transform [[ 0.06722052  0.14474078 -0.98718363]
 [ 0.98206466  0.16508764  0.0910771 ]
 [ 0.17615439 -0.97560042 -0.13104753]]
transform [[ 0.06722052  0.14474078 -0.98718363]
 [ 0.98206466  0.16508764  0.0910771 ]
 [ 0.17615439 -0.97560042 -0.13104753]]
support
[-1.20251918  0.11094385 -0.15963309]
[-586.12405058 -166.52175947  334.02862089]
[ -0.84969547  -6.25256302 225.74356973]
[ 9.67439958 -0.89255555  1.28426581]
zmp_s [        0.         -36867579.14820655   6755058.65172461]
transform [[ 0.06722052  0.98206466  0.17615439]
 [ 0.14474078  0.16508764 -0.97560042]
 [-0.98718363  0.0910771  -0.13104753]]
zmp [-35016413.50603507 -12676619.71201401  -4243025.83796796]
d1:32654977.65892, d2:0.05940, d3:18718719.56844
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-222.94838651211478 steps:279[00m
[RDDPG] Resetting Environment
transform [[ 0.04526069  0.08338121  0.99548936]
 [-0.71006173 -0.69826448  0.09076945]
 [ 0.70268333 -0.71096724  0.02760188]]
planes
[[ 0.04526069  0.08338121  0.99548936]
 [-0.71006173 -0.69826448  0.09076945]
 [ 0.70268333 -0.71096724  0.02760188]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.04526069  0.08338121  0.99548936]
 [-0.71006173 -0.69826448  0.09076945]
 [ 0.70268333 -0.71096724  0.02760188]]
transform [[ 0.04526069  0.08338121  0.99548936]
 [-0.71006173 -0.69826448  0.09076945]
 [ 0.70268333 -0.71096724  0.02760188]]
transform [[ 0.04526069  0.08338121  0.99548936]
 [-0.71006173 -0.69826448  0.09076945]
 [ 0.70268333 -0.71096724  0.02760188]]
support
[1.21263665 0.1105691  0.03362271]
[6.88376947e+02 3.69296712e+02 5.46765098e-01]
[-52.48512157  99.56400605 202.08714523]
[-9.75579572 -0.88954058 -0.27049842]
zmp_s [        0.         -29365902.84553311  -6296257.8201558 ]
transform [[ 0.04526069 -0.71006173  0.70268333]
 [ 0.08338121 -0.69826448 -0.71096724]
 [ 0.99548936  0.09076945  0.02760188]]
zmp [16427328.33782855 24981599.93134736 -2839315.32035963]
d1:40730794.30645, d2:0.05940, d3:6217582.17323
transform [[ 0.09870747  0.05899191 -0.99336642]
 [ 0.70462263  0.70074648  0.1116304 ]
 [ 0.70268333 -0.71096724  0.02760188]]
planes
[[ 0.09870747  0.05899191 -0.99336642]
 [ 0.70462263  0.70074648  0.1116304 ]
 [ 0.70268333 -0.71096724  0.02760188]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.09870747  0.05899191 -0.99336642]
 [ 0.70462263  0.70074648  0.1116304 ]
 [ 0.70268333 -0.71096724  0.02760188]]
transform [[ 0.09870747  0.05899191 -0.99336642]
 [ 0.70462263  0.70074648  0.1116304 ]
 [ 0.70268333 -0.71096724  0.02760188]]
transform [[ 0.09870747  0.05899191 -0.99336642]
 [ 0.70462263  0.70074648  0.1116304 ]
 [ 0.70268333 -0.71096724  0.02760188]]
support
[-1.21005063  0.13598047  0.03362271]
[-7.48658695e+02 -2.23053935e+02  5.46765098e-01]
[  31.35220402 -108.09586997  202.08714523]
[ 9.73499092 -1.09397787 -0.27049842]
zmp_s [        0.         -29365901.22346968  -6296257.82054143]
transform [[ 0.09870747  0.70462263  0.70268333]
 [ 0.05899191  0.70074648 -0.71096724]
 [-0.99336642  0.1116304   0.02760188]]
zmp [-25116153.85312956 -16101618.75389493  -3451915.70179916]
d1:39024103.94745, d2:0.05940, d3:3341518.12493
transform [[ 0.15026119  0.12238564 -0.98104197]
 [ 0.89009637  0.41513774  0.18812022]
 [ 0.43029076 -0.90148902 -0.04655591]]
planes
[[ 0.15026119  0.12238564 -0.98104197]
 [ 0.89009637  0.41513774  0.18812022]
 [ 0.43029076 -0.90148902 -0.04655591]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.15026119  0.12238564 -0.98104197]
 [ 0.89009637  0.41513774  0.18812022]
 [ 0.43029076 -0.90148902 -0.04655591]]
transform [[ 0.15026119  0.12238564 -0.98104197]
 [ 0.89009637  0.41513774  0.18812022]
 [ 0.43029076 -0.90148902 -0.04655591]]
transform [[ 0.15026119  0.12238564 -0.98104197]
 [ 0.89009637  0.41513774  0.18812022]
 [ 0.43029076 -0.90148902 -0.04655591]]
support
[-1.19503783  0.2291551  -0.0567112 ]
[-764.42546671 -153.49132065   48.34564198]
[ 20.64912685 -36.04800523 227.55448195]
[ 9.61421129 -1.84357812  0.45624788]
zmp_s [       0.         -3829059.9734424  -2514579.58621805]
transform [[ 0.15026119  0.89009637  0.43029076]
 [ 0.12238564  0.41513774 -0.90148902]
 [-0.98104197  0.18812022 -0.04655591]]
zmp [-4490232.72684818   677278.58936695  -603255.05759459]
d1:3714625.62330, d2:0.05940, d3:2500472.67416
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-211.99013710875175 steps:283[00m
[RDDPG] Resetting Environment
transform [[ 0.7223261  -0.68569267 -0.08983696]
 [-0.03947277 -0.17057428  0.98455393]
 [-0.69042522 -0.70762289 -0.15027644]]
planes
[[ 0.7223261  -0.68569267 -0.08983696]
 [-0.03947277 -0.17057428  0.98455393]
 [-0.69042522 -0.70762289 -0.15027644]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.7223261  -0.68569267 -0.08983696]
 [-0.03947277 -0.17057428  0.98455393]
 [-0.69042522 -0.70762289 -0.15027644]]
transform [[ 0.7223261  -0.68569267 -0.08983696]
 [-0.03947277 -0.17057428  0.98455393]
 [-0.69042522 -0.70762289 -0.15027644]]
transform [[ 0.7223261  -0.68569267 -0.08983696]
 [-0.03947277 -0.17057428  0.98455393]
 [-0.69042522 -0.70762289 -0.15027644]]
support
[-0.1094332   1.19931586 -0.18305642]
[-93.47703746 751.07196921 193.38093714]
[202.36159205  -2.65984688 112.02501995]
[ 0.88040216 -9.64862854  1.47270909]
zmp_s [        0.         -40911134.46710082   8463536.61538539]
transform [[ 0.7223261  -0.03947277 -0.69042522]
 [-0.68569267 -0.17057428 -0.70762289]
 [-0.08983696  0.98455393 -0.15027644]]
zmp [ -4228563.45891017    989395.00609282 -41551088.47933102]
d1:81029265.98459, d2:0.05940, d3:27378670.56310
transform [[ 0.38775209 -0.18662965 -0.90267259]
 [ 0.61070573 -0.68149781  0.40323603]
 [-0.69042522 -0.70762289 -0.15027644]]
planes
[[ 0.38775209 -0.18662965 -0.90267259]
 [ 0.61070573 -0.68149781  0.40323603]
 [-0.69042522 -0.70762289 -0.15027644]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.38775209 -0.18662965 -0.90267259]
 [ 0.61070573 -0.68149781  0.40323603]
 [-0.69042522 -0.70762289 -0.15027644]]
transform [[ 0.38775209 -0.18662965 -0.90267259]
 [ 0.61070573 -0.68149781  0.40323603]
 [-0.69042522 -0.70762289 -0.15027644]]
transform [[ 0.38775209 -0.18662965 -0.90267259]
 [ 0.61070573 -0.68149781  0.40323603]
 [-0.69042522 -0.70762289 -0.15027644]]
support
[-1.09957364  0.49119439 -0.18305642]
[-700.80988852  285.85403593  193.38093714]
[101.30455425 175.19894555 112.02501995]
[ 8.84619137 -3.95171311  1.47270909]
zmp_s [        0.         -40911135.7948717    8463536.25411799]
transform [[ 0.38775209  0.61070573 -0.69042522]
 [-0.18662965 -0.68149781 -0.70762289]
 [-0.90267259  0.40323603 -0.15027644]]
zmp [-30828104.04183274  21891857.59433196 -17768714.11949217]
d1:61753207.73567, d2:0.05940, d3:13765294.99485
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:52.12197784449165 steps:286[00m
[RDDPG] Resetting Environment
transform [[ 0.71766776 -0.68922067  0.09963883]
 [-0.15119448 -0.01454493  0.988397  ]
 [-0.67977446 -0.72440553 -0.1146448 ]]
planes
[[ 0.71766776 -0.68922067  0.09963883]
 [-0.15119448 -0.01454493  0.988397  ]
 [-0.67977446 -0.72440553 -0.1146448 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.68285 -200.85779  718.80786]
[  68.93114985 -217.57559036  -37.6330251 ]
[ 0.   0.  -9.8]
transform [[ 0.71766776 -0.68922067  0.09963883]
 [-0.15119448 -0.01454493  0.988397  ]
 [-0.67977446 -0.72440553 -0.1146448 ]]
transform [[ 0.71766776 -0.68922067  0.09963883]
 [-0.15119448 -0.01454493  0.988397  ]
 [-0.67977446 -0.72440553 -0.1146448 ]]
transform [[ 0.71766776 -0.68922067  0.09963883]
 [-0.15119448 -0.01454493  0.988397  ]
 [-0.67977446 -0.72440553 -0.1146448 ]]
support
[ 0.12137317  1.20399723 -0.1396524 ]
[ 44.5028752  748.26697225 219.90721933]
[195.67754652 -44.45375615 115.06975531]
[-0.97646058 -9.68629062  1.123519  ]
zmp_s [        0.         -11127042.49920744 -14373024.77730069]
transform [[ 0.71766776 -0.15119448 -0.67977446]
 [-0.68922067 -0.01454493 -0.72440553]
 [ 0.09963883  0.988397   -0.1146448 ]]
zmp [11452762.64066677 10573740.68918392 -9350142.96123768]
d1:27773627.12065, d2:0.05940, d3:12904870.90497
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-315.4985865233812 steps:288[00m
[RDDPG] Resetting Environment
transform [[ 0.67452395  0.73822403 -0.00654204]
 [ 0.01384296 -0.00378753  0.999897  ]
 [ 0.73812318 -0.67454499 -0.01277399]]
planes
[[ 0.67452395  0.73822403 -0.00654204]
 [ 0.01384296 -0.00378753  0.999897  ]
 [ 0.73812318 -0.67454499 -0.01277399]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 413.54855  208.77196 1756.0436 ]
[ -25.79601063 -688.28877736   -7.38740351]
[ 0.   0.  -9.8]
transform [[ 0.67452395  0.73822403 -0.00654204]
 [ 0.01384296 -0.00378753  0.999897  ]
 [ 0.73812318 -0.67454499 -0.01277399]]
transform [[ 0.67452395  0.73822403 -0.00654204]
 [ 0.01384296 -0.00378753  0.999897  ]
 [ 0.73812318 -0.67454499 -0.01277399]]
transform [[ 0.67452395  0.73822403 -0.00654204]
 [ 0.01384296 -0.00378753  0.999897  ]
 [ 0.73812318 -0.67454499 -0.01277399]]
support
[-0.00796906  1.21800574 -0.01556039]
[ 421.58077353 1760.79671974  141.99201549]
[-525.463013     -5.13682156  445.33547973]
[ 0.06411198 -9.79899063  0.12518508]
zmp_s [        0.         -12969564.80508665 -14591974.0250572 ]
transform [[ 0.67452395  0.01384296  0.73812318]
 [ 0.73822403 -0.00378753 -0.67454499]
 [-0.00654204  0.999897   -0.01277399]]
zmp [-10950211.46138347   9892065.58805642 -12781831.28235901]
d1:31383280.54576, d2:0.05940, d3:14757939.22298
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-294.9020838392805 steps:290[00m
[RDDPG] Resetting Environment
transform [[ 0.11482803 -0.17835912 -0.97724235]
 [ 0.69924104 -0.68424702  0.20704605]
 [-0.70560372 -0.7071026   0.04614528]]
planes
[[ 0.11482803 -0.17835912 -0.97724235]
 [ 0.69924104 -0.68424702  0.20704605]
 [-0.70560372 -0.7071026   0.04614528]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 413.54855  208.77196 1756.0436 ]
[ -25.79601063 -688.28877736   -7.38740351]
[ 0.   0.  -9.8]
transform [[ 0.11482803 -0.17835912 -0.97724235]
 [ 0.69924104 -0.68424702  0.20704605]
 [-0.70560372 -0.7071026   0.04614528]]
transform [[ 0.11482803 -0.17835912 -0.97724235]
 [ 0.69924104 -0.68424702  0.20704605]
 [-0.70560372 -0.7071026   0.04614528]]
transform [[ 0.11482803 -0.17835912 -0.97724235]
 [ 0.69924104 -0.68424702  0.20704605]
 [-0.70560372 -0.7071026   0.04614528]]
support
[-1.1904094   0.25220925  0.056211  ]
[-1705.829573     509.90041359  -358.3914696 ]
[127.01975993 451.39238063 504.55164903]
[ 9.57697504 -2.02905126 -0.45222373]
zmp_s [       0.         13870181.19324209  8440049.0419316 ]
transform [[ 0.11482803  0.69924104 -0.70560372]
 [-0.17835912 -0.68424702 -0.7071026 ]
 [-0.97724235  0.20704605  0.04614528]]
zmp [  3743269.96170994 -15458610.69976171   3261234.60267646]
d1:19839283.19793, d2:0.05940, d3:5616476.35014
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-338.57400523771224 steps:292[00m
[RDDPG] Resetting Environment
transform [[ 0.19902411  0.26334295 -0.9439491 ]
 [ 0.68586564  0.65057158  0.32610577]
 [ 0.69998413 -0.71232516 -0.05113845]]
planes
[[ 0.19902411  0.26334295 -0.9439491 ]
 [ 0.68586564  0.65057158  0.32610577]
 [ 0.69998413 -0.71232516 -0.05113845]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -8.885393 -666.1146    377.92145 ]
[  23.87332098 -142.98775743   15.25547477]
[ 0.   0.  -9.8]
transform [[ 0.19902411  0.26334295 -0.9439491 ]
 [ 0.68586564  0.65057158  0.32610577]
 [ 0.69998413 -0.71232516 -0.05113845]]
transform [[ 0.19902411  0.26334295 -0.9439491 ]
 [ 0.68586564  0.65057158  0.32610577]
 [ 0.69998413 -0.71232516 -0.05113845]]
transform [[ 0.19902411  0.26334295 -0.9439491 ]
 [ 0.68586564  0.65057158  0.32610577]
 [ 0.69998413 -0.71232516 -0.05113845]]
support
[-1.14985385  0.39723962 -0.06229335]
[-533.92360719 -316.20706638  448.94425081]
[-47.30384264 -71.67498296 117.78458109]
[ 9.25070121 -3.19583658  0.50115684]
zmp_s [       0.          5936081.82172273 -6211918.41067249]
transform [[ 0.19902411  0.68586564  0.69998413]
 [ 0.26334295  0.65057158 -0.71232516]
 [-0.9439491   0.32610577 -0.05113845]]
zmp [-276889.76292545 8286751.90697164 2253458.45256579]
d1:10414178.77069, d2:0.05940, d3:4035836.33632
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-448.1072984962928 steps:294[00m
[RDDPG] Resetting Environment
transform [[ 0.2112684  -0.15962166  0.96430629]
 [-0.6843524   0.68024784  0.26253515]
 [-0.69787353 -0.71539068  0.03447742]]
planes
[[ 0.2112684  -0.15962166  0.96430629]
 [-0.6843524   0.68024784  0.26253515]
 [-0.69787353 -0.71539068  0.03447742]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -8.885393 -666.1146    377.92145 ]
[  23.87332098 -142.98775743   15.25547477]
[ 0.   0.  -9.8]
transform [[ 0.2112684  -0.15962166  0.96430629]
 [-0.6843524   0.68024784  0.26253515]
 [-0.69787353 -0.71539068  0.03447742]]
transform [[ 0.2112684  -0.15962166  0.96430629]
 [-0.6843524   0.68024784  0.26253515]
 [-0.69787353 -0.71539068  0.03447742]]
transform [[ 0.2112684  -0.15962166  0.96430629]
 [-0.6843524   0.68024784  0.26253515]
 [-0.69787353 -0.71539068  0.03447742]]
support
[1.17465158 0.31980226 0.04199802]
[ 468.88114764 -347.82463046  495.76283256]
[  42.57857118 -109.59977963   86.1575199 ]
[-9.45020169 -2.57284452 -0.33787872]
zmp_s [       0.          1650435.02815122 -3586536.96323686]
transform [[ 0.2112684  -0.6843524  -0.69787353]
 [-0.15962166  0.68024784 -0.71539068]
 [ 0.96430629  0.26253515  0.03447742]]
zmp [1373470.0518274  3688479.99328867  309642.67386574]
d1:5210580.27845, d2:0.05940, d3:1801920.03193
transform [[ 0.32317492 -0.27157223  0.90653545]
 [-0.63916391  0.64378935  0.42071939]
 [-0.69787353 -0.71539068  0.03447742]]
planes
[[ 0.32317492 -0.27157223  0.90653545]
 [-0.63916391  0.64378935  0.42071939]
 [-0.69787353 -0.71539068  0.03447742]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -8.885393 -666.1146    377.92145 ]
[  23.87332098 -142.98775743   15.25547477]
[ 0.   0.  -9.8]
transform [[ 0.32317492 -0.27157223  0.90653545]
 [-0.63916391  0.64378935  0.42071939]
 [-0.69787353 -0.71539068  0.03447742]]
transform [[ 0.32317492 -0.27157223  0.90653545]
 [-0.63916391  0.64378935  0.42071939]
 [-0.69787353 -0.71539068  0.03447742]]
transform [[ 0.32317492 -0.27157223  0.90653545]
 [-0.63916391  0.64378935  0.42071939]
 [-0.69787353 -0.71539068  0.03447742]]
support
[1.10427911 0.51249141 0.04199802]
[ 520.62588756 -264.15939971  495.76283256]
[  60.37639179 -100.8946868    86.1575199 ]
[-8.88404738 -4.12304997 -0.33787872]
zmp_s [       0.         1650434.9230523 -3586536.7242305]
transform [[ 0.32317492 -0.63916391 -0.69787353]
 [-0.27157223  0.64378935 -0.71539068]
 [ 0.90653545  0.42071939  0.03447742]]
zmp [1448050.61332092 3628307.38191325  570715.43252273]
d1:5292922.41808, d2:0.05940, d3:1972978.42005
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-287.95550487902955 steps:297[00m
[RDDPG] Resetting Environment
transform [[ 0.07785832  0.0168604   0.99682188]
 [-0.72181952 -0.68872988  0.06802812]
 [ 0.68768799 -0.72482204 -0.04145319]]
planes
[[ 0.07785832  0.0168604   0.99682188]
 [-0.72181952 -0.68872988  0.06802812]
 [ 0.68768799 -0.72482204 -0.04145319]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 269.62848 -251.4762  1039.1843 ]
[   3.838645   -282.53628409   14.77832627]
[ 0.   0.  -9.8]
transform [[ 0.07785832  0.0168604   0.99682188]
 [-0.72181952 -0.68872988  0.06802812]
 [ 0.68768799 -0.72482204 -0.04145319]]
transform [[ 0.07785832  0.0168604   0.99682188]
 [-0.72181952 -0.68872988  0.06802812]
 [ 0.68768799 -0.72482204 -0.04145319]]
transform [[ 0.07785832  0.0168604   0.99682188]
 [-0.72181952 -0.68872988  0.06802812]
 [ 0.68768799 -0.72482204 -0.04145319]]
support
[ 1.21425983  0.08286718 -0.05049542]
[1052.63450616   49.26983008  324.61825283]
[ 10.26655537 192.82571456 206.81570835]
[-9.76885443 -0.6666756   0.40624126]
zmp_s [        0.          26431843.82796132 -10452453.24403759]
transform [[ 0.07785832 -0.72181952  0.68768799]
 [ 0.0168604  -0.68872988 -0.72482204]
 [ 0.99682188  0.06802812 -0.04145319]]
zmp [-26267047.41836249 -10628232.15797377   2231396.23338417]
d1:37445030.06158, d2:0.05940, d3:6099033.65667
transform [[ 0.08442243  0.02404678  0.99613988]
 [-0.87825578  0.47402456  0.06298887]
 [-0.47068006 -0.88018322  0.06113752]]
planes
[[ 0.08442243  0.02404678  0.99613988]
 [-0.87825578  0.47402456  0.06298887]
 [-0.47068006 -0.88018322  0.06113752]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 456.09177   81.95286 -407.70642]
[-175.09434519 -371.84930753   60.04194892]
[ 0.   0.  -9.8]
transform [[ 0.08442243  0.02404678  0.99613988]
 [-0.87825578  0.47402456  0.06298887]
 [-0.47068006 -0.88018322  0.06113752]]
transform [[ 0.08442243  0.02404678  0.99613988]
 [-0.87825578  0.47402456  0.06298887]
 [-0.47068006 -0.88018322  0.06113752]]
transform [[ 0.08442243  0.02404678  0.99613988]
 [-0.87825578  0.47402456  0.06298887]
 [-0.47068006 -0.88018322  0.06113752]]
support
[1.21342907 0.07672871 0.07447352]
[-365.6575485  -387.39853098 -311.73299034]
[ 36.0865116  -18.70610988 413.37975344]
[-9.76217086 -0.61729092 -0.59914773]
zmp_s [        0.           6496791.92370018 -24491110.8852171 ]
transform [[ 0.08442243 -0.87825578 -0.47068006]
 [ 0.02404678  0.47402456 -0.88018322]
 [ 0.99613988  0.06298887  0.06113752]]
zmp [ 5821632.40424125 24636303.79732633 -1088100.28644015]
d1:38307051.69181, d2:0.05940, d3:10565377.65141
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-311.8427895979038 steps:300[00m
[RDDPG] Resetting Environment
transform [[ 1.18622735e-01  1.14727549e-01 -9.86289144e-01]
 [ 7.08623767e-01  6.86016560e-01  1.65026560e-01]
 [ 6.95543766e-01 -7.18483806e-01  7.84930744e-05]]
planes
[[ 1.18622735e-01  1.14727549e-01 -9.86289144e-01]
 [ 7.08623767e-01  6.86016560e-01  1.65026560e-01]
 [ 6.95543766e-01 -7.18483806e-01  7.84930744e-05]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-422.34332  -79.22557  230.80325]
[  17.77188591 -124.22725837  -11.25429227]
[ 0.   0.  -9.8]
transform [[ 1.18622735e-01  1.14727549e-01 -9.86289144e-01]
 [ 7.08623767e-01  6.86016560e-01  1.65026560e-01]
 [ 6.95543766e-01 -7.18483806e-01  7.84930744e-05]]
transform [[ 1.18622735e-01  1.14727549e-01 -9.86289144e-01]
 [ 7.08623767e-01  6.86016560e-01  1.65026560e-01]
 [ 6.95543766e-01 -7.18483806e-01  7.84930744e-05]]
transform [[ 1.18622735e-01  1.14727549e-01 -9.86289144e-01]
 [ 7.08623767e-01  6.86016560e-01  1.65026560e-01]
 [ 6.95543766e-01 -7.18483806e-01  7.84930744e-05]]
support
[-1.20142958e+00  2.01024002e-01  9.56148629e-05]
[-286.82761858 -315.54390272 -236.81785928]
[ -1.0441529  -74.4856328  101.61551443]
[ 9.66563361e+00 -1.61726029e+00 -7.69232129e-04]
zmp_s [      0.         1862101.44246887  384037.92039063]
transform [[ 1.18622735e-01  7.08623767e-01  6.95543766e-01]
 [ 1.14727549e-01  6.86016560e-01 -7.18483806e-01]
 [-9.86289144e-01  1.65026560e-01  7.84930744e-05]]
zmp [1586644.51995421 1001507.3986316   307326.34053154]
d1:2693853.98298, d2:0.05940, d3:427324.88545
transform [[ 0.13310783  0.11258571 -0.98468614]
 [ 0.87688196 -0.47641787  0.06406306]
 [-0.46190947 -0.87198079 -0.16213934]]
planes
[[ 0.13310783  0.11258571 -0.98468614]
 [ 0.87688196 -0.47641787  0.06406306]
 [-0.46190947 -0.87198079 -0.16213934]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  220.79599  -235.6968  -2144.5073 ]
[ 32.39479404  50.64244336 -12.70492588]
[ 0.   0.  -9.8]
transform [[ 0.13310783  0.11258571 -0.98468614]
 [ 0.87688196 -0.47641787  0.06406306]
 [-0.46190947 -0.87198079 -0.16213934]]
transform [[ 0.13310783  0.11258571 -0.98468614]
 [ 0.87688196 -0.47641787  0.06406306]
 [-0.46190947 -0.87198079 -0.16213934]]
transform [[ 0.13310783  0.11258571 -0.98468614]
 [ 0.87688196 -0.47641787  0.06406306]
 [-0.46190947 -0.87198079 -0.16213934]]
support
[-1.1994769   0.07803722 -0.19750699]
[2114.52021509  168.51847197  451.24432001]
[ 22.52398035   3.46552894 -57.06273151]
[ 9.64992414 -0.62781803  1.58896554]
zmp_s [        0.         -21688019.8002947    7438289.55983049]
transform [[ 0.13310783  0.87688196 -0.46190947]
 [ 0.11258571 -0.47641787 -0.87198079]
 [-0.98468614  0.06406306 -0.16213934]]
zmp [-22453649.65728522   3846514.60394816  -2595440.3859998 ]
d1:25271442.94387, d2:0.05940, d3:7706305.37215
transform [[-0.01091593 -0.18102644 -0.98341769]
 [ 0.65180808  0.74453169 -0.14428763]
 [ 0.75830543 -0.64257455  0.10986722]]
planes
[[-0.01091593 -0.18102644 -0.98341769]
 [ 0.65180808  0.74453169 -0.14428763]
 [ 0.75830543 -0.64257455  0.10986722]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-383.4468  -755.67725 1146.6952 ]
[  84.2225473    78.70621135 -103.86050736]
[ 0.   0.  -9.8]
transform [[-0.01091593 -0.18102644 -0.98341769]
 [ 0.65180808  0.74453169 -0.14428763]
 [ 0.75830543 -0.64257455  0.10986722]]
transform [[-0.01091593 -0.18102644 -0.98341769]
 [ 0.65180808  0.74453169 -0.14428763]
 [ 0.75830543 -0.64257455  0.10986722]]
transform [[-0.01091593 -0.18102644 -0.98341769]
 [ 0.65180808  0.74453169 -0.14428763]
 [ 0.75830543 -0.64257455  0.10986722]]
support
[-1.19793177 -0.17576126  0.13383269]
[-986.6970933  -978.01331914  320.79338446]
[ 86.97098751 128.4819923    1.88094126]
[ 9.63749336  1.41401878 -1.07669878]
zmp_s [       0.          8539111.02353126 25449831.61034286]
transform [[-0.01091593  0.65180808  0.75830543]
 [-0.18102644  0.74453169 -0.64257455]
 [-0.98341769 -0.14428763  0.10986722]]
zmp [24864607.10046366 -9995775.29142795  1564014.21513669]
d1:25485631.71231, d2:0.05940, d3:14666488.83253
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-1143.6842437903256 steps:304[00m
[RDDPG] Resetting Environment
transform [[ 0.69413668  0.71922255 -0.0298881 ]
 [ 0.03643068  0.00636768  0.99931592]
 [ 0.71892083 -0.69475067 -0.02178173]]
planes
[[ 0.69413668  0.71922255 -0.0298881 ]
 [ 0.03643068  0.00636768  0.99931592]
 [ 0.71892083 -0.69475067 -0.02178173]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-572.4483   101.97349  496.45874]
[  55.19284584 -340.46561354  -36.51393154]
[ 0.   0.  -9.8]
transform [[ 0.69413668  0.71922255 -0.0298881 ]
 [ 0.03643068  0.00636768  0.99931592]
 [ 0.71892083 -0.69475067 -0.02178173]]
transform [[ 0.69413668  0.71922255 -0.0298881 ]
 [ 0.03643068  0.00636768  0.99931592]
 [ 0.71892083 -0.69475067 -0.02178173]]
transform [[ 0.69413668  0.71922255 -0.0298881 ]
 [ 0.03643068  0.00636768  0.99931592]
 [ 0.71892083 -0.69475067 -0.02178173]]
support
[-0.03640763  1.2172979  -0.026533  ]
[-338.85394068  475.91377344 -493.20488434]
[-205.46783454  -36.64621622  277.01333478]
[ 0.29290337 -9.79329599  0.21346091]
zmp_s [        0.         -17386910.01461905  -4521659.3652774 ]
transform [[ 0.69413668  0.03643068  0.71892083]
 [ 0.71922255  0.00636768 -0.69475067]
 [-0.0298881   0.99931592 -0.02178173]]
zmp [ -3884132.09676493   3030711.56836357 -17276526.38911229]
d1:34868679.35281, d2:0.05940, d3:13186764.30299
transform [[ 0.43759447  0.42802641  0.79076201]
 [-0.54005921 -0.57802683  0.61173612]
 [ 0.71892083 -0.69475067 -0.02178173]]
planes
[[ 0.43759447  0.42802641  0.79076201]
 [-0.54005921 -0.57802683  0.61173612]
 [ 0.71892083 -0.69475067 -0.02178173]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-572.4483   101.97349  496.45874]
[  55.19284584 -340.46561354  -36.51393154]
[ 0.   0.  -9.8]
transform [[ 0.43759447  0.42802641  0.79076201]
 [-0.54005921 -0.57802683  0.61173612]
 [ 0.71892083 -0.69475067 -0.02178173]]
transform [[ 0.43759447  0.42802641  0.79076201]
 [-0.54005921 -0.57802683  0.61173612]
 [ 0.71892083 -0.69475067 -0.02178173]]
transform [[ 0.43759447  0.42802641  0.79076201]
 [-0.54005921 -0.57802683  0.61173612]
 [ 0.71892083 -0.69475067 -0.02178173]]
support
[ 0.96325187  0.74517485 -0.026533  ]
[ 185.72784188  553.9143086  -493.20488434]
[-150.45001909  144.65396429  277.01333478]
[-7.74946767 -5.99501396  0.21346091]
zmp_s [        0.         -17386915.77670948  -4521656.04561079]
transform [[ 0.43759447 -0.54005921  0.71892083]
 [ 0.42802641 -0.57802683 -0.69475067]
 [ 0.79076201  0.61173612 -0.02178173]]
zmp [  6139251.27573608  13191527.38179125 -10537714.90284551]
d1:28726651.42866, d2:0.05940, d3:9071052.27430
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-69.1576120632372 steps:307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-188.5733477734686 steps:308[00m
[RDDPG] Resetting Environment
transform [[ 0.3753334  -0.07150508  0.92412764]
 [-0.63267201 -0.74840164  0.19905089]
 [ 0.67738539 -0.65938008 -0.32613939]]
planes
[[ 0.3753334  -0.07150508  0.92412764]
 [-0.63267201 -0.74840164  0.19905089]
 [ 0.67738539 -0.65938008 -0.32613939]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-617.6551  337.0489  774.1648]
[  85.03160662 -303.95136627  -26.38638044]
[ 0.   0.  -9.8]
transform [[ 0.3753334  -0.07150508  0.92412764]
 [-0.63267201 -0.74840164  0.19905089]
 [ 0.67738539 -0.65938008 -0.32613939]]
transform [[ 0.3753334  -0.07150508  0.92412764]
 [-0.63267201 -0.74840164  0.19905089]
 [ 0.67738539 -0.65938008 -0.32613939]]
transform [[ 0.3753334  -0.07150508  0.92412764]
 [-0.63267201 -0.74840164  0.19905089]
 [ 0.67738539 -0.65938008 -0.32613939]]
support
[ 1.12570871  0.2424701  -0.39728057]
[ 459.49979007  292.62333681 -893.1194914 ]
[ 29.26488663 168.42835146 266.62428173]
[-9.05645086 -1.95069871  3.19616603]
zmp_s [        0.         -29671133.07586886   -868957.61184496]
transform [[ 0.3753334  -0.63267201  0.67738539]
 [-0.07150508 -0.74840164 -0.65938008]
 [ 0.92412764  0.19905089 -0.32613939]]
zmp [18183476.26642274 22778898.04755399 -5622664.0932844 ]
d1:35120562.01400, d2:0.05940, d3:5239552.25654
transform [[ 0.34811985 -0.10323131  0.93174887]
 [-0.64804447 -0.74468863  0.15961592]
 [ 0.67738539 -0.65938008 -0.32613939]]
planes
[[ 0.34811985 -0.10323131  0.93174887]
 [-0.64804447 -0.74468863  0.15961592]
 [ 0.67738539 -0.65938008 -0.32613939]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-617.6551  337.0489  774.1648]
[  85.03160662 -303.95136627  -26.38638044]
[ 0.   0.  -9.8]
transform [[ 0.34811985 -0.10323131  0.93174887]
 [-0.64804447 -0.74468863  0.15961592]
 [ 0.67738539 -0.65938008 -0.32613939]]
transform [[ 0.34811985 -0.10323131  0.93174887]
 [-0.64804447 -0.74468863  0.15961592]
 [ 0.67738539 -0.65938008 -0.32613939]]
transform [[ 0.34811985 -0.10323131  0.93174887]
 [-0.64804447 -0.74468863  0.15961592]
 [ 0.67738539 -0.65938008 -0.32613939]]
support
[ 1.13499237  0.19443313 -0.39728057]
[ 471.51517148  272.84051343 -893.1194914 ]
[ 36.39300845 167.03317802 266.62428173]
[-9.1311389  -1.56423601  3.19616603]
zmp_s [        0.         -29671133.04808552   -868957.66408419]
transform [[ 0.34811985 -0.64804447  0.67738539]
 [-0.10323131 -0.74468863 -0.65938008]
 [ 0.93174887  0.15961592 -0.32613939]]
zmp [18639594.37460272 22668728.79581115 -4452583.8461545 ]
d1:34535651.93911, d2:0.05940, d3:4316458.81836
transform [[ 0.29222387 -0.07625316  0.95330513]
 [-0.95488226  0.03194071  0.29526219]
 [-0.05296392 -0.99657679 -0.06347895]]
planes
[[ 0.29222387 -0.07625316  0.95330513]
 [-0.95488226  0.03194071  0.29526219]
 [-0.05296392 -0.99657679 -0.06347895]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-617.6551  337.0489  774.1648]
[  85.03160662 -303.95136627  -26.38638044]
[ 0.   0.  -9.8]
transform [[ 0.29222387 -0.07625316  0.95330513]
 [-0.95488226  0.03194071  0.29526219]
 [-0.05296392 -0.99657679 -0.06347895]]
transform [[ 0.29222387 -0.07625316  0.95330513]
 [-0.95488226  0.03194071  0.29526219]
 [-0.05296392 -0.99657679 -0.06347895]]
transform [[ 0.29222387 -0.07625316  0.95330513]
 [-0.95488226  0.03194071  0.29526219]
 [-0.05296392 -0.99657679 -0.06347895]]
support
[ 1.16125072  0.35966808 -0.07732569]
[ 531.82066233  829.13506413 -352.32482969]
[ 22.87124593 -98.69449698 300.08224815]
[-9.34239023 -2.89356944  0.62209368]
zmp_s [       0.         -5784038.55106523 -8692870.48453442]
transform [[ 0.29222387 -0.95488226 -0.05296392]
 [-0.07625316  0.03194071 -0.99657679]
 [ 0.95330513  0.29526219 -0.06347895]]
zmp [ 5983484.32386931  8478366.61057416 -1155993.6144063 ]
d1:9958722.99119, d2:0.05940, d3:5072939.56585
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-314.2667933673222 steps:312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-186.25767272466257 steps:313[00m
[RDDPG] Resetting Environment
transform [[ 0.71060967  0.70355129 -0.00703826]
 [-0.02491065  0.03515518  0.99907136]
 [ 0.70314538 -0.70977443  0.04250753]]
planes
[[ 0.71060967  0.70355129 -0.00703826]
 [-0.02491065  0.03515518  0.99907136]
 [ 0.70314538 -0.70977443  0.04250753]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.15848 -257.9186  1219.8308 ]
[ 118.02685813 -522.08234686  -66.60295764]
[ 0.   0.  -9.8]
transform [[ 0.71060967  0.70355129 -0.00703826]
 [-0.02491065  0.03515518  0.99907136]
 [ 0.70314538 -0.70977443  0.04250753]]
transform [[ 0.71060967  0.70355129 -0.00703826]
 [-0.02491065  0.03515518  0.99907136]
 [ 0.70314538 -0.70977443  0.04250753]]
transform [[ 0.71060967  0.70355129 -0.00703826]
 [-0.02491065  0.03515518  0.99907136]
 [ 0.70314538 -0.70977443  0.04250753]]
support
[-0.00857352  1.21699999  0.05177975]
[ 109.23483708 1199.1395201   531.05166909]
[-282.97191404  -87.83513071  450.71961594]
[ 0.0689749  -9.79089932 -0.41657379]
zmp_s [        0.         -20972512.81325939 -11976653.71018564]
transform [[ 0.71060967 -0.02491065  0.70314538]
 [ 0.70355129  0.03515518 -0.70977443]
 [-0.00703826  0.99907136  0.04250753]]
zmp [ -7898889.83115249   7763430.21261978 -21462134.84930029]
d1:45035446.02999, d2:0.05940, d3:18629039.48263
transform [[ 0.89816171  0.42948467 -0.09406629]
 [ 0.04383544  0.1254089   0.99113625]
 [ 0.43747455 -0.89432412  0.09381083]]
planes
[[ 0.89816171  0.42948467 -0.09406629]
 [ 0.04383544  0.1254089   0.99113625]
 [ 0.43747455 -0.89432412  0.09381083]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.15848 -257.9186  1219.8308 ]
[ 118.02685813 -522.08234686  -66.60295764]
[ 0.   0.  -9.8]
transform [[ 0.89816171  0.42948467 -0.09406629]
 [ 0.04383544  0.1254089   0.99113625]
 [ 0.43747455 -0.89432412  0.09381083]]
transform [[ 0.89816171  0.42948467 -0.09406629]
 [ 0.04383544  0.1254089   0.99113625]
 [ 0.43747455 -0.89432412  0.09381083]]
transform [[ 0.89816171  0.42948467 -0.09406629]
 [ 0.04383544  0.1254089   0.99113625]
 [ 0.43747455 -0.89432412  0.09381083]]
support
[-0.11458509  1.20733399  0.1142739 ]
[ 152.75136927 1195.13491555  529.34229529]
[-111.95406415 -126.31262102  512.29650495]
[ 0.92184966 -9.71313528 -0.91934617]
zmp_s [       0.         -2875888.99244126 12025595.68633185]
transform [[ 0.89816171  0.04383544  0.43747455]
 [ 0.42948467  0.1254089  -0.89432412]
 [-0.09406629  0.99113625  0.09381083]]
zmp [  5134826.19124079 -11115442.40908023  -1722266.67909911]
d1:12631851.23598, d2:0.05940, d3:3762766.26966
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-399.80707781076524 steps:316[00m
[RDDPG] Resetting Environment
transform [[ 0.26003802  0.24417686  0.93421513]
 [-0.66499525 -0.65620685  0.35661441]
 [ 0.70011538 -0.71398199 -0.00826227]]
planes
[[ 0.26003802  0.24417686  0.93421513]
 [-0.66499525 -0.65620685  0.35661441]
 [ 0.70011538 -0.71398199 -0.00826227]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 237.91216 -299.55817 1036.1356 ]
[ 108.37232201 -331.61283842  -48.21008112]
[ 0.   0.  -9.8]
transform [[ 0.26003802  0.24417686  0.93421513]
 [-0.66499525 -0.65620685  0.35661441]
 [ 0.70011538 -0.71398199 -0.00826227]]
transform [[ 0.26003802  0.24417686  0.93421513]
 [-0.66499525 -0.65620685  0.35661441]
 [ 0.70011538 -0.71398199 -0.00826227]]
transform [[ 0.26003802  0.24417686  0.93421513]
 [-0.66499525 -0.65620685  0.35661441]
 [ 0.70011538 -0.71398199 -0.00826227]]
support
[ 1.1379966   0.43440314 -0.01006452]
[956.69460288 407.86255964 371.88426664]
[-97.82984643 128.34712549 313.03704715]
[-9.15530826 -3.49482123  0.0809702 ]
zmp_s [       0.          1105487.49338827 -7751204.32134243]
transform [[ 0.26003802 -0.66499525  0.70011538]
 [ 0.24417686 -0.65620685 -0.71398199]
 [ 0.93421513  0.35661441 -0.00826227]]
zmp [-6161881.31504976  4808791.79400818   458275.27902988]
d1:10654856.62706, d2:0.05940, d3:3786267.56661
transform [[ 0.98977542  0.11488745 -0.08453112]
 [ 0.0676987   0.14324385  0.9873693 ]
 [ 0.12554495 -0.98299646  0.13400149]]
planes
[[ 0.98977542  0.11488745 -0.08453112]
 [ 0.0676987   0.14324385  0.9873693 ]
 [ 0.12554495 -0.98299646  0.13400149]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 237.91216 -299.55817 1036.1356 ]
[ 108.37232201 -331.61283842  -48.21008112]
[ 0.   0.  -9.8]
transform [[ 0.98977542  0.11488745 -0.08453112]
 [ 0.0676987   0.14324385  0.9873693 ]
 [ 0.12554495 -0.98299646  0.13400149]]
transform [[ 0.98977542  0.11488745 -0.08453112]
 [ 0.0676987   0.14324385  0.9873693 ]
 [ 0.12554495 -0.98299646  0.13400149]]
transform [[ 0.98977542  0.11488745 -0.08453112]
 [ 0.0676987   0.14324385  0.9873693 ]
 [ 0.12554495 -0.98299646  0.13400149]]
support
[-0.10297     1.20274535  0.1632314 ]
[113.47842272 996.24498013 463.17700859]
[ 73.24135806 -87.76598789 333.11962242]
[ 0.82840499 -9.67621913 -1.31321464]
zmp_s [       0.         24706509.17720894 -4544890.18852252]
transform [[ 0.98977542  0.0676987   0.12554495]
 [ 0.11488745  0.14324385 -0.98299646]
 [-0.08453112  0.9873693   0.13400149]]
zmp [ 1102010.59445133  8006666.46031941 23785426.57258401]
d1:49428985.51368, d2:0.05940, d3:11353522.53649
transform [[-0.32619575 -0.62575746 -0.70853651]
 [ 0.61081147  0.43252507 -0.66319788]
 [ 0.72146082 -0.64911461  0.24113201]]
planes
[[-0.32619575 -0.62575746 -0.70853651]
 [ 0.61081147  0.43252507 -0.66319788]
 [ 0.72146082 -0.64911461  0.24113201]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 280.5387     29.976559 -130.97153 ]
[-392.29540789  -41.48566709  191.759732  ]
[ 0.   0.  -9.8]
transform [[-0.32619575 -0.62575746 -0.70853651]
 [ 0.61081147  0.43252507 -0.66319788]
 [ 0.72146082 -0.64911461  0.24113201]]
transform [[-0.32619575 -0.62575746 -0.70853651]
 [ 0.61081147  0.43252507 -0.66319788]
 [ 0.72146082 -0.64911461  0.24113201]]
transform [[-0.32619575 -0.62575746 -0.70853651]
 [ 0.61081147  0.43252507 -0.66319788]
 [ 0.72146082 -0.64911461  0.24113201]]
support
[-0.86309042 -0.80786202  0.29373042]
[-17.47047644 271.18190558 151.35802843]
[  18.05628853 -384.73677331 -209.85740494]
[ 6.94365776  6.49933918 -2.36309366]
zmp_s [       0.          7106396.48964242 10013203.62593177]
transform [[-0.32619575  0.61081147  0.72146082]
 [-0.62575746  0.43252507 -0.64911461]
 [-0.70853651 -0.66319788  0.24113201]]
zmp [11564802.59124683 -3426022.12550393 -2298443.17370135]
d1:15614661.36194, d2:0.05940, d3:5910875.69695
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-187.62316137204022 steps:320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-219.87903893560025 steps:321[00m
[RDDPG] Resetting Environment
transform [[ 0.67856407  0.72195786 -0.13537976]
 [-0.15148123  0.31788349  0.93595064]
 [ 0.71875185 -0.61459494  0.32506737]]
planes
[[ 0.67856407  0.72195786 -0.13537976]
 [-0.15148123  0.31788349  0.93595064]
 [ 0.71875185 -0.61459494  0.32506737]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-351.00027  396.58246  545.3654 ]
[ -50.03651386 -426.81557166   39.20239795]
[ 0.   0.  -9.8]
transform [[ 0.67856407  0.72195786 -0.13537976]
 [-0.15148123  0.31788349  0.93595064]
 [ 0.71875185 -0.61459494  0.32506737]]
transform [[ 0.67856407  0.72195786 -0.13537976]
 [-0.15148123  0.31788349  0.93595064]
 [ 0.71875185 -0.61459494  0.32506737]]
transform [[ 0.67856407  0.72195786 -0.13537976]
 [-0.15148123  0.31788349  0.93595064]
 [ 0.71875185 -0.61459494  0.32506737]]
support
[-0.16491031  1.14011067  0.39597471]
[ -25.69179166  689.67207836 -318.73916425]
[-347.4030496   -91.40652236  239.09827276]
[ 1.32672166 -9.17231624 -3.18566024]
zmp_s [       0.         30408648.34743596  -395473.20484926]
transform [[ 0.67856407 -0.15148123  0.71875185]
 [ 0.72195786  0.31788349 -0.61459494]
 [-0.13537976  0.93595064  0.32506737]]
zmp [-4890586.43202501  9909463.13813934 28332438.35189455]
d1:60108634.73376, d2:0.05940, d3:22286856.60031
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-287.49826550866703 steps:323[00m
[RDDPG] Resetting Environment
transform [[ 0.09873114 -0.0944897  -0.99061793]
 [ 0.69793051 -0.70301414  0.13661681]
 [-0.70932728 -0.70487076 -0.00346215]]
planes
[[ 0.09873114 -0.0944897  -0.99061793]
 [ 0.69793051 -0.70301414  0.13661681]
 [-0.70932728 -0.70487076 -0.00346215]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-351.00027  396.58246  545.3654 ]
[ -50.03651386 -426.81557166   39.20239795]
[ 0.   0.  -9.8]
transform [[ 0.09873114 -0.0944897  -0.99061793]
 [ 0.69793051 -0.70301414  0.13661681]
 [-0.70932728 -0.70487076 -0.00346215]]
transform [[ 0.09873114 -0.0944897  -0.99061793]
 [ 0.69793051 -0.70301414  0.13661681]
 [-0.70932728 -0.70487076 -0.00346215]]
transform [[ 0.09873114 -0.0944897  -0.99061793]
 [ 0.69793051 -0.70301414  0.13661681]
 [-0.70932728 -0.70487076 -0.00346215]]
support
[-1.20670261  0.1664172  -0.00421735]
[-612.37637589 -449.2707923   -32.45344302]
[ -3.4450845  270.49107679 336.20635647]
[ 9.70805572 -1.33884475  0.03392902]
zmp_s [       0.         2574791.3765208 -4557403.8881273]
transform [[ 0.09873114  0.69793051 -0.70932728]
 [-0.0944897  -0.70301414 -0.70487076]
 [-0.99061793  0.13661681 -0.00346215]]
zmp [5029716.37715282 1402266.01096127  367538.18081575]
d1:6576303.39347, d2:0.05940, d3:2327478.90439
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-370.76299173826453 steps:325[00m
[RDDPG] Resetting Environment
transform [[ 0.60025334 -0.79483682 -0.0890525 ]
 [ 0.086351   -0.04628823  0.99518889]
 [-0.79513484 -0.60505533  0.04085028]]
planes
[[ 0.60025334 -0.79483682 -0.0890525 ]
 [ 0.086351   -0.04628823  0.99518889]
 [-0.79513484 -0.60505533  0.04085028]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-351.00027  396.58246  545.3654 ]
[ -50.03651386 -426.81557166   39.20239795]
[ 0.   0.  -9.8]
transform [[ 0.60025334 -0.79483682 -0.0890525 ]
 [ 0.086351   -0.04628823  0.99518889]
 [-0.79513484 -0.60505533  0.04085028]]
transform [[ 0.60025334 -0.79483682 -0.0890525 ]
 [ 0.086351   -0.04628823  0.99518889]
 [-0.79513484 -0.60505533  0.04085028]]
transform [[ 0.60025334 -0.79483682 -0.0890525 ]
 [ 0.086351   -0.04628823  0.99518889]
 [-0.79513484 -0.60505533  0.04085028]]
support
[-0.10847763  1.21227064  0.049761  ]
[-574.47358125  494.07528247   61.41654785]
[305.72307512  54.44962353 299.63424205]
[ 0.87271448 -9.75285114 -0.40033276]
zmp_s [       0.         16949525.64305118  2847167.94329583]
transform [[ 0.60025334  0.086351   -0.79513484]
 [-0.79483682 -0.04628823 -0.60505533]
 [-0.0890525   0.99518889  0.04085028]]
zmp [ -800273.94891893 -2507257.61587907 16984287.25530434]
d1:33592642.21602, d2:0.05940, d3:11781495.59095
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-205.01945967158366 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-271.2385865429573 steps:328[00m
[RDDPG] Resetting Environment
transform [[ 7.29315460e-01 -6.83404267e-01  3.25202867e-02]
 [-4.50423211e-02 -5.30848280e-04  9.98984933e-01]
 [-6.82693303e-01 -7.30040014e-01 -3.11692692e-02]]
planes
[[ 7.29315460e-01 -6.83404267e-01  3.25202867e-02]
 [-4.50423211e-02 -5.30848280e-04  9.98984933e-01]
 [-6.82693303e-01 -7.30040014e-01 -3.11692692e-02]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-351.00027  396.58246  545.3654 ]
[ -50.03651386 -426.81557166   39.20239795]
[ 0.   0.  -9.8]
transform [[ 7.29315460e-01 -6.83404267e-01  3.25202867e-02]
 [-4.50423211e-02 -5.30848280e-04  9.98984933e-01]
 [-6.82693303e-01 -7.30040014e-01 -3.11692692e-02]]
transform [[ 7.29315460e-01 -6.83404267e-01  3.25202867e-02]
 [-4.50423211e-02 -5.30848280e-04  9.98984933e-01]
 [-6.82693303e-01 -7.30040014e-01 -3.11692692e-02]]
transform [[ 7.29315460e-01 -6.83404267e-01  3.25202867e-02]
 [-4.50423211e-02 -5.30848280e-04  9.98984933e-01]
 [-6.82693303e-01 -7.30040014e-01 -3.11692692e-02]]
support
[ 0.03961398  1.21689472 -0.03796826]
[-509.28063121  560.41117694  -66.89416827]
[256.47005293  41.64293992 344.53012862]
[-0.31869881 -9.79005234  0.30545884]
zmp_s [        0.          -8259620.06422204 -14253920.12486159]
transform [[ 7.29315460e-01 -4.50423211e-02 -6.82693303e-01]
 [-6.83404267e-01 -5.30848280e-04 -7.30040014e-01]
 [ 3.25202867e-02  9.98984933e-01 -3.11692692e-02]]
zmp [10103088.2644661  10410316.64961858 -7806951.7216211 ]
d1:25880577.53437, d2:0.05940, d3:11489782.11571
transform [[ 0.92152983  0.37913534  0.08389973]
 [-0.07566366 -0.03660046  0.99646145]
 [ 0.38086456 -0.92461711 -0.00504165]]
planes
[[ 0.92152983  0.37913534  0.08389973]
 [-0.07566366 -0.03660046  0.99646145]
 [ 0.38086456 -0.92461711 -0.00504165]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-106.979836  101.63202    59.8718  ]
[-138.94711425 -907.92051248  -14.29113506]
[ 0.   0.  -9.8]
transform [[ 0.92152983  0.37913534  0.08389973]
 [-0.07566366 -0.03660046  0.99646145]
 [ 0.38086456 -0.92461711 -0.00504165]]
transform [[ 0.92152983  0.37913534  0.08389973]
 [-0.07566366 -0.03660046  0.99646145]
 [ 0.38086456 -0.92461711 -0.00504165]]
transform [[ 0.92152983  0.37913534  0.08389973]
 [-0.07566366 -0.03660046  0.99646145]
 [ 0.38086456 -0.92461711 -0.00504165]]
support
[ 0.10220088  1.21382078 -0.00614139]
[ -55.02959169   64.03464669 -135.01738452]
[-473.46768546   29.50299268  786.63086115]
[-0.82221734 -9.76532222  0.04940816]
zmp_s [        0.         -10649977.60262371   5984629.71864937]
transform [[ 0.92152983 -0.07566366  0.38086456]
 [ 0.37913534 -0.03660046 -0.92461711]
 [ 0.08389973  0.99646145 -0.00504165]]
zmp [  3085149.60986507  -5143696.93277024 -10642464.53584366]
d1:22005642.88125, d2:0.05940, d3:9330593.12930
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-391.13757197728825 steps:331[00m
[RDDPG] Resetting Environment
transform [[ 0.36096674 -0.26440611  0.89431113]
 [-0.65841836  0.60687751  0.44517979]
 [-0.66044557 -0.74952596  0.04497275]]
planes
[[ 0.36096674 -0.26440611  0.89431113]
 [-0.65841836  0.60687751  0.44517979]
 [-0.66044557 -0.74952596  0.04497275]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-106.979836  101.63202    59.8718  ]
[-138.94711425 -907.92051248  -14.29113506]
[ 0.   0.  -9.8]
transform [[ 0.36096674 -0.26440611  0.89431113]
 [-0.65841836  0.60687751  0.44517979]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.36096674 -0.26440611  0.89431113]
 [-0.65841836  0.60687751  0.44517979]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.36096674 -0.26440611  0.89431113]
 [-0.65841836  0.60687751  0.44517979]
 [-0.66044557 -0.74952596  0.04497275]]
support
[1.08938829 0.54228739 0.05478271]
[-11.94427334 158.76938892  -2.82887898]
[ 177.12372697 -465.87332984  771.63429212]
[-8.76424907 -4.36276194 -0.44073296]
zmp_s [       0.        13154377.9266487  7516975.379478 ]
transform [[ 0.36096674 -0.65841836 -0.66044557]
 [-0.26440611  0.60687751 -0.74952596]
 [ 0.89431113  0.44517979  0.04497275]]
zmp [-13625637.00300268   2348927.84657971   6194122.27055665]
d1:18585474.03927, d2:0.05940, d3:7417072.98054
transform [[ 0.08735594 -0.01721047  0.99602848]
 [-0.74577516  0.66175127  0.07684213]
 [-0.66044557 -0.74952596  0.04497275]]
planes
[[ 0.08735594 -0.01721047  0.99602848]
 [-0.74577516  0.66175127  0.07684213]
 [-0.66044557 -0.74952596  0.04497275]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-106.979836  101.63202    59.8718  ]
[-138.94711425 -907.92051248  -14.29113506]
[ 0.   0.  -9.8]
transform [[ 0.08735594 -0.01721047  0.99602848]
 [-0.74577516  0.66175127  0.07684213]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.08735594 -0.01721047  0.99602848]
 [-0.74577516  0.66175127  0.07684213]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.08735594 -0.01721047  0.99602848]
 [-0.74577516  0.66175127  0.07684213]
 [-0.66044557 -0.74952596  0.04497275]]
support
[1.21329337 0.0936038  0.05478271]
[ 48.53955809 151.63869854  -2.82887898]
[ -10.74649097 -498.2924069   771.63429212]
[-9.76107913 -0.75305287 -0.44073296]
zmp_s [       0.         13154307.4742048   7516940.30736658]
transform [[ 0.08735594 -0.74577516 -0.66044557]
 [-0.01721047  0.66175127 -0.74952596]
 [ 0.99602848  0.07684213  0.04497275]]
zmp [-14774685.73607555   3070737.74873082   1348862.48177258]
d1:16779175.46018, d2:0.05940, d3:4456597.81875
transform [[ 0.16932224 -0.09031204  0.9814142 ]
 [-0.73153377  0.6557855   0.18655759]
 [-0.66044557 -0.74952596  0.04497275]]
planes
[[ 0.16932224 -0.09031204  0.9814142 ]
 [-0.73153377  0.6557855   0.18655759]
 [-0.66044557 -0.74952596  0.04497275]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-106.979836  101.63202    59.8718  ]
[-138.94711425 -907.92051248  -14.29113506]
[ 0.   0.  -9.8]
transform [[ 0.16932224 -0.09031204  0.9814142 ]
 [-0.73153377  0.6557855   0.18655759]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.16932224 -0.09031204  0.9814142 ]
 [-0.73153377  0.6557855   0.18655759]
 [-0.66044557 -0.74952596  0.04497275]]
transform [[ 0.16932224 -0.09031204  0.9814142 ]
 [-0.73153377  0.6557855   0.18655759]
 [-0.66044557 -0.74952596  0.04497275]]
support
[1.19549126 0.22725162 0.05478271]
[ 31.4663739  156.07770514  -2.82887898]
[  44.44379573 -496.42272214  771.63429212]
[-9.61785915 -1.82826439 -0.44073296]
zmp_s [       0.         13154288.46967082  7516930.51256713]
transform [[ 0.16932224 -0.73153377 -0.66044557]
 [-0.09031204  0.6557855  -0.74952596]
 [ 0.9814142   0.18655759  0.04497275]]
zmp [-14587329.64467557   2992257.0637165    2792089.41411678]
d1:16469213.42830, d2:0.05940, d3:5342213.89527
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-678.0524468783576 steps:335[00m
[RDDPG] Resetting Environment
transform [[ 0.05462321  0.05447493 -0.99702001]
 [ 0.77292794  0.6298337   0.0767587 ]
 [ 0.63213819 -0.77481747 -0.00770166]]
planes
[[ 0.05462321  0.05447493 -0.99702001]
 [ 0.77292794  0.6298337   0.0767587 ]
 [ 0.63213819 -0.77481747 -0.00770166]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1058.2599   638.821   1512.3236]
[ -50.60178132 -296.5097011    19.19010616]
[ 0.   0.  -9.8]
transform [[ 0.05462321  0.05447493 -0.99702001]
 [ 0.77292794  0.6298337   0.0767587 ]
 [ 0.63213819 -0.77481747 -0.00770166]]
transform [[ 0.05462321  0.05447493 -0.99702001]
 [ 0.77292794  0.6298337   0.0767587 ]
 [ 0.63213819 -0.77481747 -0.00770166]]
transform [[ 0.05462321  0.05447493 -0.99702001]
 [ 0.77292794  0.6298337   0.0767587 ]
 [ 0.63213819 -0.77481747 -0.00770166]]
support
[-1.21450118  0.09350216 -0.00938164]
[-1530.82271676  -299.52366148 -1175.58355784]
[ -38.0492983  -224.39032465  197.60578113]
[ 9.77079606 -0.75223524  0.07547631]
zmp_s [        0.          -4293840.03682524 -13168257.92326074]
transform [[ 0.05462321  0.77292794  0.63213819]
 [ 0.05447493  0.6298337  -0.77481747]
 [-0.99702001  0.0767587  -0.00770166]]
zmp [-11642987.69789556   7498591.09523999   -228172.06801225]
d1:18187430.88489, d2:0.05940, d3:6388019.48942
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-252.06229597588506 steps:337[00m
[RDDPG] Resetting Environment
transform [[ 0.31609076  0.33472183 -0.88772064]
 [ 0.60313463  0.6513775   0.46036506]
 [ 0.73233545 -0.68093222  0.00401207]]
planes
[[ 0.31609076  0.33472183 -0.88772064]
 [ 0.60313463  0.6513775   0.46036506]
 [ 0.73233545 -0.68093222  0.00401207]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -13.618477 -565.10614  -208.42238 ]
[ -36.86403344 -139.90182867   30.14602365]
[ 0.   0.  -9.8]
transform [[ 0.31609076  0.33472183 -0.88772064]
 [ 0.60313463  0.6513775   0.46036506]
 [ 0.73233545 -0.68093222  0.00401207]]
transform [[ 0.31609076  0.33472183 -0.88772064]
 [ 0.60313463  0.6513775   0.46036506]
 [ 0.73233545 -0.68093222  0.00401207]]
transform [[ 0.31609076  0.33472183 -0.88772064]
 [ 0.60313463  0.6513775   0.46036506]
 [ 0.73233545 -0.68093222  0.00401207]]
support
[-1.08136021  0.56078504  0.00488723]
[  -8.43718987 -472.2615795   373.98948164]
[-85.24182458 -99.48470263  68.38777288]
[ 8.69966232 -4.51157756 -0.03931831]
zmp_s [       0.         -6091624.74910379  8649863.61300754]
transform [[ 0.31609076  0.60313463  0.73233545]
 [ 0.33472183  0.6513775  -0.68093222]
 [-0.88772064  0.46036506  0.00401207]]
zmp [ 2660531.89445713 -9857918.16009312 -2769667.2952178 ]
d1:12616445.01216, d2:0.05940, d3:5879358.63222
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-345.53149222050087 steps:339[00m
[RDDPG] Resetting Environment
transform [[ 0.70144898  0.70507663 -0.10409767]
 [ 0.0507504   0.09627399  0.99406028]
 [ 0.7109105  -0.70256549  0.03174837]]
planes
[[ 0.70144898  0.70507663 -0.10409767]
 [ 0.0507504   0.09627399  0.99406028]
 [ 0.7109105  -0.70256549  0.03174837]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-367.16983 1140.203   1411.2098 ]
[  34.8142799  -461.58314597  -10.73893309]
[ 0.   0.  -9.8]
transform [[ 0.70144898  0.70507663 -0.10409767]
 [ 0.0507504   0.09627399  0.99406028]
 [ 0.7109105  -0.70256549  0.03174837]]
transform [[ 0.70144898  0.70507663 -0.10409767]
 [ 0.0507504   0.09627399  0.99406028]
 [ 0.7109105  -0.70256549  0.03174837]]
transform [[ 0.70144898  0.70507663 -0.10409767]
 [ 0.0507504   0.09627399  0.99406028]
 [ 0.7109105  -0.70256549  0.03174837]]
support
[-0.12680462  1.21089584  0.03867367]
[  399.47593587  1493.96551798 -1017.28856423]
[-299.91315233  -53.3467585   348.7012832 ]
[ 1.02015718 -9.74179072 -0.31113398]
zmp_s [        0.          -8194184.18984429 -11523704.41671929]
transform [[ 0.70144898  0.0507504   0.7109105 ]
 [ 0.70507663  0.09627399 -0.70256549]
 [-0.10409767  0.99406028  0.03174837]]
zmp [-8608180.62129517  7307270.25963037 -8511371.79425192]
d1:21976386.47692, d2:0.05940, d3:10501026.51694
transform [[ 0.97377789  0.17907923 -0.14031154]
 [ 0.09311211  0.24900693  0.96401542]
 [ 0.20757376 -0.95180154  0.22580296]]
planes
[[ 0.97377789  0.17907923 -0.14031154]
 [ 0.09311211  0.24900693  0.96401542]
 [ 0.20757376 -0.95180154  0.22580296]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-367.16983 1140.203   1411.2098 ]
[  34.8142799  -461.58314597  -10.73893309]
[ 0.   0.  -9.8]
transform [[ 0.97377789  0.17907923 -0.14031154]
 [ 0.09311211  0.24900693  0.96401542]
 [ 0.20757376 -0.95180154  0.22580296]]
transform [[ 0.97377789  0.17907923 -0.14031154]
 [ 0.09311211  0.24900693  0.96401542]
 [ 0.20757376 -0.95180154  0.22580296]]
transform [[ 0.97377789  0.17907923 -0.14031154]
 [ 0.09311211  0.24900693  0.96401542]
 [ 0.20757376 -0.95180154  0.22580296]]
support
[-0.17091786  1.17429727  0.27505763]
[-351.36420625 1610.15853942 -842.80643734]
[ -47.25178423 -122.04826678  444.13719647]
[ 1.37505308 -9.44735116 -2.21286899]
zmp_s [       0.         32113367.66158968 -1387547.33855546]
transform [[ 0.97377789  0.09311211  0.20757376]
 [ 0.17907923  0.24900693 -0.95180154]
 [-0.14031154  0.96401542  0.22580296]]
zmp [ 2702125.04374136  9317120.68899729 30644469.45700661]
d1:63648608.71930, d2:0.05940, d3:15150488.21071
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-252.6946330363319 steps:342[00m
[RDDPG] Resetting Environment
transform [[ 0.74694836  0.64514655 -0.16079207]
 [ 0.12048126  0.10649727  0.98698664]
 [ 0.65387487 -0.7566005   0.0018199 ]]
planes
[[ 0.74694836  0.64514655 -0.16079207]
 [ 0.12048126  0.10649727  0.98698664]
 [ 0.65387487 -0.7566005   0.0018199 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 490.19943 -531.3842   668.76587]
[ -32.00114256 -430.1861285     2.42193297]
[ 0.   0.  -9.8]
transform [[ 0.74694836  0.64514655 -0.16079207]
 [ 0.12048126  0.10649727  0.98698664]
 [ 0.65387487 -0.7566005   0.0018199 ]]
transform [[ 0.74694836  0.64514655 -0.16079207]
 [ 0.12048126  0.10649727  0.98698664]
 [ 0.65387487 -0.7566005   0.0018199 ]]
transform [[ 0.74694836  0.64514655 -0.16079207]
 [ 0.12048126  0.10649727  0.98698664]
 [ 0.65387487 -0.7566005   0.0018199 ]]
support
[-0.19586583  1.20227922  0.00221688]
[-84.19927731 662.53185561 723.79174182]
[-301.82572473  -47.2787688   304.55870416]
[ 1.57576226 -9.67246904 -0.01783501]
zmp_s [        0.          11423588.34072438 -19870751.14132938]
transform [[ 0.74694836  0.12048126  0.65387487]
 [ 0.64514655  0.10649727 -0.7566005 ]
 [-0.16079207  0.98698664  0.0018199 ]]
zmp [-11616656.58271451  16250801.15140294  11238766.27862379]
d1:34198355.75773, d2:0.05940, d3:16075944.68051
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-192.47755049685026 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-172.72336925786547 steps:345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-105.06940624516764 steps:346[00m
[RDDPG] Resetting Environment
transform [[ 0.68821841 -0.71931285  0.09457483]
 [-0.07177961  0.06220822  0.99547869]
 [-0.72194391 -0.69189537 -0.00881915]]
planes
[[ 0.68821841 -0.71931285  0.09457483]
 [-0.07177961  0.06220822  0.99547869]
 [-0.72194391 -0.69189537 -0.00881915]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 490.19943 -531.3842   668.76587]
[ -32.00114256 -430.1861285     2.42193297]
[ 0.   0.  -9.8]
transform [[ 0.68821841 -0.71931285  0.09457483]
 [-0.07177961  0.06220822  0.99547869]
 [-0.72194391 -0.69189537 -0.00881915]]
transform [[ 0.68821841 -0.71931285  0.09457483]
 [-0.07177961  0.06220822  0.99547869]
 [-0.72194391 -0.69189537 -0.00881915]]
transform [[ 0.68821841 -0.71931285  0.09457483]
 [-0.07177961  0.06220822  0.99547869]
 [-0.72194391 -0.69189537 -0.00881915]]
support
[ 0.11520455  1.21262365 -0.01074288]
[782.84418892 597.49938123   7.86783425]
[287.64368698 -22.05310133 320.72545946]
[-0.92683335 -9.75569116  0.08642765]
zmp_s [        0.          -9737659.28415034 -20792830.04011871]
transform [[ 0.68821841 -0.07177961 -0.72194391]
 [-0.71931285  0.06220822 -0.69189537]
 [ 0.09457483  0.99547869 -0.00881915]]
zmp [15710222.49414    13780700.29029337 -9510257.26033675]
d1:34983646.34341, d2:0.05940, d3:15425225.49470
transform [[ 0.43701875  0.52624023 -0.72944218]
 [ 0.33464879  0.65763378  0.67492825]
 [ 0.83488017 -0.53906316  0.11129258]]
planes
[[ 0.43701875  0.52624023 -0.72944218]
 [ 0.33464879  0.65763378  0.67492825]
 [ 0.83488017 -0.53906316  0.11129258]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 245.81923 -529.94635  271.36404]
[ 232.6539834  -249.43573456 -107.24907851]
[ 0.   0.  -9.8]
transform [[ 0.43701875  0.52624023 -0.72944218]
 [ 0.33464879  0.65763378  0.67492825]
 [ 0.83488017 -0.53906316  0.11129258]]
transform [[ 0.43701875  0.52624023 -0.72944218]
 [ 0.33464879  0.65763378  0.67492825]
 [ 0.83488017 -0.53906316  0.11129258]]
transform [[ 0.43701875  0.52624023 -0.72944218]
 [ 0.33464879  0.65763378  0.67492825]
 [ 0.83488017 -0.53906316  0.11129258]]
support
[-0.88855628  0.82215116  0.13556896]
[-369.39585595  -83.09625619  521.10495653]
[  48.64303681 -158.56542443  316.76378569]
[ 7.14853336 -6.61429683 -1.09066727]
zmp_s [       0.         -1591887.08335722 -3475850.20224686]
transform [[ 0.43701875  0.33464879  0.83488017]
 [ 0.52624023  0.65763378 -0.53906316]
 [-0.72944218  0.67492825  0.11129258]]
zmp [-3434641.50193016   826824.05635095 -1461245.8907935 ]
d1:5873667.25212, d2:0.05940, d3:2257335.46443
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-349.76772166001007 steps:349[00m
[RDDPG] Resetting Environment
transform [[ 0.02352595  0.01563592 -0.99960101]
 [ 0.70847917 -0.70570928  0.00563548]
 [-0.70533955 -0.70832902 -0.02768021]]
planes
[[ 0.02352595  0.01563592 -0.99960101]
 [ 0.70847917 -0.70570928  0.00563548]
 [-0.70533955 -0.70832902 -0.02768021]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 245.81923 -529.94635  271.36404]
[ 232.6539834  -249.43573456 -107.24907851]
[ 0.   0.  -9.8]
transform [[ 0.02352595  0.01563592 -0.99960101]
 [ 0.70847917 -0.70570928  0.00563548]
 [-0.70533955 -0.70832902 -0.02768021]]
transform [[ 0.02352595  0.01563592 -0.99960101]
 [ 0.70847917 -0.70570928  0.00563548]
 [-0.70533955 -0.70832902 -0.02768021]]
transform [[ 0.02352595  0.01563592 -0.99960101]
 [ 0.70847917 -0.70570928  0.00563548]
 [-0.70533955 -0.70832902 -0.02768021]]
support
[-1.21764517  0.00686476 -0.03371812]
[-273.75883659  549.67512662  194.47894273]
[108.77953717 340.25521194  15.55119021]
[ 9.79608986 -0.05522774  0.27126601]
zmp_s [       0.          6596078.53041369 -4474731.72111718]
transform [[ 0.02352595  0.70847917 -0.70533955]
 [ 0.01563592 -0.70570928 -0.70832902]
 [-0.99960101  0.00563548 -0.02768021]]
zmp [ 7829389.4791946  -1485331.47775735   161033.58799543]
d1:9035695.83965, d2:0.05940, d3:2260989.91699
transform [[ 0.22706412 -0.18877016 -0.95540971]
 [ 0.67151922 -0.68017346  0.29398316]
 [-0.70533955 -0.70832902 -0.02768021]]
planes
[[ 0.22706412 -0.18877016 -0.95540971]
 [ 0.67151922 -0.68017346  0.29398316]
 [-0.70533955 -0.70832902 -0.02768021]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 245.81923 -529.94635  271.36404]
[ 232.6539834  -249.43573456 -107.24907851]
[ 0.   0.  -9.8]
transform [[ 0.22706412 -0.18877016 -0.95540971]
 [ 0.67151922 -0.68017346  0.29398316]
 [-0.70533955 -0.70832902 -0.02768021]]
transform [[ 0.22706412 -0.18877016 -0.95540971]
 [ 0.67151922 -0.68017346  0.29398316]
 [-0.70533955 -0.70832902 -0.02768021]]
transform [[ 0.22706412 -0.18877016 -0.95540971]
 [ 0.67151922 -0.68017346  0.29398316]
 [-0.70533955 -0.70832902 -0.02768021]]
support
[-1.16381437  0.35811006 -0.03371812]
[-103.40905784  605.30423738  194.47894273]
[202.38020556 294.36176406  15.55119021]
[ 9.36301512 -2.88103498  0.27126601]
zmp_s [       0.          6596074.06851477 -4474735.07371577]
transform [[ 0.22706412  0.67151922 -0.70533955]
 [-0.18877016 -0.68017346 -0.70832902]
 [-0.95540971  0.29398316 -0.02768021]]
zmp [ 7585598.14034224 -1316889.78146141  2062996.29278874]
d1:9890514.29646, d2:0.05940, d3:3440744.22388
transform [[ 0.94261104 -0.24717602  0.22447385]
 [-0.18661836  0.16746853  0.9680537 ]
 [-0.27687198 -0.95438898  0.11173009]]
planes
[[ 0.94261104 -0.24717602  0.22447385]
 [-0.18661836  0.16746853  0.9680537 ]
 [-0.27687198 -0.95438898  0.11173009]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 245.81923 -529.94635  271.36404]
[ 232.6539834  -249.43573456 -107.24907851]
[ 0.   0.  -9.8]
transform [[ 0.94261104 -0.24717602  0.22447385]
 [-0.18661836  0.16746853  0.9680537 ]
 [-0.27687198 -0.95438898  0.11173009]]
transform [[ 0.94261104 -0.24717602  0.22447385]
 [-0.18661836  0.16746853  0.9680537 ]
 [-0.27687198 -0.95438898  0.11173009]]
transform [[ 0.94261104 -0.24717602  0.22447385]
 [-0.18661836  0.16746853  0.9680537 ]
 [-0.27687198 -0.95438898  0.11173009]]
support
[0.2734386  1.17921641 0.13610191]
[423.6160807  128.07124797 468.03402738]
[ 256.88213194 -189.01300798  161.66039712]
[-2.19984372 -9.48692625 -1.09495489]
zmp_s [        0.         -23087415.28133995   6107000.38460696]
transform [[ 0.94261104 -0.18661836 -0.27687198]
 [-0.24717602  0.16746853 -0.95438898]
 [ 0.22447385  0.9680537   0.11173009]]
zmp [  2617678.24420044  -9694869.41016778 -21667522.04244274]
d1:46679893.86727, d2:0.05940, d3:10956010.17149
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-520.4023915179457 steps:353[00m
[RDDPG] Resetting Environment
transform [[ 0.69356596  0.69937944  0.17272756]
 [-0.10727229 -0.13683037  0.98476911]
 [ 0.71236163 -0.70153111 -0.01987685]]
planes
[[ 0.69356596  0.69937944  0.17272756]
 [-0.10727229 -0.13683037  0.98476911]
 [ 0.71236163 -0.70153111 -0.01987685]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-25.210953 675.10565  494.83408 ]
[ -25.48090017 -422.39091875   10.82794007]
[ 0.   0.  -9.8]
transform [[ 0.69356596  0.69937944  0.17272756]
 [-0.10727229 -0.13683037  0.98476911]
 [ 0.71236163 -0.70153111 -0.01987685]]
transform [[ 0.69356596  0.69937944  0.17272756]
 [-0.10727229 -0.13683037  0.98476911]
 [ 0.71236163 -0.70153111 -0.01987685]]
transform [[ 0.69356596  0.69937944  0.17272756]
 [-0.10727229 -0.13683037  0.98476911]
 [ 0.71236163 -0.70153111 -0.01987685]]
support
[ 0.21040482  1.19957797 -0.02421261]
[ 540.14103683  397.62678792 -501.40267461]
[-311.21392745   71.19232301  277.95353005]
[-1.69273004 -9.65073724  0.19479308]
zmp_s [       0.         -2603254.4682402  -9585300.69614234]
transform [[ 0.69356596 -0.10727229  0.71236163]
 [ 0.69937944 -0.13683037 -0.70153111]
 [ 0.17272756  0.98476911 -0.01987685]]
zmp [-6548943.39669112  7080590.94214378 -2373079.03719794]
d1:13850500.70633, d2:0.05940, d3:5844342.68135
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-252.97930110955198 steps:355[00m
[RDDPG] Resetting Environment
transform [[ 0.71025401  0.70082575  0.06620049]
 [-0.04194076 -0.05174593  0.99777919]
 [ 0.70269501 -0.7114532  -0.00735959]]
planes
[[ 0.71025401  0.70082575  0.06620049]
 [-0.04194076 -0.05174593  0.99777919]
 [ 0.70269501 -0.7114532  -0.00735959]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 316.61285  -68.41969 -730.8944 ]
[-26.1694254  -22.92951955  13.45509467]
[ 0.   0.  -9.8]
transform [[ 0.71025401  0.70082575  0.06620049]
 [-0.04194076 -0.05174593  0.99777919]
 [ 0.70269501 -0.7114532  -0.00735959]]
transform [[ 0.71025401  0.70082575  0.06620049]
 [-0.04194076 -0.05174593  0.99777919]
 [ 0.70269501 -0.7114532  -0.00735959]]
transform [[ 0.71025401  0.70082575  0.06620049]
 [-0.04194076 -0.05174593  0.99777919]
 [ 0.70269501 -0.7114532  -0.00735959]]
support
[ 0.08064088  1.21542596 -0.00896494]
[ 128.53970152 -739.00977533  276.53876349]
[-33.76580335  15.70928825  -2.17486859]
[-0.64876478 -9.77823607  0.07212395]
zmp_s [       0.         -2278923.5454245  -5166637.56054684]
transform [[ 0.71025401 -0.04194076  0.70269501]
 [ 0.70082575 -0.05174593 -0.7114532 ]
 [ 0.06620049  0.99777919 -0.00735959]]
zmp [-3534990.65791161  3793745.82960911 -2235838.17360945]
d1:7525365.49932, d2:0.05940, d3:3738772.70577
transform [[ 0.18357493  0.97215408 -0.14565982]
 [-0.0367265  -0.14129163 -0.98928654]
 [-0.98231941  0.18695778  0.00976622]]
planes
[[ 0.18357493  0.97215408 -0.14565982]
 [-0.0367265  -0.14129163 -0.98928654]
 [-0.98231941  0.18695778  0.00976622]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 125.03005  -995.2543     17.730131]
[1157.97935269 -856.31854005 -841.1286264 ]
[ 0.   0.  -9.8]
transform [[ 0.18357493  0.97215408 -0.14565982]
 [-0.0367265  -0.14129163 -0.98928654]
 [-0.98231941  0.18695778  0.00976622]]
transform [[ 0.18357493  0.97215408 -0.14565982]
 [-0.0367265  -0.14129163 -0.98928654]
 [-0.98231941  0.18695778  0.00976622]]
transform [[ 0.18357493  0.97215408 -0.14565982]
 [-0.0367265  -0.14129163 -0.98928654]
 [-0.98231941  0.18695778  0.00976622]]
support
[-0.17743277 -1.2050808   0.01189654]
[-947.17068712  118.48900474 -308.71681719]
[ -497.37894113   910.57934126 -1305.81565745]
[ 1.42746623  9.69500811 -0.09570896]
zmp_s [        0.         -55393794.60985926  12499014.10701468]
transform [[ 0.18357493 -0.0367265  -0.98231941]
 [ 0.97215408 -0.14129163  0.18695778]
 [-0.14565982 -0.98928654  0.00976622]]
zmp [-10243603.7703031   10163467.59872004  54922403.63744595]
d1:104676655.09973, d2:0.05940, d3:34948912.55984
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-82.98723871676228 steps:358[00m
[RDDPG] Resetting Environment
transform [[ 0.71647137  0.69473237  0.06337001]
 [-0.03356343 -0.05640465  0.99784368]
 [ 0.69680864 -0.71705335 -0.01709472]]
planes
[[ 0.71647137  0.69473237  0.06337001]
 [-0.03356343 -0.05640465  0.99784368]
 [ 0.69680864 -0.71705335 -0.01709472]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -4.2955003 -104.19917    975.76654  ]
[ -41.40092183 -479.87227019   -2.8541831 ]
[ 0.   0.  -9.8]
transform [[ 0.71647137  0.69473237  0.06337001]
 [-0.03356343 -0.05640465  0.99784368]
 [ 0.69680864 -0.71705335 -0.01709472]]
transform [[ 0.71647137  0.69473237  0.06337001]
 [-0.03356343 -0.05640465  0.99784368]
 [ 0.69680864 -0.71705335 -0.01709472]]
transform [[ 0.71647137  0.69473237  0.06337001]
 [-0.03356343 -0.05640465  0.99784368]
 [ 0.69680864 -0.71705335 -0.01709472]]
support
[ 0.07719299  1.21550452 -0.02082361]
[-13.63380403 979.68396755  55.04277244]
[-363.22624357   25.60855403  315.2942923 ]
[-0.62102612 -9.77886809  0.16752822]
zmp_s [       0.         22905414.58616846  4886547.48166953]
transform [[ 0.71647137 -0.03356343  0.69680864]
 [ 0.69473237 -0.05640465 -0.71705335]
 [ 0.06337001  0.99784368 -0.01709472]]
zmp [ 2636204.26164125 -4795887.07251707 22772489.10242403]
d1:45135190.86818, d2:0.05940, d3:16844443.55650
transform [[ 0.14092013  0.11349477  0.98349404]
 [-0.70327753 -0.68771607  0.18013138]
 [ 0.69680864 -0.71705335 -0.01709472]]
planes
[[ 0.14092013  0.11349477  0.98349404]
 [-0.70327753 -0.68771607  0.18013138]
 [ 0.69680864 -0.71705335 -0.01709472]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -4.2955003 -104.19917    975.76654  ]
[ -41.40092183 -479.87227019   -2.8541831 ]
[ 0.   0.  -9.8]
transform [[ 0.14092013  0.11349477  0.98349404]
 [-0.70327753 -0.68771607  0.18013138]
 [ 0.69680864 -0.71705335 -0.01709472]]
transform [[ 0.14092013  0.11349477  0.98349404]
 [-0.70327753 -0.68771607  0.18013138]
 [ 0.69680864 -0.71705335 -0.01709472]]
transform [[ 0.14092013  0.11349477  0.98349404]
 [-0.70327753 -0.68771607  0.18013138]
 [ 0.69680864 -0.71705335 -0.01709472]]
support
[ 1.19802478  0.21942365 -0.02082361]
[947.2291968  250.44654362  55.04277244]
[-63.10428779 358.61808028 315.2942923 ]
[-9.63824162 -1.76528748  0.16752822]
zmp_s [       0.         22905385.56538513  4886549.29111922]
transform [[ 0.14092013 -0.70327753  0.69680864]
 [ 0.11349477 -0.68771607 -0.71705335]
 [ 0.98349404  0.18013138 -0.01709472]]
zmp [-12703853.19764872 -19256318.2280587    4042444.44043355]
d1:34280118.59057, d2:0.05940, d3:4710349.79317
transform [[ 0.07518192 -0.01436128  0.99706644]
 [-0.99143875  0.10597143  0.07628393]
 [-0.10675609 -0.9942655  -0.0062712 ]]
planes
[[ 0.07518192 -0.01436128  0.99706644]
 [-0.99143875  0.10597143  0.07628393]
 [-0.10675609 -0.9942655  -0.0062712 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -4.2955003 -104.19917    975.76654  ]
[ -41.40092183 -479.87227019   -2.8541831 ]
[ 0.   0.  -9.8]
transform [[ 0.07518192 -0.01436128  0.99706644]
 [-0.99143875  0.10597143  0.07628393]
 [-0.10675609 -0.9942655  -0.0062712 ]]
transform [[ 0.07518192 -0.01436128  0.99706644]
 [-0.99143875  0.10597143  0.07628393]
 [-0.10675609 -0.9942655  -0.0062712 ]]
transform [[ 0.07518192 -0.01436128  0.99706644]
 [-0.99143875  0.10597143  0.07628393]
 [-0.10675609 -0.9942655  -0.0062712 ]]
support
[ 1.21455774  0.09292384 -0.00763914]
[974.07755863  67.65189865  97.94099092]
[  0.93316923 -10.02399893 481.55814081]
[-9.77125109 -0.74758253  0.06145771]
zmp_s [        0.           9763950.50927392 -19131086.14146968]
transform [[ 0.07518192 -0.99143875 -0.10675609]
 [-0.01436128  0.10597143 -0.9942655 ]
 [ 0.99706644  0.07628393 -0.0062712 ]]
zmp [-7637998.87803479 20056078.62208036   864807.30837153]
d1:27344485.16163, d2:0.05940, d3:4809595.17076
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-413.32688689022143 steps:362[00m
[RDDPG] Resetting Environment
transform [[ 0.73984879  0.65902454 -0.13531648]
 [ 0.08506349  0.10788553  0.9905175 ]
 [ 0.66737407 -0.74434358  0.02376003]]
planes
[[ 0.73984879  0.65902454 -0.13531648]
 [ 0.08506349  0.10788553  0.9905175 ]
 [ 0.66737407 -0.74434358  0.02376003]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[111.56007 504.16333 178.09239]
[ -21.39755604 -166.63204509   13.76753912]
[ 0.   0.  -9.8]
transform [[ 0.73984879  0.65902454 -0.13531648]
 [ 0.08506349  0.10788553  0.9905175 ]
 [ 0.66737407 -0.74434358  0.02376003]]
transform [[ 0.73984879  0.65902454 -0.13531648]
 [ 0.08506349  0.10788553  0.9905175 ]
 [ 0.66737407 -0.74434358  0.02376003]]
transform [[ 0.73984879  0.65902454 -0.13531648]
 [ 0.08506349  0.10788553  0.9905175 ]
 [ 0.66737407 -0.74434358  0.02376003]]
support
[-0.16483322  1.20658027  0.02894284]
[ 390.69475035  240.28524857 -296.58696023]
[-127.50853718   -6.16034935  110.07843582]
[ 1.32610147 -9.70707147 -0.23284833]
zmp_s [       0.          9526896.0227342  -6257902.11157549]
transform [[ 0.73984879  0.08506349  0.66737407]
 [ 0.65902454  0.10788553 -0.74434358]
 [-0.13531648  0.9905175   0.02376003]]
zmp [-3365970.56003155  5685843.50010118  9287869.23770599]
d1:20006055.90448, d2:0.05940, d3:8505995.36106
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:12.278098689646491 steps:364[00m
[RDDPG] Resetting Environment
transform [[ 0.2365538  -0.25239795  0.93826306]
 [-0.67387223  0.65305227  0.34557059]
 [-0.69995612 -0.71401548 -0.01560199]]
planes
[[ 0.2365538  -0.25239795  0.93826306]
 [-0.67387223  0.65305227  0.34557059]
 [-0.69995612 -0.71401548 -0.01560199]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[111.56007 504.16333 178.09239]
[ -21.39755604 -166.63204509   13.76753912]
[ 0.   0.  -9.8]
transform [[ 0.2365538  -0.25239795  0.93826306]
 [-0.67387223  0.65305227  0.34557059]
 [-0.69995612 -0.71401548 -0.01560199]]
transform [[ 0.2365538  -0.25239795  0.93826306]
 [-0.67387223  0.65305227  0.34557059]
 [-0.69995612 -0.71401548 -0.01560199]]
transform [[ 0.2365538  -0.25239795  0.93826306]
 [-0.67387223  0.65305227  0.34557059]
 [-0.69995612 -0.71401548 -0.01560199]]
support
[ 1.14292751  0.42095032 -0.01900527]
[  66.23767712  315.61127018 -440.84617075]
[ 49.91348744 -89.64255984 133.74040958]
[-9.19497797 -3.38659182  0.1528995 ]
zmp_s [       0.          7175745.82054063 -2858041.51061975]
transform [[ 0.2365538  -0.67387223 -0.69995612]
 [-0.25239795  0.65305227 -0.71401548]
 [ 0.93826306  0.34557059 -0.01560199]]
zmp [-2835032.21160189  6726822.99209295  2524317.8806506 ]
d1:10436687.32174, d2:0.05940, d3:2719327.18906
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-313.51565800262665 steps:366[00m
[RDDPG] Resetting Environment
transform [[ 0.6931569  -0.70229203 -0.1622327 ]
 [ 0.14232172 -0.08729175  0.98596388]
 [-0.70659614 -0.70651692  0.03944452]]
planes
[[ 0.6931569  -0.70229203 -0.1622327 ]
 [ 0.14232172 -0.08729175  0.98596388]
 [-0.70659614 -0.70651692  0.03944452]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[111.56007 504.16333 178.09239]
[ -21.39755604 -166.63204509   13.76753912]
[ 0.   0.  -9.8]
transform [[ 0.6931569  -0.70229203 -0.1622327 ]
 [ 0.14232172 -0.08729175  0.98596388]
 [-0.70659614 -0.70651692  0.03944452]]
transform [[ 0.6931569  -0.70229203 -0.1622327 ]
 [ 0.14232172 -0.08729175  0.98596388]
 [-0.70659614 -0.70651692  0.03944452]]
transform [[ 0.6931569  -0.70229203 -0.1622327 ]
 [ 0.14232172 -0.08729175  0.98596388]
 [-0.70659614 -0.70651692  0.03944452]]
support
[-0.19762071  1.20103337  0.0480486 ]
[-305.63366568  147.46078477 -428.00306654]
[ 99.95894782  25.07456293 133.39084393]
[ 1.58988043 -9.66244603 -0.38655631]
zmp_s [       0.         -6876377.94980956 -8593038.7559793 ]
transform [[ 0.6931569   0.14232172 -0.70659614]
 [-0.70229203 -0.08729175 -0.70651692]
 [-0.1622327   0.98596388  0.03944452]]
zmp [ 5093150.04014017  6671378.38616305 -7118808.58898704]
d1:18200391.14704, d2:0.05940, d3:8231839.49175
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-250.68835541899057 steps:368[00m
[RDDPG] Resetting Environment
transform [[ 0.69449133  0.71640694 -0.06665592]
 [ 0.07697921  0.01812623  0.9968679 ]
 [ 0.71537137 -0.69744718 -0.04255993]]
planes
[[ 0.69449133  0.71640694 -0.06665592]
 [ 0.07697921  0.01812623  0.9968679 ]
 [ 0.71537137 -0.69744718 -0.04255993]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-423.53244  766.54083 1306.3407 ]
[ -76.57884331 -690.57108675   46.8278459 ]
[ 0.   0.  -9.8]
transform [[ 0.69449133  0.71640694 -0.06665592]
 [ 0.07697921  0.01812623  0.9968679 ]
 [ 0.71537137 -0.69744718 -0.04255993]]
transform [[ 0.69449133  0.71640694 -0.06665592]
 [ 0.07697921  0.01812623  0.9968679 ]
 [ 0.71537137 -0.69744718 -0.04255993]]
transform [[ 0.69449133  0.71640694 -0.06665592]
 [ 0.07697921  0.01812623  0.9968679 ]
 [ 0.71537137 -0.69744718 -0.04255993]]
support
[-0.08119565  1.21431589 -0.05184358]
[ 167.94022725 1283.54040617 -893.20249716]
[-551.03461568   28.26874816  424.86155551]
[ 0.65322801 -9.76930537  0.41708734]
zmp_s [      0.         6804694.30773608 -411913.75164052]
transform [[ 0.69449133  0.07697921  0.71537137]
 [ 0.71640694  0.01812623 -0.69744718]
 [-0.06665592  0.9968679  -0.04255993]]
zmp [ 229148.65319849  410631.53089416 6800912.31316863]
d1:13542385.29976, d2:0.05940, d3:4362884.36587
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-314.5914996509505 steps:370[00m
[RDDPG] Resetting Environment
transform [[ 0.71688437  0.6838904   0.13553911]
 [-0.11234806 -0.07854909  0.99055946]
 [ 0.68808049 -0.72534412  0.02052314]]
planes
[[ 0.71688437  0.6838904   0.13553911]
 [-0.11234806 -0.07854909  0.99055946]
 [ 0.68808049 -0.72534412  0.02052314]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  32.4578  -206.75174 1129.1304 ]
[ -55.91372653 -347.71918308   -0.59343907]
[ 0.   0.  -9.8]
transform [[ 0.71688437  0.6838904   0.13553911]
 [-0.11234806 -0.07854909  0.99055946]
 [ 0.68808049 -0.72534412  0.02052314]]
transform [[ 0.71688437  0.6838904   0.13553911]
 [-0.11234806 -0.07854909  0.99055946]
 [ 0.68808049 -0.72534412  0.02052314]]
transform [[ 0.71688437  0.6838904   0.13553911]
 [-0.11234806 -0.07854909  0.99055946]
 [ 0.68808049 -0.72534412  0.02052314]]
support
[0.16510442 1.20663138 0.02499988]
[  34.91429128 1131.06435839  195.47303993]
[-277.96592309   33.00698666  213.7307418 ]
[-1.32828332 -9.7074827  -0.20112677]
zmp_s [        0.         -29111468.66949643   2956490.29782873]
transform [[ 0.71688437 -0.11234806  0.68808049]
 [ 0.6838904  -0.07854909 -0.72534412]
 [ 0.13553911  0.99055946  0.02052314]]
zmp [  5304920.45966087    142206.42893089 -28775964.18326479]
d1:57382153.65336, d2:0.05940, d3:19657520.67935
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-364.5051080050491 steps:372[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620123693.608748494, 200.188000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620123693.609591014, 200.188000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620123694.611189231, 200.188000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620123694.611338587, 200.188000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620123695.613018064, 200.188000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620123695.613214796, 200.188000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620123696.618684163, 200.188000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620123696.618849394, 200.188000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 959, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:53:06.264493: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:53:06.264529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620123792.795944252, 0.965000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620123792.798473050, 0.966000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620123792.798627808, 0.966000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620123794.499837864, 2.118000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620123795.703418194, 3.006000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620123797.102123380, 3.800000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620123798.257505307, 4.602000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71123111 -0.70250982 -0.02510522]
 [ 0.03412984 -0.00116209  0.99941671]
 [-0.7021293  -0.71167314  0.02315004]]
planes
[[ 0.71123111 -0.70250982 -0.02510522]
 [ 0.03412984 -0.00116209  0.99941671]
 [-0.7021293  -0.71167314  0.02315004]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71123111 -0.70250982 -0.02510522]
 [ 0.03412984 -0.00116209  0.99941671]
 [-0.7021293  -0.71167314  0.02315004]]
transform [[ 0.71123111 -0.70250982 -0.02510522]
 [ 0.03412984 -0.00116209  0.99941671]
 [-0.7021293  -0.71167314  0.02315004]]
transform [[ 0.71123111 -0.70250982 -0.02510522]
 [ 0.03412984 -0.00116209  0.99941671]
 [-0.7021293  -0.71167314  0.02315004]]
support
[-0.03058146  1.21742067  0.02819978]
[-1.63839310e-10  1.03238446e-08 -1.39065241e-08]
[-1.63839310e-10  1.03238446e-08 -1.39065241e-08]
[ 0.24603119 -9.79428375 -0.22687037]
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 88, in train
    validate_reward = self.evaluate(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/evaluator.py", line 37, in __call__
    observation, reward, done, info = env.step(
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 44, in step
    self.stability += 5e-6 * self.quadruped.get_stability_reward()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 1193, in get_stability_reward
    self.compute_reward.stability_reward(
  File "/home/shandilya/Desktop/CNS/DDP/src/reward/__init__.py", line 22, in stability_reward
    zmp = self.zmp(com, force, torque, v_real, v_exp, eta)
  File "/home/shandilya/Desktop/CNS/DDP/src/reward/zmp.py", line 75, in __call__
    print('v_real {}'.format(self.v_real))
AttributeError: 'ZMP' object has no attribute 'v_real'
2021-05-04 15:55:07.693317: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 15:55:07.693350: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620123914.746141162, 1.369000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620123914.748358298, 1.369000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620123914.748620172, 1.369000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620123916.273026223, 2.466000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620123917.479799496, 3.317000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620123918.556099219, 4.117000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620123919.105473002, 4.517000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71106696 -0.70249778 -0.02967803]
 [ 0.03745319 -0.00430636  0.99928916]
 [-0.70212615 -0.71167302  0.02324867]]
planes
[[ 0.71106696 -0.70249778 -0.02967803]
 [ 0.03745319 -0.00430636  0.99928916]
 [-0.70212615 -0.71167302  0.02324867]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71106696 -0.70249778 -0.02967803]
 [ 0.03745319 -0.00430636  0.99928916]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71106696 -0.70249778 -0.02967803]
 [ 0.03745319 -0.00430636  0.99928916]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71106696 -0.70249778 -0.02967803]
 [ 0.03745319 -0.00430636  0.99928916]
 [-0.70212615 -0.71167302  0.02324867]]
support
[-0.03615173  1.2172653   0.02831993]
[-2.11088490e-10  1.03243598e-08 -1.39055050e-08]
[-2.11088490e-10  1.03243598e-08 -1.39055050e-08]
[ 0.29084469 -9.79303372 -0.22783695]
v_real [ 4.9248119e-03  7.4965326e-05 -3.0725223e-01]
zmp_s [ 0.00000000e+00  7.49553263e+03 -3.07252238e+07]
transform [[ 0.71106696  0.03745319 -0.70212615]
 [-0.70249778 -0.00430636 -0.71167302]
 [-0.02967803  0.99928916  0.02324867]]
zmp [21573263.7019393  21866280.59241233  -706830.34683648]
d1:44502421.65245, d2:0.05940, d3:14269921.88037
eta 23760000.0
transform [[ 0.71106529 -0.70249748 -0.02972338]
 [ 0.03748545 -0.00433824  0.99928772]
 [-0.70212615 -0.71167302  0.02324867]]
planes
[[ 0.71106529 -0.70249748 -0.02972338]
 [ 0.03748545 -0.00433824  0.99928772]
 [-0.70212615 -0.71167302  0.02324867]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71106529 -0.70249748 -0.02972338]
 [ 0.03748545 -0.00433824  0.99928772]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71106529 -0.70249748 -0.02972338]
 [ 0.03748545 -0.00433824  0.99928772]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71106529 -0.70249748 -0.02972338]
 [ 0.03748545 -0.00433824  0.99928772]
 [-0.70212615 -0.71167302  0.02324867]]
support
[-0.03620697  1.21726355  0.02831993]
[-2.11555678e-10  1.03243494e-08 -1.39055050e-08]
[-2.11555678e-10  1.03243494e-08 -1.39055050e-08]
[ 0.2912891  -9.7930197  -0.22783695]
v_real [ 4.9248119e-03  7.4965326e-05 -3.0725223e-01]
zmp_s [ 0.00000000e+00  7.49553263e+03 -3.07252238e+07]
transform [[ 0.71106529  0.03748545 -0.70212615]
 [-0.70249748 -0.00433824 -0.71167302]
 [-0.02972338  0.99928772  0.02324867]]
zmp [21573263.94380863 21866280.35347492  -706830.35755892]
d1:44502421.65905, d2:0.05940, d3:14269921.89073
eta 23760000.0
transform [[ 0.71086597 -0.70246649 -0.03479132]
 [ 0.04109145 -0.0079012   0.99912423]
 [-0.70212615 -0.71167302  0.02324867]]
planes
[[ 0.71086597 -0.70246649 -0.03479132]
 [ 0.04109145 -0.0079012   0.99912423]
 [-0.70212615 -0.71167302  0.02324867]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71086597 -0.70246649 -0.03479132]
 [ 0.04109145 -0.0079012   0.99912423]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71086597 -0.70246649 -0.03479132]
 [ 0.04109145 -0.0079012   0.99912423]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71086597 -0.70246649 -0.03479132]
 [ 0.04109145 -0.0079012   0.99912423]
 [-0.70212615 -0.71167302  0.02324867]]
support
[-0.04238039  1.2170644   0.02831993]
[-2.63918303e-10  1.03231447e-08 -1.39055050e-08]
[-2.63918303e-10  1.03231447e-08 -1.39055050e-08]
[ 0.34095491 -9.79141744 -0.22783695]
v_real [ 4.9248119e-03  7.4965326e-05 -3.0725223e-01]
zmp_s [ 0.00000000e+00  7.49553263e+03 -3.07252238e+07]
transform [[ 0.71086597  0.04109145 -0.70212615]
 [-0.70246649 -0.0079012  -0.71167302]
 [-0.03479132  0.99912423  0.02324867]]
zmp [21573290.97266429 21866253.64714079  -706831.58304509]
d1:44502422.39503, d2:0.05940, d3:14269923.06444
eta 23760000.0
transform [[ 0.71140784 -0.70250541 -0.01962155]
 [ 0.03029644  0.00276248  0.99953711]
 [-0.70212615 -0.71167302  0.02324867]]
planes
[[ 0.71140784 -0.70250541 -0.01962155]
 [ 0.03029644  0.00276248  0.99953711]
 [-0.70212615 -0.71167302  0.02324867]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71140784 -0.70250541 -0.01962155]
 [ 0.03029644  0.00276248  0.99953711]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71140784 -0.70250541 -0.01962155]
 [ 0.03029644  0.00276248  0.99953711]
 [-0.70212615 -0.71167302  0.02324867]]
transform [[ 0.71140784 -0.70250541 -0.01962155]
 [ 0.03029644  0.00276248  0.99953711]
 [-0.70212615 -0.71167302  0.02324867]]
support
[-0.02390163  1.21756734  0.02831993]
[-1.07191242e-10  1.03259603e-08 -1.39055050e-08]
[-1.07191242e-10  1.03259603e-08 -1.39055050e-08]
[ 0.19229124 -9.79546368 -0.22783695]
v_real [ 4.9248119e-03  7.4965326e-05 -3.0725223e-01]
zmp_s [ 0.00000000e+00  7.49553263e+03 -3.07252238e+07]
transform [[ 0.71140784  0.03029644 -0.70212615]
 [-0.70250541  0.00276248 -0.71167302]
 [-0.01962155  0.99953711  0.02324867]]
zmp [21573210.05834055 21866333.57712691  -706828.48827924]
d1:44502420.25323, d2:0.05940, d3:14269919.91011
eta 23760000.0
transform [[ 0.32771316  0.32914352  0.88558948]
 [-0.57194674 -0.67695963  0.46325228]
 [ 0.75198478 -0.65832388 -0.03359604]]
planes
[[ 0.32771316  0.32914352  0.88558948]
 [-0.57194674 -0.67695963  0.46325228]
 [ 0.75198478 -0.65832388 -0.03359604]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 22.672543 217.1064    47.807972]
[  8.04652735 -60.6898007   35.46564822]
[ 0.   0.  -9.8]
transform [[ 0.32771316  0.32914352  0.88558948]
 [-0.57194674 -0.67695963  0.46325228]
 [ 0.75198478 -0.65832388 -0.03359604]]
transform [[ 0.32771316  0.32914352  0.88558948]
 [-0.57194674 -0.67695963  0.46325228]
 [ 0.75198478 -0.65832388 -0.03359604]]
transform [[ 0.32771316  0.32914352  0.88558948]
 [-0.57194674 -0.67695963  0.46325228]
 [ 0.75198478 -0.65832388 -0.03359604]]
support
[ 1.07876418  0.56430205 -0.04092438]
[ 121.22749312 -137.79260372 -127.48307966]
[14.06930302 52.91190244 44.81290621]
[-8.67877691 -4.53987231  0.32924114]
v_real [ 0.14531669 -0.02708075  0.03742146]
zmp_s [      0.         -643437.032125    889135.64795236]
transform [[ 0.32771316 -0.57194674  0.75198478]
 [ 0.32914352 -0.67695963 -0.65832388]
 [ 0.88558948  0.46325228 -0.03359604]]
zmp [1036628.18324492 -149758.33551382 -327945.10214292]
d1:1528184.46654, d2:0.05940, d3:578663.83818
eta 23760000.0
transform [[ 0.43864363 -0.35616824  0.82506728]
 [ 0.05147358  0.92655766  0.37261429]
 [-0.89718574 -0.1209757   0.42476183]]
planes
[[ 0.43864363 -0.35616824  0.82506728]
 [ 0.05147358  0.92655766  0.37261429]
 [-0.89718574 -0.1209757   0.42476183]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 22.672543 217.1064    47.807972]
[  8.04652735 -60.6898007   35.46564822]
[ 0.   0.  -9.8]
transform [[ 0.43864363 -0.35616824  0.82506728]
 [ 0.05147358  0.92655766  0.37261429]
 [-0.89718574 -0.1209757   0.42476183]]
transform [[ 0.43864363 -0.35616824  0.82506728]
 [ 0.05147358  0.92655766  0.37261429]
 [-0.89718574 -0.1209757   0.42476183]]
transform [[ 0.43864363 -0.35616824  0.82506728]
 [ 0.05147358  0.92655766  0.37261429]
 [-0.89718574 -0.1209757   0.42476183]]
support
[1.0050402  0.4538931  0.51741564]
[-27.93644434 220.1425683  -26.2990779 ]
[ 54.40688349 -42.60340864  15.18721494]
[-8.08565936 -3.65162008 -4.16266595]
v_real [-0.01322414 -0.10200722  0.3283897 ]
zmp_s [       0.         -2423684.58425997  7802540.35021496]
transform [[ 0.43864363  0.05147358 -0.89718574]
 [-0.35616824  0.92655766 -0.1209757 ]
 [ 0.82506728  0.37261429  0.42476183]]
zmp [-7125083.69236495 -3189601.26314689  2411121.81059489]
d1:3420291.95232, d2:0.05940, d3:3738549.55012
eta 23760000.0
transform [[ 0.43873757 -0.35446286  0.82575142]
 [ 0.05066645  0.9272114   0.37109563]
 [-0.89718574 -0.1209757   0.42476183]]
planes
[[ 0.43873757 -0.35446286  0.82575142]
 [ 0.05066645  0.9272114   0.37109563]
 [-0.89718574 -0.1209757   0.42476183]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 22.672543 217.1064    47.807972]
[  8.04652735 -60.6898007   35.46564822]
[ 0.   0.  -9.8]
transform [[ 0.43873757 -0.35446286  0.82575142]
 [ 0.05066645  0.9272114   0.37109563]
 [-0.89718574 -0.1209757   0.42476183]]
transform [[ 0.43873757 -0.35446286  0.82575142]
 [ 0.05066645  0.9272114   0.37109563]
 [-0.89718574 -0.1209757   0.42476183]]
transform [[ 0.43873757 -0.35446286  0.82575142]
 [ 0.05066645  0.9272114   0.37109563]
 [-0.89718574 -0.1209757   0.42476183]]
support
[1.00587357 0.45204316 0.51741564]
[-27.53135857 220.19359613 -26.2990779 ]
[ 54.32840383 -42.70343934  15.18721494]
[-8.09236395 -3.63673715 -4.16266595]
v_real [-0.01322414 -0.10200722  0.3283897 ]
zmp_s [       0.         -2423684.50692126  7802540.35603203]
transform [[ 0.43873757  0.05066645 -0.89718574]
 [-0.35446286  0.9272114  -0.1209757 ]
 [ 0.82575142  0.37109563  0.42476183]]
zmp [-7123127.4588934  -3191185.66077542  2414802.61094244]
d1:3428369.64485, d2:0.05940, d3:3738495.14383
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.68748838 -0.72448426 -0.04982369]
 [ 0.04169979 -0.02911187  0.99870604]
 [-0.72499722 -0.68867642  0.01019677]]
planes
[[ 0.68748838 -0.72448426 -0.04982369]
 [ 0.04169979 -0.02911187  0.99870604]
 [-0.72499722 -0.68867642  0.01019677]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 22.672543 217.1064    47.807972]
[  8.04652735 -60.6898007   35.46564822]
[ 0.   0.  -9.8]
transform [[ 0.68748838 -0.72448426 -0.04982369]
 [ 0.04169979 -0.02911187  0.99870604]
 [-0.72499722 -0.68867642  0.01019677]]
transform [[ 0.68748838 -0.72448426 -0.04982369]
 [ 0.04169979 -0.02911187  0.99870604]
 [-0.72499722 -0.68867642  0.01019677]]
transform [[ 0.68748838 -0.72448426 -0.04982369]
 [ 0.04169979 -0.02911187  0.99870604]
 [-0.72499722 -0.68867642  0.01019677]]
support
[-0.06069179  1.21655499  0.012421  ]
[-144.08503017   42.37117673 -165.46610092]
[47.73367033 37.52208948 36.32355949]
[ 0.48827213 -9.78731922 -0.09992832]
v_real [-0.47073054  1.0230029   0.12022129]
zmp_s [       0.         24306549.45573857  2856457.57109641]
transform [[ 0.68748838  0.04169979 -0.72499722]
 [-0.72448426 -0.02911187 -0.68867642]
 [-0.04982369  0.99870604  0.01019677]]
zmp [-1057345.81010351 -2674784.15455238 24304224.4546834 ]
d1:48405266.92825, d2:0.05940, d3:16666721.75716
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.11766197  0.11883999  0.98591721]
 [-0.70311308  0.71107584 -0.00179993]
 [-0.70127577 -0.69299948  0.16722456]]
planes
[[ 0.11766197  0.11883999  0.98591721]
 [-0.70311308  0.71107584 -0.00179993]
 [-0.70127577 -0.69299948  0.16722456]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 22.672543 217.1064    47.807972]
[  8.04652735 -60.6898007   35.46564822]
[ 0.   0.  -9.8]
transform [[ 0.11766197  0.11883999  0.98591721]
 [-0.70311308  0.71107584 -0.00179993]
 [-0.70127577 -0.69299948  0.16722456]]
transform [[ 0.11766197  0.11883999  0.98591721]
 [-0.70311308  0.71107584 -0.00179993]
 [-0.70127577 -0.69299948  0.16722456]]
transform [[ 0.11766197  0.11883999  0.98591721]
 [-0.70311308  0.71107584 -0.00179993]
 [-0.70127577 -0.69299948  0.16722456]]
support
[ 1.20097651 -0.00219255  0.20370145]
[  75.60332156  138.3517039  -158.35966021]
[ 28.70058765 -48.87650532  42.34589312]
[-9.66198866  0.01763928 -1.63880065]
v_real [0.4045377  1.3765643  0.25561506]
zmp_s [       0.         32707162.83553858  6073415.87650995]
transform [[ 0.11766197 -0.70311308 -0.70127577]
 [ 0.11883999  0.71107584 -0.69299948]
 [ 0.98591721 -0.00179993  0.16722456]]
zmp [-27255973.33937707  19048399.30782514    956753.79654909]
d1:37832893.51051, d2:0.05940, d3:3684623.11263
eta 23760000.0
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:159.52612260819228[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.6211347   0.7283715   0.28925195]
 [-0.22523496 -0.18760285  0.95607239]
 [ 0.75064033 -0.65899938  0.04752808]]
planes
[[ 0.6211347   0.7283715   0.28925195]
 [-0.22523496 -0.18760285  0.95607239]
 [ 0.75064033 -0.65899938  0.04752808]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 20.27278 146.57306 147.71358]
[-35.17103847 -73.25146955   9.51073522]
[ 0.   0.  -9.8]
transform [[ 0.6211347   0.7283715   0.28925195]
 [-0.22523496 -0.18760285  0.95607239]
 [ 0.75064033 -0.65899938  0.04752808]]
transform [[ 0.6211347   0.7283715   0.28925195]
 [-0.22523496 -0.18760285  0.95607239]
 [ 0.75064033 -0.65899938  0.04752808]]
transform [[ 0.6211347   0.7283715   0.28925195]
 [-0.22523496 -0.18760285  0.95607239]
 [ 0.75064033 -0.65899938  0.04752808]]
support
[0.35234683 1.16462161 0.05789543]
[162.07820657 109.16121099 -74.35344738]
[-72.44923646  30.75688293  22.32390021]
[-2.83466914 -9.36950942 -0.46577515]
v_real [0.479733   1.3016616  0.16631065]
zmp_s [       0.         30927480.80363245  3951541.41658628]
transform [[ 0.6211347  -0.22523496  0.75064033]
 [ 0.7283715  -0.18760285 -0.65899938]
 [ 0.28925195  0.95607239  0.04752808]]
zmp [-3999763.40043664 -8406146.83169732 29756719.65545464]
d1:59452890.48344, d2:0.05940, d3:20050088.67020
eta 23760000.0
transform [[ 0.10920442 -0.09893226  0.98908383]
 [-0.07804804  0.99110949  0.10775214]
 [-0.99095052 -0.08896306  0.10051206]]
planes
[[ 0.10920442 -0.09893226  0.98908383]
 [-0.07804804  0.99110949  0.10775214]
 [-0.99095052 -0.08896306  0.10051206]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 218.67429 -307.0129   997.7692 ]
[ -76.07026758 -673.66994766  -42.11107893]
[ 0.   0.  -9.8]
transform [[ 0.10920442 -0.09893226  0.98908383]
 [-0.07804804  0.99110949  0.10775214]
 [-0.99095052 -0.08896306  0.10051206]]
transform [[ 0.10920442 -0.09893226  0.98908383]
 [-0.07804804  0.99110949  0.10775214]
 [-0.99095052 -0.08896306  0.10051206]]
transform [[ 0.10920442 -0.09893226  0.98908383]
 [-0.07804804  0.99110949  0.10775214]
 [-0.99095052 -0.08896306  0.10051206]]
support
[1.20483387 0.13125624 0.12243688]
[1041.13108302 -213.83873992  -89.09474474]
[  16.68909314 -666.28110232  131.08094111]
[-9.6930215  -1.05597094 -0.98501824]
v_real [-0.05377333 -0.544913   -1.1254534 ]
zmp_s [        0.         -12947132.74480856 -26740772.41831294]
transform [[ 0.10920442 -0.07804804 -0.99095052]
 [-0.09893226  0.99110949 -0.08896306]
 [ 0.98908383  0.10775214  0.10051206]]
zmp [ 27509280.73779267 -10453085.15366863  -4082851.47508407]
d1:30803200.23972, d2:0.05940, d3:8028774.11331
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-335.36705095436525 steps:3[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.7213921  -0.68032241  0.1294407 ]
 [-0.09827265  0.08445455  0.99156946]
 [-0.68551874 -0.72803086 -0.00593224]]
planes
[[ 0.7213921  -0.68032241  0.1294407 ]
 [-0.09827265  0.08445455  0.99156946]
 [-0.68551874 -0.72803086 -0.00593224]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 218.67429 -307.0129   997.7692 ]
[ -76.07026758 -673.66994766  -42.11107893]
[ 0.   0.  -9.8]
transform [[ 0.7213921  -0.68032241  0.1294407 ]
 [-0.09827265  0.08445455  0.99156946]
 [-0.68551874 -0.72803086 -0.00593224]]
transform [[ 0.7213921  -0.68032241  0.1294407 ]
 [-0.09827265  0.08445455  0.99156946]
 [-0.68551874 -0.72803086 -0.00593224]]
transform [[ 0.7213921  -0.68032241  0.1294407 ]
 [-0.09827265  0.08445455  0.99156946]
 [-0.68551874 -0.72803086 -0.00593224]]
support
[ 0.15767575  1.2078617  -0.00722624]
[495.76960506 941.93915279  67.69054743]
[397.98538442 -91.17492606 542.84991864]
[-1.26851881 -9.7173807   0.05813592]
v_real [-0.07246047  0.02489721 -0.14918713]
zmp_s [       0.           591557.50034214 -3544686.46320607]
transform [[ 0.7213921  -0.09827265 -0.68551874]
 [-0.68032241  0.08445455 -0.72803086]
 [ 0.1294407   0.99156946 -0.00593224]]
zmp [2371815.0796165  2630600.85902408  607598.27110803]
d1:5276077.65149, d2:0.05940, d3:1972991.69895
eta 23760000.0
transform [[ 7.27994144e-01 -6.85544014e-01  7.34815467e-03]
 [-9.41649266e-03  7.18663912e-04  9.99955416e-01]
 [-6.85518742e-01 -7.28030860e-01 -5.93223702e-03]]
planes
[[ 7.27994144e-01 -6.85544014e-01  7.34815467e-03]
 [-9.41649266e-03  7.18663912e-04  9.99955416e-01]
 [-6.85518742e-01 -7.28030860e-01 -5.93223702e-03]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 218.67429 -307.0129   997.7692 ]
[ -76.07026758 -673.66994766  -42.11107893]
[ 0.   0.  -9.8]
transform [[ 7.27994144e-01 -6.85544014e-01  7.34815467e-03]
 [-9.41649266e-03  7.18663912e-04  9.99955416e-01]
 [-6.85518742e-01 -7.28030860e-01 -5.93223702e-03]]
transform [[ 7.27994144e-01 -6.85544014e-01  7.34815467e-03]
 [-9.41649266e-03  7.18663912e-04  9.99955416e-01]
 [-6.85518742e-01 -7.28030860e-01 -5.93223702e-03]]
transform [[ 7.27994144e-01 -6.85544014e-01  7.34815467e-03]
 [-9.41649266e-03  7.18663912e-04  9.99955416e-01]
 [-6.85518742e-01 -7.28030860e-01 -5.93223702e-03]]
support
[ 0.00895102  1.21807689 -0.00722624]
[376.9962241  995.44495735  67.69054743]
[406.14225197 -41.8770286  542.84991864]
[-0.07201192 -9.79956307  0.05813592]
v_real [-0.07246047  0.02489721 -0.14918713]
zmp_s [       0.           591557.44196052 -3544686.36993709]
transform [[ 7.27994144e-01 -9.41649266e-03 -6.85518742e-01]
 [-6.85544014e-01  7.18663912e-04 -7.28030860e-01]
 [ 7.34815467e-03  9.99955416e-01 -5.93223702e-03]]
zmp [2424378.54340537 2581066.19882424  612558.98751506]
d1:5282143.77559, d2:0.05940, d3:1978824.71453
eta 23760000.0
transform [[ 0.99258596 -0.03149058 -0.11739464]
 [ 0.11694843 -0.0156623   0.99301451]
 [-0.03310927 -0.99938136 -0.01186341]]
planes
[[ 0.99258596 -0.03149058 -0.11739464]
 [ 0.11694843 -0.0156623   0.99301451]
 [-0.03310927 -0.99938136 -0.01186341]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 218.67429 -307.0129   997.7692 ]
[ -76.07026758 -673.66994766  -42.11107893]
[ 0.   0.  -9.8]
transform [[ 0.99258596 -0.03149058 -0.11739464]
 [ 0.11694843 -0.0156623   0.99301451]
 [-0.03310927 -0.99938136 -0.01186341]]
transform [[ 0.99258596 -0.03149058 -0.11739464]
 [ 0.11694843 -0.0156623   0.99301451]
 [-0.03310927 -0.99938136 -0.01186341]]
transform [[ 0.99258596 -0.03149058 -0.11739464]
 [ 0.11694843 -0.0156623   0.99301451]
 [-0.03310927 -0.99938136 -0.01186341]]
support
[-0.14300207  1.20962196 -0.01445119]
[ 109.5882784  1021.18146631  287.74588939]
[-49.34840999 -40.16198767 676.27140249]
[ 1.15046748 -9.73154224  0.11626141]
v_real [-0.6177372  1.177267  -0.3290196]
zmp_s [       0.         27971858.4088455  -7817506.00539476]
transform [[ 0.99258596  0.11694843 -0.03310927]
 [-0.03149058 -0.0156623  -0.99938136]
 [-0.11739464  0.99301451 -0.01186341]]
zmp [ 3530096.6949903   7374566.08268533 27869203.67135471]
d1:56657220.75011, d2:0.05940, d3:14489841.57735
eta 23760000.0
transform [[ 0.68107885  0.57572174 -0.45241156]
 [ 0.05260689  0.5777992   0.81448185]
 [ 0.73031789 -0.5785262   0.36323982]]
planes
[[ 0.68107885  0.57572174 -0.45241156]
 [ 0.05260689  0.5777992   0.81448185]
 [ 0.73031789 -0.5785262   0.36323982]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 285.8584  385.4724 1440.1882]
[ 45.95071077 290.24829286  -4.75434583]
[ 0.   0.  -9.8]
transform [[ 0.68107885  0.57572174 -0.45241156]
 [ 0.05260689  0.5777992   0.81448185]
 [ 0.73031789 -0.5785262   0.36323982]]
transform [[ 0.68107885  0.57572174 -0.45241156]
 [ 0.05260689  0.5777992   0.81448185]
 [ 0.73031789 -0.5785262   0.36323982]]
transform [[ 0.68107885  0.57572174 -0.45241156]
 [ 0.05260689  0.5777992   0.81448185]
 [ 0.73031789 -0.5785262   0.36323982]]
support
[-0.55109664  0.99214576  0.44247376]
[-234.94085038 1410.7709548   508.89533441]
[ 200.54923074  166.2502272  -136.08458318]
[ 4.43363331 -7.98192217 -3.55975028]
v_real [-0.08603641  0.9743945  -0.63280296]
zmp_s [        0.          23151611.04798767 -15035399.48691905]
transform [[ 0.68107885  0.05260689  0.73031789]
 [ 0.57572174  0.5777992  -0.5785262 ]
 [-0.45241156  0.81448185  0.36323982]]
zmp [-9762687.02618482 22075354.87922871 13395111.22460668]
d1:44130948.18942, d2:0.05940, d3:10877310.82762
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-475.68213770496436 steps:8[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.67125189  0.63392013  0.38414338]
 [-0.25015903 -0.29409984  0.92245638]
 [ 0.6977402  -0.71529758 -0.03883425]]
planes
[[ 0.67125189  0.63392013  0.38414338]
 [-0.25015903 -0.29409984  0.92245638]
 [ 0.6977402  -0.71529758 -0.03883425]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-414.04782  615.7659   138.73822]
[ 159.83685085 -285.45659016  -77.39646623]
[ 0.   0.  -9.8]
transform [[ 0.67125189  0.63392013  0.38414338]
 [-0.25015903 -0.29409984  0.92245638]
 [ 0.6977402  -0.71529758 -0.03883425]]
transform [[ 0.67125189  0.63392013  0.38414338]
 [-0.25015903 -0.29409984  0.92245638]
 [ 0.6977402  -0.71529758 -0.03883425]]
transform [[ 0.67125189  0.63392013  0.38414338]
 [-0.25015903 -0.29409984  0.92245638]
 [ 0.6977402  -0.71529758 -0.03883425]]
support
[ 0.46793704  1.1236729  -0.04730521]
[ 165.71140591   50.46109617 -734.74148279]
[-103.39723124  -27.42675835  318.71663773]
[-3.76460515 -9.04007256  0.38057566]
v_real [ 0.18519506  0.00963207 -0.85966074]
zmp_s [        0.            228857.11408103 -20425538.09476333]
transform [[ 0.67125189 -0.25015903  0.6977402 ]
 [ 0.63392013 -0.29409984 -0.71529758]
 [ 0.38414338  0.92245638 -0.03883425]]
zmp [-14308969.65034935  14543031.12451709   1004321.18848794]
d1:27509019.22046, d2:0.05940, d3:9813952.80032
eta 23760000.0
transform [[ 0.67329407  0.16907153  0.71978468]
 [-0.41541147 -0.71882492  0.55742627]
 [ 0.61164409 -0.67431861 -0.41374633]]
planes
[[ 0.67329407  0.16907153  0.71978468]
 [-0.41541147 -0.71882492  0.55742627]
 [ 0.61164409 -0.67431861 -0.41374633]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-260.26746  862.7343  -248.16786]
[ 159.83685085 -285.45659016  -77.39646623]
[ 0.   0.  -9.8]
transform [[ 0.67329407  0.16907153  0.71978468]
 [-0.41541147 -0.71882492  0.55742627]
 [ 0.61164409 -0.67431861 -0.41374633]]
transform [[ 0.67329407  0.16907153  0.71978468]
 [-0.41541147 -0.71882492  0.55742627]
 [ 0.61164409 -0.67431861 -0.41374633]]
transform [[ 0.67329407  0.16907153  0.71978468]
 [-0.41541147 -0.71882492  0.55742627]
 [ 0.61164409 -0.67431861 -0.41374633]]
support
[ 0.87679217  0.67901834 -0.50399731]
[-208.00015203 -650.37212628 -638.27031451]
[  3.64583186  95.65242614 322.27446025]
[-7.05388983 -5.46277748  4.05471401]
v_real [0.0317167  2.0463488  0.14066666]
zmp_s [       0.         48621247.50370236  3342236.46547281]
transform [[ 0.67329407 -0.41541147  0.61164409]
 [ 0.16907153 -0.71882492 -0.67431861]
 [ 0.71978468  0.55742627 -0.41374633]]
zmp [-18153564.83268667 -37203896.74799344  25719922.76250859]
d1:87916865.15758, d2:0.05940, d3:20026030.79081
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-173.12801240158956 steps:11[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-384.5003409374956 steps:12[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.75754815 -0.60449952 -0.24637616]
 [ 0.19012146 -0.15674686  0.96916676]
 [-0.62447953 -0.78103185 -0.00381494]]
planes
[[ 0.75754815 -0.60449952 -0.24637616]
 [ 0.19012146 -0.15674686  0.96916676]
 [-0.62447953 -0.78103185 -0.00381494]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-260.26746  862.7343  -248.16786]
[ 159.83685085 -285.45659016  -77.39646623]
[ 0.   0.  -9.8]
transform [[ 0.75754815 -0.60449952 -0.24637616]
 [ 0.19012146 -0.15674686  0.96916676]
 [-0.62447953 -0.78103185 -0.00381494]]
transform [[ 0.75754815 -0.60449952 -0.24637616]
 [ 0.19012146 -0.15674686  0.96916676]
 [-0.62447953 -0.78103185 -0.00381494]]
transform [[ 0.75754815 -0.60449952 -0.24637616]
 [ 0.19012146 -0.15674686  0.96916676]
 [-0.62447953 -0.78103185 -0.00381494]]
support
[-0.30011848  1.18057226 -0.0046471 ]
[-657.54496436 -425.22936802 -510.34453025]
[3.12711127e+02 1.22758295e-01 1.23431109e+02]
[ 2.41448634 -9.49783421  0.0373864 ]
v_real [-1.1118478   0.38638788 -0.12747584]
zmp_s [       0.          9180577.56812984 -3028825.77106027]
transform [[ 0.75754815  0.19012146 -0.62447953]
 [-0.60449952 -0.15674686 -0.78103185]
 [-0.24637616  0.96916676 -0.00381494]]
zmp [3636864.48393092  926582.63977247 8909065.36232683]
d1:18339393.60992, d2:0.05940, d3:7087119.84440
eta 23760000.0
transform [[ 0.44324836 -0.35037225 -0.82508802]
 [ 0.64308339 -0.51694155  0.56499135]
 [-0.62447953 -0.78103185 -0.00381494]]
planes
[[ 0.44324836 -0.35037225 -0.82508802]
 [ 0.64308339 -0.51694155  0.56499135]
 [-0.62447953 -0.78103185 -0.00381494]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-260.26746  862.7343  -248.16786]
[ 159.83685085 -285.45659016  -77.39646623]
[ 0.   0.  -9.8]
transform [[ 0.44324836 -0.35037225 -0.82508802]
 [ 0.64308339 -0.51694155  0.56499135]
 [-0.62447953 -0.78103185 -0.00381494]]
transform [[ 0.44324836 -0.35037225 -0.82508802]
 [ 0.64308339 -0.51694155  0.56499135]
 [-0.62447953 -0.78103185 -0.00381494]]
transform [[ 0.44324836 -0.35037225 -0.82508802]
 [ 0.64308339 -0.51694155  0.56499135]
 [-0.62447953 -0.78103185 -0.00381494]]
support
[-1.00506546  0.6882336  -0.0046471 ]
[-212.88095947 -753.5695867  -510.34453025]
[234.72238877 206.62446157 123.43110879]
[ 8.08586264 -5.53691528  0.0373864 ]
v_real [-1.1118478   0.38638788 -0.12747584]
zmp_s [       0.          9180581.01637842 -3028824.5091639 ]
transform [[ 0.44324836  0.64308339 -0.62447953]
 [-0.35037225 -0.51694155 -0.78103185]
 [-0.82508802  0.56499135 -0.00381494]]
zmp [ 7795318.10771672 -2380215.35594927  5198503.68817545]
d1:14181933.70726, d2:0.05940, d3:4912956.95741
eta 23760000.0
transform [[ 0.47769958  0.75846744 -0.44331744]
 [-0.27256638  0.60767055  0.74595183]
 [ 0.8351711  -0.23550741  0.49701664]]
planes
[[ 0.47769958  0.75846744 -0.44331744]
 [-0.27256638  0.60767055  0.74595183]
 [ 0.8351711  -0.23550741  0.49701664]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-464.7013   762.0542   135.51447]
[-115.24137222  166.20290947   20.29442412]
[ 0.   0.  -9.8]
transform [[ 0.47769958  0.75846744 -0.44331744]
 [-0.27256638  0.60767055  0.74595183]
 [ 0.8351711  -0.23550741  0.49701664]]
transform [[ 0.47769958  0.75846744 -0.44331744]
 [-0.27256638  0.60767055  0.74595183]
 [ 0.8351711  -0.23550741  0.49701664]]
transform [[ 0.47769958  0.75846744 -0.44331744]
 [-0.27256638  0.60767055  0.74595183]
 [ 0.8351711  -0.23550741  0.49701664]]
support
[-0.54001881  0.9086672   0.60543147]
[ 295.92975625  690.82710318 -500.22156201]
[  62.01186751  147.54619895 -125.30161491]
[ 4.34451094 -7.31032795 -4.87076306]
v_real [-0.43561143 -0.9358583   0.6113111 ]
zmp_s [        0.         -22235991.44479301  14524751.18843551]
transform [[ 0.47769958 -0.27256638  0.8351711 ]
 [ 0.75846744  0.60767055 -0.23550741]
 [-0.44331744  0.74595183  0.49701664]]
zmp [ 18191436.1297206  -16932843.64040217  -9367935.52894394]
d1:45553665.67433, d2:0.05940, d3:17079230.73724
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-347.0738209382366 steps:16[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.6767416  -0.73560071 -0.0302066 ]
 [ 0.04019011 -0.00405604  0.99918389]
 [-0.73512286 -0.67740333  0.02681899]]
planes
[[ 0.6767416  -0.73560071 -0.0302066 ]
 [ 0.04019011 -0.00405604  0.99918389]
 [-0.73512286 -0.67740333  0.02681899]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-464.7013   762.0542   135.51447]
[-115.24137222  166.20290947   20.29442412]
[ 0.   0.  -9.8]
transform [[ 0.6767416  -0.73560071 -0.0302066 ]
 [ 0.04019011 -0.00405604  0.99918389]
 [-0.73512286 -0.67740333  0.02681899]]
transform [[ 0.6767416  -0.73560071 -0.0302066 ]
 [ 0.04019011 -0.00405604  0.99918389]
 [-0.73512286 -0.67740333  0.02681899]]
transform [[ 0.6767416  -0.73560071 -0.0302066 ]
 [ 0.04019011 -0.00405604  0.99918389]
 [-0.73512286 -0.67740333  0.02681899]]
support
[-0.0367956   1.21713707  0.03266904]
[-879.14373791  113.63655618 -170.97114837]
[-200.8606343    14.97217343  -27.32556153]
[ 0.29602465 -9.79200215 -0.26282605]
v_real [-0.5812726   0.18156625 -0.24391411]
zmp_s [       0.          4314015.18169682 -5795399.47719787]
transform [[ 0.6767416   0.04019011 -0.73512286]
 [-0.73560071 -0.00405604 -0.67740333]
 [-0.0302066   0.99918389  0.02681899]]
zmp [4433711.37208061 3908325.10626822 4155067.75224754]
d1:11592779.28893, d2:0.05940, d3:5300551.82956
eta 23760000.0
transform [[ 0.76785773  0.57853085 -0.27513012]
 [ 0.23287064  0.14802504  0.96117634]
 [ 0.59679621 -0.80211639 -0.02106066]]
planes
[[ 0.76785773  0.57853085 -0.27513012]
 [ 0.23287064  0.14802504  0.96117634]
 [ 0.59679621 -0.80211639 -0.02106066]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-277.6373    -813.6747       6.1698484]
[165.17668208 220.2392293  -21.04877488]
[ 0.   0.  -9.8]
transform [[ 0.76785773  0.57853085 -0.27513012]
 [ 0.23287064  0.14802504  0.96117634]
 [ 0.59679621 -0.80211639 -0.02106066]]
transform [[ 0.76785773  0.57853085 -0.27513012]
 [ 0.23287064  0.14802504  0.96117634]
 [ 0.59679621 -0.80211639 -0.02106066]]
transform [[ 0.76785773  0.57853085 -0.27513012]
 [ 0.23287064  0.14802504  0.96117634]
 [ 0.59679621 -0.80211639 -0.02106066]]
support
[-0.33514459  1.17083888 -0.02565465]
[-685.61936127 -179.16748671  486.83897242]
[260.03853233  50.8341349  -77.63737665]
[ 2.6962752  -9.41952809  0.20639451]
v_real [-0.8895425   0.09747022 -0.07220777]
zmp_s [       0.          2315893.64970406 -1715656.96410833]
transform [[ 0.76785773  0.23287064  0.59679621]
 [ 0.57853085  0.14802504 -0.80211639]
 [-0.27513012  0.96117634 -0.02106066]]
zmp [-484593.94909378 1718966.8180064  2262115.04756698]
d1:5382237.02617, d2:0.05940, d3:2169143.18920
eta 23760000.0
transform [[ 0.48223558 -0.07535429 -0.87279469]
 [-0.05560352 -0.99691767  0.05534867]
 [-0.87427521  0.02183936 -0.4849391 ]]
planes
[[ 0.48223558 -0.07535429 -0.87279469]
 [-0.05560352 -0.99691767  0.05534867]
 [-0.87427521  0.02183936 -0.4849391 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-509.48477 -523.1142   502.23312]
[-210.35878916  294.31599862  -76.02486932]
[ 0.   0.  -9.8]
transform [[ 0.48223558 -0.07535429 -0.87279469]
 [-0.05560352 -0.99691767  0.05534867]
 [-0.87427521  0.02183936 -0.4849391 ]]
transform [[ 0.48223558 -0.07535429 -0.87279469]
 [-0.05560352 -0.99691767  0.05534867]
 [-0.87427521  0.02183936 -0.4849391 ]]
transform [[ 0.48223558 -0.07535429 -0.87279469]
 [-0.05560352 -0.99691767  0.05534867]
 [-0.87427521  0.02183936 -0.4849391 ]]
support
[-1.06317844  0.06742194 -0.59071945]
[-644.61918674  577.62886813  190.4529462 ]
[ -57.26636475 -285.92000394  227.20657916]
[ 8.55338794 -0.54241699  4.75240316]
v_real [-0.45364255 -1.6154892   1.1895416 ]
zmp_s [        0.         -38384024.53996693  28263507.53250976]
transform [[ 0.48223558 -0.05560352 -0.87427521]
 [-0.07535429 -0.99691767  0.02183936]
 [-0.87279469  0.05534867 -0.4849391 ]]
zmp [-22575796.9292685   38882969.08002414 -15830584.64251086]
d1:20016656.54679, d2:0.05940, d3:12841542.14022
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-518.0551537923866 steps:20[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70390451 -0.69398719  0.15132813]
 [-0.09359751  0.12056608  0.98828304]
 [-0.70410085 -0.70982081  0.01991153]]
planes
[[ 0.70390451 -0.69398719  0.15132813]
 [-0.09359751  0.12056608  0.98828304]
 [-0.70410085 -0.70982081  0.01991153]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-509.48477 -523.1142   502.23312]
[-210.35878916  294.31599862  -76.02486932]
[ 0.   0.  -9.8]
transform [[ 0.70390451 -0.69398719  0.15132813]
 [-0.09359751  0.12056608  0.98828304]
 [-0.70410085 -0.70982081  0.01991153]]
transform [[ 0.70390451 -0.69398719  0.15132813]
 [-0.09359751  0.12056608  0.98828304]
 [-0.70410085 -0.70982081  0.01991153]]
transform [[ 0.70390451 -0.69398719  0.15132813]
 [-0.09359751  0.12056608  0.98828304]
 [-0.70410085 -0.70982081  0.01991153]]
support
[0.18433752 1.2038584  0.02425485]
[ 80.40792371 480.96515221 740.04622945]
[-363.82873481  -19.96050247  -62.31158926]
[-1.48301569 -9.68517377 -0.19513297]
v_real [-0.68734765 -0.3399537  -0.5098909 ]
zmp_s [        0.          -8077298.60736138 -12115009.95665107]
transform [[ 0.70390451 -0.09359751 -0.70410085]
 [-0.69398719  0.12056608 -0.70982081]
 [ 0.15132813  0.98828304  0.01991153]]
zmp [ 9286203.80368171  7625637.87369065 -8223885.5631758 ]
d1:23395752.87353, d2:0.05940, d3:10604719.44877
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-335.5515781633776 steps:22[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-184.8736744335833 steps:23[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69594073  0.71638805  0.0495458 ]
 [-0.00527578 -0.06389309  0.99794281]
 [ 0.71807986 -0.69477046 -0.04068631]]
planes
[[ 0.69594073  0.71638805  0.0495458 ]
 [-0.00527578 -0.06389309  0.99794281]
 [ 0.71807986 -0.69477046 -0.04068631]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[710.06354 206.20656  10.87904]
[   3.43527287 -222.40010386   -7.31072626]
[ 0.   0.  -9.8]
transform [[ 0.69594073  0.71638805  0.0495458 ]
 [-0.00527578 -0.06389309  0.99794281]
 [ 0.71807986 -0.69477046 -0.04068631]]
transform [[ 0.69594073  0.71638805  0.0495458 ]
 [-0.00527578 -0.06389309  0.99794281]
 [ 0.71807986 -0.69477046 -0.04068631]]
transform [[ 0.69594073  0.71638805  0.0495458 ]
 [-0.00527578 -0.06389309  0.99794281]
 [ 0.71807986 -0.69477046 -0.04068631]]
support
[ 0.06035329  1.21562527 -0.04956126]
[642.42506303  -6.06465042 366.17347691]
[-157.29624548    6.89601882  157.28126815]
[-0.48554886 -9.77983949  0.3987258 ]
v_real [ 0.11201693  0.5280074  -0.8189164 ]
zmp_s [        0.          12545456.97210544 -19457454.07328284]
transform [[ 0.69594073 -0.00527578  0.71807986]
 [ 0.71638805 -0.06389309 -0.69477046]
 [ 0.0495458   0.99794281 -0.04068631]]
zmp [-14038193.01638443  12716896.25026269  13311300.44725405]
d1:36006414.67299, d2:0.05940, d3:16999297.26868
eta 23760000.0
transform [[ 0.42959186 -0.89992815 -0.07470053]
 [-0.03207503 -0.09787716  0.99468148]
 [-0.90245336 -0.42491105 -0.07091246]]
planes
[[ 0.42959186 -0.89992815 -0.07470053]
 [-0.03207503 -0.09787716  0.99468148]
 [-0.90245336 -0.42491105 -0.07091246]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1402.6945   -614.8121   -129.24806]
[  18.48392883 -337.40519324  -45.21596562]
[ 0.   0.  -9.8]
transform [[ 0.42959186 -0.89992815 -0.07470053]
 [-0.03207503 -0.09787716  0.99468148]
 [-0.90245336 -0.42491105 -0.07091246]]
transform [[ 0.42959186 -0.89992815 -0.07470053]
 [-0.03207503 -0.09787716  0.99468148]
 [-0.90245336 -0.42491105 -0.07091246]]
transform [[ 0.42959186 -0.89992815 -0.07470053]
 [-0.03207503 -0.09787716  0.99468148]
 [-0.90245336 -0.42491105 -0.07091246]]
support
[-0.09099505  1.21165254 -0.08638068]
[ -39.64453522  -23.39312874 1536.2720732 ]
[314.95863446 -12.54409405 129.89268714]
[ 0.73206524 -9.74787848  0.69494209]
v_real [ 0.02696666 -0.01915599  0.06203212]
zmp_s [      0.         -455141.74777515 1473879.8918584 ]
transform [[ 0.42959186 -0.03207503 -0.90245336]
 [-0.89992815 -0.09787716 -0.42491105]
 [-0.07470053  0.99468148 -0.07091246]]
zmp [-1315509.18028157  -581719.87381458  -557237.51210241]
d1:2332896.13216, d2:0.05940, d3:966981.02554
eta 23760000.0
transform [[ 0.208351    0.48474231  0.84947908]
 [-0.92460525 -0.18556958  0.33266962]
 [ 0.31889656 -0.85474479  0.40953186]]
planes
[[ 0.208351    0.48474231  0.84947908]
 [-0.92460525 -0.18556958  0.33266962]
 [ 0.31889656 -0.85474479  0.40953186]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1402.6945   -614.8121   -129.24806]
[  18.48392883 -337.40519324  -45.21596562]
[ 0.   0.  -9.8]
transform [[ 0.208351    0.48474231  0.84947908]
 [-0.92460525 -0.18556958  0.33266962]
 [ 0.31889656 -0.85474479  0.40953186]]
transform [[ 0.208351    0.48474231  0.84947908]
 [-0.92460525 -0.18556958  0.33266962]
 [ 0.31889656 -0.85474479  0.40953186]]
transform [[ 0.208351    0.48474231  0.84947908]
 [-0.92460525 -0.18556958  0.33266962]
 [ 0.31889656 -0.85474479  0.40953186]]
support
[1.03477697 0.40523524 0.49886354]
[-700.07174603 1368.03217816   25.26177775]
[-198.11344577   30.47982593  275.7724145 ]
[-8.32489498 -3.26016223 -4.01341224]
v_real [ 0.5746973 -0.6639239 -0.0721045]
zmp_s [        0.         -15774829.21190893  -1713202.38812481]
transform [[ 0.208351   -0.92460525  0.31889656]
 [ 0.48474231 -0.18556958 -0.85474479]
 [ 0.84947908  0.33266962  0.40953186]]
zmp [14039155.5614958   4391679.31922149 -5949417.33558712]
d1:18178436.64882, d2:0.05940, d3:10264716.94997
eta 23760000.0
transform [[ 0.06327529 -0.43918023 -0.89616793]
 [ 0.48881081 -0.76924485  0.41149291]
 [-0.87009186 -0.46409565  0.16599828]]
planes
[[ 0.06327529 -0.43918023 -0.89616793]
 [ 0.48881081 -0.76924485  0.41149291]
 [-0.87009186 -0.46409565  0.16599828]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 437.9045  -339.22684 -396.3048 ]
[  -1.7117949  -140.64755768   23.51178994]
[ 0.   0.  -9.8]
transform [[ 0.06327529 -0.43918023 -0.89616793]
 [ 0.48881081 -0.76924485  0.41149291]
 [-0.87009186 -0.46409565  0.16599828]]
transform [[ 0.06327529 -0.43918023 -0.89616793]
 [ 0.48881081 -0.76924485  0.41149291]
 [-0.87009186 -0.46409565  0.16599828]]
transform [[ 0.06327529 -0.43918023 -0.89616793]
 [ 0.48881081 -0.76924485  0.41149291]
 [-0.87009186 -0.46409565  0.16599828]]
support
[-1.09165012  0.50125236  0.20220768]
[ 531.84591385  311.92433382 -289.36936464]
[ 40.59079952 117.03060047  70.66625549]
[ 8.78244575 -4.03263056 -1.62678314]
v_real [0.26647374 0.8984632  0.38084012]
zmp_s [       0.         21347486.99224354  9048760.83109253]
transform [[ 0.06327529  0.48881081 -0.87009186]
 [-0.43918023 -0.76924485 -0.46409565]
 [-0.89616793  0.41149291  0.16599828]]
zmp [  2561629.2523233  -20620934.98106753  10286418.36272202]
d1:25926235.75619, d2:0.05940, d3:11138010.75277
eta 23760000.0
transform [[ 0.19088148 -0.62778127 -0.7546224 ]
 [ 0.4544276  -0.62490481  0.63481468]
 [-0.87009186 -0.46409565  0.16599828]]
planes
[[ 0.19088148 -0.62778127 -0.7546224 ]
 [ 0.4544276  -0.62490481  0.63481468]
 [-0.87009186 -0.46409565  0.16599828]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 437.9045  -339.22684 -396.3048 ]
[  -1.7117949  -140.64755768   23.51178994]
[ 0.   0.  -9.8]
transform [[ 0.19088148 -0.62778127 -0.7546224 ]
 [ 0.4544276  -0.62490481  0.63481468]
 [-0.87009186 -0.46409565  0.16599828]]
transform [[ 0.19088148 -0.62778127 -0.7546224 ]
 [ 0.4544276  -0.62490481  0.63481468]
 [-0.87009186 -0.46409565  0.16599828]]
transform [[ 0.19088148 -0.62778127 -0.7546224 ]
 [ 0.4544276  -0.62490481  0.63481468]
 [-0.87009186 -0.46409565  0.16599828]]
support
[-0.91922909  0.77328757  0.20220768]
[ 595.60860098  159.40026766 -289.36936464]
[ 70.22662937 102.03907805  70.66625549]
[ 7.39529952 -6.22118386 -1.62678314]
v_real [0.26647374 0.8984632  0.38084012]
zmp_s [       0.         21347486.88960591  9048760.9278263 ]
transform [[ 0.19088148  0.4544276  -0.87009186]
 [-0.62778127 -0.62490481 -0.46409565]
 [-0.7546224   0.63481468  0.16599828]]
zmp [  1827634.0453848  -17539637.8717627   15053776.80116196]
d1:29955454.88310, d2:0.05940, d3:13560707.33273
eta 23760000.0
transform [[ 0.57121009  0.42822209 -0.70024633]
 [ 0.80814087 -0.44268635  0.38850635]
 [-0.1436225  -0.78781641 -0.59893066]]
planes
[[ 0.57121009  0.42822209 -0.70024633]
 [ 0.80814087 -0.44268635  0.38850635]
 [-0.1436225  -0.78781641 -0.59893066]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1016.0564  -345.6081   413.08545]
[213.70898563 -29.44621182 -62.03349884]
[ 0.   0.  -9.8]
transform [[ 0.57121009  0.42822209 -0.70024633]
 [ 0.80814087 -0.44268635  0.38850635]
 [-0.1436225  -0.78781641 -0.59893066]]
transform [[ 0.57121009  0.42822209 -0.70024633]
 [ 0.80814087 -0.44268635  0.38850635]
 [-0.1436225  -0.78781641 -0.59893066]]
transform [[ 0.57121009  0.42822209 -0.70024633]
 [ 0.80814087 -0.44268635  0.38850635]
 [-0.1436225  -0.78781641 -0.59893066]]
support
[-0.85299191  0.47325171 -0.72957612]
[ 143.12307047 1134.59901055 -121.06237632]
[152.90193992 161.64199402  29.6585536 ]
[ 6.86241407 -3.80736226  5.86952044]
v_real [-0.01410212  0.24331313 -0.202509  ]
zmp_s [       0.          5781126.70650537 -4811614.30697909]
transform [[ 0.57121009  0.80814087 -0.1436225 ]
 [ 0.42822209 -0.44268635 -0.78781641]
 [-0.70024633  0.38850635 -0.59893066]]
zmp [5363020.87749522 1231442.81129987 5127827.77008189]
d1:12429745.29259, d2:0.05940, d3:5125057.50233
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-801.8898649112629 steps:30[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.36228901 -0.03396772  0.93144667]
 [-0.64917028  0.7078985   0.27831218]
 [-0.66882336 -0.70549697  0.23441301]]
planes
[[ 0.36228901 -0.03396772  0.93144667]
 [-0.64917028  0.7078985   0.27831218]
 [-0.66882336 -0.70549697  0.23441301]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1016.0564  -345.6081   413.08545]
[213.70898563 -29.44621182 -62.03349884]
[ 0.   0.  -9.8]
transform [[ 0.36228901 -0.03396772  0.93144667]
 [-0.64917028  0.7078985   0.27831218]
 [-0.66882336 -0.70549697  0.23441301]]
transform [[ 0.36228901 -0.03396772  0.93144667]
 [-0.64917028  0.7078985   0.27831218]
 [-0.66882336 -0.70549697  0.23441301]]
transform [[ 0.36228901 -0.03396772  0.93144667]
 [-0.64917028  0.7078985   0.27831218]
 [-0.66882336 -0.70549697  0.23441301]]
support
[1.13462425 0.33902075 0.2855458 ]
[ 764.61265391 -789.28235443 -338.90418823]
[  20.64374187 -176.84312912 -136.70080837]
[-9.12817738 -2.72745933 -2.29724753]
v_real [ 0.79248273 -0.23269866  0.09307652]
zmp_s [       0.         -5528918.79055487  2211498.56390003]
transform [[ 0.36228901 -0.64917028 -0.66882336]
 [-0.03396772  0.7078985  -0.70549697]
 [ 0.93144667  0.27831218  0.23441301]]
zmp [ 2110107.85338138 -5474118.83408373 -1020361.38079878]
d1:7822657.52197, d2:0.05940, d3:1329491.63272
eta 23760000.0
transform [[ 0.03866985 -0.34790438 -0.93673223]
 [ 0.74241501 -0.61744368  0.25996807]
 [-0.66882336 -0.70549697  0.23441301]]
planes
[[ 0.03866985 -0.34790438 -0.93673223]
 [ 0.74241501 -0.61744368  0.25996807]
 [-0.66882336 -0.70549697  0.23441301]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1016.0564  -345.6081   413.08545]
[213.70898563 -29.44621182 -62.03349884]
[ 0.   0.  -9.8]
transform [[ 0.03866985 -0.34790438 -0.93673223]
 [ 0.74241501 -0.61744368  0.25996807]
 [-0.66882336 -0.70549697  0.23441301]]
transform [[ 0.03866985 -0.34790438 -0.93673223]
 [ 0.74241501 -0.61744368  0.25996807]
 [-0.66882336 -0.70549697  0.23441301]]
transform [[ 0.03866985 -0.34790438 -0.93673223]
 [ 0.74241501 -0.61744368  0.25996807]
 [-0.66882336 -0.70549697  0.23441301]]
support
[-1.14106276  0.31667522  0.2855458 ]
[-227.42113133 1075.11808178 -338.90418823]
[  76.61733941  160.71540721 -136.70080837]
[ 9.17997588 -2.54768711 -2.29724753]
v_real [ 0.79248273 -0.23269866  0.09307652]
zmp_s [       0.         -5528926.41757945  2211499.33308812]
transform [[ 0.03866985  0.74241501 -0.66882336]
 [-0.34790438 -0.61744368 -0.70549697]
 [-0.93673223  0.25996807  0.23441301]]
zmp [-5583860.38441623  1853594.60627962  -918940.12036903]
d1:8158175.81518, d2:0.05940, d3:2135180.33851
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-346.0772897067443 steps:33[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-291.67218615235475 steps:34[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.59736353  0.79468912  0.1078245 ]
 [-0.00355998 -0.13182048  0.99126726]
 [ 0.80196273 -0.59253067 -0.07591566]]
planes
[[ 0.59736353  0.79468912  0.1078245 ]
 [-0.00355998 -0.13182048  0.99126726]
 [ 0.80196273 -0.59253067 -0.07591566]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-609.7994  -785.11084 -301.58795]
[ -62.13898413 -176.01695313   38.48023032]
[ 0.   0.  -9.8]
transform [[ 0.59736353  0.79468912  0.1078245 ]
 [-0.00355998 -0.13182048  0.99126726]
 [ 0.80196273 -0.59253067 -0.07591566]]
transform [[ 0.59736353  0.79468912  0.1078245 ]
 [-0.00355998 -0.13182048  0.99126726]
 [ 0.80196273 -0.59253067 -0.07591566]]
transform [[ 0.59736353  0.79468912  0.1078245 ]
 [-0.00355998 -0.13182048  0.99126726]
 [ 0.80196273 -0.59253067 -0.07591566]]
support
[ 0.13134439  1.20749358 -0.09247524]
[-1.02070952e+03 -1.93289700e+02 -9.38875527e-01]
[-172.84920863   61.56804613   51.54104098]
[-1.05668014 -9.71441919  0.74397351]
v_real [ 1.2566828   0.15853775 -0.24535494]
zmp_s [       0.          3766857.98184121 -5829633.65275678]
transform [[ 0.59736353 -0.00355998  0.80196273]
 [ 0.79468912 -0.13182048 -0.59253067]
 [ 0.1078245   0.99126726 -0.07591566]]
zmp [-4688558.86695951  2957687.67511464  4176523.51727772]
d1:9526641.48375, d2:0.05940, d3:4768554.09419
eta 23760000.0
transform [[ 0.09273957  0.24903311 -0.96404457]
 [ 0.59013152  0.76608741  0.2546663 ]
 [ 0.80196273 -0.59253067 -0.07591566]]
planes
[[ 0.09273957  0.24903311 -0.96404457]
 [ 0.59013152  0.76608741  0.2546663 ]
 [ 0.80196273 -0.59253067 -0.07591566]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-609.7994  -785.11084 -301.58795]
[ -62.13898413 -176.01695313   38.48023032]
[ 0.   0.  -9.8]
transform [[ 0.09273957  0.24903311 -0.96404457]
 [ 0.59013152  0.76608741  0.2546663 ]
 [ 0.80196273 -0.59253067 -0.07591566]]
transform [[ 0.09273957  0.24903311 -0.96404457]
 [ 0.59013152  0.76608741  0.2546663 ]
 [ 0.80196273 -0.59253067 -0.07591566]]
transform [[ 0.09273957  0.24903311 -0.96404457]
 [ 0.59013152  0.76608741  0.2546663 ]
 [ 0.80196273 -0.59253067 -0.07591566]]
support
[-1.17433277  0.31021696 -0.09247524]
[ 3.86731043e+01 -1.03812965e+03 -9.38875527e-01]
[ -86.69344858 -161.71492764   51.54104098]
[ 9.4476368  -2.49572973  0.74397351]
v_real [ 1.2566828   0.15853775 -0.24535494]
zmp_s [       0.          3766830.59384298 -5829636.95783919]
transform [[ 0.09273957  0.59013152  0.80196273]
 [ 0.24903311  0.76608741 -0.59253067]
 [-0.96404457  0.2546663  -0.07591566]]
zmp [-2452226.12013184  6339960.18377585  1401845.56795804]
d1:8719466.65966, d2:0.05940, d3:4036203.13834
eta 23760000.0
transform [[ 0.92587113  0.35529637  0.12855805]
 [-0.02127288 -0.29068777  0.95658147]
 [ 0.37724015 -0.88840598 -0.26158124]]
planes
[[ 0.92587113  0.35529637  0.12855805]
 [-0.02127288 -0.29068777  0.95658147]
 [ 0.37724015 -0.88840598 -0.26158124]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-609.7994  -785.11084 -301.58795]
[ -62.13898413 -176.01695313   38.48023032]
[ 0.   0.  -9.8]
transform [[ 0.92587113  0.35529637  0.12855805]
 [-0.02127288 -0.29068777  0.95658147]
 [ 0.37724015 -0.88840598 -0.26158124]]
transform [[ 0.92587113  0.35529637  0.12855805]
 [-0.02127288 -0.29068777  0.95658147]
 [ 0.37724015 -0.88840598 -0.26158124]]
transform [[ 0.92587113  0.35529637  0.12855805]
 [-0.02127288 -0.29068777  0.95658147]
 [ 0.37724015 -0.88840598 -0.26158124]]
support
[ 0.15660058  1.16524174 -0.31864027]
[-882.31423542  -47.29914202  546.34610571]
[-115.12393323   89.29732581  122.8674873 ]
[-1.25986893 -9.37449844  2.56349617]
v_real [ 1.0528023  1.5008225 -1.3842043]
zmp_s [        0.          35659545.29425453 -32888694.32241784]
transform [[ 0.92587113 -0.02127288  0.37724015]
 [ 0.35529637 -0.29068777 -0.88840598]
 [ 0.12855805  0.95658147 -0.26158124]]
zmp [-13165517.08061684  18852718.97863331  42714325.88798339]
d1:87441270.43021, d2:0.05940, d3:27628672.51256
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-442.5286804495381 steps:38[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.14117061  0.15293786 -0.97810072]
 [ 0.68557233  0.69764745  0.2080352 ]
 [ 0.71418589 -0.69992721 -0.00636263]]
planes
[[ 0.14117061  0.15293786 -0.97810072]
 [ 0.68557233  0.69764745  0.2080352 ]
 [ 0.71418589 -0.69992721 -0.00636263]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-489.8854    110.693886 -458.34503 ]
[ -23.46215503 -163.87626277    9.47594646]
[ 0.   0.  -9.8]
transform [[ 0.14117061  0.15293786 -0.97810072]
 [ 0.68557233  0.69764745  0.2080352 ]
 [ 0.71418589 -0.69992721 -0.00636263]]
transform [[ 0.14117061  0.15293786 -0.97810072]
 [ 0.68557233  0.69764745  0.2080352 ]
 [ 0.71418589 -0.69992721 -0.00636263]]
transform [[ 0.14117061  0.15293786 -0.97810072]
 [ 0.68557233  0.69764745  0.2080352 ]
 [ 0.71418589 -0.69992721 -0.00636263]]
support
[-1.191455    0.25341417 -0.00775052]
[ 396.07947043 -353.978471   -424.430629  ]
[ -37.64348149 -128.441531     97.88482341]
[ 9.58538703 -2.03874497  0.06235379]
v_real [0.00686404 0.16671057 0.00764103]
zmp_s [      0.         3961042.2164816   181549.31986693]
transform [[ 0.14117061  0.68557233  0.71418589]
 [ 0.15293786  0.69764745 -0.69992721]
 [-0.97810072  0.2080352  -0.00636263]]
zmp [2845240.88969357 2636339.70191823  822881.08160624]
d1:5789265.91551, d2:0.05940, d3:779552.44878
eta 23760000.0
transform [[ 0.99767542  0.01036072  0.06735396]
 [-0.06312198 -0.23197111  0.97067243]
 [ 0.02568099 -0.97266752 -0.23077789]]
planes
[[ 0.99767542  0.01036072  0.06735396]
 [-0.06312198 -0.23197111  0.97067243]
 [ 0.02568099 -0.97266752 -0.23077789]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-489.8854    110.693886 -458.34503 ]
[ -23.46215503 -163.87626277    9.47594646]
[ 0.   0.  -9.8]
transform [[ 0.99767542  0.01036072  0.06735396]
 [-0.06312198 -0.23197111  0.97067243]
 [ 0.02568099 -0.97266752 -0.23077789]]
transform [[ 0.99767542  0.01036072  0.06735396]
 [-0.06312198 -0.23197111  0.97067243]
 [ 0.02568099 -0.97266752 -0.23077789]]
transform [[ 0.99767542  0.01036072  0.06735396]
 [-0.06312198 -0.23197111  0.97067243]
 [ 0.02568099 -0.97266752 -0.23077789]]
support
[ 0.08204596  1.18240637 -0.28111775]
[-518.4711146  -439.65813143  -14.47319044]
[-24.46724865  48.69357707 156.60774701]
[-0.66006885 -9.5125898   2.26162332]
v_real [-0.3649129 -0.3194174  0.8337999]
zmp_s [       0.         -7589355.58690993 19811085.62315407]
transform [[ 0.99767542 -0.06312198  0.02568099]
 [ 0.01036072 -0.23197111 -0.97266752]
 [ 0.06735396  0.97067243 -0.23077789]]
zmp [   987823.47553502 -17509088.1513604  -11938738.74773481]
d1:37831043.89559, d2:0.05940, d3:7205112.62591
eta 23760000.0
transform [[ 0.99795347  0.01142095  0.06291632]
 [-0.05856096 -0.23192134  0.97097021]
 [ 0.02568099 -0.97266752 -0.23077789]]
planes
[[ 0.99795347  0.01142095  0.06291632]
 [-0.05856096 -0.23192134  0.97097021]
 [ 0.02568099 -0.97266752 -0.23077789]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-489.8854    110.693886 -458.34503 ]
[ -23.46215503 -163.87626277    9.47594646]
[ 0.   0.  -9.8]
transform [[ 0.99795347  0.01142095  0.06291632]
 [-0.05856096 -0.23192134  0.97097021]
 [ 0.02568099 -0.97266752 -0.23077789]]
transform [[ 0.99795347  0.01142095  0.06291632]
 [-0.05856096 -0.23192134  0.97097021]
 [ 0.02568099 -0.97266752 -0.23077789]]
transform [[ 0.99795347  0.01142095  0.06291632]
 [-0.05856096 -0.23192134  0.97097021]
 [ 0.02568099 -0.97266752 -0.23077789]]
support
[ 0.07664034  1.18276911 -0.28111775]
[-516.45599857 -442.02348847  -14.47319044]
[-24.68956991  48.58123136 156.60774701]
[-0.61657997 -9.51550809  2.26162332]
v_real [-0.3649129 -0.3194174  0.8337999]
zmp_s [       0.         -7589355.58128404 19811085.62311788]
transform [[ 0.99795347 -0.05856096  0.02568099]
 [ 0.01142095 -0.23192134 -0.97266752]
 [ 0.06291632  0.97097021 -0.23077789]]
zmp [   953208.25798357 -17509465.87393457 -11940998.73703967]
d1:37853694.99001, d2:0.05940, d3:7220423.42710
eta 23760000.0
transform [[ 0.0601458  -0.96689987  0.24796598]
 [ 0.99799287  0.05331686 -0.03417007]
 [ 0.01981826  0.24952348  0.96816593]]
planes
[[ 0.0601458  -0.96689987  0.24796598]
 [ 0.99799287  0.05331686 -0.03417007]
 [ 0.01981826  0.24952348  0.96816593]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 202.38075 -376.62115 -391.57837]
[ 20.40629298 -70.69224811 -20.56990712]
[ 0.   0.  -9.8]
transform [[ 0.0601458  -0.96689987  0.24796598]
 [ 0.99799287  0.05331686 -0.03417007]
 [ 0.01981826  0.24952348  0.96816593]]
transform [[ 0.0601458  -0.96689987  0.24796598]
 [ 0.99799287  0.05331686 -0.03417007]
 [ 0.01981826  0.24952348  0.96816593]]
transform [[ 0.0601458  -0.96689987  0.24796598]
 [ 0.99799287  0.05331686 -0.03417007]
 [ 0.01981826  0.24952348  0.96816593]]
support
[ 0.30205509 -0.04162363  1.17935313]
[ 279.2291849   195.27455064 -469.07782211]
[ 64.47904125  17.29912131 -37.15004152]
[-2.43006657  0.33486667 -9.48802615]
v_real [-0.23258628 -0.33111405 -2.08345   ]
zmp_s [        0.          -7867270.12086802 -49502770.23591822]
transform [[ 0.0601458   0.99799287  0.01981826]
 [-0.96689987  0.05331686  0.24952348]
 [ 0.24796598 -0.03417007  0.96816593]]
zmp [ -8832538.43822149 -12771561.43988142 -47658070.623993  ]
d1:79963907.35632, d2:0.05940, d3:30401642.57886
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-397.8784799544959 steps:43[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-117.00514928710635 steps:44[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-66.81182531250249 steps:45[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.18451867  0.1461499   0.97190177]
 [-0.70707417 -0.66710538  0.23455639]
 [ 0.68264127 -0.73048663 -0.01975458]]
planes
[[ 0.18451867  0.1461499   0.97190177]
 [-0.70707417 -0.66710538  0.23455639]
 [ 0.68264127 -0.73048663 -0.01975458]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 259.39365    42.942833 -636.5554  ]
[  71.66190085 -268.46653824  -20.23590563]
[ 0.   0.  -9.8]
transform [[ 0.18451867  0.1461499   0.97190177]
 [-0.70707417 -0.66710538  0.23455639]
 [ 0.68264127 -0.73048663 -0.01975458]]
transform [[ 0.18451867  0.1461499   0.97190177]
 [-0.70707417 -0.66710538  0.23455639]
 [ 0.68264127 -0.73048663 -0.01975458]]
transform [[ 0.18451867  0.1461499   0.97190177]
 [-0.70707417 -0.66710538  0.23455639]
 [ 0.68264127 -0.73048663 -0.01975458]]
support
[ 1.18390387  0.28572046 -0.02406366]
[-564.5302819  -361.36608316  158.27852429]
[-45.68071297 123.67873139 245.43033973]
[-9.52463739 -2.29865264  0.19359484]
v_real [-0.41374657  0.7465853   0.0469961 ]
zmp_s [       0.         17738865.96325349  1116627.33731422]
transform [[ 0.18451867 -0.70707417  0.68264127]
 [ 0.1461499  -0.66710538 -0.73048663]
 [ 0.97190177  0.23455639 -0.01975458]]
zmp [-11780437.94394271 -12649374.20316589   4138705.89647577]
d1:25450590.10409, d2:0.05940, d3:3690248.70240
eta 23760000.0
transform [[ 0.72001284  0.6769796  -0.15257825]
 [ 0.12482981  0.08993267  0.98809397]
 [ 0.68264127 -0.73048663 -0.01975458]]
planes
[[ 0.72001284  0.6769796  -0.15257825]
 [ 0.12482981  0.08993267  0.98809397]
 [ 0.68264127 -0.73048663 -0.01975458]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 259.39365    42.942833 -636.5554  ]
[  71.66190085 -268.46653824  -20.23590563]
[ 0.   0.  -9.8]
transform [[ 0.72001284  0.6769796  -0.15257825]
 [ 0.12482981  0.08993267  0.98809397]
 [ 0.68264127 -0.73048663 -0.01975458]]
transform [[ 0.72001284  0.6769796  -0.15257825]
 [ 0.12482981  0.08993267  0.98809397]
 [ 0.68264127 -0.73048663 -0.01975458]]
transform [[ 0.72001284  0.6769796  -0.15257825]
 [ 0.12482981  0.08993267  0.98809397]
 [ 0.68264127 -0.73048663 -0.01975458]]
support
[-0.18586033  1.2036281  -0.02406366]
[ 312.9626905  -592.73454941  158.27852429]
[-127.06132198  -35.19334594  245.43033973]
[ 1.49526685 -9.68332093  0.19359484]
v_real [-0.41374657  0.7465853   0.0469961 ]
zmp_s [       0.         17738866.06708213  1116627.20768376]
transform [[ 0.72001284  0.12482981  0.68264127]
 [ 0.6769796   0.08993267 -0.73048663]
 [-0.15257825  0.98809397 -0.01975458]]
zmp [ 2976595.16153813   779622.25608702 17505608.13810283]
d1:35025354.65265, d2:0.05940, d3:11666780.27527
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-161.37556317323333 steps:48[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-190.5218653515644 steps:49[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.11165158  0.08549777  0.99006265]
 [-0.72258902 -0.67696369  0.13994782]
 [ 0.68220162 -0.73103374 -0.01380432]]
planes
[[ 0.11165158  0.08549777  0.99006265]
 [-0.72258902 -0.67696369  0.13994782]
 [ 0.68220162 -0.73103374 -0.01380432]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[214.82828   26.154636 207.0937  ]
[  41.70042325 -280.33165484  -55.36753386]
[ 0.   0.  -9.8]
transform [[ 0.11165158  0.08549777  0.99006265]
 [-0.72258902 -0.67696369  0.13994782]
 [ 0.68220162 -0.73103374 -0.01380432]]
transform [[ 0.11165158  0.08549777  0.99006265]
 [-0.72258902 -0.67696369  0.13994782]
 [ 0.68220162 -0.73103374 -0.01380432]]
transform [[ 0.11165158  0.08549777  0.99006265]
 [-0.72258902 -0.67696369  0.13994782]
 [ 0.68220162 -0.73103374 -0.01380432]]
support
[ 1.20602621  0.1704748  -0.01681548]
[ 231.25782322 -143.95598101  124.57748972]
[-74.12914171 151.89351734 234.14430654]
[-9.70261401 -1.3714886   0.13528237]
v_real [-0.26332268  0.4339149  -0.83939725]
zmp_s [        0.          10309817.90473711 -19944078.01010543]
transform [[ 0.11165158 -0.72258902  0.68220162]
 [ 0.08549777 -0.67696369 -0.73103374]
 [ 0.99006265  0.13994782 -0.01380432]]
zmp [-21055643.58053172   7600421.64649753   1718151.00223257]
d1:27172693.77416, d2:0.05940, d3:10151523.87775
eta 23760000.0
transform [[ 0.32863396  0.32343772 -0.88734871]
 [ 0.65314674  0.60081416  0.46089226]
 [ 0.68220162 -0.73103374 -0.01380432]]
planes
[[ 0.32863396  0.32343772 -0.88734871]
 [ 0.65314674  0.60081416  0.46089226]
 [ 0.68220162 -0.73103374 -0.01380432]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[214.82828   26.154636 207.0937  ]
[  41.70042325 -280.33165484  -55.36753386]
[ 0.   0.  -9.8]
transform [[ 0.32863396  0.32343772 -0.88734871]
 [ 0.65314674  0.60081416  0.46089226]
 [ 0.68220162 -0.73103374 -0.01380432]]
transform [[ 0.32863396  0.32343772 -0.88734871]
 [ 0.65314674  0.60081416  0.46089226]
 [ 0.68220162 -0.73103374 -0.01380432]]
transform [[ 0.32863396  0.32343772 -0.88734871]
 [ 0.65314674  0.60081416  0.46089226]
 [ 0.68220162 -0.73103374 -0.01380432]]
support
[-1.08090715  0.56142724 -0.01681548]
[-104.70506717  251.47635135  124.57748972]
[ -27.83534621 -166.70920091  234.14430654]
[ 8.69601737 -4.51674415  0.13528237]
v_real [-0.26332268  0.4339149  -0.83939725]
zmp_s [        0.          10309818.21983341 -19944077.68448979]
transform [[ 0.32863396  0.65314674  0.68220162]
 [ 0.32343772  0.60081416 -0.73103374]
 [-0.88734871  0.46089226 -0.01380432]]
zmp [-6872057.98468795 20774078.56045585  5027029.91138801]
d1:28652069.27615, d2:0.05940, d3:12037394.83472
eta 23760000.0
transform [[ 0.33438864  0.32218987 -0.88565117]
 [ 0.5529182  -0.82808673 -0.09248742]
 [-0.7631945  -0.45876586 -0.45504743]]
planes
[[ 0.33438864  0.32218987 -0.88565117]
 [ 0.5529182  -0.82808673 -0.09248742]
 [-0.7631945  -0.45876586 -0.45504743]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-440.99167 -373.8889    32.20474]
[1302.86994771   27.0850599  -309.80584212]
[ 0.   0.  -9.8]
transform [[ 0.33438864  0.32218987 -0.88565117]
 [ 0.5529182  -0.82808673 -0.09248742]
 [-0.7631945  -0.45876586 -0.45504743]]
transform [[ 0.33438864  0.32218987 -0.88565117]
 [ 0.5529182  -0.82808673 -0.09248742]
 [-0.7631945  -0.45876586 -0.45504743]]
transform [[ 0.33438864  0.32218987 -0.88565117]
 [ 0.5529182  -0.82808673 -0.09248742]
 [-0.7631945  -0.45876586 -0.45504743]]
support
[-1.07883932 -0.11266182 -0.55430747]
[-296.44798084   62.80157488  493.43519095]
[ 718.77135326  726.60486643 -865.79252922]
[8.67938148 0.90637676 4.4594648 ]
v_real [-1.368062    0.91926396 -0.55473447]
zmp_s [        0.          21841708.63985679 -13180495.94586792]
transform [[ 0.33438864  0.5529182  -0.7631945 ]
 [ 0.32218987 -0.82808673 -0.45876586]
 [-0.88565117 -0.09248742 -0.45504743]]
zmp [ 22135960.16430087 -12040067.5531235    3977667.40671757]
d1:31899551.56390, d2:0.05940, d3:6327691.87477
eta 23760000.0
transform [[ 0.93765736 -0.21082336  0.27631915]
 [-0.26720938  0.07112433  0.96101016]
 [-0.22225642 -0.97493327  0.01035626]]
planes
[[ 0.93765736 -0.21082336  0.27631915]
 [-0.26720938  0.07112433  0.96101016]
 [-0.22225642 -0.97493327  0.01035626]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-440.99167 -373.8889    32.20474]
[1302.86994771   27.0850599  -309.80584212]
[ 0.   0.  -9.8]
transform [[ 0.93765736 -0.21082336  0.27631915]
 [-0.26720938  0.07112433  0.96101016]
 [-0.22225642 -0.97493327  0.01035626]]
transform [[ 0.93765736 -0.21082336  0.27631915]
 [-0.26720938  0.07112433  0.96101016]
 [-0.22225642 -0.97493327  0.01035626]]
transform [[ 0.93765736 -0.21082336  0.27631915]
 [-0.26720938  0.07112433  0.96101016]
 [-0.22225642 -0.97493327  0.01035626]]
support
[0.33659297 1.17063646 0.01261529]
[-325.77578631  122.19359517  462.86346372]
[1130.3301417  -643.93922664 -319.18577004]
[-2.70792763 -9.41789955 -0.10149139]
v_real [ 0.30985248  0.6813572  -0.22709037]
zmp_s [       0.         16189047.31450189 -5395665.0528602 ]
transform [[ 0.93765736 -0.26720938 -0.22225642]
 [-0.21082336  0.07112433 -0.97493327]
 [ 0.27631915  0.96101016  0.01035626]]
zmp [-3126644.10051348  6411848.5018998  15501959.98582019]
d1:31184631.59838, d2:0.05940, d3:8320744.76841
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-574.4844583973636 steps:54[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-218.72960070312737 steps:55[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.73063785  0.68185353 -0.03527236]
 [-0.02851149  0.08208583  0.99621743]
 [ 0.68216968 -0.72686851  0.07941567]]
planes
[[ 0.73063785  0.68185353 -0.03527236]
 [-0.02851149  0.08208583  0.99621743]
 [ 0.68216968 -0.72686851  0.07941567]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 908.7149  -162.6674   779.41077]
[   2.78033236 -282.8082708    -8.80392599]
[ 0.   0.  -9.8]
transform [[ 0.73063785  0.68185353 -0.03527236]
 [-0.02851149  0.08208583  0.99621743]
 [ 0.68216968 -0.72686851  0.07941567]]
transform [[ 0.73063785  0.68185353 -0.03527236]
 [-0.02851149  0.08208583  0.99621743]
 [ 0.68216968 -0.72686851  0.07941567]]
transform [[ 0.73063785  0.68185353 -0.03527236]
 [-0.02851149  0.08208583  0.99621743]
 [ 0.68216968 -0.72686851  0.07941567]]
support
[-0.04296636  1.21352353  0.09673871]
[525.53450158 737.20108802 800.03299518]
[-190.49186725  -32.06444841  206.76191521]
[ 0.34566913 -9.76293081 -0.77827358]
v_real [ 0.8127689   0.04173296 -1.0779324 ]
zmp_s [        0.            991575.87978487 -25611671.89893213]
transform [[ 0.73063785 -0.02851149  0.68216968]
 [ 0.68185353  0.08208583 -0.72686851]
 [-0.03527236  0.99621743  0.07941567]]
zmp [-17499777.21943667  18697712.13012193  -1046142.94854254]
d1:28346939.87327, d2:0.05940, d3:12092418.74975
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-318.2619956266699 steps:57[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-181.6390386914067 steps:58[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-254.4350049999946 steps:59[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.18315211 -0.37700716  0.9079212 ]
 [-0.6625191   0.63498437  0.39732021]
 [-0.72630835 -0.67428517 -0.13347574]]
planes
[[ 0.18315211 -0.37700716  0.9079212 ]
 [-0.6625191   0.63498437  0.39732021]
 [-0.72630835 -0.67428517 -0.13347574]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 908.7149  -162.6674   779.41077]
[   2.78033236 -282.8082708    -8.80392599]
[ 0.   0.  -9.8]
transform [[ 0.18315211 -0.37700716  0.9079212 ]
 [-0.6625191   0.63498437  0.39732021]
 [-0.72630835 -0.67428517 -0.13347574]]
transform [[ 0.18315211 -0.37700716  0.9079212 ]
 [-0.6625191   0.63498437  0.39732021]
 [-0.72630835 -0.67428517 -0.13347574]]
transform [[ 0.18315211 -0.37700716  0.9079212 ]
 [-0.6625191   0.63498437  0.39732021]
 [-0.72630835 -0.67428517 -0.13347574]]
support
[ 1.10596713  0.48398815 -0.16259096]
[ 935.40338179 -395.65658807 -654.35542601]
[  99.13669477 -184.91883382  189.84915582]
[-8.89762771 -3.89373807  1.30806221]
v_real [-1.0561391  -0.5343748  -0.84650224]
zmp_s [        0.         -12696744.2439786  -20112893.58263764]
transform [[ 0.18315211 -0.6625191  -0.72630835]
 [-0.37700716  0.63498437 -0.67428517]
 [ 0.9079212   0.39732021 -0.13347574]]
zmp [23019998.00267748  5499591.7410801  -2360089.83150929]
d1:29742978.65055, d2:0.05940, d3:10333976.71652
eta 23760000.0
transform [[ 0.67445588 -0.66163534 -0.32763994]
 [ 0.1326105  -0.3279911   0.93532687]
 [-0.72630835 -0.67428517 -0.13347574]]
planes
[[ 0.67445588 -0.66163534 -0.32763994]
 [ 0.1326105  -0.3279911   0.93532687]
 [-0.72630835 -0.67428517 -0.13347574]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 908.7149  -162.6674   779.41077]
[   2.78033236 -282.8082708    -8.80392599]
[ 0.   0.  -9.8]
transform [[ 0.67445588 -0.66163534 -0.32763994]
 [ 0.1326105  -0.3279911   0.93532687]
 [-0.72630835 -0.67428517 -0.13347574]]
transform [[ 0.67445588 -0.66163534 -0.32763994]
 [ 0.1326105  -0.3279911   0.93532687]
 [-0.72630835 -0.67428517 -0.13347574]]
transform [[ 0.67445588 -0.66163534 -0.32763994]
 [ 0.1326105  -0.3279911   0.93532687]
 [-0.72630835 -0.67428517 -0.13347574]]
support
[-0.39910843  1.13935085 -0.16259096]
[ 465.14852016  902.86243437 -654.35542601]
[191.87567547  84.89274799 189.84915582]
[ 3.21087139 -9.16620337  1.30806221]
v_real [-1.0561391  -0.5343748  -0.84650224]
zmp_s [        0.         -12696743.5044429  -20112894.53782409]
transform [[ 0.67445588  0.1326105  -0.72630835]
 [-0.66163534 -0.3279911  -0.67428517]
 [-0.32763994  0.93532687 -0.13347574]]
zmp [12924441.65820596 17726245.42648526 -9191022.01806889]
d1:36990061.48607, d2:0.05940, d3:15662531.71079
eta 23760000.0
transform [[ 0.42361066  0.32449216  0.84572983]
 [-0.3602303  -0.79629177  0.4859564 ]
 [ 0.83113664 -0.51051378 -0.22042577]]
planes
[[ 0.42361066  0.32449216  0.84572983]
 [-0.3602303  -0.79629177  0.4859564 ]
 [ 0.83113664 -0.51051378 -0.22042577]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[2162.8145 -741.8098 2688.0085]
[ -21.8908408  -621.0350719   109.82516646]
[ 0.   0.  -9.8]
transform [[ 0.42361066  0.32449216  0.84572983]
 [-0.3602303  -0.79629177  0.4859564 ]
 [ 0.83113664 -0.51051378 -0.22042577]]
transform [[ 0.42361066  0.32449216  0.84572983]
 [-0.3602303  -0.79629177  0.4859564 ]
 [ 0.83113664 -0.51051378 -0.22042577]]
transform [[ 0.42361066  0.32449216  0.84572983]
 [-0.3602303  -0.79629177  0.4859564 ]
 [ 0.83113664 -0.51051378 -0.22042577]]
support
[ 1.03020989  0.59195865 -0.26850751]
[2948.80879007 1117.84071396 1583.79212775]
[-117.91178409  555.78110241  274.64438682]
[-8.28815231 -4.76237273  2.16017254]
v_real [-0.34379348  0.56851923 -0.5827249 ]
zmp_s [        0.          13508017.10859231 -13845544.63513736]
transform [[ 0.42361066 -0.3602303   0.83113664]
 [ 0.32449216 -0.79629177 -0.51051378]
 [ 0.84572983  0.4859564  -0.22042577]]
zmp [-16373536.51371557  -3687981.47054296   9616222.20671029]
d1:26882221.02250, d2:0.05940, d3:11028583.35187
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-327.0636948799495 steps:63[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.11805248 -0.00638224 -0.99298686]
 [ 0.70692027 -0.70172793  0.08855332]
 [-0.69737172 -0.71241647 -0.078329  ]]
planes
[[ 0.11805248 -0.00638224 -0.99298686]
 [ 0.70692027 -0.70172793  0.08855332]
 [-0.69737172 -0.71241647 -0.078329  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[2162.8145 -741.8098 2688.0085]
[ -21.8908408  -621.0350719   109.82516646]
[ 0.   0.  -9.8]
transform [[ 0.11805248 -0.00638224 -0.99298686]
 [ 0.70692027 -0.70172793  0.08855332]
 [-0.69737172 -0.71241647 -0.078329  ]]
transform [[ 0.11805248 -0.00638224 -0.99298686]
 [ 0.70692027 -0.70172793  0.08855332]
 [-0.69737172 -0.71241647 -0.078329  ]]
transform [[ 0.11805248 -0.00638224 -0.99298686]
 [ 0.70692027 -0.70172793  0.08855332]
 [-0.69737172 -0.71241647 -0.078329  ]]
support
[-1.20958827  0.10786957 -0.09541499]
[-2409.09713549  2287.51812448 -1190.35712147]
[-107.67562048  430.04795802  449.09917191]
[ 9.73127121 -0.86782258  0.76762417]
v_real [-0.47655213  0.16945584 -0.17639326]
zmp_s [       0.          4026269.89227851 -4191103.42494325]
transform [[ 0.11805248  0.70692027 -0.69737172]
 [-0.00638224 -0.70172793 -0.71241647]
 [-0.99298686  0.08855332 -0.078329  ]]
zmp [5769008.79331064  160465.08364745  684824.51082477]
d1:6221184.82278, d2:0.05940, d3:2452661.34985
eta 23760000.0
transform [[ 0.71579218 -0.69783515 -0.02583966]
 [-0.03625213 -0.07408714  0.99659264]
 [-0.69737172 -0.71241647 -0.078329  ]]
planes
[[ 0.71579218 -0.69783515 -0.02583966]
 [-0.03625213 -0.07408714  0.99659264]
 [-0.69737172 -0.71241647 -0.078329  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[2162.8145 -741.8098 2688.0085]
[ -21.8908408  -621.0350719   109.82516646]
[ 0.   0.  -9.8]
transform [[ 0.71579218 -0.69783515 -0.02583966]
 [-0.03625213 -0.07408714  0.99659264]
 [-0.69737172 -0.71241647 -0.078329  ]]
transform [[ 0.71579218 -0.69783515 -0.02583966]
 [-0.03625213 -0.07408714  0.99659264]
 [-0.69737172 -0.71241647 -0.078329  ]]
transform [[ 0.71579218 -0.69783515 -0.02583966]
 [-0.03625213 -0.07408714  0.99659264]
 [-0.69737172 -0.71241647 -0.078329  ]]
support
[-0.0314761   1.21398059 -0.09541499]
[ 1996.32939887  2655.40147644 -1190.35712147]
[414.87296309 156.25525171 449.09917191]
[ 0.25322869 -9.76660788  0.76762417]
v_real [-0.47655213  0.16945584 -0.17639326]
zmp_s [       0.          4026271.78075506 -4191103.78590751]
transform [[ 0.71579218 -0.03625213 -0.69737172]
 [-0.69783515 -0.07408714 -0.71241647]
 [-0.02583966  0.99659264 -0.078329  ]]
zmp [2776796.34889043 2687516.42181734 4340837.78231058]
d1:9910397.40188, d2:0.05940, d3:4460030.35247
eta 23760000.0
transform [[ 0.32952115  0.2869871   0.89947444]
 [-0.6429534  -0.62943572  0.43637335]
 [ 0.69139487 -0.72211438 -0.022893  ]]
planes
[[ 0.32952115  0.2869871   0.89947444]
 [-0.6429534  -0.62943572  0.43637335]
 [ 0.69139487 -0.72211438 -0.022893  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-302.4152  1353.1213  -934.92126]
[-25.40496681 -58.41102609  25.66578127]
[ 0.   0.  -9.8]
transform [[ 0.32952115  0.2869871   0.89947444]
 [-0.6429534  -0.62943572  0.43637335]
 [ 0.69139487 -0.72211438 -0.022893  ]]
transform [[ 0.32952115  0.2869871   0.89947444]
 [-0.6429534  -0.62943572  0.43637335]
 [ 0.69139487 -0.72211438 -0.022893  ]]
transform [[ 0.32952115  0.2869871   0.89947444]
 [-0.6429534  -0.62943572  0.43637335]
 [ 0.69139487 -0.72211438 -0.022893  ]]
support
[ 1.09567788  0.53156    -0.02788668]
[ -552.26162099 -1065.23875356 -1164.79353602]
[-2.04897033 64.30005886 24.02701169]
[-8.81484953 -4.27645886  0.22435144]
v_real [ 1.5873144 -1.5241855 -0.7243473]
zmp_s [        0.         -36214649.51418103 -17210494.41667471]
transform [[ 0.32952115 -0.6429534   0.69139487]
 [ 0.2869871  -0.62943572 -0.72211438]
 [ 0.89947444  0.43637335 -0.022893  ]]
zmp [ 11385084.41179863  35222739.49826619 -15409108.11680657]
d1:49750578.86179, d2:0.05940, d3:18822035.19096
eta 23760000.0
transform [[ 0.96318799 -0.17775932 -0.20166931]
 [ 0.26861826  0.60671538  0.74815828]
 [-0.01063617 -0.77478909  0.63213032]]
planes
[[ 0.96318799 -0.17775932 -0.20166931]
 [ 0.26861826  0.60671538  0.74815828]
 [-0.01063617 -0.77478909  0.63213032]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-302.4152  1353.1213  -934.92126]
[-25.40496681 -58.41102609  25.66578127]
[ 0.   0.  -9.8]
transform [[ 0.96318799 -0.17775932 -0.20166931]
 [ 0.26861826  0.60671538  0.74815828]
 [-0.01063617 -0.77478909  0.63213032]]
transform [[ 0.96318799 -0.17775932 -0.20166931]
 [ 0.26861826  0.60671538  0.74815828]
 [-0.01063617 -0.77478909  0.63213032]]
transform [[ 0.96318799 -0.17775932 -0.20166931]
 [ 0.26861826  0.60671538  0.74815828]
 [-0.01063617 -0.77478909  0.63213032]]
support
[-0.24565967  0.91135494  0.77001767]
[ -343.26768746    40.2562053  -1636.15919936]
[-19.26265502 -23.06103916  61.75055629]
[ 1.97635919 -7.33195111 -6.19487718]
v_real [-0.8034797  1.4102902  0.9947966]
zmp_s [       0.         33508497.06858834 23636368.01974531]
transform [[ 0.96318799  0.26861826 -0.01063617]
 [-0.17775932  0.60671538 -0.77478909]
 [-0.20166931  0.74815828  0.63213032]]
zmp [ 8749593.55704498  2016920.38524973 40010924.39527544]
d1:71371297.04637, d2:0.05940, d3:24622732.94884
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-415.7976224006393 steps:68[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.66603887  0.68530881  0.29452354]
 [-0.20762648 -0.20891441  0.95563912]
 [ 0.71643806 -0.69764364  0.00314312]]
planes
[[ 0.66603887  0.68530881  0.29452354]
 [-0.20762648 -0.20891441  0.95563912]
 [ 0.71643806 -0.69764364  0.00314312]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 452.51862 -603.5776   876.1924 ]
[  54.25281047 -425.2223398   -35.27138283]
[ 0.   0.  -9.8]
transform [[ 0.66603887  0.68530881  0.29452354]
 [-0.20762648 -0.20891441  0.95563912]
 [ 0.71643806 -0.69764364  0.00314312]]
transform [[ 0.66603887  0.68530881  0.29452354]
 [-0.20762648 -0.20891441  0.95563912]
 [ 0.71643806 -0.69764364  0.00314312]]
transform [[ 0.66603887  0.68530881  0.29452354]
 [-0.20762648 -0.20891441  0.95563912]
 [ 0.71643806 -0.69764364  0.00314312]]
support
[0.35876831 1.16409383 0.00382874]
[145.81723508 869.46493074 748.03759337]
[-265.66238921   43.86404268  335.41157565]
[-2.88633066 -9.36526341 -0.03080261]
v_real [ 0.04703289 -0.3566026  -0.72024316]
zmp_s [        0.          -8472881.34149635 -17112979.5668399 ]
transform [[ 0.66603887 -0.20762648  0.71643806]
 [ 0.68530881 -0.20891441 -0.69764364]
 [ 0.29452354  0.95563912  0.00314312]]
zmp [-10501195.29478943  13708868.35692153  -8150805.11190389]
d1:27917564.65572, d2:0.05940, d3:12856858.14588
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-512.8428545837553 steps:70[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69163889  0.66464263 -0.28264073]
 [ 0.20693545  0.192568    0.959216  ]
 [ 0.69196337 -0.72191948 -0.00435058]]
planes
[[ 0.69163889  0.66464263 -0.28264073]
 [ 0.20693545  0.192568    0.959216  ]
 [ 0.69196337 -0.72191948 -0.00435058]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[212.67862 223.67268 127.76249]
[ -56.33146584 -234.16159123   23.49765185]
[ 0.   0.  -9.8]
transform [[ 0.69163889  0.66464263 -0.28264073]
 [ 0.20693545  0.192568    0.959216  ]
 [ 0.69196337 -0.72191948 -0.00435058]]
transform [[ 0.69163889  0.66464263 -0.28264073]
 [ 0.20693545  0.192568    0.959216  ]
 [ 0.69196337 -0.72191948 -0.00435058]]
transform [[ 0.69163889  0.66464263 -0.28264073]
 [ 0.20693545  0.192568    0.959216  ]
 [ 0.69196337 -0.72191948 -0.00435058]]
support
[-0.34429349  1.16845094 -0.00529958]
[259.64832214 209.63477196 -14.86369305]
[-201.23620201  -34.20968394  129.96427377]
[ 2.76987911 -9.40031679  0.04263572]
v_real [0.36561635 0.45021302 0.04584369]
zmp_s [       0.         10697061.93590283  1089245.96989192]
transform [[ 0.69163889  0.20693545  0.69196337]
 [ 0.66464263  0.192568   -0.72191948]
 [-0.28264073  0.959216   -0.00435058]]
zmp [ 2967319.64714566  1273563.98617249 10256054.09188179]
d1:20974146.13622, d2:0.05940, d3:7224792.54142
eta 23760000.0
transform [[ 0.93961525  0.06693373 -0.33562347]
 [ 0.26248139  0.48834831  0.83223766]
 [ 0.21960588 -0.87007809  0.44129062]]
planes
[[ 0.93961525  0.06693373 -0.33562347]
 [ 0.26248139  0.48834831  0.83223766]
 [ 0.21960588 -0.87007809  0.44129062]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[212.67862 223.67268 127.76249]
[ -56.33146584 -234.16159123   23.49765185]
[ 0.   0.  -9.8]
transform [[ 0.93961525  0.06693373 -0.33562347]
 [ 0.26248139  0.48834831  0.83223766]
 [ 0.21960588 -0.87007809  0.44129062]]
transform [[ 0.93961525  0.06693373 -0.33562347]
 [ 0.26248139  0.48834831  0.83223766]
 [ 0.21960588 -0.87007809  0.44129062]]
transform [[ 0.93961525  0.06693373 -0.33562347]
 [ 0.26248139  0.48834831  0.83223766]
 [ 0.21960588 -0.87007809  0.44129062]]
support
[-0.40883342  1.01377466  0.53754987]
[171.92723041 271.38311122 -91.52683805]
[ -76.48957629 -109.58274695  201.73744158]
[ 3.28911003 -8.15592908 -4.32464805]
v_real [-0.43125117  0.9010886   0.03026365]
zmp_s [       0.         21409866.47660232   719064.06348501]
transform [[ 0.93961525  0.26248139  0.21960588]
 [ 0.06693373  0.48834831 -0.87007809]
 [-0.33562347  0.83223766  0.44129062]]
zmp [ 5777602.2381036   9829830.12426846 18135413.42057465]
d1:41527250.04289, d2:0.05940, d3:10690564.55826
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-363.0390846109502 steps:73[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.14443867 -0.10674307  0.9837395 ]
 [-0.69955611  0.69210154  0.17781128]
 [-0.69982773 -0.71386379  0.02529347]]
planes
[[ 0.14443867 -0.10674307  0.9837395 ]
 [-0.69955611  0.69210154  0.17781128]
 [-0.69982773 -0.71386379  0.02529347]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[212.67862 223.67268 127.76249]
[ -56.33146584 -234.16159123   23.49765185]
[ 0.   0.  -9.8]
transform [[ 0.14443867 -0.10674307  0.9837395 ]
 [-0.69955611  0.69210154  0.17781128]
 [-0.69982773 -0.71386379  0.02529347]]
transform [[ 0.14443867 -0.10674307  0.9837395 ]
 [-0.69955611  0.69210154  0.17781128]
 [-0.69982773 -0.71386379  0.02529347]]
transform [[ 0.14443867 -0.10674307  0.9837395 ]
 [-0.69955611  0.69210154  0.17781128]
 [-0.69982773 -0.71386379  0.02529347]]
support
[1.19832377 0.21659747 0.03081076]
[ 132.52851511   28.74119205 -305.27866915]
[  39.97425276 -118.47842868  207.17613995]
[-9.64064705 -1.74255054 -0.24787596]
v_real [ 0.70787406 -0.57867926 -0.7649586 ]
zmp_s [        0.         -13749420.73257178 -18175413.95400827]
transform [[ 0.14443867 -0.69955611 -0.69982773]
 [-0.10674307  0.69210154 -0.71386379]
 [ 0.9837395   0.17781128  0.02529347]]
zmp [22338150.01507059  3458774.65255302 -2904521.30774159]
d1:27328151.32027, d2:0.05940, d3:10027166.61709
eta 23760000.0
transform [[ 0.71369368 -0.70025641 -0.01680498]
 [ 0.02970837  0.00629119  0.99953878]
 [-0.69982773 -0.71386379  0.02529347]]
planes
[[ 0.71369368 -0.70025641 -0.01680498]
 [ 0.02970837  0.00629119  0.99953878]
 [-0.69982773 -0.71386379  0.02529347]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[212.67862 223.67268 127.76249]
[ -56.33146584 -234.16159123   23.49765185]
[ 0.   0.  -9.8]
transform [[ 0.71369368 -0.70025641 -0.01680498]
 [ 0.02970837  0.00629119  0.99953878]
 [-0.69982773 -0.71386379  0.02529347]]
transform [[ 0.71369368 -0.70025641 -0.01680498]
 [ 0.02970837  0.00629119  0.99953878]
 [-0.69982773 -0.71386379  0.02529347]]
transform [[ 0.71369368 -0.70025641 -0.01680498]
 [ 0.02970837  0.00629119  0.99953878]
 [-0.69982773 -0.71386379  0.02529347]]
support
[-0.02047067  1.21756937  0.03081076]
[  -6.98788981  135.42906607 -305.27866915]
[123.37486595  20.34014221 207.17613995]
[ 0.16468881 -9.79548004 -0.24787596]
v_real [ 0.70787406 -0.57867926 -0.7649586 ]
zmp_s [        0.         -13749387.79586919 -18175418.03358818]
transform [[ 0.71369368  0.02970837 -0.69982773]
 [-0.70025641  0.00629119 -0.71386379]
 [-0.01680498  0.99953878  0.02529347]]
zmp [ 12311189.64846378  12888272.73847275 -14202765.60572139]
d1:37377008.51743, d2:0.05940, d3:17056612.30111
eta 23760000.0
transform [[ 0.89453709  0.37306458  0.246224  ]
 [-0.24472308 -0.05220777  0.96818644]
 [ 0.37405089 -0.92633533  0.04459573]]
planes
[[ 0.89453709  0.37306458  0.246224  ]
 [-0.24472308 -0.05220777  0.96818644]
 [ 0.37405089 -0.92633533  0.04459573]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-826.3693     43.080276  945.7486  ]
[  33.72675854 -546.92660633    7.98448322]
[ 0.   0.  -9.8]
transform [[ 0.89453709  0.37306458  0.246224  ]
 [-0.24472308 -0.05220777  0.96818644]
 [ 0.37405089 -0.92633533  0.04459573]]
transform [[ 0.89453709  0.37306458  0.246224  ]
 [-0.24472308 -0.05220777  0.96818644]
 [ 0.37405089 -0.92633533  0.04459573]]
transform [[ 0.89453709  0.37306458  0.246224  ]
 [-0.24472308 -0.05220777  0.96818644]
 [ 0.37405089 -0.92633533  0.04459573]]
support
[0.29993314 1.17937811 0.05432345]
[-490.28028266 1115.64348686 -306.83461096]
[-171.90313548   28.03057148  519.60903872]
[-2.41299521 -9.48822709 -0.43703815]
v_real [-1.0542979   0.5707508  -0.42693338]
zmp_s [        0.          13561040.90739368 -10143937.18962451]
transform [[ 0.89453709 -0.24472308  0.37405089]
 [ 0.37306458 -0.05220777 -0.92633533]
 [ 0.246224    0.96818644  0.04459573]]
zmp [-7113048.40802424  8688695.7249618  12677239.61325747]
d1:25956482.16773, d2:0.05940, d3:13103952.90263
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-348.7016307493044 steps:77[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.72791171  0.68464464 -0.03750144]
 [ 0.03473482  0.01780337  0.99923801]
 [ 0.68479049 -0.72865963 -0.01082172]]
planes
[[ 0.72791171  0.68464464 -0.03750144]
 [ 0.03473482  0.01780337  0.99923801]
 [ 0.68479049 -0.72865963 -0.01082172]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[377.39233   82.909485 539.3926  ]
[ -89.47676327 -164.98162912   38.91003337]
[ 0.   0.  -9.8]
transform [[ 0.72791171  0.68464464 -0.03750144]
 [ 0.03473482  0.01780337  0.99923801]
 [ 0.68479049 -0.72865963 -0.01082172]]
transform [[ 0.72791171  0.68464464 -0.03750144]
 [ 0.03473482  0.01780337  0.99923801]
 [ 0.68479049 -0.72865963 -0.01082172]]
transform [[ 0.72791171  0.68464464 -0.03750144]
 [ 0.03473482  0.01780337  0.99923801]
 [ 0.68479049 -0.72865963 -0.01082172]]
support
[-0.04568167  1.217203   -0.01318228]
[311.24383772 553.5662897  192.18473127]
[-179.54415393   32.83519709   58.52154251]
[ 0.36751407 -9.79253254  0.10605287]
v_real [ 0.02610504  0.1563338  -0.31379384]
zmp_s [       0.          3714492.35911628 -7455741.37962051]
transform [[ 0.72791171  0.03473482  0.68479049]
 [ 0.68464464  0.01780337 -0.72865963]
 [-0.03750144  0.99923801 -0.01082172]]
zmp [-4976598.60175929  5498828.2252536   3792345.92567281]
d1:12095623.30470, d2:0.05940, d3:5746800.82784
eta 23760000.0
transform [[ 0.99838763 -0.05534167  0.01262838]
 [-0.01992025 -0.13326152  0.99088073]
 [-0.05315416 -0.98953456 -0.13414906]]
planes
[[ 0.99838763 -0.05534167  0.01262838]
 [-0.01992025 -0.13326152  0.99088073]
 [-0.05315416 -0.98953456 -0.13414906]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[377.39233   82.909485 539.3926  ]
[ -89.47676327 -164.98162912   38.91003337]
[ 0.   0.  -9.8]
transform [[ 0.99838763 -0.05534167  0.01262838]
 [-0.01992025 -0.13326152  0.99088073]
 [-0.05315416 -0.98953456 -0.13414906]]
transform [[ 0.99838763 -0.05534167  0.01262838]
 [-0.01992025 -0.13326152  0.99088073]
 [-0.05315416 -0.98953456 -0.13414906]]
transform [[ 0.99838763 -0.05534167  0.01262838]
 [-0.01992025 -0.13326152  0.99088073]
 [-0.05315416 -0.98953456 -0.13414906]]
support
[ 0.01538302  1.20702273 -0.16341116]
[ 379.00714322  515.90731687 -174.46077976]
[-79.71076423  62.32330383 162.79134101]
[-0.1237581  -9.71063113  1.31466078]
v_real [ 1.0848911  -0.94773215  0.3269529 ]
zmp_s [        0.         -22518115.24319014   7768401.00811079]
transform [[ 0.99838763 -0.01992025 -0.05315416]
 [-0.05534167 -0.13326152 -0.98953456]
 [ 0.01262838  0.99088073 -0.13414906]]
zmp [    35643.66921967  -4686303.05880245 -23354890.11038235]
d1:47226976.52650, d2:0.05940, d3:11104937.93183
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-336.2974235029835 steps:80[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71455842  0.68517101  0.14123403]
 [-0.11259739 -0.08661238  0.98985863]
 [ 0.69045502 -0.72321439  0.01525886]]
planes
[[ 0.71455842  0.68517101  0.14123403]
 [-0.11259739 -0.08661238  0.98985863]
 [ 0.69045502 -0.72321439  0.01525886]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[526.4786   272.8477   -89.829575]
[  26.88573452 -497.64471777  -22.99949521]
[ 0.   0.  -9.8]
transform [[ 0.71455842  0.68517101  0.14123403]
 [-0.11259739 -0.08661238  0.98985863]
 [ 0.69045502 -0.72321439  0.01525886]]
transform [[ 0.71455842  0.68517101  0.14123403]
 [-0.11259739 -0.08661238  0.98985863]
 [ 0.69045502 -0.72321439  0.01525886]]
transform [[ 0.71455842  0.68517101  0.14123403]
 [-0.11259739 -0.08661238  0.98985863]
 [ 0.69045502 -0.72321439  0.01525886]]
support
[0.17204157 1.20577768 0.0185873 ]
[ 550.46003344 -171.83068136  164.8117059 ]
[-325.00861619   17.3086816   378.11626415]
[-1.38409345 -9.70061455 -0.14953686]
v_real [ 0.24508947 -0.32385063 -0.22536059]
zmp_s [       0.         -7694690.42598436 -5354567.50148289]
transform [[ 0.71455842 -0.11259739  0.69045502]
 [ 0.68517101 -0.08661238 -0.72321439]
 [ 0.14123403  0.98985863  0.01525886]]
zmp [-2830685.94192106  4538955.7171886  -7698360.31768453]
d1:16802233.37835, d2:0.05940, d3:7255102.89691
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-470.3039510343691 steps:82[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.6979686   0.69711626 -0.16391692]
 [ 0.14327565  0.08833024  0.98573321]
 [ 0.70164949 -0.71149611 -0.03822805]]
planes
[[ 0.6979686   0.69711626 -0.16391692]
 [ 0.14327565  0.08833024  0.98573321]
 [ 0.70164949 -0.71149611 -0.03822805]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 18.068455 189.71391  -61.057537]
[  55.67925097 -413.45900786   16.40169083]
[ 0.   0.  -9.8]
transform [[ 0.6979686   0.69711626 -0.16391692]
 [ 0.14327565  0.08833024  0.98573321]
 [ 0.70164949 -0.71149611 -0.03822805]]
transform [[ 0.6979686   0.69711626 -0.16391692]
 [ 0.14327565  0.08833024  0.98573321]
 [ 0.70164949 -0.71149611 -0.03822805]]
transform [[ 0.6979686   0.69711626 -0.16391692]
 [ 0.14327565  0.08833024  0.98573321]
 [ 0.70164949 -0.71149611 -0.03822805]]
support
[-0.19967231  1.20075238 -0.04656678]
[ 154.87222993  -40.84019723 -119.96887941]
[-252.05514107  -12.37576085  332.61479092]
[ 1.60638577 -9.66018547  0.37463489]
v_real [ 0.24868536  0.08237898 -0.281445  ]
zmp_s [       0.          1957323.63568751 -6687133.27826246]
transform [[ 0.6979686   0.14327565  0.70164949]
 [ 0.69711626  0.08833024 -0.71149611]
 [-0.16391692  0.98573321 -0.03822805]]
zmp [-4411586.82137313  4930760.21082427  2185034.97692926]
d1:9924195.25847, d2:0.05940, d3:4343424.77661
eta 23760000.0
transform [[ 0.99046731  0.00883112 -0.13746461]
 [ 0.13183467  0.22848253  0.96458048]
 [ 0.03992663 -0.973508    0.22514021]]
planes
[[ 0.99046731  0.00883112 -0.13746461]
 [ 0.13183467  0.22848253  0.96458048]
 [ 0.03992663 -0.973508    0.22514021]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 18.068455 189.71391  -61.057537]
[  55.67925097 -413.45900786   16.40169083]
[ 0.   0.  -9.8]
transform [[ 0.99046731  0.00883112 -0.13746461]
 [ 0.13183467  0.22848253  0.96458048]
 [ 0.03992663 -0.973508    0.22514021]]
transform [[ 0.99046731  0.00883112 -0.13746461]
 [ 0.13183467  0.22848253  0.96458048]
 [ 0.03992663 -0.973508    0.22514021]]
transform [[ 0.99046731  0.00883112 -0.13746461]
 [ 0.13183467  0.22848253  0.96458048]
 [ 0.03992663 -0.973508    0.22514021]]
support
[-0.16744993  1.17498557  0.27425032]
[  27.96484992  -13.16654469 -197.71310658]
[ 49.24252162 -71.30695349 408.42141678]
[ 1.3471532  -9.45288867 -2.2063741 ]
v_real [0.7066593  0.36286515 0.4856913 ]
zmp_s [       0.          8621663.11217869 11540022.69948756]
transform [[ 0.99046731  0.13183467  0.03992663]
 [ 0.00883112  0.22848253 -0.973508  ]
 [-0.13746461  0.96458048  0.22514021]]
zmp [ 1597388.28692585 -9264405.02589847 10914411.09084513]
d1:26622721.20922, d2:0.05940, d3:6018930.29671
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-407.8192135146572 steps:85[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-236.1210089062468 steps:86[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70933867  0.70149994  0.06882174]
 [-0.07009779 -0.02694844  0.99717611]
 [ 0.70137364 -0.71215987  0.03005802]]
planes
[[ 0.70933867  0.70149994  0.06882174]
 [-0.07009779 -0.02694844  0.99717611]
 [ 0.70137364 -0.71215987  0.03005802]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 520.67554 -274.0019  1180.647  ]
[  25.63550797 -309.20317571   -2.83276353]
[ 0.   0.  -9.8]
transform [[ 0.70933867  0.70149994  0.06882174]
 [-0.07009779 -0.02694844  0.99717611]
 [ 0.70137364 -0.71215987  0.03005802]]
transform [[ 0.70933867  0.70149994  0.06882174]
 [-0.07009779 -0.02694844  0.99717611]
 [ 0.70137364 -0.71215987  0.03005802]]
transform [[ 0.70933867  0.70149994  0.06882174]
 [-0.07009779 -0.02694844  0.99717611]
 [ 0.70137364 -0.71215987  0.03005802]]
support
[0.08383391 1.21469133 0.03661462]
[ 258.3771625  1148.19867508  595.809163  ]
[-198.91670761    3.71078578  238.09701623]
[-0.67445308 -9.77232589 -0.29456864]
v_real [-0.02324924 -0.9026748  -0.13936558]
zmp_s [        0.         -21447554.07957426  -3311326.39271424]
transform [[ 0.70933867 -0.07009779  0.70137364]
 [ 0.70149994 -0.02694844 -0.71215987]
 [ 0.06882174  0.99717611  0.03005802]]
zmp [  -819050.91038645   2936171.84211623 -21486520.49172959]
d1:42989278.70251, d2:0.05940, d3:14856061.18308
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-215.7396366939878 steps:88[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-268.77885021482405 steps:89[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.06791465  0.2198115   0.97317553]
 [-0.80143553  0.59297234 -0.07800536]
 [-0.59421259 -0.77463979  0.21643624]]
planes
[[ 0.06791465  0.2198115   0.97317553]
 [-0.80143553  0.59297234 -0.07800536]
 [-0.59421259 -0.77463979  0.21643624]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 520.67554 -274.0019  1180.647  ]
[  25.63550797 -309.20317571   -2.83276353]
[ 0.   0.  -9.8]
transform [[ 0.06791465  0.2198115   0.97317553]
 [-0.80143553  0.59297234 -0.07800536]
 [-0.59421259 -0.77463979  0.21643624]]
transform [[ 0.06791465  0.2198115   0.97317553]
 [-0.80143553  0.59297234 -0.07800536]
 [-0.59421259 -0.77463979  0.21643624]]
transform [[ 0.06791465  0.2198115   0.97317553]
 [-0.80143553  0.59297234 -0.07800536]
 [-0.59421259 -0.77463979  0.21643624]]
support
[ 1.18545547 -0.09502076  0.26364773]
[1124.10946836 -671.86020822  158.39559465]
[ -68.98216317 -203.67316626  223.67502734]
[-9.53712015  0.76445251 -2.12107512]
v_real [ 1.025648    0.831668   -0.02181764]
zmp_s [       0.         19760432.41807209  -518387.24155193]
transform [[ 0.06791465 -0.80143553 -0.59421259]
 [ 0.2198115   0.59297234 -0.77463979]
 [ 0.97317553 -0.07800536  0.21643624]]
zmp [-15528680.40539641  12118953.19627243  -1653617.40032432]
d1:26100205.99822, d2:0.05940, d3:1009032.11926
eta 23760000.0
transform [[ 0.32099718 -0.47513765 -0.81927103]
 [ 0.73747694 -0.41734576  0.53098994]
 [-0.59421259 -0.77463979  0.21643624]]
planes
[[ 0.32099718 -0.47513765 -0.81927103]
 [ 0.73747694 -0.41734576  0.53098994]
 [-0.59421259 -0.77463979  0.21643624]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 520.67554 -274.0019  1180.647  ]
[  25.63550797 -309.20317571   -2.83276353]
[ 0.   0.  -9.8]
transform [[ 0.32099718 -0.47513765 -0.81927103]
 [ 0.73747694 -0.41734576  0.53098994]
 [-0.59421259 -0.77463979  0.21643624]]
transform [[ 0.32099718 -0.47513765 -0.81927103]
 [ 0.73747694 -0.41734576  0.53098994]
 [-0.59421259 -0.77463979  0.21643624]]
transform [[ 0.32099718 -0.47513765 -0.81927103]
 [ 0.73747694 -0.41734576  0.53098994]
 [-0.59421259 -0.77463979  0.21643624]]
support
[-0.9979796   0.64681542  0.26364773]
[-669.94586532 1125.25140391  158.39559465]
[157.46379739 146.4460622  223.67502734]
[ 8.02885607 -5.20370146 -2.12107512]
v_real [ 1.025648    0.831668   -0.02181764]
zmp_s [       0.         19760431.29602715  -518387.34946444]
transform [[ 0.32099718  0.73747694 -0.59421259]
 [-0.47513765 -0.41734576 -0.77463979]
 [-0.81927103  0.53098994  0.21643624]]
zmp [14880894.79296572 -7845368.79659862 10380392.51848958]
d1:30051168.13877, d2:0.05940, d3:7765185.88215
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-378.8524273086458 steps:92[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.72869551  0.68295276  0.05077812]
 [-0.02910296 -0.04319771  0.99864256]
 [ 0.68421918 -0.72918421 -0.01160203]]
planes
[[ 0.72869551  0.68295276  0.05077812]
 [-0.02910296 -0.04319771  0.99864256]
 [ 0.68421918 -0.72918421 -0.01160203]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 662.4427 -692.0645 1443.8643]
[   1.039829   -516.65190259   -8.26695971]
[ 0.   0.  -9.8]
transform [[ 0.72869551  0.68295276  0.05077812]
 [-0.02910296 -0.04319771  0.99864256]
 [ 0.68421918 -0.72918421 -0.01160203]]
transform [[ 0.72869551  0.68295276  0.05077812]
 [-0.02910296 -0.04319771  0.99864256]
 [ 0.68421918 -0.72918421 -0.01160203]]
transform [[ 0.72869551  0.68295276  0.05077812]
 [-0.02910296 -0.04319771  0.99864256]
 [ 0.68421918 -0.72918421 -0.01160203]]
support
[ 0.06185441  1.21647766 -0.0141328 ]
[  83.38835065 1452.52086167  941.14674936]
[-352.51090561   14.03217723  377.54179408]
[-0.49762555 -9.78669713  0.11369992]
v_real [-0.39247552  0.27391413 -0.01011379]
zmp_s [      0.         6508195.08519308 -240304.29723142]
transform [[ 0.72869551 -0.02910296  0.68421918]
 [ 0.68295276 -0.04319771 -0.72918421]
 [ 0.05077812  0.99864256 -0.01160203]]
zmp [-353828.54260012 -105913.00089645 6502148.64408681]
d1:12901358.51290, d2:0.05940, d3:4169968.42731
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-199.4545812362377 steps:94[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-194.98064367186146 steps:95[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.17649871  0.09725412 -0.9794845 ]
 [ 0.69860399  0.68863297  0.19426045]
 [ 0.69339794 -0.71855849  0.05360071]]
planes
[[ 0.17649871  0.09725412 -0.9794845 ]
 [ 0.69860399  0.68863297  0.19426045]
 [ 0.69339794 -0.71855849  0.05360071]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[195.79442 100.17891 653.8178 ]
[ -43.84770481 -155.55318859    5.46719139]
[ 0.   0.  -9.8]
transform [[ 0.17649871  0.09725412 -0.9794845 ]
 [ 0.69860399  0.68863297  0.19426045]
 [ 0.69339794 -0.71855849  0.05360071]]
transform [[ 0.17649871  0.09725412 -0.9794845 ]
 [ 0.69860399  0.68863297  0.19426045]
 [ 0.69339794 -0.71855849  0.05360071]]
transform [[ 0.17649871  0.09725412 -0.9794845 ]
 [ 0.69860399  0.68863297  0.19426045]
 [ 0.69339794 -0.71855849  0.05360071]]
support
[-1.19314063  0.23663471  0.0652927 ]
[-596.10413567  332.7802016    98.82413911]
[ -28.22228104 -136.68917587   81.66320154]
[ 9.59894809 -1.90375239 -0.52528696]
v_real [ 0.6418968  -0.13531877  0.42788476]
zmp_s [       0.         -3215174.29723769 10166542.0983782 ]
transform [[ 0.17649871  0.69860399  0.69339794]
 [ 0.09725412  0.68863297 -0.71855849]
 [-0.9794845   0.19426045  0.05360071]]
zmp [ 4803325.75467723 -9519330.15112263   -79647.32652597]
d1:10772384.25503, d2:0.05940, d3:5333804.80578
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-485.4318145936891 steps:97[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.19095778 -0.01802997 -0.98143268]
 [ 0.98154432  0.0139878   0.19072254]
 [ 0.01028936 -0.99973959  0.02036829]]
planes
[[ 0.19095778 -0.01802997 -0.98143268]
 [ 0.98154432  0.0139878   0.19072254]
 [ 0.01028936 -0.99973959  0.02036829]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 197.86453 -129.10478  504.61172]
[ -43.84770481 -155.55318859    5.46719139]
[ 0.   0.  -9.8]
transform [[ 0.19095778 -0.01802997 -0.98143268]
 [ 0.98154432  0.0139878   0.19072254]
 [ 0.01028936 -0.99973959  0.02036829]]
transform [[ 0.19095778 -0.01802997 -0.98143268]
 [ 0.98154432  0.0139878   0.19072254]
 [ 0.01028936 -0.99973959  0.02036829]]
transform [[ 0.19095778 -0.01802997 -0.98143268]
 [ 0.98154432  0.0139878   0.19072254]
 [ 0.01028936 -0.99973959  0.02036829]]
support
[-1.19551376  0.23232508  0.02481125]
[-455.13090784  288.64774503  141.38514018]
[-10.93412194 -44.17159584 155.17287294]
[ 9.61804023 -1.86908089 -0.19960925]
v_real [ 0.19523689  0.4198991  -0.4485872 ]
zmp_s [        0.           9976802.81106908 -10658432.25490603]
transform [[ 0.19095778  0.98154432  0.01028936]
 [-0.01802997  0.0139878  -0.99973959]
 [-0.98143268  0.19072254  0.02036829]]
zmp [ 9683005.60472871 10795210.19657301  1685707.12294963]
d1:12840093.34890, d2:0.05940, d3:5200265.01189
eta 23760000.0
transform [[ 0.98688674 -0.05117721  0.15308663]
 [-0.12589005  0.34955651  0.92841905]
 [-0.10102633 -0.93551654  0.33853   ]]
planes
[[ 0.98688674 -0.05117721  0.15308663]
 [-0.12589005  0.34955651  0.92841905]
 [-0.10102633 -0.93551654  0.33853   ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-328.87997  440.03183  660.8989 ]
[ 153.19796475 -695.44768904 -108.11075192]
[ 0.   0.  -9.8]
transform [[ 0.98688674 -0.05117721  0.15308663]
 [-0.12589005  0.34955651  0.92841905]
 [-0.10102633 -0.93551654  0.33853   ]]
transform [[ 0.98688674 -0.05117721  0.15308663]
 [-0.12589005  0.34955651  0.92841905]
 [-0.10102633 -0.93551654  0.33853   ]]
transform [[ 0.98688674 -0.05117721  0.15308663]
 [-0.12589005  0.34955651  0.92841905]
 [-0.10102633 -0.93551654  0.33853   ]]
support
[0.1864796  1.13093622 0.41237396]
[-245.91209655  808.80985921 -154.69739918]
[ 170.22980221 -362.75644493  598.52705117]
[-1.500249   -9.09850672 -3.31759404]
v_real [-0.7536369   0.02913599  0.07445307]
zmp_s [      0.          692275.34034244 1769006.75947679]
transform [[ 0.98688674 -0.12589005 -0.10102633]
 [-0.05117721  0.34955651 -0.93551654]
 [ 0.15308663  0.92841905  0.33853   ]]
zmp [ -265866.84218683 -1412945.72726487  1241583.48168493]
d1:3264244.46235, d2:0.05940, d3:679953.32742
eta 23760000.0
transform [[-0.52194995 -0.72275257 -0.45298681]
 [ 0.56590766  0.10393401 -0.81789142]
 [ 0.63821387 -0.68324703  0.35476285]]
planes
[[-0.52194995 -0.72275257 -0.45298681]
 [ 0.56590766  0.10393401 -0.81789142]
 [ 0.63821387 -0.68324703  0.35476285]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-328.87997  440.03183  660.8989 ]
[ 153.19796475 -695.44768904 -108.11075192]
[ 0.   0.  -9.8]
transform [[-0.52194995 -0.72275257 -0.45298681]
 [ 0.56590766  0.10393401 -0.81789142]
 [ 0.63821387 -0.68324703  0.35476285]]
transform [[-0.52194995 -0.72275257 -0.45298681]
 [ 0.56590766  0.10393401 -0.81789142]
 [ 0.63821387 -0.68324703  0.35476285]]
transform [[-0.52194995 -0.72275257 -0.45298681]
 [ 0.56590766  0.10393401 -0.81789142]
 [ 0.63821387 -0.68324703  0.35476285]]
support
[-0.55179736 -0.99629906  0.4321477 ]
[-445.75374513 -680.92498232 -276.08381498]
[471.64768004 102.8380889  534.58195561]
[ 4.4392707   8.01533591 -3.47667595]
v_real [ 1.4537693  -0.60130304 -2.0554707 ]
zmp_s [        0.         -14286958.94358659 -48837983.45133074]
transform [[-0.52194995  0.56590766  0.63821387]
 [-0.72275257  0.10393401 -0.68324703]
 [-0.45298681 -0.81789142  0.35476285]]
zmp [-39254178.02707876  31883506.1662965   -5640721.18187617]
d1:71556620.14285, d2:0.05940, d3:26100418.21038
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-871.4177435954587 steps:101[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.6607874   0.71663678  0.22314081]
 [-0.15384561 -0.1616635   0.9747802 ]
 [ 0.73463708 -0.67845172  0.00342621]]
planes
[[ 0.6607874   0.71663678  0.22314081]
 [-0.15384561 -0.1616635   0.9747802 ]
 [ 0.73463708 -0.67845172  0.00342621]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 723.749     60.09276 -418.96857]
[  35.27702624 -381.04652704   22.75325356]
[ 0.   0.  -9.8]
transform [[ 0.6607874   0.71663678  0.22314081]
 [-0.15384561 -0.1616635   0.9747802 ]
 [ 0.73463708 -0.67845172  0.00342621]]
transform [[ 0.6607874   0.71663678  0.22314081]
 [-0.15384561 -0.1616635   0.9747802 ]
 [ 0.73463708 -0.67845172  0.00342621]]
transform [[ 0.6607874   0.71663678  0.22314081]
 [-0.15384561 -0.1616635   0.9747802 ]
 [ 0.73463708 -0.67845172  0.00342621]]
support
[0.27181478 1.18741018 0.00417358]
[ 427.81993489 -529.46267871  489.48735958]
[-244.68416108   78.3535217   284.51543961]
[-2.1867799  -9.55284598 -0.03357689]
v_real [-0.20187587  0.01789081 -0.7666683 ]
zmp_s [        0.            425086.45693014 -18216040.12431089]
transform [[ 0.6607874  -0.15384561  0.73463708]
 [ 0.71663678 -0.1616635  -0.67845172]
 [ 0.22314081  0.9747802   0.00342621]]
zmp [-13447576.24017126  12289982.73198227    351953.81519463]
d1:24503069.00037, d2:0.05940, d3:8590496.95137
eta 23760000.0
transform [[ 0.94516063  0.17446922  0.2761012 ]
 [-0.18215066 -0.42010105  0.88900858]
 [ 0.27109504 -0.89054793 -0.36528328]]
planes
[[ 0.94516063  0.17446922  0.2761012 ]
 [-0.18215066 -0.42010105  0.88900858]
 [ 0.27109504 -0.89054793 -0.36528328]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 723.749     60.09276 -418.96857]
[  35.27702624 -381.04652704   22.75325356]
[ 0.   0.  -9.8]
transform [[ 0.94516063  0.17446922  0.2761012 ]
 [-0.18215066 -0.42010105  0.88900858]
 [ 0.27109504 -0.89054793 -0.36528328]]
transform [[ 0.94516063  0.17446922  0.2761012 ]
 [-0.18215066 -0.42010105  0.88900858]
 [ 0.27109504 -0.89054793 -0.36528328]]
transform [[ 0.94516063  0.17446922  0.2761012 ]
 [-0.18215066 -0.42010105  0.88900858]
 [ 0.27109504 -0.89054793 -0.36528328]]
support
[ 0.33632749  1.08292909 -0.44496296]
[ 578.86569273 -529.54304571  295.73149973]
[-26.85623255 173.88014879 340.59223999]
[-2.70579178 -8.7122841   3.57977615]
v_real [-0.58653635  0.23830962  0.02616746]
zmp_s [      0.        5662237.3059883  621738.4321086]
transform [[ 0.94516063 -0.18215066  0.27109504]
 [ 0.17446922 -0.42010105 -0.89054793]
 [ 0.2761012   0.88900858 -0.36528328]]
zmp [ -862830.06983438 -2932399.6925875   4806666.90213374]
d1:10966345.42328, d2:0.05940, d3:2591085.08691
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-450.50255265156034 steps:104[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.20399433 -0.20812722 -0.95659262]
 [ 0.66115391 -0.69134414  0.29140848]
 [-0.72198468 -0.69190055 -0.00342617]]
planes
[[ 0.20399433 -0.20812722 -0.95659262]
 [ 0.66115391 -0.69134414  0.29140848]
 [-0.72198468 -0.69190055 -0.00342617]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 723.749     60.09276 -418.96857]
[  35.27702624 -381.04652704   22.75325356]
[ 0.   0.  -9.8]
transform [[ 0.20399433 -0.20812722 -0.95659262]
 [ 0.66115391 -0.69134414  0.29140848]
 [-0.72198468 -0.69190055 -0.00342617]]
transform [[ 0.20399433 -0.20812722 -0.95659262]
 [ 0.66115391 -0.69134414  0.29140848]
 [-0.72198468 -0.69190055 -0.00342617]]
transform [[ 0.20399433 -0.20812722 -0.95659262]
 [ 0.66115391 -0.69134414  0.29140848]
 [-0.72198468 -0.69190055 -0.00342617]]
support
[-1.16525532  0.35497376 -0.00417352]
[ 535.91600026  314.87372929 -562.67846628]
[ 64.73687169 293.38831922 238.09887301]
[ 9.37460767 -2.8558031   0.03357644]
v_real [-0.28731197 -0.10510013  0.08334287]
zmp_s [       0.         -2497178.66490734  1980225.83152633]
transform [[ 0.20399433  0.66115391 -0.72198468]
 [-0.20812722 -0.69134414 -0.69190055]
 [-0.95659262  0.29140848 -0.00342617]]
zmp [-3080712.16677408   356290.49684211  -734483.62274586]
d1:3855775.75151, d2:0.05940, d3:1367829.00186
eta 23760000.0
transform [[ 0.20154917  0.45016539  0.86990178]
 [-0.7728768  -0.4724873   0.42357671]
 [ 0.60169709 -0.75769842  0.25269294]]
planes
[[ 0.20154917  0.45016539  0.86990178]
 [-0.7728768  -0.4724873   0.42357671]
 [ 0.60169709 -0.75769842  0.25269294]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   1.8135408 -432.18918   -283.7959   ]
[279.67620744 -37.22213138 210.16282607]
[ 0.   0.  -9.8]
transform [[ 0.20154917  0.45016539  0.86990178]
 [-0.7728768  -0.4724873   0.42357671]
 [ 0.60169709 -0.75769842  0.25269294]]
transform [[ 0.20154917  0.45016539  0.86990178]
 [-0.7728768  -0.4724873   0.42357671]
 [ 0.60169709 -0.75769842  0.25269294]]
transform [[ 0.20154917  0.45016539  0.86990178]
 [-0.7728768  -0.4724873   0.42357671]
 [ 0.60169709 -0.75769842  0.25269294]]
support
[1.05965449 0.51597201 0.30781315]
[-441.06564901   82.59292096  256.84703914]
[ 222.43340854 -109.54818864  249.59017136]
[-8.52503741 -4.15105178 -2.47639079]
v_real [0.2992134 2.1178813 1.1603397]
zmp_s [       0.         50320861.25600391 27569673.15100942]
transform [[ 0.20154917 -0.7728768   0.60169709]
 [ 0.45016539 -0.4724873  -0.75769842]
 [ 0.86990178  0.42357671  0.25269294]]
zmp [-22303234.14338565 -44665465.59617593  28281406.69055747]
d1:67292385.68962, d2:0.05940, d3:25664521.23919
eta 23760000.0
transform [[ 0.28644055  0.33423573  0.89790773]
 [-0.69768167  0.71507913 -0.04361326]
 [-0.65665221 -0.61396116  0.43801782]]
planes
[[ 0.28644055  0.33423573  0.89790773]
 [-0.69768167  0.71507913 -0.04361326]
 [-0.65665221 -0.61396116  0.43801782]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-80.70061  206.6012   -26.645021]
[-196.65124518 -280.1046429    90.49991558]
[ 0.   0.  -9.8]
transform [[ 0.28644055  0.33423573  0.89790773]
 [-0.69768167  0.71507913 -0.04361326]
 [-0.65665221 -0.61396116  0.43801782]]
transform [[ 0.28644055  0.33423573  0.89790773]
 [-0.69768167  0.71507913 -0.04361326]
 [-0.65665221 -0.61396116  0.43801782]]
transform [[ 0.28644055  0.33423573  0.89790773]
 [-0.69768167  0.71507913 -0.04361326]
 [-0.65665221 -0.61396116  0.43801782]]
support
[ 1.09376943 -0.05312667  0.53356317]
[ 22.01280394 205.20161366 -85.52387194]
[-68.68929614 -67.04401166 340.74542201]
[-8.79949579  0.4274099  -4.29257459]
v_real [ 0.02951426 -0.59870225 -1.0661821 ]
zmp_s [        0.         -14225208.86270582 -25332485.10559948]
transform [[ 0.28644055 -0.69768167 -0.65665221]
 [ 0.33423573  0.71507913 -0.61396116]
 [ 0.89790773 -0.04361326  0.43801782]]
zmp [ 26559299.79395759   5381011.98603148 -10475672.12148052]
d1:23517475.64175, d2:0.05940, d3:19329238.80824
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-584.787180029713 steps:108[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.2324733   0.27995285 -0.93144119]
 [ 0.67583716  0.64219892  0.36169705]
 [ 0.69942862 -0.71358746 -0.03990847]]
planes
[[ 0.2324733   0.27995285 -0.93144119]
 [ 0.67583716  0.64219892  0.36169705]
 [ 0.69942862 -0.71358746 -0.03990847]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-615.4184   270.6055   546.47015]
[ -46.57731041 -323.75085636    0.53953196]
[ 0.   0.  -9.8]
transform [[ 0.2324733   0.27995285 -0.93144119]
 [ 0.67583716  0.64219892  0.36169705]
 [ 0.69942862 -0.71358746 -0.03990847]]
transform [[ 0.2324733   0.27995285 -0.93144119]
 [ 0.67583716  0.64219892  0.36169705]
 [ 0.69942862 -0.71358746 -0.03990847]]
transform [[ 0.2324733   0.27995285 -0.93144119]
 [ 0.67583716  0.64219892  0.36169705]
 [ 0.69942862 -0.71358746 -0.03990847]]
support
[-1.13461757  0.44059446 -0.04861376]
[-576.31637211  -44.48341957 -645.35071892]
[-101.96549949 -239.19598042  198.42551646]
[ 9.12812364 -3.54463107  0.39110303]
v_real [ 0.06198009  0.31475815 -0.23490483]
zmp_s [       0.          7478654.38651164 -5581336.83669801]
transform [[ 0.2324733   0.67583716  0.69942862]
 [ 0.27995285  0.64219892 -0.71358746]
 [-0.93144119  0.36169705 -0.03990847]]
zmp [1150605.82486671 8785555.76484144 2927749.84160453]
d1:11883860.21996, d2:0.05940, d3:4119794.78497
eta 23760000.0
transform [[ 0.89007986  0.39379844  0.22952253]
 [-0.13031898 -0.26267108  0.95604444]
 [ 0.43677768 -0.88086706 -0.18247882]]
planes
[[ 0.89007986  0.39379844  0.22952253]
 [-0.13031898 -0.26267108  0.95604444]
 [ 0.43677768 -0.88086706 -0.18247882]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-615.4184   270.6055   546.47015]
[ -46.57731041 -323.75085636    0.53953196]
[ 0.   0.  -9.8]
transform [[ 0.89007986  0.39379844  0.22952253]
 [-0.13031898 -0.26267108  0.95604444]
 [ 0.43677768 -0.88086706 -0.18247882]]
transform [[ 0.89007986  0.39379844  0.22952253]
 [-0.13031898 -0.26267108  0.95604444]
 [ 0.43677768 -0.88086706 -0.18247882]]
transform [[ 0.89007986  0.39379844  0.22952253]
 [-0.13031898 -0.26267108  0.95604444]
 [ 0.43677768 -0.88086706 -0.18247882]]
support
[ 0.27958855  1.16458756 -0.22228314]
[-315.78028335  531.57021044 -606.88771783]
[-168.82627341   91.62571244  264.73908352]
[-2.24932076 -9.36923547  1.78829239]
v_real [-1.0799068 -0.7232949  0.3856097]
zmp_s [        0.         -17185485.54389589   9162084.957653  ]
transform [[ 0.89007986 -0.13031898  0.43677768]
 [ 0.39379844 -0.26267108 -0.88086706]
 [ 0.22952253  0.95604444 -0.18247882]]
zmp [  6241389.24427507  -3556448.77342126 -18101974.23453388]
d1:36100801.01873, d2:0.05940, d3:11213925.99819
eta 23760000.0
transform [[-0.3598305   0.90916103  0.20963857]
 [-0.93168384 -0.33811831 -0.13282037]
 [-0.04987246 -0.24310967  0.96871585]]
planes
[[-0.3598305   0.90916103  0.20963857]
 [-0.93168384 -0.33811831 -0.13282037]
 [-0.04987246 -0.24310967  0.96871585]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-652.29767  -108.354095 -856.74896 ]
[234.44248306  36.12227794 -43.73873999]
[ 0.   0.  -9.8]
transform [[-0.3598305   0.90916103  0.20963857]
 [-0.93168384 -0.33811831 -0.13282037]
 [-0.04987246 -0.24310967  0.96871585]]
transform [[-0.3598305   0.90916103  0.20963857]
 [-0.93168384 -0.33811831 -0.13282037]
 [-0.04987246 -0.24310967  0.96871585]]
transform [[-0.3598305   0.90916103  0.20963857]
 [-0.93168384 -0.33811831 -0.13282037]
 [-0.04987246 -0.24310967  0.96871585]]
support
[ 0.25536728 -0.16179263  1.180023  ]
[ -43.40234954  758.16541197 -771.07267958]
[ -60.68791485 -224.8304807   -62.84430861]
[-2.05445794  1.3016396  -9.4934153 ]
v_real [ 1.907109   -0.7360084   0.27923822]
zmp_s [        0.         -17487557.27776421   6634701.7409828 ]
transform [[-0.3598305  -0.93168384 -0.04987246]
 [ 0.90916103 -0.33811831 -0.24310967]
 [ 0.20963857 -0.13282037  0.96871585]]
zmp [15961985.60442385  4299903.22329127  8749844.50333238]
d1:26882189.63579, d2:0.05940, d3:7989314.85458
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-453.5130625197818 steps:112[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71547055 -0.69740629 -0.04154951]
 [ 0.0239428  -0.03496072  0.99910182]
 [-0.69823253 -0.71582282 -0.00831551]]
planes
[[ 0.71547055 -0.69740629 -0.04154951]
 [ 0.0239428  -0.03496072  0.99910182]
 [-0.69823253 -0.71582282 -0.00831551]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-652.29767  -108.354095 -856.74896 ]
[234.44248306  36.12227794 -43.73873999]
[ 0.   0.  -9.8]
transform [[ 0.71547055 -0.69740629 -0.04154951]
 [ 0.0239428  -0.03496072  0.99910182]
 [-0.69823253 -0.71582282 -0.00831551]]
transform [[ 0.71547055 -0.69740629 -0.04154951]
 [ 0.0239428  -0.03496072  0.99910182]
 [-0.69823253 -0.71582282 -0.00831551]]
transform [[ 0.71547055 -0.69740629 -0.04154951]
 [ 0.0239428  -0.03496072  0.99910182]
 [-0.69823253 -0.71582282 -0.00831551]]
support
[-0.05061276  1.2170371  -0.01012938]
[-355.53544462 -867.80914026  540.14208836]
[ 144.36211222  -39.34910626 -189.18880935]
[ 0.40718521 -9.79119781  0.08149197]
v_real [-0.3542856   0.79026896 -0.0867531 ]
zmp_s [       0.         18776790.80937864 -2061253.60131934]
transform [[ 0.71547055  0.0239428  -0.69823253]
 [-0.69740629 -0.03496072 -0.71582282]
 [-0.04154951  0.99910182 -0.00831551]]
zmp [ 1888803.23670954   819042.28821362 18777066.19590854]
d1:37422216.69751, d2:0.05940, d3:12820860.62046
eta 23760000.0
transform [[ 0.25094372 -0.04666154  0.96687639]
 [-0.95701778  0.13808335  0.25504893]
 [-0.14541052 -0.98932087 -0.01000477]]
planes
[[ 0.25094372 -0.04666154  0.96687639]
 [-0.95701778  0.13808335  0.25504893]
 [-0.14541052 -0.98932087 -0.01000477]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 175.98355   80.14305 1267.7291 ]
[-23.60031783 288.93776984  21.53077866]
[ 0.   0.  -9.8]
transform [[ 0.25094372 -0.04666154  0.96687639]
 [-0.95701778  0.13808335  0.25504893]
 [-0.14541052 -0.98932087 -0.01000477]]
transform [[ 0.25094372 -0.04666154  0.96687639]
 [-0.95701778  0.13808335  0.25504893]
 [-0.14541052 -0.98932087 -0.01000477]]
transform [[ 0.25094372 -0.04666154  0.96687639]
 [-0.95701778  0.13808335  0.25504893]
 [-0.14541052 -0.98932087 -0.01000477]]
support
[ 1.17778229  0.31068306 -0.01218712]
[1266.15972683  165.979992   -117.56039311]
[   1.41296945   67.97482209 -282.63584301]
[-9.4753886  -2.49947952  0.09804676]
v_real [ 0.01674929  0.02137535 -0.6513816 ]
zmp_s [        0.            507878.78862281 -15476826.84800914]
transform [[ 0.25094372 -0.95701778 -0.14541052]
 [-0.04666154  0.13808335 -0.98932087]
 [ 0.96687639  0.25504893 -0.01000477]]
zmp [ 1764444.4530745  15381677.47370875   284376.04945935]
d1:22938862.07734, d2:0.05940, d3:1608763.83965
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-201.27158069988212 steps:115[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.08697052  0.11011243 -0.99010676]
 [ 0.69655347  0.70382142  0.13945881]
 [ 0.71221447 -0.70179111 -0.01548748]]
planes
[[ 0.08697052  0.11011243 -0.99010676]
 [ 0.69655347  0.70382142  0.13945881]
 [ 0.71221447 -0.70179111 -0.01548748]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-941.9464     62.79939    71.952805]
[  -2.45568225 -125.68114538   -3.8842638 ]
[ 0.   0.  -9.8]
transform [[ 0.08697052  0.11011243 -0.99010676]
 [ 0.69655347  0.70382142  0.13945881]
 [ 0.71221447 -0.70179111 -0.01548748]]
transform [[ 0.08697052  0.11011243 -0.99010676]
 [ 0.69655347  0.70382142  0.13945881]
 [ 0.71221447 -0.70179111 -0.01548748]]
transform [[ 0.08697052  0.11011243 -0.99010676]
 [ 0.69655347  0.70382142  0.13945881]
 [ 0.71221447 -0.70179111 -0.01548748]]
support
[-1.20607994  0.16987912 -0.01886578]
[-146.24753709 -601.88203274 -716.05428393]
[-10.20679227 -90.70929107  86.51309524]
[ 9.70304626 -1.36669629  0.15177727]
v_real [-0.10648359  0.07190683 -0.8967383 ]
zmp_s [        0.           1708512.50688667 -21306495.03107055]
transform [[ 0.08697052  0.69655347  0.71221447]
 [ 0.11011243  0.70382142 -0.70179111]
 [-0.99010676  0.13945881 -0.01548748]]
zmp [-13984723.75119043  16155196.4479203     568250.94889669]
d1:29098484.88318, d2:0.05940, d3:9942723.95027
eta 23760000.0
transform [[ 0.226549    0.20891941  0.95132977]
 [-0.66439909 -0.68105948  0.30778548]
 [ 0.71221447 -0.70179111 -0.01548748]]
planes
[[ 0.226549    0.20891941  0.95132977]
 [-0.66439909 -0.68105948  0.30778548]
 [ 0.71221447 -0.70179111 -0.01548748]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-941.9464     62.79939    71.952805]
[  -2.45568225 -125.68114538   -3.8842638 ]
[ 0.   0.  -9.8]
transform [[ 0.226549    0.20891941  0.95132977]
 [-0.66439909 -0.68105948  0.30778548]
 [ 0.71221447 -0.70179111 -0.01548748]]
transform [[ 0.226549    0.20891941  0.95132977]
 [-0.66439909 -0.68105948  0.30778548]
 [ 0.71221447 -0.70179111 -0.01548748]]
transform [[ 0.226549    0.20891941  0.95132977]
 [-0.66439909 -0.68105948  0.30778548]
 [ 0.71221447 -0.70179111 -0.01548748]]
support
[ 1.15884447  0.3749231  -0.01886578]
[-131.8261612   605.20424542 -716.05428393]
[-30.50877837  86.03236853  86.51309524]
[-9.32303172 -3.01629772  0.15177727]
v_real [-0.10648359  0.07190683 -0.8967383 ]
zmp_s [        0.           1708512.30684661 -21306508.50598775]
transform [[ 0.226549   -0.66439909  0.71221447]
 [ 0.20891941 -0.68105948 -0.70179111]
 [ 0.95132977  0.30778548 -0.01548748]]
zmp [-16309937.67874808  13789119.70188373    855839.32702365]
d1:29106167.74104, d2:0.05940, d3:10131790.77491
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-96.21090154805843 steps:118[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 1.90147460e-01  1.81628048e-01  9.64808404e-01]
 [-6.98875129e-01 -6.65153384e-01  2.62953579e-01]
 [ 6.89505279e-01 -7.24280536e-01  4.58117051e-04]]
planes
[[ 1.90147460e-01  1.81628048e-01  9.64808404e-01]
 [-6.98875129e-01 -6.65153384e-01  2.62953579e-01]
 [ 6.89505279e-01 -7.24280536e-01  4.58117051e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[289.64948 162.39886 567.92896]
[  38.88406426 -233.59523886  -23.7658075 ]
[ 0.   0.  -9.8]
transform [[ 1.90147460e-01  1.81628048e-01  9.64808404e-01]
 [-6.98875129e-01 -6.65153384e-01  2.62953579e-01]
 [ 6.89505279e-01 -7.24280536e-01  4.58117051e-04]]
transform [[ 1.90147460e-01  1.81628048e-01  9.64808404e-01]
 [-6.98875129e-01 -6.65153384e-01  2.62953579e-01]
 [ 6.89505279e-01 -7.24280536e-01  4.58117051e-04]]
transform [[ 1.90147460e-01  1.81628048e-01  9.64808404e-01]
 [-6.98875129e-01 -6.65153384e-01  2.62953579e-01]
 [ 6.89505279e-01 -7.24280536e-01  4.58117051e-04]]
support
[1.17526322e+00 3.20311959e-01 5.58046673e-04]
[ 632.51492969 -161.11001722   82.35268326]
[-57.96319213 121.95225408 195.98836491]
[-9.45512236e+00 -2.57694508e+00 -4.48954710e-03]
v_real [ 0.15876648 -0.38343525 -0.7549461 ]
zmp_s [        0.          -9110421.685487   -17937519.95904222]
transform [[ 1.90147460e-01 -6.98875129e-01  6.89505279e-01]
 [ 1.81628048e-01 -6.65153384e-01 -7.24280536e-01]
 [ 9.64808404e-01  2.62953579e-01  4.58117051e-04]]
zmp [-6000967.57235911 19051624.38925063 -2403835.47601578]
d1:24223994.52401, d2:0.05940, d3:9278454.52904
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-315.381198388547 steps:120[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69717962  0.69755435 -0.16540399]
 [ 0.14376928  0.08999218  0.98551095]
 [ 0.7023325  -0.71085823 -0.03754616]]
planes
[[ 0.69717962  0.69755435 -0.16540399]
 [ 0.14376928  0.08999218  0.98551095]
 [ 0.7023325  -0.71085823 -0.03754616]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 735.3109   438.29065 -143.32858]
[  11.6725952  -471.89300507    6.45342436]
[ 0.   0.  -9.8]
transform [[ 0.69717962  0.69755435 -0.16540399]
 [ 0.14376928  0.08999218  0.98551095]
 [ 0.7023325  -0.71085823 -0.03754616]]
transform [[ 0.69717962  0.69755435 -0.16540399]
 [ 0.14376928  0.08999218  0.98551095]
 [ 0.7023325  -0.71085823 -0.03754616]]
transform [[ 0.69717962  0.69755435 -0.16540399]
 [ 0.14376928  0.08999218  0.98551095]
 [ 0.7023325  -0.71085823 -0.03754616]]
support
[-0.20148376  1.20048163 -0.04573615]
[842.08244842   3.90596403 210.25167408]
[-322.10054509  -34.42859954  343.40476598]
[ 1.62095912 -9.65800726  0.36795238]
v_real [ 0.36006215 -0.61514854 -0.18909547]
zmp_s [        0.         -14615928.20791272  -4492908.53624486]
transform [[ 0.69717962  0.14376928  0.7023325 ]
 [ 0.69755435  0.08999218 -0.71085823]
 [-0.16540399  0.98551095 -0.03754616]]
zmp [ -5256837.13160547   1878501.74188345 -14235465.75512516]
d1:29519995.82891, d2:0.05940, d3:11250864.96406
eta 23760000.0
transform [[ 0.28895631  0.23649281  0.92767209]
 [-0.6505639  -0.66238338  0.37150353]
 [ 0.7023325  -0.71085823 -0.03754616]]
planes
[[ 0.28895631  0.23649281  0.92767209]
 [-0.6505639  -0.66238338  0.37150353]
 [ 0.7023325  -0.71085823 -0.03754616]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 735.3109   438.29065 -143.32858]
[  11.6725952  -471.89300507    6.45342436]
[ 0.   0.  -9.8]
transform [[ 0.28895631  0.23649281  0.92767209]
 [-0.6505639  -0.66238338  0.37150353]
 [ 0.7023325  -0.71085823 -0.03754616]]
transform [[ 0.28895631  0.23649281  0.92767209]
 [-0.6505639  -0.66238338  0.37150353]
 [ 0.7023325  -0.71085823 -0.03754616]]
transform [[ 0.28895631  0.23649281  0.92767209]
 [-0.6505639  -0.66238338  0.37150353]
 [ 0.7023325  -0.71085823 -0.03754616]]
support
[ 1.13002631  0.45254004 -0.04573615]
[ 183.1633941  -821.9302476   210.25167408]
[-102.23977229  307.37778348  343.40476598]
[-9.09118646 -3.64073461  0.36795238]
v_real [ 0.36006215 -0.61514854 -0.18909547]
zmp_s [        0.         -14615925.16086438  -4492908.14721151]
transform [[ 0.28895631 -0.6505639   0.7023325 ]
 [ 0.23649281 -0.66238338 -0.71085823]
 [ 0.92767209  0.37150353 -0.03754616]]
zmp [ 6353077.81572707 12875166.58841109 -5261176.3645477 ]
d1:22238200.23414, d2:0.05940, d3:5807937.87756
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-181.86146331494982 steps:123[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.28508109  0.01651792 -0.95836109]
 [ 0.9573766  -0.05337557  0.28386828]
 [-0.04646415 -0.99843794 -0.03103024]]
planes
[[ 0.28508109  0.01651792 -0.95836109]
 [ 0.9573766  -0.05337557  0.28386828]
 [-0.04646415 -0.99843794 -0.03103024]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 735.3109   438.29065 -143.32858]
[  11.6725952  -471.89300507    6.45342436]
[ 0.   0.  -9.8]
transform [[ 0.28508109  0.01651792 -0.95836109]
 [ 0.9573766  -0.05337557  0.28386828]
 [-0.04646415 -0.99843794 -0.03103024]]
transform [[ 0.28508109  0.01651792 -0.95836109]
 [ 0.9573766  -0.05337557  0.28386828]
 [-0.04646415 -0.99843794 -0.03103024]]
transform [[ 0.28508109  0.01651792 -0.95836109]
 [ 0.9573766  -0.05337557  0.28386828]
 [-0.04646415 -0.99843794 -0.03103024]]
support
[-1.16740954  0.34578881 -0.0377989 ]
[ 354.22342392  639.88901024 -467.32409184]
[-10.65176751  38.19454929 470.41327184]
[ 9.39193867 -2.78190917  0.30409635]
v_real [ 0.2138196   0.68590814 -0.6729055 ]
zmp_s [        0.          16297178.09754923 -15988236.43215432]
transform [[ 0.28508109  0.9573766  -0.04646415]
 [ 0.01651792 -0.05337557 -0.99843794]
 [-0.95836109  0.28386828 -0.03103024]]
zmp [16345416.8033453  15093390.72305088  5122370.77111003]
d1:19742035.66966, d2:0.05940, d3:10026568.79157
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-157.42968360185137 steps:125[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.66677594  0.63824493  0.38477692]
 [-0.24409387 -0.30079186  0.92192322]
 [ 0.70415062 -0.70863789 -0.04476909]]
planes
[[ 0.66677594  0.63824493  0.38477692]
 [-0.24409387 -0.30079186  0.92192322]
 [ 0.70415062 -0.70863789 -0.04476909]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-639.0542  -195.47113  278.33438]
[ -59.45173362 -211.61858319   28.60621586]
[ 0.   0.  -9.8]
transform [[ 0.66677594  0.63824493  0.38477692]
 [-0.24409387 -0.30079186  0.92192322]
 [ 0.70415062 -0.70863789 -0.04476909]]
transform [[ 0.66677594  0.63824493  0.38477692]
 [-0.24409387 -0.30079186  0.92192322]
 [ 0.70415062 -0.70863789 -0.04476909]]
transform [[ 0.66677594  0.63824493  0.38477692]
 [-0.24409387 -0.30079186  0.92192322]
 [ 0.70415062 -0.70863789 -0.04476909]]
support
[ 0.46870877  1.12302344 -0.05453463]
[-443.76777698  471.38826325 -323.93293665]
[-163.69846122  104.53768526  106.81729769]
[-3.77081382 -9.03484756  0.43873712]
v_real [ 0.07020556  0.16103806 -0.71321595]
zmp_s [        0.           3826266.09592512 -16946010.62691489]
transform [[ 0.66677594 -0.24409387  0.70415062]
 [ 0.63824493 -0.30079186 -0.70863789]
 [ 0.38477692  0.92192322 -0.04476909]]
zmp [-12866511.92117949  10857675.57438026   4286181.09275203]
d1:23711443.15661, d2:0.05940, d3:10301762.78214
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-414.4121014715626 steps:127[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.23209764 -0.0373372   0.97197568]
 [-0.97218078 -0.04131408  0.23055957]
 [ 0.03154783 -0.99844837 -0.0458874 ]]
planes
[[ 0.23209764 -0.0373372   0.97197568]
 [-0.97218078 -0.04131408  0.23055957]
 [ 0.03154783 -0.99844837 -0.0458874 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-639.0542  -195.47113  278.33438]
[ -59.45173362 -211.61858319   28.60621586]
[ 0.   0.  -9.8]
transform [[ 0.23209764 -0.0373372   0.97197568]
 [-0.97218078 -0.04131408  0.23055957]
 [ 0.03154783 -0.99844837 -0.0458874 ]]
transform [[ 0.23209764 -0.0373372   0.97197568]
 [-0.97218078 -0.04131408  0.23055957]
 [ 0.03154783 -0.99844837 -0.0458874 ]]
transform [[ 0.23209764 -0.0373372   0.97197568]
 [-0.97218078 -0.04131408  0.23055957]
 [ 0.03154783 -0.99844837 -0.0458874 ]]
support
[ 1.18399391  0.28085181 -0.05589687]
[129.50962236 693.52457818 162.23501563]
[ 21.90718346  73.13609704 208.10199162]
[-9.5253617  -2.25948381  0.44969651]
v_real [-0.01615942  0.00388775 -0.3369198 ]
zmp_s [       0.            92364.5688492  -8005216.05170758]
transform [[ 0.23209764 -0.97218078  0.03154783]
 [-0.0373372  -0.04131408 -0.99844837]
 [ 0.97197568  0.23055957 -0.0458874 ]]
zmp [-342342.2799364  7988978.97621314  388634.08228227]
d1:13420794.28194, d2:0.05940, d3:264678.16863
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-187.99827726947717 steps:129[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70283377 -0.70752913 -0.0736695 ]
 [ 0.03001839 -0.07397074  0.99680853]
 [-0.71072048 -0.70280218 -0.03075025]]
planes
[[ 0.70283377 -0.70752913 -0.0736695 ]
 [ 0.03001839 -0.07397074  0.99680853]
 [-0.71072048 -0.70280218 -0.03075025]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-639.0542  -195.47113  278.33438]
[ -59.45173362 -211.61858319   28.60621586]
[ 0.   0.  -9.8]
transform [[ 0.70283377 -0.70752913 -0.0736695 ]
 [ 0.03001839 -0.07397074  0.99680853]
 [-0.71072048 -0.70280218 -0.03075025]]
transform [[ 0.70283377 -0.70752913 -0.0736695 ]
 [ 0.03001839 -0.07397074  0.99680853]
 [-0.71072048 -0.70280218 -0.03075025]]
transform [[ 0.70283377 -0.70752913 -0.0736695 ]
 [ 0.03001839 -0.07397074  0.99680853]
 [-0.71072048 -0.70280218 -0.03075025]]
support
[-0.08973912  1.21424357 -0.03745784]
[-331.35210969  272.72185167  583.00759228]
[105.83421974  42.38385693 190.09991824]
[ 0.72196111 -9.76872358  0.30135244]
v_real [-0.26782808  0.43560007 -0.8659729 ]
zmp_s [        0.          10349859.71783569 -20575516.32396978]
transform [[ 0.70283377  0.03001839 -0.71072048]
 [-0.70752913 -0.07397074 -0.70280218]
 [-0.0736695   0.99680853 -0.03075025]]
zmp [14934126.92564873 13694931.0214737  10949530.68130669]
d1:34777800.96260, d2:0.05940, d3:16085798.56574
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-500.93048598848316 steps:131[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-72.7661082714871 steps:132[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71021199  0.67752331 -0.1912097 ]
 [ 0.13114698  0.13952194  0.98149586]
 [ 0.69166428 -0.72214669  0.01023502]]
planes
[[ 0.71021199  0.67752331 -0.1912097 ]
 [ 0.13114698  0.13952194  0.98149586]
 [ 0.69166428 -0.72214669  0.01023502]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[150.64679 184.75906 -96.71872]
[ -14.25340565 -203.85973744  -20.66673952]
[ 0.   0.  -9.8]
transform [[ 0.71021199  0.67752331 -0.1912097 ]
 [ 0.13114698  0.13952194  0.98149586]
 [ 0.69166428 -0.72214669  0.01023502]]
transform [[ 0.71021199  0.67752331 -0.1912097 ]
 [ 0.13114698  0.13952194  0.98149586]
 [ 0.69166428 -0.72214669  0.01023502]]
transform [[ 0.71021199  0.67752331 -0.1912097 ]
 [ 0.13114698  0.13952194  0.98149586]
 [ 0.69166428 -0.72214669  0.01023502]]
support
[-0.23291851  1.19559073  0.01246759]
[250.66328755 -49.39420736 -30.21606086]
[-144.29098358  -50.59651673  137.14653866]
[ 1.8738551  -9.6186594  -0.10030315]
v_real [ 0.57865506 -0.3557007  -0.28872198]
zmp_s [       0.         -8451448.40191238 -6860034.21584638]
transform [[ 0.71021199  0.13114698  0.69166428]
 [ 0.67752331  0.13952194 -0.72214669]
 [-0.1912097   0.98149586  0.01023502]]
zmp [-5853222.57051641  3774788.51163593 -8365274.1493218 ]
d1:18625699.79855, d2:0.05940, d3:8438913.79648
eta 23760000.0
transform [[ 0.2773926   0.25254562 -0.92697036]
 [ 0.66682374  0.64399135  0.37499493]
 [ 0.69166428 -0.72214669  0.01023502]]
planes
[[ 0.2773926   0.25254562 -0.92697036]
 [ 0.66682374  0.64399135  0.37499493]
 [ 0.69166428 -0.72214669  0.01023502]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[150.64679 184.75906 -96.71872]
[ -14.25340565 -203.85973744  -20.66673952]
[ 0.   0.  -9.8]
transform [[ 0.2773926   0.25254562 -0.92697036]
 [ 0.66682374  0.64399135  0.37499493]
 [ 0.69166428 -0.72214669  0.01023502]]
transform [[ 0.2773926   0.25254562 -0.92697036]
 [ 0.66682374  0.64399135  0.37499493]
 [ 0.69166428 -0.72214669  0.01023502]]
transform [[ 0.2773926   0.25254562 -0.92697036]
 [ 0.66682374  0.64399135  0.37499493]
 [ 0.69166428 -0.72214669  0.01023502]]
support
[-1.12917152  0.45679303  0.01246759]
[178.10378372 183.16906563 -30.21606086]
[ -36.28021897 -148.5383397   137.14653866]
[ 9.08430955 -3.67495035 -0.10030315]
v_real [ 0.57865506 -0.3557007  -0.28872198]
zmp_s [       0.        -8451448.1931147 -6860034.9639338]
transform [[ 0.2773926   0.66682374  0.69166428]
 [ 0.25254562  0.64399135 -0.72214669]
 [-0.92697036  0.37499493  0.01023502]]
zmp [-10380467.46675872   -488707.99912215  -3239462.81687905]
d1:13856361.45997, d2:0.05940, d3:5598840.92269
eta 23760000.0
transform [[ 0.12290476  0.22031191 -0.96765548]
 [ 0.92952174 -0.36715299  0.03446936]
 [-0.34768358 -0.9036932  -0.24990954]]
planes
[[ 0.12290476  0.22031191 -0.96765548]
 [ 0.92952174 -0.36715299  0.03446936]
 [-0.34768358 -0.9036932  -0.24990954]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[150.64679 184.75906 -96.71872]
[ -14.25340565 -203.85973744  -20.66673952]
[ 0.   0.  -9.8]
transform [[ 0.12290476  0.22031191 -0.96765548]
 [ 0.92952174 -0.36715299  0.03446936]
 [-0.34768358 -0.9036932  -0.24990954]]
transform [[ 0.12290476  0.22031191 -0.96765548]
 [ 0.92952174 -0.36715299  0.03446936]
 [-0.34768358 -0.9036932  -0.24990954]]
transform [[ 0.12290476  0.22031191 -0.96765548]
 [ 0.92952174 -0.36715299  0.03446936]
 [-0.34768358 -0.9036932  -0.24990954]]
support
[-1.17873133  0.0419882  -0.3044226 ]
[ 152.81022791   68.86079117 -195.17199407]
[-26.66625569  60.88649225 194.34714866]
[ 9.4830237  -0.33779971  2.44911344]
v_real [-1.2644613 -0.2159357 -0.4828784]
zmp_s [        0.          -5130633.15783727 -11473191.32900005]
transform [[ 0.12290476  0.92952174 -0.34768358]
 [ 0.22031191 -0.36715299 -0.9036932 ]
 [-0.96765548  0.03446936 -0.24990954]]
zmp [ -779994.83680495 12251972.27555678  2690410.2762939 ]
d1:20598587.38563, d2:0.05940, d3:1530696.17914
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-514.3374851792829 steps:136[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.25229228  0.2287686   0.94021994]
 [-0.66299576 -0.66687703  0.34016427]
 [ 0.70482999 -0.70918268 -0.0165753 ]]
planes
[[ 0.25229228  0.2287686   0.94021994]
 [-0.66299576 -0.66687703  0.34016427]
 [ 0.70482999 -0.70918268 -0.0165753 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-418.68222 -721.2794   336.07397]
[  37.11375331 -443.27741884  -11.97346624]
[ 0.   0.  -9.8]
transform [[ 0.25229228  0.2287686   0.94021994]
 [-0.66299576 -0.66687703  0.34016427]
 [ 0.70482999 -0.70918268 -0.0165753 ]]
transform [[ 0.25229228  0.2287686   0.94021994]
 [-0.66299576 -0.66687703  0.34016427]
 [ 0.70482999 -0.70918268 -0.0165753 ]]
transform [[ 0.25229228  0.2287686   0.94021994]
 [-0.66299576 -0.66687703  0.34016427]
 [ 0.70482999 -0.70918268 -0.0165753 ]]
support
[ 1.14531124  0.41436472 -0.02019088]
[ 45.34707741 872.90957238 210.84856005]
[-103.30213384  266.93232276  340.72201787]
[-9.2141554  -3.33360988  0.1624379 ]
v_real [-0.62326556 -0.17479686 -0.44350517]
zmp_s [        0.          -4153210.07841277 -10537682.3211316 ]
transform [[ 0.25229228 -0.66299576  0.70482999]
 [ 0.2287686  -0.66687703 -0.70918268]
 [ 0.94021994  0.34016427 -0.0165753 ]]
zmp [-4673713.87972509 10242822.19340027 -1238108.49287123]
d1:14802900.87841, d2:0.05940, d3:5575681.25000
eta 23760000.0
transform [[ 0.2456982   0.22261055  0.94343889]
 [-0.96081847  0.1847458   0.20663236]
 [-0.12829784 -0.95724267  0.25928003]]
planes
[[ 0.2456982   0.22261055  0.94343889]
 [-0.96081847  0.1847458   0.20663236]
 [-0.12829784 -0.95724267  0.25928003]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[151.07704 246.54233 270.5298 ]
[130.094155   102.85791556 130.64382887]
[ 0.   0.  -9.8]
transform [[ 0.2456982   0.22261055  0.94343889]
 [-0.96081847  0.1847458   0.20663236]
 [-0.12829784 -0.95724267  0.25928003]]
transform [[ 0.2456982   0.22261055  0.94343889]
 [-0.96081847  0.1847458   0.20663236]
 [-0.12829784 -0.95724267  0.25928003]]
transform [[ 0.2456982   0.22261055  0.94343889]
 [-0.96081847  0.1847458   0.20663236]
 [-0.12829784 -0.95724267  0.25928003]]
support
[1.14923234 0.25170533 0.31583709]
[ 347.23059931  -43.70974328 -185.24072337]
[178.11562508 -78.99905586 -81.27744865]
[-9.2457011  -2.02499714 -2.54094425]
v_real [1.3795518e+00 1.0793384e-03 3.6230725e-01]
zmp_s [      0.           25645.72776946 8608420.7206058 ]
transform [[ 0.2456982  -0.96081847 -0.12829784]
 [ 0.22261055  0.1847458  -0.95724267]
 [ 0.94343889  0.20663236  0.25928003]]
zmp [-1129082.63519383 -8235609.67447912  2237290.78517864]
d1:10654354.77484, d2:0.05940, d3:4449050.90908
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-428.7649730840905 steps:139[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.1763725   0.13733962  0.97469515]
 [-0.7052598  -0.67313981  0.22246666]
 [ 0.68665963 -0.7266503  -0.02186325]]
planes
[[ 0.1763725   0.13733962  0.97469515]
 [-0.7052598  -0.67313981  0.22246666]
 [ 0.68665963 -0.7266503  -0.02186325]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 255.33253 -118.63141  -49.58771]
[  68.20684275 -290.85420738  -39.29855731]
[ 0.   0.  -9.8]
transform [[ 0.1763725   0.13733962  0.97469515]
 [-0.7052598  -0.67313981  0.22246666]
 [ 0.68665963 -0.7266503  -0.02186325]]
transform [[ 0.1763725   0.13733962  0.97469515]
 [-0.7052598  -0.67313981  0.22246666]
 [ 0.68665963 -0.7266503  -0.02186325]]
transform [[ 0.1763725   0.13733962  0.97469515]
 [-0.7052598  -0.67313981  0.22246666]
 [ 0.68665963 -0.7266503  -0.02186325]]
support
[ 1.18730657  0.27099358 -0.0266323 ]
[ -19.59205729 -111.25186108  262.61424179]
[-66.22010864 138.9393829  259.04337616]
[-9.55201243 -2.18017329  0.21425983]
v_real [-0.06832123  0.24887732 -0.6658797 ]
zmp_s [        0.           5913329.53823484 -15821296.08653454]
transform [[ 0.1763725  -0.7052598   0.68665963]
 [ 0.13733962 -0.67313981 -0.7266503 ]
 [ 0.97469515  0.22246666 -0.02186325]]
zmp [-15034278.98919513   7516051.98519978   1661423.60996161]
d1:22129788.19911, d2:0.05940, d3:8314211.59562
eta 23760000.0
transform [[ 0.13905953  0.19754332  0.9703809 ]
 [-0.98217165  0.15268283  0.1096671 ]
 [-0.12649649 -0.96833086  0.21525346]]
planes
[[ 0.13905953  0.19754332  0.9703809 ]
 [-0.98217165  0.15268283  0.1096671 ]
 [-0.12649649 -0.96833086  0.21525346]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 255.33253 -118.63141  -49.58771]
[  68.20684275 -290.85420738  -39.29855731]
[ 0.   0.  -9.8]
transform [[ 0.13905953  0.19754332  0.9703809 ]
 [-0.98217165  0.15268283  0.1096671 ]
 [-0.12649649 -0.96833086  0.21525346]]
transform [[ 0.13905953  0.19754332  0.9703809 ]
 [-0.98217165  0.15268283  0.1096671 ]
 [-0.12649649 -0.96833086  0.21525346]]
transform [[ 0.13905953  0.19754332  0.9703809 ]
 [-0.98217165  0.15268283  0.1096671 ]
 [-0.12649649 -0.96833086  0.21525346]]
support
[1.18205125 0.13358892 0.26220695]
[ -36.04738881 -274.33149741   71.9018573 ]
[ -86.10606474 -115.70902873  264.55602801]
[-9.50973284 -1.07473758 -2.10948388]
v_real [ 0.99254566 -0.16756402 -0.1834467 ]
zmp_s [       0.         -3981322.20513168 -4358688.88705305]
transform [[ 0.13905953 -0.98217165 -0.12649649]
 [ 0.19754332  0.15268283 -0.96833086]
 [ 0.9703809   0.1096671   0.21525346]]
zmp [ 4461700.67996156  3612773.4338844  -1374842.9132383 ]
d1:4305893.34333, d2:0.05940, d3:2656395.77378
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-403.69930587136935 steps:142[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.17602667  0.1818509   0.96744251]
 [-0.70373547 -0.66394627  0.25284749]
 [ 0.68831038 -0.72533143  0.01110266]]
planes
[[ 0.17602667  0.1818509   0.96744251]
 [-0.70373547 -0.66394627  0.25284749]
 [ 0.68831038 -0.72533143  0.01110266]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[683.3879 271.9354 505.3732]
[ -6.62989139 -84.99081417   4.57249313]
[ 0.   0.  -9.8]
transform [[ 0.17602667  0.1818509   0.96744251]
 [-0.70373547 -0.66394627  0.25284749]
 [ 0.68831038 -0.72533143  0.01110266]]
transform [[ 0.17602667  0.1818509   0.96744251]
 [-0.70373547 -0.66394627  0.25284749]
 [ 0.68831038 -0.72533143  0.01110266]]
transform [[ 0.17602667  0.1818509   0.96744251]
 [-0.70373547 -0.66394627  0.25284749]
 [ 0.68831038 -0.72533143  0.01110266]]
support
[1.17847191 0.30800142 0.0135245 ]
[ 658.66570676 -533.69243495  278.75067339]
[-12.19906912  62.25116729  57.13385215]
[-9.48093662 -2.47790543 -0.10880607]
v_real [-0.2951943 -0.1984242 -0.4419907]
zmp_s [        0.          -4714557.80669156 -10501699.39640571]
transform [[ 0.17602667 -0.70373547  0.68831038]
 [ 0.1818509  -0.66394627 -0.72533143]
 [ 0.96744251  0.25284749  0.01110266]]
zmp [-3910627.1944998  10747425.67001582 -1308660.9242791 ]
d1:15228626.09489, d2:0.05940, d3:5502708.22810
eta 23760000.0
transform [[ 0.10108174  0.11105595  0.98866028]
 [-0.71833938 -0.6793828   0.14975871]
 [ 0.68831038 -0.72533143  0.01110266]]
planes
[[ 0.10108174  0.11105595  0.98866028]
 [-0.71833938 -0.6793828   0.14975871]
 [ 0.68831038 -0.72533143  0.01110266]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[683.3879 271.9354 505.3732]
[ -6.62989139 -84.99081417   4.57249313]
[ 0.   0.  -9.8]
transform [[ 0.10108174  0.11105595  0.98866028]
 [-0.71833938 -0.6793828   0.14975871]
 [ 0.68831038 -0.72533143  0.01110266]]
transform [[ 0.10108174  0.11105595  0.98866028]
 [-0.71833938 -0.6793828   0.14975871]
 [ 0.68831038 -0.72533143  0.01110266]]
transform [[ 0.10108174  0.11105595  0.98866028]
 [-0.71833938 -0.6793828   0.14975871]
 [ 0.68831038 -0.72533143  0.01110266]]
support
[1.20431793 0.18242576 0.0135245 ]
[ 598.92048826 -599.96861806  278.75067339]
[-5.58825409 63.18858017 57.13385215]
[-9.6888707  -1.46763537 -0.10880607]
v_real [-0.2951943 -0.1984242 -0.4419907]
zmp_s [        0.          -4714557.68527483 -10501699.44874672]
transform [[ 0.10108174 -0.71833938  0.68831038]
 [ 0.11105595 -0.6793828  -0.72533143]
 [ 0.98866028  0.14975871  0.01110266]]
zmp [-3841776.32650249 10820202.03904548  -822642.88831096]
d1:15034257.97552, d2:0.05940, d3:5194780.44582
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-282.3332771466563 steps:145[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.4449867   0.41682592 -0.7926178 ]
 [ 0.56308085  0.55800343  0.60956717]
 [ 0.69636685 -0.71755719  0.01359738]]
planes
[[ 0.4449867   0.41682592 -0.7926178 ]
 [ 0.56308085  0.55800343  0.60956717]
 [ 0.69636685 -0.71755719  0.01359738]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-701.9089   379.47192 -525.2913 ]
[105.80857644 -42.24595049 -41.08713424]
[ 0.   0.  -9.8]
transform [[ 0.4449867   0.41682592 -0.7926178 ]
 [ 0.56308085  0.55800343  0.60956717]
 [ 0.69636685 -0.71755719  0.01359738]]
transform [[ 0.4449867   0.41682592 -0.7926178 ]
 [ 0.56308085  0.55800343  0.60956717]
 [ 0.69636685 -0.71755719  0.01359738]]
transform [[ 0.4449867   0.41682592 -0.7926178 ]
 [ 0.56308085  0.55800343  0.60956717]
 [ 0.69636685 -0.71755719  0.01359738]]
support
[-0.96551247  0.74253278  0.01656339]
[ 262.18886934 -503.68515176 -768.22146248]
[ 62.04059603  10.96002983 103.436793  ]
[ 7.76765442 -5.97375822 -0.13325431]
v_real [-0.0372916   0.03109494 -0.22787122]
zmp_s [       0.           738814.34905229 -5414223.19089491]
transform [[ 0.4449867   0.56308085  0.69636685]
 [ 0.41682592  0.55800343 -0.71755719]
 [-0.7926178   0.60956717  0.01359738]]
zmp [-3354273.32038859  4297275.72655319   376737.72644063]
d1:5974080.24021, d2:0.05940, d3:2757880.96785
eta 23760000.0
transform [[ 0.68663454  0.57594264  0.44364753]
 [-0.29372752 -0.33844292  0.89396906]
 [ 0.66502422 -0.74414146 -0.06321643]]
planes
[[ 0.68663454  0.57594264  0.44364753]
 [-0.29372752 -0.33844292  0.89396906]
 [ 0.66502422 -0.74414146 -0.06321643]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-701.9089   379.47192 -525.2913 ]
[105.80857644 -42.24595049 -41.08713424]
[ 0.   0.  -9.8]
transform [[ 0.68663454  0.57594264  0.44364753]
 [-0.29372752 -0.33844292  0.89396906]
 [ 0.66502422 -0.74414146 -0.06321643]]
transform [[ 0.68663454  0.57594264  0.44364753]
 [-0.29372752 -0.33844292  0.89396906]
 [ 0.66502422 -0.74414146 -0.06321643]]
transform [[ 0.68663454  0.57594264  0.44364753]
 [-0.29372752 -0.33844292  0.89396906]
 [ 0.66502422 -0.74414146 -0.06321643]]
support
[ 0.5404209  1.0889716 -0.0770059]
[-496.44501657 -391.85382337 -715.96015403]
[ 30.09237343 -53.51167427 104.39961113]
[-4.34774583 -8.76089678  0.61952097]
v_real [-1.8942951   0.57210267  0.26185802]
zmp_s [       0.         13593159.8651246   6221745.75790191]
transform [[ 0.68663454 -0.29372752  0.66502422]
 [ 0.57594264 -0.33844292 -0.74414146]
 [ 0.44364753  0.89396906 -0.06321643]]
zmp [  144926.52845003 -9230367.70775728 11758547.80628226]
d1:26363426.15968, d2:0.05940, d3:6243422.20843
eta 23760000.0
transform [[ 0.6862089   0.57545239  0.44494039]
 [-0.29472053 -0.33927581  0.89332628]
 [ 0.66502422 -0.74414146 -0.06321643]]
planes
[[ 0.6862089   0.57545239  0.44494039]
 [-0.29472053 -0.33927581  0.89332628]
 [ 0.66502422 -0.74414146 -0.06321643]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-701.9089   379.47192 -525.2913 ]
[105.80857644 -42.24595049 -41.08713424]
[ 0.   0.  -9.8]
transform [[ 0.6862089   0.57545239  0.44494039]
 [-0.29472053 -0.33927581  0.89332628]
 [ 0.66502422 -0.74414146 -0.06321643]]
transform [[ 0.6862089   0.57545239  0.44494039]
 [-0.29472053 -0.33927581  0.89332628]
 [ 0.66502422 -0.74414146 -0.06321643]]
transform [[ 0.6862089   0.57545239  0.44494039]
 [-0.29472053 -0.33927581  0.89332628]
 [ 0.66502422 -0.74414146 -0.06321643]]
support
[ 0.54199577  1.08818862 -0.0770059 ]
[-497.01141904 -391.13523022 -715.96015403]
[ 30.01492873 -53.55514772 104.39961113]
[-4.3604158  -8.75459757  0.61952097]
v_real [-1.8942951   0.57210267  0.26185802]
zmp_s [       0.         13593159.8641254   6221745.75650982]
transform [[ 0.6862089  -0.29472053  0.66502422]
 [ 0.57545239 -0.33927581 -0.74414146]
 [ 0.44494039  0.89332628 -0.06321643]]
zmp [  131428.33816958 -9241689.25218444 11749810.44190163]
d1:26365323.28922, d2:0.05940, d3:6245887.96251
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-658.3589347213906 steps:149[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.14623742  0.11905036  0.9820599 ]
 [-0.70587164 -0.68296254  0.18790279]
 [ 0.69308001 -0.72068667 -0.01584039]]
planes
[[ 0.14623742  0.11905036  0.9820599 ]
 [-0.70587164 -0.68296254  0.18790279]
 [ 0.69308001 -0.72068667 -0.01584039]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[582.9895    29.872639 323.56067 ]
[ -94.04107753 -327.00391528   57.17860123]
[ 0.   0.  -9.8]
transform [[ 0.14623742  0.11905036  0.9820599 ]
 [-0.70587164 -0.68296254  0.18790279]
 [ 0.69308001 -0.72068667 -0.01584039]]
transform [[ 0.14623742  0.11905036  0.9820599 ]
 [-0.70587164 -0.68296254  0.18790279]
 [ 0.69308001 -0.72068667 -0.01584039]]
transform [[ 0.14623742  0.11905036  0.9820599 ]
 [-0.70587164 -0.68296254  0.18790279]
 [ 0.69308001 -0.72068667 -0.01584039]]
support
[ 1.1962778   0.22889026 -0.01929567]
[ 406.56718484 -371.11969642  377.40422865]
[  3.47055258 300.45637219 169.58364198]
[-9.62418698 -1.84144737  0.15523583]
v_real [-0.6920593   0.5129243  -0.41120803]
zmp_s [       0.         12187082.92566913 -9770303.40023106]
transform [[ 0.14623742 -0.70587164  0.69308001]
 [ 0.11905036 -0.68296254 -0.72068667]
 [ 0.9820599   0.18790279 -0.01584039]]
zmp [-15374118.19058192  -1281993.60861439   2444752.34685761]
d1:18159616.67814, d2:0.05940, d3:6076539.45952
eta 23760000.0
transform [[ 0.14130466  0.11222935  0.98358405]
 [-0.88020539  0.46895376  0.07294419]
 [-0.45306894 -0.87606335  0.16505022]]
planes
[[ 0.14130466  0.11222935  0.98358405]
 [-0.88020539  0.46895376  0.07294419]
 [-0.45306894 -0.87606335  0.16505022]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[195.234   161.54843 800.7687 ]
[-782.67934817  964.99320496 -194.21416291]
[ 0.   0.  -9.8]
transform [[ 0.14130466  0.11222935  0.98358405]
 [-0.88020539  0.46895376  0.07294419]
 [-0.45306894 -0.87606335  0.16505022]]
transform [[ 0.14130466  0.11222935  0.98358405]
 [-0.88020539  0.46895376  0.07294419]
 [-0.45306894 -0.87606335  0.16505022]]
transform [[ 0.14130466  0.11222935  0.98358405]
 [-0.88020539  0.46895376  0.07294419]
 [-0.45306894 -0.87606335  0.16505022]]
support
[1.19813441 0.0888556  0.20105283]
[833.34124396 -37.67584412 -97.8140693 ]
[-193.32162428 1127.2889779  -522.84256375]
[-9.63912365 -0.7148531  -1.61749219]
v_real [ 1.3884199   0.00172089 -0.09300541]
zmp_s [       0.            40889.22475729 -2209806.78575287]
transform [[ 0.14130466 -0.88020539 -0.45306894]
 [ 0.11222935  0.46895376 -0.87606335]
 [ 0.98358405  0.07294419  0.16505022]]
zmp [ 965203.90593301 1955105.88427796 -361746.47226703]
d1:3574630.23890, d2:0.05940, d3:1159991.95272
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-438.5750545348624 steps:152[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.17042087  0.1976911  -0.96533674]
 [ 0.70642132  0.65848047  0.25956193]
 [ 0.68696851 -0.72616923 -0.02743439]]
planes
[[ 0.17042087  0.1976911  -0.96533674]
 [ 0.70642132  0.65848047  0.25956193]
 [ 0.68696851 -0.72616923 -0.02743439]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -15.606237  146.34521  -396.87088 ]
[ -45.62790628 -268.0076566    24.61259731]
[ 0.   0.  -9.8]
transform [[ 0.17042087  0.1976911  -0.96533674]
 [ 0.70642132  0.65848047  0.25956193]
 [ 0.68696851 -0.72616923 -0.02743439]]
transform [[ 0.17042087  0.1976911  -0.96533674]
 [ 0.70642132  0.65848047  0.25956193]
 [ 0.68696851 -0.72616923 -0.02743439]]
transform [[ 0.17042087  0.1976911  -0.96533674]
 [ 0.70642132  0.65848047  0.25956193]
 [ 0.68696851 -0.72616923 -0.02743439]]
support
[-1.1759068   0.31618048 -0.03341868]
[ 409.38555926  -17.67168365 -106.10447631]
[ -84.51811981 -202.32183887  162.59874716]
[ 9.46030005 -2.54370688  0.26885699]
v_real [-0.11511169  0.27099818 -0.49061146]
zmp_s [        0.           6438916.87121927 -11656928.81359749]
transform [[ 0.17042087  0.70642132  0.68696851]
 [ 0.1976911   0.65848047 -0.72616923]
 [-0.96533674  0.25956193 -0.02743439]]
zmp [-3459354.83677115 12704803.98198687  1991098.35355689]
d1:15724133.15197, d2:0.05940, d3:6255800.12016
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-260.62982524539086 steps:154[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70669591  0.69578934 -0.12828913]
 [ 0.10142736  0.07981982  0.99163568]
 [ 0.7002095  -0.71379691 -0.01416373]]
planes
[[ 0.70669591  0.69578934 -0.12828913]
 [ 0.10142736  0.07981982  0.99163568]
 [ 0.7002095  -0.71379691 -0.01416373]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 492.33133 -486.9326   265.37405]
[ 121.53018437 -304.42282616  -53.6244075 ]
[ 0.   0.  -9.8]
transform [[ 0.70669591  0.69578934 -0.12828913]
 [ 0.10142736  0.07981982  0.99163568]
 [ 0.7002095  -0.71379691 -0.01416373]]
transform [[ 0.70669591  0.69578934 -0.12828913]
 [ 0.10142736  0.07981982  0.99163568]
 [ 0.7002095  -0.71379691 -0.01416373]]
transform [[ 0.70669591  0.69578934 -0.12828913]
 [ 0.10142736  0.07981982  0.99163568]
 [ 0.7002095  -0.71379691 -0.01416373]]
support
[-0.156273    1.20794236 -0.01725328]
[-24.91857019 274.22337634 688.54736529]
[-119.04984291  -65.14836532  303.1521846 ]
[ 1.25723351 -9.71802967  0.13880451]
v_real [-0.19370909 -0.33275864 -0.23774447]
zmp_s [       0.         -7906332.72686952 -5648810.31236258]
transform [[ 0.70669591  0.10142736  0.7002095 ]
 [ 0.69578934  0.07981982 -0.71379691]
 [-0.12828913  0.99163568 -0.01416373]]
zmp [-4757269.10199977  3401021.30499857 -7760193.42994272]
d1:17015084.56234, d2:0.05940, d3:7549937.76207
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-363.28801885428084 steps:156[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.14459133 -0.02412532  0.98919731]
 [-0.98898458  0.02847203  0.14525463]
 [-0.03166877 -0.99930346 -0.01974276]]
planes
[[ 0.14459133 -0.02412532  0.98919731]
 [-0.98898458  0.02847203  0.14525463]
 [-0.03166877 -0.99930346 -0.01974276]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 492.33133 -486.9326   265.37405]
[ 121.53018437 -304.42282616  -53.6244075 ]
[ 0.   0.  -9.8]
transform [[ 0.14459133 -0.02412532  0.98919731]
 [-0.98898458  0.02847203  0.14525463]
 [-0.03166877 -0.99930346 -0.01974276]]
transform [[ 0.14459133 -0.02412532  0.98919731]
 [-0.98898458  0.02847203  0.14525463]
 [-0.03166877 -0.99930346 -0.01974276]]
transform [[ 0.14459133 -0.02412532  0.98919731]
 [-0.98898458  0.02847203  0.14525463]
 [-0.03166877 -0.99930346 -0.01974276]]
support
[ 1.20497211  0.17693919 -0.02404927]
[ 345.44154592 -462.22524382  465.7626769 ]
[ -28.12861203 -136.6482071   301.42076604]
[-9.69413368 -1.42349534  0.19347902]
v_real [0.6004549  0.13609749 0.24649525]
zmp_s [      0.         3233677.443179   5856724.89667222]
transform [[ 0.14459133 -0.98898458 -0.03166877]
 [-0.02412532  0.02847203 -0.99930346]
 [ 0.98919731  0.14525463 -0.01974276]]
zmp [-3383532.40163279 -5760576.10336501   354078.71349639]
d1:7340161.38706, d2:0.05940, d3:1914774.52267
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-251.16762175627542 steps:158[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.08374179 -0.09042767  0.99237603]
 [-0.97973078  0.17439166  0.09856571]
 [-0.18197516 -0.98051536 -0.0739909 ]]
planes
[[ 0.08374179 -0.09042767  0.99237603]
 [-0.97973078  0.17439166  0.09856571]
 [-0.18197516 -0.98051536 -0.0739909 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 520.4795  -124.68109 -496.36658]
[ 10.85067931 -47.42057655  -8.37863377]
[ 0.   0.  -9.8]
transform [[ 0.08374179 -0.09042767  0.99237603]
 [-0.97973078  0.17439166  0.09856571]
 [-0.18197516 -0.98051536 -0.0739909 ]]
transform [[ 0.08374179 -0.09042767  0.99237603]
 [-0.97973078  0.17439166  0.09856571]
 [-0.18197516 -0.98051536 -0.0739909 ]]
transform [[ 0.08374179 -0.09042767  0.99237603]
 [-0.97973078  0.17439166  0.09856571]
 [-0.18197516 -0.98051536 -0.0739909 ]]
support
[ 1.2088442   0.12006597 -0.09013063]
[-437.72178767 -580.5978489    64.26400007]
[ -3.11796789 -19.7263435   45.14199235]
[-9.72528509 -0.96594398  0.72511086]
v_real [ 0.00855205  0.48728493 -0.48032817]
zmp_s [        0.          11577888.64977358 -11412596.87046654]
transform [[ 0.08374179 -0.97973078 -0.18197516]
 [-0.09042767  0.17439166 -0.98051536]
 [ 0.99237603  0.09856571 -0.0739909 ]]
zmp [-9266404.83759337 13209313.72599382  1985611.20192543]
d1:16080016.70579, d2:0.05940, d3:5293314.07333
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-420.63743256443223 steps:160[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.30638397 -0.31756681 -0.89737403]
 [ 0.65774971 -0.61083359  0.44073534]
 [-0.68810916 -0.72528177  0.0217299 ]]
planes
[[ 0.30638397 -0.31756681 -0.89737403]
 [ 0.65774971 -0.61083359  0.44073534]
 [-0.68810916 -0.72528177  0.0217299 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 520.4795  -124.68109 -496.36658]
[ 10.85067931 -47.42057655  -8.37863377]
[ 0.   0.  -9.8]
transform [[ 0.30638397 -0.31756681 -0.89737403]
 [ 0.65774971 -0.61083359  0.44073534]
 [-0.68810916 -0.72528177  0.0217299 ]]
transform [[ 0.30638397 -0.31756681 -0.89737403]
 [ 0.65774971 -0.61083359  0.44073534]
 [-0.68810916 -0.72528177  0.0217299 ]]
transform [[ 0.30638397 -0.31756681 -0.89737403]
 [ 0.65774971 -0.61083359  0.44073534]
 [-0.68810916 -0.72528177  0.0217299 ]]
support
[-1.09311931  0.53687347  0.02646986]
[ 644.4876261   199.73834215 -278.5037767 ]
[25.90244389 32.41035198 26.74476127]
[ 8.79426553 -4.31920633 -0.21295298]
v_real [-0.02639142 -0.09484442 -0.3453786 ]
zmp_s [       0.         -2253502.67707594 -8206195.89028788]
transform [[ 0.30638397  0.65774971 -0.68810916]
 [-0.31756681 -0.61083359 -0.72528177]
 [-0.89737403  0.44073534  0.0217299 ]]
zmp [ 4164517.81861816  7328319.4409234  -1171518.05081889]
d1:12240786.47629, d2:0.05940, d3:4411133.90518
eta 23760000.0
transform [[ 0.88349295  0.29969969 -0.36002821]
 [ 0.16795391  0.51480651  0.84069371]
 [ 0.43730047 -0.80321497  0.40449214]]
planes
[[ 0.88349295  0.29969969 -0.36002821]
 [ 0.16795391  0.51480651  0.84069371]
 [ 0.43730047 -0.80321497  0.40449214]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[188.11552 305.62228 375.10583]
[403.77491101 -18.38063349 -66.69535011]
[ 0.   0.  -9.8]
transform [[ 0.88349295  0.29969969 -0.36002821]
 [ 0.16795391  0.51480651  0.84069371]
 [ 0.43730047 -0.80321497  0.40449214]]
transform [[ 0.88349295  0.29969969 -0.36002821]
 [ 0.16795391  0.51480651  0.84069371]
 [ 0.43730047 -0.80321497  0.40449214]]
transform [[ 0.88349295  0.29969969 -0.36002821]
 [ 0.16795391  0.51480651  0.84069371]
 [ 0.43730047 -0.80321497  0.40449214]]
support
[-0.43856159  1.02407524  0.4927245 ]
[122.7449625  504.28019549 -11.49002311]
[375.235823    2.2827432 164.3568148]
[ 3.52827643 -8.23879838 -3.96402297]
v_real [-1.2219394  -0.00476125  0.10955454]
zmp_s [      0.         -113125.75002457 2603016.45712861]
transform [[ 0.88349295  0.16795391  0.43730047]
 [ 0.29969969  0.51480651 -0.80321497]
 [-0.36002821  0.84069371  0.40449214]]
zmp [ 1119300.41724246 -2149019.6508161    957795.58998348]
d1:4115451.90483, d2:0.05940, d3:1629869.42118
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-567.6691577127743 steps:163[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-177.72601574218444 steps:164[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.25786528 -0.08442539  0.96248525]
 [-0.96462303 -0.07904381  0.25150463]
 [ 0.05484511 -0.99328971 -0.10182132]]
planes
[[ 0.25786528 -0.08442539  0.96248525]
 [-0.96462303 -0.07904381  0.25150463]
 [ 0.05484511 -0.99328971 -0.10182132]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[188.11552 305.62228 375.10583]
[403.77491101 -18.38063349 -66.69535011]
[ 0.   0.  -9.8]
transform [[ 0.25786528 -0.08442539  0.96248525]
 [-0.96462303 -0.07904381  0.25150463]
 [ 0.05484511 -0.99328971 -0.10182132]]
transform [[ 0.25786528 -0.08442539  0.96248525]
 [-0.96462303 -0.07904381  0.25150463]
 [ 0.05484511 -0.99328971 -0.10182132]]
transform [[ 0.25786528 -0.08442539  0.96248525]
 [-0.96462303 -0.07904381  0.25150463]
 [ 0.05484511 -0.99328971 -0.10182132]]
support
[ 1.17243332  0.30636564 -0.12403172]
[ 383.74001665 -111.27726201 -331.44802286]
[  41.47803162 -404.81189383   47.19338331]
[-9.43235549 -2.46474537  0.99784892]
v_real [ 0.19545008  0.8533619  -0.52298987]
zmp_s [        0.          20275878.53655472 -12426239.17046706]
transform [[ 0.25786528 -0.96462303  0.05484511]
 [-0.08442539 -0.07904381 -0.99328971]
 [ 0.96248525  0.25150463 -0.10182132]]
zmp [-20240097.96624204  10740172.88933405   6364733.37968767]
d1:20196706.84940, d2:0.05940, d3:12178158.68283
eta 23760000.0
transform [[ 0.67704439 -0.73587155 -0.01019742]
 [ 0.16454065  0.13785231  0.97668993]
 [-0.71731257 -0.66294026  0.21441291]]
planes
[[ 0.67704439 -0.73587155 -0.01019742]
 [ 0.16454065  0.13785231  0.97668993]
 [-0.71731257 -0.66294026  0.21441291]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 346.8661   148.91005 -169.68687]
[ 5.85714783e+00 -9.00289809e+01 -3.41013533e-02]
[ 0.   0.  -9.8]
transform [[ 0.67704439 -0.73587155 -0.01019742]
 [ 0.16454065  0.13785231  0.97668993]
 [-0.71731257 -0.66294026  0.21441291]]
transform [[ 0.67704439 -0.73587155 -0.01019742]
 [ 0.16454065  0.13785231  0.97668993]
 [-0.71731257 -0.66294026  0.21441291]]
transform [[ 0.67704439 -0.73587155 -0.01019742]
 [ 0.16454065  0.13785231  0.97668993]
 [-0.71731257 -0.66294026  0.21441291]]
support
[-0.01242179  1.18973648  0.26118306]
[ 126.99543883  -88.13029661 -383.91293161]
[ 70.21566283 -11.48027063  55.47511875]
[ 0.0999347  -9.57156136 -2.10124654]
v_real [ 1.5564805  -0.18747376  0.39974838]
zmp_s [       0.         -4454375.75629668  9498022.13312758]
transform [[ 0.67704439  0.16454065 -0.71731257]
 [-0.73587155  0.13785231 -0.66294026]
 [-0.01019742  0.97668993  0.21441291]]
zmp [-7545976.5833219  -6910667.29068781 -2314045.37597894]
d1:15576398.71333, d2:0.05940, d3:6080310.00289
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-439.2098036308374 steps:167[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71680391  0.69726348  0.00398188]
 [-0.0125214   0.00716217  0.99989599]
 [ 0.69716239 -0.71677917  0.01386459]]
planes
[[ 0.71680391  0.69726348  0.00398188]
 [-0.0125214   0.00716217  0.99989599]
 [ 0.69716239 -0.71677917  0.01386459]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  182.99965 -1023.5079    812.50073]
[-144.37559885 -121.85237739   11.56397032]
[ 0.   0.  -9.8]
transform [[ 0.71680391  0.69726348  0.00398188]
 [-0.0125214   0.00716217  0.99989599]
 [ 0.69716239 -0.71677917  0.01386459]]
transform [[ 0.71680391  0.69726348  0.00398188]
 [-0.0125214   0.00716217  0.99989599]
 [ 0.69716239 -0.71677917  0.01386459]]
transform [[ 0.71680391  0.69726348  0.00398188]
 [-0.0125214   0.00716217  0.99989599]
 [ 0.69716239 -0.71677917  0.01386459]]
support
[0.00485045 1.2180045  0.01688889]
[-579.24451691  802.79427238  872.47458635]
[-188.4061598    12.49782414  -13.15166162]
[-0.03902242 -9.7989807  -0.13587295]
v_real [0.90092444 0.15118344 0.13407601]
zmp_s [      0.         3592119.70194108 3185646.00261852]
transform [[ 0.71680391 -0.0125214   0.69716239]
 [ 0.69726348  0.00716217 -0.71677917]
 [ 0.00398188  0.99989599  0.01386459]]
zmp [ 2175934.21873668 -2257677.32331141  3635913.7515424 ]
d1:8100620.56437, d2:0.05940, d3:3712829.40090
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-601.876122721876 steps:169[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.11768632  0.05839754  0.99133229]
 [-0.71078241 -0.69218802  0.12515625]
 [ 0.69349718 -0.71935076 -0.03995312]]
planes
[[ 0.11768632  0.05839754  0.99133229]
 [-0.71078241 -0.69218802  0.12515625]
 [ 0.69349718 -0.71935076 -0.03995312]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 141.60155  443.97168 1077.5267 ]
[  -3.6964042  -328.91209008    7.92094206]
[ 0.   0.  -9.8]
transform [[ 0.11768632  0.05839754  0.99133229]
 [-0.71078241 -0.69218802  0.12515625]
 [ 0.69349718 -0.71935076 -0.03995312]]
transform [[ 0.11768632  0.05839754  0.99133229]
 [-0.71078241 -0.69218802  0.12515625]
 [ 0.69349718 -0.71935076 -0.03995312]]
transform [[ 0.11768632  0.05839754  0.99133229]
 [-0.71078241 -0.69218802  0.12515625]
 [ 0.69349718 -0.71935076 -0.03995312]]
support
[ 1.2075728   0.15245674 -0.04866814]
[1110.77846486 -273.10055965 -264.22164419]
[-11.79038713 231.28770439 233.72324815]
[-9.71505647 -1.22653129  0.39154058]
v_real [ 0.31345093 -0.12997168 -0.19314872]
zmp_s [       0.         -3088127.00895011 -4589213.04925843]
transform [[ 0.11768632 -0.71078241  0.69349718]
 [ 0.05839754 -0.69218802 -0.71935076]
 [ 0.99133229  0.12515625 -0.03995312]]
zmp [-987619.95855069 5438818.4066199  -203145.02710295]
d1:6425780.99542, d2:0.05940, d3:2230850.10032
eta 23760000.0
transform [[ 0.93017173  0.33678496 -0.14613846]
 [ 0.10923513  0.12614028  0.98597991]
 [ 0.35049713 -0.93309408  0.08054338]]
planes
[[ 0.93017173  0.33678496 -0.14613846]
 [ 0.10923513  0.12614028  0.98597991]
 [ 0.35049713 -0.93309408  0.08054338]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 141.60155  443.97168 1077.5267 ]
[  -3.6964042  -328.91209008    7.92094206]
[ 0.   0.  -9.8]
transform [[ 0.93017173  0.33678496 -0.14613846]
 [ 0.10923513  0.12614028  0.98597991]
 [ 0.35049713 -0.93309408  0.08054338]]
transform [[ 0.93017173  0.33678496 -0.14613846]
 [ 0.10923513  0.12614028  0.98597991]
 [ 0.35049713 -0.93309408  0.08054338]]
transform [[ 0.93017173  0.33678496 -0.14613846]
 [ 0.10923513  0.12614028  0.98597991]
 [ 0.35049713 -0.93309408  0.08054338]]
support
[-0.17801582  1.2010529   0.0981124 ]
[ 123.76864294 1133.89029278 -277.84877109]
[-115.36848968  -34.08295106  306.24832586]
[ 1.4321569  -9.66260316 -0.78932509]
v_real [ 0.42081735 -0.26695913  0.17250243]
zmp_s [       0.         -6342948.64652967  4098657.17970661]
transform [[ 0.93017173  0.10923513  0.35049713]
 [ 0.33678496  0.12614028 -0.93309408]
 [-0.14613846  0.98597991  0.08054338]]
zmp [  743694.74274511 -4624534.09598711 -5923900.27683964]
d1:13814226.91162, d2:0.05940, d3:2847117.45581
eta 23760000.0
transform [[ 0.65169042  0.67852241  0.33897927]
 [-0.71687078  0.40500236  0.56751156]
 [ 0.24778187 -0.6128462   0.75034904]]
planes
[[ 0.65169042  0.67852241  0.33897927]
 [-0.71687078  0.40500236  0.56751156]
 [ 0.24778187 -0.6128462   0.75034904]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 82.93882 735.96625 765.6385 ]
[  -0.57751204 -164.52054498  -54.43485065]
[ 0.   0.  -9.8]
transform [[ 0.65169042  0.67852241  0.33897927]
 [-0.71687078  0.40500236  0.56751156]
 [ 0.24778187 -0.6128462   0.75034904]]
transform [[ 0.65169042  0.67852241  0.33897927]
 [-0.71687078  0.40500236  0.56751156]
 [ 0.24778187 -0.6128462   0.75034904]]
transform [[ 0.65169042  0.67852241  0.33897927]
 [-0.71687078  0.40500236  0.56751156]
 [ 0.24778187 -0.6128462   0.75034904]]
support
[0.41292123 0.69130354 0.91402358]
[812.95560426 673.12033902 144.01272985]
[-130.45952157  -97.10961368   59.8375549 ]
[-3.32199689 -5.56161327 -7.35342064]
v_real [ 0.2021511  -0.06588931 -0.86906284]
zmp_s [        0.          -1565529.59806504 -20648933.2756167 ]
transform [[ 0.65169042 -0.71687078  0.24778187]
 [ 0.67852241  0.40500236 -0.6128462 ]
 [ 0.33897927  0.56751156  0.75034904]]
zmp [ -3994148.92577909  12020577.02823948 -16382363.50162088]
d1:35657390.58795, d2:0.05940, d3:9101087.28930
eta 23760000.0
transform [[ 0.66610295 -0.45463336 -0.5912829 ]
 [ 0.7034992   0.64631885  0.29556876]
 [ 0.24778187 -0.6128462   0.75034904]]
planes
[[ 0.66610295 -0.45463336 -0.5912829 ]
 [ 0.7034992   0.64631885  0.29556876]
 [ 0.24778187 -0.6128462   0.75034904]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 82.93882 735.96625 765.6385 ]
[  -0.57751204 -164.52054498  -54.43485065]
[ 0.   0.  -9.8]
transform [[ 0.66610295 -0.45463336 -0.5912829 ]
 [ 0.7034992   0.64631885  0.29556876]
 [ 0.24778187 -0.6128462   0.75034904]]
transform [[ 0.66610295 -0.45463336 -0.5912829 ]
 [ 0.7034992   0.64631885  0.29556876]
 [ 0.24778187 -0.6128462   0.75034904]]
transform [[ 0.66610295 -0.45463336 -0.5912829 ]
 [ 0.7034992   0.64631885  0.29556876]
 [ 0.24778187 -0.6128462   0.75034904]]
support
[-0.72026015  0.36004153  0.91402358]
[-732.05796132  760.31507612  144.01272985]
[ 106.59824146 -122.82825071   59.8375549 ]
[ 5.79457246 -2.89657389 -7.35342064]
v_real [ 0.2021511  -0.06588931 -0.86906284]
zmp_s [        0.          -1565530.18372522 -20648933.05238255]
transform [[ 0.66610295  0.7034992   0.24778187]
 [-0.45463336  0.64631885 -0.6128462 ]
 [-0.5912829   0.29556876  0.75034904]]
zmp [ -6217780.53062757  11642788.39384299 -15956629.01372709]
d1:37465715.40040, d2:0.05940, d3:9343911.99174
eta 23760000.0
transform [[ 0.07280602  0.97601098  0.20518734]
 [ 0.15301539  0.19236647 -0.96932012]
 [-0.98553824  0.10196897 -0.13533929]]
planes
[[ 0.07280602  0.97601098  0.20518734]
 [ 0.15301539  0.19236647 -0.96932012]
 [-0.98553824  0.10196897 -0.13533929]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[306.8789  859.48285 164.77177]
[-347.37672078 -294.8815852   179.95963482]
[ 0.   0.  -9.8]
transform [[ 0.07280602  0.97601098  0.20518734]
 [ 0.15301539  0.19236647 -0.96932012]
 [-0.98553824  0.10196897 -0.13533929]]
transform [[ 0.07280602  0.97601098  0.20518734]
 [ 0.15301539  0.19236647 -0.96932012]
 [-0.98553824  0.10196897 -0.13533929]]
transform [[ 0.07280602  0.97601098  0.20518734]
 [ 0.15301539  0.19236647 -0.96932012]
 [-0.98553824  0.10196897 -0.13533929]]
support
[ 0.2499451  -1.18075908 -0.16486101]
[ 895.01641041   52.57627797 -237.1004092 ]
[-276.17334399 -284.31780736  287.92866164]
[-2.01083589  9.49933716  1.32632504]
v_real [-0.3385037  1.5822042 -0.6875988]
zmp_s [        0.          37593170.47943995 -16337348.41725275]
transform [[ 0.07280602  0.15301539 -0.98553824]
 [ 0.97601098  0.19236647  0.10196897]
 [ 0.20518734 -0.96932012 -0.13533929]]
zmp [ 21853415.31849288   5565762.69414353 -34228731.32748818]
d1:40461664.71406, d2:0.05940, d3:25403179.41643
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-422.47357474731905 steps:175[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-135.10293175781757 steps:176[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.23933929 -0.14548635  0.95997423]
 [-0.72162414  0.63483369  0.27612475]
 [-0.64959633 -0.75882804  0.0469542 ]]
planes
[[ 0.23933929 -0.14548635  0.95997423]
 [-0.72162414  0.63483369  0.27612475]
 [-0.64959633 -0.75882804  0.0469542 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[306.8789  859.48285 164.77177]
[-347.37672078 -294.8815852   179.95963482]
[ 0.   0.  -9.8]
transform [[ 0.23933929 -0.14548635  0.95997423]
 [-0.72162414  0.63483369  0.27612475]
 [-0.64959633 -0.75882804  0.0469542 ]]
transform [[ 0.23933929 -0.14548635  0.95997423]
 [-0.72162414  0.63483369  0.27612475]
 [-0.64959633 -0.75882804  0.0469542 ]]
transform [[ 0.23933929 -0.14548635  0.95997423]
 [-0.72162414  0.63483369  0.27612475]
 [-0.64959633 -0.75882804  0.0469542 ]]
support
[1.16937456 0.33635617 0.05719638]
[ 106.58181045  369.6750103  -843.81037474]
[132.51696026 113.16596849 457.86892128]
[-9.40774745 -2.70602251 -0.46015116]
v_real [ 0.06020115 -0.96724486  0.18164745]
zmp_s [        0.         -22981746.79152315   4315954.88156019]
transform [[ 0.23933929 -0.72162414 -0.64959633]
 [-0.14548635  0.63483369 -0.75882804]
 [ 0.95997423  0.27612475  0.0469542 ]]
zmp [ 13780554.70490979 -17864654.79934163  -6143176.77913944]
d1:32643921.40257, d2:0.05940, d3:5145354.88873
eta 23760000.0
transform [[ 0.17689292 -0.21091622 -0.96136534]
 [ 0.73941427 -0.61619353  0.27124169]
 [-0.64959633 -0.75882804  0.0469542 ]]
planes
[[ 0.17689292 -0.21091622 -0.96136534]
 [ 0.73941427 -0.61619353  0.27124169]
 [-0.64959633 -0.75882804  0.0469542 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[306.8789  859.48285 164.77177]
[-347.37672078 -294.8815852   179.95963482]
[ 0.   0.  -9.8]
transform [[ 0.17689292 -0.21091622 -0.96136534]
 [ 0.73941427 -0.61619353  0.27124169]
 [-0.64959633 -0.75882804  0.0469542 ]]
transform [[ 0.17689292 -0.21091622 -0.96136534]
 [ 0.73941427 -0.61619353  0.27124169]
 [-0.64959633 -0.75882804  0.0469542 ]]
transform [[ 0.17689292 -0.21091622 -0.96136534]
 [ 0.73941427 -0.61619353  0.27124169]
 [-0.64959633 -0.75882804  0.0469542 ]]
support
[-1.17106912  0.33040797  0.05719638]
[-285.40004162 -258.00415413 -843.81037474]
[-172.2601292   -26.33862393  457.86892128]
[ 9.42138035 -2.65816861 -0.46015116]
v_real [ 0.06020115 -0.96724486  0.18164745]
zmp_s [        0.         -22981734.90444158   4315947.23515379]
transform [[ 0.17689292  0.73941427 -0.64959633]
 [-0.21091622 -0.61619353 -0.75882804]
 [-0.96136534  0.27124169  0.0469542 ]]
zmp [-19796646.34509523  10886134.62575399  -6030952.87411729]
d1:31636322.44150, d2:0.05940, d3:6735051.11884
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-225.65859375527796 steps:179[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.73390484  0.65533239 -0.17867072]
 [ 0.12882541  0.12397711  0.98388708]
 [ 0.66692412 -0.7450968   0.00656395]]
planes
[[ 0.73390484  0.65533239 -0.17867072]
 [ 0.12882541  0.12397711  0.98388708]
 [ 0.66692412 -0.7450968   0.00656395]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  82.44377  823.7345  1211.8817 ]
[   6.25975133 -398.70726518   -8.12036158]
[ 0.   0.  -9.8]
transform [[ 0.73390484  0.65533239 -0.17867072]
 [ 0.12882541  0.12397711  0.98388708]
 [ 0.66692412 -0.7450968   0.00656395]]
transform [[ 0.73390484  0.65533239 -0.17867072]
 [ 0.12882541  0.12397711  0.98388708]
 [ 0.66692412 -0.7450968   0.00656395]]
transform [[ 0.73390484  0.65533239 -0.17867072]
 [ 0.12882541  0.12397711  0.98388708]
 [ 0.66692412 -0.7450968   0.00656395]]
support
[-0.21764438  1.19850355  0.00799575]
[ 383.79799903 1305.0998313  -550.82347304]
[-255.24085097  -56.61367816  301.19698603]
[ 1.75097305 -9.64209335 -0.06432668]
v_real [0.4145344  0.10374983 0.28215548]
zmp_s [      0.         2465097.1485802  6704014.05017762]
transform [[ 0.73390484  0.12882541  0.66692412]
 [ 0.65533239  0.12397711 -0.7450968 ]
 [-0.17867072  0.98388708  0.00656395]]
zmp [ 4788635.81796436 -4689523.81428806  2469382.01988851]
d1:10029765.77711, d2:0.05940, d3:4585304.45532
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-179.7083710513492 steps:181[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-206.10695519532027 steps:182[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.14230569  0.07258792 -0.98715764]
 [ 0.71647936  0.68054974  0.15332787]
 [ 0.68293959 -0.72909749  0.04483834]]
planes
[[ 0.14230569  0.07258792 -0.98715764]
 [ 0.71647936  0.68054974  0.15332787]
 [ 0.68293959 -0.72909749  0.04483834]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.14230569  0.07258792 -0.98715764]
 [ 0.71647936  0.68054974  0.15332787]
 [ 0.68293959 -0.72909749  0.04483834]]
transform [[ 0.14230569  0.07258792 -0.98715764]
 [ 0.71647936  0.68054974  0.15332787]
 [ 0.68293959 -0.72909749  0.04483834]]
transform [[ 0.14230569  0.07258792 -0.98715764]
 [ 0.71647936  0.68054974  0.15332787]
 [ 0.68293959 -0.72909749  0.04483834]]
support
[-1.20248752  0.18677346  0.05461898]
[-292.56966121 -159.61135072  112.80631623]
[ -16.3594224  -177.06535274  170.51398814]
[ 9.6741449  -1.5026131  -0.43941569]
v_real [0.5450837 0.1822386 0.3803759]
zmp_s [      0.         4329990.47435668 9037731.20289123]
transform [[ 0.14230569  0.71647936  0.68293959]
 [ 0.07258792  0.68054974 -0.72909749]
 [-0.98715764  0.15332787  0.04483834]]
zmp [ 9274573.2418594  -3642613.20008283  1069145.02786108]
d1:11954840.28318, d2:0.05940, d3:5054807.80839
eta 23760000.0
transform [[ 0.26158494  0.30141294  0.91690981]
 [-0.68203151 -0.61446494  0.39656773]
 [ 0.68293959 -0.72909749  0.04483834]]
planes
[[ 0.26158494  0.30141294  0.91690981]
 [-0.68203151 -0.61446494  0.39656773]
 [ 0.68293959 -0.72909749  0.04483834]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.26158494  0.30141294  0.91690981]
 [-0.68203151 -0.61446494  0.39656773]
 [ 0.68293959 -0.72909749  0.04483834]]
transform [[ 0.26158494  0.30141294  0.91690981]
 [-0.68203151 -0.61446494  0.39656773]
 [ 0.68293959 -0.72909749  0.04483834]]
transform [[ 0.26158494  0.30141294  0.91690981]
 [-0.68203151 -0.61446494  0.39656773]
 [ 0.68293959 -0.72909749  0.04483834]]
support
[1.11691645 0.48307153 0.05461898]
[162.42852956 291.01504636 112.80631623]
[-80.55907579 158.52445604 170.51398814]
[-8.98571618 -3.88636377 -0.43941569]
v_real [0.5450837 0.1822386 0.3803759]
zmp_s [      0.         4329986.28179591 9037731.26981326]
transform [[ 0.26158494 -0.68203151  0.68293959]
 [ 0.30141294 -0.61446494 -0.72909749]
 [ 0.91690981  0.39656773  0.04483834]]
zmp [ 3219037.38727171 -9250011.89878618  2122369.66539252]
d1:11401640.61674, d2:0.05940, d3:4968327.12630
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-419.3029116320163 steps:185[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-217.18421496094567 steps:186[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.16778283 -0.13697442 -0.97626173]
 [ 0.67843831 -0.70244569  0.2151548 ]
 [-0.71524155 -0.69843262 -0.02492963]]
planes
[[ 0.16778283 -0.13697442 -0.97626173]
 [ 0.67843831 -0.70244569  0.2151548 ]
 [-0.71524155 -0.69843262 -0.02492963]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.16778283 -0.13697442 -0.97626173]
 [ 0.67843831 -0.70244569  0.2151548 ]
 [-0.71524155 -0.69843262 -0.02492963]]
transform [[ 0.16778283 -0.13697442 -0.97626173]
 [ 0.67843831 -0.70244569  0.2151548 ]
 [-0.71524155 -0.69843262 -0.02492963]]
transform [[ 0.16778283 -0.13697442 -0.97626173]
 [ 0.67843831 -0.70244569  0.2151548 ]
 [-0.71524155 -0.69843262 -0.02492963]]
support
[-1.18921488  0.26208677 -0.03036756]
[-247.19612166  153.39149673  197.89688003]
[ 34.83398045 163.4434456  181.01829197]
[ 9.567365   -2.10851701  0.24431033]
v_real [ 0.15779825 -0.16734049 -0.74135715]
zmp_s [        0.          -3976009.73324072 -17614647.70977666]
transform [[ 0.16778283  0.67843831 -0.71524155]
 [-0.13697442 -0.70244569 -0.69843262]
 [-0.97626173  0.2151548  -0.02492963]]
zmp [ 9901250.64780955 15095575.5108311   -416330.98838151]
d1:24594413.05206, d2:0.05940, d3:8271126.84624
eta 23760000.0
transform [[ 0.1583479  -0.19669576  0.96759331]
 [-0.68070227  0.68811536  0.25128031]
 [-0.71524155 -0.69843262 -0.02492963]]
planes
[[ 0.1583479  -0.19669576  0.96759331]
 [-0.68070227  0.68811536  0.25128031]
 [-0.71524155 -0.69843262 -0.02492963]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.1583479  -0.19669576  0.96759331]
 [-0.68070227  0.68811536  0.25128031]
 [-0.71524155 -0.69843262 -0.02492963]]
transform [[ 0.1583479  -0.19669576  0.96759331]
 [-0.68070227  0.68811536  0.25128031]
 [-0.71524155 -0.69843262 -0.02492963]]
transform [[ 0.1583479  -0.19669576  0.96759331]
 [-0.68070227  0.68811536  0.25128031]
 [-0.71524155 -0.69843262 -0.02492963]]
support
[ 1.1786556   0.30609238 -0.03036756]
[289.88585289 -24.51672284 197.89688003]
[  43.12626886 -161.45368661  181.01829197]
[-9.48241446 -2.46254702  0.24431033]
v_real [ 0.15779825 -0.16734049 -0.74135715]
zmp_s [        0.          -3976010.22606594 -17614647.43903042]
transform [[ 0.1583479  -0.68070227 -0.71524155]
 [-0.19669576  0.68811536 -0.69843262]
 [ 0.96759331  0.25128031 -0.02492963]]
zmp [15305206.94440025  9566690.73614367  -559966.50204839]
d1:24741597.44971, d2:0.05940, d3:8244223.58319
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-229.99441275181078 steps:189[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69458872 -0.70234019  0.15577155]
 [-0.11100174  0.10930486  0.98779106]
 [-0.71079195 -0.70339942 -0.00203906]]
planes
[[ 0.69458872 -0.70234019  0.15577155]
 [-0.11100174  0.10930486  0.98779106]
 [-0.71079195 -0.70339942 -0.00203906]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.69458872 -0.70234019  0.15577155]
 [-0.11100174  0.10930486  0.98779106]
 [-0.71079195 -0.70339942 -0.00203906]]
transform [[ 0.69458872 -0.70234019  0.15577155]
 [-0.11100174  0.10930486  0.98779106]
 [-0.71079195 -0.70339942 -0.00203906]]
transform [[ 0.69458872 -0.70234019  0.15577155]
 [-0.11100174  0.10930486  0.98779106]
 [-0.71079195 -0.70339942 -0.00203906]]
support
[ 0.18975019  1.20325911 -0.00248384]
[136.09630256 251.68799113 204.76572765]
[163.41090055 -28.78909206 182.10670527]
[-1.52656122 -9.6803524   0.01998276]
v_real [-0.39564413  0.08171256  0.01806085]
zmp_s [      0.         1941489.88376451  429125.24482351]
transform [[ 0.69458872 -0.11100174 -0.71079195]
 [-0.70234019  0.10930486 -0.70339942]
 [ 0.15577155  0.98779106 -0.00203906]]
zmp [-520527.51788606  -89632.16783265 1916911.34196256]
d1:3857106.34448, d2:0.05940, d3:1410098.04582
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-266.1336144384769 steps:191[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70616221 -0.70804781 -0.00179725]
 [ 0.00453111  0.00198076  0.99998778]
 [-0.70803559 -0.70616174  0.00460698]]
planes
[[ 0.70616221 -0.70804781 -0.00179725]
 [ 0.00453111  0.00198076  0.99998778]
 [-0.70803559 -0.70616174  0.00460698]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.70616221 -0.70804781 -0.00179725]
 [ 0.00453111  0.00198076  0.99998778]
 [-0.70803559 -0.70616174  0.00460698]]
transform [[ 0.70616221 -0.70804781 -0.00179725]
 [ 0.00453111  0.00198076  0.99998778]
 [-0.70803559 -0.70616174  0.00460698]]
transform [[ 0.70616221 -0.70804781 -0.00179725]
 [ 0.00453111  0.00198076  0.99998778]
 [-0.70803559 -0.70616174  0.00460698]]
support
[-0.00218929  1.21811632  0.0056119 ]
[ 93.94452694 268.61635407 206.92443931]
[165.19608942  -3.89913712 182.72885411]
[ 0.01761306 -9.79988025 -0.04514839]
v_real [-0.28847614 -0.19361168 -0.8753211 ]
zmp_s [        0.          -4600214.22056059 -20797630.03106477]
transform [[ 0.70616221  0.00453111 -0.70803559]
 [-0.70804781  0.00198076 -0.70616174]
 [-0.00179725  0.99998778  0.00460698]]
zmp [14704618.12968062 14677378.65361067 -4695972.25489592]
d1:31518044.78027, d2:0.05940, d3:12335830.13153
eta 23760000.0
transform [[ 0.966712   -0.25249913 -0.04137838]
 [-0.02607149 -0.25808272  0.96577102]
 [-0.25453538 -0.93254358 -0.25607467]]
planes
[[ 0.966712   -0.25249913 -0.04137838]
 [-0.02607149 -0.25808272  0.96577102]
 [-0.25453538 -0.93254358 -0.25607467]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.966712   -0.25249913 -0.04137838]
 [-0.02607149 -0.25808272  0.96577102]
 [-0.25453538 -0.93254358 -0.25607467]]
transform [[ 0.966712   -0.25249913 -0.04137838]
 [-0.02607149 -0.25808272  0.96577102]
 [-0.25453538 -0.93254358 -0.25607467]]
transform [[ 0.966712   -0.25249913 -0.04137838]
 [-0.02607149 -0.25808272  0.96577102]
 [-0.25453538 -0.93254358 -0.25607467]]
support
[-0.05040429  1.17643581 -0.31193254]
[-33.91481337 316.97595375 148.9096356 ]
[ 49.9394064   60.58390204 233.51751936]
[ 0.40550808 -9.46455599  2.50953174]
v_real [1.1762513  1.4110895  0.89161843]
zmp_s [       0.         33527495.68261742 21184851.6523321 ]
transform [[ 0.966712   -0.02607149 -0.25453538]
 [-0.25249913 -0.25808272 -0.93254358]
 [-0.04137838  0.96577102 -0.25607467]]
zmp [ -6266406.12000883 -28408664.51389559  26954979.85347437]
d1:68311887.52870, d2:0.05940, d3:16855546.49769
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-231.0119908671561 steps:194[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.33353227 -0.35518068  0.87327141]
 [-0.61907852  0.61607814  0.48702121]
 [-0.71098387 -0.70306081 -0.01440281]]
planes
[[ 0.33353227 -0.35518068  0.87327141]
 [-0.61907852  0.61607814  0.48702121]
 [-0.71098387 -0.70306081 -0.01440281]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.33353227 -0.35518068  0.87327141]
 [-0.61907852  0.61607814  0.48702121]
 [-0.71098387 -0.70306081 -0.01440281]]
transform [[ 0.33353227 -0.35518068  0.87327141]
 [-0.61907852  0.61607814  0.48702121]
 [-0.71098387 -0.70306081 -0.01440281]]
transform [[ 0.33353227 -0.35518068  0.87327141]
 [-0.61907852  0.61607814  0.48702121]
 [-0.71098387 -0.70306081 -0.01440281]]
support
[ 1.06375915  0.59325573 -0.01754451]
[284.26029692  49.40555036 201.37829437]
[  80.19958856 -145.30762749  182.06731799]
[-8.55805978 -4.77280784  0.14114752]
v_real [0.0787233  0.16182177 0.23497358]
zmp_s [      0.         3844885.01066979 5582971.17787494]
transform [[ 0.33353227 -0.61907852 -0.71098387]
 [-0.35518068  0.61607814 -0.70306081]
 [ 0.87327141  0.48702121 -0.01440281]]
zmp [-6349688.17790698 -1556418.6155126   1792130.07637042]
d1:9130794.60937, d2:0.05940, d3:3663509.25030
eta 23760000.0
transform [[ 0.7031135  -0.71107531  0.00186109]
 [-0.01154994 -0.00880361  0.99989462]
 [-0.71098387 -0.70306081 -0.01440281]]
planes
[[ 0.7031135  -0.71107531  0.00186109]
 [-0.01154994 -0.00880361  0.99989462]
 [-0.71098387 -0.70306081 -0.01440281]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -78.95266 -212.10727  269.39752]
[ -12.74096069 -246.01057215   -3.35416037]
[ 0.   0.  -9.8]
transform [[ 0.7031135  -0.71107531  0.00186109]
 [-0.01154994 -0.00880361  0.99989462]
 [-0.71098387 -0.70306081 -0.01440281]]
transform [[ 0.7031135  -0.71107531  0.00186109]
 [-0.01154994 -0.00880361  0.99989462]
 [-0.71098387 -0.70306081 -0.01440281]]
transform [[ 0.7031135  -0.71107531  0.00186109]
 [-0.01154994 -0.00880361  0.99989462]
 [-0.71098387 -0.70306081 -0.01440281]]
support
[ 0.00226705  1.21800283 -0.01754451]
[ 95.81293379 272.14833973 201.37829437]
[165.96745904  -1.04086964 182.06731799]
[-0.01823868 -9.79896727  0.14114752]
v_real [0.0787233  0.16182177 0.23497358]
zmp_s [      0.         3844884.56119497 5582972.46682076]
transform [[ 0.7031135  -0.01154994 -0.71098387]
 [-0.71107531 -0.00880361 -0.70306081]
 [ 0.00186109  0.99989462 -0.01440281]]
zmp [-4013811.57130712 -3959017.96660823  3764068.89939017]
d1:10996275.69877, d2:0.05940, d3:4924427.18656
eta 23760000.0
transform [[ 0.17779621 -0.28943527 -0.94054019]
 [ 0.98090285  0.1287131   0.14581695]
 [ 0.07885527 -0.94850421  0.30679256]]
planes
[[ 0.17779621 -0.28943527 -0.94054019]
 [ 0.98090285  0.1287131   0.14581695]
 [ 0.07885527 -0.94850421  0.30679256]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 587.09735 -166.90709 -411.8302 ]
[-166.29052823   58.74676636   17.63300352]
[ 0.   0.  -9.8]
transform [[ 0.17779621 -0.28943527 -0.94054019]
 [ 0.98090285  0.1287131   0.14581695]
 [ 0.07885527 -0.94850421  0.30679256]]
transform [[ 0.17779621 -0.28943527 -0.94054019]
 [ 0.98090285  0.1287131   0.14581695]
 [ 0.07885527 -0.94850421  0.30679256]]
transform [[ 0.17779621 -0.28943527 -0.94054019]
 [ 0.98090285  0.1287131   0.14581695]
 [ 0.07885527 -0.94850421  0.30679256]]
support
[-1.14570136  0.17762418  0.37371359]
[540.03534136 494.35051168  78.26135582]
[ -63.15376108 -152.98218387  -63.42476523]
[ 9.21729391 -1.42900613 -3.00656706]
v_real [-1.0522115   0.12184121 -0.5432052 ]
zmp_s [        0.           2894948.57129753 -12906555.74783826]
transform [[ 0.17779621  0.98090285  0.07885527]
 [-0.28943527  0.1287131  -0.94850421]
 [-0.94054019  0.14581695  0.30679256]]
zmp [ 1821913.3850719  12614540.26548634 -3537502.6661991 ]
d1:21724825.22880, d2:0.05940, d3:3047631.45180
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-730.614248753174 steps:198[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69892508 -0.71128345  0.07469682]
 [-0.14884275 -0.04250546  0.98794693]
 [-0.69953525 -0.70161897 -0.1355775 ]]
planes
[[ 0.69892508 -0.71128345  0.07469682]
 [-0.14884275 -0.04250546  0.98794693]
 [-0.69953525 -0.70161897 -0.1355775 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 587.09735 -166.90709 -411.8302 ]
[-166.29052823   58.74676636   17.63300352]
[ 0.   0.  -9.8]
transform [[ 0.69892508 -0.71128345  0.07469682]
 [-0.14884275 -0.04250546  0.98794693]
 [-0.69953525 -0.70161897 -0.1355775 ]]
transform [[ 0.69892508 -0.71128345  0.07469682]
 [-0.14884275 -0.04250546  0.98794693]
 [-0.69953525 -0.70161897 -0.1355775 ]]
transform [[ 0.69892508 -0.71128345  0.07469682]
 [-0.14884275 -0.04250546  0.98794693]
 [-0.69953525 -0.70161897 -0.1355775 ]]
support
[ 0.09099053  1.20344898 -0.16515118]
[ 498.29290336 -487.1571041  -237.7552038 ]
[-156.69309342   39.67455329   72.71760215]
[-0.73202887 -9.68187989  1.3286595 ]
v_real [-0.75773674 -1.1466918  -0.15928763]
zmp_s [        0.         -27245396.85184066  -3784674.04217702]
transform [[ 0.69892508 -0.14884275 -0.69953525]
 [-0.71128345 -0.04250546 -0.70161897]
 [ 0.07469682  0.98794693 -0.1355775 ]]
zmp [  6702792.75098542   3813477.17264659 -26403889.46513913]
d1:54351135.07654, d2:0.05940, d3:20135433.22241
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-312.8923580868509 steps:200[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70830512  0.70376754  0.05491079]
 [-0.05516892 -0.02236106  0.99822664]
 [ 0.70374739 -0.71007836  0.02298765]]
planes
[[ 0.70830512  0.70376754  0.05491079]
 [-0.05516892 -0.02236106  0.99822664]
 [ 0.70374739 -0.71007836  0.02298765]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-255.74384  665.54926  551.4997 ]
[  48.66338042 -497.90260283  -19.98949953]
[ 0.   0.  -9.8]
transform [[ 0.70830512  0.70376754  0.05491079]
 [-0.05516892 -0.02236106  0.99822664]
 [ 0.70374739 -0.71007836  0.02298765]]
transform [[ 0.70830512  0.70376754  0.05491079]
 [-0.05516892 -0.02236106  0.99822664]
 [ 0.70374739 -0.71007836  0.02298765]]
transform [[ 0.70830512  0.70376754  0.05491079]
 [-0.05516892 -0.02236106  0.99822664]
 [ 0.70374739 -0.71007836  0.02298765]]
support
[0.06688855 1.21597102 0.02800197]
[ 317.53057882  549.74841721 -639.89349867]
[-317.03680676  -11.5051298   387.33707843]
[-0.53812578 -9.7826211  -0.22527896]
v_real [ 0.12131172  0.6142147  -0.43277574]
zmp_s [        0.          14593741.88012026 -10282750.87322127]
transform [[ 0.70830512 -0.05516892  0.70374739]
 [ 0.70376754 -0.02236106 -0.71007836]
 [ 0.05491079  0.99822664  0.02298765]]
zmp [-8041580.12846649  6975227.39738772 14331485.69385825]
d1:32247410.24136, d2:0.05940, d3:13889949.78058
eta 23760000.0
transform [[ 0.98599207  0.03922021  0.16211551]
 [-0.14555347 -0.27230328  0.95113885]
 [ 0.08144838 -0.96141183 -0.26278028]]
planes
[[ 0.98599207  0.03922021  0.16211551]
 [-0.14555347 -0.27230328  0.95113885]
 [ 0.08144838 -0.96141183 -0.26278028]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-255.74384  665.54926  551.4997 ]
[  48.66338042 -497.90260283  -19.98949953]
[ 0.   0.  -9.8]
transform [[ 0.98599207  0.03922021  0.16211551]
 [-0.14555347 -0.27230328  0.95113885]
 [ 0.08144838 -0.96141183 -0.26278028]]
transform [[ 0.98599207  0.03922021  0.16211551]
 [-0.14555347 -0.27230328  0.95113885]
 [ 0.08144838 -0.96141183 -0.26278028]]
transform [[ 0.98599207  0.03922021  0.16211551]
 [-0.14555347 -0.27230328  0.95113885]
 [ 0.08144838 -0.96141183 -0.26278028]]
support
[ 0.19747797  1.15861191 -0.32010086]
[-136.65175889  380.54594295 -805.62009572]
[ 25.21325652 109.48459993 487.90585437]
[-1.58873204 -9.32116077  2.57524673]
v_real [-0.16193356  0.10174439  1.1635317 ]
zmp_s [       0.          2417451.96830937 27645509.74075482]
transform [[ 0.98599207 -0.14555347  0.08144838]
 [ 0.03922021 -0.27230328 -0.96141183]
 [ 0.16211551  0.95113885 -0.26278028]]
zmp [  1899813.56127441 -27237000.32315952  -4965362.2657897 ]
d1:46232182.59068, d2:0.05940, d3:3396465.33888
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-400.56745394520146 steps:203[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.22357354  0.17889068  0.95812994]
 [-0.66278201 -0.69285899  0.28401843]
 [ 0.71465719 -0.69853032 -0.03633941]]
planes
[[ 0.22357354  0.17889068  0.95812994]
 [-0.66278201 -0.69285899  0.28401843]
 [ 0.71465719 -0.69853032 -0.03633941]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[195.58044 190.1835  198.51251]
[ 174.96208467 -359.96715712 -100.39863747]
[ 0.   0.  -9.8]
transform [[ 0.22357354  0.17889068  0.95812994]
 [-0.66278201 -0.69285899  0.28401843]
 [ 0.71465719 -0.69853032 -0.03633941]]
transform [[ 0.22357354  0.17889068  0.95812994]
 [-0.66278201 -0.69285899  0.28401843]
 [ 0.71465719 -0.69853032 -0.03633941]]
transform [[ 0.22357354  0.17889068  0.95812994]
 [-0.66278201 -0.69285899  0.28401843]
 [ 0.71465719 -0.69853032 -0.03633941]]
support
[ 1.16712798  0.34597171 -0.04426616]
[ 267.94944848 -205.01633921   -0.28979845]
[-121.47281668  104.92969651  380.13431032]
[-9.38967344 -2.78338059  0.35612618]
v_real [ 0.28192198  0.2584006  -0.69706595]
zmp_s [        0.           6139597.81377197 -16562286.63874182]
transform [[ 0.22357354 -0.66278201  0.71465719]
 [ 0.17889068 -0.69285899 -0.69853032]
 [ 0.95812994  0.28401843 -0.03633941]]
zmp [-15905572.1877583   7315383.7604285   2345622.5714964]
d1:22732028.09465, d2:0.05940, d3:9069089.53084
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-381.11045603264114 steps:205[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.72129369 -0.66773701  0.18401828]
 [-0.17939648  0.07650781  0.98079741]
 [-0.66899359 -0.74045521 -0.06460507]]
planes
[[ 0.72129369 -0.66773701  0.18401828]
 [-0.17939648  0.07650781  0.98079741]
 [-0.66899359 -0.74045521 -0.06460507]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[195.58044 190.1835  198.51251]
[ 174.96208467 -359.96715712 -100.39863747]
[ 0.   0.  -9.8]
transform [[ 0.72129369 -0.66773701  0.18401828]
 [-0.17939648  0.07650781  0.98079741]
 [-0.66899359 -0.74045521 -0.06460507]]
transform [[ 0.72129369 -0.66773701  0.18401828]
 [-0.17939648  0.07650781  0.98079741]
 [-0.66899359 -0.74045521 -0.06460507]]
transform [[ 0.72129369 -0.66773701  0.18401828]
 [-0.17939648  0.07650781  0.98079741]
 [-0.66899359 -0.74045521 -0.06460507]]
support
[ 0.22415841  1.19473993 -0.07869745]
[  50.60830926  174.16463855 -284.4893443 ]
[ 348.08725445 -157.39860616  155.97730468]
[-1.80337918 -9.61181462  0.63312971]
v_real [-0.275841   0.4116392 -0.6117178]
zmp_s [        0.           9780545.2430243  -14534417.00001662]
transform [[ 0.72129369 -0.17939648 -0.66899359]
 [-0.66773701  0.07650781 -0.74045521]
 [ 0.18401828  0.98079741 -0.06460507]]
zmp [ 7968836.44805139 11510372.93351809 10531730.50166549]
d1:26621712.61146, d2:0.05940, d3:13012132.31672
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-401.998818178723 steps:207[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.25560772  0.32678542  0.90987694]
 [-0.65383673 -0.63483471  0.41168255]
 [ 0.71215326 -0.70014018  0.05139563]]
planes
[[ 0.25560772  0.32678542  0.90987694]
 [-0.65383673 -0.63483471  0.41168255]
 [ 0.71215326 -0.70014018  0.05139563]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 524.73596 -378.79767 -205.54251]
[  42.77385651 -277.76453563  -27.07109769]
[ 0.   0.  -9.8]
transform [[ 0.25560772  0.32678542  0.90987694]
 [-0.65383673 -0.63483471  0.41168255]
 [ 0.71215326 -0.70014018  0.05139563]]
transform [[ 0.25560772  0.32678542  0.90987694]
 [-0.65383673 -0.63483471  0.41168255]
 [ 0.71215326 -0.70014018  0.05139563]]
transform [[ 0.25560772  0.32678542  0.90987694]
 [-0.65383673 -0.63483471  0.41168255]
 [ 0.71215326 -0.70014018  0.05139563]]
support
[1.10834949 0.50148335 0.06260662]
[-176.6773799  -187.23600143  628.33990356]
[-104.46743864  137.22275075  223.54431647]
[-8.91679404 -4.03448895 -0.5036772 ]
v_real [ 1.2220398 -0.4749293 -0.3475757]
zmp_s [        0.         -11284319.43628535  -8258395.42738935]
transform [[ 0.25560772 -0.65383673  0.71215326]
 [ 0.32678542 -0.63483471 -0.70014018]
 [ 0.90987694  0.41168255  0.05139563]]
zmp [ 1496859.29579838 12945712.06679127 -5070002.81196689]
d1:18452373.33992, d2:0.05940, d3:6537407.03021
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-204.96212540867293 steps:209[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.30521718  0.24524964  0.92016035]
 [-0.65222561 -0.65021461  0.38964444]
 [ 0.6938619  -0.7190783  -0.03849857]]
planes
[[ 0.30521718  0.24524964  0.92016035]
 [-0.65222561 -0.65021461  0.38964444]
 [ 0.6938619  -0.7190783  -0.03849857]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1031.7604  -109.06188  647.9764 ]
[-15.09387823 -52.74945407   2.76470287]
[ 0.   0.  -9.8]
transform [[ 0.30521718  0.24524964  0.92016035]
 [-0.65222561 -0.65021461  0.38964444]
 [ 0.6938619  -0.7190783  -0.03849857]]
transform [[ 0.30521718  0.24524964  0.92016035]
 [-0.65222561 -0.65021461  0.38964444]
 [ 0.6938619  -0.7190783  -0.03849857]]
transform [[ 0.30521718  0.24524964  0.92016035]
 [-0.65222561 -0.65021461  0.38964444]
 [ 0.6938619  -0.7190783  -0.03849857]]
support
[ 1.12087604  0.47463805 -0.04689631]
[ 884.40577535 -349.54651888  769.37708367]
[-14.99972575  45.22033094  27.35148372]
[-9.01757146 -3.81851555  0.37728602]
v_real [-0.19978707 -0.48639417 -0.5511444 ]
zmp_s [        0.         -11556724.10414664 -13095191.98085783]
transform [[ 0.30521718 -0.65222561  0.6938619 ]
 [ 0.24524964 -0.65021461 -0.7190783 ]
 [ 0.92016035  0.38964444 -0.03849857]]
zmp [-1548663.3417874  16930819.30394221 -3998867.13340002]
d1:21498226.59351, d2:0.05940, d3:8537896.97330
eta 23760000.0
transform [[ 0.19751617  0.14838929  0.96900362]
 [ 0.08342041  0.98234725 -0.16743663]
 [-0.97674382  0.11390612  0.18165079]]
planes
[[ 0.19751617  0.14838929  0.96900362]
 [ 0.08342041  0.98234725 -0.16743663]
 [-0.97674382  0.11390612  0.18165079]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[647.7338  119.59844 245.47853]
[-227.25646895 -338.86550356 -130.31183214]
[ 0.   0.  -9.8]
transform [[ 0.19751617  0.14838929  0.96900362]
 [ 0.08342041  0.98234725 -0.16743663]
 [-0.97674382  0.11390612  0.18165079]]
transform [[ 0.19751617  0.14838929  0.96900362]
 [ 0.08342041  0.98234725 -0.16743663]
 [-0.97674382  0.11390612  0.18165079]]
transform [[ 0.19751617  0.14838929  0.96900362]
 [ 0.08342041  0.98234725 -0.16743663]
 [-0.97674382  0.11390612  0.18165079]]
support
[ 1.18037354 -0.20395978  0.22127449]
[ 383.55461943  130.41932464 -574.45564622]
[-221.44347793 -330.02244956  159.70124841]
[-9.49623545  1.64087897 -1.78017772]
v_real [ 0.65607756 -1.4945092  -0.6372641 ]
zmp_s [        0.         -35509541.0476292  -15141392.84263883]
transform [[ 0.19751617  0.08342041 -0.97674382]
 [ 0.14838929  0.98234725  0.11390612]
 [ 0.96900362 -0.16743663  0.18165079]]
zmp [ 11827041.34498445 -36607397.34800884   3195151.93420179]
d1:29232153.22689, d2:0.05940, d3:10473806.08595
eta 23760000.0
transform [[-0.29459566 -0.59492522  0.74784857]
 [ 0.43912515  0.61078495  0.658871  ]
 [-0.84875357  0.52249956  0.08131209]]
planes
[[-0.29459566 -0.59492522  0.74784857]
 [ 0.43912515  0.61078495  0.658871  ]
 [-0.84875357  0.52249956  0.08131209]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1191.5574  1259.6904   341.06613]
[ -959.53495477 -1101.40622583  -152.05487768]
[ 0.   0.  -9.8]
transform [[-0.29459566 -0.59492522  0.74784857]
 [ 0.43912515  0.61078495  0.658871  ]
 [-0.84875357  0.52249956  0.08131209]]
transform [[-0.29459566 -0.59492522  0.74784857]
 [ 0.43912515  0.61078495  0.658871  ]
 [-0.84875357  0.52249956  0.08131209]]
transform [[-0.29459566 -0.59492522  0.74784857]
 [ 0.43912515  0.61078495  0.658871  ]
 [-0.84875357  0.52249956  0.08131209]]
support
[0.91097768 0.80259132 0.09904879]
[-845.38342242 1517.36134563 -325.41807909]
[  824.21515572 -1194.26282416   226.56055011]
[-7.32891599 -6.45693575 -0.79685848]
v_real [0.8248222  0.4521099  0.28249344]
zmp_s [       0.         10742133.68242894  6712045.15108974]
transform [[-0.29459566  0.43912515 -0.84875357]
 [-0.59492522  0.61078495  0.52249956]
 [ 0.74784857  0.658871    0.08131209]]
zmp [ -979731.2247599  10068174.20819421  7623450.72871831]
d1:21513499.08791, d2:0.05940, d3:8078018.73550
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-570.795900254881 steps:213[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.66712207  0.64704657 -0.36915979]
 [ 0.26598409  0.2559945   0.92936504]
 [ 0.69584531 -0.71819049 -0.00132453]]
planes
[[ 0.66712207  0.64704657 -0.36915979]
 [ 0.26598409  0.2559945   0.92936504]
 [ 0.69584531 -0.71819049 -0.00132453]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-451.84402  189.68707  564.9765 ]
[ -22.16042511 -424.03639597   56.17062932]
[ 0.   0.  -9.8]
transform [[ 0.66712207  0.64704657 -0.36915979]
 [ 0.26598409  0.2559945   0.92936504]
 [ 0.69584531 -0.71819049 -0.00132453]]
transform [[ 0.66712207  0.64704657 -0.36915979]
 [ 0.26598409  0.2559945   0.92936504]
 [ 0.69584531 -0.71819049 -0.00132453]]
transform [[ 0.66712207  0.64704657 -0.36915979]
 [ 0.26598409  0.2559945   0.92936504]
 [ 0.69584531 -0.71819049 -0.00132453]]
support
[-0.44968506  1.13208855 -0.00161345]
[-387.26535565  453.44493445 -451.39332128]
[-309.89094007  -62.242286    289.04428029]
[ 3.61776592 -9.10777738  0.01298035]
v_real [-0.28649595 -0.03738394 -0.33714217]
zmp_s [       0.          -888240.94782169 -8010497.31029859]
transform [[ 0.66712207  0.26598409  0.69584531]
 [ 0.64704657  0.2559945  -0.71819049]
 [-0.36915979  0.92936504 -0.00132453]]
zmp [-5810324.9100459   5525678.20184675  -814889.97542738]
d1:10652270.67678, d2:0.05940, d3:4123059.64281
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-386.5442406545052 steps:215[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.72156775 -0.6902073   0.05434972]
 [-0.06235142  0.01339932  0.99796438]
 [-0.68953049 -0.72348768 -0.03336689]]
planes
[[ 0.72156775 -0.6902073   0.05434972]
 [-0.06235142  0.01339932  0.99796438]
 [-0.68953049 -0.72348768 -0.03336689]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-451.84402  189.68707  564.9765 ]
[ -22.16042511 -424.03639597   56.17062932]
[ 0.   0.  -9.8]
transform [[ 0.72156775 -0.6902073   0.05434972]
 [-0.06235142  0.01339932  0.99796438]
 [-0.68953049 -0.72348768 -0.03336689]]
transform [[ 0.72156775 -0.6902073   0.05434972]
 [-0.06235142  0.01339932  0.99796438]
 [-0.68953049 -0.72348768 -0.03336689]]
transform [[ 0.72156775 -0.6902073   0.05434972]
 [-0.06235142  0.01339932  0.99796438]
 [-0.68953049 -0.72348768 -0.03336689]]
support
[ 0.06620509  1.21565155 -0.04064524]
[-426.2531662   594.54121975  155.4724673 ]
[279.73562676  51.75622213 320.19115622]
[-0.53262722 -9.78005095  0.32699547]
v_real [-0.280068    0.5297792   0.22021079]
zmp_s [       0.         12587556.0566011   5232208.36225334]
transform [[ 0.72156775 -0.06235142 -0.68953049]
 [-0.6902073   0.01339932 -0.72348768]
 [ 0.05434972  0.99796438 -0.03336689]]
zmp [-4392619.20640199 -3616773.57597949 12387350.10816778]
d1:25961363.53264, d2:0.05940, d3:10417075.80750
eta 23760000.0
transform [[ 0.51439154  0.78815293 -0.33795896]
 [ 0.17999221  0.28608945  0.94114596]
 [ 0.83845347 -0.5449475   0.00530059]]
planes
[[ 0.51439154  0.78815293 -0.33795896]
 [ 0.17999221  0.28608945  0.94114596]
 [ 0.83845347 -0.5449475   0.00530059]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 17.762884 519.3135   608.6983  ]
[  -7.72173632 -219.74102316   70.06846302]
[ 0.   0.  -9.8]
transform [[ 0.51439154  0.78815293 -0.33795896]
 [ 0.17999221  0.28608945  0.94114596]
 [ 0.83845347 -0.5449475   0.00530059]]
transform [[ 0.51439154  0.78815293 -0.33795896]
 [ 0.17999221  0.28608945  0.94114596]
 [ 0.83845347 -0.5449475   0.00530059]]
transform [[ 0.51439154  0.78815293 -0.33795896]
 [ 0.17999221  0.28608945  0.94114596]
 [ 0.83845347 -0.5449475   0.00530059]]
support
[-0.41167836  1.14643925  0.00645682]
[ 212.72047055  724.64123461 -264.8787706 ]
[-200.84179279    1.68920975  113.64440998]
[ 3.31199782 -9.22323037 -0.05194579]
v_real [0.3634617  0.23380499 0.39801204]
zmp_s [      0.         5555208.48371015 9456765.50941564]
transform [[ 0.51439154  0.17999221  0.83845347]
 [ 0.78815293  0.28608945 -0.5449475 ]
 [-0.33795896  0.94114596  0.00530059]]
zmp [ 8928952.14540482 -3564154.2292884   5278388.45041098]
d1:16393223.81337, d2:0.05940, d3:7288664.37732
eta 23760000.0
transform [[ 0.3259373  -0.90404344 -0.27653274]
 [-0.08794634 -0.32023236  0.94324797]
 [-0.94129187 -0.28311968 -0.18388298]]
planes
[[ 0.3259373  -0.90404344 -0.27653274]
 [-0.08794634 -0.32023236  0.94324797]
 [-0.94129187 -0.28311968 -0.18388298]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 477.95477  -487.7683    -28.345652]
[-2765.04906978   423.61072792  -535.9239607 ]
[ 0.   0.  -9.8]
transform [[ 0.3259373  -0.90404344 -0.27653274]
 [-0.08794634 -0.32023236  0.94324797]
 [-0.94129187 -0.28311968 -0.18388298]]
transform [[ 0.3259373  -0.90404344 -0.27653274]
 [-0.08794634 -0.32023236  0.94324797]
 [-0.94129187 -0.28311968 -0.18388298]]
transform [[ 0.3259373  -0.90404344 -0.27653274]
 [-0.08794634 -0.32023236  0.94324797]
 [-0.94129187 -0.28311968 -0.18388298]]
support
[-0.33685316  1.14899979 -0.2239936 ]
[ 604.58552881   87.42784633 -306.58585118]
[-1135.99460777  -397.98710706  2581.33296858]
[ 2.71002085 -9.24383014  1.80205322]
v_real [ 0.18602662 -1.6220871  -0.03540781]
zmp_s [        0.         -38540791.05817156   -841290.54839366]
transform [[ 0.3259373  -0.08794634 -0.94129187]
 [-0.90404344 -0.32023236 -0.28311968]
 [-0.27653274  0.94324797 -0.18388298]]
zmp [  4181421.48370044  12580194.44634398 -36198824.06447354]
d1:74365353.24402, d2:0.05940, d3:28286787.40900
eta 23760000.0
transform [[ 0.11186606 -0.53352898  0.83835131]
 [-0.95322359  0.18078251  0.2422446 ]
 [-0.28079432 -0.82628024 -0.48827818]]
planes
[[ 0.11186606 -0.53352898  0.83835131]
 [-0.95322359  0.18078251  0.2422446 ]
 [-0.28079432 -0.82628024 -0.48827818]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 477.95477  -487.7683    -28.345652]
[-2765.04906978   423.61072792  -535.9239607 ]
[ 0.   0.  -9.8]
transform [[ 0.11186606 -0.53352898  0.83835131]
 [-0.95322359  0.18078251  0.2422446 ]
 [-0.28079432 -0.82628024 -0.48827818]]
transform [[ 0.11186606 -0.53352898  0.83835131]
 [-0.95322359  0.18078251  0.2422446 ]
 [-0.28079432 -0.82628024 -0.48827818]]
transform [[ 0.11186606 -0.53352898  0.83835131]
 [-0.95322359  0.18078251  0.2422446 ]
 [-0.28079432 -0.82628024 -0.48827818]]
support
[ 1.02122189  0.29508571 -0.59478689]
[ 289.9418362  -550.6443241   282.66689142]
[-984.61631247 2582.46671526  688.06888421]
[-8.21584283 -2.37399709  4.78512617]
v_real [-1.3150384  0.9722812 -1.7040493]
zmp_s [        0.          23101401.85737504 -40488204.47017475]
transform [[ 0.11186606 -0.95322359 -0.28079432]
 [-0.53352898  0.18078251 -0.82628024]
 [ 0.83835131  0.2422446  -0.48827818]]
zmp [-10651943.17895168  37630932.60929765  25365696.68602147]
d1:51247279.11220, d2:0.05940, d3:24078968.72984
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-595.953098035449 steps:220[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.24168395 -0.25475967  0.93631536]
 [-0.69621897  0.62660813  0.3502019 ]
 [-0.67592019 -0.73651868 -0.02592739]]
planes
[[ 0.24168395 -0.25475967  0.93631536]
 [-0.69621897  0.62660813  0.3502019 ]
 [-0.67592019 -0.73651868 -0.02592739]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 477.95477  -487.7683    -28.345652]
[-2765.04906978   423.61072792  -535.9239607 ]
[ 0.   0.  -9.8]
transform [[ 0.24168395 -0.25475967  0.93631536]
 [-0.69621897  0.62660813  0.3502019 ]
 [-0.67592019 -0.73651868 -0.02592739]]
transform [[ 0.24168395 -0.25475967  0.93631536]
 [-0.69621897  0.62660813  0.3502019 ]
 [-0.67592019 -0.73651868 -0.02592739]]
transform [[ 0.24168395 -0.25475967  0.93631536]
 [-0.69621897  0.62660813  0.3502019 ]
 [-0.67592019 -0.73651868 -0.02592739]]
support
[ 1.14055495  0.42659187 -0.03158296]
[ 213.23721964 -648.32747026   36.92612123]
[-1277.98073138  2002.8359439   1570.85038168]
[-9.17589051 -3.43197867  0.25408839]
v_real [ 0.42102998 -0.1443631   0.11834474]
zmp_s [       0.         -3430071.12847785  2811880.57547919]
transform [[ 0.24168395 -0.69621897 -0.67592019]
 [-0.25475967  0.62660813 -0.73651868]
 [ 0.93631536  0.3502019  -0.02592739]]
zmp [  487473.73089483 -4220313.03967696 -1274122.15908085]
d1:5445044.39836, d2:0.05940, d3:2019229.05873
eta 23760000.0
transform [[ 0.30960426 -0.25185353 -0.91690516]
 [ 0.66878778 -0.62778193  0.39826214]
 [-0.67592019 -0.73651868 -0.02592739]]
planes
[[ 0.30960426 -0.25185353 -0.91690516]
 [ 0.66878778 -0.62778193  0.39826214]
 [-0.67592019 -0.73651868 -0.02592739]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 477.95477  -487.7683    -28.345652]
[-2765.04906978   423.61072792  -535.9239607 ]
[ 0.   0.  -9.8]
transform [[ 0.30960426 -0.25185353 -0.91690516]
 [ 0.66878778 -0.62778193  0.39826214]
 [-0.67592019 -0.73651868 -0.02592739]]
transform [[ 0.30960426 -0.25185353 -0.91690516]
 [ 0.66878778 -0.62778193  0.39826214]
 [-0.67592019 -0.73651868 -0.02592739]]
transform [[ 0.30960426 -0.25185353 -0.91690516]
 [ 0.66878778 -0.62778193  0.39826214]
 [-0.67592019 -0.73651868 -0.02592739]]
support
[-1.11691079  0.48513554 -0.03158296]
[296.8132756  614.57344055  36.92612123]
[ -471.36737163 -2328.60440631  1570.85038168]
[ 8.98567061 -3.902969    0.25408839]
v_real [ 0.42102998 -0.1443631   0.11834474]
zmp_s [       0.         -3430069.92130333  2811863.48939379]
transform [[ 0.30960426  0.66878778 -0.67592019]
 [-0.25185353 -0.62778193 -0.73651868]
 [-0.91690516  0.39826214 -0.02592739]]
zmp [-4194584.13865885    82345.91845007 -1438971.27134244]
d1:5649408.71135, d2:0.05940, d3:2204280.98566
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-273.6975245203066 steps:223[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-191.30003185549234 steps:224[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.45346433  0.50179702 -0.73659348]
 [ 0.51676542  0.52532697  0.67600679]
 [ 0.7261706  -0.68719095 -0.02109429]]
planes
[[ 0.45346433  0.50179702 -0.73659348]
 [ 0.51676542  0.52532697  0.67600679]
 [ 0.7261706  -0.68719095 -0.02109429]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 102.48691 -784.9178   243.06818]
[ -82.19591197 -144.45463587   50.38666151]
[ 0.   0.  -9.8]
transform [[ 0.45346433  0.50179702 -0.73659348]
 [ 0.51676542  0.52532697  0.67600679]
 [ 0.7261706  -0.68719095 -0.02109429]]
transform [[ 0.45346433  0.50179702 -0.73659348]
 [ 0.51676542  0.52532697  0.67600679]
 [ 0.7261706  -0.68719095 -0.02109429]]
transform [[ 0.45346433  0.50179702 -0.73659348]
 [ 0.51676542  0.52532697  0.67600679]
 [ 0.7261706  -0.68719095 -0.02109429]]
support
[-0.89726751  0.82346497 -0.02569562]
[-526.43768417 -195.06105172  608.68402693]
[-146.87430655  -84.30019487   38.51679281]
[ 7.21861615 -6.62486658  0.20672407]
v_real [-0.17891467 -0.36369717 -0.72602725]
zmp_s [        0.          -8641443.75381748 -17250408.91556603]
transform [[ 0.45346433  0.51676542  0.7261706 ]
 [ 0.50179702  0.52532697 -0.68719095]
 [-0.73659348  0.67600679 -0.02109429]]
zmp [-16992339.05657444   7314741.44937912  -5477789.51761699]
d1:26125941.52684, d2:0.05940, d3:11388091.12784
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-308.62628528440644 steps:226[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-322.8946192578395 steps:227[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.63297862  0.7342701   0.24532747]
 [-0.15362826 -0.19145279  0.9694041 ]
 [ 0.75877303 -0.65130121 -0.00838088]]
planes
[[ 0.63297862  0.7342701   0.24532747]
 [-0.15362826 -0.19145279  0.9694041 ]
 [ 0.75877303 -0.65130121 -0.00838088]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-612.27527   33.29236  453.9696 ]
[ -45.8455512  -382.666832     36.32903411]
[ 0.   0.  -9.8]
transform [[ 0.63297862  0.7342701   0.24532747]
 [-0.15362826 -0.19145279  0.9694041 ]
 [ 0.75877303 -0.65130121 -0.00838088]]
transform [[ 0.63297862  0.7342701   0.24532747]
 [-0.15362826 -0.19145279  0.9694041 ]
 [ 0.75877303 -0.65130121 -0.00838088]]
transform [[ 0.63297862  0.7342701   0.24532747]
 [-0.15362826 -0.19145279  0.9694041 ]
 [ 0.75877303 -0.65130121 -0.00838088]]
support
[ 0.29884105  1.18086138 -0.01020901]
[-251.74035448  527.7688658  -490.06597651]
[-301.08755492  115.52331814  214.14053195]
[-2.40420923 -9.50016019  0.08213259]
v_real [ 0.02674306  0.3032918  -0.1578334 ]
zmp_s [       0.          7206215.63287157 -3750122.54092397]
transform [[ 0.63297862 -0.15362826  0.75877303]
 [ 0.7342701  -0.19145279 -0.65130121]
 [ 0.24532747  0.9694041  -0.00838088]]
zmp [-3952570.20705991  1062809.26861265  7017164.30507815]
d1:14994113.92781, d2:0.05940, d3:6200575.84223
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-337.0782709238249 steps:229[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-221.4552159374586 steps:230[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.40590936  0.36251548 -0.83893991]
 [ 0.58119792  0.60603243  0.54307806]
 [ 0.7052989  -0.70803058  0.03530099]]
planes
[[ 0.40590936  0.36251548 -0.83893991]
 [ 0.58119792  0.60603243  0.54307806]
 [ 0.7052989  -0.70803058  0.03530099]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 504.21823  201.13425 -264.4907 ]
[-128.7482483  -317.57057026   76.742862  ]
[ 0.   0.  -9.8]
transform [[ 0.40590936  0.36251548 -0.83893991]
 [ 0.58119792  0.60603243  0.54307806]
 [ 0.7052989  -0.70803058  0.03530099]]
transform [[ 0.40590936  0.36251548 -0.83893991]
 [ 0.58119792  0.60603243  0.54307806]
 [ 0.7052989  -0.70803058  0.03530099]]
transform [[ 0.40590936  0.36251548 -0.83893991]
 [ 0.58119792  0.60603243  0.54307806]
 [ 0.7052989  -0.70803058  0.03530099]]
support
[-1.02193887  0.66154033  0.04300124]
[499.47297333 271.30536923 203.87858346]
[-231.76701587 -225.60891354  136.75277644]
[ 8.22161107 -5.32216504 -0.34594969]
v_real [ 0.14283367 -0.9850948  -0.1156989 ]
zmp_s [        0.         -23405851.07242216  -2749005.99168695]
transform [[ 0.40590936  0.58119792  0.7052989 ]
 [ 0.36251548  0.60603243 -0.70803058]
 [-0.83893991  0.54307806  0.03530099]]
zmp [-15542302.80339462 -12238324.51721423 -12808246.93764172]
d1:37940600.46637, d2:0.05940, d3:9871972.34341
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-44.43746795370518 steps:232[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-195.3723487499613 steps:233[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-31.63107189455314 steps:234[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.67906499  0.71641654 -0.16005665]
 [ 0.11661249  0.10999098  0.98706818]
 [ 0.72475672 -0.68894804 -0.00885208]]
planes
[[ 0.67906499  0.71641654 -0.16005665]
 [ 0.11661249  0.10999098  0.98706818]
 [ 0.72475672 -0.68894804 -0.00885208]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 358.9951   307.49863 1060.4794 ]
[  82.79998683 -414.79792464  -27.15163665]
[ 0.   0.  -9.8]
transform [[ 0.67906499  0.71641654 -0.16005665]
 [ 0.11661249  0.10999098  0.98706818]
 [ 0.72475672 -0.68894804 -0.00885208]]
transform [[ 0.67906499  0.71641654 -0.16005665]
 [ 0.11661249  0.10999098  0.98706818]
 [ 0.72475672 -0.68894804 -0.00885208]]
transform [[ 0.67906499  0.71641654 -0.16005665]
 [ 0.11661249  0.10999098  0.98706818]
 [ 0.72475672 -0.68894804 -0.00885208]]
support
[-0.19497     1.20237854 -0.01078299]
[ 294.34132007 1122.45082414   38.94607925]
[-236.59572087  -62.7690361   346.0244103 ]
[ 1.56855518 -9.67326813  0.08675037]
v_real [-0.53074086 -0.31635252 -0.08255663]
zmp_s [       0.         -7516535.23378862 -1961545.69718706]
transform [[ 0.67906499  0.11661249  0.72475672]
 [ 0.71641654  0.10999098 -0.68894804]
 [-0.16005665  0.98706818 -0.00885208]]
zmp [-2298165.28486349   524651.9459617  -7401968.96843289]
d1:15034740.09801, d2:0.05940, d3:5615339.15055
eta 23760000.0
transform [[ 0.05725016  0.04741265  0.99723345]
 [-0.68662232 -0.72325838  0.07380503]
 [ 0.72475672 -0.68894804 -0.00885208]]
planes
[[ 0.05725016  0.04741265  0.99723345]
 [-0.68662232 -0.72325838  0.07380503]
 [ 0.72475672 -0.68894804 -0.00885208]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 358.9951   307.49863 1060.4794 ]
[  82.79998683 -414.79792464  -27.15163665]
[ 0.   0.  -9.8]
transform [[ 0.05725016  0.04741265  0.99723345]
 [-0.68662232 -0.72325838  0.07380503]
 [ 0.72475672 -0.68894804 -0.00885208]]
transform [[ 0.05725016  0.04741265  0.99723345]
 [-0.68662232 -0.72325838  0.07380503]
 [ 0.72475672 -0.68894804 -0.00885208]]
transform [[ 0.05725016  0.04741265  0.99723345]
 [-0.68662232 -0.72325838  0.07380503]
 [ 0.72475672 -0.68894804 -0.00885208]]
support
[ 1.21476118  0.08990421 -0.01078299]
[1092.6773535  -390.62628903   38.94607925]
[-42.00287576 241.14982694 346.0244103 ]
[-9.77288781 -0.72328926  0.08675037]
v_real [-0.53074086 -0.31635252 -0.08255663]
zmp_s [       0.         -7516535.79062832 -1961545.33188054]
transform [[ 0.05725016 -0.68662232  0.72475672]
 [ 0.04741265 -0.72325838 -0.68894804]
 [ 0.99723345  0.07380503 -0.00885208]]
zmp [3739378.09867545 6787800.27242276 -537394.37137945]
d1:10885682.89627, d2:0.05940, d3:1225718.64300
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-293.04393593794015 steps:237[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.72375917  0.68234473  0.10285144]
 [-0.08079576 -0.06422774  0.99465919]
 [ 0.68530631 -0.72820365  0.00864514]]
planes
[[ 0.72375917  0.68234473  0.10285144]
 [-0.08079576 -0.06422774  0.99465919]
 [ 0.68530631 -0.72820365  0.00864514]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-208.42935 -322.4467  -333.66626]
[  15.46254939 -273.83680479  -80.27128615]
[ 0.   0.  -9.8]
transform [[ 0.72375917  0.68234473  0.10285144]
 [-0.08079576 -0.06422774  0.99465919]
 [ 0.68530631 -0.72820365  0.00864514]]
transform [[ 0.72375917  0.68234473  0.10285144]
 [-0.08079576 -0.06422774  0.99465919]
 [ 0.68530631 -0.72820365  0.00864514]]
transform [[ 0.72375917  0.68234473  0.10285144]
 [-0.08079576 -0.06422774  0.99465919]
 [ 0.68530631 -0.72820365  0.00864514]]
support
[0.12528654 1.21162539 0.01053091]
[-405.19050764 -294.33398169   89.08431338]
[-183.91595694  -63.50396207  209.31158812]
[-1.00794407 -9.74766002 -0.08472237]
v_real [-0.01888289 -0.13909972 -0.92385   ]
zmp_s [        0.          -3305007.61687067 -21950675.80568106]
transform [[ 0.72375917 -0.08079576  0.68530631]
 [ 0.68234473 -0.06422774 -0.72820365]
 [ 0.10285144  0.99465919  0.00864514]]
zmp [-14775906.05888893  16196835.49742227  -3477122.84138307]
d1:29775802.57630, d2:0.05940, d3:12050548.01811
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-264.4872074816572 steps:239[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.233503    0.21947342 -0.94726336]
 [ 0.67652708  0.66306812  0.32039338]
 [ 0.6984179  -0.71566206  0.00634869]]
planes
[[ 0.233503    0.21947342 -0.94726336]
 [ 0.67652708  0.66306812  0.32039338]
 [ 0.6984179  -0.71566206  0.00634869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -151.13538 -1671.4164    616.36523]
[ 94.28199599 -92.57672569 -18.48820249]
[ 0.   0.  -9.8]
transform [[ 0.233503    0.21947342 -0.94726336]
 [ 0.67652708  0.66306812  0.32039338]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.233503    0.21947342 -0.94726336]
 [ 0.67652708  0.66306812  0.32039338]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.233503    0.21947342 -0.94726336]
 [ 0.67652708  0.66306812  0.32039338]
 [ 0.6984179  -0.71566206  0.00634869]]
support
[-1.15389105  0.39028118  0.00773353]
[ -985.98223865 -1013.03074299  1094.52675187]
[ 19.21019488  -3.5238491  131.98450846]
[ 9.28318093 -3.13985516 -0.06221713]
v_real [ 0.49552777  0.19731751 -0.5148183 ]
zmp_s [        0.           4688265.72593791 -12232084.28168   ]
transform [[ 0.233503    0.67652708  0.6984179 ]
 [ 0.21947342  0.66306812 -0.71566206]
 [-0.94726336  0.32039338  0.00634869]]
zmp [-5371367.90548709 11862678.18249248  1424431.65288313]
d1:17050351.51075, d2:0.05940, d3:6387021.78211
eta 23760000.0
transform [[ 0.32682097  0.31102917 -0.89243984]
 [ 0.6367107   0.62537086  0.45112169]
 [ 0.6984179  -0.71566206  0.00634869]]
planes
[[ 0.32682097  0.31102917 -0.89243984]
 [ 0.6367107   0.62537086  0.45112169]
 [ 0.6984179  -0.71566206  0.00634869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -151.13538 -1671.4164    616.36523]
[ 94.28199599 -92.57672569 -18.48820249]
[ 0.   0.  -9.8]
transform [[ 0.32682097  0.31102917 -0.89243984]
 [ 0.6367107   0.62537086  0.45112169]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.32682097  0.31102917 -0.89243984]
 [ 0.6367107   0.62537086  0.45112169]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.32682097  0.31102917 -0.89243984]
 [ 0.6367107   0.62537086  0.45112169]
 [ 0.6984179  -0.71566206  0.00634869]]
support
[-1.08710882  0.5495254   0.00773353]
[-1119.32234589  -863.42888695  1094.52675187]
[ 18.51888008  -6.20485971 131.98450846]
[ 8.74591045 -4.42099254 -0.06221713]
v_real [ 0.49552777  0.19731751 -0.5148183 ]
zmp_s [        0.           4688265.51787997 -12232084.05801678]
transform [[ 0.32682097  0.6367107   0.6984179 ]
 [ 0.31102917  0.62537086 -0.71566206]
 [-0.89243984  0.45112169  0.00634869]]
zmp [-5558037.6493111  11685943.14086689  2037320.58930716]
d1:17398184.10651, d2:0.05940, d3:6780155.46062
eta 23760000.0
transform [[ 0.67233574  0.65912449  0.33692679]
 [-0.24531028 -0.23104723  0.94150949]
 [ 0.6984179  -0.71566206  0.00634869]]
planes
[[ 0.67233574  0.65912449  0.33692679]
 [-0.24531028 -0.23104723  0.94150949]
 [ 0.6984179  -0.71566206  0.00634869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -151.13538 -1671.4164    616.36523]
[ 94.28199599 -92.57672569 -18.48820249]
[ 0.   0.  -9.8]
transform [[ 0.67233574  0.65912449  0.33692679]
 [-0.24531028 -0.23104723  0.94150949]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.67233574  0.65912449  0.33692679]
 [-0.24531028 -0.23104723  0.94150949]
 [ 0.6984179  -0.71566206  0.00634869]]
transform [[ 0.67233574  0.65912449  0.33692679]
 [-0.24531028 -0.23104723  0.94150949]
 [ 0.6984179  -0.71566206  0.00634869]]
support
[0.41042103 1.14688208 0.00773353]
[-995.615233   1003.56489727 1094.52675187]
[ -3.85960222 -19.14556469 131.98450846]
[-3.30188252 -9.22679296 -0.06221713]
v_real [ 0.49552777  0.19731751 -0.5148183 ]
zmp_s [        0.           4688265.68754934 -12232082.52342193]
transform [[ 0.67233574 -0.24531028  0.6984179 ]
 [ 0.65912449 -0.23104723 -0.71566206]
 [ 0.33692679  0.94150949  0.00634869]]
zmp [-9693185.16628614  7670826.61218682  4336388.95952676]
d1:19005473.48152, d2:0.05940, d3:8282420.59774
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-939.9909915916744 steps:243[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.09796684  0.11547367 -0.98846769]
 [ 0.70945561  0.6884408   0.15073827]
 [ 0.69790781 -0.71604133 -0.01447908]]
planes
[[ 0.09796684  0.11547367 -0.98846769]
 [ 0.70945561  0.6884408   0.15073827]
 [ 0.69790781 -0.71604133 -0.01447908]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  88.42874   -36.676796 -517.9072  ]
[ -13.74968027 -146.2527648     5.03807521]
[ 0.   0.  -9.8]
transform [[ 0.09796684  0.11547367 -0.98846769]
 [ 0.70945561  0.6884408   0.15073827]
 [ 0.69790781 -0.71604133 -0.01447908]]
transform [[ 0.09796684  0.11547367 -0.98846769]
 [ 0.70945561  0.6884408   0.15073827]
 [ 0.69790781 -0.71604133 -0.01447908]]
transform [[ 0.09796684  0.11547367 -0.98846769]
 [ 0.70945561  0.6884408   0.15073827]
 [ 0.69790781 -0.71604133 -0.01447908]]
support
[-1.20408334  0.18361899 -0.01763742]
[516.36244184 -40.58197497  95.47603224]
[ -23.21533124 -109.68172742   95.05406782]
[ 9.68698339 -1.47723504  0.14189501]
v_real [-0.27851078 -0.10965057 -0.8462871 ]
zmp_s [        0.          -2605297.84334522 -20107780.00727675]
transform [[ 0.09796684  0.70945561  0.69790781]
 [ 0.11547367  0.6884408  -0.71604133]
 [-0.98846769  0.15073827 -0.01447908]]
zmp [-15881719.78612005  12604408.13907614   -101575.87151811]
d1:27901355.35787, d2:0.05940, d3:9123461.85356
eta 23760000.0
transform [[ 0.71328342  0.69675446 -0.07589472]
 [ 0.06443211  0.04263983  0.99701071]
 [ 0.69790781 -0.71604133 -0.01447908]]
planes
[[ 0.71328342  0.69675446 -0.07589472]
 [ 0.06443211  0.04263983  0.99701071]
 [ 0.69790781 -0.71604133 -0.01447908]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  88.42874   -36.676796 -517.9072  ]
[ -13.74968027 -146.2527648     5.03807521]
[ 0.   0.  -9.8]
transform [[ 0.71328342  0.69675446 -0.07589472]
 [ 0.06443211  0.04263983  0.99701071]
 [ 0.69790781 -0.71604133 -0.01447908]]
transform [[ 0.71328342  0.69675446 -0.07589472]
 [ 0.06443211  0.04263983  0.99701071]
 [ 0.69790781 -0.71604133 -0.01447908]]
transform [[ 0.71328342  0.69675446 -0.07589472]
 [ 0.06443211  0.04263983  0.99701071]
 [ 0.69790781 -0.71604133 -0.01447908]]
support
[-0.09244973  1.21448985 -0.01763742]
[  76.82645848 -512.22529196   95.47603224]
[-112.09204779   -2.09909841   95.05406782]
[ 0.74376826 -9.77070494  0.14189501]
v_real [-0.27851078 -0.10965057 -0.8462871 ]
zmp_s [        0.          -2605298.38302899 -20107779.93073871]
transform [[ 0.71328342  0.06443211  0.69790781]
 [ 0.69675446  0.04263983 -0.71604133]
 [-0.07589472  0.99701071 -0.01447908]]
zmp [-14201241.44715316  14286911.94662542  -2306368.17029265]
d1:28442071.96106, d2:0.05940, d3:10532686.96517
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-325.92056206758764 steps:246[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.75735062 -0.58245927  0.29523095]
 [-0.19575253  0.22881371  0.95358551]
 [-0.62297755 -0.77999079  0.05927433]]
planes
[[ 0.75735062 -0.58245927  0.29523095]
 [-0.19575253  0.22881371  0.95358551]
 [-0.62297755 -0.77999079  0.05927433]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  88.42874   -36.676796 -517.9072  ]
[ -13.74968027 -146.2527648     5.03807521]
[ 0.   0.  -9.8]
transform [[ 0.75735062 -0.58245927  0.29523095]
 [-0.19575253  0.22881371  0.95358551]
 [-0.62297755 -0.77999079  0.05927433]]
transform [[ 0.75735062 -0.58245927  0.29523095]
 [-0.19575253  0.22881371  0.95358551]
 [-0.62297755 -0.77999079  0.05927433]]
transform [[ 0.75735062 -0.58245927  0.29523095]
 [-0.19575253  0.22881371  0.95358551]
 [-0.62297755 -0.77999079  0.05927433]]
support
[0.35963004 1.16159226 0.07220391]
[ -64.56794272 -519.57112809  -57.18016222]
[ 76.26034559 -25.96886718 122.94018062]
[-2.89326336 -9.34513795 -0.58088844]
v_real [-0.22588946 -0.3289642   0.13906638]
zmp_s [       0.         -7816189.33563267  3304217.39922979]
transform [[ 0.75735062 -0.19575253 -0.62297755]
 [-0.58245927  0.22881371 -0.77999079]
 [ 0.29523095  0.95358551  0.05927433]]
zmp [ -528414.42840117 -4365710.41004821 -7257549.58364695]
d1:15479339.74492, d2:0.05940, d3:6246032.07176
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-257.45858460687 steps:248[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-131.23833117189983 steps:249[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.41834545  0.41125947  0.80984741]
 [-0.54029596 -0.60403895  0.58584756]
 [ 0.7301147  -0.68264389 -0.03049512]]
planes
[[ 0.41834545  0.41125947  0.80984741]
 [-0.54029596 -0.60403895  0.58584756]
 [ 0.7301147  -0.68264389 -0.03049512]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[203.55147  107.10084   56.148834]
[  75.02339522 -220.87485021  -30.99300537]
[ 0.   0.  -9.8]
transform [[ 0.41834545  0.41125947  0.80984741]
 [-0.54029596 -0.60403895  0.58584756]
 [ 0.7301147  -0.68264389 -0.03049512]]
transform [[ 0.41834545  0.41125947  0.80984741]
 [-0.54029596 -0.60403895  0.58584756]
 [ 0.7301147  -0.68264389 -0.03049512]]
transform [[ 0.41834545  0.41125947  0.80984741]
 [-0.54029596 -0.60403895  0.58584756]
 [ 0.7301147  -0.68264389 -0.03049512]]
support
[ 0.9865004   0.71363919 -0.03714706]
[ 174.67305294 -141.77645607   73.79192063]
[-84.55078349  74.72499974 206.49968604]
[-7.93650466 -5.74130605  0.29885218]
v_real [-0.971918  -0.5573629 -0.8833865]
zmp_s [        0.         -13242942.65204761 -20989264.02734463]
transform [[ 0.41834545 -0.54029596  0.7301147 ]
 [ 0.41125947 -0.60403895 -0.68264389]
 [ 0.80984741  0.58584756 -0.03049512]]
zmp [-8169461.78137333 22327446.07638388 -7118275.46509285]
d1:34266671.75300, d2:0.05940, d3:14784598.66257
eta 23760000.0
transform [[ 0.38642144  0.37566343  0.8423512 ]
 [-0.56356996 -0.6267969   0.53806555]
 [ 0.7301147  -0.68264389 -0.03049512]]
planes
[[ 0.38642144  0.37566343  0.8423512 ]
 [-0.56356996 -0.6267969   0.53806555]
 [ 0.7301147  -0.68264389 -0.03049512]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[203.55147  107.10084   56.148834]
[  75.02339522 -220.87485021  -30.99300537]
[ 0.   0.  -9.8]
transform [[ 0.38642144  0.37566343  0.8423512 ]
 [-0.56356996 -0.6267969   0.53806555]
 [ 0.7301147  -0.68264389 -0.03049512]]
transform [[ 0.38642144  0.37566343  0.8423512 ]
 [-0.56356996 -0.6267969   0.53806555]
 [ 0.7301147  -0.68264389 -0.03049512]]
transform [[ 0.38642144  0.37566343  0.8423512 ]
 [-0.56356996 -0.6267969   0.53806555]
 [ 0.7301147  -0.68264389 -0.03049512]]
support
[ 1.02609428  0.65543444 -0.03714706]
[ 166.18755754 -151.6342129    73.79192063]
[-80.09095036  79.48647104 206.49968604]
[-8.25504174 -5.27304242  0.29885218]
v_real [-0.971918  -0.5573629 -0.8833865]
zmp_s [        0.         -13242942.63265095 -20989264.01522407]
transform [[ 0.38642144 -0.56356996  0.7301147 ]
 [ 0.37566343 -0.6267969  -0.68264389]
 [ 0.8423512   0.53806555 -0.03049512]]
zmp [-7861245.47711622 22628828.24884341 -6485501.11784904]
d1:33697887.64768, d2:0.05940, d3:14409689.04601
eta 23760000.0
transform [[ 0.3880375   0.37284246  0.84286147]
 [-0.58676583  0.80517322 -0.08603504]
 [-0.71072698 -0.46117747  0.53120863]]
planes
[[ 0.3880375   0.37284246  0.84286147]
 [-0.58676583  0.80517322 -0.08603504]
 [-0.71072698 -0.46117747  0.53120863]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  9.749516 706.3606   517.55255 ]
[741.4827488  716.75621556  23.04639791]
[ 0.   0.  -9.8]
transform [[ 0.3880375   0.37284246  0.84286147]
 [-0.58676583  0.80517322 -0.08603504]
 [-0.71072698 -0.46117747  0.53120863]]
transform [[ 0.3880375   0.37284246  0.84286147]
 [-0.58676583  0.80517322 -0.08603504]
 [-0.71072698 -0.46117747  0.53120863]]
transform [[ 0.3880375   0.37284246  0.84286147]
 [-0.58676583  0.80517322 -0.08603504]
 [-0.71072698 -0.46117747  0.53120863]]
support
[ 1.02671586 -0.10480196  0.64708181]
[703.36950643 518.49429941 -57.75845095]
[ 574.38518635  140.05337374 -845.30116343]
[-8.26004244  0.84314335 -5.20584462]
v_real [-0.3574889  -0.04662205 -0.00783003]
zmp_s [       0.         -1107739.6558235   -186040.62093246]
transform [[ 0.3880375  -0.58676583 -0.71072698]
 [ 0.37284246  0.80517322 -0.46117747]
 [ 0.84286147 -0.08603504  0.53120863]]
zmp [ 782207.86186549 -806124.56110029   -3521.96351452]
d1:1357746.75513, d2:0.05940, d3:44124.49704
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-319.7479486157307 steps:253[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.2867828   0.34015065  0.89557421]
 [-0.65990955 -0.60753316  0.44206667]
 [ 0.69446027 -0.71777505  0.05023859]]
planes
[[ 0.2867828   0.34015065  0.89557421]
 [-0.65990955 -0.60753316  0.44206667]
 [ 0.69446027 -0.71777505  0.05023859]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 853.99634 -439.7698  -379.03055]
[  41.92498318 -179.68869601  -26.00005343]
[ 0.   0.  -9.8]
transform [[ 0.2867828   0.34015065  0.89557421]
 [-0.65990955 -0.60753316  0.44206667]
 [ 0.69446027 -0.71777505  0.05023859]]
transform [[ 0.2867828   0.34015065  0.89557421]
 [-0.65990955 -0.60753316  0.44206667]
 [ 0.69446027 -0.71777505  0.05023859]]
transform [[ 0.2867828   0.34015065  0.89557421]
 [-0.65990955 -0.60753316  0.44206667]
 [ 0.69446027 -0.71777505  0.05023859]]
support
[1.09092689 0.5384952  0.06119719]
[-244.12650974 -463.94236949  889.68036365]
[-72.38284077  70.00638709 156.78509151]
[-8.77662728 -4.33225336 -0.49233815]
v_real [-0.22051936  0.13069421  0.13774653]
zmp_s [      0.         3105293.6384798  3272861.12000136]
transform [[ 0.2867828  -0.65990955  0.69446027]
 [ 0.34015065 -0.60753316 -0.71777505]
 [ 0.89557421  0.44206667  0.05023859]]
zmp [  223659.10986543 -4235746.89086158  1537170.73446333]
d1:5901686.58838, d2:0.05940, d3:2492031.07599
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-188.21974267715257 steps:255[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-265.37890539065086 steps:256[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.71257144  0.69953811  0.05374398]
 [-0.02578099 -0.05044311  0.99839413]
 [ 0.70112574 -0.71281272 -0.01790953]]
planes
[[ 0.71257144  0.69953811  0.05374398]
 [-0.02578099 -0.05044311  0.99839413]
 [ 0.70112574 -0.71281272 -0.01790953]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[378.0957  -58.0536  318.39813]
[  -9.00746874 -271.60609093   24.35004656]
[ 0.   0.  -9.8]
transform [[ 0.71257144  0.69953811  0.05374398]
 [-0.02578099 -0.05044311  0.99839413]
 [ 0.70112574 -0.71281272 -0.01790953]]
transform [[ 0.71257144  0.69953811  0.05374398]
 [-0.02578099 -0.05044311  0.99839413]
 [ 0.70112574 -0.71281272 -0.01790953]]
transform [[ 0.71257144  0.69953811  0.05374398]
 [-0.02578099 -0.05044311  0.99839413]
 [ 0.70112574 -0.71281272 -0.01790953]]
support
[ 0.06546722  1.21617504 -0.02181616]
[245.92147643 311.06754821 300.77161379]
[-195.10860861   38.24381975  186.85281082]
[-0.52669098 -9.78426249  0.1755134 ]
v_real [-0.2857264   0.64601076 -0.46278816]
zmp_s [        0.          15349216.37436013 -10995846.94625771]
transform [[ 0.71257144 -0.02578099  0.70112574]
 [ 0.69953811 -0.05044311 -0.71281272]
 [ 0.05374398  0.99839413 -0.01790953]]
zmp [-8105189.37166554  7063717.45010729 15521498.0105576 ]
d1:33902615.43648, d2:0.05940, d3:14713123.93258
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1136.3823790763645 steps:258[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.05261303  0.03891769  0.99785638]
 [-0.57260382 -0.81747895  0.06207387]
 [ 0.81814229 -0.57464218 -0.02072562]]
planes
[[ 0.05261303  0.03891769  0.99785638]
 [-0.57260382 -0.81747895  0.06207387]
 [ 0.81814229 -0.57464218 -0.02072562]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 551.227   -591.87506  626.1314 ]
[ -40.81547851 -344.36992011   12.12182651]
[ 0.   0.  -9.8]
transform [[ 0.05261303  0.03891769  0.99785638]
 [-0.57260382 -0.81747895  0.06207387]
 [ 0.81814229 -0.57464218 -0.02072562]]
transform [[ 0.05261303  0.03891769  0.99785638]
 [-0.57260382 -0.81747895  0.06207387]
 [ 0.81814229 -0.57464218 -0.02072562]]
transform [[ 0.05261303  0.03891769  0.99785638]
 [-0.57260382 -0.81747895  0.06207387]
 [ 0.81814229 -0.57464218 -0.02072562]]
support
[ 1.21551999  0.07561412 -0.02524653]
[630.75653024 207.07712588 778.1215272 ]
[ -3.45366596 305.63871003 164.24538045]
[-9.77899251 -0.60832394  0.2031111 ]
v_real [ 0.8922734   0.5451102  -0.39460066]
zmp_s [       0.         12951818.40697104 -9375713.05657279]
transform [[ 0.05261303 -0.57260382  0.81814229]
 [ 0.03891769 -0.81747895 -0.57464218]
 [ 0.99785638  0.06207387 -0.02072562]]
zmp [-15086928.11477712  -5200158.77101027    998287.00343941]
d1:19867558.60073, d2:0.05940, d3:3070773.42564
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-453.1976077417706 steps:260[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-210.81071789060454 steps:261[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 6.76461577e-01 -7.35988081e-01 -2.68567167e-02]
 [ 1.88258253e-02 -1.91743225e-02  9.99638975e-01]
 [-7.36237288e-01 -6.76722944e-01  8.84889741e-04]]
planes
[[ 6.76461577e-01 -7.35988081e-01 -2.68567167e-02]
 [ 1.88258253e-02 -1.91743225e-02  9.99638975e-01]
 [-7.36237288e-01 -6.76722944e-01  8.84889741e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 551.227   -591.87506  626.1314 ]
[ -40.81547851 -344.36992011   12.12182651]
[ 0.   0.  -9.8]
transform [[ 6.76461577e-01 -7.35988081e-01 -2.68567167e-02]
 [ 1.88258253e-02 -1.91743225e-02  9.99638975e-01]
 [-7.36237288e-01 -6.76722944e-01  8.84889741e-04]]
transform [[ 6.76461577e-01 -7.35988081e-01 -2.68567167e-02]
 [ 1.88258253e-02 -1.91743225e-02  9.99638975e-01]
 [-7.36237288e-01 -6.76722944e-01  8.84889741e-04]]
transform [[ 6.76461577e-01 -7.35988081e-01 -2.68567167e-02]
 [ 1.88258253e-02 -1.91743225e-02  9.99638975e-01]
 [-7.36237288e-01 -6.76722944e-01  8.84889741e-04]]
support
[-3.27150046e-02  1.21769142e+00  1.07791180e-03]
[791.68103519 647.63146569  -4.74437282]
[225.51650105  17.95212505 263.10362975]
[ 2.63195824e-01 -9.79646195e+00 -8.67191947e-03]
v_real [-0.04829876 -0.81481546 -0.4974926 ]
zmp_s [        0.         -19360015.08818473 -11820423.97645001]
transform [[ 6.76461577e-01  1.88258253e-02 -7.36237288e-01]
 [-7.35988081e-01 -1.91743225e-02 -6.76722944e-01]
 [-2.68567167e-02  9.99638975e-01  8.84889741e-04]]
zmp [  8338168.62384507   8370367.28273732 -19363485.40419889]
d1:41898241.35097, d2:0.05940, d3:17631689.73829
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-274.93219449922975 steps:263[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.66540641  0.72929895 -0.15924014]
 [ 0.12865554  0.09808625  0.98682666]
 [ 0.73531091 -0.67712796 -0.02856112]]
planes
[[ 0.66540641  0.72929895 -0.15924014]
 [ 0.12865554  0.09808625  0.98682666]
 [ 0.73531091 -0.67712796 -0.02856112]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-691.83466 -216.91405  331.74005]
[ 127.94850724 -447.83318098  -30.84918548]
[ 0.   0.  -9.8]
transform [[ 0.66540641  0.72929895 -0.15924014]
 [ 0.12865554  0.09808625  0.98682666]
 [ 0.73531091 -0.67712796 -0.02856112]]
transform [[ 0.66540641  0.72929895 -0.15924014]
 [ 0.12865554  0.09808625  0.98682666]
 [ 0.73531091 -0.67712796 -0.02856112]]
transform [[ 0.66540641  0.72929895 -0.15924014]
 [ 0.12865554  0.09808625  0.98682666]
 [ 0.73531091 -0.67712796 -0.02856112]]
support
[-0.19397538  1.20208434 -0.0347912 ]
[-671.37273122  217.08528192 -371.30987498]
[-236.55408332  -57.90778985  398.20338806]
[ 1.56055339 -9.67090125  0.27989902]
v_real [ 0.08964587 -1.4848827  -0.39782917]
zmp_s [        0.         -35280810.2634821   -9452420.84088837]
transform [[ 0.66540641  0.12865554  0.73531091]
 [ 0.72929895  0.09808625 -0.67712796]
 [-0.15924014  0.98682666 -0.02856112]]
zmp [-11489539.81458741   2939936.20401451 -34546072.32342417]
d1:70735170.14277, d2:0.05940, d3:26636500.71482
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-87.54072261037194 steps:265[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.31209201  0.26578042  0.91211814]
 [-0.64685363 -0.64372325  0.40890193]
 [ 0.69582975 -0.71762192 -0.02897984]]
planes
[[ 0.31209201  0.26578042  0.91211814]
 [-0.64685363 -0.64372325  0.40890193]
 [ 0.69582975 -0.71762192 -0.02897984]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 215.1476   306.00345 -440.64923]
[ 28.77642391 -69.27422454 -18.9229224 ]
[ 0.   0.  -9.8]
transform [[ 0.31209201  0.26578042  0.91211814]
 [-0.64685363 -0.64372325  0.40890193]
 [ 0.69582975 -0.71762192 -0.02897984]]
transform [[ 0.31209201  0.26578042  0.91211814]
 [-0.64685363 -0.64372325  0.40890193]
 [ 0.69582975 -0.71762192 -0.02897984]]
transform [[ 0.31209201  0.26578042  0.91211814]
 [-0.64685363 -0.64372325  0.40890193]
 [ 0.69582975 -0.71762192 -0.02897984]]
support
[ 1.11107956  0.4980962  -0.03530125]
[-253.4485852  -516.33285914  -57.11873793]
[-26.69078129  18.24167529  70.28457735]
[-8.93875774 -4.00723891  0.28400247]
v_real [-0.5030245  -0.05586242 -0.3496175 ]
zmp_s [       0.         -1327292.43741892 -8306912.34548995]
transform [[ 0.31209201 -0.64685363  0.69582975]
 [ 0.26578042 -0.64372325 -0.71762192]
 [ 0.91211814  0.40890193 -0.02897984]]
zmp [-4921632.80761176  6815631.40811755  -301999.4195489 ]
d1:11403737.37120, d2:0.05940, d3:3912297.18744
eta 23760000.0
transform [[ 0.33855021  0.22834192  0.91282189]
 [-0.81808341  0.55072665  0.16564934]
 [-0.46489063 -0.80284506  0.37325141]]
planes
[[ 0.33855021  0.22834192  0.91282189]
 [-0.81808341  0.55072665  0.16564934]
 [-0.46489063 -0.80284506  0.37325141]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1841.0638    482.53378    99.04099]
[132.42112239 159.45820899 102.79762066]
[ 0.   0.  -9.8]
transform [[ 0.33855021  0.22834192  0.91282189]
 [-0.81808341  0.55072665  0.16564934]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33855021  0.22834192  0.91282189]
 [-0.81808341  0.55072665  0.16564934]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33855021  0.22834192  0.91282189]
 [-0.81808341  0.55072665  0.16564934]
 [-0.46489063 -0.80284506  0.37325141]]
support
[1.11193682 0.20178263 0.45466919]
[-422.70307301 1788.2940681   505.46065369]
[ 175.07811101   -3.4852792  -151.2122177 ]
[-8.94565451 -1.62336353 -3.6578638 ]
v_real [-0.12839249  1.1690375   0.01221853]
zmp_s [       0.         27776334.45397339   290314.00539879]
transform [[ 0.33855021 -0.81808341 -0.46489063]
 [ 0.22834192  0.55072665 -0.80284506]
 [ 0.91282189  0.16564934  0.37325141]]
zmp [-22858322.54285881  15064090.51738445   4709491.56898204]
d1:32203177.99559, d2:0.05940, d3:5165659.46059
eta 23760000.0
transform [[ 0.33865416  0.22827192  0.91280079]
 [-0.81804043  0.55075568  0.16576535]
 [-0.46489063 -0.80284506  0.37325141]]
planes
[[ 0.33865416  0.22827192  0.91280079]
 [-0.81804043  0.55075568  0.16576535]
 [-0.46489063 -0.80284506  0.37325141]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1841.0638    482.53378    99.04099]
[132.42112239 159.45820899 102.79762066]
[ 0.   0.  -9.8]
transform [[ 0.33865416  0.22827192  0.91280079]
 [-0.81804043  0.55075568  0.16576535]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33865416  0.22827192  0.91280079]
 [-0.81804043  0.55075568  0.16576535]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33865416  0.22827192  0.91280079]
 [-0.81804043  0.55075568  0.16576535]
 [-0.46489063 -0.80284506  0.37325141]]
support
[1.11191112 0.20192394 0.45466919]
[-422.93032238 1788.24044451  505.46065369]
[ 175.07854424   -3.46303465 -151.2122177 ]
[-8.94544773 -1.62450038 -3.6578638 ]
v_real [-0.12839249  1.1690375   0.01221853]
zmp_s [       0.         27776334.45163194   290314.00463361]
transform [[ 0.33865416 -0.81804043 -0.46489063]
 [ 0.22827192  0.55075568 -0.80284506]
 [ 0.91280079  0.16576535  0.37325141]]
zmp [-22857128.85403438  15064896.79320223   4712713.77698292]
d1:32204474.19751, d2:0.05940, d3:5167076.06709
eta 23760000.0
transform [[ 0.33870497  0.22823778  0.91279054]
 [-0.81801939  0.55076987  0.16582198]
 [-0.46489063 -0.80284506  0.37325141]]
planes
[[ 0.33870497  0.22823778  0.91279054]
 [-0.81801939  0.55076987  0.16582198]
 [-0.46489063 -0.80284506  0.37325141]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1841.0638    482.53378    99.04099]
[132.42112239 159.45820899 102.79762066]
[ 0.   0.  -9.8]
transform [[ 0.33870497  0.22823778  0.91279054]
 [-0.81801939  0.55076987  0.16582198]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33870497  0.22823778  0.91279054]
 [-0.81801939  0.55076987  0.16582198]
 [-0.46489063 -0.80284506  0.37325141]]
transform [[ 0.33870497  0.22823778  0.91279054]
 [-0.81801939  0.55076987  0.16582198]
 [-0.46489063 -0.80284506  0.37325141]]
support
[1.11189863 0.20199293 0.45466919]
[-423.04136066 1788.21416251  505.46065369]
[ 175.07877539   -3.45216401 -151.2122177 ]
[-8.94534726 -1.62505545 -3.6578638 ]
v_real [-0.12839249  1.1690375   0.01221853]
zmp_s [       0.         27776334.45048885   290314.0042601 ]
transform [[ 0.33870497 -0.81801939 -0.46489063]
 [ 0.22823778  0.55076987 -0.80284506]
 [ 0.91279054  0.16582198  0.37325141]]
zmp [-22856544.42663816  15065290.82532698   4714287.00917433]
d1:32205106.64949, d2:0.05940, d3:5167767.09972
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-155.9562370838608 steps:270[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-192.0857410840278 steps:271[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.18359944  0.1950862  -0.96344829]
 [ 0.67417485  0.68829322  0.26784483]
 [ 0.7153877  -0.69870877 -0.00515194]]
planes
[[ 0.18359944  0.1950862  -0.96344829]
 [ 0.67417485  0.68829322  0.26784483]
 [ 0.7153877  -0.69870877 -0.00515194]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-341.11053   97.66293  461.96182]
[-27.86557712 -17.0040973   13.96489832]
[ 0.   0.  -9.8]
transform [[ 0.18359944  0.1950862  -0.96344829]
 [ 0.67417485  0.68829322  0.26784483]
 [ 0.7153877  -0.69870877 -0.00515194]]
transform [[ 0.18359944  0.1950862  -0.96344829]
 [ 0.67417485  0.68829322  0.26784483]
 [ 0.7153877  -0.69870877 -0.00515194]]
transform [[ 0.18359944  0.1950862  -0.96344829]
 [ 0.67417485  0.68829322  0.26784483]
 [ 0.7153877  -0.69870877 -0.00515194]]
support
[-1.17360642  0.32627014 -0.00627574]
[-488.65133987  -39.01332322 -314.64423029]
[-21.88782642 -26.74965024  -8.12572557]
[ 9.4417932  -2.62487929  0.05048903]
v_real [-0.92231727  0.38057905 -0.63580287]
zmp_s [        0.           9042558.41128751 -15106675.18000071]
transform [[ 0.18359944  0.67417485  0.7153877 ]
 [ 0.1950862   0.68829322 -0.69870877]
 [-0.96344829  0.26784483 -0.00515194]]
zmp [-4710864.22439275 16779098.10737919  2499831.197043  ]
d1:20687138.73497, d2:0.05940, d3:8445516.59645
eta 23760000.0
transform [[ 2.14178860e-01  1.94808364e-01 -9.57171440e-01]
 [ 6.73202634e-01 -7.39458144e-01  1.39102354e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
planes
[[ 2.14178860e-01  1.94808364e-01 -9.57171440e-01]
 [ 6.73202634e-01 -7.39458144e-01  1.39102354e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[446.49048  82.43543 552.46295]
[ 102.65646605 -224.1605789   -90.76859739]
[ 0.   0.  -9.8]
transform [[ 2.14178860e-01  1.94808364e-01 -9.57171440e-01]
 [ 6.73202634e-01 -7.39458144e-01  1.39102354e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
transform [[ 2.14178860e-01  1.94808364e-01 -9.57171440e-01]
 [ 6.73202634e-01 -7.39458144e-01  1.39102354e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
transform [[ 2.14178860e-01  1.94808364e-01 -9.57171440e-01]
 [ 6.73202634e-01 -7.39458144e-01  1.39102354e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
support
[-1.16596039e+00  1.69444918e-04 -3.52675554e-01]
[-417.11382556  239.69786318 -529.0800477 ]
[ 65.19959834 234.85334276  98.07234468]
[ 9.38028011e+00 -1.36320307e-03  2.83731377e+00]
v_real [-0.82953215 -0.7178791  -0.25935164]
zmp_s [        0.         -17056808.44473945  -6162194.42382178]
transform [[ 2.14178860e-01  6.73202634e-01 -7.07761049e-01]
 [ 1.94808364e-01 -7.39458144e-01 -6.44400120e-01]
 [-9.57171440e-01  1.39102354e-04 -2.89521813e-01]]
zmp [-7121327.17899159 16583714.73501029  1781717.06185144]
d1:12694403.08541, d2:0.05940, d3:4178449.88676
eta 23760000.0
transform [[ 2.14185029e-01  1.94801584e-01 -9.57171440e-01]
 [ 6.73200607e-01 -7.39459872e-01  1.47879124e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
planes
[[ 2.14185029e-01  1.94801584e-01 -9.57171440e-01]
 [ 6.73200607e-01 -7.39459872e-01  1.47879124e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[446.49048  82.43543 552.46295]
[ 102.65646605 -224.1605789   -90.76859739]
[ 0.   0.  -9.8]
transform [[ 2.14185029e-01  1.94801584e-01 -9.57171440e-01]
 [ 6.73200607e-01 -7.39459872e-01  1.47879124e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
transform [[ 2.14185029e-01  1.94801584e-01 -9.57171440e-01]
 [ 6.73200607e-01 -7.39459872e-01  1.47879124e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
transform [[ 2.14185029e-01  1.94801584e-01 -9.57171440e-01]
 [ 6.73200607e-01 -7.39459872e-01  1.47879124e-04]
 [-7.07761049e-01 -6.44400120e-01 -2.89521813e-01]]
support
[-1.16596039e+00  1.80136174e-04 -3.52675554e-01]
[-417.11163004  239.70166469 -529.0800477 ]
[ 65.20175145 234.85272554  98.07234468]
[ 9.38028011e+00 -1.44921541e-03  2.83731377e+00]
v_real [-0.82953215 -0.7178791  -0.25935164]
zmp_s [        0.         -17056808.44474178  -6162194.42381526]
transform [[ 2.14185029e-01  6.73200607e-01 -7.07761049e-01]
 [ 1.94801584e-01 -7.39459872e-01 -6.44400120e-01]
 [-9.57171440e-01  1.47879124e-04 -2.89521813e-01]]
zmp [-7121292.61238749 16583744.21829305  1781567.35817529]
d1:12694454.61761, d2:0.05940, d3:4178374.99539
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-459.10788795442187 steps:275[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.73378819  0.67856538 -0.03322501]
 [ 0.02286794  0.02420749  0.99944544]
 [ 0.67899334 -0.73414105  0.00224577]]
planes
[[ 0.73378819  0.67856538 -0.03322501]
 [ 0.02286794  0.02420749  0.99944544]
 [ 0.67899334 -0.73414105  0.00224577]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[379.8985  901.84674 833.97626]
[ -26.01791799 -415.0973102    28.80613186]
[ 0.   0.  -9.8]
transform [[ 0.73378819  0.67856538 -0.03322501]
 [ 0.02286794  0.02420749  0.99944544]
 [ 0.67899334 -0.73414105  0.00224577]]
transform [[ 0.73378819  0.67856538 -0.03322501]
 [ 0.02286794  0.02420749  0.99944544]
 [ 0.67899334 -0.73414105  0.00224577]]
transform [[ 0.73378819  0.67856538 -0.03322501]
 [ 0.02286794  0.02420749  0.99944544]
 [ 0.67899334 -0.73414105  0.00224577]]
support
[-0.04047243  1.21745567  0.00273565]
[ 863.01813798  864.03270691 -402.26123995]
[-301.71939042   18.14671781  287.13867483]
[ 0.32560515 -9.7945653  -0.02200859]
v_real [ 0.98639804 -0.27551123 -0.5389726 ]
zmp_s [        0.          -6546146.07508781 -12805988.99510375]
transform [[ 0.73378819  0.02286794  0.67899334]
 [ 0.67856538  0.02420749 -0.73414105]
 [-0.03322501  0.99944544  0.00224577]]
zmp [-8844878.18521058  9242936.47920039 -6571275.20016807]
d1:22336656.71753, d2:0.05940, d3:9915787.21816
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-396.2069698118451 steps:277[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.42116091 -0.30364266 -0.85464883]
 [ 0.61153966 -0.60081613  0.51481968]
 [-0.66980797 -0.73947352 -0.06735078]]
planes
[[ 0.42116091 -0.30364266 -0.85464883]
 [ 0.61153966 -0.60081613  0.51481968]
 [-0.66980797 -0.73947352 -0.06735078]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[379.8985  901.84674 833.97626]
[ -26.01791799 -415.0973102    28.80613186]
[ 0.   0.  -9.8]
transform [[ 0.42116091 -0.30364266 -0.85464883]
 [ 0.61153966 -0.60081613  0.51481968]
 [-0.66980797 -0.73947352 -0.06735078]]
transform [[ 0.42116091 -0.30364266 -0.85464883]
 [ 0.61153966 -0.60081613  0.51481968]
 [-0.66980797 -0.73947352 -0.06735078]]
transform [[ 0.42116091 -0.30364266 -0.85464883]
 [ 0.61153966 -0.60081613  0.51481968]
 [-0.66980797 -0.73947352 -0.06735078]]
support
[-1.0410744   0.62711792 -0.08204208]
[-826.59757889  119.82632145 -977.51977498]
[ 90.46439481 248.31613462 322.44036336]
[ 8.37555852 -5.04523288  0.6600376 ]
v_real [-0.24080253  0.2585181  -0.46338657]
zmp_s [        0.           6142390.87514926 -11010064.1426057 ]
transform [[ 0.42116091  0.61153966 -0.66980797]
 [-0.30364266 -0.60081613 -0.73947352]
 [-0.85464883  0.51481968 -0.06735078]]
zmp [11130944.357646    4451203.38730539  3903760.06772206]
d1:16061703.70479, d2:0.05940, d3:7416245.15494
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-412.5609723132962 steps:279[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.62560129 -0.7272256  -0.28242874]
 [ 0.07197881 -0.3066726   0.94908959]
 [-0.77681541 -0.61408055 -0.13950992]]
planes
[[ 0.62560129 -0.7272256  -0.28242874]
 [ 0.07197881 -0.3066726   0.94908959]
 [-0.77681541 -0.61408055 -0.13950992]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[379.8985  901.84674 833.97626]
[ -26.01791799 -415.0973102    28.80613186]
[ 0.   0.  -9.8]
transform [[ 0.62560129 -0.7272256  -0.28242874]
 [ 0.07197881 -0.3066726   0.94908959]
 [-0.77681541 -0.61408055 -0.13950992]]
transform [[ 0.62560129 -0.7272256  -0.28242874]
 [ 0.07197881 -0.3066726   0.94908959]
 [-0.77681541 -0.61408055 -0.13950992]]
transform [[ 0.62560129 -0.7272256  -0.28242874]
 [ 0.07197881 -0.3066726   0.94908959]
 [-0.77681541 -0.61408055 -0.13950992]]
support
[-0.34403526  1.15611564 -0.16994138]
[-653.71991202  542.2911349  -965.26550845]
[277.4568685  152.76583365 271.09556254]
[ 2.76780167 -9.30107795  1.36719718]
v_real [-0.6910999  -0.11215403 -0.49767062]
zmp_s [        0.          -2664778.45911533 -11824653.89519126]
transform [[ 0.62560129  0.07197881 -0.77681541]
 [-0.7272256  -0.3066726  -0.61408055]
 [-0.28242874  0.94908959 -0.13950992]]
zmp [8993765.84046525 8078504.49344363 -879457.01124135]
d1:16060273.86462, d2:0.05940, d3:5989318.06277
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-458.0506130065486 steps:281[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.10216407  0.11422799 -0.98818749]
 [ 0.70466721  0.69285846  0.15294214]
 [ 0.70214432 -0.71196848 -0.00970748]]
planes
[[ 0.10216407  0.11422799 -0.98818749]
 [ 0.70466721  0.69285846  0.15294214]
 [ 0.70214432 -0.71196848 -0.00970748]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-182.84097 -924.94525  946.6066 ]
[  27.76182778 -373.49809933  -17.97200943]
[ 0.   0.  -9.8]
transform [[ 0.10216407  0.11422799 -0.98818749]
 [ 0.70466721  0.69285846  0.15294214]
 [ 0.70214432 -0.71196848 -0.00970748]]
transform [[ 0.10216407  0.11422799 -0.98818749]
 [ 0.70466721  0.69285846  0.15294214]
 [ 0.70214432 -0.71196848 -0.00970748]]
transform [[ 0.10216407  0.11422799 -0.98818749]
 [ 0.70466721  0.69285846  0.15294214]
 [ 0.70214432 -0.71196848 -0.00970748]]
support
[-1.20374202  0.18630359 -0.01182499]
[-1059.7592437   -624.92213898   520.96194919]
[ -22.06795997 -241.96714477  285.5861474 ]
[ 9.68423742 -1.49883293  0.09513331]
v_real [ 0.45962423 -0.39607388 -0.6143929 ]
zmp_s [        0.          -9410713.82363819 -14597975.37870464]
transform [[ 0.10216407  0.70466721  0.70214432]
 [ 0.11422799  0.69285846 -0.71196848]
 [-0.98818749  0.15294214 -0.00970748]]
zmp [-16881307.02508808   3873005.6995101   -1297585.10901815]
d1:20136283.39418, d2:0.05940, d3:7848125.89232
eta 23760000.0
transform [[ 0.10005126  0.12106892 -0.98758906]
 [ 0.63974869 -0.76802403 -0.02934032]
 [-0.76204425 -0.62887317 -0.15429544]]
planes
[[ 0.10005126  0.12106892 -0.98758906]
 [ 0.63974869 -0.76802403 -0.02934032]
 [-0.76204425 -0.62887317 -0.15429544]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-407.30002    80.706795 1236.6279  ]
[265.77810124 571.85437417 -97.7166464 ]
[ 0.   0.  -9.8]
transform [[ 0.10005126  0.12106892 -0.98758906]
 [ 0.63974869 -0.76802403 -0.02934032]
 [-0.76204425 -0.62887317 -0.15429544]]
transform [[ 0.10005126  0.12106892 -0.98758906]
 [ 0.63974869 -0.76802403 -0.02934032]
 [-0.76204425 -0.62887317 -0.15429544]]
transform [[ 0.10005126  0.12106892 -0.98758906]
 [ 0.63974869 -0.76802403 -0.02934032]
 [-0.76204425 -0.62887317 -0.15429544]]
support
[-1.20301305 -0.03574036 -0.18795209]
[-1252.26001199  -358.83747236    68.82024349]
[ 192.32911954 -266.29966895 -547.08131343]
[9.6783728  0.28753515 1.51209536]
v_real [ 0.02498535 -1.1855253   0.03941204]
zmp_s [        0.         -28168082.128886      936430.02076683]
transform [[ 0.10005126  0.63974869 -0.76204425]
 [ 0.12106892 -0.76802403 -0.62887317]
 [-0.98758906 -0.02934032 -0.15429544]]
zmp [-18734094.82629639  21044868.16418231    681973.69090952]
d1:31427079.66481, d2:0.05940, d3:907507.48253
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-225.83250927286676 steps:284[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-114.21353039065075 steps:285[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-308.02549914067595 steps:286[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69878525  0.69865113  0.15357693]
 [-0.13291758 -0.08413919  0.98754925]
 [ 0.70287424 -0.71049786  0.0340678 ]]
planes
[[ 0.69878525  0.69865113  0.15357693]
 [-0.13291758 -0.08413919  0.98754925]
 [ 0.70287424 -0.71049786  0.0340678 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -34.01688   53.51028 -222.94786]
[  14.85801196 -349.80705074    5.32340394]
[ 0.   0.  -9.8]
transform [[ 0.69878525  0.69865113  0.15357693]
 [-0.13291758 -0.08413919  0.98754925]
 [ 0.70287424 -0.71049786  0.0340678 ]]
transform [[ 0.69878525  0.69865113  0.15357693]
 [-0.13291758 -0.08413919  0.98754925]
 [ 0.70287424 -0.71049786  0.0340678 ]]
transform [[ 0.69878525  0.69865113  0.15357693]
 [-0.13291758 -0.08413919  0.98754925]
 [ 0.70287424 -0.71049786  0.0340678 ]]
support
[0.18707684 1.20296455 0.04149905]
[ -20.62512256 -220.15286183  -69.52387207]
[-233.19298148   32.71471462  259.1618302 ]
[-1.50505387 -9.6779826  -0.33386446]
v_real [ 0.9288749  -0.4961383  -0.18891971]
zmp_s [        0.         -11788235.02911508  -4488734.52732673]
transform [[ 0.69878525 -0.13291758  0.70287424]
 [ 0.69865113 -0.08413919 -0.71049786]
 [ 0.15357693  0.98754925  0.0340678 ]]
zmp [ -1588152.17631408   4181088.81256783 -11794383.92679595]
d1:24235298.82047, d2:0.05940, d3:9355687.22287
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-169.92935307069794 steps:288[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.33297604  0.38158983 -0.86227381]
 [ 0.6464783   0.57331872  0.50336027]
 [ 0.68643492 -0.72504818 -0.05578816]]
planes
[[ 0.33297604  0.38158983 -0.86227381]
 [ 0.6464783   0.57331872  0.50336027]
 [ 0.68643492 -0.72504818 -0.05578816]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-643.98254  226.01341  590.8773 ]
[ -3.17239028 -57.79803512  12.95225263]
[ 0.   0.  -9.8]
transform [[ 0.33297604  0.38158983 -0.86227381]
 [ 0.6464783   0.57331872  0.50336027]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.33297604  0.38158983 -0.86227381]
 [ 0.6464783   0.57331872  0.50336027]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.33297604  0.38158983 -0.86227381]
 [ 0.6464783   0.57331872  0.50336027]
 [ 0.68643492 -0.72504818 -0.05578816]]
support
[-1.05036263  0.61315885 -0.0679573 ]
[-637.6843785    10.68115094 -638.88668362]
[-34.27986061 -28.66792757  39.00613856]
[ 8.45028336 -4.93293066  0.546724  ]
v_real [-0.40951157 -0.20874423  0.45333752]
zmp_s [       0.         -4959762.33444662 10771300.04316553]
transform [[ 0.33297604  0.6464783   0.68643492]
 [ 0.38158983  0.57331872 -0.72504818]
 [-0.86227381  0.50336027 -0.05578816]]
zmp [  4187417.83380502 -10653236.13228327  -3097458.35857464]
d1:15061144.96843, d2:0.05940, d3:6833514.57859
eta 23760000.0
transform [[ 0.18284008  0.24633662 -0.95178139]
 [ 0.70383     0.64313561  0.30166191]
 [ 0.68643492 -0.72504818 -0.05578816]]
planes
[[ 0.18284008  0.24633662 -0.95178139]
 [ 0.70383     0.64313561  0.30166191]
 [ 0.68643492 -0.72504818 -0.05578816]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-643.98254  226.01341  590.8773 ]
[ -3.17239028 -57.79803512  12.95225263]
[ 0.   0.  -9.8]
transform [[ 0.18284008  0.24633662 -0.95178139]
 [ 0.70383     0.64313561  0.30166191]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.18284008  0.24633662 -0.95178139]
 [ 0.70383     0.64313561  0.30166191]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.18284008  0.24633662 -0.95178139]
 [ 0.70383     0.64313561  0.30166191]
 [ 0.68643492 -0.72504818 -0.05578816]]
support
[-1.15939461  0.36746378 -0.0679573 ]
[-624.4564758  -129.65178312 -638.88668362]
[-27.14552598 -35.49759663  39.00613856]
[ 9.32745764 -2.9562867   0.546724  ]
v_real [-0.40951157 -0.20874423  0.45333752]
zmp_s [       0.         -4959762.31918534 10771300.19289283]
transform [[ 0.18284008  0.70383     0.68643492]
 [ 0.24633662  0.64313561 -0.72504818]
 [-0.95178139  0.30166191 -0.05578816]]
zmp [  3902967.10412557 -10999511.39935685  -2097082.41945351]
d1:14534444.78222, d2:0.05940, d3:6231594.43788
eta 23760000.0
transform [[ 0.30437297  0.21679339  0.92755473]
 [-0.66042733 -0.65368629  0.36949959]
 [ 0.68643492 -0.72504818 -0.05578816]]
planes
[[ 0.30437297  0.21679339  0.92755473]
 [-0.66042733 -0.65368629  0.36949959]
 [ 0.68643492 -0.72504818 -0.05578816]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-643.98254  226.01341  590.8773 ]
[ -3.17239028 -57.79803512  12.95225263]
[ 0.   0.  -9.8]
transform [[ 0.30437297  0.21679339  0.92755473]
 [-0.66042733 -0.65368629  0.36949959]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.30437297  0.21679339  0.92755473]
 [-0.66042733 -0.65368629  0.36949959]
 [ 0.68643492 -0.72504818 -0.05578816]]
transform [[ 0.30437297  0.21679339  0.92755473]
 [-0.66042733 -0.65368629  0.36949959]
 [ 0.68643492 -0.72504818 -0.05578816]]
support
[ 1.12988335  0.45009898 -0.0679573 ]
[ 401.0583867   495.89073492 -638.88668362]
[-1.48189855 44.6627682  39.00613856]
[-9.09003632 -3.62109602  0.546724  ]
v_real [-0.40951157 -0.20874423  0.45333752]
zmp_s [       0.         -4959764.06842517 10771300.88605878]
transform [[ 0.30437297 -0.66042733  0.68643492]
 [ 0.21679339 -0.65368629 -0.72504818]
 [ 0.92755473  0.36949959 -0.05578816]]
zmp [10669360.86227743 -4567582.40254823 -2433541.90007021]
d1:14326152.87368, d2:0.05940, d3:6251068.98171
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-687.738331930139 steps:292[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.30314022  0.31815282 -0.89826769]
 [ 0.61188287  0.65765208  0.43942377]
 [ 0.73055148 -0.6828416   0.00468856]]
planes
[[ 0.30314022  0.31815282 -0.89826769]
 [ 0.61188287  0.65765208  0.43942377]
 [ 0.73055148 -0.6828416   0.00468856]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-438.961   -233.97398 -302.21454]
[  75.33935582 -149.08234652  -43.55757334]
[ 0.   0.  -9.8]
transform [[ 0.30314022  0.31815282 -0.89826769]
 [ 0.61188287  0.65765208  0.43942377]
 [ 0.73055148 -0.6828416   0.00468856]]
transform [[ 0.30314022  0.31815282 -0.89826769]
 [ 0.61188287  0.65765208  0.43942377]
 [ 0.73055148 -0.6828416   0.00468856]]
transform [[ 0.30314022  0.31815282 -0.89826769]
 [ 0.61188287  0.65765208  0.43942377]
 [ 0.73055148 -0.6828416   0.00468856]]
support
[-1.09420789  0.5352758   0.00571128]
[  63.96333776 -555.2664425  -162.33338978]
[ 14.53378153 -71.08568745 156.63468353]
[ 8.80302333 -4.30635294 -0.0459479 ]
v_real [-0.49196848 -0.4250108  -0.3974042 ]
zmp_s [        0.         -10098267.03174504  -9442327.41293488]
transform [[ 0.30314022  0.61188287  0.73055148]
 [ 0.31815282  0.65765208 -0.6828416 ]
 [-0.89826769  0.43942377  0.00468856]]
zmp [-13077062.84518883   -193532.36960616  -4481689.49435744]
d1:17139137.80460, d2:0.05940, d3:7522612.12652
eta 23760000.0
transform [[ 0.89227766  0.25286946  0.37402889]
 [-0.21071783 -0.49943259  0.84033632]
 [ 0.39929765 -0.82862788 -0.39234844]]
planes
[[ 0.89227766  0.25286946  0.37402889]
 [-0.21071783 -0.49943259  0.84033632]
 [ 0.39929765 -0.82862788 -0.39234844]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-468.5597  -460.09338 -142.86116]
[  75.33935582 -149.08234652  -43.55757334]
[ 0.   0.  -9.8]
transform [[ 0.89227766  0.25286946  0.37402889]
 [-0.21071783 -0.49943259  0.84033632]
 [ 0.39929765 -0.82862788 -0.39234844]]
transform [[ 0.89227766  0.25286946  0.37402889]
 [-0.21071783 -0.49943259  0.84033632]
 [ 0.39929765 -0.82862788 -0.39234844]]
transform [[ 0.89227766  0.25286946  0.37402889]
 [-0.21071783 -0.49943259  0.84033632]
 [ 0.39929765 -0.82862788 -0.39234844]]
support
[ 0.45561626  1.02363989 -0.47793187]
[-587.86311047  208.4680901   250.20277417]
[ 13.23346108  21.97822662 170.70636336]
[-3.66548313 -8.23529596  3.8450147 ]
v_real [-0.71666014 -0.21871512  0.29579782]
zmp_s [       0.         -5196669.53354858  7028156.18058976]
transform [[ 0.89227766 -0.21071783  0.39929765]
 [ 0.25286946 -0.49943259 -0.82862788]
 [ 0.37402889  0.84033632 -0.39234844]]
zmp [ 3901357.19144499 -3228340.04393089 -7124436.26954612]
d1:14165246.50171, d2:0.05940, d3:5640633.07137
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-467.26441747393505 steps:295[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.68120438  0.72837549 -0.07368752]
 [ 0.08228347  0.02384041  0.99632376]
 [ 0.72745454 -0.68476337 -0.04369307]]
planes
[[ 0.68120438  0.72837549 -0.07368752]
 [ 0.08228347  0.02384041  0.99632376]
 [ 0.72745454 -0.68476337 -0.04369307]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 444.35266 1304.8585   784.73236]
[ -38.70704311 -176.14303411   14.2809168 ]
[ 0.   0.  -9.8]
transform [[ 0.68120438  0.72837549 -0.07368752]
 [ 0.08228347  0.02384041  0.99632376]
 [ 0.72745454 -0.68476337 -0.04369307]]
transform [[ 0.68120438  0.72837549 -0.07368752]
 [ 0.08228347  0.02384041  0.99632376]
 [ 0.72745454 -0.68476337 -0.04369307]]
transform [[ 0.68120438  0.72837549 -0.07368752]
 [ 0.08228347  0.02384041  0.99632376]
 [ 0.72745454 -0.68476337 -0.04369307]]
support
[-0.08976106  1.21365306 -0.05322389]
[1195.29696999  849.51873295 -604.56032381]
[-155.7180021     6.8441458    91.83470653]
[ 0.72213766 -9.76397289  0.42819208]
v_real [0.477895   0.17373145 0.06142534]
zmp_s [      0.         4127860.44989289 1459466.03215852]
transform [[ 0.68120438  0.08228347  0.72745454]
 [ 0.72837549  0.02384041 -0.68476337]
 [-0.07368752  0.99632376 -0.04369307]]
zmp [1401349.86494764 -900979.01631653 4048916.911458  ]
d1:8394681.08425, d2:0.05940, d3:3308034.40679
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-244.7893740824909 steps:297[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 4.04749922e-02 -2.59489141e-04 -9.99180555e-01]
 [ 9.99150872e-01  7.71661568e-03  4.04717922e-02]
 [ 7.69978995e-03 -9.99970198e-01  5.71598765e-04]]
planes
[[ 4.04749922e-02 -2.59489141e-04 -9.99180555e-01]
 [ 9.99150872e-01  7.71661568e-03  4.04717922e-02]
 [ 7.69978995e-03 -9.99970198e-01  5.71598765e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 444.35266 1304.8585   784.73236]
[ -38.70704311 -176.14303411   14.2809168 ]
[ 0.   0.  -9.8]
transform [[ 4.04749922e-02 -2.59489141e-04 -9.99180555e-01]
 [ 9.99150872e-01  7.71661568e-03  4.04717922e-02]
 [ 7.69978995e-03 -9.99970198e-01  5.71598765e-04]]
transform [[ 4.04749922e-02 -2.59489141e-04 -9.99180555e-01]
 [ 9.99150872e-01  7.71661568e-03  4.04717922e-02]
 [ 7.69978995e-03 -9.99970198e-01  5.71598765e-04]]
transform [[ 4.04749922e-02 -2.59489141e-04 -9.99180555e-01]
 [ 9.99150872e-01  7.71661568e-03  4.04717922e-02]
 [ 7.69978995e-03 -9.99970198e-01  5.71598765e-04]]
support
[-1.21713301e+00  4.92999528e-02  6.96282289e-04]
[ -766.4427422    485.80396573 -1300.94965849]
[-15.79017444 -39.45542968 175.84791149]
[ 9.79196944e+00 -3.96623564e-01 -5.60166789e-03]
v_real [-0.08541967  0.7843399  -0.13706441]
zmp_s [       0.         18635915.5008866  -3256648.35446877]
transform [[ 4.04749922e-02  9.99150872e-01  7.69978995e-03]
 [-2.59489141e-04  7.71661568e-03 -9.99970198e-01]
 [-9.99180555e-01  4.04717922e-02  5.71598765e-04]]
zmp [18595015.71927104  3400357.49663061   752367.40382543]
d1:14543621.48696, d2:0.05940, d3:9703068.01869
eta 23760000.0
transform [[ 0.0484014   0.00893524 -0.998788  ]
 [ 0.62464631 -0.78056055  0.02328749]
 [-0.77940643 -0.62501639 -0.04336159]]
planes
[[ 0.0484014   0.00893524 -0.998788  ]
 [ 0.62464631 -0.78056055  0.02328749]
 [-0.77940643 -0.62501639 -0.04336159]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-626.6137   541.93427  215.64684]
[-10.93695003 -30.59784799   5.82126656]
[ 0.   0.  -9.8]
transform [[ 0.0484014   0.00893524 -0.998788  ]
 [ 0.62464631 -0.78056055  0.02328749]
 [-0.77940643 -0.62501639 -0.04336159]]
transform [[ 0.0484014   0.00893524 -0.998788  ]
 [ 0.62464631 -0.78056055  0.02328749]
 [-0.77940643 -0.62501639 -0.04336159]]
transform [[ 0.0484014   0.00893524 -0.998788  ]
 [ 0.62464631 -0.78056055  0.02328749]
 [-0.77940643 -0.62501639 -0.04336159]]
support
[-1.21665482  0.02836721 -0.0528201 ]
[-240.87213994 -809.40257533  140.31816427]
[-6.61697396 17.18731038 27.39606632]
[ 9.78812239 -0.22821737  0.42494358]
v_real [ 0.13517554  0.18328404 -0.7699141 ]
zmp_s [        0.           4354833.40961905 -18293158.86820792]
transform [[ 0.0484014   0.62464631 -0.77940643]
 [ 0.00893524 -0.78056055 -0.62501639]
 [-0.998788    0.02328749 -0.04336159]]
zmp [16978036.21920201  8034312.96611302   894633.56537236]
d1:25055782.19310, d2:0.05940, d3:8443255.94365
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-423.92079865569974 steps:300[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.17754051  0.16809575  0.9696511 ]
 [-0.68849874 -0.68280512  0.24443129]
 [ 0.7031706  -0.71100003 -0.00549183]]
planes
[[ 0.17754051  0.16809575  0.9696511 ]
 [-0.68849874 -0.68280512  0.24443129]
 [ 0.7031706  -0.71100003 -0.00549183]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 182.77267  423.76102 -513.3175 ]
[ 102.15136445 -319.7726717   -71.53762276]
[ 0.   0.  -9.8]
transform [[ 0.17754051  0.16809575  0.9696511 ]
 [-0.68849874 -0.68280512  0.24443129]
 [ 0.7031706  -0.71100003 -0.00549183]]
transform [[ 0.17754051  0.16809575  0.9696511 ]
 [-0.68849874 -0.68280512  0.24443129]
 [ 0.7031706  -0.71100003 -0.00549183]]
transform [[ 0.17754051  0.16809575  0.9696511 ]
 [-0.68849874 -0.68280512  0.24443129]
 [ 0.7031706  -0.71100003 -0.00549183]]
support
[ 1.18116226  0.29774938 -0.00668977]
[-394.05690374 -540.65580605 -169.9546707 ]
[-104.9829573   130.52529933  299.58108606]
[-9.50258081 -2.39542661  0.05381993]
v_real [-0.31700456 -0.08598018  0.1797012 ]
zmp_s [       0.         -2042889.67433897  4269699.67259907]
transform [[ 0.17754051 -0.68849874  0.7031706 ]
 [ 0.16809575 -0.68280512 -0.71100003]
 [ 0.9696511   0.24443129 -0.00549183]]
zmp [ 4408854.22755542 -1640861.0439591   -522794.61492132]
d1:5477741.92195, d2:0.05940, d3:2151201.56973
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-228.96029718826037 steps:302[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.1601401   0.09610726  0.98240453]
 [-0.69749236 -0.69322228  0.18151401]
 [ 0.69846946 -0.71428734 -0.04397859]]
planes
[[ 0.1601401   0.09610726  0.98240453]
 [-0.69749236 -0.69322228  0.18151401]
 [ 0.69846946 -0.71428734 -0.04397859]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[463.40848 274.74255 478.17197]
[ -44.47984259 -150.15097343   21.48769999]
[ 0.   0.  -9.8]
transform [[ 0.1601401   0.09610726  0.98240453]
 [-0.69749236 -0.69322228  0.18151401]
 [ 0.69846946 -0.71428734 -0.04397859]]
transform [[ 0.1601401   0.09610726  0.98240453]
 [-0.69749236 -0.69322228  0.18151401]
 [ 0.69846946 -0.71428734 -0.04397859]]
transform [[ 0.1601401   0.09610726  0.98240453]
 [-0.69749236 -0.69322228  0.18151401]
 [ 0.69846946 -0.71428734 -0.04397859]]
support
[ 1.19669761  0.22110788 -0.0535717 ]
[ 570.37333861 -426.88662295  106.40221029]
[ -0.44399105 139.01266981  75.23812903]
[-9.62756439 -1.7788373   0.43099022]
v_real [ 0.33828732 -1.3260515   0.18169884]
zmp_s [        0.         -31506982.99824459   4317164.46634042]
transform [[ 0.1601401  -0.69749236  0.69846946]
 [ 0.09610726 -0.69322228 -0.71428734]
 [ 0.98240453  0.18151401 -0.04397859]]
zmp [24991287.49517925 18757646.80020831 -5908821.64610987]
d1:46205159.85254, d2:0.05940, d3:5743437.01588
eta 23760000.0
transform [[ 0.7029354   0.6963011  -0.14507481]
 [ 0.13424745  0.07041622  0.98844284]
 [ 0.69846946 -0.71428734 -0.04397859]]
planes
[[ 0.7029354   0.6963011  -0.14507481]
 [ 0.13424745  0.07041622  0.98844284]
 [ 0.69846946 -0.71428734 -0.04397859]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[463.40848 274.74255 478.17197]
[ -44.47984259 -150.15097343   21.48769999]
[ 0.   0.  -9.8]
transform [[ 0.7029354   0.6963011  -0.14507481]
 [ 0.13424745  0.07041622  0.98844284]
 [ 0.69846946 -0.71428734 -0.04397859]]
transform [[ 0.7029354   0.6963011  -0.14507481]
 [ 0.13424745  0.07041622  0.98844284]
 [ 0.69846946 -0.71428734 -0.04397859]]
transform [[ 0.7029354   0.6963011  -0.14507481]
 [ 0.13424745  0.07041622  0.98844284]
 [ 0.69846946 -0.71428734 -0.04397859]]
support
[-0.17672016  1.20405306 -0.0535717 ]
[447.67905631 554.20339513 106.40221029]
[-138.93406829    4.69499372   75.23812903]
[ 1.42173318 -9.68673981  0.43099022]
v_real [ 0.33828732 -1.3260515   0.18169884]
zmp_s [        0.         -31506982.74921146   4317164.49892114]
transform [[ 0.7029354   0.13424745  0.69846946]
 [ 0.6963011   0.07041622 -0.71428734]
 [-0.14507481  0.98844284 -0.04397859]]
zmp [ -1214324.59860199  -5302298.56311905 -31332714.27727713]
d1:62505490.12245, d2:0.05940, d3:21240863.59247
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-85.13425094836238 steps:305[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.17657556  0.15529944  0.97195846]
 [-0.68369961 -0.69102025  0.23461877]
 [ 0.70807904 -0.70595551 -0.01583912]]
planes
[[ 0.17657556  0.15529944  0.97195846]
 [-0.68369961 -0.69102025  0.23461877]
 [ 0.70807904 -0.70595551 -0.01583912]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 329.29633  639.8257  1089.8894 ]
[  51.4454786  -400.19848095    3.35625746]
[ 0.   0.  -9.8]
transform [[ 0.17657556  0.15529944  0.97195846]
 [-0.68369961 -0.69102025  0.23461877]
 [ 0.70807904 -0.70595551 -0.01583912]]
transform [[ 0.17657556  0.15529944  0.97195846]
 [-0.68369961 -0.69102025  0.23461877]
 [ 0.70807904 -0.70595551 -0.01583912]]
transform [[ 0.17657556  0.15529944  0.97195846]
 [-0.68369961 -0.69102025  0.23461877]
 [ 0.70807904 -0.70595551 -0.01583912]]
support
[ 1.18397292  0.28579644 -0.01929412]
[1216.83747756 -411.56376338 -235.78352507]
[-49.80444315 242.15944193 318.89662581]
[-9.52519289 -2.29926393  0.15522336]
v_real [-0.08941473 -0.07493527 -0.19166087]
zmp_s [       0.         -1780461.69747884 -4553861.58764361]
transform [[ 0.17657556 -0.68369961  0.70807904]
 [ 0.15529944 -0.69102025 -0.70595551]
 [ 0.97195846  0.23461877 -0.01583912]]
zmp [-2007192.9771449   4445158.74637273  -345600.57673751]
d1:6174141.42881, d2:0.05940, d3:2235875.59332
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-220.5267273890031 steps:307[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.51198328  0.50969929 -0.69143319]
 [ 0.48807171  0.48976505  0.72243774]
 [ 0.70686573 -0.70734501  0.00198174]]
planes
[[ 0.51198328  0.50969929 -0.69143319]
 [ 0.48807171  0.48976505  0.72243774]
 [ 0.70686573 -0.70734501  0.00198174]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-597.1626   378.5297  -106.04043]
[ -54.33281774 -205.84250786   68.73510965]
[ 0.   0.  -9.8]
transform [[ 0.51198328  0.50969929 -0.69143319]
 [ 0.48807171  0.48976505  0.72243774]
 [ 0.70686573 -0.70734501  0.00198174]]
transform [[ 0.51198328  0.50969929 -0.69143319]
 [ 0.48807171  0.48976505  0.72243774]
 [ 0.70686573 -0.70734501  0.00198174]]
transform [[ 0.51198328  0.50969929 -0.69143319]
 [ 0.48807171  0.48976505  0.72243774]
 [ 0.70686573 -0.70734501  0.00198174]]
support
[-0.84225634  0.88002395  0.00241401]
[ -39.48107686 -182.67516375 -690.07500787]
[-180.2610093   -77.67593978  107.33187862]
[ 6.77604527 -7.07988985 -0.01942101]
v_real [ 0.3675808   0.6323186  -0.00421304]
zmp_s [       0.         15023899.04862258  -100081.70983628]
transform [[ 0.51198328  0.48807171  0.70686573]
 [ 0.50969929  0.48976505 -0.70734501]
 [-0.69143319  0.72243774  0.00198174]]
zmp [ 7261995.76692186  7428972.93703189 10853633.32972373]
d1:25755599.91002, d2:0.05940, d3:6853246.29885
eta 23760000.0
transform [[ 0.27926862  0.27650309 -0.9195407 ]
 [ 0.64988458  0.65054524  0.39298981]
 [ 0.70686573 -0.70734501  0.00198174]]
planes
[[ 0.27926862  0.27650309 -0.9195407 ]
 [ 0.64988458  0.65054524  0.39298981]
 [ 0.70686573 -0.70734501  0.00198174]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-597.1626   378.5297  -106.04043]
[ -54.33281774 -205.84250786   68.73510965]
[ 0.   0.  -9.8]
transform [[ 0.27926862  0.27650309 -0.9195407 ]
 [ 0.64988458  0.65054524  0.39298981]
 [ 0.70686573 -0.70734501  0.00198174]]
transform [[ 0.27926862  0.27650309 -0.9195407 ]
 [ 0.64988458  0.65054524  0.39298981]
 [ 0.70686573 -0.70734501  0.00198174]]
transform [[ 0.27926862  0.27650309 -0.9195407 ]
 [ 0.64988458  0.65054524  0.39298981]
 [ 0.70686573 -0.70734501  0.00198174]]
support
[-1.12012122  0.47871315  0.00241401]
[  35.40434235 -183.50888291 -690.07500787]
[-135.2942709  -142.20772611  107.33187862]
[ 9.01149889 -3.85130018 -0.01942101]
v_real [ 0.3675808   0.6323186  -0.00421304]
zmp_s [       0.         15023883.33716215  -100122.46215756]
transform [[ 0.27926862  0.64988458  0.70686573]
 [ 0.27650309  0.65054524 -0.70734501]
 [-0.9195407   0.39298981  0.00198174]]
zmp [9693016.99897359 9844536.90690213 5904034.70617727]
d1:22892089.35313, d2:0.05940, d3:3708523.18375
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-434.5626996599751 steps:310[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-58.24609874998861 steps:311[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.04676257 -0.01596622 -0.99877846]
 [ 0.9988476   0.01156603  0.04658091]
 [ 0.01080818 -0.99980563  0.01648868]]
planes
[[ 0.04676257 -0.01596622 -0.99877846]
 [ 0.9988476   0.01156603  0.04658091]
 [ 0.01080818 -0.99980563  0.01648868]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-597.1626   378.5297  -106.04043]
[ -54.33281774 -205.84250786   68.73510965]
[ 0.   0.  -9.8]
transform [[ 0.04676257 -0.01596622 -0.99877846]
 [ 0.9988476   0.01156603  0.04658091]
 [ 0.01080818 -0.99980563  0.01648868]]
transform [[ 0.04676257 -0.01596622 -0.99877846]
 [ 0.9988476   0.01156603  0.04658091]
 [ 0.01080818 -0.99980563  0.01648868]]
transform [[ 0.04676257 -0.01596622 -0.99877846]
 [ 0.9988476   0.01156603  0.04658091]
 [ 0.01080818 -0.99980563  0.01648868]]
support
[-1.21664321  0.05674166  0.02008538]
[  71.94235009 -597.03580478 -386.65882413]
[-67.90536166 -53.44924082 206.34861082]
[ 9.78802893 -0.45649292 -0.16158909]
v_real [-0.25623488 -0.32576802 -0.47667575]
zmp_s [        0.          -7740259.36231166 -11325822.39211624]
transform [[ 0.04676257  0.9988476   0.01080818]
 [-0.01596622  0.01156603 -0.99980563]
 [-0.99877846  0.04658091  0.01648868]]
zmp [-7853751.00266699 11234096.93426713  -547296.21924998]
d1:13434337.28295, d2:0.05940, d3:3898037.20072
eta 23760000.0
transform [[ 0.82030374 -0.57160002  0.01937297]
 [-0.03901466 -0.02213155  0.99899352]
 [-0.57059592 -0.82023394 -0.04045537]]
planes
[[ 0.82030374 -0.57160002  0.01937297]
 [-0.03901466 -0.02213155  0.99899352]
 [-0.57059592 -0.82023394 -0.04045537]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 24.00709   86.470856 721.8333  ]
[0. 0. 0.]
[ 0.   0.  -9.8]
transform [[ 0.82030374 -0.57160002  0.01937297]
 [-0.03901466 -0.02213155  0.99899352]
 [-0.57059592 -0.82023394 -0.04045537]]
transform [[ 0.82030374 -0.57160002  0.01937297]
 [-0.03901466 -0.02213155  0.99899352]
 [-0.57059592 -0.82023394 -0.04045537]]
transform [[ 0.82030374 -0.57160002  0.01937297]
 [-0.03901466 -0.02213155  0.99899352]
 [-0.57059592 -0.82023394 -0.04045537]]
support
[ 0.02359882  1.21690517 -0.04927995]
[ -15.74957979  718.25643637 -113.82671543]
[0. 0. 0.]
[-0.18985514 -9.79013646  0.39646267]
v_real [-2.3566468   0.04713165 -0.54186237]
zmp_s [        0.           1119850.39081131 -12874650.21721693]
transform [[ 0.82030374 -0.03901466 -0.57059592]
 [-0.57160002 -0.02213155 -0.82023394]
 [ 0.01937297  0.99899352 -0.04045537]]
zmp [ 7302532.30442809 10535441.05739865  1639572.08009056]
d1:18337141.04949, d2:0.05940, d3:6709946.08849
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-356.7756041083402 steps:314[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.68450266  0.70639074  0.18018982]
 [-0.11580799 -0.13866803  0.98354447]
 [ 0.71975327 -0.69410622 -0.01311295]]
planes
[[ 0.68450266  0.70639074  0.18018982]
 [-0.11580799 -0.13866803  0.98354447]
 [ 0.71975327 -0.69410622 -0.01311295]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  96.902176 -456.92642   469.93604 ]
[  15.72026859 -350.39761115  -12.59466523]
[ 0.   0.  -9.8]
transform [[ 0.68450266  0.70639074  0.18018982]
 [-0.11580799 -0.13866803  0.98354447]
 [ 0.71975327 -0.69410622 -0.01311295]]
transform [[ 0.68450266  0.70639074  0.18018982]
 [-0.11580799 -0.13866803  0.98354447]
 [ 0.71975327 -0.69410622 -0.01311295]]
transform [[ 0.68450266  0.70639074  0.18018982]
 [-0.11580799 -0.13866803  0.98354447]
 [ 0.71975327 -0.69410622 -0.01311295]]
support
[ 0.21949484  1.1980862  -0.01597329]
[-171.76110676  514.34202914  380.73888152]
[-239.02649206   34.38100063  254.69302968]
[-1.76586022 -9.6387358   0.12850692]
v_real [-0.63940114 -0.22835946  0.339093  ]
zmp_s [       0.         -5425817.69576969  8056849.76765654]
transform [[ 0.68450266 -0.11580799  0.71975327]
 [ 0.70639074 -0.13866803 -0.69410622]
 [ 0.18018982  0.98354447 -0.01311295]]
zmp [ 6427296.95819695 -4839922.09326974 -5442182.06060607]
d1:14828199.93547, d2:0.05940, d3:7050693.73164
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-369.45801382864886 steps:316[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69124413  0.65980804 -0.29467764]
 [ 0.21577649  0.20072013  0.95558989]
 [ 0.68965364 -0.72413039 -0.00362446]]
planes
[[ 0.69124413  0.65980804 -0.29467764]
 [ 0.21577649  0.20072013  0.95558989]
 [ 0.68965364 -0.72413039 -0.00362446]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 827.72736 -620.51636 1446.5128 ]
[ 121.34214577 -529.76546398  -66.21806292]
[ 0.   0.  -9.8]
transform [[ 0.69124413  0.65980804 -0.29467764]
 [ 0.21577649  0.20072013  0.95558989]
 [ 0.68965364 -0.72413039 -0.00362446]]
transform [[ 0.69124413  0.65980804 -0.29467764]
 [ 0.21577649  0.20072013  0.95558989]
 [ 0.68965364 -0.72413039 -0.00362446]]
transform [[ 0.69124413  0.65980804 -0.29467764]
 [ 0.21577649  0.20072013  0.95558989]
 [ 0.68965364 -0.72413039 -0.00362446]]
support
[-0.35895603  1.16403386 -0.00441506]
[-263.5149996  1436.32700199 1014.93711063]
[-246.15348402 -143.42912295  467.54332953]
[ 2.88784092 -9.36478093  0.03551967]
v_real [-0.2055623 -1.0814544  0.616587 ]
zmp_s [        0.         -25695355.00737333  14650106.14800855]
transform [[ 0.69124413  0.21577649  0.68965364]
 [ 0.65980804  0.20072013 -0.72413039]
 [-0.29467764  0.95558989 -0.00362446]]
zmp [  4559045.49232051 -15766162.14227061 -24607320.14592991]
d1:53295498.20428, d2:0.05940, d3:22015731.59567
eta 23760000.0
transform [[ 0.09593648  0.07883545  0.99226063]
 [-0.47402763  0.88018012 -0.02409937]
 [-0.87526798 -0.46804693  0.12181156]]
planes
[[ 0.09593648  0.07883545  0.99226063]
 [-0.47402763  0.88018012 -0.02409937]
 [-0.87526798 -0.46804693  0.12181156]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-343.0206    801.4636   -119.481705]
[-56.92808203 151.84721646  61.05506677]
[ 0.   0.  -9.8]
transform [[ 0.09593648  0.07883545  0.99226063]
 [-0.47402763  0.88018012 -0.02409937]
 [-0.87526798 -0.46804693  0.12181156]]
transform [[ 0.09593648  0.07883545  0.99226063]
 [-0.47402763  0.88018012 -0.02409937]
 [-0.87526798 -0.46804693  0.12181156]]
transform [[ 0.09593648  0.07883545  0.99226063]
 [-0.47402763  0.88018012 -0.02409937]
 [-0.87526798 -0.46804693  0.12181156]]
support
[ 1.20870364 -0.02935619  0.14838246]
[-88.28143461 870.91302494 -89.44189605]
[ 67.09200333 159.16699673 -13.8070835 ]
[-9.72415422  0.23617381 -1.1937533 ]
v_real [0.68854994 0.3588773  0.1109634 ]
zmp_s [      0.         8526935.57365262 2636487.65651193]
transform [[ 0.09593648 -0.47402763 -0.87526798]
 [ 0.07883545  0.88018012 -0.46804693]
 [ 0.99226063 -0.02409937  0.12181156]]
zmp [-6349636.32436574  6271239.21783117   115660.91431689]
d1:2731034.12416, d2:0.05940, d3:175840.80595
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-245.73651626254969 steps:319[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.70152843 -0.71215576  0.0263069 ]
 [ 0.03490897  0.07121149  0.99685019]
 [-0.71178597 -0.69840038  0.0748175 ]]
planes
[[ 0.70152843 -0.71215576  0.0263069 ]
 [ 0.03490897  0.07121149  0.99685019]
 [-0.71178597 -0.69840038  0.0748175 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-343.0206    801.4636   -119.481705]
[-56.92808203 151.84721646  61.05506677]
[ 0.   0.  -9.8]
transform [[ 0.70152843 -0.71215576  0.0263069 ]
 [ 0.03490897  0.07121149  0.99685019]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.70152843 -0.71215576  0.0263069 ]
 [ 0.03490897  0.07121149  0.99685019]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.70152843 -0.71215576  0.0263069 ]
 [ 0.03490897  0.07121149  0.99685019]
 [-0.71178597 -0.69840038  0.0748175 ]]
support
[0.03204525 1.21429432 0.09113753]
[-814.54883075  -74.00643341 -324.52456926]
[-146.46936825   69.68872163  -60.96155568]
[-0.25780761 -9.76913189 -0.73321151]
v_real [-0.43382782 -0.09606426 -0.1248414 ]
zmp_s [       0.         -2282485.61381767 -2966231.75718235]
transform [[ 0.70152843  0.03490897 -0.71178597]
 [-0.71215576  0.07121149 -0.69840038]
 [ 0.0263069   0.99685019  0.0748175 ]]
zmp [ 2031642.93538081  1909078.16937874 -2497222.27110401]
d1:6215436.25200, d2:0.05940, d3:2841791.48446
eta 23760000.0
transform [[ 0.23976001 -0.14146301  0.96047038]
 [-0.66020894  0.70158762  0.26813987]
 [-0.71178597 -0.69840038  0.0748175 ]]
planes
[[ 0.23976001 -0.14146301  0.96047038]
 [-0.66020894  0.70158762  0.26813987]
 [-0.71178597 -0.69840038  0.0748175 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-343.0206    801.4636   -119.481705]
[-56.92808203 151.84721646  61.05506677]
[ 0.   0.  -9.8]
transform [[ 0.23976001 -0.14146301  0.96047038]
 [-0.66020894  0.70158762  0.26813987]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.23976001 -0.14146301  0.96047038]
 [-0.66020894  0.70158762  0.26813987]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.23976001 -0.14146301  0.96047038]
 [-0.66020894  0.70158762  0.26813987]
 [-0.71178597 -0.69840038  0.0748175 ]]
support
[1.16997893 0.32662954 0.09113753]
[-310.37871869  756.72441156 -324.52456926]
[ 23.51174095 160.48985313 -60.96155568]
[-9.41260971 -2.62777072 -0.73321151]
v_real [-0.43382782 -0.09606426 -0.1248414 ]
zmp_s [       0.         -2282483.85508434 -2966233.35069885]
transform [[ 0.23976001 -0.66020894 -0.71178597]
 [-0.14146301  0.70158762 -0.69840038]
 [ 0.96047038  0.26813987  0.0748175 ]]
zmp [3618239.53674438  470256.08440187 -833951.08854654]
d1:4605340.74795, d2:0.05940, d3:1878535.24631
eta 23760000.0
transform [[ 0.02637184  0.07987005  0.99645638]
 [-0.7019012   0.71123677 -0.03843229]
 [-0.71178597 -0.69840038  0.0748175 ]]
planes
[[ 0.02637184  0.07987005  0.99645638]
 [-0.7019012   0.71123677 -0.03843229]
 [-0.71178597 -0.69840038  0.0748175 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-343.0206    801.4636   -119.481705]
[-56.92808203 151.84721646  61.05506677]
[ 0.   0.  -9.8]
transform [[ 0.02637184  0.07987005  0.99645638]
 [-0.7019012   0.71123677 -0.03843229]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.02637184  0.07987005  0.99645638]
 [-0.7019012   0.71123677 -0.03843229]
 [-0.71178597 -0.69840038  0.0748175 ]]
transform [[ 0.02637184  0.07987005  0.99645638]
 [-0.7019012   0.71123677 -0.03843229]
 [-0.71178597 -0.69840038  0.0748175 ]]
support
[ 1.21381461 -0.04681557  0.09113753]
[ -64.09144897  815.38892686 -324.52456926]
[ 71.46545819 145.61072772 -60.96155568]
[-9.76527257  0.37663639 -0.73321151]
v_real [-0.43382782 -0.09606426 -0.1248414 ]
zmp_s [       0.         -2282474.21533909 -2966238.97591315]
transform [[ 0.02637184 -0.7019012  -0.71178597]
 [ 0.07987005  0.71123677 -0.69840038]
 [ 0.99645638 -0.03843229  0.0748175 ]]
zmp [3713398.67786329  448242.82293104 -134205.88758998]
d1:4346275.16750, d2:0.05940, d3:1458802.57899
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-818.8864985360799 steps:323[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.69384211  0.70641184  0.13987702]
 [-0.11800032 -0.08008604  0.98977888]
 [ 0.71039367 -0.70325577  0.02778975]]
planes
[[ 0.69384211  0.70641184  0.13987702]
 [-0.11800032 -0.08008604  0.98977888]
 [ 0.71039367 -0.70325577  0.02778975]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-788.5191  -494.9935    26.50429]
[  36.19514382 -337.17751461 -104.58841649]
[ 0.   0.  -9.8]
transform [[ 0.69384211  0.70641184  0.13987702]
 [-0.11800032 -0.08008604  0.98977888]
 [ 0.71039367 -0.70325577  0.02778975]]
transform [[ 0.69384211  0.70641184  0.13987702]
 [-0.11800032 -0.08008604  0.98977888]
 [ 0.71039367 -0.70325577  0.02778975]]
transform [[ 0.69384211  0.70641184  0.13987702]
 [-0.11800032 -0.08008604  0.98977888]
 [ 0.71039367 -0.70325577  0.02778975]]
support
[0.17038856 1.20568053 0.03385156]
[-893.06968842  158.92096514 -211.31539436]
[-227.7019891   -80.78723035  259.92834882]
[-1.37079481 -9.69983299 -0.27233952]
v_real [ 0.31740892 -0.13302168  0.42951888]
zmp_s [       0.         -3160593.72528883 10205369.08386618]
transform [[ 0.69384211 -0.11800032  0.71039367]
 [ 0.70641184 -0.08008604 -0.70325577]
 [ 0.13987702  0.98977888  0.02778975]]
zmp [ 7622780.64325204 -6923865.26844046 -2844684.27749456]
d1:13987474.00147, d2:0.05940, d3:6347515.80514
eta 23760000.0
transform [[ 0.69756955  0.69830698 -0.16051188]
 [ 0.09347513  0.13341191  0.98664266]
 [ 0.71039367 -0.70325577  0.02778975]]
planes
[[ 0.69756955  0.69830698 -0.16051188]
 [ 0.09347513  0.13341191  0.98664266]
 [ 0.71039367 -0.70325577  0.02778975]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-788.5191  -494.9935    26.50429]
[  36.19514382 -337.17751461 -104.58841649]
[ 0.   0.  -9.8]
transform [[ 0.69756955  0.69830698 -0.16051188]
 [ 0.09347513  0.13341191  0.98664266]
 [ 0.71039367 -0.70325577  0.02778975]]
transform [[ 0.69756955  0.69830698 -0.16051188]
 [ 0.09347513  0.13341191  0.98664266]
 [ 0.71039367 -0.70325577  0.02778975]]
transform [[ 0.69756955  0.69830698 -0.16051188]
 [ 0.09347513  0.13341191  0.98664266]
 [ 0.71039367 -0.70325577  0.02778975]]
support
[-0.19552453  1.20186021  0.03385156]
[-899.95858403 -113.59469575 -211.31539436]
[-193.41709757 -144.79154505  259.92834882]
[ 1.57301643 -9.66909806 -0.27233952]
v_real [ 0.31740892 -0.13302168  0.42951888]
zmp_s [       0.         -3160593.7319844  10205369.24107009]
transform [[ 0.69756955  0.09347513  0.71039367]
 [ 0.69830698  0.13341191 -0.70325577]
 [-0.16051188  0.98664266  0.02778975]]
zmp [ 6954392.76048181 -7598645.68971016 -2834771.97008284]
d1:14054521.09406, d2:0.05940, d3:6413569.47788
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-201.73553245920925 steps:326[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.13359272 -0.18952142  0.97274595]
 [-0.67418975  0.70203841  0.2293694 ]
 [-0.7263754  -0.6864574  -0.03398617]]
planes
[[ 0.13359272 -0.18952142  0.97274595]
 [-0.67418975  0.70203841  0.2293694 ]
 [-0.7263754  -0.6864574  -0.03398617]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-788.5191  -494.9935    26.50429]
[  36.19514382 -337.17751461 -104.58841649]
[ 0.   0.  -9.8]
transform [[ 0.13359272 -0.18952142  0.97274595]
 [-0.67418975  0.70203841  0.2293694 ]
 [-0.7263754  -0.6864574  -0.03398617]]
transform [[ 0.13359272 -0.18952142  0.97274595]
 [-0.67418975  0.70203841  0.2293694 ]
 [-0.7263754  -0.6864574  -0.03398617]]
transform [[ 0.13359272 -0.18952142  0.97274595]
 [-0.67418975  0.70203841  0.2293694 ]
 [-0.7263754  -0.6864574  -0.03398617]]
support
[ 1.1849322   0.27940202 -0.04139961]
[ 14.25339435 190.1863196  911.65204975]
[ -33.00019084 -285.10334272  208.7212961 ]
[-9.53291036 -2.24782014  0.33306446]
v_real [-0.02988955  0.57496136 -0.64336133]
zmp_s [        0.         13660990.8871474 -15286554.3642465]
transform [[ 0.13359272 -0.67418975 -0.7263754 ]
 [-0.18952142  0.70203841 -0.6864574 ]
 [ 0.97274595  0.2293694  -0.03398617]]
zmp [ 1893677.07504097 20084108.58077347  3652944.74254631]
d1:23695350.79956, d2:0.05940, d3:9010152.77190
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-203.31611165520206 steps:328[00m
[RDDPG] Resetting Environment
eta 23760000.0
transform [[ 0.65534765  0.69820654 -0.28814417]
 [ 0.21513151  0.19314221  0.95729542]
 [ 0.72404283 -0.68935019 -0.02363096]]
planes
[[ 0.65534765  0.69820654 -0.28814417]
 [ 0.21513151  0.19314221  0.95729542]
 [ 0.72404283 -0.68935019 -0.02363096]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 287.38986 -148.2253  -162.3208 ]
[  57.2210885  -210.72290434  -36.14348277]
[ 0.   0.  -9.8]
transform [[ 0.65534765  0.69820654 -0.28814417]
 [ 0.21513151  0.19314221  0.95729542]
 [ 0.72404283 -0.68935019 -0.02363096]]
transform [[ 0.65534765  0.69820654 -0.28814417]
 [ 0.21513151  0.19314221  0.95729542]
 [ 0.72404283 -0.68935019 -0.02363096]]
transform [[ 0.65534765  0.69820654 -0.28814417]
 [ 0.21513151  0.19314221  0.95729542]
 [ 0.72404283 -0.68935019 -0.02363096]]
support
[-0.35099741  1.16611142 -0.02878561]
[ 131.62019034 -122.19090545  314.09750124]
[-99.21387127 -62.98941796 187.54649775]
[ 2.82381288 -9.38149509  0.23158337]
v_real [-0.6529678  -0.36762926 -0.27737093]
zmp_s [       0.         -8734871.57236753 -6590333.17667414]
transform [[ 0.65534765  0.21513151  0.72404283]
 [ 0.69820654  0.19314221 -0.68935019]
 [-0.28814417  0.95729542 -0.02363096]]
zmp [-6650829.58158227  2855975.05281969 -8206116.65661224]
d1:18890267.33727, d2:0.05940, d3:8140467.63419
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-107.8772426214276 steps:330[00m
[RDDPG] Resetting Environment
eta 23760000.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-156.62919689452676 steps:331[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 959, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 16:01:17.346549: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 16:01:17.346588: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620124283.830727159, 1.028000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620124283.833371623, 1.031000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620124283.833576010, 1.031000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620124285.441221219, 2.210000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620124286.820957230, 3.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620124287.888743775, 4.000000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620124288.970146570, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.71143645 -0.70262855 -0.01308692]
 [ 0.00506282 -0.01349744  0.99989611]
 [-0.70273215 -0.71142888 -0.00604529]]
planes
[[ 0.71143645 -0.70262855 -0.01308692]
 [ 0.00506282 -0.01349744  0.99989611]
 [-0.70273215 -0.71142888 -0.00604529]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71143645 -0.70262855 -0.01308692]
 [ 0.00506282 -0.01349744  0.99989611]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71143645 -0.70262855 -0.01308692]
 [ 0.00506282 -0.01349744  0.99989611]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71143645 -0.70262855 -0.01308692]
 [ 0.00506282 -0.01349744  0.99989611]
 [-0.70273215 -0.71142888 -0.00604529]]
support
[-0.01594158  1.21800465 -0.00736395]
[-4.27902024e-11  9.91461491e-09 -1.42020632e-08]
[-4.27902024e-11  9.91461491e-09 -1.42020632e-08]
[ 0.12825179 -9.79898187  0.05924383]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.34147997 -16798018.91906349]
transform [[ 0.71143645  0.00506282 -0.70273215]
 [-0.70262855 -0.01349744 -0.71142888]
 [-0.01308692  0.99989611 -0.00604529]]
zmp [11804711.31587373 11950053.43878774   141727.04374314]
d1:24326931.17897, d2:0.05940, d3:7813861.86567
eta 0
transform [[ 7.11454511e-01 -7.02710927e-01 -5.47199044e-03]
 [-3.55158438e-04 -8.14629067e-03  9.99966741e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
planes
[[ 7.11454511e-01 -7.02710927e-01 -5.47199044e-03]
 [-3.55158438e-04 -8.14629067e-03  9.99966741e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 7.11454511e-01 -7.02710927e-01 -5.47199044e-03]
 [-3.55158438e-04 -8.14629067e-03  9.99966741e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
transform [[ 7.11454511e-01 -7.02710927e-01 -5.47199044e-03]
 [-3.55158438e-04 -8.14629067e-03  9.99966741e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
transform [[ 7.11454511e-01 -7.02710927e-01 -5.47199044e-03]
 [-3.55158438e-04 -8.14629067e-03  9.99966741e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
support
[-0.0066656   1.21809069 -0.00736395]
[ 3.27159371e-11  9.91465292e-09 -1.42020632e-08]
[ 3.27159371e-11  9.91465292e-09 -1.42020632e-08]
[ 0.05362551 -9.79967406  0.05924383]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.34148013 -16798018.91906339]
transform [[ 7.11454511e-01 -3.55158438e-04 -7.02732146e-01]
 [-7.02710927e-01 -8.14629067e-03 -7.11428881e-01]
 [-5.47199044e-03  9.99966741e-01 -6.04528887e-03]]
zmp [11804493.60885441 11950268.46039099   141729.88188251]
d1:24326927.88913, d2:0.05940, d3:7813860.00267
eta 0
transform [[ 0.71132255 -0.70274001  0.01329239]
 [-0.01370486  0.00504084  0.99989343]
 [-0.70273215 -0.71142888 -0.00604529]]
planes
[[ 0.71132255 -0.70274001  0.01329239]
 [-0.01370486  0.00504084  0.99989343]
 [-0.70273215 -0.71142888 -0.00604529]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71132255 -0.70274001  0.01329239]
 [-0.01370486  0.00504084  0.99989343]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71132255 -0.70274001  0.01329239]
 [-0.01370486  0.00504084  0.99989343]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71132255 -0.70274001  0.01329239]
 [-0.01370486  0.00504084  0.99989343]
 [-0.70273215 -0.71142888 -0.00604529]]
support
[ 0.01619188  1.21800138 -0.00736395]
[ 2.18749270e-10  9.91229409e-09 -1.42020632e-08]
[ 2.18749270e-10  9.91229409e-09 -1.42020632e-08]
[-0.13026547 -9.79895558  0.05924383]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.34147975 -16798018.91906365]
transform [[ 0.71132255 -0.01370486 -0.70273215]
 [-0.70274001  0.00504084 -0.71142888]
 [ 0.01329239  0.99989343 -0.00604529]]
zmp [11803957.18656434 11950798.35030094   141726.93596548]
d1:24326919.71158, d2:0.05940, d3:7813855.48430
eta 0
transform [[ 7.11440265e-01 -7.02746511e-01  3.64077423e-04]
 [-4.50732047e-03 -4.04501287e-03  9.99981642e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
planes
[[ 7.11440265e-01 -7.02746511e-01  3.64077423e-04]
 [-4.50732047e-03 -4.04501287e-03  9.99981642e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 7.11440265e-01 -7.02746511e-01  3.64077423e-04]
 [-4.50732047e-03 -4.04501287e-03  9.99981642e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
transform [[ 7.11440265e-01 -7.02746511e-01  3.64077423e-04]
 [-4.50732047e-03 -4.04501287e-03  9.99981642e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
transform [[ 7.11440265e-01 -7.02746511e-01  3.64077423e-04]
 [-4.50732047e-03 -4.04501287e-03  9.99981642e-01]
 [-7.02732146e-01 -7.11428881e-01 -6.04528887e-03]]
support
[ 4.43494068e-04  1.21810884e+00 -7.36395499e-03]
[ 9.05783210e-11  9.91429308e-09 -1.42020632e-08]
[ 9.05783210e-11  9.91429308e-09 -1.42020632e-08]
[-3.56795875e-03 -9.79982009e+00  5.92438309e-02]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.34147585 -16798018.91906635]
transform [[ 7.11440265e-01 -4.50732047e-03 -7.02732146e-01]
 [-7.02746511e-01 -4.04501287e-03 -7.11428881e-01]
 [ 3.64077423e-04  9.99981642e-01 -6.04528887e-03]]
zmp [11804326.76526395 11950433.25933796   141730.4806418 ]
d1:24326925.35656, d2:0.05940, d3:7813858.58634
eta 0
transform [[ 0.71109366 -0.70262092  0.02587748]
 [-0.02265753  0.01388617  0.9996469 ]
 [-0.70273215 -0.71142888 -0.00604529]]
planes
[[ 0.71109366 -0.70262092  0.02587748]
 [-0.02265753  0.01388617  0.9996469 ]
 [-0.70273215 -0.71142888 -0.00604529]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71109366 -0.70262092  0.02587748]
 [-0.02265753  0.01388617  0.9996469 ]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71109366 -0.70262092  0.02587748]
 [-0.02265753  0.01388617  0.9996469 ]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71109366 -0.70262092  0.02587748]
 [-0.02265753  0.01388617  0.9996469 ]
 [-0.70273215 -0.71142888 -0.00604529]]
support
[ 0.03152216  1.21770108 -0.00736395]
[ 3.43502183e-10  9.90875540e-09 -1.42020632e-08]
[ 3.43502183e-10  9.90875540e-09 -1.42020632e-08]
[-0.25359928 -9.79653964  0.05924383]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.3414798  -16798018.91906361]
transform [[ 0.71109366 -0.02265753 -0.70273215]
 [-0.70262092  0.01388617 -0.71142888]
 [ 0.02587748  0.9996469  -0.00604529]]
zmp [11803597.44732928 11951153.77619304   141717.0300214 ]
d1:24326914.17045, d2:0.05940, d3:7813852.51163
eta 0
transform [[ 0.71142256 -0.70275575  0.00351172]
 [-0.0067467  -0.00183296  0.99997556]
 [-0.70273215 -0.71142888 -0.00604529]]
planes
[[ 0.71142256 -0.70275575  0.00351172]
 [-0.0067467  -0.00183296  0.99997556]
 [-0.70273215 -0.71142888 -0.00604529]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.71142256 -0.70275575  0.00351172]
 [-0.0067467  -0.00183296  0.99997556]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71142256 -0.70275575  0.00351172]
 [-0.0067467  -0.00183296  0.99997556]
 [-0.70273215 -0.71142888 -0.00604529]]
transform [[ 0.71142256 -0.70275575  0.00351172]
 [-0.0067467  -0.00183296  0.99997556]
 [-0.70273215 -0.71142888 -0.00604529]]
support
[ 0.00427773  1.21810143 -0.00736395]
[ 1.21785321e-10  9.91395906e-09 -1.42020632e-08]
[ 1.21785321e-10  9.91395906e-09 -1.42020632e-08]
[-0.03441484 -9.79976051  0.05924383]
v_real [-9.9440396e-05  4.0183341e-04 -1.6798018e-01]
zmp_s [        0.             40182.34147944 -16798018.91906386]
transform [[ 0.71142256 -0.0067467  -0.70273215]
 [-0.70275575 -0.00183296 -0.71142888]
 [ 0.00351172  0.99997556 -0.00604529]]
zmp [11804236.78180389 11950522.14491473   141730.23634985]
d1:24326923.98663, d2:0.05940, d3:7813857.82660
eta 0
transform [[ 0.99680781 -0.07096785 -0.03657562]
 [ 0.02617176 -0.14235009  0.98947036]
 [-0.07542726 -0.98726898 -0.14003833]]
planes
[[ 0.99680781 -0.07096785 -0.03657562]
 [ 0.02617176 -0.14235009  0.98947036]
 [-0.07542726 -0.98726898 -0.14003833]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1.e-08 1.e-08 1.e-08]
[1.e-08 1.e-08 1.e-08]
[ 0.   0.  -9.8]
transform [[ 0.99680781 -0.07096785 -0.03657562]
 [ 0.02617176 -0.14235009  0.98947036]
 [-0.07542726 -0.98726898 -0.14003833]]
transform [[ 0.99680781 -0.07096785 -0.03657562]
 [ 0.02617176 -0.14235009  0.98947036]
 [-0.07542726 -0.98726898 -0.14003833]]
transform [[ 0.99680781 -0.07096785 -0.03657562]
 [ 0.02617176 -0.14235009  0.98947036]
 [-0.07542726 -0.98726898 -0.14003833]]
support
[-0.04455391  1.20530472 -0.17058505]
[ 8.89264338e-09  8.73292027e-09 -1.20273457e-08]
[ 8.89264338e-09  8.73292027e-09 -1.20273457e-08]
[ 0.3584411  -9.69680955  1.3723756 ]
v_real [ 0.08898713 -0.15693432  0.09427611]
zmp_s [0.00000000e+00 6.45427536e-08 1.86365423e-08]
transform [[ 0.99680781  0.02617176 -0.07542726]
 [-0.07096785 -0.14235009 -0.98726898]
 [-0.03657562  0.98947036 -0.14003833]]
zmp [ 2.83494000e-10 -2.75869471e-08  6.12533116e-08]
d1:0.35372, d2:0.05936, d3:0.22899
eta 0
transform [[ 0.11681927 -0.13017721  0.98458475]
 [-0.67542857  0.71639478  0.17485681]
 [-0.72811371 -0.68544328 -0.00423671]]
planes
[[ 0.11681927 -0.13017721  0.98458475]
 [-0.67542857  0.71639478  0.17485681]
 [-0.72811371 -0.68544328 -0.00423671]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[111.84982 196.61255 211.53012]
[-56.27228656 164.01916598  21.31697636]
[ 0.   0.  -9.8]
transform [[ 0.11681927 -0.13017721  0.98458475]
 [-0.67542857  0.71639478  0.17485681]
 [-0.72811371 -0.68544328 -0.00423671]]
transform [[ 0.11681927 -0.13017721  0.98458475]
 [-0.67542857  0.71639478  0.17485681]
 [-0.72811371 -0.68544328 -0.00423671]]
transform [[ 0.11681927 -0.13017721  0.98458475]
 [-0.67542857  0.71639478  0.17485681]
 [-0.72811371 -0.68544328 -0.00423671]]
support
[ 1.1993534   0.21299854 -0.00516087]
[ 195.74107157  102.29312067 -217.1023319 ]
[ -6.93687581 159.2378032  -71.54352589]
[-9.64893054 -1.71359676  0.04151974]
v_real [ 0.37324473 -0.2603291   0.4801464 ]
zmp_s [ 0.         -0.05077869  2.24947721]
transform [[ 0.11681927 -0.67542857 -0.72811371]
 [-0.13017721  0.71639478 -0.68544328]
 [ 0.98458475  0.17485681 -0.00423671]]
zmp [-1.60357782 -1.57826663 -0.01840938]
d1:2.46643, d2:0.05252, d3:1.23136
eta 0
transform [[ 0.35852027  0.60758609 -0.70873302]
 [ 0.45064726  0.55223894  0.70139092]
 [ 0.81754529 -0.57085145 -0.07581811]]
planes
[[ 0.35852027  0.60758609 -0.70873302]
 [ 0.45064726  0.55223894  0.70139092]
 [ 0.81754529 -0.57085145 -0.07581811]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  96.41659 -124.29211  187.08386]
[-38.30369261 230.81825013  -9.76546212]
[ 0.   0.  -9.8]
transform [[ 0.35852027  0.60758609 -0.70873302]
 [ 0.45064726  0.55223894  0.70139092]
 [ 0.81754529 -0.57085145 -0.07581811]]
transform [[ 0.35852027  0.60758609 -0.70873302]
 [ 0.45064726  0.55223894  0.70139092]
 [ 0.81754529 -0.57085145 -0.07581811]]
transform [[ 0.35852027  0.60758609 -0.70873302]
 [ 0.45064726  0.55223894  0.70139092]
 [ 0.81754529 -0.57085145 -0.07581811]]
support
[-0.86332981  0.85438617 -0.09235641]
[-173.54336466  106.0298529   135.59291082]
[ 133.43041242  103.35596528 -162.33753641]
[ 6.94558362 -6.87363104  0.74301752]
v_real [ 0.09504854 -0.12650244  0.48127997]
zmp_s [ 0.         -0.63388131 -1.41925785]
transform [[ 0.35852027  0.45064726  0.81754529]
 [ 0.60758609  0.55223894 -0.57085145]
 [-0.70873302  0.70139092 -0.07581811]]
zmp [-1.44596446  0.46013146 -0.33699314]
d1:2.01466, d2:0.05451, d3:0.86180
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
eta 0
transform [[ 0.66890824  0.68871909 -0.27969229]
 [ 0.23562431  0.16041085  0.95851421]
 [ 0.7050128  -0.70706034 -0.05497885]]
planes
[[ 0.66890824  0.68871909 -0.27969229]
 [ 0.23562431  0.16041085  0.95851421]
 [ 0.7050128  -0.70706034 -0.05497885]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 268.33475  579.0381  1500.8506 ]
[  -1.70090856 -836.63689001  -38.76130892]
[ 0.   0.  -9.8]
transform [[ 0.66890824  0.68871909 -0.27969229]
 [ 0.23562431  0.16041085  0.95851421]
 [ 0.7050128  -0.70706034 -0.05497885]]
transform [[ 0.66890824  0.68871909 -0.27969229]
 [ 0.23562431  0.16041085  0.95851421]
 [ 0.7050128  -0.70706034 -0.05497885]]
transform [[ 0.66890824  0.68871909 -0.27969229]
 [ 0.23562431  0.16041085  0.95851421]
 [ 0.7050128  -0.70706034 -0.05497885]]
support
[-0.34070191  1.16759607 -0.06697145]
[ 158.5095683  1594.6968019  -302.75047421]
[-566.50431313 -171.75967666  592.48465138]
[ 2.74098446 -9.39343929  0.53879274]
v_real [0.15172447 0.11647631 0.2909759 ]
zmp_s [ 0.          0.84282961 -1.77067893]
transform [[ 0.66890824  0.23562431  0.7050128 ]
 [ 0.68871909  0.16041085 -0.70706034]
 [-0.27969229  0.95851421 -0.05497885]]
zmp [-1.04976016  1.38717586  0.90521405]
d1:2.05681, d2:0.05829, d3:1.27002
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:-73.6679413361956[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.68326646  0.717731    0.13419874]
 [-0.09331039 -0.09645522  0.99095392]
 [ 0.72418249 -0.68960762  0.00106715]]
planes
[[ 0.68326646  0.717731    0.13419874]
 [-0.09331039 -0.09645522  0.99095392]
 [ 0.72418249 -0.68960762  0.00106715]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.39432  512.2414  -287.60355]
[ -83.93641016 -538.73975755   46.25397551]
[ 0.   0.  -9.8]
transform [[ 0.68326646  0.717731    0.13419874]
 [-0.09331039 -0.09645522  0.99095392]
 [ 0.72418249 -0.68960762  0.00106715]]
transform [[ 0.68326646  0.717731    0.13419874]
 [-0.09331039 -0.09645522  0.99095392]
 [ 0.72418249 -0.68960762  0.00106715]]
transform [[ 0.68326646  0.717731    0.13419874]
 [-0.09331039 -0.09645522  0.99095392]
 [ 0.72418249 -0.68960762  0.00106715]]
support
[0.16347167 1.20711189 0.00129993]
[ 171.63478391 -312.91203221 -520.40001533]
[-437.81393305  105.6319578   310.78312395]
[-1.31514765 -9.71134844 -0.01045809]
v_real [ 0.95806414 -0.06037383  0.33200285]
zmp_s [ 0.         -0.30794149  1.12098485]
transform [[ 0.68326646 -0.09331039  0.72418249]
 [ 0.717731   -0.09645522 -0.68960762]
 [ 0.13419874  0.99095392  0.00106715]]
zmp [ 0.84053174 -0.74333713 -0.30395956]
d1:1.21443, d2:0.05918, d3:0.71094
eta 0
transform [[ 0.68471104  0.71885455 -0.12007863]
 [ 0.08204001  0.08768953  0.99276388]
 [ 0.72418249 -0.68960762  0.00106715]]
planes
[[ 0.68471104  0.71885455 -0.12007863]
 [ 0.08204001  0.08768953  0.99276388]
 [ 0.72418249 -0.68960762  0.00106715]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.39432  512.2414  -287.60355]
[ -83.93641016 -538.73975755   46.25397551]
[ 0.   0.  -9.8]
transform [[ 0.68471104  0.71885455 -0.12007863]
 [ 0.08204001  0.08768953  0.99276388]
 [ 0.72418249 -0.68960762  0.00106715]]
transform [[ 0.68471104  0.71885455 -0.12007863]
 [ 0.08204001  0.08768953  0.99276388]
 [ 0.72418249 -0.68960762  0.00106715]]
transform [[ 0.68471104  0.71885455 -0.12007863]
 [ 0.08204001  0.08768953  0.99276388]
 [ 0.72418249 -0.68960762  0.00106715]]
support
[-0.14627153  1.20931665  0.00129993]
[ 245.00856244 -259.50575499 -520.40001533]
[-450.30182478   -8.20870623  310.78312395]
[ 1.17677058 -9.72908599 -0.01045809]
v_real [ 0.95806414 -0.06037383  0.33200285]
zmp_s [ 0.         -0.21304475 -0.34124664]
transform [[ 0.68471104  0.08204001  0.72418249]
 [ 0.71885455  0.08768953 -0.68960762]
 [-0.12007863  0.99276388  0.00106715]]
zmp [-0.26460303  0.21664449 -0.21186729]
d1:0.69846, d2:0.05911, d3:0.32069
eta 0
transform [[ 0.83000982  0.47990218 -0.28421402]
 [ 0.16795856  0.27085906  0.94785297]
 [ 0.53185874 -0.83446348  0.14421201]]
planes
[[ 0.83000982  0.47990218 -0.28421402]
 [ 0.16795856  0.27085906  0.94785297]
 [ 0.53185874 -0.83446348  0.14421201]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-230.39432  512.2414  -287.60355]
[ -83.93641016 -538.73975755   46.25397551]
[ 0.   0.  -9.8]
transform [[ 0.83000982  0.47990218 -0.28421402]
 [ 0.16795856  0.27085906  0.94785297]
 [ 0.53185874 -0.83446348  0.14421201]]
transform [[ 0.83000982  0.47990218 -0.28421402]
 [ 0.16795856  0.27085906  0.94785297]
 [ 0.53185874 -0.83446348  0.14421201]]
transform [[ 0.83000982  0.47990218 -0.28421402]
 [ 0.16795856  0.27085906  0.94785297]
 [ 0.53185874 -0.83446348  0.14421201]]
support
[-0.34620996  1.15460927  0.17566915]
[ 136.33717498 -172.55734857 -591.45985156]
[-341.35645588 -116.17841611  411.58671649]
[ 2.78529739 -9.2889591  -1.41327767]
v_real [0.49906266 0.27000982 0.6281068 ]
zmp_s [ 0.         -2.25636892 -2.13479153]
transform [[ 0.83000982  0.16795856  0.53185874]
 [ 0.47990218  0.27085906 -0.83446348]
 [-0.28421402  0.94785297  0.14421201]]
zmp [-1.51438401  1.17024759 -2.44656856]
d1:5.34238, d2:0.05919, d3:1.70977
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-722.9063429372064 steps:4[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.72173363  0.69212395  0.00807114]
 [ 0.00352018 -0.01533075  0.99987626]
 [ 0.69216204 -0.72161585 -0.01350112]]
planes
[[ 0.72173363  0.69212395  0.00807114]
 [ 0.00352018 -0.01533075  0.99987626]
 [ 0.69216204 -0.72161585 -0.01350112]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  -1.3603375 -116.06428    300.83264  ]
[  47.2710795  -153.67369459  -22.80628564]
[ 0.   0.  -9.8]
transform [[ 0.72173363  0.69212395  0.00807114]
 [ 0.00352018 -0.01533075  0.99987626]
 [ 0.69216204 -0.72161585 -0.01350112]]
transform [[ 0.72173363  0.69212395  0.00807114]
 [ 0.00352018 -0.01533075  0.99987626]
 [ 0.69216204 -0.72161585 -0.01350112]]
transform [[ 0.72173363  0.69212395  0.00807114]
 [ 0.00352018 -0.01533075  0.99987626]
 [ 0.69216204 -0.72161585 -0.01350112]]
support
[ 0.00983171  1.21798047 -0.01644613]
[-78.88460424 302.56998043  78.75067125]
[-72.42818944 -20.28112803 143.92053093]
[-0.0790972  -9.79878736  0.13231096]
v_real [ 0.03136735  0.3403027  -0.23284426]
zmp_s [0.         3.07704951 0.25021668]
transform [[ 0.72173363  0.00352018  0.69216204]
 [ 0.69212395 -0.01533075 -0.72161585]
 [ 0.00807114  0.99987626 -0.01350112]]
zmp [ 0.18402226 -0.22773379  3.07329055]
d1:5.92721, d2:0.05940, d3:2.02654
eta 0
transform [[ 0.66051489 -0.74883622 -0.05444685]
 [ 0.01036393 -0.0634168   0.99793333]
 [-0.75074148 -0.6597141  -0.03412686]]
planes
[[ 0.66051489 -0.74883622 -0.05444685]
 [ 0.01036393 -0.0634168   0.99793333]
 [-0.75074148 -0.6597141  -0.03412686]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 1.8892564e-01 -1.9846042e+02  1.2810256e+03]
[  89.03640072 -230.99066539  -27.6163945 ]
[ 0.   0.  -9.8]
transform [[ 0.66051489 -0.74883622 -0.05444685]
 [ 0.01036393 -0.0634168   0.99793333]
 [-0.75074148 -0.6597141  -0.03412686]]
transform [[ 0.66051489 -0.74883622 -0.05444685]
 [ 0.01036393 -0.0634168   0.99793333]
 [-0.75074148 -0.6597141  -0.03412686]]
transform [[ 0.66051489 -0.74883622 -0.05444685]
 [ 0.01036393 -0.0634168   0.99793333]
 [-0.75074148 -0.6597141  -0.03412686]]
support
[-0.06632341  1.21561372 -0.04157099]
[  78.9913225  1290.96585812   87.0679261 ]
[233.28767088 -11.98786423  86.48694085]
[ 0.53357917 -9.77974662  0.33444318]
v_real [-0.46963578  0.48108578 -0.8923785 ]
zmp_s [ 0.          1.19657179 -0.11942133]
transform [[ 0.66051489  0.01036393 -0.75074148]
 [-0.74883622 -0.0634168  -0.6597141 ]
 [-0.05444685  0.99793333 -0.03412686]]
zmp [0.10205573 0.00290118 1.19817435]
d1:2.04658, d2:0.04576, d3:0.71910
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-421.4958358303841 steps:7[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.72285992  0.6819579   0.11138654]
 [-0.05469238 -0.1042254   0.99304873]
 [ 0.6888268  -0.72392714 -0.03804247]]
planes
[[ 0.72285992  0.6819579   0.11138654]
 [-0.05469238 -0.1042254   0.99304873]
 [ 0.6888268  -0.72392714 -0.03804247]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.72285992  0.6819579   0.11138654]
 [-0.05469238 -0.1042254   0.99304873]
 [ 0.6888268  -0.72392714 -0.03804247]]
transform [[ 0.72285992  0.6819579   0.11138654]
 [-0.05469238 -0.1042254   0.99304873]
 [ 0.6888268  -0.72392714 -0.03804247]]
transform [[ 0.72285992  0.6819579   0.11138654]
 [-0.05469238 -0.1042254   0.99304873]
 [ 0.6888268  -0.72392714 -0.03804247]]
support
[ 0.13568342  1.20966364 -0.04634072]
[319.53259983 912.47795918 405.17221429]
[-230.55437902   36.32130287  267.30377429]
[-1.09158807 -9.73187753  0.37281621]
v_real [0.3838868  0.4473789  0.04339465]
zmp_s [ 0.         -0.01439806 -0.10507823]
transform [[ 0.72285992 -0.05469238  0.6888268 ]
 [ 0.6819579  -0.1042254  -0.72392714]
 [ 0.11138654  0.99304873 -0.03804247]]
zmp [-0.07159324  0.07756963 -0.01030054]
d1:0.66999, d2:0.05904, d3:0.10803
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-241.9606009961666 steps:9[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.32071146 -0.3281486   0.88851708]
 [-0.62316346  0.63334972  0.45884144]
 [-0.71331024 -0.70084709 -0.00136771]]
planes
[[ 0.32071146 -0.3281486   0.88851708]
 [-0.62316346  0.63334972  0.45884144]
 [-0.71331024 -0.70084709 -0.00136771]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.32071146 -0.3281486   0.88851708]
 [-0.62316346  0.63334972  0.45884144]
 [-0.71331024 -0.70084709 -0.00136771]]
transform [[ 0.32071146 -0.3281486   0.88851708]
 [-0.62316346  0.63334972  0.45884144]
 [-0.71331024 -0.70084709 -0.00136771]]
transform [[ 0.32071146 -0.3281486   0.88851708]
 [-0.62316346  0.63334972  0.45884144]
 [-0.71331024 -0.70084709 -0.00136771]]
support
[ 1.08233038  0.55892908 -0.00166605]
[1026.57801741   30.27974326 -210.00549093]
[ 121.49579357 -234.08324347  237.42298269]
[-8.7074674  -4.49664614  0.01340354]
v_real [-0.43036866 -0.15232162 -0.09944145]
zmp_s [ 0.          0.29825859 -0.00834905]
transform [[ 0.32071146 -0.62316346 -0.71331024]
 [-0.3281486   0.63334972 -0.70084709]
 [ 0.88851708  0.45884144 -0.00136771]]
zmp [-0.17990839  0.1947534   0.13686482]
d1:0.37993, d2:0.01391, d3:0.02782
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-377.2237125375517 steps:11[00m
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-82.19142101562555 steps:12[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.19515292 -0.15308154 -0.9687525 ]
 [ 0.67192465 -0.6986559   0.24575871]
 [-0.71444571 -0.6988892  -0.03348548]]
planes
[[ 0.19515292 -0.15308154 -0.9687525 ]
 [ 0.67192465 -0.6986559   0.24575871]
 [-0.71444571 -0.6988892  -0.03348548]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.19515292 -0.15308154 -0.9687525 ]
 [ 0.67192465 -0.6986559   0.24575871]
 [-0.71444571 -0.6988892  -0.03348548]]
transform [[ 0.19515292 -0.15308154 -0.9687525 ]
 [ 0.67192465 -0.6986559   0.24575871]
 [-0.71444571 -0.6988892  -0.03348548]]
transform [[ 0.19515292 -0.15308154 -0.9687525 ]
 [ 0.67192465 -0.6986559   0.24575871]
 [-0.71444571 -0.6988892  -0.03348548]]
support
[-1.18006765  0.29936636 -0.0407897 ]
[-781.46340348  655.97413894 -240.61294111]
[ 57.07957242 258.14512252 236.70424482]
[ 9.49377453 -2.40843538  0.32815766]
v_real [ 0.50446284 -0.99988014  0.08690882]
zmp_s [ 0.         -0.39307993 -0.00787756]
transform [[ 0.19515292  0.67192465 -0.71444571]
 [-0.15308154 -0.6986559  -0.6988892 ]
 [-0.9687525   0.24575871 -0.03348548]]
zmp [-0.25849201  0.28013315 -0.09633903]
d1:0.51721, d2:0.03009, d3:0.15275
eta 0
transform [[ 0.36096066 -0.32715264 -0.87331474]
 [ 0.59939539 -0.63602293  0.48600429]
 [-0.71444571 -0.6988892  -0.03348548]]
planes
[[ 0.36096066 -0.32715264 -0.87331474]
 [ 0.59939539 -0.63602293  0.48600429]
 [-0.71444571 -0.6988892  -0.03348548]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.36096066 -0.32715264 -0.87331474]
 [ 0.59939539 -0.63602293  0.48600429]
 [-0.71444571 -0.6988892  -0.03348548]]
transform [[ 0.36096066 -0.32715264 -0.87331474]
 [ 0.59939539 -0.63602293  0.48600429]
 [-0.71444571 -0.6988892  -0.03348548]]
transform [[ 0.36096066 -0.32715264 -0.87331474]
 [ 0.59939539 -0.63602293  0.48600429]
 [-0.71444571 -0.6988892  -0.03348548]]
support
[-1.06381193  0.59201699 -0.0407897 ]
[-587.07822417  834.4617082  -240.61294111]
[121.37947465 234.87018337 236.70424482]
[ 8.55848444 -4.76284207  0.32815766]
v_real [ 0.50446284 -0.99988014  0.08690882]
zmp_s [ 0.         -0.52452107 -0.00492639]
transform [[ 0.36096066  0.59939539 -0.71444571]
 [-0.32715264 -0.63602293 -0.6988892 ]
 [-0.87331474  0.48600429 -0.03348548]]
zmp [-0.31087588  0.33705042 -0.25475453]
d1:0.79521, d2:0.04302, d3:0.25679
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-365.7596317105016 steps:15[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.2068003  -0.24304259  0.94771516]
 [-0.60703182  0.72779483  0.31910378]
 [-0.76729792 -0.64128393  0.00297361]]
planes
[[ 0.2068003  -0.24304259  0.94771516]
 [-0.60703182  0.72779483  0.31910378]
 [-0.76729792 -0.64128393  0.00297361]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.2068003  -0.24304259  0.94771516]
 [-0.60703182  0.72779483  0.31910378]
 [-0.76729792 -0.64128393  0.00297361]]
transform [[ 0.2068003  -0.24304259  0.94771516]
 [-0.60703182  0.72779483  0.31910378]
 [-0.76729792 -0.64128393  0.00297361]]
transform [[ 0.2068003  -0.24304259  0.94771516]
 [-0.60703182  0.72779483  0.31910378]
 [-0.76729792 -0.64128393  0.00297361]]
support
[1.15444141 0.38871027 0.00362224]
[1014.48452894 -107.8417586  -240.98348479]
[  89.57332758 -267.34706086  215.47167672]
[-9.2876086  -3.12721702 -0.02914133]
v_real [-0.19909696  0.49552506  0.2667029 ]
zmp_s [0.         0.30179745 0.01445385]
transform [[ 0.2068003  -0.60703182 -0.76729792]
 [-0.24304259  0.72779483 -0.64128393]
 [ 0.94771516  0.31910378  0.00297361]]
zmp [-0.19429106  0.2103776   0.09634769]
d1:0.34087, d2:0.00449, d3:0.02978
eta 0
transform [[ 0.09311582 -0.10682318  0.98990822]
 [-0.6344946   0.75983137  0.14167888]
 [-0.76729792 -0.64128393  0.00297361]]
planes
[[ 0.09311582 -0.10682318  0.98990822]
 [-0.6344946   0.75983137  0.14167888]
 [-0.76729792 -0.64128393  0.00297361]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 460.16516 -170.51074  926.313  ]
[ 1.54809673e+01 -3.54522433e+02  2.19274015e-01]
[ 0.   0.  -9.8]
transform [[ 0.09311582 -0.10682318  0.98990822]
 [-0.6344946   0.75983137  0.14167888]
 [-0.76729792 -0.64128393  0.00297361]]
transform [[ 0.09311582 -0.10682318  0.98990822]
 [-0.6344946   0.75983137  0.14167888]
 [-0.76729792 -0.64128393  0.00297361]]
transform [[ 0.09311582 -0.10682318  0.98990822]
 [-0.6344946   0.75983137  0.14167888]
 [-0.76729792 -0.64128393  0.00297361]]
support
[1.20583809 0.17258347 0.00362224]
[ 978.02799594 -290.29273074 -240.98348479]
[  39.52979641 -279.16878906  215.47167672]
[-9.70110054 -1.38845307 -0.02914133]
v_real [-0.19909696  0.49552506  0.2667029 ]
zmp_s [0.         0.31328864 0.01545029]
transform [[ 0.09311582 -0.6344946  -0.76729792]
 [-0.10682318  0.75983137 -0.64128393]
 [ 0.98990822  0.14167888  0.00297361]]
zmp [-0.21063493  0.22813852  0.04443233]
d1:0.34558, d2:0.00691, d3:0.06283
eta 0
transform [[ 0.52166528  0.29763502  0.7995491 ]
 [-0.56388706 -0.58299851  0.58493102]
 [ 0.64023185 -0.75599355 -0.13629757]]
planes
[[ 0.52166528  0.29763502  0.7995491 ]
 [-0.56388706 -0.58299851  0.58493102]
 [ 0.64023185 -0.75599355 -0.13629757]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 528.2845   372.06583 1281.385  ]
[  89.30588951 -589.16186545   63.3115879 ]
[ 0.   0.  -9.8]
transform [[ 0.52166528  0.29763502  0.7995491 ]
 [-0.56388706 -0.58299851  0.58493102]
 [ 0.64023185 -0.75599355 -0.13629757]]
transform [[ 0.52166528  0.29763502  0.7995491 ]
 [-0.56388706 -0.58299851  0.58493102]
 [ 0.64023185 -0.75599355 -0.13629757]]
transform [[ 0.52166528  0.29763502  0.7995491 ]
 [-0.56388706 -0.58299851  0.58493102]
 [ 0.64023185 -0.75599355 -0.13629757]]
support
[ 0.97395571  0.71252272 -0.16602832]
[1410.85772525  234.71522678 -117.70447259]
[-78.1466982  330.15496815 493.94982643]
[-7.83558121 -5.73232396  1.33571617]
v_real [-0.6175001  2.3091056 -0.2916595]
zmp_s [0.         0.2015051  0.15007003]
transform [[ 0.52166528 -0.56388706  0.64023185]
 [ 0.29763502 -0.58299851 -0.75599355]
 [ 0.7995491   0.58493102 -0.13629757]]
zmp [-0.01754651 -0.23092915  0.09741241]
d1:0.47597, d2:0.03119, d3:0.05773
eta 0
transform [[ 0.22714077  0.06079688  0.97196233]
 [-0.97315454  0.0522049   0.22415392]
 [-0.03711333 -0.99678409  0.07102263]]
planes
[[ 0.22714077  0.06079688  0.97196233]
 [-0.97315454  0.0522049   0.22415392]
 [-0.03711333 -0.99678409  0.07102263]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 528.2845   372.06583 1281.385  ]
[  89.30588951 -589.16186545   63.3115879 ]
[ 0.   0.  -9.8]
transform [[ 0.22714077  0.06079688  0.97196233]
 [-0.97315454  0.0522049   0.22415392]
 [-0.03711333 -0.99678409  0.07102263]]
transform [[ 0.22714077  0.06079688  0.97196233]
 [-0.97315454  0.0522049   0.22415392]
 [-0.03711333 -0.99678409  0.07102263]]
transform [[ 0.22714077  0.06079688  0.97196233]
 [-0.97315454  0.0522049   0.22415392]
 [-0.03711333 -0.99678409  0.07102263]]
support
[1.18397764 0.27304888 0.08651488]
[1388.07334727 -207.45131546 -299.46836056]
[  46.00228653 -103.47402536  588.4492909 ]
[-9.52523086 -2.19670843 -0.69602177]
v_real [-0.8260843 -1.1675091 -0.8489384]
zmp_s [0.         0.02624523 0.26925344]
transform [[ 0.22714077 -0.97315454 -0.03711333]
 [ 0.06079688  0.0522049  -0.99678409]
 [ 0.97196233  0.22415392  0.07102263]]
zmp [-0.03553355 -0.26701741  0.02500606]
d1:0.25158, d2:0.01491, d3:0.19641
eta 0
transform [[ 0.56680775  0.42680973  0.70467186]
 [-0.6111846  -0.35570446  0.70705575]
 [ 0.55243325 -0.83144921  0.05924353]]
planes
[[ 0.56680775  0.42680973  0.70467186]
 [-0.6111846  -0.35570446  0.70705575]
 [ 0.55243325 -0.83144921  0.05924353]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-669.57745 1008.78064 -661.59937]
[-72.42848662 -77.83910116   6.07206366]
[ 0.   0.  -9.8]
transform [[ 0.56680775  0.42680973  0.70467186]
 [-0.6111846  -0.35570446  0.70705575]
 [ 0.55243325 -0.83144921  0.05924353]]
transform [[ 0.56680775  0.42680973  0.70467186]
 [-0.6111846  -0.35570446  0.70705575]
 [ 0.55243325 -0.83144921  0.05924353]]
transform [[ 0.56680775  0.42680973  0.70467186]
 [-0.6111846  -0.35570446  0.70705575]
 [ 0.55243325 -0.83144921  0.05924353]]
support
[0.85838278 0.86128667 0.0721664 ]
[ -415.17475239  -417.3799768  -1247.84220127]
[-69.99670053  76.2481781   25.0670853 ]
[-6.90578423 -6.92914633 -0.58058663]
v_real [-0.79214925  0.78588945  1.372537  ]
zmp_s [ 0.          0.05776097 -2.64739231]
transform [[ 0.56680775 -0.6111846   0.55243325]
 [ 0.42680973 -0.35570446 -0.83144921]
 [ 0.70467186  0.70705575  0.05924353]]
zmp [-1.49781016  2.18062641 -0.11600065]
d1:2.55341, d2:0.05685, d3:1.39565
eta 0
transform [[ 0.22008142  0.21403827  0.95170993]
 [-0.80397886 -0.51271784  0.30122837]
 [ 0.55243325 -0.83144921  0.05924353]]
planes
[[ 0.22008142  0.21403827  0.95170993]
 [-0.80397886 -0.51271784  0.30122837]
 [ 0.55243325 -0.83144921  0.05924353]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-669.57745 1008.78064 -661.59937]
[-72.42848662 -77.83910116   6.07206366]
[ 0.   0.  -9.8]
transform [[ 0.22008142  0.21403827  0.95170993]
 [-0.80397886 -0.51271784  0.30122837]
 [ 0.55243325 -0.83144921  0.05924353]]
transform [[ 0.22008142  0.21403827  0.95170993]
 [-0.80397886 -0.51271784  0.30122837]
 [ 0.55243325 -0.83144921  0.05924353]]
transform [[ 0.22008142  0.21403827  0.95170993]
 [-0.80397886 -0.51271784  0.30122837]
 [ 0.55243325 -0.83144921  0.05924353]]
support
[1.15930755 0.36693568 0.0721664 ]
[ -561.09457834  -178.18621678 -1247.84220127]
[-26.82186721  99.96954605  25.0670853 ]
[-9.32675728 -2.95203807 -0.58058663]
v_real [-0.79214925  0.78588945  1.372537  ]
zmp_s [ 0.          0.04274048 -2.640347  ]
transform [[ 0.22008142 -0.80397886  0.55243325]
 [ 0.21403827 -0.51271784 -0.83144921]
 [ 0.95170993  0.30122837  0.05924353]]
zmp [-1.49297792  2.17340062 -0.14354884]
d1:2.53558, d2:0.05468, d3:1.39020
eta 0
transform [[ 0.21190788 -0.00529642  0.97727531]
 [-0.65108997  0.7449792   0.14521684]
 [-0.72881883 -0.66706675  0.15441869]]
planes
[[ 0.21190788 -0.00529642  0.97727531]
 [-0.65108997  0.7449792   0.14521684]
 [-0.72881883 -0.66706675  0.15441869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-104.93941 -340.33783  497.80774]
[ 57.0707443  287.33899967 -30.10441253]
[ 0.   0.  -9.8]
transform [[ 0.21190788 -0.00529642  0.97727531]
 [-0.65108997  0.7449792   0.14521684]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.21190788 -0.00529642  0.97727531]
 [-0.65108997  0.7449792   0.14521684]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.21190788 -0.00529642  0.97727531]
 [-0.65108997  0.7449792   0.14521684]
 [-0.72881883 -0.66706675  0.15441869]]
support
[1.19044955 0.17689316 0.18810223]
[ 466.06029757 -112.92954417  380.38068732]
[ -18.84842597  172.53172233 -237.91721081]
[-9.57729806 -1.42312501 -1.51330318]
v_real [ 0.21037589  0.72935647 -1.2222255 ]
zmp_s [ 0.          0.99630658 -0.42197698]
transform [[ 0.21190788 -0.65108997 -0.72881883]
 [-0.00529642  0.7449792  -0.66706675]
 [ 0.97727531  0.14521684  0.15441869]]
zmp [-0.34114045  1.02371449  0.07951936]
d1:1.19830, d2:0.03868, d3:0.29750
eta 0
transform [[ 0.28472891 -0.09016237  0.95435858]
 [-0.62269807  0.73952192  0.25564519]
 [-0.72881883 -0.66706675  0.15441869]]
planes
[[ 0.28472891 -0.09016237  0.95435858]
 [-0.62269807  0.73952192  0.25564519]
 [-0.72881883 -0.66706675  0.15441869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-104.93941 -340.33783  497.80774]
[ 57.0707443  287.33899967 -30.10441253]
[ 0.   0.  -9.8]
transform [[ 0.28472891 -0.09016237  0.95435858]
 [-0.62269807  0.73952192  0.25564519]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.28472891 -0.09016237  0.95435858]
 [-0.62269807  0.73952192  0.25564519]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.28472891 -0.09016237  0.95435858]
 [-0.62269807  0.73952192  0.25564519]
 [-0.72881883 -0.66706675  0.15441869]]
support
[1.16253396 0.31140938 0.18810223]
[475.89346918 -59.07956719 380.38068732]
[ -38.38787963  169.25959854 -237.91721081]
[-9.35271406 -2.50532282 -1.51330318]
v_real [ 0.21037589  0.72935647 -1.2222255 ]
zmp_s [ 0.          0.97482781 -0.39316875]
transform [[ 0.28472891 -0.62269807 -0.72881883]
 [-0.09016237  0.73952192 -0.66706675]
 [ 0.95435858  0.25564519  0.15441869]]
zmp [-0.3204746   0.98317634  0.18849743]
d1:1.13866, d2:0.03590, d3:0.36139
eta 0
transform [[ 0.38898414 -0.2177798   0.89513314]
 [-0.56348425  0.71245629  0.4182004 ]
 [-0.72881883 -0.66706675  0.15441869]]
planes
[[ 0.38898414 -0.2177798   0.89513314]
 [-0.56348425  0.71245629  0.4182004 ]
 [-0.72881883 -0.66706675  0.15441869]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-104.93941 -340.33783  497.80774]
[ 57.0707443  287.33899967 -30.10441253]
[ 0.   0.  -9.8]
transform [[ 0.38898414 -0.2177798   0.89513314]
 [-0.56348425  0.71245629  0.4182004 ]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.38898414 -0.2177798   0.89513314]
 [-0.56348425  0.71245629  0.4182004 ]
 [-0.72881883 -0.66706675  0.15441869]]
transform [[ 0.38898414 -0.2177798   0.89513314]
 [-0.56348425  0.71245629  0.4182004 ]
 [-0.72881883 -0.66706675  0.15441869]]
support
[1.0903896  0.50942296 0.18810223]
[478.90314266  24.83927476 380.38068732]
[ -67.32447261  159.96833342 -237.91721081]
[-8.77230475 -4.09836395 -1.51330318]
v_real [ 0.21037589  0.72935647 -1.2222255 ]
zmp_s [ 0.          0.96738385 -0.35035367]
transform [[ 0.38898414 -0.56348425 -0.72881883]
 [-0.2177798   0.71245629 -0.66706675]
 [ 0.89513314  0.4182004   0.15441869]]
zmp [-0.28976121  0.92292799  0.35045916]
d1:1.12368, d2:0.03231, d3:0.45634
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2468.0289741385677 steps:25[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.71157146  0.68692601  0.14764439]
 [-0.11120591 -0.09737811  0.98901504]
 [ 0.69375747 -0.72017372  0.00709875]]
planes
[[ 0.71157146  0.68692601  0.14764439]
 [-0.11120591 -0.09737811  0.98901504]
 [ 0.69375747 -0.72017372  0.00709875]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-734.349     35.15347 1412.0623 ]
[  82.62467744 -682.37810177  -45.41187084]
[ 0.   0.  -9.8]
transform [[ 0.71157146  0.68692601  0.14764439]
 [-0.11120591 -0.09737811  0.98901504]
 [ 0.69375747 -0.72017372  0.00709875]]
transform [[ 0.71157146  0.68692601  0.14764439]
 [-0.11120591 -0.09737811  0.98901504]
 [ 0.69375747 -0.72017372  0.00709875]]
transform [[ 0.71157146  0.68692601  0.14764439]
 [-0.11120591 -0.09737811  0.98901504]
 [ 0.69375747 -0.72017372  0.00709875]]
support
[0.17985023 1.20475008 0.00864721]
[-289.91088922 1474.79158492 -524.75283152]
[-416.65471073   12.3473154   548.42989358]
[-1.44691498 -9.69234742 -0.06956777]
v_real [-0.3431869  -0.18470241 -0.22836024]
zmp_s [ 0.          3.99145536 -0.35769529]
transform [[ 0.71157146 -0.11120591  0.69375747]
 [ 0.68692601 -0.09737811 -0.72017372]
 [ 0.14764439  0.98901504  0.00709875]]
zmp [-0.69202722 -0.13107764  3.94507021]
d1:7.64683, d2:0.05928, d3:2.62647
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-279.80487182665064 steps:27[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.21236561  0.21245654  0.95381504]
 [-0.65212214 -0.69612211  0.30025113]
 [ 0.72776204 -0.68576694 -0.00928478]]
planes
[[ 0.21236561  0.21245654  0.95381504]
 [-0.65212214 -0.69612211  0.30025113]
 [ 0.72776204 -0.68576694 -0.00928478]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-222.22801 -194.44832  324.20667]
[ 163.60356902 -519.50991753  -50.00430362]
[ 0.   0.  -9.8]
transform [[ 0.21236561  0.21245654  0.95381504]
 [-0.65212214 -0.69612211  0.30025113]
 [ 0.72776204 -0.68576694 -0.00928478]]
transform [[ 0.21236561  0.21245654  0.95381504]
 [-0.65212214 -0.69612211  0.30025113]
 [ 0.72776204 -0.68576694 -0.00928478]]
transform [[ 0.21236561  0.21245654  0.95381504]
 [-0.65212214 -0.69612211  0.30025113]
 [ 0.72776204 -0.68576694 -0.00928478]]
support
[ 1.16187186  0.36574526 -0.01131008]
[220.72778946 377.62299685 -31.39307151]
[-123.32436407  239.93898189  475.79147057]
[-9.34738742 -2.94246104  0.09099082]
v_real [ 0.8171387   0.06210085 -0.21229188]
zmp_s [ 0.         -3.94459871  1.29584984]
transform [[ 0.21236561 -0.65212214  0.72776204]
 [ 0.21245654 -0.69612211 -0.68576694]
 [ 0.95381504  0.30025113 -0.00928478]]
zmp [ 3.51543048  1.8572714  -1.19640188]
d1:5.28996, d2:0.05752, d3:1.48594
eta 0
transform [[ 0.99143499  0.00863036 -0.1303159 ]
 [ 0.12217018  0.29141775  0.94876248]
 [ 0.04616453 -0.95655698  0.28786734]]
planes
[[ 0.99143499  0.00863036 -0.1303159 ]
 [ 0.12217018  0.29141775  0.94876248]
 [ 0.04616453 -0.95655698  0.28786734]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-222.22801 -194.44832  324.20667]
[ 163.60356902 -519.50991753  -50.00430362]
[ 0.   0.  -9.8]
transform [[ 0.99143499  0.00863036 -0.1303159 ]
 [ 0.12217018  0.29141775  0.94876248]
 [ 0.04616453 -0.95655698  0.28786734]]
transform [[ 0.99143499  0.00863036 -0.1303159 ]
 [ 0.12217018  0.29141775  0.94876248]
 [ 0.04616453 -0.95655698  0.28786734]]
transform [[ 0.99143499  0.00863036 -0.1303159 ]
 [ 0.12217018  0.29141775  0.94876248]
 [ 0.04616453 -0.95655698  0.28786734]]
support
[-0.15874186  1.15571717  0.35066019]
[-264.25206943  223.77979112  269.07035375]
[ 164.23510148 -178.84913953  490.09891136]
[ 1.27709582 -9.29787227 -2.82109991]
v_real [-7.0314761e-04  1.2204924e+00  7.2765511e-01]
zmp_s [0.         2.8899189  0.87004131]
transform [[ 0.99143499  0.12217018  0.04616453]
 [ 0.00863036  0.29141775 -0.95655698]
 [-0.1303159   0.94876248  0.28786734]]
zmp [0.39322696 0.00992957 2.99230308]
d1:5.76793, d2:0.05917, d3:1.74445
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-556.6885287018044 steps:30[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.21847843 -0.11523492 -0.96901399]
 [ 0.9742232  -0.03141232  0.22338848]
 [-0.05618113 -0.99284148  0.10540162]]
planes
[[ 0.21847843 -0.11523492 -0.96901399]
 [ 0.9742232  -0.03141232  0.22338848]
 [-0.05618113 -0.99284148  0.10540162]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 79.815125    2.7318048 618.8912   ]
[ -47.74489817 -151.51257945  127.99887319]
[ 0.   0.  -9.8]
transform [[ 0.21847843 -0.11523492 -0.96901399]
 [ 0.9742232  -0.03141232  0.22338848]
 [-0.05618113 -0.99284148  0.10540162]]
transform [[ 0.21847843 -0.11523492 -0.96901399]
 [ 0.9742232  -0.03141232  0.22338848]
 [-0.05618113 -0.99284148  0.10540162]]
transform [[ 0.21847843 -0.11523492 -0.96901399]
 [ 0.9742232  -0.03141232  0.22338848]
 [-0.05618113 -0.99284148  0.10540162]]
support
[-1.18038617  0.27211647  0.128393  ]
[-582.59112207  215.92509098   58.03577985]
[-117.00438911  -13.16135244  166.60162468]
[ 9.49633709 -2.18920709 -1.03293588]
v_real [ 0.07848723  0.1027795  -0.4206557 ]
zmp_s [0.         0.12259626 0.03395135]
transform [[ 0.21847843  0.9742232  -0.05618113]
 [-0.11523492 -0.03141232 -0.99284148]
 [-0.96901399  0.22338848  0.10540162]]
zmp [ 0.11752869 -0.03755934  0.03096512]
d1:0.42172, d2:0.00880, d3:0.26019
eta 0
transform [[ 0.99532056 -0.06400638 -0.07238939]
 [ 0.07861757  0.10084148  0.99179149]
 [-0.05618113 -0.99284148  0.10540162]]
planes
[[ 0.99532056 -0.06400638 -0.07238939]
 [ 0.07861757  0.10084148  0.99179149]
 [-0.05618113 -0.99284148  0.10540162]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 79.815125    2.7318048 618.8912   ]
[ -47.74489817 -151.51257945  127.99887319]
[ 0.   0.  -9.8]
transform [[ 0.99532056 -0.06400638 -0.07238939]
 [ 0.07861757  0.10084148  0.99179149]
 [-0.05618113 -0.99284148  0.10540162]]
transform [[ 0.99532056 -0.06400638 -0.07238939]
 [ 0.07861757  0.10084148  0.99179149]
 [-0.05618113 -0.99284148  0.10540162]]
transform [[ 0.99532056 -0.06400638 -0.07238939]
 [ 0.07861757  0.10084148  0.99179149]
 [-0.05618113 -0.99284148  0.10540162]]
support
[-0.08817977  1.20813215  0.128393  ]
[ 34.46562889 620.36134793  58.03577985]
[-47.08946678 107.91585159 166.60162468]
[ 0.70941599 -9.71955657 -1.03293588]
v_real [ 0.07848723  0.1027795  -0.4206557 ]
zmp_s [ 0.         -1.99741803  3.33925882]
transform [[ 0.99532056  0.07861757 -0.05618113]
 [-0.06400638  0.10084148 -0.99284148]
 [-0.07238939  0.99179149  0.10540162]]
zmp [-0.34463546 -3.51677728 -1.62905891]
d1:6.64132, d2:0.05939, d3:0.79888
eta 0
transform [[ 0.80300349  0.51884365 -0.29323494]
 [ 0.33189425  0.01935636  0.94311804]
 [ 0.49500674 -0.85465002 -0.15665799]]
planes
[[ 0.80300349  0.51884365 -0.29323494]
 [ 0.33189425  0.01935636  0.94311804]
 [ 0.49500674 -0.85465002 -0.15665799]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  606.11755  -340.08618 -1193.5312 ]
[-22.97232568 -12.30177786  10.97321593]
[ 0.   0.  -9.8]
transform [[ 0.80300349  0.51884365 -0.29323494]
 [ 0.33189425  0.01935636  0.94311804]
 [ 0.49500674 -0.85465002 -0.15665799]]
transform [[ 0.80300349  0.51884365 -0.29323494]
 [ 0.33189425  0.01935636  0.94311804]
 [ 0.49500674 -0.85465002 -0.15665799]]
transform [[ 0.80300349  0.51884365 -0.29323494]
 [ 0.33189425  0.01935636  0.94311804]
 [ 0.49500674 -0.85465002 -0.15665799]]
support
[-0.35719863  1.1488415  -0.19082999]
[ 660.24802455 -931.05674692  777.66314768]
[-28.0472874    2.4865375   -2.57678334]
[ 2.87370245 -9.24255675  1.53524834]
v_real [-0.62763536 -1.6443233  -0.53359085]
zmp_s [0.         0.64622361 0.23264451]
transform [[ 0.80300349  0.33189425  0.49500674]
 [ 0.51884365  0.01935636 -0.85465002]
 [-0.29323494  0.94311804 -0.15665799]]
zmp [ 0.3296385  -0.1863211   0.57301952]
d1:0.93243, d2:0.05219, d3:0.43711
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-843.1439817724221 steps:34[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.32421383  0.27737755 -0.90440434]
 [ 0.63510889  0.64471996  0.42540917]
 [ 0.7010864  -0.71231872  0.03286218]]
planes
[[ 0.32421383  0.27737755 -0.90440434]
 [ 0.63510889  0.64471996  0.42540917]
 [ 0.7010864  -0.71231872  0.03286218]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1215.5356   -512.26385   641.5348 ]
[-107.79540038 -282.34004451   79.29115263]
[ 0.   0.  -9.8]
transform [[ 0.32421383  0.27737755 -0.90440434]
 [ 0.63510889  0.64471996  0.42540917]
 [ 0.7010864  -0.71231872  0.03286218]]
transform [[ 0.32421383  0.27737755 -0.90440434]
 [ 0.63510889  0.64471996  0.42540917]
 [ 0.7010864  -0.71231872  0.03286218]]
transform [[ 0.32421383  0.27737755 -0.90440434]
 [ 0.63510889  0.64471996  0.42540917]
 [ 0.7010864  -0.71231872  0.03286218]]
support
[-1.10168315  0.51820418  0.04003045]
[-1116.39081068  -829.34944165  -466.21814768]
[-184.97481126 -216.76089534  128.14788931]
[ 8.86316255 -4.16900985 -0.32204935]
v_real [-0.19400552  0.25243306  0.26669842]
zmp_s [0.         1.46303036 0.69982469]
transform [[ 0.32421383  0.63510889  0.7010864 ]
 [ 0.27737755  0.64471996 -0.71231872]
 [-0.90440434  0.42540917  0.03286218]]
zmp [1.41982116 0.44474665 0.64538429]
d1:1.96215, d2:0.04294, d3:0.72600
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-355.42239429760093 steps:36[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.27067703 -0.22698443  0.93552768]
 [-0.65702266  0.66671962  0.35186124]
 [-0.7036016  -0.7099036   0.03133176]]
planes
[[ 0.27067703 -0.22698443  0.93552768]
 [-0.65702266  0.66671962  0.35186124]
 [-0.7036016  -0.7099036   0.03133176]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1215.5356   -512.26385   641.5348 ]
[-107.79540038 -282.34004451   79.29115263]
[ 0.   0.  -9.8]
transform [[ 0.27067703 -0.22698443  0.93552768]
 [-0.65702266  0.66671962  0.35186124]
 [-0.7036016  -0.7099036   0.03133176]]
transform [[ 0.27067703 -0.22698443  0.93552768]
 [-0.65702266  0.66671962  0.35186124]
 [-0.7036016  -0.7099036   0.03133176]]
transform [[ 0.27067703 -0.22698443  0.93552768]
 [-0.65702266  0.66671962  0.35186124]
 [-0.7036016  -0.7099036   0.03133176]]
support
[1.13959546 0.42861315 0.0381662 ]
[ 387.43189429  682.82932177 1239.01119229]
[109.08812246 -89.51814258 278.76356103]
[-9.16817129 -3.44824014 -0.30705127]
v_real [-1.148861    0.15745378  0.16033702]
zmp_s [ 0.         -2.35511442 -3.93033425]
transform [[ 0.27067703 -0.65702266 -0.7036016 ]
 [-0.22698443  0.66671962 -0.7099036 ]
 [ 0.93552768  0.35186124  0.03133176]]
zmp [ 4.312753    1.21995745 -0.95181778]
d1:5.38542, d2:0.05782, d3:2.49003
eta 0
transform [[ 0.87556803 -0.46282429 -0.13847138]
 [ 0.08732457 -0.13028486  0.98762363]
 [-0.47513688 -0.8768236  -0.07365733]]
planes
[[ 0.87556803 -0.46282429 -0.13847138]
 [ 0.08732457 -0.13028486  0.98762363]
 [-0.47513688 -0.8768236  -0.07365733]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1215.5356   -512.26385   641.5348 ]
[-107.79540038 -282.34004451   79.29115263]
[ 0.   0.  -9.8]
transform [[ 0.87556803 -0.46282429 -0.13847138]
 [ 0.08732457 -0.13028486  0.98762363]
 [-0.47513688 -0.8768236  -0.07365733]]
transform [[ 0.87556803 -0.46282429 -0.13847138]
 [ 0.08732457 -0.13028486  0.98762363]
 [-0.47513688 -0.8768236  -0.07365733]]
transform [[ 0.87556803 -0.46282429 -0.13847138]
 [ 0.08732457 -0.13028486  0.98762363]
 [-0.47513688 -0.8768236  -0.07365733]]
support
[-0.16867631  1.20305516 -0.08972429]
[-916.03020762  594.18901131  979.45711109]
[ 25.31206732 105.68126203 292.93961089]
[ 1.35701952 -9.67871159  0.7218418 ]
v_real [1.2847652  0.09247038 0.00488449]
zmp_s [ 0.          1.41553168 -0.38602053]
transform [[ 0.87556803  0.08732457 -0.47513688]
 [-0.46282429 -0.13028486 -0.8768236 ]
 [-0.13847138  0.98762363 -0.07365733]]
zmp [0.30702329 0.15404957 1.42644577]
d1:2.69990, d2:0.05391, d3:0.91953
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-555.575624758059 steps:39[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.29715708  0.28552172 -0.91113943]
 [ 0.6541875   0.63420552  0.41209492]
 [ 0.69551164 -0.71851289  0.00167392]]
planes
[[ 0.29715708  0.28552172 -0.91113943]
 [ 0.6541875   0.63420552  0.41209492]
 [ 0.69551164 -0.71851289  0.00167392]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-683.5752  536.8169  567.4411]
[-2103.90657758 -4577.05306547   575.23274217]
[ 0.   0.  -9.8]
transform [[ 0.29715708  0.28552172 -0.91113943]
 [ 0.6541875   0.63420552  0.41209492]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.29715708  0.28552172 -0.91113943]
 [ 0.6541875   0.63420552  0.41209492]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.29715708  0.28552172 -0.91113943]
 [ 0.6541875   0.63420552  0.41209492]
 [ 0.69551164 -0.71851289  0.00167392]]
support
[-1.10988737  0.50198568  0.00203906]
[-566.87428807  127.10548506 -860.19451206]
[-2456.15600999 -4042.09121401  1826.34302073]
[ 8.9291664  -4.03853022 -0.01640444]
v_real [-0.00629657  0.44760492  0.2622293 ]
zmp_s [0.         3.53051393 8.95780952]
transform [[ 0.29715708  0.6541875   0.69551164]
 [ 0.28552172  0.63420552 -0.71851289]
 [-0.91113943  0.41209492  0.00167392]]
zmp [ 8.53987887 -4.19723021  1.46990153]
d1:11.83513, d2:0.05899, d3:4.75599
eta 0
transform [[ 0.70107168  0.67913526  0.21742529]
 [-0.15735969 -0.15004827  0.97607553]
 [ 0.69551164 -0.71851289  0.00167392]]
planes
[[ 0.70107168  0.67913526  0.21742529]
 [-0.15735969 -0.15004827  0.97607553]
 [ 0.69551164 -0.71851289  0.00167392]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-683.5752  536.8169  567.4411]
[-2103.90657758 -4577.05306547   575.23274217]
[ 0.   0.  -9.8]
transform [[ 0.70107168  0.67913526  0.21742529]
 [-0.15735969 -0.15004827  0.97607553]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.70107168  0.67913526  0.21742529]
 [-0.15735969 -0.15004827  0.97607553]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.70107168  0.67913526  0.21742529]
 [-0.15735969 -0.15004827  0.97607553]
 [ 0.69551164 -0.71851289  0.00167392]]
support
[0.26485253 1.18898806 0.00203906]
[   8.71211665  580.8841072  -860.19451206]
[-4458.35731135  1579.31958738  1826.34302073]
[-2.13076781 -9.56554019 -0.01640444]
v_real [-0.00629657  0.44760492  0.2622293 ]
zmp_s [   0.         -299.30536855  274.58839883]
transform [[ 0.70107168 -0.15735969  0.69551164]
 [ 0.67913526 -0.15004827 -0.71851289]
 [ 0.21742529  0.97607553  0.00167392]]
zmp [ 238.0780272  -152.38505175 -291.68500664]
d1:671.40939, d2:0.05940, d3:301.79808
eta 0
transform [[ 0.71503437  0.6923697   0.09669608]
 [-0.07063635 -0.06605633  0.99531257]
 [ 0.69551164 -0.71851289  0.00167392]]
planes
[[ 0.71503437  0.6923697   0.09669608]
 [-0.07063635 -0.06605633  0.99531257]
 [ 0.69551164 -0.71851289  0.00167392]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-683.5752  536.8169  567.4411]
[-2103.90657758 -4577.05306547   575.23274217]
[ 0.   0.  -9.8]
transform [[ 0.71503437  0.6923697   0.09669608]
 [-0.07063635 -0.06605633  0.99531257]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.71503437  0.6923697   0.09669608]
 [-0.07063635 -0.06605633  0.99531257]
 [ 0.69551164 -0.71851289  0.00167392]]
transform [[ 0.71503437  0.6923697   0.09669608]
 [-0.07063635 -0.06605633  0.99531257]
 [ 0.69551164 -0.71851289  0.00167392]]
support
[0.11778851 1.2124213  0.00203906]
[ -62.2346748   577.60636544 -860.19451206]
[-4617.75560998  1023.4920141   1826.34302073]
[-0.94762157 -9.7540632  -0.01640444]
v_real [-0.00629657  0.44760492  0.2622293 ]
zmp_s [  0.          31.17697792 -17.80065317]
transform [[ 0.71503437 -0.07063635  0.69551164]
 [ 0.6923697  -0.06605633 -0.71851289]
 [ 0.09669608  0.99531257  0.00167392]]
zmp [-14.58278953  10.73056195  31.00104116]
d1:64.66677, d2:0.05940, d3:27.25239
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-804.6649719858303 steps:43[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.99856514  0.05351943 -0.00183391]
 [ 0.0054905  -0.068256    0.99765277]
 [ 0.05326867 -0.99623132 -0.06845191]]
planes
[[ 0.99856514  0.05351943 -0.00183391]
 [ 0.0054905  -0.068256    0.99765277]
 [ 0.05326867 -0.99623132 -0.06845191]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-683.5752  536.8169  567.4411]
[-2103.90657758 -4577.05306547   575.23274217]
[ 0.   0.  -9.8]
transform [[ 0.99856514  0.05351943 -0.00183391]
 [ 0.0054905  -0.068256    0.99765277]
 [ 0.05326867 -0.99623132 -0.06845191]]
transform [[ 0.99856514  0.05351943 -0.00183391]
 [ 0.0054905  -0.068256    0.99765277]
 [ 0.05326867 -0.99623132 -0.06845191]]
transform [[ 0.99856514  0.05351943 -0.00183391]
 [ 0.0054905  -0.068256    0.99765277]
 [ 0.05326867 -0.99623132 -0.06845191]]
support
[-0.00223394  1.21527196 -0.08338341]
[-654.90485694  525.71504254 -610.04936963]
[-2346.90396098   874.74236281  4408.35552564]
[ 0.01797227 -9.77699714  0.67082873]
v_real [-0.80978036  0.33997867 -0.35229892]
zmp_s [ 0.          7.94498828 -1.4170199 ]
transform [[ 0.99856514  0.0054905   0.05326867]
 [ 0.05351943 -0.068256   -0.99623132]
 [-0.00183391  0.99765277 -0.06845191]]
zmp [-0.0318608   0.8693865   8.02333728]
d1:15.77576, d2:0.05940, d3:3.92682
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-334.9648175733119 steps:45[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.1123787  -0.02397482 -0.9933762 ]
 [ 0.71205842  0.69922662  0.06367816]
 [ 0.69306844 -0.71449798  0.09564967]]
planes
[[ 0.1123787  -0.02397482 -0.9933762 ]
 [ 0.71205842  0.69922662  0.06367816]
 [ 0.69306844 -0.71449798  0.09564967]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-904.6989  -658.96906  720.48267]
[  46.11380901 -318.92517848  -60.3111983 ]
[ 0.   0.  -9.8]
transform [[ 0.1123787  -0.02397482 -0.9933762 ]
 [ 0.71205842  0.69922662  0.06367816]
 [ 0.69306844 -0.71449798  0.09564967]]
transform [[ 0.1123787  -0.02397482 -0.9933762 ]
 [ 0.71205842  0.69922662  0.06367816]
 [ 0.69306844 -0.71449798  0.09564967]]
transform [[ 0.1123787  -0.02397482 -0.9933762 ]
 [ 0.71205842  0.69922662  0.06367816]
 [ 0.69306844 -0.71449798  0.09564967]]
support
[-1.21006254  0.07756835  0.11651384]
[ -801.58055373 -1059.08817644   -87.27228075]
[  72.74009275 -194.00575383  254.06267675]
[ 9.73508672 -0.62404597 -0.93736674]
v_real [-0.69804746 -0.02070373 -0.568393  ]
zmp_s [0.         2.0178216  0.49631641]
transform [[ 0.1123787   0.71205842  0.69306844]
 [-0.02397482  0.69922662 -0.71449798]
 [-0.9933762   0.06367816  0.09564967]]
zmp [1.78078811 1.0562975  0.17596367]
d1:2.26700, d2:0.05066, d3:0.41163
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-294.54615955070017 steps:47[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 7.22334206e-01  6.91196859e-01 -2.19135880e-02]
 [ 1.59850847e-02  1.49910292e-02  9.99759853e-01]
 [ 6.91359341e-01 -7.22511053e-01 -2.20306916e-04]]
planes
[[ 7.22334206e-01  6.91196859e-01 -2.19135880e-02]
 [ 1.59850847e-02  1.49910292e-02  9.99759853e-01]
 [ 6.91359341e-01 -7.22511053e-01 -2.20306916e-04]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-338.05264  209.98184 -167.11366]
[ -19.22758748 -376.62614399    4.77702579]
[ 0.   0.  -9.8]
transform [[ 7.22334206e-01  6.91196859e-01 -2.19135880e-02]
 [ 1.59850847e-02  1.49910292e-02  9.99759853e-01]
 [ 6.91359341e-01 -7.22511053e-01 -2.20306916e-04]]
transform [[ 7.22334206e-01  6.91196859e-01 -2.19135880e-02]
 [ 1.59850847e-02  1.49910292e-02  9.99759853e-01]
 [ 6.91359341e-01 -7.22511053e-01 -2.20306916e-04]]
transform [[ 7.22334206e-01  6.91196859e-01 -2.19135880e-02]
 [ 1.59850847e-02  1.49910292e-02  9.99759853e-01]
 [ 6.91359341e-01 -7.22511053e-01 -2.20306916e-04]]
support
[-2.66936253e-02  1.21783867e+00 -2.68362728e-04]
[ -95.38613777 -169.32948707 -385.39323794]
[-274.31623361   -1.17748952  258.82232729]
[ 2.14753163e-01 -9.79764656e+00  2.15900778e-03]
v_real [-0.20414893 -0.18455164 -0.16443156]
zmp_s [0.         3.98761953 0.12019825]
transform [[ 7.22334206e-01  1.59850847e-02  6.91359341e-01]
 [ 6.91196859e-01  1.49910292e-02 -7.22511053e-01]
 [-2.19135880e-02  9.99759853e-01 -2.20306916e-04]]
zmp [ 0.14684262 -0.02706605  3.98663544]
d1:7.73516, d2:0.05940, d3:2.53869
eta 0
transform [[ 0.99802637 -0.05416856 -0.03176724]
 [ 0.03796602  0.11754285  0.99234182]
 [-0.05001967 -0.99158937  0.11936742]]
planes
[[ 0.99802637 -0.05416856 -0.03176724]
 [ 0.03796602  0.11754285  0.99234182]
 [-0.05001967 -0.99158937  0.11936742]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-338.05264  209.98184 -167.11366]
[ -19.22758748 -376.62614399    4.77702579]
[ 0.   0.  -9.8]
transform [[ 0.99802637 -0.05416856 -0.03176724]
 [ 0.03796602  0.11754285  0.99234182]
 [-0.05001967 -0.99158937  0.11936742]]
transform [[ 0.99802637 -0.05416856 -0.03176724]
 [ 0.03796602  0.11754285  0.99234182]
 [-0.05001967 -0.99158937  0.11936742]]
transform [[ 0.99802637 -0.05416856 -0.03176724]
 [ 0.03796602  0.11754285  0.99234182]
 [-0.05001967 -0.99158937  0.11936742]]
support
[-0.03869667  1.20880253  0.14540518]
[-343.45112614 -153.98652541 -211.25440832]
[  1.05990344 -40.25926212 374.99045862]
[ 0.31131897 -9.7249498  -1.16980072]
v_real [-0.4528422 -0.4916708  1.0614496]
zmp_s [0.         2.32008586 0.28668687]
transform [[ 0.99802637  0.03796602 -0.05001967]
 [-0.05416856  0.11754285 -0.99158937]
 [-0.03176724  0.99234182  0.11936742]]
zmp [ 0.07374445 -0.01156615  2.33653929]
d1:4.43181, d2:0.05936, d3:1.21606
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-365.2755001538238 steps:50[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.26734516  0.26778257  0.92564523]
 [-0.6180191  -0.68936568  0.37792507]
 [ 0.73930979 -0.67310286 -0.01880381]]
planes
[[ 0.26734516  0.26778257  0.92564523]
 [-0.6180191  -0.68936568  0.37792507]
 [ 0.73930979 -0.67310286 -0.01880381]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 344.45923 -338.05478  114.20194]
[   7.42502201 -281.78492652  -32.76757686]
[ 0.   0.  -9.8]
transform [[ 0.26734516  0.26778257  0.92564523]
 [-0.6180191  -0.68936568  0.37792507]
 [ 0.73930979 -0.67310286 -0.01880381]]
transform [[ 0.26734516  0.26778257  0.92564523]
 [-0.6180191  -0.68936568  0.37792507]
 [ 0.73930979 -0.67310286 -0.01880381]]
transform [[ 0.26734516  0.26778257  0.92564523]
 [-0.6180191  -0.68936568  0.37792507]
 [ 0.73930979 -0.67310286 -0.01880381]]
support
[ 1.12755734  0.46036232 -0.02290551]
[107.274814    63.32075743 480.06028479]
[-103.8031991   177.28036472  195.77578543]
[-9.07132328 -3.70366567  0.18427733]
v_real [ 0.15118061 -0.22102346 -0.50366914]
zmp_s [ 0.         -2.21772451 -3.73176466]
transform [[ 0.26734516 -0.6180191   0.73930979]
 [ 0.26778257 -0.68936568 -0.67310286]
 [ 0.92564523  0.37792507 -0.01880381]]
zmp [-1.38833402  4.04068462 -0.7679623 ]
d1:5.19984, d2:0.05767, d3:2.26352
eta 0
transform [[ 0.28363761  0.22282355  0.932684  ]
 [-0.59706783  0.80212772 -0.01005919]
 [-0.75037307 -0.55402243  0.36055434]]
planes
[[ 0.28363761  0.22282355  0.932684  ]
 [-0.59706783  0.80212772 -0.01005919]
 [-0.75037307 -0.55402243  0.36055434]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[248.98491 621.5134  121.72458]
[   44.38092091 -1498.35952009   484.47003089]
[ 0.   0.  -9.8]
transform [[ 0.28363761  0.22282355  0.932684  ]
 [-0.59706783  0.80212772 -0.01005919]
 [-0.75037307 -0.55402243  0.36055434]]
transform [[ 0.28363761  0.22282355  0.932684  ]
 [-0.59706783  0.80212772 -0.01005919]
 [-0.75037307 -0.55402243  0.36055434]]
transform [[ 0.28363761  0.22282355  0.932684  ]
 [-0.59706783  0.80212772 -0.01005919]
 [-0.75037307 -0.55402243  0.36055434]]
support
[ 1.13613149 -0.01225342  0.43920249]
[ 322.63987837  348.64781698 -487.27562494]
[  130.57576639 -1233.24750169   971.50030775]
[-9.14030324  0.09858009 -3.53343251]
v_real [ 1.2444131  -0.44377705  0.7599456 ]
zmp_s [ 0.         -4.37500915 -1.71590052]
transform [[ 0.28363761 -0.59706783 -0.75037307]
 [ 0.22282355  0.80212772 -0.55402243]
 [ 0.932684   -0.01005919  0.36055434]]
zmp [ 3.89974277 -2.55866873 -0.57466632]
d1:4.43543, d2:0.05784, d3:0.73347
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-525.333383030704 steps:53[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.71575558  0.69834936 -0.00149778]
 [ 0.00920262 -0.00728739  0.99993116]
 [ 0.69829029 -0.71572    -0.01164263]]
planes
[[ 0.71575558  0.69834936 -0.00149778]
 [ 0.00920262 -0.00728739  0.99993116]
 [ 0.69829029 -0.71572    -0.01164263]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-963.4198   493.55185  384.21277]
[  35.47393852 -103.5453237   -14.00444688]
[ 0.   0.  -9.8]
transform [[ 0.71575558  0.69834936 -0.00149778]
 [ 0.00920262 -0.00728739  0.99993116]
 [ 0.69829029 -0.71572    -0.01164263]]
transform [[ 0.71575558  0.69834936 -0.00149778]
 [ 0.00920262 -0.00728739  0.99993116]
 [ 0.69829029 -0.71572    -0.01164263]]
transform [[ 0.71575558  0.69834936 -0.00149778]
 [ 0.00920262 -0.00728739  0.99993116]
 [ 0.69829029 -0.71572    -0.01164263]]
support
[-0.00182449  1.21804734 -0.01418225]
[ -345.47694958   371.72362819 -1030.46486639]
[-46.89916508 -12.92245424  99.04361424]
[ 0.01467826 -9.79932534  0.11409779]
v_real [-0.86315006  1.114931   -0.19640969]
zmp_s [0.         1.50283469 0.02866562]
transform [[ 0.71575558  0.00920262  0.69829029]
 [ 0.69834936 -0.00728739 -0.71572   ]
 [-0.00149778  0.99993116 -0.01164263]]
zmp [ 0.03384694 -0.0314683   1.50239749]
d1:2.83341, d2:0.05940, d3:0.91710
eta 0
transform [[ 0.66198963 -0.74774712 -0.05142043]
 [-0.01748232 -0.08399091  0.99631315]
 [-0.74930912 -0.65865004 -0.06867347]]
planes
[[ 0.66198963 -0.74774712 -0.05142043]
 [-0.01748232 -0.08399091  0.99631315]
 [-0.74930912 -0.65865004 -0.06867347]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -51.93553 -401.72415 1418.6394 ]
[ -75.969078   1699.1810289   -29.38812162]
[ 0.   0.  -9.8]
transform [[ 0.66198963 -0.74774712 -0.05142043]
 [-0.01748232 -0.08399091  0.99631315]
 [-0.74930912 -0.65865004 -0.06867347]]
transform [[ 0.66198963 -0.74774712 -0.05142043]
 [-0.01748232 -0.08399091  0.99631315]
 [-0.74930912 -0.65865004 -0.06867347]]
transform [[ 0.66198963 -0.74774712 -0.05142043]
 [-0.01748232 -0.08399091  0.99631315]
 [-0.74930912 -0.65865004 -0.06867347]]
support
[-0.06263683  1.21364014 -0.0836533 ]
[ 193.06025024 1448.05823038  206.08850707]
[-1319.33731822  -170.66741617 -1060.22314627]
[ 0.50392019 -9.76386892  0.673     ]
v_real [0.11300948 0.16928756 0.85301584]
zmp_s [ 0.          7.15644112 -0.8984556 ]
transform [[ 0.66198963 -0.01748232 -0.74930912]
 [-0.74774712 -0.08399091 -0.65865004]
 [-0.05142043  0.99631315 -0.06867347]]
zmp [ 0.54810981 -0.00930818  7.19175649]
d1:13.80711, d2:0.05940, d3:4.65046
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-565.6762258639086 steps:56[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.14258246 -0.11191557  0.98343539]
 [-0.6962949   0.69481331  0.18002188]
 [-0.70345128 -0.71042901  0.02114194]]
planes
[[ 0.14258246 -0.11191557  0.98343539]
 [-0.6962949   0.69481331  0.18002188]
 [-0.70345128 -0.71042901  0.02114194]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -51.93553 -401.72415 1418.6394 ]
[ -75.969078   1699.1810289   -29.38812162]
[ 0.   0.  -9.8]
transform [[ 0.14258246 -0.11191557  0.98343539]
 [-0.6962949   0.69481331  0.18002188]
 [-0.70345128 -0.71042901  0.02114194]]
transform [[ 0.14258246 -0.11191557  0.98343539]
 [-0.6962949   0.69481331  0.18002188]
 [-0.70345128 -0.71042901  0.02114194]]
transform [[ 0.14258246 -0.11191557  0.98343539]
 [-0.6962949   0.69481331  0.18002188]
 [-0.70345128 -0.71042901  0.02114194]]
support
[1.19795333 0.21929027 0.02575366]
[1432.69429209   12.42529358  351.9234039 ]
[ -229.89799633  1228.21997374 -1154.32827808]
[-9.63766685 -1.76421444 -0.20719106]
v_real [-0.06092937  0.12908389 -0.36262953]
zmp_s [0.         1.02147676 0.59275876]
transform [[ 0.14258246 -0.6962949  -0.70345128]
 [-0.11191557  0.69481331 -0.71042901]
 [ 0.98343539  0.18002188  0.02114194]]
zmp [-1.12822597  0.28862263  0.19642024]
d1:0.89539, d2:0.03766, d3:0.34308
eta 0
transform [[ 0.71071702 -0.70285696  0.02955383]
 [-0.00613614  0.03581562  0.99933958]
 [-0.70345128 -0.71042901  0.02114194]]
planes
[[ 0.71071702 -0.70285696  0.02955383]
 [-0.00613614  0.03581562  0.99933958]
 [-0.70345128 -0.71042901  0.02114194]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -51.93553 -401.72415 1418.6394 ]
[ -75.969078   1699.1810289   -29.38812162]
[ 0.   0.  -9.8]
transform [[ 0.71071702 -0.70285696  0.02955383]
 [-0.00613614  0.03581562  0.99933958]
 [-0.70345128 -0.71042901  0.02114194]]
transform [[ 0.71071702 -0.70285696  0.02955383]
 [-0.00613614  0.03581562  0.99933958]
 [-0.70345128 -0.71042901  0.02114194]]
transform [[ 0.71071702 -0.70285696  0.02955383]
 [-0.00613614  0.03581562  0.99933958]
 [-0.70345128 -0.71042901  0.02114194]]
support
[0.03600044 1.21732672 0.02575366]
[ 287.3693774  1403.63319154  351.9234039 ]
[-1249.14225739    31.95466363 -1154.32827808]
[-0.28962754 -9.79352789 -0.20719106]
v_real [-0.06092937  0.12908389 -0.36262953]
zmp_s [0.         5.06346855 0.09295702]
transform [[ 0.71071702 -0.00613614 -0.70345128]
 [-0.70285696  0.03581562 -0.71042901]
 [ 0.02955383  0.99933958  0.02114194]]
zmp [-0.09646086  0.11531189  5.06208982]
d1:9.91082, d2:0.05940, d3:3.15238
eta 0
transform [[ 0.4230108   0.17578126  0.88891107]
 [-0.84907866 -0.26568291  0.45659408]
 [ 0.31642914 -0.94789958  0.03686536]]
planes
[[ 0.4230108   0.17578126  0.88891107]
 [-0.84907866 -0.26568291  0.45659408]
 [ 0.31642914 -0.94789958  0.03686536]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1659.4028  -630.6443   928.8397]
[-597.80867638 -823.40996151  385.39704595]
[ 0.   0.  -9.8]
transform [[ 0.4230108   0.17578126  0.88891107]
 [-0.84907866 -0.26568291  0.45659408]
 [ 0.31642914 -0.94789958  0.03686536]]
transform [[ 0.4230108   0.17578126  0.88891107]
 [-0.84907866 -0.26568291  0.45659408]
 [ 0.31642914 -0.94789958  0.03686536]]
transform [[ 0.4230108   0.17578126  0.88891107]
 [-0.84907866 -0.26568291  0.45659408]
 [ 0.31642914 -0.94789958  0.03686536]]
support
[1.08281031 0.55619149 0.04490685]
[  12.85514554 2000.61764986  106.94605853]
[-55.03586891 902.3225479  605.55367366]
[-8.71132847 -4.47462198 -0.36128054]
v_real [-0.18150702  0.06010573  0.18473372]
zmp_s [   0.         -667.18513724  189.94504919]
transform [[ 0.4230108  -0.84907866  0.31642914]
 [ 0.17578126 -0.26568291 -0.94789958]
 [ 0.88891107  0.45659408  0.03686536]]
zmp [ 626.59680734   -2.78914631 -297.63039093]
d1:960.28800, d2:0.05940, d3:384.70673
eta 0
transform [[ 0.93882978  0.31849596  0.13099243]
 [-0.13590914 -0.00683952  0.99069774]
 [ 0.31642914 -0.94789958  0.03686536]]
planes
[[ 0.93882978  0.31849596  0.13099243]
 [-0.13590914 -0.00683952  0.99069774]
 [ 0.31642914 -0.94789958  0.03686536]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-1659.4028  -630.6443   928.8397]
[-597.80867638 -823.40996151  385.39704595]
[ 0.   0.  -9.8]
transform [[ 0.93882978  0.31849596  0.13099243]
 [-0.13590914 -0.00683952  0.99069774]
 [ 0.31642914 -0.94789958  0.03686536]]
transform [[ 0.93882978  0.31849596  0.13099243]
 [-0.13590914 -0.00683952  0.99069774]
 [ 0.31642914 -0.94789958  0.03686536]]
transform [[ 0.93882978  0.31849596  0.13099243]
 [-0.13590914 -0.00683952  0.99069774]
 [ 0.31642914 -0.94789958  0.03686536]]
support
[0.15956596 1.20679983 0.04490685]
[-1637.08348227  1150.04073383   106.94605853]
[-773.0092387   468.69137915  605.55367366]
[-1.28372579 -9.70883787 -0.36128054]
v_real [-0.18150702  0.06010573  0.18473372]
zmp_s [ 0.          1.68746853 -0.23078475]
transform [[ 0.93882978 -0.13590914  0.31642914]
 [ 0.31849596 -0.00683952 -0.94789958]
 [ 0.13099243  0.99069774  0.03686536]]
zmp [-0.30236942  0.20721929  1.66326329]
d1:3.15256, d2:0.05708, d3:1.14579
eta 0
transform [[ 0.50006568  0.13664697  0.8551386 ]
 [-0.20996636  0.97713941 -0.03335853]
 [-0.84014785 -0.16286886  0.51732516]]
planes
[[ 0.50006568  0.13664697  0.8551386 ]
 [-0.20996636  0.97713941 -0.03335853]
 [-0.84014785 -0.16286886  0.51732516]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[1751.8237  -264.35898 -439.94843]
[  41.36170052 -269.40088853  -13.02504151]
[ 0.   0.  -9.8]
transform [[ 0.50006568  0.13664697  0.8551386 ]
 [-0.20996636  0.97713941 -0.03335853]
 [-0.84014785 -0.16286886  0.51732516]]
transform [[ 0.50006568  0.13664697  0.8551386 ]
 [-0.20996636  0.97713941 -0.03335853]
 [-0.84014785 -0.16286886  0.51732516]]
transform [[ 0.50006568  0.13664697  0.8551386 ]
 [-0.20996636  0.97713941 -0.03335853]
 [-0.84014785 -0.16286886  0.51732516]]
support
[ 1.04167101 -0.04063507  0.63016992]
[  463.6861985   -611.46359926 -1656.33149186]
[ -27.26746411 -271.49229571    2.38888928]
[-8.38035828  0.32691359 -5.0697866 ]
v_real [-0.07117047  0.20553888  0.05459842]
zmp_s [0.         1.35230661 3.83491961]
transform [[ 0.50006568 -0.20996636 -0.84014785]
 [ 0.13664697  0.97713941 -0.16286886]
 [ 0.8551386  -0.03335853  0.51732516]]
zmp [-3.50583838  0.69680311  1.93878945]
d1:7.11311, d2:0.05692, d3:2.52121
eta 0
transform [[-0.10137071  0.20610566  0.97326481]
 [-0.84588766 -0.53278786  0.02472334]
 [ 0.52363932 -0.82076657  0.228351  ]]
planes
[[-0.10137071  0.20610566  0.97326481]
 [-0.84588766 -0.53278786  0.02472334]
 [ 0.52363932 -0.82076657  0.228351  ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-571.8258  -115.82328 -780.4283 ]
[ 148.03540583 -755.27490387   -9.28578601]
[ 0.   0.  -9.8]
transform [[-0.10137071  0.20610566  0.97326481]
 [-0.84588766 -0.53278786  0.02472334]
 [ 0.52363932 -0.82076657  0.228351  ]]
transform [[-0.10137071  0.20610566  0.97326481]
 [-0.84588766 -0.53278786  0.02472334]
 [ 0.52363932 -0.82076657  0.228351  ]]
transform [[-0.10137071  0.20610566  0.97326481]
 [-0.84588766 -0.53278786  0.02472334]
 [ 0.52363932 -0.82076657  0.228351  ]]
support
[1.18556424 0.03011627 0.27816147]
[-725.46883151  526.11483863 -382.57817712]
[-179.71041951  276.95040052  695.30113184]
[-9.53799517 -0.24228871 -2.23783977]
v_real [-0.8680686  -1.2080803   0.22041412]
zmp_s [ 0.          1.82432657 -0.7193456 ]
transform [[-0.10137071 -0.84588766  0.52363932]
 [ 0.20610566 -0.53278786 -0.82076657]
 [ 0.97326481  0.02472334  0.228351  ]]
zmp [-1.91985298 -0.38156423 -0.11915984]
d1:3.35384, d2:0.05144, d3:0.80195
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-411.00835853043566 steps:63[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.21852154  0.20485002 -0.95408851]
 [ 0.70811206  0.63944548  0.29947761]
 [ 0.67143553 -0.74104387 -0.00532417]]
planes
[[ 0.21852154  0.20485002 -0.95408851]
 [ 0.70811206  0.63944548  0.29947761]
 [ 0.67143553 -0.74104387 -0.00532417]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-239.4803   302.1691  -541.38916]
[-40.27937293 -23.64345247  18.07509178]
[ 0.   0.  -9.8]
transform [[ 0.21852154  0.20485002 -0.95408851]
 [ 0.70811206  0.63944548  0.29947761]
 [ 0.67143553 -0.74104387 -0.00532417]]
transform [[ 0.21852154  0.20485002 -0.95408851]
 [ 0.70811206  0.63944548  0.29947761]
 [ 0.67143553 -0.74104387 -0.00532417]]
transform [[ 0.21852154  0.20485002 -0.95408851]
 [ 0.70811206  0.63944548  0.29947761]
 [ 0.67143553 -0.74104387 -0.00532417]]
support
[-1.16220498  0.36480302 -0.00648554]
[ 526.10091875 -138.49215463 -381.83369116]
[-30.89050944 -38.22792345  -9.62040179]
[ 9.35006739 -2.93488055  0.05217689]
v_real [ 0.81790525  0.7536434  -0.14393029]
zmp_s [ 0.          0.07580028 -0.90654234]
transform [[ 0.21852154  0.70811206  0.67143553]
 [ 0.20485002  0.63944548 -0.74104387]
 [-0.95408851  0.29947761 -0.00532417]]
zmp [-0.55500965  0.72025778  0.02752707]
d1:0.55403, d2:0.03748, d3:0.43736
eta 0
transform [[ 0.47141168  0.42156512  0.7746315 ]
 [-0.57179141 -0.52262497  0.6323905 ]
 [ 0.67143553 -0.74104387 -0.00532417]]
planes
[[ 0.47141168  0.42156512  0.7746315 ]
 [-0.57179141 -0.52262497  0.6323905 ]
 [ 0.67143553 -0.74104387 -0.00532417]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-239.4803   302.1691  -541.38916]
[-40.27937293 -23.64345247  18.07509178]
[ 0.   0.  -9.8]
transform [[ 0.47141168  0.42156512  0.7746315 ]
 [-0.57179141 -0.52262497  0.6323905 ]
 [ 0.67143553 -0.74104387 -0.00532417]]
transform [[ 0.47141168  0.42156512  0.7746315 ]
 [-0.57179141 -0.52262497  0.6323905 ]
 [ 0.67143553 -0.74104387 -0.00532417]]
transform [[ 0.47141168  0.42156512  0.7746315 ]
 [-0.57179141 -0.52262497  0.6323905 ]
 [ 0.67143553 -0.74104387 -0.00532417]]
support
[ 0.9436028   0.7703346  -0.00648554]
[-404.88695654 -363.35769775 -381.83369116]
[-14.95388598  46.81857439  -9.62040179]
[-7.5913887  -6.19742689  0.05217689]
v_real [ 0.81790525  0.7536434  -0.14393029]
zmp_s [ 0.         -0.09839865 -0.99337051]
transform [[ 0.47141168 -0.57179141  0.67143553]
 [ 0.42156512 -0.52262497 -0.74104387]
 [ 0.7746315   0.6323905  -0.00532417]]
zmp [-0.61072076  0.78755671 -0.05693749]
d1:0.75013, d2:0.04826, d3:0.52581
eta 0
transform [[ 0.56828058  0.49976575  0.65367526]
 [-0.7760585   0.58956951  0.2239221 ]
 [-0.27347842 -0.63454086  0.72288835]]
planes
[[ 0.56828058  0.49976575  0.65367526]
 [-0.7760585   0.58956951  0.2239221 ]
 [-0.27347842 -0.63454086  0.72288835]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-253.7441 -557.4154 -259.3265]
[ 12.29193002 -33.13871446  14.17850233]
[ 0.   0.  -9.8]
transform [[ 0.56828058  0.49976575  0.65367526]
 [-0.7760585   0.58956951  0.2239221 ]
 [-0.27347842 -0.63454086  0.72288835]]
transform [[ 0.56828058  0.49976575  0.65367526]
 [-0.7760585   0.58956951  0.2239221 ]
 [-0.27347842 -0.63454086  0.72288835]]
transform [[ 0.56828058  0.49976575  0.65367526]
 [-0.7760585   0.58956951  0.2239221 ]
 [-0.27347842 -0.63454086  0.72288835]]
support
[0.79626223 0.2727665  0.88057285]
[-592.29029275 -189.78380354  235.63227084]
[ -0.30819335 -25.90195225  27.91576481]
[-6.40601753 -2.19443662 -7.08430583]
v_real [ 0.7633494  -0.47616598  0.2574279 ]
zmp_s [0.         0.06406427 1.2278041 ]
transform [[ 0.56828058 -0.7760585  -0.27347842]
 [ 0.49976575  0.58956951 -0.63454086]
 [ 0.65367526  0.2239221   0.72288835]]
zmp [-0.38549554 -0.74132152  0.90191068]
d1:0.63084, d2:0.02694, d3:0.84231
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-662.503828890379 steps:67[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.70345014  0.69251871  0.15992449]
 [-0.10791767 -0.11832978  0.98709261]
 [ 0.70250386 -0.71162915 -0.00850411]]
planes
[[ 0.70345014  0.69251871  0.15992449]
 [-0.10791767 -0.11832978  0.98709261]
 [ 0.70250386 -0.71162915 -0.00850411]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.8273    26.26757 1274.7493 ]
[  42.17086309 -366.29340939   -9.17582339]
[ 0.   0.  -9.8]
transform [[ 0.70345014  0.69251871  0.15992449]
 [-0.10791767 -0.11832978  0.98709261]
 [ 0.70250386 -0.71162915 -0.00850411]]
transform [[ 0.70345014  0.69251871  0.15992449]
 [-0.10791767 -0.11832978  0.98709261]
 [ 0.70250386 -0.71162915 -0.00850411]]
transform [[ 0.70345014  0.69251871  0.15992449]
 [-0.10791767 -0.11832978  0.98709261]
 [ 0.70250386 -0.71162915 -0.00850411]]
support
[ 0.19480901  1.20240831 -0.01035912]
[-102.11461755 1304.91875811 -353.26633399]
[-225.46737896   29.7350493   290.36829473]
[-1.56726002 -9.67350762  0.08334027]
v_real [ 0.4509431  -0.43385077 -0.17501493]
zmp_s [ 0.          6.43662819 -0.9607497 ]
transform [[ 0.70345014 -0.10791767  0.70250386]
 [ 0.69251871 -0.11832978 -0.71162915]
 [ 0.15992449  0.98709261 -0.00850411]]
zmp [-1.36955627 -0.07794729  6.36171846]
d1:12.46095, d2:0.05936, d3:4.38405
eta 0
transform [[ 0.71148342  0.70254046 -0.01510815]
 [ 0.01672588  0.004563    0.9998498 ]
 [ 0.70250386 -0.71162915 -0.00850411]]
planes
[[ 0.71148342  0.70254046 -0.01510815]
 [ 0.01672588  0.004563    0.9998498 ]
 [ 0.70250386 -0.71162915 -0.00850411]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.8273    26.26757 1274.7493 ]
[  42.17086309 -366.29340939   -9.17582339]
[ 0.   0.  -9.8]
transform [[ 0.71148342  0.70254046 -0.01510815]
 [ 0.01672588  0.004563    0.9998498 ]
 [ 0.70250386 -0.71162915 -0.00850411]]
transform [[ 0.71148342  0.70254046 -0.01510815]
 [ 0.01672588  0.004563    0.9998498 ]
 [ 0.70250386 -0.71162915 -0.00850411]]
transform [[ 0.71148342  0.70254046 -0.01510815]
 [ 0.01672588  0.004563    0.9998498 ]
 [ 0.70250386 -0.71162915 -0.00850411]]
support
[-0.01840371  1.21794823 -0.01035912]
[-328.67605757 1266.96991102 -353.26633399]
[-227.19343974  -10.14049776  290.36829473]
[ 0.14805988 -9.798528    0.08334027]
v_real [ 0.4509431  -0.43385077 -0.17501493]
zmp_s [0.         2.03136955 0.04029219]
transform [[ 0.71148342  0.01672588  0.70250386]
 [ 0.70254046  0.004563   -0.71162915]
 [-0.01510815  0.9998498  -0.00850411]]
zmp [ 0.06228187 -0.01940396  2.03072178]
d1:3.88978, d2:0.05938, d3:1.26068
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-469.2049943000799 steps:70[00m
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-215.13245812499224 steps:71[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.58112854 -0.81363076 -0.01716704]
 [-0.10316656 -0.09457743  0.99015749]
 [-0.80724615 -0.57363772 -0.13890111]]
planes
[[ 0.58112854 -0.81363076 -0.01716704]
 [-0.10316656 -0.09457743  0.99015749]
 [-0.80724615 -0.57363772 -0.13890111]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.8273    26.26757 1274.7493 ]
[  42.17086309 -366.29340939   -9.17582339]
[ 0.   0.  -9.8]
transform [[ 0.58112854 -0.81363076 -0.01716704]
 [-0.10316656 -0.09457743  0.99015749]
 [-0.80724615 -0.57363772 -0.13890111]]
transform [[ 0.58112854 -0.81363076 -0.01716704]
 [-0.10316656 -0.09457743  0.99015749]
 [-0.80724615 -0.57363772 -0.13890111]]
transform [[ 0.58112854 -0.81363076 -0.01716704]
 [-0.10316656 -0.09457743  0.99015749]
 [-0.80724615 -0.57363772 -0.13890111]]
support
[-0.02091171  1.20614173 -0.16919978]
[-311.05567194 1307.26017586  179.86890064]
[322.6917987   21.2069569  177.35198293]
[ 0.168237   -9.70354335  1.36123092]
v_real [-0.25675133 -0.6207854  -0.61029553]
zmp_s [ 0.          1.68933223 -0.24960441]
transform [[ 0.58112854 -0.10316656 -0.80724615]
 [-0.81363076 -0.09457743 -0.57363772]
 [-0.01716704  0.99015749 -0.13890111]]
zmp [ 0.02720961 -0.0165902   1.70737528]
d1:3.09702, d2:0.05935, d3:1.01306
eta 0
transform [[ 0.93750209 -0.2198202  -0.26975718]
 [ 0.15051705 -0.44277459  0.88390917]
 [-0.3137427  -0.86926973 -0.38201541]]
planes
[[ 0.93750209 -0.2198202  -0.26975718]
 [ 0.15051705 -0.44277459  0.88390917]
 [-0.3137427  -0.86926973 -0.38201541]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-460.8273    26.26757 1274.7493 ]
[  42.17086309 -366.29340939   -9.17582339]
[ 0.   0.  -9.8]
transform [[ 0.93750209 -0.2198202  -0.26975718]
 [ 0.15051705 -0.44277459  0.88390917]
 [-0.3137427  -0.86926973 -0.38201541]]
transform [[ 0.93750209 -0.2198202  -0.26975718]
 [ 0.15051705 -0.44277459  0.88390917]
 [-0.3137427  -0.86926973 -0.38201541]]
transform [[ 0.93750209 -0.2198202  -0.26975718]
 [ 0.15051705 -0.44277459  0.88390917]
 [-0.3137427  -0.86926973 -0.38201541]]
support
[-0.32859964  1.07671733 -0.46534489]
[-781.67346813 1045.76958465 -365.22626388]
[122.5292074  160.42225493 308.68227817]
[ 2.64362038 -8.66230983  3.74375099]
v_real [0.46460804 0.7603252  0.5386478 ]
zmp_s [ 0.          1.03549838 -0.518795  ]
transform [[ 0.93750209  0.15051705 -0.3137427 ]
 [-0.2198202  -0.44277459 -0.86926973]
 [-0.26975718  0.88390917 -0.38201541]]
zmp [ 0.3186283  -0.00751959  1.11347419]
d1:1.82815, d2:0.01195, d3:0.78711
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-575.4978237158905 steps:74[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.70651031  0.7039482   0.07280261]
 [-0.04433702 -0.05864217  0.99729407]
 [ 0.70631266 -0.70782626 -0.01022033]]
planes
[[ 0.70651031  0.7039482   0.07280261]
 [-0.04433702 -0.05864217  0.99729407]
 [ 0.70631266 -0.70782626 -0.01022033]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[884.743   645.36206 912.1741 ]
[  77.71497382 -319.0861214   -32.08535508]
[ 0.   0.  -9.8]
transform [[ 0.70651031  0.7039482   0.07280261]
 [-0.04433702 -0.05864217  0.99729407]
 [ 0.70631266 -0.70782626 -0.01022033]]
transform [[ 0.70651031  0.7039482   0.07280261]
 [-0.04433702 -0.05864217  0.99729407]
 [ 0.70631266 -0.70782626 -0.01022033]]
transform [[ 0.70651031  0.7039482   0.07280261]
 [-0.04433702 -0.05864217  0.99729407]
 [ 0.70631266 -0.70782626 -0.01022033]]
support
[ 0.08868313  1.21483502 -0.0124497 ]
[1145.79014826  832.6334948   158.77823757]
[-172.04956845  -16.73228279  281.07652727]
[-0.71346558 -9.77348187  0.10015919]
v_real [ 1.2669938  -0.07194019  0.37559587]
zmp_s [ 0.          0.90564147 -0.03936677]
transform [[ 0.70651031 -0.04433702  0.70631266]
 [ 0.7039482  -0.05864217 -0.70782626]
 [ 0.07280261  0.99729407 -0.01022033]]
zmp [-0.06795869 -0.02524394  0.9035932 ]
d1:1.72086, d2:0.05711, d3:0.52893
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-313.3653420993213 steps:76[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.31205398  0.25339541 -0.91564906]
 [ 0.66282058  0.63241279  0.40090278]
 [ 0.68065506 -0.7320143   0.02939125]]
planes
[[ 0.31205398  0.25339541 -0.91564906]
 [ 0.66282058  0.63241279  0.40090278]
 [ 0.68065506 -0.7320143   0.02939125]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-312.3396  1169.1143   281.98422]
[ -62.99657479 -290.59905857   45.33651102]
[ 0.   0.  -9.8]
transform [[ 0.31205398  0.25339541 -0.91564906]
 [ 0.66282058  0.63241279  0.40090278]
 [ 0.68065506 -0.7320143   0.02939125]]
transform [[ 0.31205398  0.25339541 -0.91564906]
 [ 0.66282058  0.63241279  0.40090278]
 [ 0.68065506 -0.7320143   0.02939125]]
transform [[ 0.31205398  0.25339541 -0.91564906]
 [ 0.66282058  0.63241279  0.40090278]
 [ 0.68065506 -0.7320143   0.02939125]]
support
[-1.11538068  0.48835218  0.0358024 ]
[  -59.41721705   645.38595534 -1060.1160131 ]
[-134.80713245 -207.35845465  171.17622534]
[ 8.97336075 -3.92884722 -0.28803428]
v_real [-0.22165169  0.6173033   0.10992487]
zmp_s [  0.         -10.30171588  27.59342286]
transform [[ 0.31205398  0.66282058  0.68065506]
 [ 0.25339541  0.63241279 -0.7320143 ]
 [-0.91564906  0.40090278  0.02939125]]
zmp [ 11.95341369 -26.71371697  -3.31898123]
d1:37.35292, d2:0.05936, d3:14.75886
eta 0
transform [[ 0.32974857  0.1817334  -0.92641187]
 [ 0.39802492 -0.91658181 -0.0381314 ]
 [-0.856062   -0.35616121 -0.37457597]]
planes
[[ 0.32974857  0.1817334  -0.92641187]
 [ 0.39802492 -0.91658181 -0.0381314 ]
 [-0.856062   -0.35616121 -0.37457597]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[  409.62375 -1203.783    -399.89468]
[-143.06384315 -100.37439945  -81.76654122]
[ 0.   0.  -9.8]
transform [[ 0.32974857  0.1817334  -0.92641187]
 [ 0.39802492 -0.91658181 -0.0381314 ]
 [-0.856062   -0.35616121 -0.37457597]]
transform [[ 0.32974857  0.1817334  -0.92641187]
 [ 0.39802492 -0.91658181 -0.0381314 ]
 [-0.856062   -0.35616121 -0.37457597]]
transform [[ 0.32974857  0.1817334  -0.92641187]
 [ 0.39802492 -0.91658181 -0.0381314 ]
 [-0.856062   -0.35616121 -0.37457597]]
support
[-1.1284912  -0.04644905 -0.45628268]
[ 286.77245694 1281.65456581  227.86840812]
[ 10.33301545  38.1762472  188.84876794]
[9.0788363  0.37368773 3.67084453]
v_real [-0.41475138 -0.27845404  0.4374143 ]
zmp_s [0.         4.20537902 0.55593617]
transform [[ 0.32974857  0.39802492 -0.856062  ]
 [ 0.1817334  -0.91658181 -0.35616121]
 [-0.92641187 -0.0381314  -0.37457597]]
zmp [ 1.19792981 -4.05257681 -0.36859733]
d1:4.49789, d2:0.05751, d3:1.23380
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-340.6408228268143 steps:79[00m
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-211.75715343748303 steps:80[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.71919852  0.69133633 -0.06933679]
 [ 0.01980252  0.07935723  0.99664956]
 [ 0.69452244 -0.71816194  0.0433834 ]]
planes
[[ 0.71919852  0.69133633 -0.06933679]
 [ 0.01980252  0.07935723  0.99664956]
 [ 0.69452244 -0.71816194  0.0433834 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ -26.499252  -14.375631 -598.4615  ]
[ -17.32612966 -139.08401042    9.76600707]
[ 0.   0.  -9.8]
transform [[ 0.71919852  0.69133633 -0.06933679]
 [ 0.01980252  0.07935723  0.99664956]
 [ 0.69452244 -0.71816194  0.0433834 ]]
transform [[ 0.71919852  0.69133633 -0.06933679]
 [ 0.01980252  0.07935723  0.99664956]
 [ 0.69452244 -0.71816194  0.0433834 ]]
transform [[ 0.71919852  0.69133633 -0.06933679]
 [ 0.01980252  0.07935723  0.99664956]
 [ 0.69452244 -0.71816194  0.0433834 ]]
support
[-0.0844613   1.21404993  0.05284667]
[  12.49877712 -598.12194184  -34.04358646]
[-109.29190029   -1.6471361    88.27513953]
[ 0.67950051 -9.76716572 -0.42515729]
v_real [ 1.4650066  -0.477088   -0.55590266]
zmp_s [ 0.         -9.3805247  -0.29305674]
transform [[ 0.71919852  0.01980252  0.69452244]
 [ 0.69133633  0.07935723 -0.71816194]
 [-0.06933679  0.99664956  0.0433834 ]]
zmp [-0.38929254 -0.53395025 -9.36180965]
d1:18.93047, d2:0.05940, d3:6.07124
eta 0
transform [[ 0.6812678  -0.73031467  0.0501466 ]
 [ 0.04995915  0.11472862  0.99213988]
 [-0.73032755 -0.67340761  0.11464681]]
planes
[[ 0.6812678  -0.73031467  0.0501466 ]
 [ 0.04995915  0.11472862  0.99213988]
 [-0.73032755 -0.67340761  0.11464681]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-109.01707 -193.90541  803.9176 ]
[ -38.23688454 -141.44622188   13.09880443]
[ 0.   0.  -9.8]
transform [[ 0.6812678  -0.73031467  0.0501466 ]
 [ 0.04995915  0.11472862  0.99213988]
 [-0.73032755 -0.67340761  0.11464681]]
transform [[ 0.6812678  -0.73031467  0.0501466 ]
 [ 0.04995915  0.11472862  0.99213988]
 [-0.73032755 -0.67340761  0.11464681]]
transform [[ 0.6812678  -0.73031467  0.0501466 ]
 [ 0.04995915  0.11472862  0.99213988]
 [-0.73032755 -0.67340761  0.11464681]]
support
[0.06108514 1.20855654 0.13965485]
[107.65588245 769.9058103  302.36213357]
[ 77.90755349  -5.14236601 124.678149  ]
[-0.49143666 -9.72297078 -1.12353871]
v_real [-0.02148038 -0.02462238 -0.54213506]
zmp_s [ 0.         -0.38818593 -0.08004083]
transform [[ 0.6812678   0.04995915 -0.73032755]
 [-0.73031467  0.11472862 -0.67340761]
 [ 0.0501466   0.99213988  0.11464681]]
zmp [ 0.03906259  0.00936407 -0.39431116]
d1:1.42668, d2:0.05936, d3:0.33607
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-227.40111797344588 steps:83[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.14219889  0.15874416 -0.97702599]
 [ 0.69413745  0.68768221  0.21275905]
 [ 0.70565766 -0.70844442 -0.01240259]]
planes
[[ 0.14219889  0.15874416 -0.97702599]
 [ 0.69413745  0.68768221  0.21275905]
 [ 0.70565766 -0.70844442 -0.01240259]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-467.50656 -149.04532  553.7684 ]
[-168.89455409 -439.82386539   59.15444138]
[ 0.   0.  -9.8]
transform [[ 0.14219889  0.15874416 -0.97702599]
 [ 0.69413745  0.68768221  0.21275905]
 [ 0.70565766 -0.70844442 -0.01240259]]
transform [[ 0.14219889  0.15874416 -0.97702599]
 [ 0.69413745  0.68768221  0.21275905]
 [ 0.70565766 -0.70844442 -0.01240259]]
transform [[ 0.14219889  0.15874416 -0.97702599]
 [ 0.69413745  0.68768221  0.21275905]
 [ 0.70565766 -0.70844442 -0.01240259]]
support
[-1.19014584  0.25916843 -0.01510798]
[-631.18507676 -309.19039708 -231.17742398]
[-151.63151306 -407.10944153  191.67535751]
[ 9.57485466 -2.08503867  0.12154537]
v_real [ 0.22763208  0.21642815 -0.48449713]
zmp_s [0.         1.16349481 1.08220286]
transform [[ 0.14219889  0.69413745  0.70565766]
 [ 0.15874416  0.68768221 -0.70844442]
 [-0.97702599  0.21275905 -0.01240259]]
zmp [1.57129006 0.03343411 0.23412193]
d1:1.57524, d2:0.04555, d3:0.59478
eta 0
transform [[ 0.07599652  0.10657484 -0.99139619]
 [ 0.97377801  0.20588918  0.09677902]
 [ 0.21443194 -0.9727546  -0.08813336]]
planes
[[ 0.07599652  0.10657484 -0.99139619]
 [ 0.97377801  0.20588918  0.09677902]
 [ 0.21443194 -0.9727546  -0.08813336]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-467.50656 -149.04532  553.7684 ]
[-168.89455409 -439.82386539   59.15444138]
[ 0.   0.  -9.8]
transform [[ 0.07599652  0.10657484 -0.99139619]
 [ 0.97377801  0.20588918  0.09677902]
 [ 0.21443194 -0.9727546  -0.08813336]]
transform [[ 0.07599652  0.10657484 -0.99139619]
 [ 0.97377801  0.20588918  0.09677902]
 [ 0.21443194 -0.9727546  -0.08813336]]
transform [[ 0.07599652  0.10657484 -0.99139619]
 [ 0.97377801  0.20588918  0.09677902]
 [ 0.21443194 -0.9727546  -0.08813336]]
support
[-1.20765063  0.11788954 -0.10735799]
[-600.417205   -432.34126755   -4.06928652]
[-118.35504423 -249.29586902  386.41082055]
[ 9.71568265 -0.94843438  0.8637069 ]
v_real [ 0.00140025 -1.3210355  -0.15349539]
zmp_s [0.         1.65787779 0.32122917]
transform [[ 0.07599652  0.97377801  0.21443194]
 [ 0.10657484  0.20588918 -0.9727546 ]
 [-0.99139619  0.09677902 -0.08813336]]
zmp [1.68328673 0.02886195 0.13213678]
d1:1.46267, d2:0.04739, d3:0.99280
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-568.7702933790754 steps:86[00m
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-131.16743859375492 steps:87[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.1738369   0.18839556 -0.9665857 ]
 [ 0.71354485  0.65236771  0.25548032]
 [ 0.67870069 -0.73411411 -0.02102308]]
planes
[[ 0.1738369   0.18839556 -0.9665857 ]
 [ 0.71354485  0.65236771  0.25548032]
 [ 0.67870069 -0.73411411 -0.02102308]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[180.48082   48.069756  63.499187]
[ -1.00985703 -89.69662059  -3.67668325]
[ 0.   0.  -9.8]
transform [[ 0.1738369   0.18839556 -0.9665857 ]
 [ 0.71354485  0.65236771  0.25548032]
 [ 0.67870069 -0.73411411 -0.02102308]]
transform [[ 0.1738369   0.18839556 -0.9665857 ]
 [ 0.71354485  0.65236771  0.25548032]
 [ 0.67870069 -0.73411411 -0.02102308]]
transform [[ 0.1738369   0.18839556 -0.9665857 ]
 [ 0.71354485  0.65236771  0.25548032]
 [ 0.67870069 -0.73411411 -0.02102308]]
support
[-1.17742819  0.31120855 -0.02560887]
[-20.94705126 176.36310771  85.86882185]
[-13.52016603 -60.17507755  65.23945937]
[ 9.47253982 -2.50370713  0.20602616]
v_real [ 0.37750754  0.8715691  -0.75990343]
zmp_s [  0.         -11.84333949  -3.61372462]
transform [[ 0.1738369   0.71354485  0.67870069]
 [ 0.18839556  0.65236771 -0.73411411]
 [-0.9665857   0.25548032 -0.02102308]]
zmp [-10.90339122  -5.07332604  -2.94976854]
d1:16.65675, d2:0.05915, d3:3.63475
eta 0
transform [[ 0.1714642   0.18612354 -0.96744925]
 [ 0.52511036 -0.84814191 -0.07010347]
 [-0.83358216 -0.49599737 -0.24316135]]
planes
[[ 0.1714642   0.18612354 -0.96744925]
 [ 0.52511036 -0.84814191 -0.07010347]
 [-0.83358216 -0.49599737 -0.24316135]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.1714642   0.18612354 -0.96744925]
 [ 0.52511036 -0.84814191 -0.07010347]
 [-0.83358216 -0.49599737 -0.24316135]]
transform [[ 0.1714642   0.18612354 -0.96744925]
 [ 0.52511036 -0.84814191 -0.07010347]
 [-0.83358216 -0.49599737 -0.24316135]]
transform [[ 0.1714642   0.18612354 -0.96744925]
 [ 0.52511036 -0.84814191 -0.07010347]
 [-0.83358216 -0.49599737 -0.24316135]]
support
[-1.17848011 -0.08539523 -0.29620243]
[-2221.61344304  1134.06834183   194.42746995]
[ 74.60364727 336.6030585  120.78491581]
[9.48100263 0.68701404 2.38298123]
v_real [-0.18504447 -1.5347537   0.23047501]
zmp_s [ 0.         -0.63531787 -0.55321247]
transform [[ 0.1714642   0.52511036 -0.83358216]
 [ 0.18612354 -0.84814191 -0.49599737]
 [-0.96744925 -0.07010347 -0.24316135]]
zmp [0.12753606 0.81323164 0.17905788]
d1:0.78844, d2:0.02720, d3:0.30926
eta 0
transform [[ 0.17061146  0.18750028 -0.96733421]
 [ 0.525388   -0.84783858 -0.07167406]
 [-0.83358216 -0.49599737 -0.24316135]]
planes
[[ 0.17061146  0.18750028 -0.96733421]
 [ 0.525388   -0.84783858 -0.07167406]
 [-0.83358216 -0.49599737 -0.24316135]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.17061146  0.18750028 -0.96733421]
 [ 0.525388   -0.84783858 -0.07167406]
 [-0.83358216 -0.49599737 -0.24316135]]
transform [[ 0.17061146  0.18750028 -0.96733421]
 [ 0.525388   -0.84783858 -0.07167406]
 [-0.83358216 -0.49599737 -0.24316135]]
transform [[ 0.17061146  0.18750028 -0.96733421]
 [ 0.525388   -0.84783858 -0.07167406]
 [-0.83358216 -0.49599737 -0.24316135]]
support
[-1.17833998 -0.0873084  -0.29620243]
[-2223.45183015  1130.45995633   194.42746995]
[ 74.05706813 336.72372    120.78491581]
[9.47987527 0.70240575 2.38298123]
v_real [-0.18504447 -1.5347537   0.23047501]
zmp_s [ 0.         -0.63479001 -0.55304098]
transform [[ 0.17061146  0.525388   -0.83358216]
 [ 0.18750028 -0.84783858 -0.49599737]
 [-0.96733421 -0.07167406 -0.24316135]]
zmp [0.12749404 0.81250633 0.17997617]
d1:0.78704, d2:0.02712, d3:0.30962
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-621.2887157035212 steps:91[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.71104747 -0.70172817  0.04459891]
 [-0.01074138  0.05258021  0.99855894]
 [-0.70306194 -0.71050185  0.0298495 ]]
planes
[[ 0.71104747 -0.70172817  0.04459891]
 [-0.01074138  0.05258021  0.99855894]
 [-0.70306194 -0.71050185  0.0298495 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.71104747 -0.70172817  0.04459891]
 [-0.01074138  0.05258021  0.99855894]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.71104747 -0.70172817  0.04459891]
 [-0.01074138  0.05258021  0.99855894]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.71104747 -0.70172817  0.04459891]
 [-0.01074138  0.05258021  0.99855894]
 [-0.70306194 -0.71050185  0.0298495 ]]
support
[0.05432733 1.2163758  0.03636061]
[1160.33118026 1941.6537451  1069.15462613]
[ 290.23383896 -143.34756111  169.32838741]
[-0.43706936 -9.7858776  -0.29252509]
v_real [-0.51261735  0.5409509  -0.6300264 ]
zmp_s [ 0.          0.97990455 -0.13728971]
transform [[ 0.71104747 -0.01074138 -0.70306194]
 [-0.70172817  0.05258021 -0.71050185]
 [ 0.04459891  0.99855894  0.0298495 ]]
zmp [0.08599765 0.14906818 0.97439442]
d1:1.82819, d2:0.05841, d3:0.61157
eta 0
transform [[ 0.70600384 -0.69234991  0.14903109]
 [-0.08522056  0.12585194  0.98838186]
 [-0.70306194 -0.71050185  0.0298495 ]]
planes
[[ 0.70600384 -0.69234991  0.14903109]
 [-0.08522056  0.12585194  0.98838186]
 [-0.70306194 -0.71050185  0.0298495 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.70600384 -0.69234991  0.14903109]
 [-0.08522056  0.12585194  0.98838186]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.70600384 -0.69234991  0.14903109]
 [-0.08522056  0.12585194  0.98838186]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.70600384 -0.69234991  0.14903109]
 [-0.08522056  0.12585194  0.98838186]
 [-0.70306194 -0.71050185  0.0298495 ]]
support
[0.18153942 1.20397878 0.03636061]
[1357.47963691 1809.31938184 1069.15462613]
[ 273.60776003 -172.98266461  169.32838741]
[-1.46050466 -9.68614225 -0.29252509]
v_real [-0.51261735  0.5409509  -0.6300264 ]
zmp_s [ 0.          0.83817808 -0.2343017 ]
transform [[ 0.70600384 -0.08522056 -0.70306194]
 [-0.69234991  0.12585194 -0.71050185]
 [ 0.14903109  0.98838186  0.0298495 ]]
zmp [0.0932986  0.27195813 0.82144622]
d1:1.51680, d2:0.05517, d3:0.55579
eta 0
transform [[ 0.13277088 -0.17238586 -0.97604048]
 [ 0.69862425 -0.68225378  0.2155319 ]
 [-0.70306194 -0.71050185  0.0298495 ]]
planes
[[ 0.13277088 -0.17238586 -0.97604048]
 [ 0.69862425 -0.68225378  0.2155319 ]
 [-0.70306194 -0.71050185  0.0298495 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.13277088 -0.17238586 -0.97604048]
 [ 0.69862425 -0.68225378  0.2155319 ]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.13277088 -0.17238586 -0.97604048]
 [ 0.69862425 -0.68225378  0.2155319 ]
 [-0.70306194 -0.71050185  0.0298495 ]]
transform [[ 0.13277088 -0.17238586 -0.97604048]
 [ 0.69862425 -0.68225378  0.2155319 ]
 [-0.70306194 -0.71050185  0.0298495 ]]
support
[-1.18894536  0.26254613  0.03636061]
[-1713.3739946   1476.73197246  1069.15462613]
[191.09011066 261.28294503 169.32838741]
[ 9.56519673 -2.11221263 -0.29252509]
v_real [-0.51261735  0.5409509  -0.6300264 ]
zmp_s [ 0.         -0.66708514 -0.86286094]
transform [[ 0.13277088  0.69862425 -0.70306194]
 [-0.17238586 -0.68225378 -0.71050185]
 [-0.97604048  0.2155319   0.0298495 ]]
zmp [ 0.14060283  1.06818565 -0.1695341 ]
d1:1.00353, d2:0.04373, d3:0.57091
eta 0
transform [[ 0.95884258 -0.26808158  0.09355862]
 [-0.04541634  0.18045765  0.98253369]
 [-0.2802825  -0.9463442   0.1608552 ]]
planes
[[ 0.95884258 -0.26808158  0.09355862]
 [-0.04541634  0.18045765  0.98253369]
 [-0.2802825  -0.9463442   0.1608552 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[   52.512573 -1471.7809    2022.5189  ]
[  88.86144124 -331.51064395 -125.14250659]
[ 0.   0.  -9.8]
transform [[ 0.95884258 -0.26808158  0.09355862]
 [-0.04541634  0.18045765  0.98253369]
 [-0.2802825  -0.9463442   0.1608552 ]]
transform [[ 0.95884258 -0.26808158  0.09355862]
 [-0.04541634  0.18045765  0.98253369]
 [-0.2802825  -0.9463442   0.1608552 ]]
transform [[ 0.95884258 -0.26808158  0.09355862]
 [-0.04541634  0.18045765  0.98253369]
 [-0.2802825  -0.9463442   0.1608552 ]]
support
[0.11396667 1.19685495 0.19594274]
[ 634.13270225 1719.21393447 1703.4256365 ]
[ 162.36786912 -186.8161226   268.687044  ]
[-0.91687445 -9.62883019 -1.576381  ]
v_real [1.0323133  0.38569725 0.64396656]
zmp_s [ 0.          0.46484108 -0.40538495]
transform [[ 0.95884258 -0.04541634 -0.2802825 ]
 [-0.26808158  0.18045765 -0.9463442 ]
 [ 0.09355862  0.98253369  0.1608552 ]]
zmp [0.09251093 0.46751783 0.39151374]
d1:0.72752, d2:0.05897, d3:0.33782
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-952.7014426196104 steps:96[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.69086248  0.69942325  0.18307422]
 [-0.1469136  -0.11212587  0.98277378]
 [ 0.70790213 -0.70585763  0.02529123]]
planes
[[ 0.69086248  0.69942325  0.18307422]
 [-0.1469136  -0.11212587  0.98277378]
 [ 0.70790213 -0.70585763  0.02529123]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 595.7072  -140.40453 1497.8115 ]
[  28.91508941 -322.69892778  -20.07368807]
[ 0.   0.  -9.8]
transform [[ 0.69086248  0.69942325  0.18307422]
 [-0.1469136  -0.11212587  0.98277378]
 [ 0.70790213 -0.70585763  0.02529123]]
transform [[ 0.69086248  0.69942325  0.18307422]
 [-0.1469136  -0.11212587  0.98277378]
 [ 0.70790213 -0.70585763  0.02529123]]
transform [[ 0.69086248  0.69942325  0.18307422]
 [-0.1469136  -0.11212587  0.98277378]
 [ 0.70790213 -0.70585763  0.02529123]]
support
[0.22300842 1.1971474  0.03080803]
[ 587.56024924 1400.23538079  558.68950813]
[-209.4017585    12.20698489  247.74086708]
[-1.79412737 -9.63118305 -0.24785404]
v_real [ 0.76812404 -0.56345433 -0.15589052]
zmp_s [ 0.          0.24479237 -0.16095827]
transform [[ 0.69086248 -0.1469136   0.70790213]
 [ 0.69942325 -0.11212587 -0.70585763]
 [ 0.18307422  0.98277378  0.02529123]]
zmp [-0.14990603  0.08616607  0.23650469]
d1:0.55631, d2:0.05789, d3:0.17045
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-641.4985770906494 steps:98[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.70434821 -0.69344401  0.15175316]
 [-0.20346349  0.00759289  0.97905314]
 [-0.6800707  -0.72047055 -0.1357425 ]]
planes
[[ 0.70434821 -0.69344401  0.15175316]
 [-0.20346349  0.00759289  0.97905314]
 [-0.6800707  -0.72047055 -0.1357425 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 595.7072  -140.40453 1497.8115 ]
[  28.91508941 -322.69892778  -20.07368807]
[ 0.   0.  -9.8]
transform [[ 0.70434821 -0.69344401  0.15175316]
 [-0.20346349  0.00759289  0.97905314]
 [-0.6800707  -0.72047055 -0.1357425 ]]
transform [[ 0.70434821 -0.69344401  0.15175316]
 [-0.20346349  0.00759289  0.97905314]
 [-0.6800707  -0.72047055 -0.1357425 ]]
transform [[ 0.70434821 -0.69344401  0.15175316]
 [-0.20346349  0.00759289  0.97905314]
 [-0.6800707  -0.72047055 -0.1357425 ]]
support
[ 0.18485526  1.19261518 -0.16535217]
[ 744.24561375 1344.16632733 -507.28237701]
[241.09368549 -27.98658887 215.5556208 ]
[-1.48718094 -9.59472077  1.3302765 ]
v_real [ 0.0304226 -1.0673809 -0.2493875]
zmp_s [ 0.          0.57026183 -0.07711175]
transform [[ 0.70434821 -0.20346349 -0.6800707 ]
 [-0.69344401  0.00759289 -0.72047055]
 [ 0.15175316  0.97905314 -0.1357425 ]]
zmp [-0.06358602  0.05988668  0.56878398]
d1:1.07663, d2:0.05699, d3:0.29108
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-412.76687879858383 steps:100[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.11380131 -0.08763965  0.98963052]
 [-0.70109528  0.69868481  0.14249566]
 [-0.70392805 -0.71004152  0.01806749]]
planes
[[ 0.11380131 -0.08763965  0.98963052]
 [-0.70109528  0.69868481  0.14249566]
 [-0.70392805 -0.71004152  0.01806749]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 595.7072  -140.40453 1497.8115 ]
[  28.91508941 -322.69892778  -20.07368807]
[ 0.   0.  -9.8]
transform [[ 0.11380131 -0.08763965  0.98963052]
 [-0.70109528  0.69868481  0.14249566]
 [-0.70392805 -0.71004152  0.01806749]]
transform [[ 0.11380131 -0.08763965  0.98963052]
 [-0.70109528  0.69868481  0.14249566]
 [-0.70392805 -0.71004152  0.01806749]]
transform [[ 0.11380131 -0.08763965  0.98963052]
 [-0.70109528  0.69868481  0.14249566]
 [-0.70392805 -0.71004152  0.01806749]]
support
[1.20549981 0.17357841 0.02200858]
[1562.37726128 -302.31438313 -292.58027572]
[  11.70626242 -248.59748582  208.41281431]
[-9.6983791  -1.39645749 -0.17706144]
v_real [ 0.16915762 -0.20453468 -0.38453692]
zmp_s [0.        0.2751516 0.0891966]
transform [[ 0.11380131 -0.70109528 -0.70392805]
 [-0.08763965  0.69868481 -0.71004152]
 [ 0.98963052  0.14249566  0.01806749]]
zmp [-0.25569548  0.12891095  0.04081947]
d1:0.41488, d2:0.00597, d3:0.10624
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-196.90095539096288 steps:102[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.32466823  0.28900814  0.90059143]
 [-0.61985147 -0.65418237  0.43339312]
 [ 0.71440518 -0.69894189 -0.03325011]]
planes
[[ 0.32466823  0.28900814  0.90059143]
 [-0.61985147 -0.65418237  0.43339312]
 [ 0.71440518 -0.69894189 -0.03325011]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.1016  788.9933 1968.9603]
[ 107.16111256 -656.70062216  -24.11473048]
[ 0.   0.  -9.8]
transform [[ 0.32466823  0.28900814  0.90059143]
 [-0.61985147 -0.65418237  0.43339312]
 [ 0.71440518 -0.69894189 -0.03325011]]
transform [[ 0.32466823  0.28900814  0.90059143]
 [-0.61985147 -0.65418237  0.43339312]
 [ 0.71440518 -0.69894189 -0.03325011]]
transform [[ 0.32466823  0.28900814  0.90059143]
 [-0.61985147 -0.65418237  0.43339312]
 [ 0.71440518 -0.69894189 -0.03325011]]
support
[ 1.09703852  0.52792968 -0.04050299]
[2137.97259346   76.16791803 -316.09144108]
[-176.71753681  352.72684088  536.35384287]
[-8.82579604 -4.24725258  0.32585106]
v_real [ 0.03284419 -0.07500583 -0.7674135 ]
zmp_s [0.         0.23896248 0.28786039]
transform [[ 0.32466823 -0.61985147  0.71440518]
 [ 0.28900814 -0.65418237 -0.69894189]
 [ 0.90059143  0.43339312 -0.03325011]]
zmp [ 0.05752771 -0.35752273  0.09399331]
d1:0.32539, d2:0.02200, d3:0.14471
eta 0
transform [[ 0.8174907   0.39208022 -0.42187929]
 [ 0.26784825  0.38965452  0.88115084]
 [ 0.50986898 -0.83333212  0.21352093]]
planes
[[ 0.8174907   0.39208022 -0.42187929]
 [ 0.26784825  0.38965452  0.88115084]
 [ 0.50986898 -0.83333212  0.21352093]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.1016  788.9933 1968.9603]
[ 107.16111256 -656.70062216  -24.11473048]
[ 0.   0.  -9.8]
transform [[ 0.8174907   0.39208022 -0.42187929]
 [ 0.26784825  0.38965452  0.88115084]
 [ 0.50986898 -0.83333212  0.21352093]]
transform [[ 0.8174907   0.39208022 -0.42187929]
 [ 0.26784825  0.38965452  0.88115084]
 [ 0.50986898 -0.83333212  0.21352093]]
transform [[ 0.8174907   0.39208022 -0.42187929]
 [ 0.26784825  0.38965452  0.88115084]
 [ 0.50986898 -0.83333212  0.21352093]]
support
[-0.51390433  1.07335733  0.26009651]
[-177.06829382 2155.17717366  -22.37257076]
[-159.70260484 -248.4321621   596.73885001]
[ 4.13441706 -8.63527825 -2.09250511]
v_real [0.7976173  1.0534462  0.24301213]
zmp_s [ 0.         -1.85480417  1.76937205]
transform [[ 0.8174907   0.26784825  0.50986898]
 [ 0.39208022  0.38965452 -0.83333212]
 [-0.42187929  0.88115084  0.21352093]]
zmp [ 0.40534186 -2.19720738 -1.25656429]
d1:3.79223, d2:0.05869, d3:0.89177
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-503.1039853590604 steps:105[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.21986975 -0.21758455 -0.95095444]
 [ 0.68870145 -0.65577191  0.3092792 ]
 [-0.69090354 -0.72292477  0.0056664 ]]
planes
[[ 0.21986975 -0.21758455 -0.95095444]
 [ 0.68870145 -0.65577191  0.3092792 ]
 [-0.69090354 -0.72292477  0.0056664 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.1016  788.9933 1968.9603]
[ 107.16111256 -656.70062216  -24.11473048]
[ 0.   0.  -9.8]
transform [[ 0.21986975 -0.21758455 -0.95095444]
 [ 0.68870145 -0.65577191  0.3092792 ]
 [-0.69090354 -0.72292477  0.0056664 ]]
transform [[ 0.21986975 -0.21758455 -0.95095444]
 [ 0.68870145 -0.65577191  0.3092792 ]
 [-0.69090354 -0.72292477  0.0056664 ]]
transform [[ 0.21986975 -0.21758455 -0.95095444]
 [ 0.68870145 -0.65577191  0.3092792 ]
 [-0.69090354 -0.72292477  0.0056664 ]]
support
[-1.15838727  0.37674265  0.00690242]
[-1951.47680826   381.57212446  -850.16645851]
[189.38140635 496.9896511  400.57050937]
[ 9.31935349 -3.03093619 -0.0555307 ]
v_real [ 0.47554836  0.41738757 -0.0669935 ]
zmp_s [0.         0.35721448 0.25811618]
transform [[ 0.21986975  0.68870145 -0.69090354]
 [-0.21758455 -0.65577191 -0.72292477]
 [-0.95095444  0.3092792   0.0056664 ]]
zmp [ 0.06768075 -0.4208498   0.1119416 ]
d1:0.35378, d2:0.01263, d3:0.11821
eta 0
transform [[ 0.72248214 -0.69071913 -0.03044324]
 [ 0.02592206 -0.01693947  0.99952042]
 [-0.69090354 -0.72292477  0.0056664 ]]
planes
[[ 0.72248214 -0.69071913 -0.03044324]
 [ 0.02592206 -0.01693947  0.99952042]
 [-0.69090354 -0.72292477  0.0056664 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[ 421.1016  788.9933 1968.9603]
[ 107.16111256 -656.70062216  -24.11473048]
[ 0.   0.  -9.8]
transform [[ 0.72248214 -0.69071913 -0.03044324]
 [ 0.02592206 -0.01693947  0.99952042]
 [-0.69090354 -0.72292477  0.0056664 ]]
transform [[ 0.72248214 -0.69071913 -0.03044324]
 [ 0.02592206 -0.01693947  0.99952042]
 [-0.69090354 -0.72292477  0.0056664 ]]
transform [[ 0.72248214 -0.69071913 -0.03044324]
 [ 0.02592206 -0.01693947  0.99952042]
 [-0.69090354 -0.72292477  0.0056664 ]]
support
[-0.03708386  1.21754701  0.00690242]
[-300.67590758 1965.56674888 -850.16645851]
[531.75180188 -10.20116915 400.57050937]
[ 0.29834377 -9.79530013 -0.0555307 ]
v_real [ 0.47554836  0.41738757 -0.0669935 ]
zmp_s [0.         2.30964905 0.14582985]
transform [[ 0.72248214  0.02592206 -0.69090354]
 [-0.69071913 -0.01693947 -0.72292477]
 [-0.03044324  0.99952042  0.0056664 ]]
zmp [-0.0408835  -0.14454824  2.30936772]
d1:4.44084, d2:0.05937, d3:1.44595
eta 0
transform [[ 0.9217962   0.21095498  0.32525334]
 [-0.29760444 -0.15260395  0.94241381]
 [ 0.24844182 -0.96551031 -0.0778886 ]]
planes
[[ 0.9217962   0.21095498  0.32525334]
 [-0.29760444 -0.15260395  0.94241381]
 [ 0.24844182 -0.96551031 -0.0778886 ]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-392.36148 -637.47375  868.80865]
[-102.0656101  -389.38864988  173.18973225]
[ 0.   0.  -9.8]
transform [[ 0.9217962   0.21095498  0.32525334]
 [-0.29760444 -0.15260395  0.94241381]
 [ 0.24844182 -0.96551031 -0.0778886 ]]
transform [[ 0.9217962   0.21095498  0.32525334]
 [-0.29760444 -0.15260395  0.94241381]
 [ 0.24844182 -0.96551031 -0.0778886 ]]
transform [[ 0.9217962   0.21095498  0.32525334]
 [-0.29760444 -0.15260395  0.94241381]
 [ 0.24844182 -0.96551031 -0.0778886 ]]
support
[ 0.39620124  1.14798366 -0.09487853]
[-213.57267088 1032.82680684  450.33819309]
[-119.89662784  253.01382144  337.11188423]
[-3.18748271 -9.23565531  0.76330829]
v_real [ 0.4529873  -0.07966758 -0.17797393]
zmp_s [ 0.          4.57416672 -0.43759304]
transform [[ 0.9217962  -0.29760444  0.24844182]
 [ 0.21095498 -0.15260395 -0.96551031]
 [ 0.32525334  0.94241381 -0.0778886 ]]
zmp [-1.47000874 -0.27553534  4.34484138]
d1:7.33577, d2:0.05901, d3:3.09863
eta 0
transform [[ 0.47493172  0.52750981  0.70439565]
 [-0.60207289  0.77855182 -0.17710249]
 [-0.64183182 -0.33998594  0.68735838]]
planes
[[ 0.47493172  0.52750981  0.70439565]
 [-0.60207289  0.77855182 -0.17710249]
 [-0.64183182 -0.33998594  0.68735838]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-392.36148 -637.47375  868.80865]
[-102.0656101  -389.38864988  173.18973225]
[ 0.   0.  -9.8]
transform [[ 0.47493172  0.52750981  0.70439565]
 [-0.60207289  0.77855182 -0.17710249]
 [-0.64183182 -0.33998594  0.68735838]]
transform [[ 0.47493172  0.52750981  0.70439565]
 [-0.60207289  0.77855182 -0.17710249]
 [-0.64183182 -0.33998594  0.68735838]]
transform [[ 0.47493172  0.52750981  0.70439565]
 [-0.60207289  0.77855182 -0.17710249]
 [-0.64183182 -0.33998594  0.68735838]]
support
[ 0.85804632 -0.21573407  0.83729269]
[  89.36646862 -413.94431489 1065.74510212]
[-131.88643325 -272.38063659  316.93903443]
[-6.90307739  1.73560441 -6.73611212]
v_real [-0.3493052 -1.5183903 -0.6228412]
zmp_s [  0.           0.22998048 -13.48493426]
transform [[ 0.47493172 -0.60207289 -0.64183182]
 [ 0.52750981  0.77855182 -0.33998594]
 [ 0.70439565 -0.17710249  0.68735838]]
zmp [ 8.51659482  4.76373972 -9.30971267]
d1:23.06483, d2:0.05929, d3:10.04505
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-958.5240099598635 steps:110[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.73412645 -0.67722368  0.0492596 ]
 [ 0.01248992  0.08600175  0.99621671]
 [-0.67889798 -0.73073375  0.07159462]]
planes
[[ 0.73412645 -0.67722368  0.0492596 ]
 [ 0.01248992  0.08600175  0.99621671]
 [-0.67889798 -0.73073375  0.07159462]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-392.36148 -637.47375  868.80865]
[-102.0656101  -389.38864988  173.18973225]
[ 0.   0.  -9.8]
transform [[ 0.73412645 -0.67722368  0.0492596 ]
 [ 0.01248992  0.08600175  0.99621671]
 [-0.67889798 -0.73073375  0.07159462]]
transform [[ 0.73412645 -0.67722368  0.0492596 ]
 [ 0.01248992  0.08600175  0.99621671]
 [-0.67889798 -0.73073375  0.07159462]]
transform [[ 0.73412645 -0.67722368  0.0492596 ]
 [ 0.01248992  0.08600175  0.99621671]
 [-0.67889798 -0.73073375  0.07159462]]
support
[0.06000465 1.21352266 0.08721164]
[186.46654627 805.79728399 794.39902831]
[197.30540765 137.77161087 366.23101818]
[-0.48274404 -9.7629238  -0.70162726]
v_real [0.3028249  0.81574124 0.21869077]
zmp_s [ 0.         -1.01246034  0.57191017]
transform [[ 0.73412645  0.01248992 -0.67889798]
 [-0.67722368  0.08600175 -0.73073375]
 [ 0.0492596   0.99621671  0.07159462]]
zmp [-0.40091421 -0.50498742 -0.96768422]
d1:2.11497, d2:0.05938, d3:0.97712
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-197.09299960764767 steps:112[00m
[RDDPG] Resetting Environment
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-54.361258906244124 steps:113[00m
[RDDPG] Resetting Environment
eta 0
transform [[ 0.64880729 -0.75906384  0.05358363]
 [-0.04072783  0.0356762   0.99853319]
 [-0.75986212 -0.65003794 -0.00776805]]
planes
[[ 0.64880729 -0.75906384  0.05358363]
 [-0.04072783  0.0356762   0.99853319]
 [-0.75986212 -0.65003794 -0.00776805]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-392.36148 -637.47375  868.80865]
[-102.0656101  -389.38864988  173.18973225]
[ 0.   0.  -9.8]
transform [[ 0.64880729 -0.75906384  0.05358363]
 [-0.04072783  0.0356762   0.99853319]
 [-0.75986212 -0.65003794 -0.00776805]]
transform [[ 0.64880729 -0.75906384  0.05358363]
 [-0.04072783  0.0356762   0.99853319]
 [-0.75986212 -0.65003794 -0.00776805]]
transform [[ 0.64880729 -0.75906384  0.05358363]
 [-0.04072783  0.0356762   0.99853319]
 [-0.75986212 -0.65003794 -0.00776805]]
support
[ 0.06527189  1.21634443 -0.0094625 ]
[275.87020608 860.77166568 705.77381196]
[238.63006597 163.20069788 329.32784305]
[-0.52511953 -9.78562526  0.07612685]
v_real [-0.01225332  0.55087525 -0.02564068]
zmp_s [ 0.         -0.18144084  0.41592567]
transform [[ 0.64880729 -0.04072783 -0.75986212]
 [-0.75906384  0.0356762  -0.65003794]
 [ 0.05358363  0.99853319 -0.00776805]]
zmp [-0.30865647 -0.27684058 -0.18440563]
d1:0.61413, d2:0.05934, d3:0.37941
eta 0
transform [[ 0.16850907 -0.18540972 -0.96810532]
 [ 0.6278649  -0.73693556  0.2504231 ]
 [-0.75986212 -0.65003794 -0.00776805]]
planes
[[ 0.16850907 -0.18540972 -0.96810532]
 [ 0.6278649  -0.73693556  0.2504231 ]
 [-0.75986212 -0.65003794 -0.00776805]]
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
inertial
[0.        0.        1.2181312]
[-392.36148 -637.47375  868.80865]
[-102.0656101  -389.38864988  173.18973225]
[ 0.   0.  -9.8]
transform [[ 0.16850907 -0.18540972 -0.96810532]
 [ 0.6278649  -0.73693556  0.2504231 ]
 [-0.75986212 -0.65003794 -0.00776805]]
transform [[ 0.16850907 -0.18540972 -0.96810532]
 [ 0.6278649  -0.73693556  0.2504231 ]
 [-0.75986212 -0.65003794 -0.00776805]]
transform [[ 0.16850907 -0.18540972 -0.96810532]
 [ 0.6278649  -0.73693556  0.2504231 ]
 [-0.75986212 -0.65003794 -0.00776805]]
support
[-1.17927929  0.3050482  -0.0094625 ]
[-789.02091071  440.99683492  705.77381196]
[-112.66843876  266.24163763  329.32784305]
[ 9.4874321  -2.45414641  0.07612685]
v_real [-0.01225332  0.55087525 -0.02564068]
zmp_s [ 0.          0.06408809 -1.41881294]
transform [[ 0.16850907  0.6278649  -0.75986212]
 [-0.18540972 -0.73693556 -0.65003794]
 [-0.96810532  0.2504231  -0.00776805]]
zmp [1.11834088 0.87505345 0.02707054]
d1:1.21916, d2:0.04582, d3:0.69874
eta 0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-352.60831888882984 steps:116[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620124425.162618347, 76.377000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620124425.162723596, 76.377000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620124426.165347259, 76.377000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620124426.165462902, 76.377000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620124427.796963055, 76.377000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620124427.797098032, 76.377000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620124428.798178587, 76.377000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620124428.798296960, 76.377000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 959, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 16:04:59.584482: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 16:04:59.584534: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620124506.720327077, 1.349000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620124506.724406688, 1.351000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620124506.724728438, 1.351000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620124508.427132870, 2.503000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620124509.516465437, 3.318000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620124510.597883161, 4.118000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620124511.708705920, 4.918000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
transform [[ 0.71133989 -0.70232868 -0.02702121]
 [ 0.02938673 -0.0086919   0.99953032]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71133989 -0.70232868 -0.02702121]
 [ 0.02938673 -0.0086919   0.99953032]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71133989 -0.70232868 -0.02702121]
 [ 0.02938673 -0.0086919   0.99953032]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71133989 -0.70232868 -0.02702121]
 [ 0.02938673 -0.0086919   0.99953032]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71133989  0.02938673 -0.70223361]
 [-0.70232868 -0.0086919  -0.71179986]
 [-0.02702121  0.99953032  0.01445625]]
transform [[ 0.71089524 -0.70215517 -0.04007771]
 [ 0.03867783 -0.01786704  0.99909198]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71089524 -0.70215517 -0.04007771]
 [ 0.03867783 -0.01786704  0.99909198]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71089524 -0.70215517 -0.04007771]
 [ 0.03867783 -0.01786704  0.99909198]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71089524 -0.70215517 -0.04007771]
 [ 0.03867783 -0.01786704  0.99909198]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71089524  0.03867783 -0.70223361]
 [-0.70215517 -0.01786704 -0.71179986]
 [-0.04007771  0.99909198  0.01445625]]
transform [[ 0.71183842 -0.70162809  0.03168775]
 [-0.01241243  0.03254272  0.99939328]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71183842 -0.70162809  0.03168775]
 [-0.01241243  0.03254272  0.99939328]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71183842 -0.70162809  0.03168775]
 [-0.01241243  0.03254272  0.99939328]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71183842 -0.70162809  0.03168775]
 [-0.01241243  0.03254272  0.99939328]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71183842 -0.01241243 -0.70223361]
 [-0.70162809  0.03254272 -0.71179986]
 [ 0.03168775  0.99939328  0.01445625]]
transform [[ 0.71134692 -0.70066428  0.05527346]
 [-0.02921466  0.04909829  0.99836659]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71134692 -0.70066428  0.05527346]
 [-0.02921466  0.04909829  0.99836659]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71134692 -0.70066428  0.05527346]
 [-0.02921466  0.04909829  0.99836659]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71134692 -0.70066428  0.05527346]
 [-0.02921466  0.04909829  0.99836659]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71134692 -0.02921466 -0.70223361]
 [-0.70066428  0.04909829 -0.71179986]
 [ 0.05527346  0.99836659  0.01445625]]
transform [[ 0.71056795 -0.69946623  0.07642134]
 [-0.04428504  0.06393778  0.99697083]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71056795 -0.69946623  0.07642134]
 [-0.04428504  0.06393778  0.99697083]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71056795 -0.69946623  0.07642134]
 [-0.04428504  0.06393778  0.99697083]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71056795 -0.69946623  0.07642134]
 [-0.04428504  0.06393778  0.99697083]
 [-0.70223361 -0.71179986  0.01445625]]
transform [[ 0.71056795 -0.04428504 -0.70223361]
 [-0.69946623  0.06393778 -0.71179986]
 [ 0.07642134  0.99697083  0.01445625]]
transform [[ 0.08951228  0.19547945  0.97661424]
 [-0.67591041 -0.70826828  0.20371827]
 [ 0.73152763 -0.67833906  0.06872785]]
transform [[ 0.08951228  0.19547945  0.97661424]
 [-0.67591041 -0.70826828  0.20371827]
 [ 0.73152763 -0.67833906  0.06872785]]
transform [[ 0.08951228  0.19547945  0.97661424]
 [-0.67591041 -0.70826828  0.20371827]
 [ 0.73152763 -0.67833906  0.06872785]]
transform [[ 0.08951228  0.19547945  0.97661424]
 [-0.67591041 -0.70826828  0.20371827]
 [ 0.73152763 -0.67833906  0.06872785]]
transform [[ 0.08951228 -0.67591041  0.73152763]
 [ 0.19547945 -0.70826828 -0.67833906]
 [ 0.97661424  0.20371827  0.06872785]]
transform [[ 0.0660873   0.16232431  0.98452187]
 [ 0.76105803  0.62990719 -0.15494376]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.0660873   0.16232431  0.98452187]
 [ 0.76105803  0.62990719 -0.15494376]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.0660873   0.16232431  0.98452187]
 [ 0.76105803  0.62990719 -0.15494376]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.0660873   0.16232431  0.98452187]
 [ 0.76105803  0.62990719 -0.15494376]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.0660873   0.76105803 -0.64530855]
 [ 0.16232431  0.62990719  0.75951809]
 [ 0.98452187 -0.15494376 -0.08190934]]
transform [[ 0.06612314  0.16235398  0.98451459]
 [ 0.76105499  0.62989962 -0.15499014]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06612314  0.16235398  0.98451459]
 [ 0.76105499  0.62989962 -0.15499014]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06612314  0.16235398  0.98451459]
 [ 0.76105499  0.62989962 -0.15499014]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06612314  0.16235398  0.98451459]
 [ 0.76105499  0.62989962 -0.15499014]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06612314  0.76105499 -0.64530855]
 [ 0.16235398  0.62989962  0.75951809]
 [ 0.98451459 -0.15499014 -0.08190934]]
transform [[ 0.06611452  0.16234683  0.98451632]
 [ 0.76105571  0.62990141 -0.15497896]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611452  0.16234683  0.98451632]
 [ 0.76105571  0.62990141 -0.15497896]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611452  0.16234683  0.98451632]
 [ 0.76105571  0.62990141 -0.15497896]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611452  0.16234683  0.98451632]
 [ 0.76105571  0.62990141 -0.15497896]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611452  0.76105571 -0.64530855]
 [ 0.16234683  0.62990141  0.75951809]
 [ 0.98451632 -0.15497896 -0.08190934]]
transform [[ 0.06611092  0.16234384  0.98451704]
 [ 0.76105601  0.62990218 -0.15497431]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611092  0.16234384  0.98451704]
 [ 0.76105601  0.62990218 -0.15497431]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611092  0.16234384  0.98451704]
 [ 0.76105601  0.62990218 -0.15497431]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611092  0.16234384  0.98451704]
 [ 0.76105601  0.62990218 -0.15497431]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06611092  0.76105601 -0.64530855]
 [ 0.16234384  0.62990218  0.75951809]
 [ 0.98451704 -0.15497431 -0.08190934]]
transform [[ 0.06610154  0.1623361   0.98451895]
 [ 0.76105678  0.62990421 -0.15496218]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06610154  0.1623361   0.98451895]
 [ 0.76105678  0.62990421 -0.15496218]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06610154  0.1623361   0.98451895]
 [ 0.76105678  0.62990421 -0.15496218]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06610154  0.1623361   0.98451895]
 [ 0.76105678  0.62990421 -0.15496218]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06610154  0.76105678 -0.64530855]
 [ 0.1623361   0.62990421  0.75951809]
 [ 0.98451895 -0.15496218 -0.08190934]]
transform [[ 0.06599051  0.1622442   0.98454159]
 [ 0.7610665   0.62992787 -0.15481855]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06599051  0.1622442   0.98454159]
 [ 0.7610665   0.62992787 -0.15481855]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06599051  0.1622442   0.98454159]
 [ 0.7610665   0.62992787 -0.15481855]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06599051  0.1622442   0.98454159]
 [ 0.7610665   0.62992787 -0.15481855]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06599051  0.7610665  -0.64530855]
 [ 0.1622442   0.62992787  0.75951809]
 [ 0.98454159 -0.15481855 -0.08190934]]
transform [[ 0.06588051  0.16215314  0.98456395]
 [ 0.76107603  0.6299513  -0.15467624]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06588051  0.16215314  0.98456395]
 [ 0.76107603  0.6299513  -0.15467624]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06588051  0.16215314  0.98456395]
 [ 0.76107603  0.6299513  -0.15467624]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06588051  0.16215314  0.98456395]
 [ 0.76107603  0.6299513  -0.15467624]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06588051  0.76107603 -0.64530855]
 [ 0.16215314  0.6299513   0.75951809]
 [ 0.98456395 -0.15467624 -0.08190934]]
transform [[ 0.06586499  0.16214029  0.98456711]
 [ 0.76107734  0.62995464 -0.15465616]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06586499  0.16214029  0.98456711]
 [ 0.76107734  0.62995464 -0.15465616]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06586499  0.16214029  0.98456711]
 [ 0.76107734  0.62995464 -0.15465616]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06586499  0.16214029  0.98456711]
 [ 0.76107734  0.62995464 -0.15465616]
 [-0.64530855  0.75951809 -0.08190934]]
transform [[ 0.06586499  0.76107734 -0.64530855]
 [ 0.16214029  0.62995464  0.75951809]
 [ 0.98456711 -0.15465616 -0.08190934]]
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
transform [[ 0.16025461 -0.08712796 -0.9832229 ]
 [ 0.98492557  0.079826    0.15345839]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.16025461 -0.08712796 -0.9832229 ]
 [ 0.98492557  0.079826    0.15345839]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.16025461 -0.08712796 -0.9832229 ]
 [ 0.98492557  0.079826    0.15345839]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.16025461 -0.08712796 -0.9832229 ]
 [ 0.98492557  0.079826    0.15345839]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.16025461  0.98492557  0.06511623]
 [-0.08712796  0.079826   -0.99299371]
 [-0.9832229   0.15345839  0.09860703]]
transform [[ 0.17078087 -0.08626909 -0.98152512]
 [ 0.98315501  0.08075342  0.16396682]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.17078087 -0.08626909 -0.98152512]
 [ 0.98315501  0.08075342  0.16396682]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.17078087 -0.08626909 -0.98152512]
 [ 0.98315501  0.08075342  0.16396682]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.17078087 -0.08626909 -0.98152512]
 [ 0.98315501  0.08075342  0.16396682]
 [ 0.06511623 -0.99299371  0.09860703]]
transform [[ 0.17078087  0.98315501  0.06511623]
 [-0.08626909  0.08075342 -0.99299371]
 [-0.98152512  0.16396682  0.09860703]]
transform [[ 0.20094272 -0.19244732 -0.96051347]
 [ 0.94774187 -0.20984332  0.24031481]
 [-0.24780525 -0.95860827  0.14022388]]
transform [[ 0.20094272 -0.19244732 -0.96051347]
 [ 0.94774187 -0.20984332  0.24031481]
 [-0.24780525 -0.95860827  0.14022388]]
transform [[ 0.20094272 -0.19244732 -0.96051347]
 [ 0.94774187 -0.20984332  0.24031481]
 [-0.24780525 -0.95860827  0.14022388]]
transform [[ 0.20094272 -0.19244732 -0.96051347]
 [ 0.94774187 -0.20984332  0.24031481]
 [-0.24780525 -0.95860827  0.14022388]]
transform [[ 0.20094272  0.94774187 -0.24780525]
 [-0.19244732 -0.20984332 -0.95860827]
 [-0.96051347  0.24031481  0.14022388]]
transform [[ 0.19450554 -0.97893065  0.06214796]
 [-0.29097471  0.00292401  0.95672631]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19450554 -0.97893065  0.06214796]
 [-0.29097471  0.00292401  0.95672631]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19450554 -0.97893065  0.06214796]
 [-0.29097471  0.00292401  0.95672631]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19450554 -0.97893065  0.06214796]
 [-0.29097471  0.00292401  0.95672631]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19450554 -0.29097471 -0.93675041]
 [-0.97893065  0.00292401 -0.20417209]
 [ 0.06214796  0.95672631 -0.28427532]]
transform [[ 0.19230959 -0.97888094  0.0693483 ]
 [-0.29243067  0.01029317  0.9562313 ]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19230959 -0.97888094  0.0693483 ]
 [-0.29243067  0.01029317  0.9562313 ]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19230959 -0.97888094  0.0693483 ]
 [-0.29243067  0.01029317  0.9562313 ]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19230959 -0.97888094  0.0693483 ]
 [-0.29243067  0.01029317  0.9562313 ]
 [-0.93675041 -0.20417209 -0.28427532]]
transform [[ 0.19230959 -0.29243067 -0.93675041]
 [-0.97888094  0.01029317 -0.20417209]
 [ 0.0693483   0.9562313  -0.28427532]]
transform [[-0.24922214  0.48268545 -0.83958507]
 [ 0.69592565 -0.5136295  -0.50186884]
 [-0.67348045 -0.70936561 -0.20790538]]
transform [[-0.24922214  0.48268545 -0.83958507]
 [ 0.69592565 -0.5136295  -0.50186884]
 [-0.67348045 -0.70936561 -0.20790538]]
transform [[-0.24922214  0.48268545 -0.83958507]
 [ 0.69592565 -0.5136295  -0.50186884]
 [-0.67348045 -0.70936561 -0.20790538]]
transform [[-0.24922214  0.48268545 -0.83958507]
 [ 0.69592565 -0.5136295  -0.50186884]
 [-0.67348045 -0.70936561 -0.20790538]]
transform [[-0.24922214  0.69592565 -0.67348045]
 [ 0.48268545 -0.5136295  -0.70936561]
 [-0.83958507 -0.50186884 -0.20790538]]
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:212.21910347541473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-240.40017589843498 steps:1[00m
[RDDPG] Resetting Environment
transform [[ 0.68115038  0.69416672  0.23273773]
 [-0.14797115 -0.18080106  0.97232485]
 [ 0.7170347  -0.69673789 -0.02043607]]
transform [[ 0.68115038  0.69416672  0.23273773]
 [-0.14797115 -0.18080106  0.97232485]
 [ 0.7170347  -0.69673789 -0.02043607]]
transform [[ 0.68115038  0.69416672  0.23273773]
 [-0.14797115 -0.18080106  0.97232485]
 [ 0.7170347  -0.69673789 -0.02043607]]
transform [[ 0.68115038  0.69416672  0.23273773]
 [-0.14797115 -0.18080106  0.97232485]
 [ 0.7170347  -0.69673789 -0.02043607]]
transform [[ 0.68115038 -0.14797115  0.7170347 ]
 [ 0.69416672 -0.18080106 -0.69673789]
 [ 0.23273773  0.97232485 -0.02043607]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-262.9770580952059 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-311.58437414061603 steps:4[00m
[RDDPG] Resetting Environment
transform [[ 0.22814192  0.1865198   0.95559496]
 [-0.6835109  -0.66828012  0.29362333]
 [ 0.69337159 -0.72014731 -0.02497438]]
transform [[ 0.22814192  0.1865198   0.95559496]
 [-0.6835109  -0.66828012  0.29362333]
 [ 0.69337159 -0.72014731 -0.02497438]]
transform [[ 0.22814192  0.1865198   0.95559496]
 [-0.6835109  -0.66828012  0.29362333]
 [ 0.69337159 -0.72014731 -0.02497438]]
transform [[ 0.22814192  0.1865198   0.95559496]
 [-0.6835109  -0.66828012  0.29362333]
 [ 0.69337159 -0.72014731 -0.02497438]]
transform [[ 0.22814192 -0.6835109   0.69337159]
 [ 0.1865198  -0.66828012 -0.72014731]
 [ 0.95559496  0.29362333 -0.02497438]]
transform [[ 0.25697982  0.2165204   0.94184941]
 [-0.45943281  0.88477701 -0.07804573]
 [-0.85022521 -0.41266033  0.32684642]]
transform [[ 0.25697982  0.2165204   0.94184941]
 [-0.45943281  0.88477701 -0.07804573]
 [-0.85022521 -0.41266033  0.32684642]]
transform [[ 0.25697982  0.2165204   0.94184941]
 [-0.45943281  0.88477701 -0.07804573]
 [-0.85022521 -0.41266033  0.32684642]]
transform [[ 0.25697982  0.2165204   0.94184941]
 [-0.45943281  0.88477701 -0.07804573]
 [-0.85022521 -0.41266033  0.32684642]]
transform [[ 0.25697982 -0.45943281 -0.85022521]
 [ 0.2165204   0.88477701 -0.41266033]
 [ 0.94184941 -0.07804573  0.32684642]]
transform [[-0.5436582  -0.09043169  0.83442074]
 [-0.73379487 -0.43137094 -0.52484697]
 [ 0.40740764 -0.89763093  0.16815996]]
transform [[-0.5436582  -0.09043169  0.83442074]
 [-0.73379487 -0.43137094 -0.52484697]
 [ 0.40740764 -0.89763093  0.16815996]]
transform [[-0.5436582  -0.09043169  0.83442074]
 [-0.73379487 -0.43137094 -0.52484697]
 [ 0.40740764 -0.89763093  0.16815996]]
transform [[-0.5436582  -0.09043169  0.83442074]
 [-0.73379487 -0.43137094 -0.52484697]
 [ 0.40740764 -0.89763093  0.16815996]]
transform [[-0.5436582  -0.73379487  0.40740764]
 [-0.09043169 -0.43137094 -0.89763093]
 [ 0.83442074 -0.52484697  0.16815996]]
transform [[-0.6042546   0.36437431 -0.70859557]
 [ 0.75851959 -0.00925155 -0.65158463]
 [-0.24397635 -0.93120664 -0.27079481]]
transform [[-0.6042546   0.36437431 -0.70859557]
 [ 0.75851959 -0.00925155 -0.65158463]
 [-0.24397635 -0.93120664 -0.27079481]]
transform [[-0.6042546   0.36437431 -0.70859557]
 [ 0.75851959 -0.00925155 -0.65158463]
 [-0.24397635 -0.93120664 -0.27079481]]
transform [[-0.6042546   0.36437431 -0.70859557]
 [ 0.75851959 -0.00925155 -0.65158463]
 [-0.24397635 -0.93120664 -0.27079481]]
transform [[-0.6042546   0.75851959 -0.24397635]
 [ 0.36437431 -0.00925155 -0.93120664]
 [-0.70859557 -0.65158463 -0.27079481]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1178.2837797929647 steps:9[00m
[RDDPG] Resetting Environment
transform [[ 0.12382422  0.14525314 -0.9816156 ]
 [ 0.69428408  0.69408989  0.1902862 ]
 [ 0.70896912 -0.70508212 -0.0149018 ]]
transform [[ 0.12382422  0.14525314 -0.9816156 ]
 [ 0.69428408  0.69408989  0.1902862 ]
 [ 0.70896912 -0.70508212 -0.0149018 ]]
transform [[ 0.12382422  0.14525314 -0.9816156 ]
 [ 0.69428408  0.69408989  0.1902862 ]
 [ 0.70896912 -0.70508212 -0.0149018 ]]
transform [[ 0.12382422  0.14525314 -0.9816156 ]
 [ 0.69428408  0.69408989  0.1902862 ]
 [ 0.70896912 -0.70508212 -0.0149018 ]]
transform [[ 0.12382422  0.69428408  0.70896912]
 [ 0.14525314  0.69408989 -0.70508212]
 [-0.9816156   0.1902862  -0.0149018 ]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-495.1543339615145 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-284.38193249023436 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-102.22220519531986 steps:13[00m
[RDDPG] Resetting Environment
transform [[ 0.66954392  0.63324302 -0.3882193 ]
 [ 0.26639453  0.28316972  0.92132998]
 [ 0.69335771 -0.72029036  0.02090208]]
transform [[ 0.66954392  0.63324302 -0.3882193 ]
 [ 0.26639453  0.28316972  0.92132998]
 [ 0.69335771 -0.72029036  0.02090208]]
transform [[ 0.66954392  0.63324302 -0.3882193 ]
 [ 0.26639453  0.28316972  0.92132998]
 [ 0.69335771 -0.72029036  0.02090208]]
transform [[ 0.66954392  0.63324302 -0.3882193 ]
 [ 0.26639453  0.28316972  0.92132998]
 [ 0.69335771 -0.72029036  0.02090208]]
transform [[ 0.66954392  0.26639453  0.69335771]
 [ 0.63324302  0.28316972 -0.72029036]
 [-0.3882193   0.92132998  0.02090208]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-285.1105452136421 steps:15[00m
[RDDPG] Resetting Environment
transform [[ 0.69686896  0.69516921  0.1763899 ]
 [-0.09201213 -0.15725267  0.98326266]
 [ 0.7112717  -0.70143521 -0.04562049]]
transform [[ 0.69686896  0.69516921  0.1763899 ]
 [-0.09201213 -0.15725267  0.98326266]
 [ 0.7112717  -0.70143521 -0.04562049]]
transform [[ 0.69686896  0.69516921  0.1763899 ]
 [-0.09201213 -0.15725267  0.98326266]
 [ 0.7112717  -0.70143521 -0.04562049]]
transform [[ 0.69686896  0.69516921  0.1763899 ]
 [-0.09201213 -0.15725267  0.98326266]
 [ 0.7112717  -0.70143521 -0.04562049]]
transform [[ 0.69686896 -0.09201213  0.7112717 ]
 [ 0.69516921 -0.15725267 -0.70143521]
 [ 0.1763899   0.98326266 -0.04562049]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-340.7312822783771 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-36.23955504882539 steps:18[00m
[RDDPG] Resetting Environment
transform [[ 0.63081402  0.76629525  0.12192317]
 [-0.03528512 -0.12863876  0.99106359]
 [ 0.7751314  -0.62947887 -0.05410831]]
transform [[ 0.63081402  0.76629525  0.12192317]
 [-0.03528512 -0.12863876  0.99106359]
 [ 0.7751314  -0.62947887 -0.05410831]]
transform [[ 0.63081402  0.76629525  0.12192317]
 [-0.03528512 -0.12863876  0.99106359]
 [ 0.7751314  -0.62947887 -0.05410831]]
transform [[ 0.63081402  0.76629525  0.12192317]
 [-0.03528512 -0.12863876  0.99106359]
 [ 0.7751314  -0.62947887 -0.05410831]]
transform [[ 0.63081402 -0.03528512  0.7751314 ]
 [ 0.76629525 -0.12863876 -0.62947887]
 [ 0.12192317  0.99106359 -0.05410831]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-597.6455084418749 steps:20[00m
[RDDPG] Resetting Environment
transform [[ 0.23331815  0.19086447 -0.95348489]
 [ 0.66003925  0.68897814  0.29942852]
 [ 0.71408045 -0.6991995   0.03477307]]
transform [[ 0.23331815  0.19086447 -0.95348489]
 [ 0.66003925  0.68897814  0.29942852]
 [ 0.71408045 -0.6991995   0.03477307]]
transform [[ 0.23331815  0.19086447 -0.95348489]
 [ 0.66003925  0.68897814  0.29942852]
 [ 0.71408045 -0.6991995   0.03477307]]
transform [[ 0.23331815  0.19086447 -0.95348489]
 [ 0.66003925  0.68897814  0.29942852]
 [ 0.71408045 -0.6991995   0.03477307]]
transform [[ 0.23331815  0.66003925  0.71408045]
 [ 0.19086447  0.68897814 -0.6991995 ]
 [-0.95348489  0.29942852  0.03477307]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-232.76148105863155 steps:22[00m
[RDDPG] Resetting Environment
transform [[ 0.73224777  0.68024033 -0.03295837]
 [ 0.01044744  0.03716875  0.99925441]
 [ 0.68095821 -0.73204613  0.02010997]]
transform [[ 0.73224777  0.68024033 -0.03295837]
 [ 0.01044744  0.03716875  0.99925441]
 [ 0.68095821 -0.73204613  0.02010997]]
transform [[ 0.73224777  0.68024033 -0.03295837]
 [ 0.01044744  0.03716875  0.99925441]
 [ 0.68095821 -0.73204613  0.02010997]]
transform [[ 0.73224777  0.68024033 -0.03295837]
 [ 0.01044744  0.03716875  0.99925441]
 [ 0.68095821 -0.73204613  0.02010997]]
transform [[ 0.73224777  0.01044744  0.68095821]
 [ 0.68024033  0.03716875 -0.73204613]
 [-0.03295837  0.99925441  0.02010997]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-63.955856577274496 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-324.16661144532475 steps:25[00m
[RDDPG] Resetting Environment
transform [[ 0.14220719  0.08722926  0.98598588]
 [-0.68727082 -0.70815814  0.16177408]
 [ 0.71234536 -0.70064479 -0.04075506]]
transform [[ 0.14220719  0.08722926  0.98598588]
 [-0.68727082 -0.70815814  0.16177408]
 [ 0.71234536 -0.70064479 -0.04075506]]
transform [[ 0.14220719  0.08722926  0.98598588]
 [-0.68727082 -0.70815814  0.16177408]
 [ 0.71234536 -0.70064479 -0.04075506]]
transform [[ 0.14220719  0.08722926  0.98598588]
 [-0.68727082 -0.70815814  0.16177408]
 [ 0.71234536 -0.70064479 -0.04075506]]
transform [[ 0.14220719 -0.68727082  0.71234536]
 [ 0.08722926 -0.70815814 -0.70064479]
 [ 0.98598588  0.16177408 -0.04075506]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-330.0033641788044 steps:27[00m
[RDDPG] Resetting Environment
transform [[ 0.69481617  0.68745446  0.21127453]
 [-0.14337537 -0.15546659  0.97738099]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.69481617  0.68745446  0.21127453]
 [-0.14337537 -0.15546659  0.97738099]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.69481617  0.68745446  0.21127453]
 [-0.14337537 -0.15546659  0.97738099]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.69481617  0.68745446  0.21127453]
 [-0.14337537 -0.15546659  0.97738099]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.69481617 -0.14337537  0.70475101]
 [ 0.68745446 -0.15546659 -0.70939177]
 [ 0.21127453  0.97738099 -0.00945667]]
transform [[ 0.19630665  0.20779684 -0.95827144]
 [ 0.68175489  0.67348635  0.28570333]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.19630665  0.20779684 -0.95827144]
 [ 0.68175489  0.67348635  0.28570333]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.19630665  0.20779684 -0.95827144]
 [ 0.68175489  0.67348635  0.28570333]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.19630665  0.20779684 -0.95827144]
 [ 0.68175489  0.67348635  0.28570333]
 [ 0.70475101 -0.70939177 -0.00945667]]
transform [[ 0.19630665  0.68175489  0.70475101]
 [ 0.20779684  0.67348635 -0.70939177]
 [-0.95827144  0.28570333 -0.00945667]]
transform [[ 0.12596537  0.25331423 -0.95914787]
 [ 0.92897362 -0.36933705  0.0244594 ]
 [-0.34805289 -0.89410406 -0.2818459 ]]
transform [[ 0.12596537  0.25331423 -0.95914787]
 [ 0.92897362 -0.36933705  0.0244594 ]
 [-0.34805289 -0.89410406 -0.2818459 ]]
transform [[ 0.12596537  0.25331423 -0.95914787]
 [ 0.92897362 -0.36933705  0.0244594 ]
 [-0.34805289 -0.89410406 -0.2818459 ]]
transform [[ 0.12596537  0.25331423 -0.95914787]
 [ 0.92897362 -0.36933705  0.0244594 ]
 [-0.34805289 -0.89410406 -0.2818459 ]]
transform [[ 0.12596537  0.92897362 -0.34805289]
 [ 0.25331423 -0.36933705 -0.89410406]
 [-0.95914787  0.0244594  -0.2818459 ]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-527.719567664963 steps:31[00m
[RDDPG] Resetting Environment
transform [[ 0.22942141  0.01803466 -0.97316009]
 [ 0.9731831  -0.02145702  0.22902919]
 [-0.01675065 -0.99960715 -0.02247372]]
transform [[ 0.22942141  0.01803466 -0.97316009]
 [ 0.9731831  -0.02145702  0.22902919]
 [-0.01675065 -0.99960715 -0.02247372]]
transform [[ 0.22942141  0.01803466 -0.97316009]
 [ 0.9731831  -0.02145702  0.22902919]
 [-0.01675065 -0.99960715 -0.02247372]]
transform [[ 0.22942141  0.01803466 -0.97316009]
 [ 0.9731831  -0.02145702  0.22902919]
 [-0.01675065 -0.99960715 -0.02247372]]
transform [[ 0.22942141  0.9731831  -0.01675065]
 [ 0.01803466 -0.02145702 -0.99960715]
 [-0.97316009  0.22902919 -0.02247372]]
transform [[ 0.71283185 -0.70106107 -0.01960057]
 [-0.15340944 -0.18313406  0.97104454]
 [-0.68435109 -0.68918455 -0.23809318]]
transform [[ 0.71283185 -0.70106107 -0.01960057]
 [-0.15340944 -0.18313406  0.97104454]
 [-0.68435109 -0.68918455 -0.23809318]]
transform [[ 0.71283185 -0.70106107 -0.01960057]
 [-0.15340944 -0.18313406  0.97104454]
 [-0.68435109 -0.68918455 -0.23809318]]
transform [[ 0.71283185 -0.70106107 -0.01960057]
 [-0.15340944 -0.18313406  0.97104454]
 [-0.68435109 -0.68918455 -0.23809318]]
transform [[ 0.71283185 -0.15340944 -0.68435109]
 [-0.70106107 -0.18313406 -0.68918455]
 [-0.01960057  0.97104454 -0.23809318]]
transform [[-0.33773369 -0.70085621 -0.62828064]
 [ 0.56915635  0.37957472 -0.72937244]
 [ 0.74966466 -0.60392356  0.27070162]]
transform [[-0.33773369 -0.70085621 -0.62828064]
 [ 0.56915635  0.37957472 -0.72937244]
 [ 0.74966466 -0.60392356  0.27070162]]
transform [[-0.33773369 -0.70085621 -0.62828064]
 [ 0.56915635  0.37957472 -0.72937244]
 [ 0.74966466 -0.60392356  0.27070162]]
transform [[-0.33773369 -0.70085621 -0.62828064]
 [ 0.56915635  0.37957472 -0.72937244]
 [ 0.74966466 -0.60392356  0.27070162]]
transform [[-0.33773369  0.56915635  0.74966466]
 [-0.70085621  0.37957472 -0.60392356]
 [-0.62828064 -0.72937244  0.27070162]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-844.1007735929414 steps:35[00m
[RDDPG] Resetting Environment
transform [[ 9.98439848e-01  5.36263920e-02  1.55608058e-02]
 [-1.55512812e-02 -5.94910816e-04  9.99878943e-01]
 [ 5.36291562e-02 -9.98560905e-01  2.39976493e-04]]
transform [[ 9.98439848e-01  5.36263920e-02  1.55608058e-02]
 [-1.55512812e-02 -5.94910816e-04  9.99878943e-01]
 [ 5.36291562e-02 -9.98560905e-01  2.39976493e-04]]
transform [[ 9.98439848e-01  5.36263920e-02  1.55608058e-02]
 [-1.55512812e-02 -5.94910816e-04  9.99878943e-01]
 [ 5.36291562e-02 -9.98560905e-01  2.39976493e-04]]
transform [[ 9.98439848e-01  5.36263920e-02  1.55608058e-02]
 [-1.55512812e-02 -5.94910816e-04  9.99878943e-01]
 [ 5.36291562e-02 -9.98560905e-01  2.39976493e-04]]
transform [[ 9.98439848e-01 -1.55512812e-02  5.36291562e-02]
 [ 5.36263920e-02 -5.94910816e-04 -9.98560905e-01]
 [ 1.55608058e-02  9.99878943e-01  2.39976493e-04]]
transform [[ 0.37657601  0.5208866   0.76607293]
 [-0.50245577 -0.57990068  0.64129043]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.37657601  0.5208866   0.76607293]
 [-0.50245577 -0.57990068  0.64129043]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.37657601  0.5208866   0.76607293]
 [-0.50245577 -0.57990068  0.64129043]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.37657601  0.5208866   0.76607293]
 [-0.50245577 -0.57990068  0.64129043]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.37657601 -0.50245577  0.7782858 ]
 [ 0.5208866  -0.57990068 -0.62641239]
 [ 0.76607293  0.64129043  0.04334583]]
transform [[ 0.6212011   0.75806862 -0.19859838]
 [ 0.09154537  0.18149276  0.97912198]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.6212011   0.75806862 -0.19859838]
 [ 0.09154537  0.18149276  0.97912198]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.6212011   0.75806862 -0.19859838]
 [ 0.09154537  0.18149276  0.97912198]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.6212011   0.75806862 -0.19859838]
 [ 0.09154537  0.18149276  0.97912198]
 [ 0.7782858  -0.62641239  0.04334583]]
transform [[ 0.6212011   0.09154537  0.7782858 ]
 [ 0.75806862  0.18149276 -0.62641239]
 [-0.19859838  0.97912198  0.04334583]]
transform [[ 0.58346474 -0.81050307  0.05151403]
 [ 0.08713791  0.12554038  0.98825431]
 [-0.80745023 -0.57212275  0.14387393]]
transform [[ 0.58346474 -0.81050307  0.05151403]
 [ 0.08713791  0.12554038  0.98825431]
 [-0.80745023 -0.57212275  0.14387393]]
transform [[ 0.58346474 -0.81050307  0.05151403]
 [ 0.08713791  0.12554038  0.98825431]
 [-0.80745023 -0.57212275  0.14387393]]
transform [[ 0.58346474 -0.81050307  0.05151403]
 [ 0.08713791  0.12554038  0.98825431]
 [-0.80745023 -0.57212275  0.14387393]]
transform [[ 0.58346474  0.08713791 -0.80745023]
 [-0.81050307  0.12554038 -0.57212275]
 [ 0.05151403  0.98825431  0.14387393]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-933.0627322114394 steps:40[00m
[RDDPG] Resetting Environment
transform [[ 0.08581603  0.01871796 -0.99613518]
 [ 0.70073771 -0.71186978  0.04699139]
 [-0.7082389  -0.70206207 -0.07420621]]
transform [[ 0.08581603  0.01871796 -0.99613518]
 [ 0.70073771 -0.71186978  0.04699139]
 [-0.7082389  -0.70206207 -0.07420621]]
transform [[ 0.08581603  0.01871796 -0.99613518]
 [ 0.70073771 -0.71186978  0.04699139]
 [-0.7082389  -0.70206207 -0.07420621]]
transform [[ 0.08581603  0.01871796 -0.99613518]
 [ 0.70073771 -0.71186978  0.04699139]
 [-0.7082389  -0.70206207 -0.07420621]]
transform [[ 0.08581603  0.70073771 -0.7082389 ]
 [ 0.01871796 -0.71186978 -0.70206207]
 [-0.99613518  0.04699139 -0.07420621]]
transform [[ 0.3266086   0.13635553 -0.93527216]
 [ 0.75368333  0.55954707  0.34477323]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.3266086   0.13635553 -0.93527216]
 [ 0.75368333  0.55954707  0.34477323]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.3266086   0.13635553 -0.93527216]
 [ 0.75368333  0.55954707  0.34477323]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.3266086   0.13635553 -0.93527216]
 [ 0.75368333  0.55954707  0.34477323]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.3266086   0.75368333  0.57034051]
 [ 0.13635553  0.55954707 -0.81750494]
 [-0.93527216  0.34477323  0.07998399]]
transform [[ 0.17351928  0.2150864   0.96105617]
 [-0.80287164 -0.5342505   0.26452535]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.17351928  0.2150864   0.96105617]
 [-0.80287164 -0.5342505   0.26452535]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.17351928  0.2150864   0.96105617]
 [-0.80287164 -0.5342505   0.26452535]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.17351928  0.2150864   0.96105617]
 [-0.80287164 -0.5342505   0.26452535]
 [ 0.57034051 -0.81750494  0.07998399]]
transform [[ 0.17351928 -0.80287164  0.57034051]
 [ 0.2150864  -0.5342505  -0.81750494]
 [ 0.96105617  0.26452535  0.07998399]]
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-890.2002583074366 steps:44[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/rdpg.py", line 115, in train
    state0 = deepcopy(self.env.reset())
  File "/home/shandilya/Desktop/CNS/DDP/src/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/home/shandilya/Desktop/CNS/DDP/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 959, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 16:07:09.367140: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu
2021-05-04 16:07:09.367171: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620124636.248223173, 1.251000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620124636.253246870, 1.255000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620124636.253426951, 1.255000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620124637.776468593, 2.324000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620124638.991802678, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620124640.075136396, 4.002000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620124641.170209628, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
2021-05-04 13:19:44.060538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:310): Gdk-CRITICAL **: 13:19:48.028: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 9, in <module>
    from torchsummary import summary
ModuleNotFoundError: No module named 'torchsummary'
2021-05-04 13:20:10.930529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:593): Gdk-CRITICAL **: 13:20:13.630: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620134416.538176990, 1.636000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620134416.539147022, 1.636000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620134416.539198204, 1.636000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620134417.978131973, 3.077000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620134418.703834528, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620134419.505171140, 4.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620134420.307862418, 5.401000000]: Ready to take commands for planning group back_left_leg.[0m
2021-05-04 14:47:19.899121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:476): Gdk-CRITICAL **: 14:47:23.422: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 9, in <module>
    from torchsummary import summary
ModuleNotFoundError: No module named 'torchsummary'
2021-05-04 14:48:22.013634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:702): Gdk-CRITICAL **: 14:48:24.092: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620139706.804784112, 1.675000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620139706.805788572, 1.677000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620139706.805849029, 1.677000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620139708.111039353, 2.972000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620139708.941139004, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620139709.742365955, 4.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620139710.542755613, 5.400000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3539110.4633327746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.9106507346196606 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:14.659707281497312 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.8259580620894615 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.1955227331542915 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.918901036145134 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:6.126768313822582 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:27.16912779671447 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.938157443056745 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:5.364455813194748 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-4.815319612172944 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-0.9926338530621059 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:8.71333251588327 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-0.9441183715603803 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.38459941685297 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:0.5132041298997811 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-3.521370614389181 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:1.6436393155348967 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:12.669194250269742 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-1.7915359472910741 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-0.2748228248348803 steps:77[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-2.738522443676156 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-1.7506290463964185 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:18.261918844201897 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:0.4852086007469518 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-4.002055057042243 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-3.749979695003029 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-5.704764062907163 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-3.2604317067383484 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-3.6243725161463667 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-1.9414889811570195 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-1.085445961317165 steps:110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:34.92599876334454 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:13.11125836585528 steps:115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-1.732194748709058 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-4.5311456653452735 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:38.228086244493426 steps:130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-3.720609456096233 steps:135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-1.474593144682843 steps:137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-3.3928676541298626 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-1.290156520488872 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-4.161618989234014 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:10.503013955476767 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-3.4348159830973772 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-1.3993169154541512 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-2.0304839637380367 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-4.3153612934787535 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.368230062615835 steps:164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-2.764320172556334 steps:168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-2.502493113156685 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:1.0459639478505962 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:1.9102705942352083 steps:177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:2.597961741107286 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:27.271598314663418 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-1.660983003159087 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-2.64044721510503 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-0.8178839476835553 steps:194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-1.4250847535803697 steps:197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-0.6438580132177196 steps:200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:3.6051222370961065 steps:203[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 14:50:14.536853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:2759): Gdk-CRITICAL **: 14:50:16.620: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620139819.276791796, 1.835000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620139819.278196024, 1.840000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620139819.278336125, 1.840000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620139820.627369847, 3.178000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620139821.250251046, 3.800000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620139822.052228619, 4.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620139823.064307663, 5.600000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3291264.8976364937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.01391102585164 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-2.5565417655083142 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:7.6327563936591325 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:16.066650162086898 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:12.726985465638613 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-3.4598119695765654 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-6.01641412155141 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-1.1632660107473791 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-4.133687012557911 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-4.4254637649983595 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-2.165623497611592 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.5039842439529294 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:39.10113161842458 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-4.006385375927512 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-0.5986947644332856 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:2.2676032754668447 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-4.5216531691606185 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-2.436366287757839 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:2.009457879634714 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:18.294638165737865 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-3.683757602000896 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-1.9065681468382212 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:18.618048408734555 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-2.347761118018458 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-2.122883661552783 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:190.787118316732 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-3.480805753707177 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-1.7499645499831458 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.2673730526737437 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-3.9344084499902054 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-1.92774069963205 steps:111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:15.041655502988 steps:114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:0.1020210612957122 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-2.0293569186827987 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-3.6171641076924637 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-4.355830496825813 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.6818183622624798 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-2.4627071041666504 steps:129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-3.6542102765908115 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:9.16755475635522 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-4.039851877755797 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:12.2272882793449 steps:148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-0.8126521802266353 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-3.7016330526683827 steps:154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-2.0250224731610604 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-1.8468992043931007 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.216988731744965 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-2.171683762556289 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:2.0536074560470494 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-6.092442208878026 steps:176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:2.1765342484908468 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:2.9634027892783927 steps:182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:0.43984179279934743 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-3.710468578679663 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-7.068070454815619 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:16.39112416418901 steps:200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:0.7259212556060586 steps:204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:3.3125938621604347 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:14.056745789912181 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-2.9567884765625365 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-3.943095313490004 steps:215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-4.503224901472379 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-1.4697013478693095 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-2.6393656874834854 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:16.533879838112146 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-2.0986508403539745 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:0.6544278414736655 steps:233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-2.288398042566499 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:58.918974173365534 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:19.291617119039735 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-4.204135173353845 steps:247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-2.5529292697007895 steps:250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-4.33143414759601 steps:252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-2.3878433066317672 steps:255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:1.788296231913948 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-3.8061704838600634 steps:262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-0.717244790282233 steps:268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-2.55863225598532 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-3.43548413895041 steps:277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:1.9526702229723938 steps:281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:5.129019895359218 steps:284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:8.101098811274213 steps:288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:0.18756525226676413 steps:290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-3.119851127557281 steps:293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-2.953873779529402 steps:295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-3.245927205387244 steps:297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-3.1404957518385723 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-0.05855588862318273 steps:305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:5.086898877172031 steps:309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:22.88109150312504 steps:317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-2.8080021416918526 steps:319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-1.6817472419247435 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-4.322887586692229 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-3.1427984176427595 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-3.604012466193433 steps:332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-2.6834121328411245 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-2.277200500396499 steps:337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-2.2479586182093434 steps:339[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-3.587313594697281 steps:341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-2.7145351789014986 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-2.7890341660856897 steps:347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-3.583361340290875 steps:350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-2.0586620995183993 steps:352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:0.09634850159188968 steps:354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-5.230744392192454 steps:358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:103.68426946240007 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:1.4448260453258222 steps:366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-2.6530394537924926 steps:368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-1.247366065641763 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-2.882251669543454 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-1.9991996358162774 steps:379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-4.0717925074665136 steps:382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-4.148309314149806 steps:384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:680.9255994769958 steps:389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-0.9675305848393299 steps:391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-4.626220631859887 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-5.1132692531019295 steps:397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-3.4627036187571107 steps:401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:0.5230274847657035 steps:406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:31.946390845463416 steps:412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-5.274948131623226 steps:415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-3.4407668786668504 steps:418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-0.27955548558325605 steps:420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-0.7474783598684627 steps:423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:1.2645881810292696 steps:425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-3.2109268364791173 steps:427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-4.268184404142338 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-2.017792355940256 steps:432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-0.3730899928024072 steps:434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:2.476263761950654 steps:439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:57.79483656173221 steps:443[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-3.980303474205889 steps:446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-1.9795028440131661 steps:448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-3.422566047685856 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-1.3199806267045968 steps:453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:98.45107681619844 steps:456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-1.205490494713826 steps:460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-4.6837837109206095 steps:463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-1.706477446074383 steps:466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-4.460884430541808 steps:468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-2.2890306504094102 steps:472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-2.341204634153466 steps:475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-2.2207403594650703 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:3.694888496724506 steps:482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-2.6569497866275227 steps:484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:2.9230095957319673 steps:487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:-2.8148744725262236 steps:489[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-3.343572788222093 steps:493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-2.7747425091083895 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-4.483602785301644 steps:502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-0.12053153919595738 steps:505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-4.49479451220189 steps:509[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-4.980915272486517 steps:512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:1.1471363732340465 steps:517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:-4.627369961498355 steps:519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:182.3015996432822 steps:526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:11.416561556073852 steps:530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:-3.1838871903560726 steps:533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-3.6364761747387995 steps:535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-1.920821208100088 steps:538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-2.042369295240925 steps:540[00m
[RDDPG] Resetting Environment
2021-05-04 14:53:43.118801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-2.4800915644798933 steps:544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:10.27754666958366 steps:547[00m
[RDDPG] Resetting Environment
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:7356): Gdk-CRITICAL **: 14:53:46.456: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
shutdown request: [/joint_position_node_exp45] Reason: new node registered with same name
[DDPG] Waiting for joint trajectory action
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620140028.431487375, 204.688000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620140028.432555794, 204.689000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620140028.432606337, 204.689000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 24, in <module>
    env = Env(
  File "/app/rl/torch/env.py", line 12, in __init__
    self.quadruped = Quadruped(params, experiment)
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 488, in __init__
    self.kinematics = Kinematics(
  File "/app/simulations/ws/src/quadruped/scripts/kinematics.py", line 21, in __init__
    self.front_right_leg = moveit_commander.MoveGroupCommander(
  File "/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py", line 53, in __init__
    self._g = _moveit_move_group_interface.MoveGroupInterface(name, robot_description, ns, wait_for_servers)
RuntimeError: Unable to connect to move_group action server 'place' within allotted time (5s)
2021-05-04 14:54:10.213250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:7667): Gdk-CRITICAL **: 14:54:12.306: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620140056.160153817, 2.800000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620140056.161083254, 2.800000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620140056.161143271, 2.800000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620140057.354078625, 3.966000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620140058.126813539, 4.738000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620140058.928116838, 5.539000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620140060.163697771, 6.739000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1911422.5361616034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.201395122673423 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:1.1651862088427247 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-4.788067435271128 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-3.8835068963736266 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:2.0769871898040675 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-4.661435954974248 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:1.8116337483496867 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.129506201147998 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-4.382627789313458 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:3.446515387604893 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-2.4632528805906966 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.3885745047881057 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.3458805167869814 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-5.27862563104184 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-1.82939309783682 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:0.17305694673650418 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-1.9844033300547554 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-2.8184036642390984 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-0.755693139775738 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:4.244973298023633 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-4.5205890062181 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:15.533035321259568 steps:83[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:72.26011113312907 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-0.9268515538693309 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:11.156834488727746 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-0.2466149506923161 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-4.650135150900775 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-3.5989586896771586 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.3223189310863317 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:2.9549808969527236 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-4.9617244191546845 steps:122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-1.625766759107767 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-0.2703589892802367 steps:131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:2.4057151753174466 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-2.8454379086404824 steps:136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:421.3777860032246 steps:139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.4333097177314933 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:19.72165124572891 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:2.3384736845862335 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-2.5240611697692756 steps:154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-4.077613906149422 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-5.581614530699982 steps:160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:1.0895852945332036 steps:166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-3.472620200199832 steps:169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:14.750651491731924 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-3.528524352076825 steps:179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:5.849126584621835 steps:181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-4.324848199465853 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-2.0683284109496958 steps:188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:0.31070921175078325 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-1.9595967884387635 steps:196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-3.1847205490914954 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:3.9659951269470826 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-1.0459187780346024 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-3.5016498631817305 steps:215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-3.0803055994117443 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-4.382891123901663 steps:225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:34.55050447081892 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-1.4524496300870047 steps:230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-5.006039654209201 steps:233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-4.798056649447095 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-3.1209906085118546 steps:239[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-3.590411626577432 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-3.4713021230487944 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:106.35857031271357 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:39.79487320606234 steps:253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-0.0904546386718934 steps:255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:0.044882786673700714 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:4.085962946260867 steps:260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:22.627568837867187 steps:263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-1.5877929591831894 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-3.4893367831768045 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-2.1433241606285844 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-2.42660021107915 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-2.7543252035289423 steps:275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:8.565050072741812 steps:277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-3.95202571479413 steps:282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-2.8727655192264767 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-5.799771836037367 steps:292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:22.47682080331303 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-2.816389249434308 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-1.0669684211164885 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-6.685226524055658 steps:304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-1.6636897904152503 steps:309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-3.3863389372320603 steps:312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-1.8960159166946522 steps:316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:27.760326385275853 steps:319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-5.109629198708272 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-2.1226725095135484 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:6.821480510904864 steps:330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:15.39102248364603 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:23.902796376751432 steps:341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-1.6159864397574608 steps:345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-1.6367654315613545 steps:347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:1.1205227358914196 steps:350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:3.1587165008228824 steps:355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-4.438302932361712 steps:358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-2.712767688814405 steps:361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:3.7397933841915334 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:1.4317773584885911 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-4.08639879033233 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:66.02806615530744 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:3.64892938032874 steps:381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:9.014639343865188 steps:384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:18.705751931087583 steps:390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:17.81295512285561 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-2.2961003543433205 steps:396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-3.115730594650281 steps:398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-5.1415186577095415 steps:401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-3.2442195995403234 steps:405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-5.009798764309382 steps:409[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-2.8099089907001824 steps:411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-3.706152230361873 steps:414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:8.3599453278822 steps:416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-0.8570215910875127 steps:419[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:2.2273133698977565 steps:421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-1.0118931055841105 steps:426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:0.9354454507021233 steps:428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-1.7035647993819636 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-4.379908936704832 steps:432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:107.4680212800423 steps:435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-4.84169934467789 steps:438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-0.8501678421152996 steps:440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-4.634046863267253 steps:444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-3.469917432000642 steps:448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-2.2540112658560476 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-3.146493072861572 steps:453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-1.0660878131346285 steps:455[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-1.3273796063887562 steps:457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-2.7253650649234826 steps:459[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-2.479755693208689 steps:463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:2.5459046097333466 steps:466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:12.1599687541224 steps:471[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:6.011824939938308 steps:474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-6.049419343820404 steps:477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-2.9719853158571015 steps:479[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-1.9868564866527851 steps:482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:1.443784227411487 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:4.7211285251602515 steps:487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-2.9133279016112708 steps:488[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:6.054250983815798 steps:492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-3.0376056747946967 steps:495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-3.8711478999610267 steps:498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-2.0896209910793466 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:2.992810764100579 steps:506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-3.8357000187551584 steps:510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:35.32405531888758 steps:515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-1.732947210316574 steps:517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-4.839168326674966 steps:519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:3.1533657868099376 steps:521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:395.8321204419365 steps:527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-2.109807867279982 steps:531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-3.054471231111395 steps:535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:9.104861403229092 steps:537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:11.731547910968281 steps:540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-0.6262156527367226 steps:544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:0.7827039982500734 steps:547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:0.7080428632449678 steps:550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:4.3511399313223045 steps:553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:0.0833342191722175 steps:557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-4.017638603199763 steps:560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-3.6237043187421003 steps:563[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-4.038135827695406 steps:565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-0.3759046285306922 steps:570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-0.558876048051332 steps:573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-1.9919023774770737 steps:576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:641.0266813752561 steps:578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-2.9299580665373064 steps:581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:-5.988307080078499 steps:582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:-2.9126829288428526 steps:584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-1.9410103596305752 steps:586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-2.7721872512609265 steps:588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-2.621309616193505 steps:590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-2.253348918087542 steps:592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-1.0867398543678712 steps:595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-2.7511396980324845 steps:598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:-1.4670144107878915 steps:603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:23.654399099075782 steps:607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-5.166029956054903 steps:608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-0.703985964002992 steps:610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:1.2521102565764224 steps:614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:2.812271135534301 steps:617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-3.4032726645118934 steps:619[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:8.551198187627616 steps:625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-3.0767368053509765 steps:627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:13.222020204920895 steps:638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:0.2524485258436657 steps:640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-3.501892406274619 steps:644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:0.732317510922579 steps:646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-2.7631835357048447 steps:648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:-4.672297997709248 steps:650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:3.1175491350706888 steps:652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-0.5596487869890958 steps:655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:24.387927887847322 steps:661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:-2.0013284247309104 steps:665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-1.68691174315958 steps:667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:-3.2816884531937616 steps:669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-2.9902733519361746 steps:671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:-3.326254684862144 steps:675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:-0.8931954654712984 steps:677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:-0.7545670785101413 steps:682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:2.4780714791235434 steps:686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-0.3985347825659069 steps:688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:-1.3786632277970492 steps:690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:-1.8799090600922905 steps:694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:28.087272923048058 steps:696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-3.180519065405616 steps:699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:-3.4582016466817054 steps:703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-5.080702613300923 steps:706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:-4.250091545599521 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:2.1294515153995075 steps:712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:-1.360774578644863 steps:714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-2.0717897921587967 steps:716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:2.2632351799265114 steps:721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:-2.266602500277271 steps:725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-1.5488848989003534 steps:728[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-2.549712511017394 steps:731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:-3.5279362630299227 steps:733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:14.36681305701284 steps:739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:0.18878564312101087 steps:741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:27.39814461638947 steps:746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:-2.46185057826947 steps:748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:-2.873597516704424 steps:750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:-2.3942947216112263 steps:752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:4.819098155328551 steps:759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-2.914569523446297 steps:762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:-5.771867758432025 steps:767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:-3.7707575437803804 steps:769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-3.095590277335595 steps:771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:14.431312917230901 steps:775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:-2.408680060336775 steps:777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:-3.237472022815883 steps:783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:-5.467504099699061 steps:785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-2.3881734045556025 steps:789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-3.1931602523962157 steps:791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-2.6629192497482133 steps:793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-2.0682107463796653 steps:798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:-2.0983120425743733 steps:800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-3.569370626342802 steps:802[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:-1.8821894992635104 steps:804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-4.225070305017846 steps:807[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:-3.0912134635287694 steps:809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:16.36841357621651 steps:817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:10.399402031533956 steps:824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:2.0582935148158006 steps:826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:-2.804779615688698 steps:831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:35.79509767612506 steps:837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:-5.97197223338446 steps:843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-4.193671320966093 steps:850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-1.5868617163983132 steps:852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:-4.3423280179563655 steps:858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:3.6398250549881768 steps:865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-3.805674214983406 steps:871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:20.219313185620265 steps:878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:3.674034037998004 steps:882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-1.03233054444864 steps:885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-3.58885928725351 steps:888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-1.8701201371370946 steps:890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-2.288957436531283 steps:892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:-3.387336696131263 steps:898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-4.359296096392427 steps:902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:23.672602052249598 steps:905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:-2.4481279238433182 steps:909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:-3.7985982321132594 steps:911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-3.4950326147036743 steps:915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:122.38453803353266 steps:920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:-1.2116039021153506 steps:923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:2.461800921375093 steps:926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:56.691534549140925 steps:934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:-2.0096987718246266 steps:936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:20.858831181063128 steps:940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:-2.595799015420123 steps:944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:9.048906610363568 steps:947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:8.014554921835291 steps:951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-3.3857873857173253 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:1.7738572874518548 steps:955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:-0.7387504194630896 steps:959[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:-2.7980260512948947 steps:961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:-2.3594487020946193 steps:963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-2.7303004732455567 steps:965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:-2.5025183517406226 steps:967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:0.8687922020360697 steps:969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:150.92270441520319 steps:972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-1.599935388604488 steps:974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-2.876920428658278 steps:976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:-3.7590475413962445 steps:979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:-3.8341261348785585 steps:981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-3.499562989927532 steps:983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:9.340757301017552 steps:987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-3.2091256713866008 steps:988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:1.1410361902026813 steps:991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:-2.4002701978276435 steps:994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:0.18170671623605372 steps:997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:-2.299851763137077 steps:999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:-1.2425151273981927 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 9.02989
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:21.525964796004736 steps:1013[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.97289
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:9.856357899349536 steps:1025[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40320
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:2.8944485987527986 steps:1032[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.56818
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 298: episode_reward:31.476216972273797 steps:1045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 299: episode_reward:-1.6900950156869323 steps:1047[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.20958
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 300: episode_reward:2.818617832349884 steps:1053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 301: episode_reward:5.518861994813321 steps:1059[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.41194
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77896
[RDDPG] Episode Done
[92m [RDDPG] 302: episode_reward:254.36565818132024 steps:1070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 303: episode_reward:2.8200404760044924 steps:1074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.05567
[RDDPG] Episode Done
[92m [RDDPG] 304: episode_reward:0.18692915007578348 steps:1080[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 305: episode_reward:-4.523472064290575 steps:1085[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.23738
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 306: episode_reward:42.045968988730664 steps:1098[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.50437
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.65962
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.79652
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29738
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.63713
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.19854
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 307: episode_reward:120.57192515857241 steps:1155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 308: episode_reward:86.08149015562728 steps:1159[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.23695
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 309: episode_reward:-2.9321786298965957 steps:1162[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.21806
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 310: episode_reward:4.29644556065548 steps:1171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 311: episode_reward:1.009707926504059 steps:1174[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.14480
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 312: episode_reward:15.65006656714768 steps:1185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 313: episode_reward:-2.6734038459963845 steps:1189[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.63175
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 314: episode_reward:-1.5038726266593587 steps:1195[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.86702
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 315: episode_reward:9.852757824881571 steps:1209[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.16904
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 316: episode_reward:55.48521059935182 steps:1212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 317: episode_reward:6.167329013619065 steps:1215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 318: episode_reward:-2.8778234754752003 steps:1217[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.46631
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 319: episode_reward:-1.3743959419243845 steps:1223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 320: episode_reward:-4.168662680147316 steps:1226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.36376
[RDDPG] Episode Done
[92m [RDDPG] 321: episode_reward:-0.623927977787349 steps:1230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 322: episode_reward:7.115349174991183 steps:1234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 323: episode_reward:-1.8627801573503957 steps:1238[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.82430
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 324: episode_reward:-1.8145836764892085 steps:1241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 325: episode_reward:47.990379724427015 steps:1246[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.26704
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 326: episode_reward:-2.272727004834014 steps:1252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 327: episode_reward:1.1505163459403014 steps:1254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 328: episode_reward:16.014997309696845 steps:1258[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.05021
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 329: episode_reward:1.149316456585277 steps:1263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 330: episode_reward:0.3459039589524795 steps:1265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.69082
[RDDPG] Episode Done
[92m [RDDPG] 331: episode_reward:0.5434617849068006 steps:1270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 332: episode_reward:3.4028061870652095 steps:1274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 333: episode_reward:4.267184351049816 steps:1277[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35124
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 334: episode_reward:-4.170861769514127 steps:1282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 335: episode_reward:2.540592465988963 steps:1286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 336: episode_reward:4.053747252380546 steps:1289[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95509
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 337: episode_reward:1.5034709724312747 steps:1293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 338: episode_reward:-2.4586104243126954 steps:1296[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.56050
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 339: episode_reward:13.3075012355043 steps:1301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 340: episode_reward:1.4938110476127044 steps:1305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 341: episode_reward:-1.8604460391175035 steps:1309[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.23777
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 342: episode_reward:18.82578916586037 steps:1313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 343: episode_reward:-2.639039296281407 steps:1316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.45907
[RDDPG] Episode Done
[92m [RDDPG] 344: episode_reward:-4.284717211682316 steps:1320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 345: episode_reward:-0.880982569746654 steps:1323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 346: episode_reward:-3.41378901240023 steps:1326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.25698
[RDDPG] Episode Done
[92m [RDDPG] 347: episode_reward:-1.2500324146045454 steps:1330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 348: episode_reward:146.90007881490106 steps:1334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 349: episode_reward:-2.5271599381990146 steps:1337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.15156
[RDDPG] Episode Done
[92m [RDDPG] 350: episode_reward:-3.1204987139780407 steps:1340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 351: episode_reward:3.2920699583114414 steps:1343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 352: episode_reward:0.6108540174080854 steps:1346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 353: episode_reward:-2.1839371498672517 steps:1349[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.52678
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 354: episode_reward:-2.844188553539075 steps:1353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 355: episode_reward:-3.150699393705004 steps:1356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 356: episode_reward:-1.0282762448710132 steps:1358[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.89425
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 357: episode_reward:-1.4686731947977796 steps:1362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 358: episode_reward:4.781231201136066 steps:1365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 359: episode_reward:15.099427136303493 steps:1368[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59350
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 360: episode_reward:1.6048664360905596 steps:1372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 361: episode_reward:-3.9121193650048824 steps:1375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 362: episode_reward:8.761867746712145 steps:1378[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44010
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 363: episode_reward:1.2177817834323328 steps:1381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 364: episode_reward:-2.2094633204909653 steps:1383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 365: episode_reward:-1.402258213811369 steps:1386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 366: episode_reward:-2.109570641337238 steps:1389[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.67375
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 367: episode_reward:-1.4634905156002658 steps:1393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 368: episode_reward:-2.3097329173070196 steps:1397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.57338
[RDDPG] Episode Done
[92m [RDDPG] 369: episode_reward:0.44645400725048034 steps:1400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 370: episode_reward:-2.9577546506808265 steps:1403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 371: episode_reward:-1.0504338253632624 steps:1405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 372: episode_reward:-1.8479247151262888 steps:1408[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.43876
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 373: episode_reward:-1.6576780487288443 steps:1411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 374: episode_reward:9.806988938631351 steps:1415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 375: episode_reward:-0.2482409913868624 steps:1418[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.93213
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 376: episode_reward:-0.42382445892473175 steps:1421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 377: episode_reward:-3.2255060904559993 steps:1423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 378: episode_reward:-1.0337205198740218 steps:1426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 379: episode_reward:-2.021843627356127 steps:1429[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.45116
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 380: episode_reward:-2.6974309027640926 steps:1432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 381: episode_reward:-4.468448351236052 steps:1435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 382: episode_reward:0.008447576530920209 steps:1438[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24598
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 383: episode_reward:-3.048847762483301 steps:1441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 384: episode_reward:-1.76419193781562 steps:1444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 385: episode_reward:0.42315666681229125 steps:1446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 386: episode_reward:-2.0946107736312434 steps:1449[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.92204
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 387: episode_reward:-2.3656379056106287 steps:1452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 388: episode_reward:0.7252696276882724 steps:1456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.78519
[RDDPG] Episode Done
[92m [RDDPG] 389: episode_reward:1.7995899136543572 steps:1460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 390: episode_reward:-4.921803429685809 steps:1462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 391: episode_reward:-0.8405119003926966 steps:1465[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 392: episode_reward:-2.7076489009427793 steps:1467[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44755
[RDDPG] Episode Done
[92m [RDDPG] 393: episode_reward:-2.109966159231472 steps:1470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 394: episode_reward:-2.1706957687522204 steps:1473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 395: episode_reward:7.9772238841779854 steps:1476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 396: episode_reward:-2.2112330602728636 steps:1479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.66139
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 397: episode_reward:-2.8804326353318723 steps:1482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 398: episode_reward:-3.4461073384734577 steps:1485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 399: episode_reward:10.707977172791141 steps:1488[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.44443
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 400: episode_reward:-1.535574488645642 steps:1492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 401: episode_reward:-3.880014033716505 steps:1494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 402: episode_reward:-1.4578898725662053 steps:1497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.53128
[RDDPG] Episode Done
[92m [RDDPG] 403: episode_reward:-0.9335096898098949 steps:1500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 404: episode_reward:-2.1693093218142296 steps:1503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 405: episode_reward:-2.4617222114936026 steps:1506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 406: episode_reward:-1.7907770817114754 steps:1509[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.78066
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 407: episode_reward:-1.9602319997767694 steps:1512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 408: episode_reward:-2.8823001376250814 steps:1515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 409: episode_reward:15.564550963930222 steps:1518[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.53609
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 410: episode_reward:-3.5357459150059083 steps:1521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 411: episode_reward:-1.245525082030657 steps:1524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 412: episode_reward:0.4417913633087269 steps:1527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.63853
[RDDPG] Episode Done
[92m [RDDPG] 413: episode_reward:0.3065261872745739 steps:1530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 414: episode_reward:8.904728381788384 steps:1534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 415: episode_reward:-0.979371920077871 steps:1537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.83677
[RDDPG] Episode Done
[92m [RDDPG] 416: episode_reward:9.946230448637708 steps:1540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 417: episode_reward:-0.49182257244983374 steps:1543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 418: episode_reward:-1.4200551098222105 steps:1546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 419: episode_reward:35.457416640567644 steps:1549[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.34893
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 420: episode_reward:-4.094961666964886 steps:1552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 421: episode_reward:14.597069478080295 steps:1555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 422: episode_reward:-3.662591095462502 steps:1558[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31940
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 423: episode_reward:0.8892207709443376 steps:1561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 424: episode_reward:-2.605849816237928 steps:1564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 425: episode_reward:-1.8866528938429932 steps:1567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.86369
[RDDPG] Episode Done
[92m [RDDPG] 426: episode_reward:38.30609154345073 steps:1570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 427: episode_reward:-1.748222754147164 steps:1573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 428: episode_reward:-4.327947207936786 steps:1576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 429: episode_reward:-1.4635871611783127 steps:1579[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.54784
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 430: episode_reward:21.805758778030423 steps:1582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 431: episode_reward:-0.6221612568001795 steps:1585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 432: episode_reward:-0.14642396637422417 steps:1588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.00456
[RDDPG] Episode Done
[92m [RDDPG] 433: episode_reward:0.0926203627964366 steps:1590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 434: episode_reward:-5.474874382407591 steps:1592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 435: episode_reward:2.2571870690664904 steps:1595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 436: episode_reward:-2.7184858526281217 steps:1598[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.74098
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 437: episode_reward:0.29453326555531056 steps:1601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 438: episode_reward:-2.7567144606800276 steps:1604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 439: episode_reward:-2.966961527097885 steps:1607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.96439
[RDDPG] Episode Done
[92m [RDDPG] 440: episode_reward:-3.8318640586885664 steps:1610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 441: episode_reward:-1.5336726670354517 steps:1613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 442: episode_reward:-1.3998017552355613 steps:1616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 443: episode_reward:1.5422162415793648 steps:1619[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.30541
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 444: episode_reward:5.053031219798935 steps:1622[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 445: episode_reward:-4.058085667482425 steps:1625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 446: episode_reward:-2.2747037400981833 steps:1628[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.33138
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 447: episode_reward:-1.0677990555105759 steps:1631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 448: episode_reward:-3.9332932776300193 steps:1634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 449: episode_reward:-2.5347539800423884 steps:1637[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.90457
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 450: episode_reward:-0.06564406036450676 steps:1641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 451: episode_reward:-1.487265870708229 steps:1644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 452: episode_reward:-1.9770715438643927 steps:1647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.76479
[RDDPG] Episode Done
[92m [RDDPG] 453: episode_reward:16.967345651433547 steps:1650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 454: episode_reward:-1.6099469246187295 steps:1653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 455: episode_reward:-1.907158265270855 steps:1656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 456: episode_reward:-1.4129700585365603 steps:1659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.81424
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 457: episode_reward:-3.243754122403823 steps:1662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 458: episode_reward:-0.49242405110059195 steps:1665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 459: episode_reward:-4.4351946004896075 steps:1668[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.03802
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 460: episode_reward:-2.1934372248548106 steps:1671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 461: episode_reward:-3.366753159606249 steps:1674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 462: episode_reward:-0.7167194314835688 steps:1677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.66566
[RDDPG] Episode Done
[92m [RDDPG] 463: episode_reward:-2.7000405817450783 steps:1680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 464: episode_reward:0.7427331386052467 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 465: episode_reward:-2.2049600813753285 steps:1687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.10898
[RDDPG] Episode Done
[92m [RDDPG] 466: episode_reward:0.9943583668741041 steps:1690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 467: episode_reward:-1.0969341365719165 steps:1693[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 468: episode_reward:-2.270694939884294 steps:1695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 469: episode_reward:13.288201277398478 steps:1698[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.61335
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 470: episode_reward:-0.8322953258804544 steps:1701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 471: episode_reward:-3.2197141673105545 steps:1704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 472: episode_reward:-2.5311356204461624 steps:1708[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49565
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 473: episode_reward:-3.475167123780376 steps:1711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 474: episode_reward:-2.8015230857448756 steps:1714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 475: episode_reward:-3.7032662595704315 steps:1717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97355
[RDDPG] Episode Done
[92m [RDDPG] 476: episode_reward:-1.5092264696733528 steps:1720[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 477: episode_reward:-1.3899422453255799 steps:1723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 478: episode_reward:2.875264073313451 steps:1726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 479: episode_reward:-2.4420916488311466 steps:1729[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.90113
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 480: episode_reward:-2.4974797274306186 steps:1732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 481: episode_reward:1.2791600547739375 steps:1735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 482: episode_reward:-3.7846374785249965 steps:1738[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23150
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 483: episode_reward:-4.248329271359683 steps:1741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 484: episode_reward:-1.7372148470216424 steps:1743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 485: episode_reward:-2.6919331517621994 steps:1746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 486: episode_reward:-1.3449141170478975 steps:1749[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.28440
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 487: episode_reward:-1.727865601395099 steps:1752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 488: episode_reward:-1.1342435946286227 steps:1755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 489: episode_reward:-1.7341965761170632 steps:1758[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.76753
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 490: episode_reward:-2.5902379933995747 steps:1761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 491: episode_reward:-3.6369105833513924 steps:1764[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 492: episode_reward:-1.739633429289347 steps:1767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.68644
[RDDPG] Episode Done
[92m [RDDPG] 493: episode_reward:-0.7258245321381547 steps:1770[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 494: episode_reward:-1.2071567049943897 steps:1773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 495: episode_reward:-5.362353301250563 steps:1775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 496: episode_reward:-5.434232518750092 steps:1777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.67317
[RDDPG] Episode Done
[92m [RDDPG] 497: episode_reward:-3.580719660623066 steps:1780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 498: episode_reward:-2.6816165303631867 steps:1783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 499: episode_reward:2.099369162518825 steps:1786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 500: episode_reward:-2.3051950810839954 steps:1789[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.99990
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 501: episode_reward:-3.0954912025737937 steps:1792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 502: episode_reward:-0.9075257220389048 steps:1795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 503: episode_reward:-3.655993268050096 steps:1797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.53544
[RDDPG] Episode Done
[92m [RDDPG] 504: episode_reward:-3.8841231280937976 steps:1800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 505: episode_reward:-0.02597346270691503 steps:1803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 506: episode_reward:-0.5452425788198694 steps:1806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 507: episode_reward:-1.9511813237767595 steps:1808[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08111
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 508: episode_reward:-1.6567683095516998 steps:1811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 509: episode_reward:-1.3258066081516502 steps:1814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 510: episode_reward:-0.746967576599102 steps:1817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.80310
[RDDPG] Episode Done
[92m [RDDPG] 511: episode_reward:-0.10356299860714735 steps:1820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 512: episode_reward:0.31054062214541656 steps:1823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 513: episode_reward:4.713633989568044 steps:1826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 514: episode_reward:10.022350076033879 steps:1829[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.17179
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 515: episode_reward:1.3410725238543044 steps:1832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 516: episode_reward:-3.420359930837998 steps:1835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 517: episode_reward:-2.941258445751732 steps:1838[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40991
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 518: episode_reward:-0.8780998987596094 steps:1841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 519: episode_reward:36.96593301827303 steps:1844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 520: episode_reward:-3.3224224810654763 steps:1846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 521: episode_reward:8.387883110238615 steps:1849[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.27796
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 522: episode_reward:-4.875481671458205 steps:1851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 523: episode_reward:-2.38634479477823 steps:1854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 524: episode_reward:-2.5705583962414025 steps:1857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09553
[RDDPG] Episode Done
[92m [RDDPG] 525: episode_reward:82.74574769764955 steps:1860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 526: episode_reward:-1.9132805652480072 steps:1863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 527: episode_reward:-1.8729400285392173 steps:1866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 528: episode_reward:-3.178006674982602 steps:1869[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.46718
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 529: episode_reward:2.5378273850050945 steps:1872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 530: episode_reward:-1.941720390189367 steps:1875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 531: episode_reward:-2.0039387299580778 steps:1878[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.85080
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 532: episode_reward:-0.7958562960426692 steps:1881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 533: episode_reward:-0.45810503635582367 steps:1884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 534: episode_reward:-3.923477055943425 steps:1886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 535: episode_reward:0.8970354017525941 steps:1889[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.01889
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 536: episode_reward:-3.7991699606104805 steps:1892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 537: episode_reward:0.8081036172876201 steps:1895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 538: episode_reward:-1.3155816744671707 steps:1898[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.63368
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 539: episode_reward:0.9888184809908158 steps:1901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 540: episode_reward:-3.75618221719392 steps:1903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 541: episode_reward:0.4345104648988931 steps:1906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 542: episode_reward:-2.987895409872818 steps:1909[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.85905
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 543: episode_reward:-1.593822580281259 steps:1912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 544: episode_reward:-1.1402484847206646 steps:1915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 545: episode_reward:-0.18910405632603444 steps:1918[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12120
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 546: episode_reward:1.533581479846681 steps:1921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 547: episode_reward:-0.3210221009019061 steps:1924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 548: episode_reward:773.0201523149959 steps:1927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.88450
[RDDPG] Episode Done
[92m [RDDPG] 549: episode_reward:2.9753220171738812 steps:1930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 550: episode_reward:-5.548095280908418 steps:1932[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 551: episode_reward:-1.0351852194189508 steps:1935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 552: episode_reward:-3.97925256834195 steps:1938[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.70689
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 553: episode_reward:-3.131042204597927 steps:1941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 554: episode_reward:-1.2429946172022182 steps:1944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 555: episode_reward:-0.09872115904206424 steps:1947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.81270
[RDDPG] Episode Done
[92m [RDDPG] 556: episode_reward:-0.23767054107982477 steps:1950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 557: episode_reward:-2.194190160930324 steps:1953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 558: episode_reward:-0.8478466122123345 steps:1956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 559: episode_reward:-2.3637275195511993 steps:1959[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.92041
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 560: episode_reward:-2.7607711587724246 steps:1961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 561: episode_reward:-3.1043306878616708 steps:1964[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 562: episode_reward:-0.2199723320208582 steps:1967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.04803
[RDDPG] Episode Done
[92m [RDDPG] 563: episode_reward:-2.551739662654081 steps:1970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 564: episode_reward:-3.7810030916786084 steps:1973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 565: episode_reward:6.452379899365198 steps:1976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 566: episode_reward:-1.4507237653140503 steps:1979[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.29241
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 567: episode_reward:-0.21502882004695523 steps:1982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 568: episode_reward:0.015928659635759956 steps:1985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 569: episode_reward:-3.9037191877387682 steps:1987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.10545
[RDDPG] Episode Done
[92m [RDDPG] 570: episode_reward:0.6547145077944183 steps:1990[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 571: episode_reward:0.07345215555141671 steps:1993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 572: episode_reward:-3.7231105326022265 steps:1996[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 573: episode_reward:-0.01683373206400951 steps:1999[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.53884
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 574: episode_reward:0.1042143094258492 steps:2002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 575: episode_reward:0.5657112844297867 steps:2005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 576: episode_reward:9.08778897073016 steps:2008[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71716
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 577: episode_reward:1.9520084031059466 steps:2011[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 578: episode_reward:-3.6871849131508894 steps:2013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 579: episode_reward:-3.319272907227312 steps:2016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 580: episode_reward:-2.0072540383558506 steps:2019[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.83840
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 581: episode_reward:-0.8468518421566271 steps:2022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 582: episode_reward:-0.15192443711037829 steps:2025[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 583: episode_reward:-3.3981581181657763 steps:2027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.06170
[RDDPG] Episode Done
[92m [RDDPG] 584: episode_reward:-2.3205502883659106 steps:2030[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 585: episode_reward:-1.6264157412956797 steps:2032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 586: episode_reward:-4.467534932037357 steps:2035[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 587: episode_reward:0.21656690299827153 steps:2038[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.48048
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 588: episode_reward:-0.18782222253582703 steps:2041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 589: episode_reward:-3.8901927680719286 steps:2044[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 590: episode_reward:-3.615205295263324 steps:2046[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 591: episode_reward:1.4909318155179263 steps:2049[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.46744
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 592: episode_reward:18.291586895783233 steps:2052[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 593: episode_reward:-2.2845376505583057 steps:2055[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 594: episode_reward:-4.0347431159709775 steps:2057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.92234
[RDDPG] Episode Done
[92m [RDDPG] 595: episode_reward:-2.1911617180724834 steps:2060[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 596: episode_reward:1.2237189439846774 steps:2063[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 597: episode_reward:0.12113515162961264 steps:2066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 598: episode_reward:-0.8211625264978486 steps:2068[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.68172
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 599: episode_reward:-1.814957927595189 steps:2071[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 600: episode_reward:9.120051760635759 steps:2075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 601: episode_reward:-2.7391136074204576 steps:2078[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.68810
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 602: episode_reward:-2.876837662414671 steps:2081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 603: episode_reward:1.2819154882028805 steps:2084[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 604: episode_reward:0.30208691182784086 steps:2087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.42901
[RDDPG] Episode Done
[92m [RDDPG] 605: episode_reward:-1.309366234433673 steps:2090[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 606: episode_reward:2.3056237898409533 steps:2093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 607: episode_reward:-2.9754223587030393 steps:2096[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 608: episode_reward:1.0095750983454677 steps:2099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.21924
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 609: episode_reward:2.6574157753788894 steps:2102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 610: episode_reward:-3.2523855675192683 steps:2105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 611: episode_reward:-1.953770407919427 steps:2108[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34461
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 612: episode_reward:-1.5685095050537208 steps:2111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 613: episode_reward:0.9675051347235031 steps:2114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 614: episode_reward:-0.6123801741452182 steps:2117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 615: episode_reward:-2.5334863184478014 steps:2119[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.88914
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 616: episode_reward:-1.490069047755572 steps:2122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 617: episode_reward:-0.9202784132084778 steps:2125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 618: episode_reward:-1.725877394051012 steps:2128[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.69577
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 619: episode_reward:0.03579348350603828 steps:2131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 620: episode_reward:-0.9382098469111448 steps:2134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 621: episode_reward:-3.409414598455988 steps:2136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29996
[RDDPG] Episode Done
[92m [RDDPG] 622: episode_reward:3.3225722299317177 steps:2140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 623: episode_reward:-2.4568949608280644 steps:2143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 624: episode_reward:-3.912919142440215 steps:2146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 625: episode_reward:-2.7290594500582888 steps:2148[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30821
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 626: episode_reward:-1.5789732875563753 steps:2151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 627: episode_reward:-1.3743223689304498 steps:2154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 628: episode_reward:-3.1848358442367295 steps:2157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62188
[RDDPG] Episode Done
[92m [RDDPG] 629: episode_reward:2.9173090562063324 steps:2160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 630: episode_reward:-1.5109845101960269 steps:2163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 631: episode_reward:-2.737366810571734 steps:2165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 632: episode_reward:-2.5332241329023506 steps:2168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.01112
[RDDPG] Episode Done
[92m [RDDPG] 633: episode_reward:-0.7874694306301553 steps:2170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 634: episode_reward:2.6576859940735598 steps:2173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 635: episode_reward:-4.073388605127745 steps:2175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 636: episode_reward:0.8536102241826331 steps:2178[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.39085
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 637: episode_reward:-2.0495931671091365 steps:2181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 638: episode_reward:-3.231807850124026 steps:2184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 639: episode_reward:-2.9664559940086175 steps:2187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.84520
[RDDPG] Episode Done
[92m [RDDPG] 640: episode_reward:-3.54734832704983 steps:2190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 641: episode_reward:-3.1726091750170284 steps:2192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 642: episode_reward:-2.7679264100850665 steps:2194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 643: episode_reward:-1.8844356133358875 steps:2196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 644: episode_reward:-3.606542348013118 steps:2199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.42177
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 645: episode_reward:-0.6651022516707301 steps:2202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 646: episode_reward:-0.32531916088667145 steps:2205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 647: episode_reward:-0.8536736571693555 steps:2208[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21217
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 648: episode_reward:-2.67841612812332 steps:2211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 649: episode_reward:-2.5153234219505007 steps:2214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 650: episode_reward:0.09471373593526344 steps:2217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 651: episode_reward:-5.029881503435885 steps:2219[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.20181
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 652: episode_reward:1.6686348287292416 steps:2222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 653: episode_reward:-1.915577672079934 steps:2225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 654: episode_reward:-3.178132237381466 steps:2227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.82719
[RDDPG] Episode Done
[92m [RDDPG] 655: episode_reward:-1.5778276070628727 steps:2230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 656: episode_reward:2.0139085913451535 steps:2233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 657: episode_reward:-3.541384553728373 steps:2235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 658: episode_reward:-1.1468265191862366 steps:2237[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.79006
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 659: episode_reward:-4.026518140649449 steps:2241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 660: episode_reward:-1.4664377485004072 steps:2246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 661: episode_reward:-3.775306008744771 steps:2248[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30672
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 662: episode_reward:-1.4327389297674176 steps:2251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 663: episode_reward:-1.972282239444164 steps:2253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 664: episode_reward:1.3424938925429837 steps:2256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 665: episode_reward:0.24998349484567006 steps:2259[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.46508
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 666: episode_reward:-5.145922819982161 steps:2261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 667: episode_reward:-3.867727344480473 steps:2264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 668: episode_reward:-1.475874822152747 steps:2267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18425
[RDDPG] Episode Done
[92m [RDDPG] 669: episode_reward:-0.6930956705249827 steps:2270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 670: episode_reward:-2.8261747923975786 steps:2272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 671: episode_reward:-1.5577580208498765 steps:2274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 672: episode_reward:-1.2923495113711805 steps:2277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.35564
[RDDPG] Episode Done
[92m [RDDPG] 673: episode_reward:-3.118099309661069 steps:2280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 674: episode_reward:-2.2523024509999043 steps:2282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 675: episode_reward:-2.794759748310538 steps:2284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 676: episode_reward:-2.866002534725588 steps:2287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49528
[RDDPG] Episode Done
[92m [RDDPG] 677: episode_reward:-0.535574709636145 steps:2290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 678: episode_reward:-2.53338643730927 steps:2292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 679: episode_reward:-4.623996184019449 steps:2294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 680: episode_reward:-3.3135414156864185 steps:2296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 681: episode_reward:-0.7781107460161139 steps:2299[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.18275
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 682: episode_reward:-2.4773209176212703 steps:2301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 683: episode_reward:-3.1696886206586443 steps:2303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 684: episode_reward:-2.9618708308336394 steps:2305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 685: episode_reward:-2.5243930322612695 steps:2307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.93299
[RDDPG] Episode Done
[92m [RDDPG] 686: episode_reward:-2.35346128600883 steps:2310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 687: episode_reward:-0.9515702900536334 steps:2313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 688: episode_reward:-4.268756532851667 steps:2316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 689: episode_reward:-4.606651461629816 steps:2318[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.70084
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 690: episode_reward:-1.7773943757791986 steps:2321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 691: episode_reward:-0.16146066123482816 steps:2324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 692: episode_reward:-1.936332184628843 steps:2326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 693: episode_reward:-2.0587949118102298 steps:2328[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.53106
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 694: episode_reward:-3.4238546528260896 steps:2331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 695: episode_reward:-3.0080239345085626 steps:2334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 696: episode_reward:-0.5787847452979129 steps:2337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.15499
[RDDPG] Episode Done
[92m [RDDPG] 697: episode_reward:1.2667336223240113 steps:2340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 698: episode_reward:-2.99580208468 steps:2343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 699: episode_reward:-1.7382619739268899 steps:2346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 700: episode_reward:-3.4224865756386498 steps:2348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.72482
[RDDPG] Episode Done
[92m [RDDPG] 701: episode_reward:-4.213933795013742 steps:2350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 702: episode_reward:0.3961554031161909 steps:2352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 703: episode_reward:-3.6330392788148105 steps:2354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 704: episode_reward:-2.5825264717070997 steps:2356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 705: episode_reward:-1.6321203526651384 steps:2358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05380
[RDDPG] Episode Done
[92m [RDDPG] 706: episode_reward:-4.255191551548739 steps:2360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 707: episode_reward:8.626662931266388 steps:2363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 708: episode_reward:0.8570540561082667 steps:2365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 709: episode_reward:-3.9868508548045054 steps:2367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.26847
[RDDPG] Episode Done
[92m [RDDPG] 710: episode_reward:-3.084507778116899 steps:2370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 711: episode_reward:-0.6230241989633987 steps:2372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 712: episode_reward:1.4424329062116361 steps:2374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 713: episode_reward:-4.226435259492842 steps:2376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 714: episode_reward:-3.5825099654746535 steps:2378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.84516
[RDDPG] Episode Done
[92m [RDDPG] 715: episode_reward:4.758338430235424 steps:2380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 716: episode_reward:0.2692144053293912 steps:2382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 717: episode_reward:-3.7324435805777036 steps:2385[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 718: episode_reward:-4.018138369551142 steps:2388[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.84297
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 719: episode_reward:-1.2539371205014698 steps:2391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 720: episode_reward:2.8138223165958474 steps:2393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 721: episode_reward:-2.2823041577422583 steps:2396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 722: episode_reward:-1.5992537066825339 steps:2399[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.35675
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 723: episode_reward:-2.6245820503591126 steps:2401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 724: episode_reward:-2.3230642338939713 steps:2404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 725: episode_reward:3.3716721626820148 steps:2406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 726: episode_reward:-2.727271481671668 steps:2409[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.66387
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 727: episode_reward:-2.927456266500716 steps:2411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 728: episode_reward:-3.351188580987153 steps:2414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 729: episode_reward:-3.0613780220733475 steps:2416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 730: episode_reward:-0.9034692104199138 steps:2419[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.82761
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 731: episode_reward:-4.977502829533908 steps:2421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 732: episode_reward:-3.604130011884923 steps:2423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 733: episode_reward:-3.9300263439349807 steps:2426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 734: episode_reward:-2.4110303575727925 steps:2428[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.02391
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 735: episode_reward:0.9301961797619054 steps:2431[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 736: episode_reward:-0.9286962227707738 steps:2434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 737: episode_reward:-3.6315308158285253 steps:2436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 738: episode_reward:-0.4281939115732287 steps:2439[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35461
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 739: episode_reward:-3.193538333042418 steps:2441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 740: episode_reward:0.11528597628159964 steps:2444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 741: episode_reward:-1.2360549455404302 steps:2447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 742: episode_reward:-4.574837476659354 steps:2449[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81620
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 743: episode_reward:-2.147043877350104 steps:2451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 744: episode_reward:-3.5691908431140127 steps:2453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 745: episode_reward:-1.9503964275395735 steps:2455[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 746: episode_reward:-1.9042799329899847 steps:2458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54501
[RDDPG] Episode Done
[92m [RDDPG] 747: episode_reward:-1.1436071680498037 steps:2460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 748: episode_reward:-2.859147913134416 steps:2462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 749: episode_reward:-3.4620014221382824 steps:2464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 750: episode_reward:-0.7849032115933516 steps:2466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 751: episode_reward:-2.6734851201787775 steps:2468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24817
[RDDPG] Episode Done
[92m [RDDPG] 752: episode_reward:-1.427930407730645 steps:2470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 753: episode_reward:-1.4943530966895076 steps:2473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 754: episode_reward:-3.5830197694741077 steps:2475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 755: episode_reward:-0.1596188589893197 steps:2478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.91082
[RDDPG] Episode Done
[92m [RDDPG] 756: episode_reward:-4.251227464007882 steps:2480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 757: episode_reward:-0.25387238819946667 steps:2482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 758: episode_reward:-2.323341067538977 steps:2484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 759: episode_reward:4.179377469955178 steps:2487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.43155
[RDDPG] Episode Done
[92m [RDDPG] 760: episode_reward:-3.202139813946793 steps:2490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 761: episode_reward:3.2579030577928028 steps:2493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 762: episode_reward:-3.3143400871852773 steps:2495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 763: episode_reward:-2.2213886208004263 steps:2497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.28853
[RDDPG] Episode Done
[92m [RDDPG] 764: episode_reward:0.9946120368406661 steps:2500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 765: episode_reward:-1.6274126174173276 steps:2503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 766: episode_reward:-2.910446116315418 steps:2505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 767: episode_reward:-4.418069920093303 steps:2507[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 768: episode_reward:-3.435105451011741 steps:2509[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.40591
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 769: episode_reward:-2.0280134286145106 steps:2512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 770: episode_reward:0.5492011729263835 steps:2517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21526
[RDDPG] Episode Done
[92m [RDDPG] 771: episode_reward:0.5040109699308593 steps:2520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 772: episode_reward:-5.285225253512696 steps:2522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 773: episode_reward:-1.507279737006196 steps:2524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 774: episode_reward:-0.7708375734879089 steps:2527[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.58538
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 775: episode_reward:2.9520441608062136 steps:2531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 776: episode_reward:-2.385308813805686 steps:2533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 777: episode_reward:-4.134267969201176 steps:2535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 778: episode_reward:-3.3103518212124614 steps:2537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.72453
[RDDPG] Episode Done
[92m [RDDPG] 779: episode_reward:-1.131683812156214 steps:2540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 780: episode_reward:0.5326513709010712 steps:2543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 781: episode_reward:0.037773950813931645 steps:2546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 782: episode_reward:-2.7763018644203576 steps:2548[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.20056
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 783: episode_reward:-2.326501691292437 steps:2551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 784: episode_reward:-2.4466772421349354 steps:2554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 785: episode_reward:-2.601901511923 steps:2556[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 786: episode_reward:-4.31577436407126 steps:2558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.17334
[RDDPG] Episode Done
[92m [RDDPG] 787: episode_reward:-3.341408136438338 steps:2560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 788: episode_reward:-3.5215525457215167 steps:2562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 789: episode_reward:-1.5815956725636535 steps:2565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 790: episode_reward:-3.88662803090017 steps:2567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37131
[RDDPG] Episode Done
[92m [RDDPG] 791: episode_reward:-3.4954220511432936 steps:2570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 792: episode_reward:6.342378373336123 steps:2573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 793: episode_reward:-4.054849882048233 steps:2575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 794: episode_reward:-1.9309720200583755 steps:2578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49120
[RDDPG] Episode Done
[92m [RDDPG] 795: episode_reward:-4.5307713625462185 steps:2580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 796: episode_reward:-4.3538456154520055 steps:2582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 797: episode_reward:-1.4209027411832813 steps:2585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 798: episode_reward:-3.544712907788775 steps:2587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 799: episode_reward:-4.0514543757904145 steps:2589[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.14601
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 800: episode_reward:-3.258902529905275 steps:2591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 801: episode_reward:-0.5705490311305792 steps:2594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 802: episode_reward:-1.2394341027702267 steps:2596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 803: episode_reward:-0.5846396846371813 steps:2599[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.35278
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 804: episode_reward:-4.529787857922736 steps:2601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 805: episode_reward:4.184941030737746 steps:2606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 806: episode_reward:-1.2867383289921723 steps:2609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.31088
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 807: episode_reward:-2.8551125640533765 steps:2612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 808: episode_reward:-2.0813486842591056 steps:2615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 809: episode_reward:-4.14880621672255 steps:2618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.54075
[RDDPG] Episode Done
[92m [RDDPG] 810: episode_reward:0.7544215277027657 steps:2620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 811: episode_reward:-1.2049612034286779 steps:2623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 812: episode_reward:-1.9526749073614393 steps:2625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 813: episode_reward:-1.6979965032048154 steps:2628[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.68223
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 814: episode_reward:111.68441713235222 steps:2631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 815: episode_reward:-3.5778063745662023 steps:2633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 816: episode_reward:-3.9972942574470585 steps:2636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 817: episode_reward:-1.6980612912329902 steps:2639[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.14554
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 818: episode_reward:-3.3556129211738157 steps:2641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 819: episode_reward:-3.493759925183574 steps:2643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 820: episode_reward:-3.7454286092523263 steps:2646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 821: episode_reward:-2.6223455830706532 steps:2649[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.48024
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 822: episode_reward:-2.9119125543245667 steps:2651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 823: episode_reward:-2.4528304935549614 steps:2654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 824: episode_reward:-3.455765139952444 steps:2657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 825: episode_reward:16.862361861087763 steps:2659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.38511
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 826: episode_reward:0.9482483789689327 steps:2662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 827: episode_reward:-1.7649451319971419 steps:2665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 828: episode_reward:-1.8597080345267543 steps:2667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 829: episode_reward:-3.33228271232999 steps:2669[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.63134
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 830: episode_reward:-2.285352648295748 steps:2671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 831: episode_reward:-3.040563392604991 steps:2673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 832: episode_reward:-0.49321111189735767 steps:2676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 833: episode_reward:-2.461272387853513 steps:2678[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12255
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 834: episode_reward:-2.2605922585174207 steps:2681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 835: episode_reward:-2.524879003077187 steps:2683[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 836: episode_reward:-0.988584491576521 steps:2686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 837: episode_reward:-2.2995440168777455 steps:2688[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59861
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 838: episode_reward:0.35503049763692296 steps:2691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 839: episode_reward:-0.7777090630437598 steps:2693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 840: episode_reward:-2.4442849993834552 steps:2696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 841: episode_reward:-2.813455223362031 steps:2698[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31436
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 842: episode_reward:-3.590800919401755 steps:2701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 843: episode_reward:-2.5186060034627853 steps:2704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 844: episode_reward:-1.5012947887168677 steps:2707[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29862
[RDDPG] Episode Done
[92m [RDDPG] 845: episode_reward:-0.21087805993929054 steps:2710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 846: episode_reward:-2.8192591696339475 steps:2713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 847: episode_reward:-0.7789071886245331 steps:2716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 848: episode_reward:-0.7063153206402841 steps:2719[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.22324
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 849: episode_reward:-4.978068541496178 steps:2722[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 850: episode_reward:-0.6329170570627638 steps:2725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 851: episode_reward:-1.586662857440981 steps:2728[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27487
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 852: episode_reward:-1.191756234140598 steps:2731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 853: episode_reward:-1.0078587951528821 steps:2734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 854: episode_reward:-3.621163471996706 steps:2736[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 855: episode_reward:-0.571742964566345 steps:2739[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.00803
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 856: episode_reward:-2.7759715138626486 steps:2741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 857: episode_reward:-4.07614833342861 steps:2743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 858: episode_reward:-2.601710029923616 steps:2746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 859: episode_reward:-0.8459284233393554 steps:2749[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.03396
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 860: episode_reward:-0.8692832441044396 steps:2751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 861: episode_reward:-4.1123116467277825 steps:2754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 862: episode_reward:-3.4404493928359985 steps:2757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 863: episode_reward:-3.1525926196362697 steps:2759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.76139
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 864: episode_reward:-0.9487903300308989 steps:2762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 865: episode_reward:-3.4502843505467506 steps:2765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 866: episode_reward:-1.8183920353268073 steps:2767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 867: episode_reward:-0.36128471465759815 steps:2769[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.76185
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 868: episode_reward:-2.2412156679503075 steps:2772[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 869: episode_reward:-0.928673895225822 steps:2775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 870: episode_reward:-2.2218041466573077 steps:2778[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20933
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 871: episode_reward:-3.509685257988666 steps:2781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 872: episode_reward:-1.4194461310256443 steps:2784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 873: episode_reward:-2.977823207930221 steps:2786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 874: episode_reward:-1.9959913349984297 steps:2788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97678
[RDDPG] Episode Done
[92m [RDDPG] 875: episode_reward:-3.2673298893056475 steps:2790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 876: episode_reward:-2.608998061940974 steps:2792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 877: episode_reward:-2.997074086849036 steps:2795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 878: episode_reward:-4.56006369631676 steps:2798[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08918
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 879: episode_reward:-4.404579342624883 steps:2801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 880: episode_reward:-2.9897082868842935 steps:2803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 881: episode_reward:-3.105941287067133 steps:2806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 882: episode_reward:-3.770595003991795 steps:2808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.86695
[RDDPG] Episode Done
[92m [RDDPG] 883: episode_reward:-3.329992466048826 steps:2810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 884: episode_reward:66.17181327462659 steps:2813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 885: episode_reward:-3.752544128986435 steps:2816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 886: episode_reward:-1.9871626693680238 steps:2818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12950
[RDDPG] Episode Done
[92m [RDDPG] 887: episode_reward:-3.244720190162475 steps:2820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 888: episode_reward:-1.1057329820045394 steps:2823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 889: episode_reward:-1.6889885554726547 steps:2826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 890: episode_reward:9.999451321919292 steps:2828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18034
[RDDPG] Episode Done
[92m [RDDPG] 891: episode_reward:-3.2071902604770064 steps:2830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 892: episode_reward:-0.888838929173275 steps:2833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 893: episode_reward:-3.936622546564384 steps:2836[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    #rospy.sleep(0.5)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 15:42:27.902629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:29417): Gdk-CRITICAL **: 15:42:30.077: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 2, in <module>
    from rl.torch.rdpg import RDPG
  File "/app/rl/torch/rdpg.py", line 347
    total_policy_loss.backward)
                              ^
SyntaxError: unmatched ')'
2021-05-04 15:43:01.161867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:29692): Gdk-CRITICAL **: 15:43:03.202: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620142985.806882946, 1.358000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620142985.807726163, 1.358000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620142985.807769552, 1.358000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[33m[ WARN] [1620142986.640447613, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640511141, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640528272, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640546447, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640561228, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640575998, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640590452, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640614508, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640629057, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640644032, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640670299, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 2.187000 according to authority unknown_publisher[0m
[33m[ WARN] [1620142986.640688680, 2.187000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 2.187000 according to authority unknown_publisher[0m
[0m[ INFO] [1620142987.031357510, 2.577000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620142987.656220207, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620142988.460774047, 4.002000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620142989.261403631, 4.801000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2341229.322634016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.2664087468035365 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.0282593696920483 steps:4[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:1.974481420476569 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-3.0411315557566554 steps:10[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-1.3183587056965642 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-3.2152155823174127 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.9221571225332355 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:25.195266602886154 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-3.1758460526733776 steps:26[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-3.9804201053379424 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:18.37401901059095 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-0.18180165590760566 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:4.251254961806598 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-2.9142343308025556 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:1.625603601719984 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-0.606555184151524 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:4.71335528376979 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-1.5135308708332607 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:25.17702854228083 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-1.2848507346079727 steps:65[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 964, in reset
    A, B = AB
ValueError: not enough values to unpack (expected 2, got 1)
2021-05-04 15:44:57.587676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:30722): Gdk-CRITICAL **: 15:44:59.718: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143103.964957394, 3.283000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143103.966093321, 3.284000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143103.966280156, 3.284000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143105.294481048, 4.608000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143106.097502950, 5.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143106.904617973, 6.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143107.705782647, 7.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1784734.9468483224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:5.899345343757959 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:13.713947309967956 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:1.23282644211816 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-0.6281591661519323 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:4.387724070235547 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:12.210511370233494 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:14.09081247809589 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.762339032597747 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-2.040576555551839 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.5472115096226848 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:33.72300646489984 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.475719400634784 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-0.7187417799456362 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.7385992372212866 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-2.698371793545641 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-0.8983720851303012 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-4.876955312365947 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:1.494543195239503 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.3941203695931623 steps:66[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 964, in reset
    A, B = AB
ValueError: not enough values to unpack (expected 2, got 1)
2021-05-04 15:46:43.947650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:31773): Gdk-CRITICAL **: 15:46:46.085: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143208.745993967, 1.547000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143208.746795913, 1.547000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143208.746844678, 1.547000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143209.988051150, 2.782000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143210.806036922, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143211.608084326, 4.402000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143212.610203296, 5.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:31457111.71303171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.011795208000653 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.8953751236918148 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.5861596487636707 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.2487504083252365 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:17.9343278850583 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-5.004809342645389 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-4.070843448005273 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:2.696751136066162 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:47.20099672983553 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-2.375521970227923 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-3.16962914032654 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-3.0088529476039962 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:1.661734292624912 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.5915954295841046 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:15.969373766074632 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:51.5463925574619 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-1.5135489599089467 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-2.253476541634906 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-6.848411141323618 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:18.37397535290222 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-0.1185276818332004 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-2.3043957151681917 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:0.033747713722262596 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-2.388939493714533 steps:83[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-4.072438592640565 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-1.9195489582949354 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-1.3468405682506097 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-1.6153519375681031 steps:98[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-3.4041752847556905 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-1.2048888279855468 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 242, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 15:48:33.910902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:633): Gdk-CRITICAL **: 15:48:36.155: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143319.381984821, 2.380000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143319.382886445, 2.380000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143319.382932055, 2.380000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143320.726667020, 3.711000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143321.417064856, 4.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143322.221106571, 5.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143323.025639530, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2887669.913415401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.6134594244229072 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.7424427706042138 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:129.24738682162686 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-3.62940347168293 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.2820804785156357 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-3.4829727681358458 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.744548086493084 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.710691155695425 steps:21[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:194.1226259998881 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:56.792151881423045 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-4.442408634990266 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-5.560975321473871 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-3.339048993438323 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.1175547131968298 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:0.3811667144966475 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:3.453814458793908 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:1.4264369666673344 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-5.2101577970042445 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.469002829651635 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:5.32754908221159 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:0.9087344812716092 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:4.406731224491615 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-3.117581704902822 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-7.160153570618953 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-3.7988863042348195 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-2.4343659765498806 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-1.6856882514580698 steps:94[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:40.987549075163194 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-3.5694646908518948 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 242, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 15:50:17.489163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:2070): Gdk-CRITICAL **: 15:50:19.589: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143423.314169975, 2.538000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143423.315398506, 2.542000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143423.315459184, 2.542000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143424.612946375, 3.820000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143425.410612409, 4.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143426.218597330, 5.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143427.020511527, 6.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:15876125.655457059[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:0.11864461321788022 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:0.5558514484013122 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:6.0145350944265505 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:1.4241145625771559 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:0.11096639186011537 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:134.49198943080577 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:5.204071005169804 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:0.7547584871037785 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-2.3982436649097103 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-3.0364289641307094 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:3.7042126036006597 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.5615381942284974 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.7208651533091075 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.280285186282765 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-5.394384907556446 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:0.9293877936112862 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-2.7943177553741467 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:0.34669850452800155 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-0.3647847837629281 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-1.5648002687962679 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-2.5425754702849996 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.9554054772311096 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-2.995745134167441 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-3.3994236060036815 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:4.292194926969847 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:9.190536739660796 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-3.9637220603175507 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-2.747751035506315 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-3.177485039606778 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-2.1753992863621145 steps:102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:5.312446502165315 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 242, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 15:52:06.375711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:3409): Gdk-CRITICAL **: 15:52:08.478: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143531.741117871, 2.236000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143531.742182187, 2.236000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143531.742329566, 2.236000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143533.117082136, 3.603000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143533.916601375, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143534.716641100, 5.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143535.728540525, 6.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2384386.3958915207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:8.92100794633202 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-3.1001740686743897 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:11.044511147880861 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-4.581683068099996 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-3.0220928555448854 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-0.9744461909191244 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.5932604362694898 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.231733867598751 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-2.963027374879369 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:9.031089121716002 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-2.935138847162382 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:8.108218285760664 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-3.2637453697203114 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.6855080794678876 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-1.6773085980062221 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-1.1775935726401303 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:39.76814284878929 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:5.343608731839598 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:52.94885160749684 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.0243094917200457 steps:57[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-4.4884816021728255 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-4.008954189103132 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:5.634985327671239 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-3.1571272470278453 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-1.9925519899746442 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-1.1162191847557388 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:16.347461200805824 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-2.297172806488674 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.533847031002563 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-4.907561811772062 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:0.40516520023886926 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-1.6203715940173264 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-3.6862502011495866 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:0.9052607027557005 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:12.320926922324377 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 242, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 15:54:16.642463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:4814): Gdk-CRITICAL **: 15:54:18.725: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143661.421853973, 1.566000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143661.422763139, 1.568000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143661.422813456, 1.568000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143662.589977907, 2.718000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143663.273305216, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143664.077636742, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143664.878674706, 5.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3345999.4015219626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.931381848427918 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-3.4591902250894937 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.680298501915468 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:1.0616968320081601 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 242, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 15:55:48.455487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:5494): Gdk-CRITICAL **: 15:55:50.536: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143754.099185017, 2.462000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143754.100378696, 2.464000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143754.100523914, 2.464000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143755.451544881, 3.803000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143756.451294396, 4.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143757.252324686, 5.597000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143758.054998424, 6.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:12859469.935853612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.5689625643596767 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-3.3100963604480476 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:11.548029733415483 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 346, in update_policy
    total_value_loss.backward()
UnboundLocalError: local variable 'total_value_loss' referenced before assignment
2021-05-04 15:57:28.279862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:6161): Gdk-CRITICAL **: 15:57:30.425: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143853.052299341, 1.470000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143853.053597455, 1.472000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143853.053707757, 1.472000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143854.314091126, 2.720000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143854.999934475, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143855.805603183, 4.202000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143856.606557130, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2846220.0319343028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-4.30576386237465 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:15.372420439637448 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.6014769821350905 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 355, in update_policy
    del total_value_loss
UnboundLocalError: local variable 'total_value_loss' referenced before assignment
2021-05-04 15:59:00.995828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:6816): Gdk-CRITICAL **: 15:59:03.152: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620143946.062756345, 1.954000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620143946.063775060, 1.957000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620143946.063817530, 1.957000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620143947.252811024, 3.128000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620143947.931618941, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620143948.731208842, 4.600000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620143949.541836053, 5.400000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:2419916.213869032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-6.356173750998702 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:17.3996657490616 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.4380450872202806 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 4.13388
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:1.6470277582014328 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[W python_anomaly_mode.cpp:104] Warning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 311, in update_policy
    current_q = self.agent.critic(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 360, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 346, in update_policy
    value_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 16:01:00.691900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:7510): Gdk-CRITICAL **: 16:01:02.801: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620144065.596702276, 1.775000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620144065.597854709, 1.776000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620144065.598073948, 1.776000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620144067.045370709, 3.216000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620144067.773002139, 3.940000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620144068.573615804, 4.739000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620144069.375501852, 5.539000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1781994.7162760023[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.5611149852332327 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:4.077887568012071 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-4.103479982358399 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
here
here
here
here
[RDDPG] Update Time: 4.30077
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-0.43880070440478947 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[W python_anomaly_mode.cpp:104] Warning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 312, in update_policy
    current_q = self.agent.critic(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 360, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 347, in update_policy
    value_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 16:03:39.992260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:8203): Gdk-CRITICAL **: 16:03:42.173: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620144225.576403907, 2.552000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620144225.577297127, 2.552000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620144225.577586154, 2.553000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620144226.942263727, 3.903000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620144227.581668562, 4.541000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620144228.381935076, 5.340000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620144229.183393430, 6.139000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:1696112.40599661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:10.077423587363143 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-4.393591834866757 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-4.097939165572706 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
here
here
here
here
[RDDPG] Update Time: 3.98048
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:6.2788651983237305 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-0.6694070359630859 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[W python_anomaly_mode.cpp:104] Warning: Error detected in AddmmBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 312, in update_policy
    current_q = self.agent.critic(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 360, in forward
    return self.out_dense_seq(torch.cat([ms, rs, ac], -1))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 159, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 347, in update_policy
    value_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [72, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!
2021-05-04 16:09:37.893416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:8906): Gdk-CRITICAL **: 16:09:39.944: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620144582.715670475, 1.724000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620144582.716492341, 1.724000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620144582.716573133, 1.724000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620144583.972701386, 2.969000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620144584.405362067, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620144585.009725358, 4.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620144585.622098686, 4.600000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1575537.8284612265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.9809908892022112 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-3.1508190378719627 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-4.519636711125639 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:0.026836410119431164 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
here
here
here
here
[RDDPG] Update Time: 4.41804
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:1.8512794221727698 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.92869
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:143.50687352104924 steps:23[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.98711
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:1.4864508354920931 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.78230
[RDDPG] Last Step of episode
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.82106
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:9.598719244896019 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-2.920642356866597 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.88473
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:9.881147168427047 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.77397
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:0.7823081365149989 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.37480
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.0822749234404405 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.873254743200527 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.28161
[RDDPG] Last Step of episode
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:4.045126609399499 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.15310
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:0.8437484016070766 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.70352
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:4.061479266826316 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 3.75421
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:2.348582783462546 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-4.034964653539848 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.87948
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:104.90977482880618 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.36096
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.2471859742889584 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
here
here
here
here
here
[RDDPG] Update Time: 4.37385
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 133, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1021, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/app/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
2021-05-04 16:15:02.814708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:10039): Gdk-CRITICAL **: 16:15:04.847: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620144908.230805597, 2.273000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620144908.231974620, 2.273000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620144908.232041923, 2.273000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620144909.621240103, 3.658000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620144910.365843485, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620144911.166445127, 5.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620144911.968050398, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1969574.7795946472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.3238534476243933 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.6904295766183868 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.488463195501921 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.441243593391231 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-3.291198512287689 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:0.41924026700092654 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:8.41699224330759 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:1.3921180236421407 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-4.239634771238677 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-2.0060475765107864 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:8.350249887573273 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.899356120639667 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.8653028836323142 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.1241637990603526 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:18.700166528162132 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-1.5526181679517603 steps:65[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-2.4053232915655602 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:11.813310158881785 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.4154976813917775 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-0.824406464508749 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-3.7519602741130242 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.5090527204752373 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-2.3740882301416306 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:5.860231411416913 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-6.699015453033691 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-3.8226550662536214 steps:96[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:38.77346622754037 steps:102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-4.050058778769565 steps:108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:4.098594211969207 steps:114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-4.080355649394107 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-6.08791024243243 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-2.7112769887020525 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-0.5441772887626191 steps:128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:36.74504590713283 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-4.07088585615136 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-3.4369181708803156 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-0.16733006986898324 steps:147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-0.7725624709861432 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-1.489652742346306 steps:155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-4.57394506913825 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:4.3225810900787 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-4.134410533302851 steps:164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:1.4191039628920956 steps:167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:4.595934141704758 steps:171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-5.44596828719353 steps:174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:4.1780788558091375 steps:180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-3.6340778266524327 steps:182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-3.6479921618777853 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-4.658865268969889 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:16.03069895461103 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-2.7788314057802475 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-2.8850427220020487 steps:194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-2.777638952535927 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-2.9976899537361783 steps:200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-1.9843580299855725 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-2.119761551272501 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-5.305266087890669 steps:208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-2.4396282235828397 steps:210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-3.50885809271405 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-2.671697450901825 steps:214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-3.130142721732747 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:44.736194922481396 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-6.201297033704561 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:13.10306321338577 steps:228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-4.436257252010137 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-3.291741154985233 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-2.6950766340371626 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-3.1454207987742944 steps:240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-1.7538307366870491 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:123.11559397108111 steps:246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-2.4480465728330136 steps:248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-3.2295319689463193 steps:250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-3.15530120117608 steps:253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-3.0819755869566374 steps:255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:0.6821714663430671 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:9.828865554521144 steps:261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:0.4768453246892608 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-2.738858380937463 steps:270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-5.510067423196693 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-0.5447288070099501 steps:278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-4.480545442353712 steps:281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-1.1416500971816688 steps:285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:1.153688673804544 steps:288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-0.42471807435011977 steps:290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-0.7796982203838101 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-4.046245949796371 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:14.9922343802261 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-0.06598331136546598 steps:305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-5.120316314792067 steps:309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-2.756628617112786 steps:314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-2.706029175829765 steps:316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-4.946106976549698 steps:322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:31.44604312707324 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-1.6191916662722778 steps:331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-3.383494423642249 steps:336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:0.008179690645118143 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-3.3366324473246816 steps:341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-0.6102424645346058 steps:346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-3.1452717874156213 steps:350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:7.468339816997155 steps:355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.2484242957039566 steps:362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1.5169326956956302 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-6.233627016097582 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-3.178985799875159 steps:375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-2.400111236022978 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:0.1273841773635911 steps:379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-4.132859216083736 steps:383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-4.0749376925833225 steps:386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-0.9422476458641662 steps:389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:0.6844559112943323 steps:392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-1.220648252397147 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:2.2915599751621323 steps:397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-3.930267437213285 steps:399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:0.02134052352893745 steps:402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-2.334278860402632 steps:404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-3.168474093247676 steps:406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-4.807448828009623 steps:410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-0.6637215392979865 steps:415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-5.211239418599595 steps:421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-4.544029521497054 steps:425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-3.6267647810054076 steps:427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-3.7306612700868733 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:30.03949716334349 steps:433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:6.267297173968422 steps:435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-2.9907986815084886 steps:437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-1.6070499585501294 steps:439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-2.43230544145562 steps:443[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:8.819854078899274 steps:445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-1.5432742123465626 steps:447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:38.177326863482044 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-2.8873449568755634 steps:453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-0.28234741591949497 steps:456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:3.3472483152542267 steps:460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-8.005949648542334 steps:466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:9.76546037384345 steps:472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-1.7297773033182913 steps:475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:0.40113931264852454 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-2.6454452181343098 steps:481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:0.6169502600381622 steps:483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:0.17728123366387072 steps:495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-2.2062117705036783 steps:499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-1.6371977768320438 steps:501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-4.049929611286933 steps:505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-1.8202781704327209 steps:507[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-3.9879381273096186 steps:511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-12.587606542624764 steps:520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:-4.764000375283224 steps:523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-2.9001682259480264 steps:525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:20.81221685631162 steps:532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:1.5906461651961723 steps:535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-0.3108372790537848 steps:540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-2.788704070288141 steps:543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-1.9161740743524898 steps:547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:-5.092955469466464 steps:551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:0.9215841717335223 steps:553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-3.43404231811329 steps:558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:-2.1068363972014295 steps:560[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:-4.487393834838848 steps:562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-4.216461901952451 steps:564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-2.1935282925534025 steps:566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-0.0782128360398282 steps:570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-4.019275634112721 steps:573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-0.8562138593916204 steps:576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:3.810746358208223 steps:580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-6.869234059594653 steps:591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:11.053966323990467 steps:596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:1.477721033054494 steps:599[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:19.761669069952934 steps:602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:10.315064420467156 steps:608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:-5.727473634415955 steps:613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-3.9808458096139905 steps:617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-2.0094051054000848 steps:618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-0.020822990356665905 steps:626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:3.3423452408533674 steps:633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-3.6306235334420025 steps:635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:0.6133344887710823 steps:638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:-3.820424919271714 steps:640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-0.6208504077461097 steps:645[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:1.7763466613064676 steps:648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-0.47365439530880726 steps:651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:-2.0996686584986155 steps:654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:5.4802598015289465 steps:657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-0.4734188229010754 steps:661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-2.0795697682189775 steps:662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-2.5164067171062783 steps:665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-2.9419580337214852 steps:669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-3.7378871599467756 steps:675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-1.9100593741144738 steps:677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-3.94545961101084 steps:680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:9.872677811604099 steps:686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:1.1777100183002704 steps:691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-1.8842650987052485 steps:694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-3.425149105854674 steps:696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:-3.6333398860461217 steps:700[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:4.88547621825502 steps:704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-4.603751179831947 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:-3.686498000650395 steps:711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-2.4070380420522333 steps:715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:-4.444357224870661 steps:718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:-3.786548984330932 steps:725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:-1.9982928766012469 steps:729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:-3.3995517806050746 steps:732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-5.102508476991337 steps:737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:-0.8007183127679569 steps:740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:2.2459206095155135 steps:743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:-3.37946105110777 steps:749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-0.7996773667148924 steps:751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:9.521495630141025 steps:755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-3.009632555367425 steps:757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:19.171405517895305 steps:762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:172.94576772578634 steps:765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:15.22369890826073 steps:771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:14.746164216566044 steps:777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:-3.52611927215412 steps:780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:-8.849648266133359 steps:787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-2.5141605138066927 steps:792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-4.539484858185065 steps:795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:3.398590501858041 steps:798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-3.0667660135967614 steps:800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:39.85930010064806 steps:810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:-1.6070429788195555 steps:812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:1.0430681160769426 steps:816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:-0.7896885036410426 steps:818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:38.755610054922144 steps:823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:-3.8438040282018617 steps:827[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-1.5257819031540283 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:7.130546216156716 steps:833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:-1.4327684134403715 steps:835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:0.9353911553155991 steps:837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:15.994171794272216 steps:840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:2.3635382494770343 steps:846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:-2.9249297726346346 steps:848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:-1.2681468043483508 steps:852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-3.3842804846373244 steps:855[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-2.3260600518136796 steps:857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-3.702622119914783 steps:860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-3.8435055925132353 steps:863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:-1.712702546590374 steps:865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-4.51653356140138 steps:868[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:2.1545130255215756 steps:872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-3.3490640197644828 steps:877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:-3.657479495381919 steps:879[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:-4.501473610485752 steps:884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:6.69355678421789 steps:892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:2.428068282929251 steps:896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:2.0395563764949745 steps:900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:-4.610349594087314 steps:902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:-7.228037761563444 steps:907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-4.310662774012363 steps:911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-3.741702545332438 steps:914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:68.398369599284 steps:918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:-1.210462209613372 steps:924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-4.088428586231052 steps:927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:-0.06371713976439786 steps:930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:-3.8947527335897303 steps:933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-0.3426249367526055 steps:935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-2.610397386940785 steps:938[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-0.7177851249049763 steps:942[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-2.193119692062636 steps:944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:22.716595002974977 steps:950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-2.6836831170074316 steps:952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:-2.857333124600827 steps:956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:-2.4154543921052642 steps:958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:-1.148393108818547 steps:961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-2.804062371079721 steps:963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:1.9028447467555396 steps:966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:-1.0588168903003994 steps:970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:-1.2324943933383519 steps:972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-3.1244693041971816 steps:975[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:-1.5826640611585072 steps:978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:-2.058683981647941 steps:981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:1.6139394670122469 steps:984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:-3.5996646894399857 steps:986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:-0.8413934865939867 steps:995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-6.183129215497839 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 14.44278
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:63.17696881106073 steps:1011[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 12.90018
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:77.21950429003962 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:25.531267147940724 steps:1028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.76608
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:3.862520417163512 steps:1035[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:13.890996006991337 steps:1042[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 13.57921
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:24.899676465545657 steps:1054[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:13.820309051727284 steps:1063[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 14.16083
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:-2.179024428262455 steps:1067[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 13.51070
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:31.398480801028338 steps:1086[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-2.951770040515688 steps:1088[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:1.7454493109838305 steps:1090[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 14.48702
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:3.9174627552948493 steps:1099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 14.19033
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:22.433221848410767 steps:1115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:2.6914502994979115 steps:1119[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.2)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 16:22:48.691246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:18269): Gdk-CRITICAL **: 16:22:50.797: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620145373.460147073, 1.809000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620145373.461113288, 1.810000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620145373.461163861, 1.810000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620145374.712194347, 3.034000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620145375.369283712, 3.690000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620145376.386205336, 4.691000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620145377.191180529, 5.490000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:18280783.746558435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.3479091480833474 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-2.3645672495649626 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:10.71182510169582 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-5.0815526485695885 steps:15[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-0.9086575093927656 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-0.3727410962835105 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-1.3411484855723668 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:0.7956744988370437 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:0.2332687424817066 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.2872608007184203 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-3.8151114620162936 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:7.238731019846671 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.7351184791745768 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.1215387178590936 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-3.2589042918947255 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-5.241691666569856 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-3.374794878024655 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-3.2586541951006813 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.7279486704657065 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-5.911783162507502 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:0.300109418991394 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-2.933828090982962 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:0.6650918687120977 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-3.53824711004002 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-3.9614784024410565 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-4.046189985336336 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-2.9075719806735223 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:35.58240975794407 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:6.455908144458849 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-7.955424485722455 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-1.5752285339156502 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:7.220814472748668 steps:111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-1.808157471111108 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-2.070067111561677 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-1.6355360284054123 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-2.664876101405066 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-2.4043720489419016 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:10.457268258037445 steps:125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:15.721677413282698 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-6.534386617454333 steps:138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-1.0399088666557066 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:74.33307977947149 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:0.326265698707652 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:0.04565558815979909 steps:155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-3.2335576035038915 steps:157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-2.6823620845345957 steps:159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-3.289671473099477 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-0.8127524179058021 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:17.468609336740904 steps:168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-2.8582040455407918 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:2.328599489728073 steps:178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-4.2806502483858075 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:0.2710234040886337 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:12.465849477937464 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:1.3355206700492745 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:60.479699330042706 steps:201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-5.0028809960938645 steps:202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-2.492613226543269 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-2.7503127291900182 steps:208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-0.8050400758343046 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-2.8568941861695007 steps:214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-3.925750023214795 steps:216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-4.840600076003808 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-0.6620758772874691 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-1.6411783048178257 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:21.040628810835994 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-3.3034932406345794 steps:233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-7.00925574988023 steps:238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:63.57885060187239 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-3.48342449248036 steps:246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:1.7099346737898582 steps:251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-1.5358158350492803 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-1.7424058243552878 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-2.820114335393042 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-6.058762916348419 steps:263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-2.724190905821308 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:0.2926528443045746 steps:268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-5.155847822267163 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-0.1939414044930512 steps:276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:0.5181918160245091 steps:279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:7.821678682075751 steps:286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-0.7209828720069376 steps:289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-7.514137475746696 steps:295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-2.626161268204563 steps:297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-5.2454562606032775 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-2.104378597458881 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-1.505853930795049 steps:304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-3.120912567337003 steps:307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-3.1345069774649046 steps:309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-4.313412450210751 steps:316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-1.3050939592105655 steps:320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-2.7403419862592893 steps:322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-3.2925846431079644 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:2.3415072763316056 steps:330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-4.299336756183001 steps:332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-5.299815616676382 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-3.6901161359704293 steps:336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:21.243049212758635 steps:339[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-4.446632939876562 steps:341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-3.6396536074939085 steps:343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.0526836476612664 steps:345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:1.5245613034500698 steps:347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-1.8642365166643013 steps:349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:58.992831112866 steps:352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:14.612818016389255 steps:356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-4.470436378052705 steps:360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-3.3235531313045934 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-4.362863694920778 steps:367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-8.159844163765834 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-5.874864142471724 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-1.095626334466695 steps:383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-1.8370202877767756 steps:387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-4.250006196127223 steps:390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-1.9025015922384276 steps:398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-1.9669886954773863 steps:403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-2.64525752734051 steps:406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-2.2063001739537036 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-2.660660427756575 steps:410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-1.9393713559454342 steps:413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-2.140356134096288 steps:415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-3.3022263791975526 steps:417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:4.917489836873967 steps:421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-1.2281337391386546 steps:425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-2.4994856605132263 steps:428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-2.436823165190104 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:0.24979381445128412 steps:434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-3.4604849209581334 steps:437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-2.667482306225775 steps:439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-4.236505216559109 steps:442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:10.188147134279099 steps:448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:81.92839313028449 steps:452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:5.513498234776702 steps:456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:1.8332056121909588 steps:461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-0.9920611231878087 steps:464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-0.16535462907762266 steps:469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-0.04326979618296134 steps:472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-2.137941201209123 steps:475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-3.620490265048997 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-3.1327200134227766 steps:481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-3.913059833249471 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-3.8088711080380304 steps:487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:4.2717046297237555 steps:490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:10.29018890194838 steps:495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-2.7191513419023314 steps:497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-1.0984653602552772 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-3.33339000981888 steps:502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:23.485560038003584 steps:506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:7.284542427797488 steps:508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-3.2116883976716104 steps:510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-1.2852647420494148 steps:512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-3.546600729254184 steps:514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-0.7300941007590751 steps:516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-1.9527088371555035 steps:518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:-4.315656627215112 steps:520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:6.7719511756402255 steps:522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-2.7041528488535826 steps:525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:-5.803421622655017 steps:527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:10.879816307373716 steps:530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-2.6801134469235883 steps:534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-4.735737529021113 steps:538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-2.582096141286045 steps:541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-1.4635449036168486 steps:545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-0.695478618158722 steps:550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-2.8418355031555107 steps:552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-3.7274209366965043 steps:554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-2.676148259123077 steps:559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:1.0049965521218218 steps:564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-2.5853411339190595 steps:566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:-2.0454650215175647 steps:569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:-2.1668858426812907 steps:571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-3.502984773594623 steps:573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:1.0392189050916376 steps:575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:57.74769903994797 steps:578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-6.334150244238126 steps:583[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-2.642978424677744 steps:587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-1.601134457895394 steps:589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:1.5850987304496025 steps:595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-2.5248688421653585 steps:597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-1.9004268821607346 steps:600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-0.8152890199555869 steps:603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:0.5345694475904663 steps:606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:2.2151710675543885 steps:609[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-3.251606317051844 steps:612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-2.857671155560898 steps:615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-1.6699174954424567 steps:617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-9.36094240210257 steps:619[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-3.3076507875070646 steps:623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-1.4073151166654772 steps:626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-3.704406598557967 steps:628[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-3.6928392990619234 steps:630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:-2.206450128591112 steps:632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-3.833414147636367 steps:634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-0.2963543439820948 steps:637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:26.387053358286305 steps:642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:12.275184577270545 steps:644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-2.381242465784078 steps:647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:0.8291342747885304 steps:652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-4.1209023996162655 steps:656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:-3.193777666776337 steps:658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:-0.9102634912308265 steps:660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:20.526647632637566 steps:664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:-3.4267876105158477 steps:667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-2.4940361645237727 steps:669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:-5.421273578954689 steps:673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:0.47244163717672505 steps:675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:-4.560608032247167 steps:681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-3.461292270296165 steps:684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:-2.364164749722298 steps:686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-0.8904888751039439 steps:689[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:-5.293647063292317 steps:698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:-5.462351226573064 steps:702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:-1.0889400299225258 steps:706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-2.6607060592772505 steps:709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:3.9001173346961675 steps:714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:12.43735535264221 steps:718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-2.9125119766510688 steps:721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-0.9468359921865841 steps:725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:5.305014421971432 steps:729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-0.7786087291217938 steps:734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:-1.8961053809281436 steps:739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:322.6042409617821 steps:744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:-2.5799765749607784 steps:748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:-0.7001259214336408 steps:751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:4.617327303283006 steps:753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:-4.531448975323448 steps:757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-0.4711286315290457 steps:759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:-1.1506233223864637 steps:761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:-2.864975244793235 steps:763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-5.151655334179582 steps:765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:0.5868678049814777 steps:770[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:2.830504768909886 steps:772[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:29.333762684018193 steps:774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:22.34077750484653 steps:780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-2.8095510317441152 steps:782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-2.454288051757773 steps:783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-2.6821771275434365 steps:786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-4.182627924986164 steps:788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:-3.2465135602250808 steps:791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-0.6660898413548635 steps:794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:-4.0698762003214535 steps:798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:11.516200710866151 steps:801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:21.41935399328764 steps:808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:7.986310731986514 steps:811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:-3.144417266155139 steps:814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:-2.8278926800348465 steps:816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:-3.3857160533530677 steps:818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:-2.626413366673657 steps:820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:-2.6617829819441248 steps:822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-3.6261444017772737 steps:824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-2.1753586492524377 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:0.3819941625962868 steps:835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:-0.6215991665889664 steps:837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-8.17592466098503 steps:846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:-2.174133310203173 steps:848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:0.48518528973646236 steps:851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-0.9395723269656866 steps:853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-3.6937426602274206 steps:856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-0.6834719472853448 steps:860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-2.9767186916203157 steps:863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:25.618547484081432 steps:866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-3.1330881992043604 steps:870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:-3.258416143626916 steps:872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:-2.4216127942734866 steps:874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:0.14571713368551276 steps:878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:23.174325152333743 steps:882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:-1.6668859987174827 steps:885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:4.522858950466984 steps:888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:-3.0853481996426737 steps:890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-6.690133939207746 steps:892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:1.0714892563090181 steps:899[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:0.7890083817281432 steps:901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:-3.4140095524788396 steps:907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:-2.4394039107100345 steps:909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:7.783665200473908 steps:918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-4.24863686386108 steps:921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:-2.9536299026241855 steps:923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:-3.8757951106116084 steps:926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:-4.076827354864344 steps:930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:0.8455250149596099 steps:933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-0.6700145335115844 steps:937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:-2.835045534990213 steps:939[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:3.9188488281428455 steps:942[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:20.07783333079662 steps:945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-0.9263174289797005 steps:949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-2.6692900382019875 steps:952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:1.5304053244350326 steps:960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:2.2652750565433966 steps:962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-0.9763301864103595 steps:965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:8.283742137827264 steps:971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-4.014524294315473 steps:973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:-3.47448871843333 steps:979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:84.42289504889348 steps:985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:-0.9235016504806881 steps:989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:-5.129132424375036 steps:999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:-3.6959520248262967 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 10.03393
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:26.62991341503918 steps:1015[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.30425
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:13.973375898716597 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:29.27657864406035 steps:1029[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 964, in reset
    A, B = AB
ValueError: not enough values to unpack (expected 2, got 1)
2021-05-04 16:28:14.214189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:26221): Gdk-CRITICAL **: 16:28:16.376: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620145698.970708220, 1.436000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620145698.971537166, 1.436000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620145698.971586851, 1.436000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620145700.084471921, 2.536000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620145700.750617830, 3.201000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620145701.759696256, 4.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620145702.562655505, 5.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:9692236.899611656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.7462346339051522 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.2828250023689305 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.926044988738056 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-1.7140620216035913 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.1941338135830133 steps:14[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-2.6787386286107546 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:24.739668772238524 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:13.414941749452336 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:1.5482770837344275 steps:30[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.25646719830183295 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:73.67601922122971 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:0.4378470348468224 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.0835663746449375 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:5.3678707536952945 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-0.3903370006378397 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:0.12712616641769658 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:5.58415519830673 steps:65[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-4.277262843275441 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-9.156237032057554 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.8913158964705357 steps:76[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:4.052856335983905 steps:78[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-5.560703121545076 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-3.225189752963262 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:0.30851071550442466 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-2.4934046479635867 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-2.792858969060844 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-2.0469788483145663 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:4.760184602327733 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:32.34800889202022 steps:108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-0.15102707626110012 steps:110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-3.6048355904715756 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:0.6829216817511563 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-1.8982602100279038 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-5.75789553585512 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-3.1594295064959677 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-2.9556551161996905 steps:130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-6.407915497919856 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:2.221729425936652 steps:139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-3.234094570312659 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-3.175836805158511 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-0.45959916944069734 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:44.81894009328296 steps:149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-4.517088627109527 steps:161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-3.799522957909078 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-1.3826383706040721 steps:168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-5.458139118337753 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:0.060126468188926196 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:0.5631868550325874 steps:177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:6.828451837831118 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-1.9824598569309293 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:5.6577655771706326 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-4.302463173584572 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-2.638703721148956 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-3.2752118229349034 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-3.1590043327647894 steps:205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-2.160795480237252 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:0.479287850740755 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:1.5560098822262503 steps:215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-2.963603518715084 steps:217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-2.203538188725233 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-2.910818087658948 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-2.453152923204306 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:38.073297967101595 steps:225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-1.4812122378740136 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-2.7157377650368693 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-1.5996827220436685 steps:231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:2.049291903878257 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-3.775660294686261 steps:238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-3.7507351217359757 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-0.01944449417330718 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-1.176728170007764 steps:248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-2.65611643621068 steps:251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-0.12515074635255585 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-1.0750952150810686 steps:257[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:6.397148355262572 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-0.8322011604236454 steps:261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-3.049263919904446 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:1.543957324105337 steps:268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-2.349146541747988 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-1.200828583958421 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:4.039050796342773 steps:279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-3.914925933760681 steps:281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-4.07151619663675 steps:283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-1.8069960547018102 steps:286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-4.761860642437284 steps:293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-3.3167549954702897 steps:297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:26.876669108618444 steps:306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-3.2677979142737588 steps:309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:0.059748035955117906 steps:314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-1.2721840216455298 steps:316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-2.822151319775287 steps:319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:21.549696004554193 steps:324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-3.6065700411328425 steps:326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-1.1455336143849066 steps:328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-1.5588929393924866 steps:331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-4.8651233234220985 steps:335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:2.4391186954313415 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-3.117175216944568 steps:340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-4.1567011459183885 steps:345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:2.6748906085358346 steps:349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:2.87185882340452 steps:354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1.703569649365447 steps:356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-3.078076638140585 steps:360[00m
[RDDPG] Resetting Environment
[33m[ WARN] [1620145824.329177116, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329264597, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329300828, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329333766, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329366875, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329403854, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329440098, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329477706, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329516228, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329553776, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329585312, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.329622330, 123.900000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 123.880000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620145824.336402460, 123.906000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336465109, 123.906000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336491021, 123.906000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336524241, 123.906000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336545896, 123.906000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336566236, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336586551, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336607636, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336630463, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336652923, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336674304, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 123.880000 according to authority unknown_publisher[0m
[33m[ WARN] [1620145824.336696497, 123.907000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 123.880000 according to authority unknown_publisher[0m
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-3.459980485422861 steps:363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-4.507882216164603 steps:366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-1.5047458392468973 steps:368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-5.048574771306616 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-3.4433589267387297 steps:374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-5.193643101283643 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:2.8850924685869144 steps:380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-2.679920756215994 steps:384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:38.964472601625985 steps:389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-0.6596180115419219 steps:396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-1.8742499838386983 steps:400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-5.412725002169266 steps:404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-2.9485587430431135 steps:406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:10.530197812734636 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-3.7022679461261725 steps:411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-4.1491239647578935 steps:413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-3.0179760675768397 steps:415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-0.8871670260790943 steps:425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-5.448204286699436 steps:428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-2.4877220156841893 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-0.9457671286156626 steps:434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:39.4936154951182 steps:437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-3.8254796510658564 steps:439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-4.277905014622586 steps:443[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-1.6900113356741286 steps:447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:4.010874899284567 steps:452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-2.4309069474234235 steps:454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-3.963670830476275 steps:456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-0.7321496091210706 steps:458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-6.462225881568477 steps:461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-2.8223628882732172 steps:463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-2.8396325014469515 steps:470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-2.7576166076728024 steps:472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-4.151493083931399 steps:474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-2.0608271211967706 steps:477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:4.282176941517659 steps:482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-1.3150622091790225 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-0.5332448568557537 steps:488[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-3.5915771708078945 steps:490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:1.561572002185363 steps:493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:4.346083548786084 steps:499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:2.687502807689686 steps:505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:1.1242836866895631 steps:512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:-1.5024315705048699 steps:515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-2.164623701975553 steps:519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:0.42430839136551013 steps:523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-4.94264822921728 steps:526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-3.362795617345049 steps:530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-3.2574808754799625 steps:533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-3.440035811942961 steps:536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:1.2758488615691528 steps:540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:4.25352001433702 steps:548[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-0.22350030680419364 steps:551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:-3.477111948974505 steps:554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:2.998762575353719 steps:558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-2.7942886151129214 steps:560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-3.6575889291539023 steps:562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:212.46140499040715 steps:569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-3.8502569056407494 steps:572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-1.5021702859288482 steps:574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-3.8837812838880685 steps:577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-3.174001177323303 steps:582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-0.2286280450393834 steps:587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:-3.14761918765168 steps:590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-0.5834761084529587 steps:593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:0.9934878880387172 steps:596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:1.532940575532621 steps:602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:11.73690855274894 steps:604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:3.5363776179661084 steps:607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:46.189635080133684 steps:610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-3.666710925270202 steps:612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-4.186781231271475 steps:616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:1.094762564063652 steps:618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:9.26605730752496 steps:621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-1.3277626956249018 steps:625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:0.3972962751579705 steps:629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:0.5068133172690148 steps:631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:2.024535847755807 steps:634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:4.175785903448386 steps:638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:1.5169730617714823 steps:644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:7.687168795242346 steps:657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-5.0199583009138475 steps:660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-2.650545727750154 steps:663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-2.927531575173901 steps:666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-4.013704263559472 steps:668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-3.444432230927168 steps:675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:11.596239407899397 steps:679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:-2.892863987026518 steps:681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-0.985680316140876 steps:683[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-2.5792740638917144 steps:686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:-2.385217185761626 steps:688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:-3.377502824646459 steps:692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-2.4122873171296013 steps:695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:-2.7887537410999292 steps:697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-2.350741459027267 steps:699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:-3.119707279836537 steps:701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:-3.149630699434783 steps:704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:-6.362186235379414 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:1.5729371708086157 steps:710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-1.4145099950995106 steps:712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:-0.553014013047652 steps:714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:-7.038734002331081 steps:719[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:0.10702859480036508 steps:723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-4.894666226808564 steps:727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:-3.3382827215009234 steps:729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-2.488039837427957 steps:731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:-2.8512253226002975 steps:733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:-5.199080368068145 steps:735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:12.39425125683616 steps:740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-5.212424886830172 steps:744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:-0.7555308483560159 steps:746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:32.453070019498185 steps:751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:9.869245229880745 steps:753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:5.029800020716583 steps:762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:-2.368040457542234 steps:764[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-1.8655530606534003 steps:766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:-3.7476329302367044 steps:768[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:-6.082630217894431 steps:774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:127.88848646276983 steps:778[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:4.441500223030971 steps:780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:-3.7931609688383814 steps:783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:-1.3000771801387587 steps:785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-2.915977784081916 steps:788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:0.7825022149173009 steps:791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:22.466799342684638 steps:796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-1.998298533195403 steps:800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:33.44744449036165 steps:803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:10.101479170374713 steps:808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:-2.36581167088844 steps:810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:6.638487883653877 steps:814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-6.7704982872556645 steps:818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-4.084408160556961 steps:824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-2.691024791821171 steps:826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-1.6279272942781182 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:0.7755117043292401 steps:831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-3.347311943914221 steps:833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:3.936398175650271 steps:836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-3.883013190610112 steps:841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:-1.9666339712974241 steps:844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:29.567646747313102 steps:852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:-4.113126809220859 steps:854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:-3.8339268083039437 steps:856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:-1.4557915387187021 steps:859[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:-4.0075832811290555 steps:862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:28.701109132408373 steps:865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-1.6167242937204866 steps:867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-1.8736745208139323 steps:870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:-0.800957710811876 steps:873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:-0.906224458183249 steps:876[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-3.5276321177121672 steps:878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:0.585990114563733 steps:882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:13.558018251465327 steps:884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-2.8557273265098475 steps:887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-1.931568689143801 steps:890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-5.806402498223539 steps:893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-3.9084120540944545 steps:895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:-3.044584984058052 steps:897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-0.7803479239932223 steps:901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:-3.7373898141742368 steps:904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:4.068813614987244 steps:907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:176.5443655177792 steps:911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-3.9865002816467947 steps:913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:-3.837700624086613 steps:917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:-3.1345176074085703 steps:920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:-2.4697424192157915 steps:922[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-1.6821826875394796 steps:924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:3.0283646395145336 steps:932[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:-3.675654650779065 steps:934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:-3.4945412451392883 steps:936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:-2.7963461226269857 steps:940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:43.94563925130943 steps:944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-2.118142235327475 steps:946[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:-2.2184215029549605 steps:948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:-2.952133325830656 steps:950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:-2.125905866942332 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:-3.7917115119474656 steps:955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-5.02051613044493 steps:958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:-4.071346042733146 steps:963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:-2.6911931840530356 steps:965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:0.41442786057569814 steps:972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-0.28161010187719393 steps:977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-0.8393074123869493 steps:979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:14.506032130475935 steps:981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:-3.4541932268701636 steps:983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-4.132188025000892 steps:986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:-3.284949487914978 steps:988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-3.482516890962077 steps:990[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:12.459150263590848 steps:997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:-2.2993793033579712 steps:999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:-2.007130133184012 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 7.45548
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:2.7996738572340103 steps:1010[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:-1.5082124024103192 steps:1012[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.78550
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:27.704246117351808 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:0.3457541194267044 steps:1023[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.51009
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:38.6168264530399 steps:1039[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.53369
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.17665
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 298: episode_reward:43.29848624733932 steps:1051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 299: episode_reward:4.514368611554291 steps:1056[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.94829
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.50302
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 300: episode_reward:2.829232533781762 steps:1071[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95673
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 301: episode_reward:52.25830902846588 steps:1082[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.40505
[RDDPG] Episode Done
[92m [RDDPG] 302: episode_reward:8.267821659329384 steps:1090[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 303: episode_reward:-0.1787703415631008 steps:1099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.61510
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 304: episode_reward:-9.661762331701118 steps:1104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44912
[RDDPG] Episode Done
[92m [RDDPG] 305: episode_reward:12.539657633704232 steps:1110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 306: episode_reward:7.13520942263813 steps:1117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 307: episode_reward:-3.212675114989133 steps:1119[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.32382
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 308: episode_reward:3.0093439204656933 steps:1123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 309: episode_reward:2.919563077002137 steps:1128[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.21101
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 310: episode_reward:-2.359987445058925 steps:1131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 311: episode_reward:-2.5839493919446435 steps:1133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 312: episode_reward:213.87602928708833 steps:1135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 313: episode_reward:6.425259035023778 steps:1137[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.65800
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 314: episode_reward:4.8040610001458095 steps:1141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 315: episode_reward:-4.117622178968519 steps:1145[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05756
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 316: episode_reward:1.9009339444999651 steps:1151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 317: episode_reward:1.4603196899477422 steps:1156[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.31370
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 318: episode_reward:-0.6157672914315424 steps:1162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 319: episode_reward:4.643119801552476 steps:1166[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.65173
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 320: episode_reward:6.644049752843825 steps:1171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 321: episode_reward:-1.5243373227749348 steps:1174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 322: episode_reward:-0.7265497146437188 steps:1178[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.19674
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 323: episode_reward:4.537684700218156 steps:1183[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91402
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 324: episode_reward:47.5000735577167 steps:1193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 325: episode_reward:-2.1669894706930894 steps:1196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 326: episode_reward:-0.689968440913602 steps:1199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.06264
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 327: episode_reward:3.431989259571283 steps:1203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 328: episode_reward:12.172101455246645 steps:1208[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.67746
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 329: episode_reward:8.15067775755667 steps:1213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 330: episode_reward:7.569087197326597 steps:1217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 331: episode_reward:-2.2415708275630504 steps:1219[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.16948
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 332: episode_reward:-2.001037415089635 steps:1222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 333: episode_reward:-1.2892935188088437 steps:1226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.54621
[RDDPG] Episode Done
[92m [RDDPG] 334: episode_reward:-2.4339037313123044 steps:1230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 335: episode_reward:0.4836844406128815 steps:1234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 336: episode_reward:10.05194995624542 steps:1237[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.16265
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 337: episode_reward:22.139116764545186 steps:1245[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09794
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 338: episode_reward:231.66102336148336 steps:1252[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41541
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 339: episode_reward:6.7828203888467264 steps:1261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 340: episode_reward:-2.6280719741041625 steps:1264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.99484
[RDDPG] Episode Done
[92m [RDDPG] 341: episode_reward:-0.9336645385792091 steps:1270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 342: episode_reward:-0.48443556936412424 steps:1274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 343: episode_reward:-4.524962136158449 steps:1278[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.91827
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 344: episode_reward:-0.49582215677434194 steps:1282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 345: episode_reward:1.3912584878980323 steps:1285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 346: episode_reward:-0.6477105551923694 steps:1288[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.20512
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 347: episode_reward:-1.6928462936718476 steps:1291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 348: episode_reward:-3.0770632760763332 steps:1293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 349: episode_reward:-2.709721512601104 steps:1298[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.40999
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 350: episode_reward:11.760416565187505 steps:1301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 351: episode_reward:-3.4045399812349966 steps:1304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 352: episode_reward:6.988598840744147 steps:1307[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.47217
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 353: episode_reward:-2.7785078064835718 steps:1311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 354: episode_reward:-2.614685082626201 steps:1314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 355: episode_reward:-2.91082728911555 steps:1317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06241
[RDDPG] Episode Done
[92m [RDDPG] 356: episode_reward:-2.441464992702051 steps:1320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 357: episode_reward:-0.6481559052669195 steps:1324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 358: episode_reward:0.03830191817836148 steps:1327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46991
[RDDPG] Episode Done
[92m [RDDPG] 359: episode_reward:-2.1350945448790775 steps:1330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 360: episode_reward:-3.3006830995625562 steps:1333[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 361: episode_reward:-3.3404485814465277 steps:1337[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.93412
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 362: episode_reward:10.818911117159589 steps:1341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 363: episode_reward:-1.2995798637414662 steps:1344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 364: episode_reward:-1.8139084403751162 steps:1346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 365: episode_reward:-0.897218244318938 steps:1349[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.31567
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 366: episode_reward:1.9319400127420847 steps:1355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 367: episode_reward:-3.5496001643922463 steps:1359[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72708
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 368: episode_reward:-2.2316997716391533 steps:1362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 369: episode_reward:-0.21572254332887342 steps:1366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 370: episode_reward:-4.608714620549527 steps:1369[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.22758
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 371: episode_reward:-3.4868599046875306 steps:1373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 372: episode_reward:-4.2266118540380155 steps:1375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 373: episode_reward:-2.7241960070346596 steps:1378[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67107
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 374: episode_reward:-4.275076118507228 steps:1381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 375: episode_reward:-2.49136009010647 steps:1384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 376: episode_reward:-1.6168551236249111 steps:1387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 377: episode_reward:-3.2475850867372333 steps:1389[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.87781
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 378: episode_reward:-3.057000854195353 steps:1392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 379: episode_reward:-2.043416846393558 steps:1395[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 380: episode_reward:-3.524460300373136 steps:1398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76259
[RDDPG] Episode Done
[92m [RDDPG] 381: episode_reward:-2.5339427286680003 steps:1400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 382: episode_reward:-2.086281692764288 steps:1403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 383: episode_reward:-4.2832391404673755 steps:1406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 384: episode_reward:-2.863925545295303 steps:1409[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.59036
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 385: episode_reward:-3.6547689507157717 steps:1411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 386: episode_reward:-3.0397723389157805 steps:1414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 387: episode_reward:0.04294304280269445 steps:1417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 388: episode_reward:-4.660058712832276 steps:1419[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91764
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 389: episode_reward:-2.5485763500400673 steps:1422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 390: episode_reward:-1.2128973119470228 steps:1425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 391: episode_reward:-3.787890675904929 steps:1429[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72233
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 392: episode_reward:-3.3687742481558014 steps:1432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 393: episode_reward:-3.7263910845775485 steps:1435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 394: episode_reward:-1.8855223548407887 steps:1438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68520
[RDDPG] Episode Done
[92m [RDDPG] 395: episode_reward:-3.2497649340172323 steps:1440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 396: episode_reward:-2.787147230563674 steps:1442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 397: episode_reward:-1.8489090015163108 steps:1445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 398: episode_reward:-2.7640803694723832 steps:1448[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.17810
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 399: episode_reward:-3.5866813855386326 steps:1451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 400: episode_reward:-3.1054494236424572 steps:1454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 401: episode_reward:-2.0559835799465573 steps:1457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.99775
[RDDPG] Episode Done
[92m [RDDPG] 402: episode_reward:-3.148636607169011 steps:1460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 403: episode_reward:-2.7410128882556837 steps:1463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 404: episode_reward:-0.8708984178430219 steps:1467[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50902
[RDDPG] Episode Done
[92m [RDDPG] 405: episode_reward:-3.7049903173468137 steps:1470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 406: episode_reward:-2.0129244559028674 steps:1473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 407: episode_reward:-1.052893007979958 steps:1476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 408: episode_reward:-3.03118573152542 steps:1479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.27850
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 409: episode_reward:-0.7656034763481003 steps:1482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 410: episode_reward:-3.513722676169758 steps:1484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 411: episode_reward:-3.6379225476163013 steps:1486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 412: episode_reward:-1.41646944063966 steps:1489[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.65164
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 413: episode_reward:-2.3291817797600665 steps:1492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 414: episode_reward:-3.4909533792395844 steps:1495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 415: episode_reward:-4.786494719509291 steps:1497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66036
[RDDPG] Episode Done
[92m [RDDPG] 416: episode_reward:-2.7679146763991165 steps:1500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 417: episode_reward:-0.005388284313811109 steps:1503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 418: episode_reward:-3.9268670287132634 steps:1506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 419: episode_reward:-4.184608446250074 steps:1509[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95486
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 420: episode_reward:-2.7792030499115774 steps:1512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 421: episode_reward:-3.42659915181115 steps:1514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 422: episode_reward:-2.950371171754214 steps:1517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.29964
[RDDPG] Episode Done
[92m [RDDPG] 423: episode_reward:-2.253589591265772 steps:1520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 424: episode_reward:-1.305130617311744 steps:1523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 425: episode_reward:-1.3256315093185669 steps:1526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 426: episode_reward:-3.1928944990948795 steps:1529[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.18151
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 427: episode_reward:-3.8315304018026355 steps:1531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 428: episode_reward:-0.679085853110398 steps:1533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 429: episode_reward:-1.8824534402323496 steps:1536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 430: episode_reward:-2.5752713520071877 steps:1538[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35596
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 431: episode_reward:6.956044170677659 steps:1541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 432: episode_reward:-3.2754496632918118 steps:1544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 433: episode_reward:-4.496682906616272 steps:1546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 434: episode_reward:-1.3217875531495271 steps:1549[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.73286
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 435: episode_reward:-1.30698734054545 steps:1552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 436: episode_reward:-4.028691262572436 steps:1554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 437: episode_reward:-2.070083225962824 steps:1557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.72843
[RDDPG] Episode Done
[92m [RDDPG] 438: episode_reward:-1.6099702361989827 steps:1560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 439: episode_reward:-3.9797230394522076 steps:1562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 440: episode_reward:-0.9999804804813359 steps:1565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 441: episode_reward:-3.379661799755399 steps:1567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.96488
[RDDPG] Episode Done
[92m [RDDPG] 442: episode_reward:4.986126810916606 steps:1570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 443: episode_reward:-4.287062664530746 steps:1573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 444: episode_reward:-4.594313597601657 steps:1575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 445: episode_reward:-2.526109556185328 steps:1578[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.28773
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 446: episode_reward:-3.26157419324291 steps:1582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 447: episode_reward:-3.5556851800360514 steps:1585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 448: episode_reward:-3.6491963027720455 steps:1588[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20104
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 449: episode_reward:-2.7454188991863604 steps:1591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 450: episode_reward:-0.33325019719546267 steps:1594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 451: episode_reward:-0.960539606684911 steps:1597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.65599
[RDDPG] Episode Done
[92m [RDDPG] 452: episode_reward:-2.279808504826285 steps:1600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 453: episode_reward:-2.9707737969384524 steps:1603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 454: episode_reward:-2.4289698339703762 steps:1606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 455: episode_reward:1.8578277959332223 steps:1609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91021
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 456: episode_reward:-2.773545913097414 steps:1612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 457: episode_reward:-1.8653045597743108 steps:1615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 458: episode_reward:-1.194128426715368 steps:1618[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.75344
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 459: episode_reward:-2.346301435465217 steps:1621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 460: episode_reward:-3.365205469775702 steps:1624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 461: episode_reward:-3.312768551022157 steps:1627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.02644
[RDDPG] Episode Done
[92m [RDDPG] 462: episode_reward:-2.787165267441101 steps:1630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 463: episode_reward:-2.2723892704776065 steps:1633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 464: episode_reward:-3.4391729226705676 steps:1636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 465: episode_reward:-2.1156494710264337 steps:1639[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.39535
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 466: episode_reward:50.30185240988001 steps:1641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 467: episode_reward:-0.6238415995003379 steps:1644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 468: episode_reward:-2.709549917345315 steps:1647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.47512
[RDDPG] Episode Done
[92m [RDDPG] 469: episode_reward:-2.6369917057618357 steps:1650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 470: episode_reward:-2.8745999949547616 steps:1653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 471: episode_reward:-2.6513502014281167 steps:1656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 472: episode_reward:-2.6801554213653236 steps:1659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.09142
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 473: episode_reward:-3.544661300749864 steps:1662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 474: episode_reward:-4.4781165279598385 steps:1665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 475: episode_reward:0.13513866452701073 steps:1668[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75383
/app/reward/__init__.py:28: RuntimeWarning: invalid value encountered in true_divide
  dl = np.abs(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 476: episode_reward:-6.591440788050848 steps:1672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 477: episode_reward:-2.675165557122125 steps:1674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 478: episode_reward:4.902598305867053 steps:1677[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.10649
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 479: episode_reward:-2.499609208606625 steps:1681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 480: episode_reward:-1.6476830957969835 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 481: episode_reward:-2.536654184604357 steps:1687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.48142
[RDDPG] Episode Done
[92m [RDDPG] 482: episode_reward:38.93030109819721 steps:1690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 483: episode_reward:-4.336378468937635 steps:1693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 484: episode_reward:-3.419403227069873 steps:1696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 485: episode_reward:0.01887394533604514 steps:1699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64781
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 486: episode_reward:-3.99364493590626 steps:1702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 487: episode_reward:-2.39382536285424 steps:1706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 488: episode_reward:8.358605741565675 steps:1709[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06208
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 489: episode_reward:6.701266300651792 steps:1712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 490: episode_reward:-1.8812902742979851 steps:1715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 491: episode_reward:-2.425569197662056 steps:1718[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21523
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 492: episode_reward:5.394361723541788 steps:1721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 493: episode_reward:-2.20454351632564 steps:1724[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 494: episode_reward:-2.688521693318086 steps:1727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.29193
[RDDPG] Episode Done
[92m [RDDPG] 495: episode_reward:-0.47607072733764255 steps:1730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 496: episode_reward:0.15114530543730664 steps:1733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 497: episode_reward:-1.9186518788689393 steps:1737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.45209
[RDDPG] Episode Done
[92m [RDDPG] 498: episode_reward:-1.675346053063323 steps:1740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 499: episode_reward:-2.35984670748823 steps:1743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 500: episode_reward:-2.9316991297474084 steps:1746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 501: episode_reward:-3.4726400186392827 steps:1748[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.36165
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 502: episode_reward:-1.9788709898047554 steps:1751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 503: episode_reward:-1.7649029379836634 steps:1754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 504: episode_reward:-0.8457981839900766 steps:1757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.17722
[RDDPG] Episode Done
[92m [RDDPG] 505: episode_reward:1.9428458491282745 steps:1760[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 506: episode_reward:-4.216383213739278 steps:1763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 507: episode_reward:-2.241261365019724 steps:1766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 508: episode_reward:-2.010875428428568 steps:1769[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.78067
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 509: episode_reward:-3.327436609584799 steps:1771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 510: episode_reward:-3.311084869879833 steps:1774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 511: episode_reward:-4.2976027640914465 steps:1776[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 512: episode_reward:0.19755295469400203 steps:1779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.01311
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 513: episode_reward:-3.258780750981452 steps:1781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 514: episode_reward:-2.4832190025219387 steps:1784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 515: episode_reward:-4.044337569938733 steps:1786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 516: episode_reward:-3.0327036064940365 steps:1788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.87923
[RDDPG] Episode Done
[92m [RDDPG] 517: episode_reward:-3.6186121363382635 steps:1790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 518: episode_reward:-0.4653682514981332 steps:1793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 519: episode_reward:-2.0044714530003622 steps:1796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 520: episode_reward:-4.753001831955612 steps:1798[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53750
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 521: episode_reward:-0.32958517127159404 steps:1801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 522: episode_reward:-4.037015715024176 steps:1803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 523: episode_reward:-2.1397070744886637 steps:1806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 524: episode_reward:-2.43301966135945 steps:1808[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62695
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 525: episode_reward:7.692711318372924 steps:1811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 526: episode_reward:-2.772797265205684 steps:1813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 527: episode_reward:1.0988498436474181 steps:1816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 528: episode_reward:-0.2986042625323624 steps:1819[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73092
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 529: episode_reward:-0.49943381090370464 steps:1822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 530: episode_reward:8.554381339978484 steps:1825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 531: episode_reward:-2.4368063823598343 steps:1827[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 532: episode_reward:-5.058387916053675 steps:1829[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.71425
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 533: episode_reward:-2.991932352262251 steps:1831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 534: episode_reward:-4.477785448356338 steps:1833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 535: episode_reward:-4.516531628978721 steps:1835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 536: episode_reward:-3.6461426501836462 steps:1837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78051
[RDDPG] Episode Done
[92m [RDDPG] 537: episode_reward:-4.594067411893464 steps:1840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 538: episode_reward:-4.014294026550379 steps:1842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 539: episode_reward:11.5144056091944 steps:1844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 540: episode_reward:-0.9194158761401277 steps:1847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.36330
[RDDPG] Episode Done
[92m [RDDPG] 541: episode_reward:-2.7402183858648748 steps:1850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 542: episode_reward:-2.388150810011805 steps:1852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 543: episode_reward:-1.685442871187437 steps:1854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 544: episode_reward:-3.2567775220211717 steps:1856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 545: episode_reward:-3.261357860128413 steps:1858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.38968
[RDDPG] Episode Done
[92m [RDDPG] 546: episode_reward:-3.5744498380091523 steps:1860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 547: episode_reward:-3.125000042468824 steps:1862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 548: episode_reward:-3.624991973169184 steps:1864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 549: episode_reward:1.2934782407944292 steps:1867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 550: episode_reward:-1.134801220290886 steps:1869[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.73877
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 551: episode_reward:-2.555054758432356 steps:1871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 552: episode_reward:13.839874522434704 steps:1874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 553: episode_reward:-3.7100980640433185 steps:1876[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 554: episode_reward:-0.27948185502786904 steps:1878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09199
[RDDPG] Episode Done
[92m [RDDPG] 555: episode_reward:-3.2516175006890817 steps:1880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 556: episode_reward:-2.7144749344940693 steps:1882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 557: episode_reward:-0.1017679206998463 steps:1884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 558: episode_reward:-3.305055862848293 steps:1886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 559: episode_reward:-2.240886479685356 steps:1888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.19635
[RDDPG] Episode Done
[92m [RDDPG] 560: episode_reward:-2.8584507626493068 steps:1890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 561: episode_reward:11.818491821891712 steps:1893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 562: episode_reward:-3.122236435589666 steps:1895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 563: episode_reward:-3.3509894119518506 steps:1898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.62252
[RDDPG] Episode Done
[92m [RDDPG] 564: episode_reward:-4.592225453411709 steps:1900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 565: episode_reward:-2.9275114900619306 steps:1902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 566: episode_reward:-3.637469004935103 steps:1904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 567: episode_reward:-4.583475384422693 steps:1906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 568: episode_reward:-3.554197199873255 steps:1908[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08158
[RDDPG] Episode Done
[92m [RDDPG] 569: episode_reward:-1.734774724493558 steps:1910[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 570: episode_reward:-1.4200111068713848 steps:1912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 571: episode_reward:-1.233326951877166 steps:1915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 572: episode_reward:-2.5655745050656984 steps:1917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 573: episode_reward:-1.8850912252537146 steps:1919[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.15062
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 574: episode_reward:-2.5692706928282707 steps:1921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 575: episode_reward:-2.1275154379716885 steps:1923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 576: episode_reward:-1.183569835519696 steps:1925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 577: episode_reward:-1.8087859679635678 steps:1927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 578: episode_reward:-1.4369198740682987 steps:1929[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.31717
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 579: episode_reward:-3.290432454200232 steps:1931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 580: episode_reward:-2.1018089141465524 steps:1933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 581: episode_reward:-1.8804147658394346 steps:1935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 582: episode_reward:-2.0683360737035 steps:1937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 583: episode_reward:-2.062473619602901 steps:1939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.10158
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 584: episode_reward:-1.3635998530098283 steps:1941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 585: episode_reward:-1.1769345058320193 steps:1943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 586: episode_reward:-2.482984697054779 steps:1945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 587: episode_reward:-3.1695603599076994 steps:1947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 588: episode_reward:8.21686063885983 steps:1949[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.66491
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 589: episode_reward:14.161843379051653 steps:1951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 590: episode_reward:0.8808264187536472 steps:1954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 591: episode_reward:-1.5958912385914172 steps:1956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 592: episode_reward:-2.6716145628961065 steps:1958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.31415
[RDDPG] Episode Done
[92m [RDDPG] 593: episode_reward:-1.1352785280786701 steps:1960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 594: episode_reward:327.5280617466293 steps:1962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 595: episode_reward:6.899486440284813 steps:1965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 596: episode_reward:-0.9408487297028925 steps:1967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 597: episode_reward:-3.556677493130049 steps:1969[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.53883
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 598: episode_reward:-2.6378311794408806 steps:1971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 599: episode_reward:-1.239666154965842 steps:1974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 600: episode_reward:-3.6538277995725608 steps:1976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 601: episode_reward:-3.174670647146557 steps:1978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.10897
[RDDPG] Episode Done
[92m [RDDPG] 602: episode_reward:78.04372144453419 steps:1980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 603: episode_reward:0.025357244729691253 steps:1982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 604: episode_reward:7.486590413088025 steps:1985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 605: episode_reward:-2.2640709013884806 steps:1987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 606: episode_reward:-1.5119787418400545 steps:1989[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.12919
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 607: episode_reward:-2.8156477508206303 steps:1991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 608: episode_reward:-2.7908138487252128 steps:1993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 609: episode_reward:-1.9689559203190308 steps:1995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 610: episode_reward:-0.7489585497957294 steps:1998[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.15728
[RDDPG] Episode Done
[92m [RDDPG] 611: episode_reward:-3.8751012164007452 steps:2000[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0002000: mean_reward:-2.6403103060694573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 612: episode_reward:-2.0556049521226014 steps:2002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 613: episode_reward:-3.557417338039846 steps:2004[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 614: episode_reward:-0.8136242433560237 steps:2006[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 615: episode_reward:-1.9827698601306296 steps:2008[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.01783
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 616: episode_reward:-1.2253966232560705 steps:2011[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 617: episode_reward:-1.9462256299972076 steps:2013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 618: episode_reward:-1.779252657960243 steps:2015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 619: episode_reward:-3.327765553279351 steps:2017[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.61159
[RDDPG] Episode Done
[92m [RDDPG] 620: episode_reward:18.470892951740257 steps:2020[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 621: episode_reward:-2.564515686615012 steps:2022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 622: episode_reward:-0.9574174181687485 steps:2024[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 623: episode_reward:-3.9858253472145577 steps:2026[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 624: episode_reward:-2.0965643177250266 steps:2028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.63118
[RDDPG] Episode Done
[92m [RDDPG] 625: episode_reward:-2.4288763441798853 steps:2030[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 626: episode_reward:1.4986205460323863 steps:2032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 627: episode_reward:-2.1250106018985 steps:2034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 628: episode_reward:3.1998769390184094 steps:2036[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 629: episode_reward:3.0801468337299083 steps:2039[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.86334
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 630: episode_reward:-1.0613268545571506 steps:2041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 631: episode_reward:-1.552219792631992 steps:2044[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 632: episode_reward:-2.31829812695406 steps:2047[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95180
[RDDPG] Episode Done
[92m [RDDPG] 633: episode_reward:-3.9472461825205665 steps:2050[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 634: episode_reward:-4.5392715047599195 steps:2052[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 635: episode_reward:-2.804996556526881 steps:2054[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 636: episode_reward:1.0643910874450664 steps:2056[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 637: episode_reward:-1.6457433248366522 steps:2058[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.83816
[RDDPG] Episode Done
[92m [RDDPG] 638: episode_reward:3.8316586812062963 steps:2060[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 639: episode_reward:-3.3901074073126605 steps:2062[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 640: episode_reward:-2.8084285070319908 steps:2064[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 641: episode_reward:-1.0889705507248855 steps:2066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 642: episode_reward:-2.362978197612546 steps:2068[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52539
[RDDPG] Episode Done
[92m [RDDPG] 643: episode_reward:15.762841991632811 steps:2070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 644: episode_reward:-1.4101861251073307 steps:2072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 645: episode_reward:-4.276778717929226 steps:2074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 646: episode_reward:-3.834419036876552 steps:2076[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 647: episode_reward:-3.2763510758835546 steps:2078[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29210
[RDDPG] Episode Done
[92m [RDDPG] 648: episode_reward:-3.164026449647424 steps:2080[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 649: episode_reward:-2.856285117977627 steps:2082[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 650: episode_reward:-2.412332872563746 steps:2085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 651: episode_reward:-2.2685806068940333 steps:2087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 652: episode_reward:-1.9967215374177676 steps:2089[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31829
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 653: episode_reward:-1.8073096044587071 steps:2091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 654: episode_reward:-1.6972731591735633 steps:2093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 655: episode_reward:-4.228060256600108 steps:2095[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 656: episode_reward:2.845267959483393 steps:2097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 657: episode_reward:-4.249754304077382 steps:2099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.12797
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 658: episode_reward:-3.734474234569724 steps:2101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 659: episode_reward:-2.6680698315760623 steps:2103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 660: episode_reward:-1.9194370628370667 steps:2105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 661: episode_reward:-3.0026607831127423 steps:2108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.30576
[RDDPG] Episode Done
[92m [RDDPG] 662: episode_reward:-2.377498707582407 steps:2110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 663: episode_reward:-1.8548127252551438 steps:2112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 664: episode_reward:-2.6840472069016172 steps:2114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 665: episode_reward:-2.7394091252433923 steps:2116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 666: episode_reward:-1.3939819171066388 steps:2118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77178
[RDDPG] Episode Done
[92m [RDDPG] 667: episode_reward:-3.437136322487232 steps:2120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 668: episode_reward:-1.2030685314883989 steps:2122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 669: episode_reward:-1.5492209883546255 steps:2124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 670: episode_reward:-2.3927582947063226 steps:2126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 671: episode_reward:-4.318763469812161 steps:2128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.79735
[RDDPG] Episode Done
[92m [RDDPG] 672: episode_reward:-4.236208273086554 steps:2130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 673: episode_reward:-2.2311088336121205 steps:2132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 674: episode_reward:-2.3285040593435804 steps:2134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 675: episode_reward:-3.1251284121617258 steps:2136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 676: episode_reward:-2.2135297075415616 steps:2138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36779
[RDDPG] Episode Done
[92m [RDDPG] 677: episode_reward:-2.7353191067074825 steps:2140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 678: episode_reward:-2.6515966505705837 steps:2142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 679: episode_reward:-3.812958497658435 steps:2144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 680: episode_reward:-1.7606216956250262 steps:2146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 681: episode_reward:1.9182499964156134 steps:2148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.51936
[RDDPG] Episode Done
[92m [RDDPG] 682: episode_reward:-2.266447784139677 steps:2150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 683: episode_reward:-1.5004598700099256 steps:2152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 684: episode_reward:-1.5238440492290388 steps:2154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 685: episode_reward:-1.4025350159441858 steps:2156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 686: episode_reward:-3.9701390732128012 steps:2158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.85535
[RDDPG] Episode Done
[92m [RDDPG] 687: episode_reward:-3.414211195241907 steps:2160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 688: episode_reward:-2.675583307074733 steps:2162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 689: episode_reward:-4.6985385716340105 steps:2164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 690: episode_reward:-3.367199924472739 steps:2166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 691: episode_reward:20.921324611355466 steps:2168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40260
[RDDPG] Episode Done
[92m [RDDPG] 692: episode_reward:5.16334847396204 steps:2170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 693: episode_reward:-1.7532176711507756 steps:2172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 694: episode_reward:-3.7988924167590277 steps:2174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 695: episode_reward:4.562423909724436 steps:2176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 696: episode_reward:-4.2384586894020835 steps:2178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.02399
[RDDPG] Episode Done
[92m [RDDPG] 697: episode_reward:4.586556891778109 steps:2180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 698: episode_reward:-2.5610079434061253 steps:2182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 699: episode_reward:-3.689612188438187 steps:2184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 700: episode_reward:-2.5390336226392707 steps:2186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 701: episode_reward:-3.008410381639034 steps:2188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24180
[RDDPG] Episode Done
[92m [RDDPG] 702: episode_reward:-1.6125556617040107 steps:2190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 703: episode_reward:-3.76579838510137 steps:2192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 704: episode_reward:-3.8566939630435506 steps:2194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 705: episode_reward:-2.4313383146728587 steps:2196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 706: episode_reward:-3.449752491668957 steps:2198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18532
[RDDPG] Episode Done
[92m [RDDPG] 707: episode_reward:-2.99010977585041 steps:2200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 708: episode_reward:1.0704311369044803 steps:2202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 709: episode_reward:-1.278918975634716 steps:2204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 710: episode_reward:-2.221197324301562 steps:2206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 711: episode_reward:-1.6460745803729775 steps:2208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.25821
[RDDPG] Episode Done
[92m [RDDPG] 712: episode_reward:-2.6194132556345657 steps:2210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 713: episode_reward:-2.304138598686289 steps:2212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 714: episode_reward:-2.890391131542164 steps:2214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 715: episode_reward:-2.399727146217819 steps:2216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 716: episode_reward:-0.5412442850434169 steps:2218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.05694
[RDDPG] Episode Done
[92m [RDDPG] 717: episode_reward:-2.9548183517265105 steps:2220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 718: episode_reward:-1.9186026385745905 steps:2222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 719: episode_reward:8.058631843467499 steps:2225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 720: episode_reward:-2.2074146036920927 steps:2227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 721: episode_reward:-3.9212452384157226 steps:2229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.12342
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 722: episode_reward:-3.4335045846048162 steps:2231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 723: episode_reward:-3.3952843748994255 steps:2233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 724: episode_reward:-1.952463812923981 steps:2235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 725: episode_reward:-2.8063619783998277 steps:2237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.73092
[RDDPG] Episode Done
[92m [RDDPG] 726: episode_reward:-0.9440909887781586 steps:2240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 727: episode_reward:-3.089433197166932 steps:2242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 728: episode_reward:-1.6716830746440507 steps:2244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 729: episode_reward:0.26669899339256453 steps:2246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 730: episode_reward:-2.173288989319828 steps:2248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.57389
[RDDPG] Episode Done
[92m [RDDPG] 731: episode_reward:-3.456525302501235 steps:2250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 732: episode_reward:-1.3597592434839672 steps:2252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 733: episode_reward:-2.7338052354435973 steps:2254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 734: episode_reward:4.319200892280441 steps:2256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 735: episode_reward:-3.730595297715852 steps:2258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70522
[RDDPG] Episode Done
[92m [RDDPG] 736: episode_reward:-3.1271409446819165 steps:2260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 737: episode_reward:-3.2189253038661056 steps:2262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 738: episode_reward:-1.1102436237538773 steps:2264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 739: episode_reward:-1.471943998992588 steps:2266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 740: episode_reward:-2.3988726399206013 steps:2268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.30774
[RDDPG] Episode Done
[92m [RDDPG] 741: episode_reward:-3.068462518399578 steps:2270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 742: episode_reward:-1.8372854382034771 steps:2272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 743: episode_reward:-2.15502367313341 steps:2274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 744: episode_reward:-1.1372043522380344 steps:2276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 745: episode_reward:-2.0290331520058507 steps:2279[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.85695
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 746: episode_reward:-2.898830595960729 steps:2281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 747: episode_reward:-2.2301512602337934 steps:2283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 748: episode_reward:-1.4273485139311777 steps:2285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 749: episode_reward:-2.02307620507438 steps:2287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 750: episode_reward:-2.5270150179418076 steps:2289[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.71900
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 751: episode_reward:8.701626932165441 steps:2292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 752: episode_reward:14.928153757394815 steps:2294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 753: episode_reward:-0.8561755390303716 steps:2296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 754: episode_reward:59.95921678926049 steps:2299[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29644
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 755: episode_reward:-1.5149681100525503 steps:2301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 756: episode_reward:-1.9243971252530025 steps:2304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 757: episode_reward:2.729853087336158 steps:2307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40072
[RDDPG] Episode Done
[92m [RDDPG] 758: episode_reward:0.22445125807008948 steps:2310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 759: episode_reward:-2.5826576292524868 steps:2313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 760: episode_reward:2.986907317407245 steps:2316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 761: episode_reward:-3.4627223625087256 steps:2318[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.58589
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 762: episode_reward:46.13858597758547 steps:2327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.00875
[RDDPG] Episode Done
[92m [RDDPG] 763: episode_reward:4.702705375846603 steps:2330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 764: episode_reward:0.09769756596408952 steps:2333[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 765: episode_reward:-2.321487634936077 steps:2336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 766: episode_reward:0.06196940727488842 steps:2339[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91953
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 767: episode_reward:0.3527183917127261 steps:2342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 768: episode_reward:0.8367211046872405 steps:2344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 769: episode_reward:0.20295198108249357 steps:2347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75661
[RDDPG] Episode Done
[92m [RDDPG] 770: episode_reward:-1.847458951237791 steps:2350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 771: episode_reward:-1.845116966349535 steps:2353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 772: episode_reward:-3.1067291986007515 steps:2356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 773: episode_reward:-1.170997098956224 steps:2359[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.92483
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 774: episode_reward:-3.333284267682778 steps:2361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 775: episode_reward:-2.455762060748013 steps:2364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 776: episode_reward:-1.1407833035689092 steps:2367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.92009
[RDDPG] Episode Done
[92m [RDDPG] 777: episode_reward:0.017793603643926126 steps:2370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 778: episode_reward:-2.7030737336019506 steps:2372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 779: episode_reward:-3.1859698997475334 steps:2375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 780: episode_reward:-0.2731246321105387 steps:2378[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01374
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 781: episode_reward:0.12146872457041535 steps:2383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 782: episode_reward:-3.244941627770317 steps:2385[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 783: episode_reward:-2.4070041196896526 steps:2387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80059
[RDDPG] Episode Done
[92m [RDDPG] 784: episode_reward:5.393755280934033 steps:2390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 785: episode_reward:-3.726465550543281 steps:2393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 786: episode_reward:-1.669135311338176 steps:2396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 787: episode_reward:-0.4518415392586488 steps:2399[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81155
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 788: episode_reward:0.9740686299329364 steps:2403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 789: episode_reward:-3.0976783909981727 steps:2406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 790: episode_reward:-2.4257651103796256 steps:2409[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.43727
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 791: episode_reward:-2.6369074061358346 steps:2411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 792: episode_reward:-1.030707372938498 steps:2414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 793: episode_reward:-0.5078553551934251 steps:2417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.25806
[RDDPG] Episode Done
[92m [RDDPG] 794: episode_reward:22.55919048938141 steps:2420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 795: episode_reward:-2.327779083023108 steps:2423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 796: episode_reward:5.377547157274265 steps:2426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 797: episode_reward:1.2173891015666123 steps:2428[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.63588
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 798: episode_reward:-2.400627186740258 steps:2431[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 799: episode_reward:129.3595624964689 steps:2435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 800: episode_reward:0.8723803664938354 steps:2438[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.85067
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 801: episode_reward:1.000974712452431 steps:2441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 802: episode_reward:-1.351460409394058 steps:2444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 803: episode_reward:1.6328963671407393 steps:2448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.45780
[RDDPG] Episode Done
[92m [RDDPG] 804: episode_reward:-2.1307288024259146 steps:2450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 805: episode_reward:5.348217545408304 steps:2453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 806: episode_reward:-1.1408422887932899 steps:2455[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 807: episode_reward:22.0773847986044 steps:2459[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.58498
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 808: episode_reward:0.6941903330191774 steps:2461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 809: episode_reward:-2.495107969692988 steps:2463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 810: episode_reward:0.17192423475281027 steps:2467[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.39963
[RDDPG] Episode Done
[92m [RDDPG] 811: episode_reward:-0.7523646181115895 steps:2470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 812: episode_reward:-0.32021621076200857 steps:2473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 813: episode_reward:5.27199840944484 steps:2477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 814: episode_reward:-1.0754802353777668 steps:2479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.50019
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 815: episode_reward:-2.462964391242981 steps:2481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 816: episode_reward:-0.7721789752958881 steps:2485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 817: episode_reward:-3.7357724999772586 steps:2487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.45256
[RDDPG] Episode Done
[92m [RDDPG] 818: episode_reward:-1.5367686863364196 steps:2490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 819: episode_reward:-2.476115316561269 steps:2492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 820: episode_reward:-1.0661905081126117 steps:2494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 821: episode_reward:-0.7746388966639479 steps:2497[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07838
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 822: episode_reward:0.1722202237304975 steps:2501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 823: episode_reward:1.6578867152289662 steps:2504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 824: episode_reward:0.15595899511342548 steps:2507[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 825: episode_reward:0.06376038782343674 steps:2509[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.82310
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 826: episode_reward:0.8101105405226083 steps:2511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 827: episode_reward:-3.2350388903241307 steps:2515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 828: episode_reward:-4.362471271680461 steps:2517[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.64560
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 829: episode_reward:2.3180675634901275 steps:2521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 830: episode_reward:5.640307990383333 steps:2525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 831: episode_reward:-0.7185246400648 steps:2528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55382
[RDDPG] Episode Done
[92m [RDDPG] 832: episode_reward:-3.1588601456773686 steps:2530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 833: episode_reward:86.58332104819364 steps:2536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 834: episode_reward:-0.03548010042354832 steps:2538[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.43674
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 835: episode_reward:0.1623674314673922 steps:2541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 836: episode_reward:-2.3763341708850083 steps:2543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 837: episode_reward:9.774052833275855 steps:2546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 838: episode_reward:0.4858730947679937 steps:2548[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21268
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 839: episode_reward:-0.5083193568810929 steps:2551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 840: episode_reward:-3.6239311529696643 steps:2553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 841: episode_reward:-2.8045977398106743 steps:2555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 842: episode_reward:0.3797144961600205 steps:2558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.62130
[RDDPG] Episode Done
[92m [RDDPG] 843: episode_reward:-1.151386347064538 steps:2560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 844: episode_reward:-1.3241181249809428 steps:2562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 845: episode_reward:-1.332783260038756 steps:2565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 846: episode_reward:-3.1828107630449765 steps:2567[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.27357
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 847: episode_reward:0.9653477943141286 steps:2573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 848: episode_reward:0.3152500966500158 steps:2576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 849: episode_reward:-3.0617329708871317 steps:2578[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.38191
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 850: episode_reward:36.55799429217849 steps:2586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 851: episode_reward:-2.5453331159122703 steps:2589[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.68788
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 852: episode_reward:1.06400172047494 steps:2592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 853: episode_reward:1.364328741324492 steps:2596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 854: episode_reward:-0.024539379740652567 steps:2599[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34363
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 855: episode_reward:-1.3237717802036646 steps:2601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 856: episode_reward:4.814439346651222 steps:2603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 857: episode_reward:-1.4517435065994726 steps:2606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 858: episode_reward:-0.5354735558849049 steps:2609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14635
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 859: episode_reward:-0.1155192834717409 steps:2611[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 860: episode_reward:-3.438819405788334 steps:2615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 861: episode_reward:-1.4476201708161707 steps:2617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.30279
[RDDPG] Episode Done
[92m [RDDPG] 862: episode_reward:-1.3525519375209525 steps:2620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 863: episode_reward:-1.841566254127593 steps:2623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 864: episode_reward:-0.7276182029338636 steps:2625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.00981
[RDDPG] Episode Done
[92m [RDDPG] 865: episode_reward:10.050519335188921 steps:2630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 866: episode_reward:-2.5414573769651034 steps:2632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 867: episode_reward:-1.4109128078756257 steps:2636[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.08757
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 868: episode_reward:318.985946018833 steps:2643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 869: episode_reward:5.201575060919841 steps:2647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 870: episode_reward:4.10082698025624 steps:2649[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.75824
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 871: episode_reward:3.978552546801482 steps:2652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 872: episode_reward:-1.577312321202703 steps:2654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 873: episode_reward:-0.027123834524579227 steps:2658[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.70471
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 874: episode_reward:-0.29250514157512675 steps:2661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 875: episode_reward:-3.4997057419073005 steps:2665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 876: episode_reward:-2.4051436887875277 steps:2668[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.38988
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 877: episode_reward:23.52819215563747 steps:2677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.69812
[RDDPG] Episode Done
[92m [RDDPG] 878: episode_reward:0.37345387833213994 steps:2680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 879: episode_reward:-2.9953344951791614 steps:2682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 880: episode_reward:-1.1579094005479846 steps:2685[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.98174
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 881: episode_reward:2.402412652482448 steps:2691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 882: episode_reward:0.013258637030760578 steps:2694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 883: episode_reward:9.518820577616331 steps:2696[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.25441
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 884: episode_reward:0.00986459048462418 steps:2701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 885: episode_reward:-0.007553981935698673 steps:2704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 886: episode_reward:-3.3046565312007763 steps:2708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.51147
[RDDPG] Episode Done
[92m [RDDPG] 887: episode_reward:13.594891805596092 steps:2710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 888: episode_reward:-0.6301331687118692 steps:2713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 889: episode_reward:5.258081580813081 steps:2717[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.31125
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 890: episode_reward:3.4194214233065225 steps:2721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 891: episode_reward:-0.8927183251085142 steps:2723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 892: episode_reward:-1.2716005009585283 steps:2727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 893: episode_reward:2.0057425399978275 steps:2729[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.66823
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 894: episode_reward:1.1749215073479244 steps:2732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 895: episode_reward:-2.8118298980565526 steps:2734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 896: episode_reward:-2.46122883123028 steps:2738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57027
[RDDPG] Episode Done
[92m [RDDPG] 897: episode_reward:-5.232445653570915 steps:2740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 898: episode_reward:-1.4256480324804173 steps:2742[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 899: episode_reward:-3.38178653609497 steps:2744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 900: episode_reward:-0.8826743060913813 steps:2746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64183
[RDDPG] Episode Done
[92m [RDDPG] 901: episode_reward:1.5164592470803782 steps:2750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 902: episode_reward:0.6084335500055098 steps:2752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 903: episode_reward:-4.2165144363004625 steps:2754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 904: episode_reward:-3.286630131755742 steps:2756[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 905: episode_reward:-0.029978921945369663 steps:2759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.74102
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 906: episode_reward:-1.8096332763157075 steps:2761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 907: episode_reward:4.103774016316745 steps:2766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 908: episode_reward:-3.998465815994564 steps:2769[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.26610
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 909: episode_reward:0.03392477488452261 steps:2771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 910: episode_reward:4.612264810720099 steps:2774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 911: episode_reward:-1.4947869872796997 steps:2777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 912: episode_reward:-2.322656637404873 steps:2779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.92481
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 913: episode_reward:8.752343219239783 steps:2781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 914: episode_reward:-2.860101474511943 steps:2785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 915: episode_reward:-1.8703547142974055 steps:2787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.27440
[RDDPG] Episode Done
[92m [RDDPG] 916: episode_reward:-3.0485145140696246 steps:2790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 917: episode_reward:-4.1773568169922575 steps:2792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 918: episode_reward:-4.885456223138678 steps:2795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 919: episode_reward:4.180054220571442 steps:2799[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.29747
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 920: episode_reward:-0.7295640077535235 steps:2801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 921: episode_reward:-3.6370058479722713 steps:2803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 922: episode_reward:10.586181070362823 steps:2807[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.93122
[RDDPG] Episode Done
[92m [RDDPG] 923: episode_reward:4.2582146585292096 steps:2810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 924: episode_reward:-2.496176115172256 steps:2812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 925: episode_reward:1.1202839403778784 steps:2817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84588
[RDDPG] Episode Done
[92m [RDDPG] 926: episode_reward:-2.116830684580388 steps:2820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 927: episode_reward:-3.4441073270258875 steps:2822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 928: episode_reward:-4.308187256970757 steps:2828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21816
[RDDPG] Episode Done
[92m [RDDPG] 929: episode_reward:-2.99139506618923 steps:2830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 930: episode_reward:-0.9831832546908124 steps:2833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 931: episode_reward:-0.04320468790118248 steps:2836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46833
[RDDPG] Episode Done
[92m [RDDPG] 932: episode_reward:14.482368306102952 steps:2840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 933: episode_reward:-1.0604799045180742 steps:2843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 934: episode_reward:-0.9883137726596205 steps:2845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 935: episode_reward:-0.8408378312958749 steps:2848[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.64253
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 936: episode_reward:10.42755299799686 steps:2851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 937: episode_reward:7.015980375899143 steps:2854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 938: episode_reward:-3.3621357631939635 steps:2856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 939: episode_reward:-1.3192463184016616 steps:2859[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.00304
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 940: episode_reward:-1.2603101719992331 steps:2861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 941: episode_reward:-2.14248699466916 steps:2864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 942: episode_reward:16.833693090761376 steps:2866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 943: episode_reward:2.706277701246033 steps:2869[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18075
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 944: episode_reward:-1.0052627198450446 steps:2871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 945: episode_reward:-1.2119639650693288 steps:2875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 946: episode_reward:-3.0861755818162315 steps:2878[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.14864
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 947: episode_reward:-1.4712734081423866 steps:2881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 948: episode_reward:0.11787197559666351 steps:2884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 949: episode_reward:-0.25831640419275503 steps:2887[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24727
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 950: episode_reward:-0.6118373233075789 steps:2891[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 951: episode_reward:-2.4503341034079984 steps:2894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 952: episode_reward:-2.127742875454041 steps:2897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.88519
[RDDPG] Episode Done
[92m [RDDPG] 953: episode_reward:-1.7383424042927622 steps:2900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 954: episode_reward:-2.6052643659722996 steps:2903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 955: episode_reward:-3.132635731993115 steps:2905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 956: episode_reward:-3.7999293869231 steps:2908[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.70892
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 957: episode_reward:4.331001251921953 steps:2911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 958: episode_reward:-0.8159626493240935 steps:2914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 959: episode_reward:-1.8196154372980724 steps:2916[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 960: episode_reward:-0.24537230517948272 steps:2918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.66350
[RDDPG] Episode Done
[92m [RDDPG] 961: episode_reward:-3.917132324547623 steps:2920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 962: episode_reward:0.0489684617148014 steps:2923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 963: episode_reward:2094.3901646122517 steps:2926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 964: episode_reward:1.0033516360283943 steps:2928[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.89952
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 965: episode_reward:-3.5516482604506496 steps:2931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 966: episode_reward:-0.9465425626635107 steps:2933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 967: episode_reward:-4.868335314933043 steps:2936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 968: episode_reward:2.6654213306670522 steps:2939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.93166
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 969: episode_reward:-1.622120215924111 steps:2941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 970: episode_reward:-4.170536053406087 steps:2944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 971: episode_reward:-1.3699126833079376 steps:2947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.54695
[RDDPG] Episode Done
[92m [RDDPG] 972: episode_reward:-3.7801624988059612 steps:2950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 973: episode_reward:-2.071779676211347 steps:2953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 974: episode_reward:-1.7372271976158722 steps:2955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 975: episode_reward:-2.5231086272996026 steps:2957[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.98297
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 976: episode_reward:0.006268183436497932 steps:2961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 977: episode_reward:6.166674412472667 steps:2965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 978: episode_reward:-0.8519614373553703 steps:2968[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.56216
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 979: episode_reward:-3.052280386218342 steps:2971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 980: episode_reward:0.4981313853069671 steps:2974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 981: episode_reward:1.6588139806373912 steps:2977[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.59710
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 982: episode_reward:3.7469710781839978 steps:2984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 983: episode_reward:-3.4828076911495875 steps:2986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 984: episode_reward:6.016718807729703 steps:2989[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.91480
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 985: episode_reward:-1.9756837742818263 steps:2991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 986: episode_reward:-0.5883157126831793 steps:2994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 987: episode_reward:7.890815323871524 steps:2998[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.35492
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 988: episode_reward:-0.6382617878229147 steps:3002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 989: episode_reward:-2.41898352705473 steps:3005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 990: episode_reward:-2.0024668076074157 steps:3008[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46971
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 991: episode_reward:-1.443810761373664 steps:3011[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 992: episode_reward:0.25069343518621245 steps:3014[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 993: episode_reward:-3.7380080223268606 steps:3016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 994: episode_reward:-3.335015445890698 steps:3018[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26938
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 995: episode_reward:-4.622913472607406 steps:3021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 996: episode_reward:-0.06796629603188187 steps:3024[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 997: episode_reward:-0.1064366390794591 steps:3026[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 998: episode_reward:-2.7689077885067976 steps:3029[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26565
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 999: episode_reward:-1.1731438716567573 steps:3031[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1000: episode_reward:-1.2355912247696517 steps:3034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1001: episode_reward:-1.0882071584617181 steps:3037[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.13991
[RDDPG] Episode Done
[92m [RDDPG] 1002: episode_reward:-1.6176698226110418 steps:3040[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1003: episode_reward:1.576259013292748 steps:3043[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1004: episode_reward:7.307270915490591 steps:3045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1005: episode_reward:-1.2205836054469452 steps:3048[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21558
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1006: episode_reward:0.37304337635720586 steps:3051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1007: episode_reward:-2.342558075811631 steps:3055[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1008: episode_reward:-2.6096745773890784 steps:3058[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.87613
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1009: episode_reward:-0.5025230433208012 steps:3061[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1010: episode_reward:-3.1211841606877666 steps:3064[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1011: episode_reward:5.073415531910639 steps:3067[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88599
[RDDPG] Episode Done
[92m [RDDPG] 1012: episode_reward:2.022154763051847 steps:3070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1013: episode_reward:10.862659472577434 steps:3072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1014: episode_reward:-0.8675528704909592 steps:3075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1015: episode_reward:4.689255122936571 steps:3079[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49433
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1016: episode_reward:-1.5394452825098632 steps:3081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1017: episode_reward:-2.692579067184359 steps:3083[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1018: episode_reward:13.141463862515952 steps:3086[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54883
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1019: episode_reward:-0.5943988917724483 steps:3091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1020: episode_reward:-2.6818563612688195 steps:3094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1021: episode_reward:-2.388679790584375 steps:3097[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.47715
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1022: episode_reward:4.992060683450553 steps:3101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1023: episode_reward:-0.946587276225269 steps:3105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1024: episode_reward:-0.9533614755393138 steps:3108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.46806
[RDDPG] Episode Done
[92m [RDDPG] 1025: episode_reward:-0.2382996241520563 steps:3110[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08055
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1026: episode_reward:98.64131242810313 steps:3127[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.39426
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1027: episode_reward:333.0052608143232 steps:3132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1028: episode_reward:-1.3594147460991075 steps:3135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18740
[RDDPG] Episode Done
[92m [RDDPG] 1029: episode_reward:3.6496689291549154 steps:3140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1030: episode_reward:-4.091782882287647 steps:3143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1031: episode_reward:-0.6428818729280779 steps:3146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.41641
[RDDPG] Episode Done
[92m [RDDPG] 1032: episode_reward:-1.6511871428032237 steps:3150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1033: episode_reward:-1.7161391891523143 steps:3153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1034: episode_reward:5.779143093948806 steps:3156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.75469
[RDDPG] Episode Done
[92m [RDDPG] 1035: episode_reward:-2.9216984860170507 steps:3160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1036: episode_reward:-0.7368798198284805 steps:3164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1037: episode_reward:1.4765692658452036 steps:3166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1038: episode_reward:-2.9677202248359826 steps:3169[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.32293
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1039: episode_reward:-1.342281505731084 steps:3172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1040: episode_reward:3.5561757296961263 steps:3175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1041: episode_reward:-1.3875780500748096 steps:3177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.58015
[RDDPG] Episode Done
[92m [RDDPG] 1042: episode_reward:2.083112213950254 steps:3180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1043: episode_reward:41.8990866873971 steps:3184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1044: episode_reward:-3.3118225499119025 steps:3187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.16040
[RDDPG] Episode Done
[92m [RDDPG] 1045: episode_reward:-0.5852158327816959 steps:3190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1046: episode_reward:0.5150642990454526 steps:3195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1047: episode_reward:-2.1410305315967633 steps:3197[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.24886
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1048: episode_reward:6.237309590227431 steps:3201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1049: episode_reward:-3.6557718812905877 steps:3204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1050: episode_reward:-0.7731791566076258 steps:3207[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.86595
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1051: episode_reward:7.111462751354278 steps:3212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1052: episode_reward:-3.2255364673494817 steps:3214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1053: episode_reward:-3.2628811795757944 steps:3218[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.72490
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1054: episode_reward:3.3041003780025857 steps:3223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1055: episode_reward:-2.746845938678216 steps:3226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1056: episode_reward:3.731063467977034 steps:3229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35968
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1057: episode_reward:-3.9073616684801484 steps:3232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1058: episode_reward:-2.834201119884942 steps:3234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1059: episode_reward:3.5264688305698266 steps:3238[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.94318
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1060: episode_reward:-3.4607423367372414 steps:3241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1061: episode_reward:-0.7734812650432277 steps:3245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1062: episode_reward:-0.7788345939259613 steps:3247[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.57578
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1063: episode_reward:9.452159349462562 steps:3251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1064: episode_reward:-4.502502724490244 steps:3254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1065: episode_reward:18.550151888677306 steps:3258[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.86587
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1066: episode_reward:-0.1301525038371254 steps:3261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1067: episode_reward:-1.747793244812435 steps:3263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1068: episode_reward:5.4140643289412544 steps:3266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1069: episode_reward:19.00784712408371 steps:3269[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07175
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1070: episode_reward:-1.7985279841821034 steps:3272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1071: episode_reward:-0.9452669527507911 steps:3274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1072: episode_reward:-5.748615994607292 steps:3278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.17629
[RDDPG] Episode Done
[92m [RDDPG] 1073: episode_reward:-1.1985029481341092 steps:3280[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620148978.942646457, 3226.924000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620148978.942715948, 3226.924000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620148980.547981600, 3226.924000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620148980.548031213, 3226.924000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620148981.548746894, 3226.924000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620148981.548806703, 3226.924000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620148982.549385002, 3226.924000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620148982.549427946, 3226.924000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 117, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.35)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 17:24:27.946358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:19366): Gdk-CRITICAL **: 17:24:30.036: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 2, in <module>
    from rl.torch.rdpg import RDPG
  File "/app/rl/torch/rdpg.py", line 129
    state0[0], state0[1], train = True
                                ^
SyntaxError: invalid syntax
2021-05-04 17:26:46.586230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:19641): Gdk-CRITICAL **: 17:26:48.943: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620149211.818186287, 2.138000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620149211.819366210, 2.139000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620149211.819417648, 2.139000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620149213.077693412, 3.386000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620149213.830359389, 4.132000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620149214.639056617, 4.938000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620149215.442483159, 5.737000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1719999.1429414656[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 150, in train
    [torch.squeeze(_, 0) for _ in hs],
UnboundLocalError: local variable 'hs' referenced before assignment
2021-05-04 17:35:30.327017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:20253): Gdk-CRITICAL **: 17:35:32.396: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620149734.900934784, 1.450000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620149734.901874229, 1.451000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620149734.901932827, 1.451000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620149736.250191450, 2.787000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620149737.070038807, 3.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620149737.878589520, 4.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620149738.682667020, 5.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:15641067.91682433[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 143, in train
    self.memory.append(
  File "/app/rl/torch/memory.py", line 278, in append
    self.trajectory.append(Experience(state0=state0, action=action, reward=reward, state1=None, terminal1=terminal)) # 
TypeError: __new__() missing 1 required positional argument: 'hs'
2021-05-04 17:38:38.890277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:20811): Gdk-CRITICAL **: 17:38:40.960: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620149923.742549236, 1.765000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620149923.743455125, 1.765000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620149923.743670115, 1.766000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620149925.062724669, 3.076000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620149925.933370896, 3.941000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620149926.538413566, 4.541000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620149927.340291299, 5.341000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1992585.0371126663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:3.239735700351053 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:90.82165740520621 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:0.8214717754105307 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:0.6802129987876677 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:10.058688909937722 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:30.451029505771984 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:0.11706290538726938 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:7.461002775709969 steps:95[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-0.2380339363531636 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.9285341537881819 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:99.76124127002517 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:1.569273045930311 steps:128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:0.8846723531271534 steps:130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:9.700791229819213 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:77.10223158757232 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:6.721175725305213 steps:178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:938.017979274312 steps:184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-1.0656441377754735 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:19.641101774274087 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:10.934553731667654 steps:216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-0.8917385446593773 steps:218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-2.6403231912775667 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:21.387614472135063 steps:242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:187.08986264196318 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:5.118240991831948 steps:261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:8.13169259732777 steps:263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:6.493471968041272 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:0.8081370591512549 steps:268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:106.31158718843444 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:55.98244208760343 steps:289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:44.774987979573595 steps:311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-2.03765102012666 steps:313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:0.7446388480170092 steps:315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:9.625399326707655 steps:337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:5.390094095503356 steps:339[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:2.4648679847647945 steps:341[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 129, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1021, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/app/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
2021-05-04 17:42:50.760878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:23193): Gdk-CRITICAL **: 17:42:52.771: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620150175.546162848, 1.641000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620150175.547262834, 1.641000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620150175.547388070, 1.641000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620150176.780441383, 2.869000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620150177.515516470, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620150178.319107766, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620150179.119798124, 5.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3061595.4659875436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.1104301339440066 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.21215565697798366 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:13.719026331661812 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:94.40526063201169 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.6429387115170226 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-1.5432871932657535 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-1.698162089882691 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:14.125440174470228 steps:56[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:6.511804198894685 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-1.277939100475115 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:45.269196528656266 steps:89[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:9.815988795627117 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.4286037351574712 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.1915623591343645 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:240.68422808294247 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-1.937355341064635 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:2.358023864244905 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:6.506311346561802 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:14.260501295974972 steps:169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.5695002828401114 steps:171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:4.081072073729172 steps:190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.5950239912779436 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:10.872803014272352 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:12.41881686350283 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-2.306719436473026 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:68.98223401637193 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:0.533277749762155 steps:234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:18.912919517530007 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:0.18885197062741277 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:5.224726003698857 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:2515.8923268639273 steps:275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-2.7268397195948513 steps:277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:3.495926930873603 steps:285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:0.03337844819963243 steps:290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:0.8182678802787144 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-0.8938075382232755 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-0.501601558137954 steps:304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:30.928636706267103 steps:315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:29.327961332101133 steps:355[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:22.484011618556895 steps:375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-0.22185924830973747 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:8.997081487174349 steps:397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.194063925790248 steps:403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:4.8422266175739335 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-0.0985049954008379 steps:410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:29.083599741047035 steps:422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.144772251115393 steps:424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:22.00759304577384 steps:432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:10.634681570757513 steps:438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-0.5634608833984964 steps:440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:9.923629899740613 steps:454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:14.093540963709746 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:4.1899174325769755 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:2.6356492558626408 steps:493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:39.528264508921204 steps:498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:13.895208007805065 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:70.63878673532892 steps:505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:17.151040478486276 steps:512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-2.5624107967804486 steps:514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-1.7680246437124896 steps:516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-0.5177066109502724 steps:525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:3.064000475858582 steps:529[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:16.628675358954116 steps:541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-0.40725988978270133 steps:543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:7.496606817497499 steps:550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:2.6525938610741173 steps:557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-0.8764805070625816 steps:559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:6.802351224501161 steps:566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:0.4602704326906859 steps:568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:14.503136514428626 steps:574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:8.327624101091185 steps:581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:14.146109291765885 steps:589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-0.3377291915101355 steps:591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:10.779893679299176 steps:615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:1.9956243502122044 steps:621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-1.194203537222382 steps:623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:461.68464911250555 steps:637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:87.51568723570075 steps:646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:1383.4022978541634 steps:665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:48.11241329928334 steps:697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-1.3557367266745284 steps:699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-0.9790674265697192 steps:701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:1.246402974058697 steps:704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:1.9451667047707701 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:438.39757014559194 steps:741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:108.60252076596743 steps:784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:0.7791580781239595 steps:789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:9.281186174655025 steps:801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:13.36070654849711 steps:806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:102.45991089660198 steps:814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:108.63910399456199 steps:832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:0.1191589400465296 steps:834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-1.1608205720427 steps:836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-2.3938640784397283 steps:838[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:0.8890886708721952 steps:840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:18.890530066375163 steps:847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-2.580885043932404 steps:856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:18.262942087063333 steps:860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:142.33128559137967 steps:873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-1.9045642506446245 steps:875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:21.24785338783566 steps:898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:1.3468028327085602 steps:904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:0.026938290977315038 steps:906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:92.87840338143178 steps:928[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:3.2262956941372334 steps:937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:15.248968518134713 steps:951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-0.7247935599549524 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:23.897705608268357 steps:980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:2103.7943451452234 steps:997[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 161, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 275, in update_policy
    hs = [trajectory.hs for trajectory in experience[0]]
NameError: name 'experience' is not defined
2021-05-04 17:59:12.359726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:217): Gdk-CRITICAL **: 17:59:14.924: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620151158.028879858, 2.462000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620151158.029840222, 2.462000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620151158.029907071, 2.462000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620151159.382154429, 3.804000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620151160.385277829, 4.800000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620151161.192736279, 5.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620151161.994014384, 6.400000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:13266569.34552655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.9000040128619553 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.09137916518678146 steps:10[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:10.706513412080774 steps:34[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.292817480527913 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.1275520294163903 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-1.0599087858238059 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:1.67649694535847 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:3.4428605623693516 steps:65[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:5.976256914123237 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:35.43293564362663 steps:83[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:29.259406365451508 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.7688985308063945 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.0433499927573853 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:24.838040961947353 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:241.60097110257368 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-2.019696885242076 steps:145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:18.57608968937149 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-2.204597982705355 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:11.83358384528685 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.5155793896485314 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:382.6004031085187 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-1.2061787570969962 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:156.7354485992508 steps:693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:8.384367298551332 steps:709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-1.806856899676823 steps:711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-0.7168143519690549 steps:718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:4.5838370404556095 steps:726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-2.7982186531926905 steps:728[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-1.615754466363274 steps:730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-0.21468691987809319 steps:732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:7.619245970283478 steps:740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:21.984775506885335 steps:749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:2.8911549848247464 steps:755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-1.3050801354364288 steps:759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:8.113714556238985 steps:775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-1.3567922699455692 steps:777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.8432999016297562 steps:779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:16.02891173242677 steps:795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:15.970964682887676 steps:805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:37.737793609074316 steps:819[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-2.9618584032784443 steps:821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-1.4398804630301916 steps:823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.2855563786758772 steps:825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-1.6597644063298913 steps:827[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-1.4751716747527905 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:141.58192247738015 steps:867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-1.3188620074920956 steps:869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:6.661813395490018 steps:871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:13.987632726815356 steps:882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:8299.833441277531 steps:933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:132.9468836656067 steps:970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:4.86292586028831 steps:992[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:39.42775258999122 steps:1007[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:2.149279260573744 steps:1009[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 161, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 276, in update_policy
    robot_enc_state = np.stack(hs[0].cpu())
AttributeError: 'list' object has no attribute 'cpu'
2021-05-04 18:17:20.739099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:211): Gdk-CRITICAL **: 18:17:23.263: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 9, in <module>
    from torchsummary import summary
ModuleNotFoundError: No module named 'torchsummary'
2021-05-04 18:17:56.788814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:494): Gdk-CRITICAL **: 18:17:58.733: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620152281.655638505, 1.778000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620152281.656590393, 1.779000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620152281.656696858, 1.779000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620152282.917030566, 3.030000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620152283.619938908, 3.732000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620152284.425474930, 4.533000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620152285.226017832, 5.332000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3688443.8902456416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:56.00472747865968 steps:40[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.11025377860661978 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-0.5542495085773826 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:13.982102895180972 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:18.989771439804073 steps:71[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:41.68361424177062 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-1.7342169321566687 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:14.568701576340448 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:71.43388214629265 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:10.176459211776395 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:23.985777470009737 steps:157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:6.193351227173549 steps:162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:20.31363623083157 steps:176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:130.31012709314226 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:15.568965625304473 steps:198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:104.30606754379006 steps:235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:69.94336957644384 steps:252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:12.13903158446991 steps:264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:2.686390268897796 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:73.69194254310646 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:17.022056210551007 steps:318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:85.28557720264442 steps:330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-0.447388724802944 steps:332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-2.504677162779514 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:12.665758984598275 steps:336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:35.66497103080489 steps:357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:12.239155545350377 steps:365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-0.5314656089653265 steps:367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:18.205474945289033 steps:375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-0.5695508684766188 steps:377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:32.89964547450751 steps:392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:19.60232611287492 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:5.184959579605601 steps:417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:1.445935718978665 steps:431[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:0.32312733139650796 steps:433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:21.303608134863318 steps:446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:0.15529049092980518 steps:449[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:3471.021831662416 steps:949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:1.6266947266024427 steps:951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:2.053188413277494 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:1.7670402370907579 steps:955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:1.0010200291421447 steps:958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:1.5815264429448903 steps:965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-0.45252121841127435 steps:967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:81.45179423623085 steps:996[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 161, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 276, in update_policy
    robot_enc_state = [_.cpu() for _ in h[0]]
NameError: name 'h' is not defined
2021-05-04 18:27:50.858499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:5649): Gdk-CRITICAL **: 18:27:53.028: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620152875.532451476, 1.417000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620152875.533541860, 1.422000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620152875.533806623, 1.422000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620152876.878655911, 2.748000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620152877.533041899, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620152878.338957509, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620152879.140410559, 5.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3370417.7253092066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.1870514667001726 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:5.787085218839728 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:801.4139797269013 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:5.626205282302436 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:3.5019404029891175 steps:31[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-2.163072429745036 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.2809066130937916 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:79.07419653292997 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:3.123477931125258 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:2.14601913715096 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:11.972210094041085 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-0.2742893814474989 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:37.751499374722975 steps:105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.0513677602295664 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:1.2484397898416608 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:5.814548340138895 steps:125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-1.4846576380019516 steps:127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:4.460739349768676 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:92.66610986292926 steps:158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:4.028193494579358 steps:169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:0.3945270131877261 steps:171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:0.2439326285180421 steps:173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:14.154350019833485 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:4265.797606175692 steps:221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-0.22937206031925195 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:40.8238973148649 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:3.9439068347430766 steps:244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:1704.2993219110385 steps:257[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:20.31155438341638 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:12.189151473841447 steps:283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:16.17616100508784 steps:297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:15.975093552131527 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:6.536111430674879 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:2.604177037975119 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-1.30792682774104 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-0.0315557554354422 steps:371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:15.997911771250472 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-1.5364865076131542 steps:380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:1.8271589886435309 steps:394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:12.888253581699159 steps:414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:1.4590947263028773 steps:421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:9.740994417956227 steps:436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-0.6486506202467985 steps:444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-0.8203691694785451 steps:446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:34.366323205321166 steps:463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:6.305756844514885 steps:477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:12.646185709400758 steps:484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:6.280635870045148 steps:489[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:8.453913441732361 steps:495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:20.538505963643544 steps:515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:60.395269360222656 steps:522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-0.27541673480894424 steps:530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:99.502679546911 steps:551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:8.764346623538696 steps:564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-0.7309904866165793 steps:566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:0.29860285681715837 steps:581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:10.895583215097433 steps:590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:62.82283638937769 steps:610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:26.798272286257088 steps:629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:7.188223131508271 steps:663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-1.6541553918320329 steps:665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:5.573570068902688 steps:677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-1.7535094410926289 steps:679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:0.6867871102634244 steps:681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-0.3864282397588985 steps:683[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:0.17076020715878482 steps:685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-2.115772543660875 steps:687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:22.07834387318287 steps:695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-1.764976291109991 steps:697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:0.6303834839206077 steps:700[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:58.22329529043505 steps:713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:281.1945939464794 steps:759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-1.1138412792121024 steps:761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:29.750222207362828 steps:787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:11.775491454334903 steps:798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:1.4240886033502238 steps:805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-2.978398089139435 steps:810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:36.221562671164925 steps:826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-0.5758688502593627 steps:831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:6.543677765474995 steps:850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:12.077646194203275 steps:874[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-5.851772311897395 steps:878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-2.6484534248948624 steps:880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-2.5349318747303853 steps:882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:90.83894245321305 steps:889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:6.38598049799228 steps:896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:22.099416472708697 steps:905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-1.6984337893412986 steps:913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-2.6039592025333804 steps:923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:96.06502941867356 steps:955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:4.2086195571392775 steps:961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:13.69332418182313 steps:985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-1.981277912205046 steps:987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:22.446669140675603 steps:992[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:0.20987459953427168 steps:999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-1.9497356199460556 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 161, in train
    [torch.squeeze(_, 0) for _ in hs],
  File "/app/rl/torch/rdpg.py", line 278, in update_policy
    torch.zeros(
  File "<__array_function__ internals>", line 5, in stack
  File "/usr/lib/python3/dist-packages/numpy/core/shape_base.py", line 425, in stack
    raise ValueError('all input arrays must have the same shape')
ValueError: all input arrays must have the same shape
2021-05-04 18:38:10.640286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:11401): Gdk-CRITICAL **: 18:38:12.688: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620153496.220039343, 2.473000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620153496.221151269, 2.474000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620153496.221227961, 2.474000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620153497.506129982, 3.731000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620153498.503699056, 4.724000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620153499.306112511, 5.524000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620153500.107335808, 6.324000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:3018508.5631019687[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 146, in train
    self.stability(self.env.quadruped.stability)
TypeError: 'list' object is not callable
2021-05-04 18:41:17.789142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:11971): Gdk-CRITICAL **: 18:41:19.912: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620153683.625705022, 2.669000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620153683.626588668, 2.670000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620153683.626642932, 2.670000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620153684.865902680, 3.893000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620153685.787447413, 4.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620153686.589292926, 5.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620153687.390356404, 6.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:7888379.106911001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:15.370437280863818 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:66.57890442150232 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.9943978831157998 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.456756083988923 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:11.211131981290645 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-0.5317306652247746 steps:38[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:31.158514926579027 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:27.87591796502866 steps:69[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:24.08935015467388 steps:79[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.610538782159133 steps:81[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:24.225075204106112 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:41.20662614448677 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.0804400491465094 steps:109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-0.6146205015256674 steps:111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-1.2815879612555088 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:2.641075721668668 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:160.20274878387227 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:1.25575484915454 steps:128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:1.8241469471435283 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:47.609467066497174 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:95.83090199753862 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:5.275046947959661 steps:193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:82.33272540171134 steps:201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-2.2780782675055686 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:21.36986570812606 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:4.1257483797445005 steps:247[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620153810.771854052, 126.465000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620153810.771912209, 126.465000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620153811.774063522, 126.465000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620153811.774136797, 126.465000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 124, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.35)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 18:43:53.668993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:13797): Gdk-CRITICAL **: 18:43:55.788: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620153838.416588619, 1.589000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620153838.417628457, 1.590000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620153838.417774540, 1.590000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620153839.801160403, 2.964000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620153840.587812821, 3.748000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620153841.390594455, 4.549000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620153842.191639842, 5.349000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:15464979.933824336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-1.250200799818416 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:107.38838424832217 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:83.34731607361768 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:32.02094699370264 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-1.57423749223065 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:57.28378005495669 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:7.456215773078463 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:29.009157048731353 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:32231.50027194359 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:2.223745884143041 steps:135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:3.0286229193112417 steps:137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-0.2573004080987915 steps:139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:28.825013792374722 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:3.476851913833474 steps:157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:578.1240827217902 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:5.389821514712267 steps:185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:42.06315465138755 steps:198[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
/app/reward/__init__.py:28: RuntimeWarning: invalid value encountered in true_divide
  dl = np.abs(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-6.577108325042745 steps:208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-0.3636344732883541 steps:210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-1.7313099353332932 steps:230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:180.0498809689987 steps:285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.04079813220688333 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:17.05493905387597 steps:294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:0.27540715245991265 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-0.8988497349650619 steps:298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:2096.085307797048 steps:331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:0.5596428638241848 steps:347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:60.812471817148825 steps:351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.282465804773727 steps:353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:66.31338354506417 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-2.3756512720843483 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:0.4152062669401886 steps:374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-0.16449072987708502 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-0.6075285076142332 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:109.3937053315666 steps:400[00m
[RDDPG] Resetting Environment
[33m[ WARN] [1620154029.936498765, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.936589180, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.936618364, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.936859364, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.936887508, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.936909122, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937007422, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937039603, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937060603, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937080423, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937164013, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.937187467, 189.318000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 189.314000 according to authority unknown_publisher[0m
[33m[ WARN] [1620154029.941272705, 189.321000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.941345459, 189.321000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.941385385, 189.321000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.941670827, 189.322000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.941718598, 189.322000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942181204, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942253945, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942360542, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942403422, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942446130, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942488642, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 189.314000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620154029.942522927, 189.323000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 189.314000 according to authority /robot_state_publisher[0m
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:56.088059265977186 steps:427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:0.3717272655828432 steps:429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:0.6340872319006223 steps:432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:11.134374175107025 steps:442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-2.1500842454143267 steps:444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-0.8540102497045623 steps:446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-0.8389416431685199 steps:448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.1286227060483989 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:1.204350784330705 steps:452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:9.348935024145144 steps:467[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:140.6544535653475 steps:475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.2527263562438495 steps:477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-0.0579785363950609 steps:479[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:6.051822486906564 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:6.280504530836533 steps:498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-0.5475643430915094 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:99.91467364724102 steps:508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:2.383636486067293 steps:515[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-2.00753184866581 steps:517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:0.29629104088518377 steps:519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:38.26101823097689 steps:537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-0.5761258055984944 steps:541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-2.227856219240335 steps:543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-2.1606203517001905 steps:545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:1.7706411263356854 steps:553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:5.221626513596692 steps:573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-0.6224300509479832 steps:575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:17.05978030241333 steps:588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-0.3127456551971193 steps:590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:5.66960991568677 steps:599[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:587.6347277461468 steps:976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:5.204196675358166 steps:983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-2.6393302899262547 steps:985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-0.22872740862181562 steps:987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:0.3578761494903926 steps:989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:0.6711757340791444 steps:991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:0.9041618693397866 steps:993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-0.2876157590874522 steps:995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:18.60562118262025 steps:1006[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 176, in train
    if step > self.warmup:
  File "/app/rl/torch/rdpg.py", line 326, in update_policy
    self.batch_size,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 289, in forward
    action, robot_enc_state, z = self.cell(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 259, in forward
    robot_enc_state = self.gru(robot_state, robot_enc_state)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 1130, in forward
    self.check_forward_hidden(input, hx, '')
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 878, in check_forward_hidden
    if input.size(0) != hx.size(0):
TypeError: 'int' object is not callable
2021-05-04 19:00:52.339618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:19235): Gdk-CRITICAL **: 19:00:54.447: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620154858.024982897, 2.556000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620154858.025909974, 2.558000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620154858.025995483, 2.558000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620154859.386475635, 3.902000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620154860.212192347, 4.715000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620154861.014279182, 5.514000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620154861.816812161, 6.316000000]: Ready to take commands for planning group back_left_leg.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 93, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 248, in save
    self.plot(checkpoint_path, 'rewards_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 230, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 25, in plot_fit_curve_polymonial_5
    popt, _ = curve_fit(objective_polynomial_5, x, y)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 747, in curve_fit
    raise ValueError("`ydata` must not be empty!")
ValueError: `ydata` must not be empty!
2021-05-04 19:08:05.261645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:19652): Gdk-CRITICAL **: 19:08:07.482: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620155290.233247748, 1.847000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620155290.234438875, 1.849000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620155290.234507263, 1.849000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620155291.488127735, 3.091000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620155292.300238010, 3.900000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620155293.101862143, 4.700000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620155293.906088694, 5.499000000]: Ready to take commands for planning group back_left_leg.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 93, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 249, in save
    self.plot(checkpoint_path, 'rewards_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 231, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 25, in plot_fit_curve_polymonial_5
    popt, _ = curve_fit(objective_polynomial_5, x, y)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 747, in curve_fit
    raise ValueError("`ydata` must not be empty!")
ValueError: `ydata` must not be empty!
2021-05-04 19:12:37.724226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:20065): Gdk-CRITICAL **: 19:12:39.830: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620155562.510667608, 1.563000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620155562.511803635, 1.564000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620155562.512300873, 1.565000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620155563.761757540, 2.798000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620155564.571104709, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620155565.372800920, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620155566.175730234, 5.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:8998185.571405886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:1.991790457326379 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:12.764020996857107 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-0.8639611875395676 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-0.04911823466442922 steps:20[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.16478142707595 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:10.262391131582369 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-1.8020722174158323 steps:32[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:42.0112113087157 steps:131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:249.55577724342126 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:56.609724852097386 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:44.55301131213094 steps:180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:17.110582517258905 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:7.6961532997132345 steps:206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:3.4727142236882163 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:24.480519568680194 steps:227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:1.2169638241437677 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:5.137053685535198 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:45.184647391115575 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:24.313490106740307 steps:271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-0.2358644715359275 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:4.909882874030081 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.7239126650134418 steps:282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:0.007378938119936063 steps:291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-1.6885084547662121 steps:297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:5.795212671788673 steps:305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:1.8878299985945728 steps:313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:2.5069819064324346 steps:319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:5.342937696508956 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-0.019081585727599215 steps:331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-2.573632786632701 steps:334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-2.691840696467135 steps:336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:0.9700191157828995 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:22.229311848303826 steps:351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:5.921656902930826 steps:356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:10.634720645749425 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:3.421626707490005 steps:382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-2.0685027875575077 steps:384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-1.8389701461385703 steps:386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-1.1472126309718795 steps:388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-2.4467869169578114 steps:390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:37.08024706658592 steps:392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:2.188714014483696 steps:395[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.9222032074056163 steps:397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:267.7303598817159 steps:420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:6.884282055294111 steps:426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-2.5713958108193746 steps:428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:0.2917919795130497 steps:430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:4.147043426435884 steps:440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:6.647646379024605 steps:456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:10.253027985364668 steps:473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:2.9951929618225006 steps:480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-1.1873326636686055 steps:482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:8.140581146031582 steps:499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:13.908683377886803 steps:511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:16.63472788930246 steps:518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:5.89645619699254 steps:530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:8.170775344999328 steps:542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:11.185160547804083 steps:544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-0.52705489391663 steps:546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:67.14896042947773 steps:559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:13.509571713285059 steps:567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-1.1618003063987952 steps:575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:2.794951741720749 steps:579[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:20.742461295799743 steps:586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-1.5714305869486411 steps:588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:2.9448767364490225 steps:608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:6.76021995753622 steps:612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-2.3343629222038453 steps:614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-0.6226238685239287 steps:616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-0.7134206216531729 steps:620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:0.32213090921880383 steps:622[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:48.560984557432775 steps:642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-0.9989703662367155 steps:648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:1.3139442460839876 steps:650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:8.782587569472021 steps:668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-2.583298965120178 steps:670[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-0.2077873944071933 steps:672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-2.586011137658396 steps:674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:0.9338945271717503 steps:676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:587.3990830734446 steps:688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:0.563752407917367 steps:693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:2.3854281048860853 steps:698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:5.710335064659505 steps:705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-1.5543022649512324 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:12.219790448548125 steps:731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-0.5496539412972807 steps:735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:7.142264387596162 steps:743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:15.369023370240507 steps:753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-1.7944695993388349 steps:766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:2.2020983263232985 steps:773[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 9.36205
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.20337
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.30011
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.70573
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.96664
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.93990
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.26625
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.13069
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.12777
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.66760
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.10407
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91743
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:2836.7002933145427 steps:1125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.39538
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-0.5897644638822437 steps:1130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.97140
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:8.774052287405333 steps:1140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-0.15159441804656693 steps:1143[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.99905
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:20.014047145060733 steps:1152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:0.3277508713165189 steps:1157[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.67214
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:1.0498554874584602 steps:1162[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95886
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40643
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:12.482809023905089 steps:1180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:2.117614639605668 steps:1183[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.37198
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:2.830135872276928 steps:1193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:2.705885027499188 steps:1199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.80529
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.12412
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:3.198013059282514 steps:1210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:1.1138468440743248 steps:1214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:4.524662431872205 steps:1219[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.52484
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-2.5172434459448008 steps:1222[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.28324
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:3.541732982184908 steps:1239[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.11127
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.34931
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:124.59909756653045 steps:1252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-0.35127386136197103 steps:1257[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24031
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:6.751163751635472 steps:1261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-3.4513975707371407 steps:1267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.16901
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-0.6988886143749595 steps:1270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:38.50066431202943 steps:1277[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.12887
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:0.2136636385184616 steps:1283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-3.264176210190383 steps:1286[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.37342
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:10.763892048758095 steps:1292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:7.59330800568683 steps:1295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:719.2329459582061 steps:1298[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.81263
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:5.898510169975994 steps:1303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-1.1108361073392414 steps:1306[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.97134
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:29.005454408103695 steps:1312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-0.6364735527005825 steps:1319[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.93836
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-1.471003939081248 steps:1322[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.99335
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:10.713573819765434 steps:1335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:1.465049510701312 steps:1339[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.29382
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:24.22865090245277 steps:1347[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.85584
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-0.112967071602744 steps:1354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67787
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-2.939975210016187 steps:1360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-0.348636552302376 steps:1365[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.55486
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:38.67063979234806 steps:1373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13175
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:0.4392399799438196 steps:1380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-0.3714089007321211 steps:1383[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:22.18599754136522 steps:1387[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.36519
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:9.892503735405114 steps:1395[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.04820
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:9.954767078710073 steps:1400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-3.835745640810673 steps:1404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:4.398863825783257 steps:1408[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.93262
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:13.070224026861588 steps:1415[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.86793
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:99.6982973016407 steps:1421[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.51571
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:39.56763384273153 steps:1433[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08210
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:105.80254860336137 steps:1441[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.85296
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:13.74818359086499 steps:1451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:1.3829470356088547 steps:1458[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59669
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:19.78783614755779 steps:1461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:108.89351717770636 steps:1468[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.50419
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:81.30123193790446 steps:1477[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.84608
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:11.001409301780786 steps:1485[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.11721
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:18.364906964926384 steps:1496[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.93750
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:3.6797716502437714 steps:1505[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.13279
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:68.39092725564124 steps:1513[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:6.046880199747847 steps:1516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:2.4336911900190024 steps:1519[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.40292
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:8.03313580954358 steps:1524[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32720
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:3.2919319271397915 steps:1531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:5.027606578307078 steps:1534[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.57187
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:24.175024421423036 steps:1545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:9.990593609664948 steps:1549[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.47472
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:7.532327384534639 steps:1557[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.07459
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:30.49734413897821 steps:1561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:3.4932426966531582 steps:1565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06831
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:6.825556357141159 steps:1570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:164.11072986005783 steps:1578[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.44081
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:3.039166633777329 steps:1581[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52158
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:71.8169914831929 steps:1591[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.64609
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-1.5706312323642722 steps:1602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:6.6786302384244065 steps:1606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:0.24226809290773588 steps:1609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.20677
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:1.9306521876973668 steps:1614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-0.2546095301229112 steps:1616[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.66576
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:36.867984949958846 steps:1624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:0.08497629981730936 steps:1626[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.59918
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:20.16954101289589 steps:1634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:5.749874077596051 steps:1637[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.41755
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-0.8013139819538024 steps:1643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.59073
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-0.7630882687757394 steps:1650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:5.069259181416106 steps:1656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-1.819696909023606 steps:1659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.45011
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:0.01162766424271533 steps:1665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-0.43124087318688265 steps:1668[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.85102
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:2.506383670356869 steps:1673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49276
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-0.2674688693941336 steps:1680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:3.3477707099888656 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09384
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:2.3996870595828015 steps:1690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:4.589318501026795 steps:1694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-0.10187877314792715 steps:1698[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.15897
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:1.9462669006466609 steps:1704[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.99423
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:6.705358716825082 steps:1711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:31.422429832529183 steps:1718[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.87542
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:0.4279689764855532 steps:1721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:19.442846121304193 steps:1728[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.80284
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:1.5306476246686818 steps:1731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:2.791016659123519 steps:1738[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.20922
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:3.9676498454818554 steps:1749[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.76244
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:3.894117381509406 steps:1752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:1.1543960052717006 steps:1758[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.07044
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:79.08878807378265 steps:1762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-1.9418596465331794 steps:1764[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.52970
[WARN] [1620157080.597270, 1491.890000]: wait_for_service(/gazebo/get_model_state): failed to contact, will keep trying
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 137, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1216, in step
    self.set_observation(action, desired_motion)
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1072, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-04 19:38:46.662973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:29861): Gdk-CRITICAL **: 19:38:48.793: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Traceback (most recent call last):
  File "rddpg_torch.py", line 2, in <module>
    from rl.torch.rdpg import RDPG
  File "/app/rl/torch/rdpg.py", line 9, in <module>
    from rl.torch.agent import Agent
  File "/app/rl/torch/agent.py", line 3, in <module>
    from layers.torch_l import Actor, Critic, ActorCell
  File "/app/layers/torch_l.py", line 346
    output_size_action_state + output_size_robot_state + \ 
                                                          ^
SyntaxError: unexpected character after line continuation character
2021-05-04 19:39:28.913826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:30139): Gdk-CRITICAL **: 19:39:31.057: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620157174.462021110, 2.286000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620157174.462916542, 2.287000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620157174.463024170, 2.287000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620157175.861045273, 3.673000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620157176.589817800, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620157177.394564006, 5.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620157178.401029354, 6.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:15899454.974032437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:4.462029937756256 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.5690022364245948 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:4.83929136285549 steps:16[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-0.5106412603781427 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:8.812805313934563 steps:29[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:61.85848053218737 steps:36[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:55.60615147950533 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:68.86128292907074 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:26703.82481576455 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:7.164050287032097 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:48.053187579358685 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:107.31637750756522 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:16.376082388787328 steps:91[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:182.48225281720903 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:51.15712130953933 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-2.2195027207984057 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:0.07867572673446244 steps:122[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 348, in update_policy
    experiences = self.memory.sample(self.batch_size, self.trajectory_length)
  File "/app/rl/torch/memory.py", line 284, in sample
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 284, in <listcomp>
    batch = [self.sample_trajectory(maxlen=maxlen) for _ in range(batch_size)]
  File "/app/rl/torch/memory.py", line 290, in sample_trajectory
    e = random.randrange(len(self.memory))
  File "/usr/lib/python3.8/random.py", line 216, in randrange
    raise ValueError("empty range for randrange()")
ValueError: empty range for randrange()
2021-05-04 19:42:12.123615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:31757): Gdk-CRITICAL **: 19:42:14.178: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620157337.482613701, 2.275000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620157337.484359058, 2.278000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620157337.484529119, 2.278000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620157338.926428778, 3.694000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620157339.635305385, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620157340.442904664, 5.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620157341.243529275, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:11414841.593751516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.6674622067150604 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:28.722949750041373 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:41.76400671646159 steps:24[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:3.193941488917261 steps:35[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:25.963562802464086 steps:39[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:95.49093000055011 steps:44[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:57.034591693173724 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-0.547383788185902 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:168.6074142168328 steps:61[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:0.12712518138123974 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:0.8722652439071883 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-1.6098948337921222 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.7140441876223411 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-1.4001743149291421 steps:74[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:76.70213811613564 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:11.469987974391403 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:0.25989607726356256 steps:106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:25.580940372531607 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:3.825963954272756 steps:131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:0.2825974032111662 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:5.610532749756666 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:16.61305322426132 steps:148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:78.19360371888507 steps:176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:747.709170406016 steps:246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:21.058104977707465 steps:265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:18.174217543892006 steps:274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:37.51917227895035 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-1.31983785312748 steps:282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:108.73636205961606 steps:322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-0.9423243587877099 steps:328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-1.392914683701483 steps:330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:1.333321748377052 steps:332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:26.29446900210605 steps:340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:21.011608538583555 steps:348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:257.47670338677614 steps:364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:27.605719806691898 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:6.1549663560159384 steps:381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:6.291964083927338 steps:400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-0.2877769272839461 steps:402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:0.2671982635362289 steps:408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:204.2114373824859 steps:416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:14.497215305053649 steps:424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:3.0072018798047284 steps:434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:1.014035799033834 steps:436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:48.506697127228925 steps:453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:53.28441025818934 steps:469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-1.4083283319563835 steps:473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:0.9419481536435845 steps:479[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:129.6680858913203 steps:498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-2.4446583656288614 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-0.9056754816546344 steps:502[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:526.7569171938137 steps:1002[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 406, in update_policy
    next_q_value, target_h = self.agent.critic_target(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 376, in forward
    return self.out_dense_seq(x), x
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 dim 1 must match mat2 dim 0
2021-05-04 19:52:40.899590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:4487): Gdk-CRITICAL **: 19:52:42.940: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620157967.414187725, 3.275000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620157967.415238029, 3.276000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620157967.415502539, 3.277000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620157968.706484531, 4.556000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620157969.553119592, 5.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620157970.360342164, 6.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620157971.162703747, 7.000000000]: Ready to take commands for planning group back_left_leg.[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 28, in <module>
    rdpg = RDPG(env, params)
  File "/app/rl/torch/rdpg.py", line 36, in __init__
    self.agent = Agent(
  File "/app/rl/torch/agent.py", line 24, in __init__
    self.critic = Critic(self.params)
  File "/app/layers/torch_l.py", line 353, in __init__
    elf.params['units_gru_rddpg'],
NameError: name 'elf' is not defined
2021-05-04 19:54:21.014818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:4898): Gdk-CRITICAL **: 19:54:23.126: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620158065.770787403, 1.493000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620158065.772210114, 1.495000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620158065.772262094, 1.495000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620158067.101094201, 2.810000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620158067.887840091, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620158068.698098117, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620158069.498880527, 5.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:12781452.798914263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.218539328311674 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-2.2298372157240034 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:161.80854987437306 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:53.64591817528355 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:2.272404685926844 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:0.3226306494206228 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-2.062929648727793 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:14.45227457233623 steps:60[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:6.736658446951559 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:27.041167488545927 steps:87[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:10.290629093149908 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:3.2681661621325833 steps:116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-0.5420013152312178 steps:118[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.7787928735349845 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:4.345240286255967 steps:129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:155.50143597355554 steps:173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:1.8700168371857382 steps:184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-0.3032807065571217 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.329227763981028 steps:197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-0.22794372732343726 steps:199[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:31.17227066859707 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:0.3957964041100812 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-1.2180809050043173 steps:226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:17.37446398771648 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:7.276982679509997 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-1.7452584831059585 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:62.30628675226742 steps:282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:4.171294438248078 steps:289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:10.422439413907796 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:0.053016571827083414 steps:302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:0.4864633527547002 steps:308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:158.79725310618278 steps:353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:15.147648971815823 steps:363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:109.9944564688047 steps:382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:41.7839639458294 steps:404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-2.178490911963394 steps:412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.020771828916699 steps:414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-1.2498553502603673 steps:416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:4.618758589276148 steps:436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:14.14665010814557 steps:447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-2.9094630026549244 steps:449[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-2.2980185572404936 steps:451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:273.6673958530474 steps:466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:10.944497815711152 steps:479[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:337.96099795857737 steps:498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-1.589132727952246 steps:500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:32.65631204623559 steps:514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-0.35920856631598674 steps:516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:3457.9901050356443 steps:557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:31.288547095023105 steps:559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:19.04452038977967 steps:561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:52.16485219533103 steps:574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:38.475355834456565 steps:580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-1.908223580746229 steps:582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-0.3204371895252387 steps:584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:5.251058420272289 steps:588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:12.69079972629065 steps:600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:2.181257966292552 steps:604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:28.82501620002513 steps:616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:9.111186222405145 steps:629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-1.8989703214345823 steps:631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:34.74013485811776 steps:652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:9.70048241734838 steps:670[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:0.6646490500567714 steps:674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-1.9557020299494456 steps:677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:5.637752978403914 steps:684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-1.783858812445816 steps:686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-0.2662139136204462 steps:688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:50.05015067478954 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:10.240432473046724 steps:719[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-0.4448098106145588 steps:721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:2.524783718783308 steps:731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:66.3319850374803 steps:763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:102.45180268894521 steps:791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-1.6861818122540542 steps:794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:41.72271567405689 steps:803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:35.82646625444157 steps:822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:28.62646342207131 steps:830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:105.94778465013798 steps:869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:0.5349712620207048 steps:871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:77.66399823928143 steps:900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:2.0147645230053666 steps:911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:0.5382730214562517 steps:913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-2.4615836106988063 steps:915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:11.859959118989622 steps:924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:54.65997042487759 steps:934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:3.1218762651647305 steps:940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:5.667833284799148 steps:947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:24.332855503898266 steps:963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:12.48922275442794 steps:972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-1.653158223587793 steps:974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:24.785920779386885 steps:988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:69.63798992806784 steps:1008[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 441, in update_policy
    policy_loss_total += -torch.mean(q_val) / len(experiences)
TypeError: mean(): argument 'input' (position 1) must be Tensor, not tuple
2021-05-04 20:02:08.416839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:10514): Gdk-CRITICAL **: 20:02:10.572: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620158533.052840901, 1.450000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620158533.053664928, 1.450000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620158533.053772948, 1.450000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620158534.308133133, 2.690000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620158535.019812264, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620158535.821166523, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620158536.622832014, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2504642.596949204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.963372150852978 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.2409886481786294 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-0.8967080150182545 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:3.2444538113498727 steps:18[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-3.206851066239427 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:0.32547228919675497 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:7.777940663700935 steps:62[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:38.25414121510352 steps:77[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:7.429322155108593 steps:92[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:4.103348857890705 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:1.367862568164183 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:3.0780651678912454 steps:122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:3.7290324215944954 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:16.320458706261775 steps:128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:147.51776223410278 steps:132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-2.1762742484738173 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-2.5333685406382216 steps:146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:11.91839032914755 steps:152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:62.29767806683893 steps:177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:32.87167899050026 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:4.09479183827128 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-1.732469342562664 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:175.4553812412857 steps:223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:1.1567938503153194 steps:230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-3.313295403411353 steps:237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:0.21810412656508538 steps:242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:1.9299590071937116 steps:247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-1.8686480874316023 steps:250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:3.19871030915494 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:11.018789266775096 steps:278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:3.8414404038229266 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:29.1105381585167 steps:296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:134.7058394177355 steps:307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:12.4310394541361 steps:317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:9.8649529052888 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:4.211867742822338 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.7384836802057966 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:447.7376377593382 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:2.3445492368001 steps:349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-0.760837659409032 steps:351[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:2639.0734537830785 steps:851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:63.419589736385284 steps:863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-1.4153917990047602 steps:867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:9.712105334200924 steps:873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:10.683154446964355 steps:880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:20.648097842516698 steps:885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.765013792546055 steps:887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:36.903288979469046 steps:895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-1.319448691498284 steps:897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:193.0777599110264 steps:917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:11.56137967449305 steps:925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:13.435226713870541 steps:934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:13.043622071467784 steps:964[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:10.24448805918567 steps:969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:2.709425639421405 steps:989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:5.7270560813859825 steps:998[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:159.38606763571116 steps:1009[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[W python_anomaly_mode.cpp:104] Warning: Error detected in ThnnFusedGruCellBackward. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 416, in update_policy
    current_q, h_ = self.agent.critic(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 372, in forward
    x = self.gru(torch.cat([ms, rs, ac], -1), h)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 1131, in forward
    return _VF.gru_cell(
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 451, in update_policy
    policy_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.
2021-05-04 20:15:42.747026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:15751): Gdk-CRITICAL **: 20:15:44.883: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620159348.314117611, 2.319000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620159348.315123120, 2.319000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620159348.315357229, 2.320000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620159349.599425452, 3.596000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620159350.405765685, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620159351.208305369, 5.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620159352.008955348, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:18859939.842757016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.466903629826737 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-2.9522476447523704 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.7837382228248924 steps:6[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-0.8104967793352487 steps:8[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:779.5814409707147 steps:37[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:5.9778867702757505 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:410.8172169766933 steps:97[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:7.8457335103575705 steps:99[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:7.555470984626718 steps:101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:22.665596853191907 steps:110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:0.5411043406118736 steps:121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:1.555666986399674 steps:125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:23.394270428612067 steps:139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:259.31492001635684 steps:163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:0.9191904607569144 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:13.004949071384019 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:23.34699773427647 steps:192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:37.68848358892208 steps:202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-0.5290255944997808 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:4.716171802044296 steps:229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-1.8574968618078678 steps:231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:79.40281015973144 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:-2.555231457543501 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-0.6976359854077572 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-0.03505150831145798 steps:247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:73.58862670329651 steps:266[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:533.1337132372298 steps:766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:23.309595032482616 steps:782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:60.07515303411853 steps:811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:1.3614310725081973 steps:814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:10.462624583830168 steps:828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:0.04733318147483834 steps:833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-0.0020619599013218526 steps:835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:198.9650770446444 steps:852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:12.352410014089044 steps:866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:3.3372128914005477 steps:871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:20.212845548322566 steps:886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:44.1500318959585 steps:899[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:184.40287917952 steps:982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:2.4419468699351743 steps:986[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:190.49478949779302 steps:1001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-0.054233869222565456 steps:1003[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 9.73553
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.19945
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:68.0038772328214 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-0.8127102745650561 steps:1023[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.52430
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.67588
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07160
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.79935
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.94123
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.56351
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.60471
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.23768
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.91095
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.34715
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.46595
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.85488
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.81927
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.12529
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.55866
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.09269
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.10598
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:400.30599491553477 steps:1198[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.65100
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:4.047229582737698 steps:1208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91405
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-3.099661681162555 steps:1210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-1.7811649481626672 steps:1212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:1.534025364378298 steps:1216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76762
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:0.40822945923408227 steps:1220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-1.9488825285009341 steps:1222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:1.0620432257935914 steps:1227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.84525
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-0.612510739315852 steps:1230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-0.49873465696455765 steps:1233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-1.9713971136843638 steps:1235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-0.7169002818946959 steps:1238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[W python_anomaly_mode.cpp:104] Warning: Error detected in DivBackward0. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 428, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 289, in forward
    action, robot_enc_state, z = self.cell(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 263, in forward
    self.pretrain_cell(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 203, in forward
    actions, Z, _, _ = self.rhythm_gen(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 189, in forward
    out = self.complex_mlp(z)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 66, in forward
    return complex_tanh(input)
  File "/app/layers/torch_l.py", line 38, in complex_tanh
    y = torch.sinh(2*y) / denominator
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 177, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 454, in update_policy
    policy_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Function 'DivBackward0' returned nan values in its 1th output.
2021-05-04 21:08:24.115667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:21882): Gdk-CRITICAL **: 21:08:26.246: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620162509.967186236, 2.609000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620162509.968224246, 2.611000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620162509.968290787, 2.611000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620162511.174860708, 3.788000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620162511.988941504, 4.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620162512.789606109, 5.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620162513.591836209, 6.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:25641489.148239493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.40063240926381116 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.2004783798154157 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:20.427137947011936 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:41.2630962359378 steps:28[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:87.4661553332514 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:23.54969050064388 steps:58[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:5.271257635664409 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-0.30460247361016934 steps:75[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:20.4733189993717 steps:90[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:5.272800261167408 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-1.2429816140792411 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:0.0739959779335968 steps:107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:70.02861725129976 steps:124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:27.762054163367793 steps:135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:40.969561315034994 steps:141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:20.64503814977563 steps:147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:4.663668862833138 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:15.226441592953854 steps:169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:13.801050815749626 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:5.619300658036945 steps:187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:15.325876652014282 steps:199[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:19.600600638650064 steps:212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:5.323596604868895 steps:219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:205.75293546354806 steps:232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-1.9281361558104302 steps:234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:22.331085857096312 steps:250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-1.9680292892271363 steps:256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-2.4371008228565616 steps:258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-0.35148014845436326 steps:264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:2.1019703321204903 steps:278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-2.2560052950759353 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:21.957111273090597 steps:294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:7.753371760560612 steps:308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-2.398435510540231 steps:311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:14.685263083118686 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:2.9886735021536426 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:5.4802427169306895 steps:335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-0.5896909792502252 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:20.13169837255831 steps:348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:28.757658061509137 steps:356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:29.217338529374455 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:0.7646464420936074 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:7.838981009052329 steps:391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:1.158718326704581 steps:399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:1.9990838076908402 steps:408[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
/app/reward/__init__.py:28: RuntimeWarning: invalid value encountered in true_divide
  dl = np.abs(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:702.0744533185772 steps:420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:17.571032603641186 steps:429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:21.267089966267644 steps:444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:1.410333842507102 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:46.71395678761972 steps:468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:80.27557704003046 steps:486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:507.5109985145071 steps:492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-2.3486725399023185 steps:497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:16.879833828644763 steps:563[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:4.28496001488433 steps:574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:41.32845103166011 steps:580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:2.776526072693017 steps:602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:30.60451133637416 steps:618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:60.12595611196055 steps:635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-0.3110163656565388 steps:637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-0.06356039425337778 steps:639[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-1.8082230134002846 steps:641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:0.3700204594044809 steps:643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:10.296704428153676 steps:655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:135.57528157941488 steps:682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:41.20613767139587 steps:684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:7.81940615345738 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:0.4683988569141322 steps:727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:70.28450299591145 steps:734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:7.89635345599185 steps:754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:20.972797995052332 steps:761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:3158.9791503050687 steps:779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:21.733971971827348 steps:788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:10.236253332101713 steps:800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:11.743552479188278 steps:809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:15.29180324272074 steps:828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:6.0120345214872115 steps:836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:102.49764956499948 steps:860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:4.493388282498988 steps:874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:0.20096242901400574 steps:885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:2.58012920216394 steps:890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:5.486520962602704 steps:893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:6.176514541975723 steps:900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:2.7025198587866073 steps:909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-1.754669887421617 steps:916[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:0.33911159690527004 steps:921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:122.37017222809531 steps:974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:1.5723303898225058 steps:977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-1.3730656061563573 steps:979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:15.797802829103517 steps:995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:2.1207192352123108 steps:997[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 8.95056
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:6.901669004136626 steps:1011[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.68849
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:24.736096483597183 steps:1029[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.53032
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.65520
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.50093
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:2.892511777849629 steps:1052[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.04494
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-0.7607356999326835 steps:1061[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.35617
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:12.80899928884624 steps:1073[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.85473
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:4.4521314563993375 steps:1085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:0.6700758703271821 steps:1088[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.49827
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:4.1625604240543925 steps:1094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-1.2533728415014205 steps:1096[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.00224
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:0.9805709222623653 steps:1101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1.080565227092662 steps:1103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-1.1307771794876333 steps:1105[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.60387
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:3.1330730858785003 steps:1111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:-3.5080704620811196 steps:1114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:9.965493521746241 steps:1118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.04901
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-2.8697490087434416 steps:1120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-1.0930346021649542 steps:1122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-0.8171143473373719 steps:1124[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.32707
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:1.678413109932349 steps:1131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:3.558890023865989 steps:1136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-2.417319169574255 steps:1138[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.77176
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-2.0429427846153234 steps:1142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-3.1008751478860037 steps:1144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:6.994187075670601 steps:1149[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.33805
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-2.585324363889948 steps:1151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-2.5624239043337287 steps:1154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-1.4256148349287847 steps:1156[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.41159
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:4.226264341591168 steps:1162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-0.8805824736650738 steps:1165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-0.6622259820159857 steps:1168[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.26551
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:13.82598918108601 steps:1173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-1.2764994212938328 steps:1177[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.89026
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:2.201677034479787 steps:1182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-1.5347193806681267 steps:1184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-0.20057871542414052 steps:1188[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[33m[ WARN] [1620163244.829518912, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829590287, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829621388, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829650045, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829671978, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829694272, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829714951, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829736191, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829767070, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829791861, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829820604, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.829854631, 724.846000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 724.815000 according to authority unknown_publisher[0m
[33m[ WARN] [1620163244.837278353, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg1 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837399062, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg2 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837440973, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_left_leg3 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837473288, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg1 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837511858, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg2 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837539878, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame back_right_leg3 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837568398, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg1 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837597870, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg2 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837636463, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_left_leg3 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837666045, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg1 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837695933, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg2 at time 724.815000 according to authority /robot_state_publisher[0m
[33m[ WARN] [1620163244.837733642, 724.852000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame front_right_leg3 at time 724.815000 according to authority /robot_state_publisher[0m
[RDDPG] Update Time: 10.81243
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-2.6097468550625904 steps:1191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:1.8941086792446944 steps:1195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-2.633642414144445 steps:1197[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.61940
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-1.517293380464339 steps:1201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-0.1309584494090239 steps:1203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:0.34497583566071865 steps:1206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.59596
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:2.131594829049423 steps:1210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:0.3201673007313488 steps:1213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:12.44213714458709 steps:1218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.32120
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-1.7994658929263796 steps:1220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:24.396286874260067 steps:1225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-2.820298065451067 steps:1227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-1.8327390338358778 steps:1229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.26391
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-1.608129110762278 steps:1232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-2.6178560598523535 steps:1234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-0.8404662300269716 steps:1237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.92832
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-0.8193431332689642 steps:1240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-0.8394468612138999 steps:1244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.46385
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:0.8030198654780105 steps:1250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:2.238630503428081 steps:1256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:11.725378202199401 steps:1258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.18700
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-1.5215177466047685 steps:1260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-0.3517056314954812 steps:1262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-2.0741421928707826 steps:1265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:-1.8761215121046733 steps:1267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-2.979503922612726 steps:1269[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.37534
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-2.99281509920681 steps:1271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:0.63464252025814 steps:1273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:2.8808436424924917 steps:1278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.75568
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-3.816324241534874 steps:1280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:-3.4518406747688437 steps:1282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:-3.77130465859713 steps:1284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:1.2076031471588067 steps:1286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-1.1254068171819254 steps:1288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73058
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-2.683125677321436 steps:1290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:3.8163888874282876 steps:1293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:7.559920870752366 steps:1295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:7.490053355640209 steps:1297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.17640
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-1.3966530292051282 steps:1300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-2.6424620979466544 steps:1303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:-3.318943863148854 steps:1306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-2.383975327148712 steps:1307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:6.657822615093494 steps:1309[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.74449
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:0.784156176200169 steps:1311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:7.449479410259052 steps:1319[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.19098
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-3.0175905861559507 steps:1321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-2.6950512573238545 steps:1322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-1.425416575139743 steps:1324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:0.8135814725150623 steps:1327[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.60795
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:1.9423498914991586 steps:1333[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:-0.43981538965688527 steps:1338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.72910
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-3.5254773405340294 steps:1340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-3.7078846683566336 steps:1342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:10.688049380961024 steps:1347[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.83413
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:4.263298147984814 steps:1355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:-2.4564252441410748 steps:1356[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.76639
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:9.427761199841528 steps:1363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-1.871637711907072 steps:1368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-2.9095770983887705 steps:1369[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.84497
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-0.9572681771433114 steps:1371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:9.950427915531094 steps:1375[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.02739
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.92356
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:29.062819310206393 steps:1391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-2.7353529687482863 steps:1392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-3.0914517456048967 steps:1393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:-2.363142256469234 steps:1394[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68500
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:21.59485642624209 steps:1401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-1.2790693030190785 steps:1403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:4.352626665308148 steps:1408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.28700
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:-1.859030688930809 steps:1410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:11.463782065383008 steps:1414[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.18241
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:17.614851007623475 steps:1422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-1.9218520859615253 steps:1424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07349
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:0.4712721163577256 steps:1430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:-3.8823831030683027 steps:1432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:0.13257482490918004 steps:1437[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.06907
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:3.2393375311489363 steps:1441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:2.3453571634971286 steps:1445[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.43231
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:6.642342003420793 steps:1452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:-0.27953554031142236 steps:1454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:12.991686727550588 steps:1459[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.10169
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-1.2911474880196638 steps:1461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:11.038150964419899 steps:1466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-1.8482498673485495 steps:1469[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.99013
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:-2.0854385944075453 steps:1471[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:-2.4348057556598013 steps:1473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:-1.7996360345819142 steps:1475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-2.5240090844717216 steps:1476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:-3.18345402832279 steps:1477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.42953
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:28.697023614799743 steps:1480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-2.9933521923844184 steps:1481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-2.4260535522465867 steps:1482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:0.4811621270293567 steps:1485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-1.4045319392090376 steps:1487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.58675
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:3.534439480627322 steps:1490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:0.23909938506922446 steps:1494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:-1.6114979517582486 steps:1499[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.38656
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:15.402795290022523 steps:1503[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.01759
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:10.741447253844036 steps:1511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:4.779285173755068 steps:1518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.46462
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:0.00704298350269239 steps:1520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:-1.1754560828923504 steps:1523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:6.703282300372763 steps:1526[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.60394
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-1.0606624539002494 steps:1531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:6.6592560876571065 steps:1533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:6.41279830986495 steps:1538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.45579
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:1.839801422563471 steps:1540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:1.2678020601764164 steps:1545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29908
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-4.182675852353871 steps:1550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-1.2438814922539958 steps:1552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-0.6428701905301004 steps:1555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-3.353316271888375 steps:1557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:-2.876963164063918 steps:1558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-3.5782916918925904 steps:1559[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.04306
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:-1.641161380190451 steps:1561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-2.0411322403571193 steps:1563[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:0.705813382973449 steps:1568[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.35579
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:23.467638207576144 steps:1573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:-0.48433099945275027 steps:1576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.62200
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:2.45732535693195 steps:1580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:-3.891893671871892 steps:1581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:-2.1869747052818758 steps:1584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:-2.7222183337424752 steps:1585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.47259
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:7.130178902785605 steps:1590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:3.924274453120013 steps:1593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:27.551901160669768 steps:1596[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40779
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:2.478528475212423 steps:1601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-1.7221357198284613 steps:1603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:3.155159593292212 steps:1607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.70444
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:-3.3307792536881404 steps:1610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-3.427331877445282 steps:1611[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-1.4311318858670086 steps:1613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-1.2746222365903186 steps:1615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-2.0821984251418764 steps:1617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:-3.6832755737314895 steps:1618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93126
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-3.1852116790108376 steps:1620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:-1.1966703875030587 steps:1623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:-3.0965964972882913 steps:1625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:-3.604975449221345 steps:1626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-2.5042020683614896 steps:1628[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.23344
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:-2.5729467842020135 steps:1630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:-2.935169811894365 steps:1632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:-2.7866943003029743 steps:1634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-0.981087851441216 steps:1637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:-2.8735701904132753 steps:1639[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.96863
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:4.800348927302592 steps:1646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:-3.462762968750056 steps:1647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:-2.3913114640858986 steps:1649[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.21914
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:22.47385816258564 steps:1655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-3.273138036435138 steps:1657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:1.3506334920591492 steps:1659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.22341
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:1.230979531844647 steps:1661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:-1.8698387549503361 steps:1664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:-3.011713233410329 steps:1666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-3.344565423305377 steps:1668[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.77140
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:1.6200140411072415 steps:1671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:-1.2410036533948503 steps:1673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:-3.2608678002956086 steps:1674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-0.9977746232881028 steps:1676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-0.42441854446299176 steps:1678[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.32767
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:-0.4111035589100327 steps:1681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:-4.317554843746429 steps:1682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-2.4660806649054985 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:-3.166045044505206 steps:1686[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.18774
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-0.6746658382878001 steps:1692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:-0.2675402575350061 steps:1694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:-3.208432348632944 steps:1695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:-3.5677200710396884 steps:1697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:-2.6444503121411356 steps:1699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.57356
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:1.795474213650769 steps:1701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:0.326166938398186 steps:1703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:-0.9210810969557865 steps:1705[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.73122
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:-2.188841838565076 steps:1711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 298: episode_reward:-2.3009346470173777 steps:1713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 299: episode_reward:-1.8897372438785656 steps:1716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.92223
[RDDPG] Episode Done
[92m [RDDPG] 300: episode_reward:-0.6923242261278166 steps:1720[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 301: episode_reward:-1.1802598434047282 steps:1722[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 302: episode_reward:-3.3310410546875504 steps:1723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 303: episode_reward:-3.0489184421167876 steps:1725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 304: episode_reward:-1.5748598652776142 steps:1727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.86237
[RDDPG] Episode Done
[92m [RDDPG] 305: episode_reward:-1.604006404535624 steps:1730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 306: episode_reward:-3.115601600839769 steps:1732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 307: episode_reward:-2.3703384695132805 steps:1734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 308: episode_reward:-0.813731228853591 steps:1736[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 309: episode_reward:-1.1494382810105377 steps:1738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.08174
[RDDPG] Episode Done
[92m [RDDPG] 310: episode_reward:-3.707409941241675 steps:1740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 311: episode_reward:-2.3434513633248106 steps:1742[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 312: episode_reward:-3.03782962122293 steps:1744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 313: episode_reward:-2.1939123369378324 steps:1746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 314: episode_reward:-0.5557704261261438 steps:1748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.72039
[RDDPG] Episode Done
[92m [RDDPG] 315: episode_reward:6.382019081386083 steps:1750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 316: episode_reward:-1.3109511880188935 steps:1752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 317: episode_reward:-2.233115755226412 steps:1755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 318: episode_reward:-2.7594176562500285 steps:1756[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 319: episode_reward:-3.3359217602583544 steps:1757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 320: episode_reward:0.6248330658177812 steps:1759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.07111
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 321: episode_reward:-2.6781358073308676 steps:1761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 322: episode_reward:-2.917732373044495 steps:1762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 323: episode_reward:-3.1295752343753245 steps:1763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 324: episode_reward:5.592180788289278 steps:1765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 325: episode_reward:-0.7958709484994624 steps:1767[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.77805
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 326: episode_reward:1.604258636234536 steps:1771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 327: episode_reward:-3.723875056564819 steps:1773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 328: episode_reward:-2.792819494629824 steps:1774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 329: episode_reward:-3.1406400911394994 steps:1776[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 330: episode_reward:-4.014560598331302 steps:1778[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 331: episode_reward:-4.195538928219957 steps:1779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.45199
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 332: episode_reward:-2.965526669295027 steps:1781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 333: episode_reward:-3.657155156751802 steps:1783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 334: episode_reward:-3.131671930990731 steps:1785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 335: episode_reward:-1.112608637093297 steps:1787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 336: episode_reward:-4.302617795240282 steps:1789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.79398
[RDDPG] Episode Done
[92m [RDDPG] 337: episode_reward:-3.5409244335988808 steps:1790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 338: episode_reward:-3.919879240727351 steps:1791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 339: episode_reward:-3.3259480834976287 steps:1792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 340: episode_reward:-3.417854956423362 steps:1794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 341: episode_reward:-4.791188045356154 steps:1796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 342: episode_reward:-4.109497109373777 steps:1797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 343: episode_reward:-3.6558795176270715 steps:1799[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.71358
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 344: episode_reward:-1.2004655388332208 steps:1801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 345: episode_reward:-1.3271496314003501 steps:1803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 346: episode_reward:-2.126640113299285 steps:1805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 347: episode_reward:4.596023357816912 steps:1807[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 348: episode_reward:-0.42031158966122417 steps:1809[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.30569
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 349: episode_reward:-2.7211300010515926 steps:1811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 350: episode_reward:-3.544163348400085 steps:1813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 351: episode_reward:-3.2506928613307435 steps:1814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 352: episode_reward:0.18814686107434575 steps:1816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 353: episode_reward:-4.384099999996327 steps:1817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 354: episode_reward:-1.7515318109666236 steps:1819[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.79416
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 355: episode_reward:37.05640580463365 steps:1822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 356: episode_reward:5.796559606273734 steps:1824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 357: episode_reward:-1.9980154615816068 steps:1826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 358: episode_reward:-3.2724774286427865 steps:1828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.43598
[RDDPG] Episode Done
[92m [RDDPG] 359: episode_reward:-3.5634702260043496 steps:1830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 360: episode_reward:-3.2682112426720065 steps:1831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 361: episode_reward:-0.9729899773243686 steps:1833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 362: episode_reward:13.78994789582508 steps:1835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 363: episode_reward:-4.69916579085986 steps:1837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 364: episode_reward:-2.0872679416293014 steps:1839[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.04194
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 365: episode_reward:21.802752340053015 steps:1842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 366: episode_reward:-3.7650003710878446 steps:1843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 367: episode_reward:-0.4170909174272388 steps:1845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 368: episode_reward:-3.802979052732735 steps:1846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 369: episode_reward:7.794182981595663 steps:1848[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72574
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 370: episode_reward:1.5750369861058 steps:1851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 371: episode_reward:-1.01771660634013 steps:1853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 372: episode_reward:-2.5674113840580275 steps:1855[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 373: episode_reward:5.103945521350566 steps:1857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 374: episode_reward:-2.3842799470203264 steps:1859[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.38916
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 375: episode_reward:-4.2399824094247744 steps:1861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 376: episode_reward:-2.705900576493434 steps:1863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 377: episode_reward:-3.5749342626985006 steps:1864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 378: episode_reward:3.4622594399047495 steps:1866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 379: episode_reward:-2.395280466833631 steps:1868[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77983
[RDDPG] Episode Done
[92m [RDDPG] 380: episode_reward:-0.7725232450896333 steps:1870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 381: episode_reward:-1.8701825770020053 steps:1872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 382: episode_reward:-1.423032163947748 steps:1874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 383: episode_reward:32.632516501766496 steps:1876[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 384: episode_reward:0.8518797111351315 steps:1878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20690
[RDDPG] Episode Done
[92m [RDDPG] 385: episode_reward:-2.401173884769428 steps:1880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 386: episode_reward:-2.205568016412612 steps:1882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 387: episode_reward:-1.7995890504496055 steps:1884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 388: episode_reward:3.2241856450607798 steps:1886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 389: episode_reward:-0.36955669440495287 steps:1888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.94187
[RDDPG] Episode Done
[92m [RDDPG] 390: episode_reward:-0.06318711060182824 steps:1890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 391: episode_reward:-4.939868937798135 steps:1892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 392: episode_reward:-2.8005833665474684 steps:1894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 393: episode_reward:1.2947625082771634 steps:1896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 394: episode_reward:-4.034409755859119 steps:1897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 395: episode_reward:-3.121714146728838 steps:1898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.69453
[RDDPG] Episode Done
[92m [RDDPG] 396: episode_reward:-2.2399010844521556 steps:1900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 397: episode_reward:-3.105348461077206 steps:1902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 398: episode_reward:-2.567402193913784 steps:1904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 399: episode_reward:-2.8070204605306794 steps:1906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 400: episode_reward:-3.0235273477342837 steps:1908[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 401: episode_reward:-4.0937726782232575 steps:1909[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.64638
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 402: episode_reward:-1.7577859131985805 steps:1912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 403: episode_reward:-2.4979072689530772 steps:1914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 404: episode_reward:-2.659563293022285 steps:1916[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 405: episode_reward:4.0481963164011 steps:1918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54887
[RDDPG] Episode Done
[92m [RDDPG] 406: episode_reward:0.7556976955684704 steps:1920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 407: episode_reward:-2.761705939045436 steps:1922[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 408: episode_reward:3.5651896882510083 steps:1924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 409: episode_reward:-3.5114246195349326 steps:1926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 410: episode_reward:-3.451433217743196 steps:1928[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32005
[RDDPG] Episode Done
[92m [RDDPG] 411: episode_reward:-3.4656422934391955 steps:1930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 412: episode_reward:-2.0002133373188973 steps:1931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 413: episode_reward:-2.754354871066975 steps:1933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 414: episode_reward:17.595953669894676 steps:1935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 415: episode_reward:-2.764287656250934 steps:1936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 416: episode_reward:-3.1215420312518134 steps:1937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 417: episode_reward:-2.405370140634587 steps:1939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.94239
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 418: episode_reward:-2.706625665488395 steps:1943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 419: episode_reward:83.54986945532906 steps:1945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 420: episode_reward:-0.3810954145755998 steps:1947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 421: episode_reward:-2.4399760516347757 steps:1948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.23735
[RDDPG] Episode Done
[92m [RDDPG] 422: episode_reward:-1.737816483025171 steps:1950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 423: episode_reward:-3.7042750463894745 steps:1951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 424: episode_reward:-2.5668066650380514 steps:1952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 425: episode_reward:-2.321891448394436 steps:1954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 426: episode_reward:-4.339144494630871 steps:1955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 427: episode_reward:-2.929480732310998 steps:1957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 428: episode_reward:1.1672563856297087 steps:1959[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07025
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 429: episode_reward:1.4437589259117103 steps:1961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 430: episode_reward:-2.0271118330171394 steps:1963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 431: episode_reward:-1.6892198729912096 steps:1965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 432: episode_reward:-1.9232286986358222 steps:1967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 433: episode_reward:-2.4333692592613803 steps:1969[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44229
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 434: episode_reward:-3.81395153077999 steps:1971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 435: episode_reward:-3.437936513669513 steps:1972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 436: episode_reward:-2.5555408369006263 steps:1974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 437: episode_reward:-3.090910120751127 steps:1976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 438: episode_reward:-3.609220653010368 steps:1978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.47788
[RDDPG] Episode Done
[92m [RDDPG] 439: episode_reward:-2.2769006375365946 steps:1980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 440: episode_reward:-3.241505519685174 steps:1982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 441: episode_reward:-2.4805411816390173 steps:1983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 442: episode_reward:-3.9573743173066473 steps:1985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 443: episode_reward:-3.89260741820327 steps:1987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 444: episode_reward:-2.702280035513656 steps:1989[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12376
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 445: episode_reward:11.648120460293145 steps:1991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 446: episode_reward:2.7308394870680175 steps:1993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 447: episode_reward:0.967797185669558 steps:1995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 448: episode_reward:-0.46775805316191876 steps:1997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 449: episode_reward:-0.21616052859697366 steps:1999[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14269
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 450: episode_reward:243.21824228706149 steps:2001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 451: episode_reward:12.33299764350929 steps:2003[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 452: episode_reward:-4.7382169775416205 steps:2004[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 453: episode_reward:1.624430292486947 steps:2006[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 454: episode_reward:-4.325819348150219 steps:2007[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 455: episode_reward:-2.3383433841733208 steps:2009[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.96991
[RDDPG] Episode Done
[92m [RDDPG] 456: episode_reward:-2.794265124513661 steps:2010[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 457: episode_reward:-0.8546386926344778 steps:2012[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 458: episode_reward:-4.095524283426182 steps:2014[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 459: episode_reward:5.141475802999378 steps:2016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 460: episode_reward:-2.6345996740481152 steps:2018[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.84345
[RDDPG] Episode Done
[92m [RDDPG] 461: episode_reward:-3.76162215631941 steps:2020[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 462: episode_reward:1.986096156281656 steps:2022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 463: episode_reward:0.7307520120990478 steps:2024[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 464: episode_reward:-0.634783965957836 steps:2026[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 465: episode_reward:-3.3274925574093595 steps:2028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34974
[RDDPG] Episode Done
[92m [RDDPG] 466: episode_reward:-2.6969766674342237 steps:2030[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 467: episode_reward:-3.6951563832259873 steps:2032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 468: episode_reward:-2.812703824266749 steps:2034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 469: episode_reward:15.96561421768294 steps:2036[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 470: episode_reward:-0.47100235186005746 steps:2038[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.82642
[RDDPG] Episode Done
[92m [RDDPG] 471: episode_reward:-3.9701333383971265 steps:2040[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 472: episode_reward:-3.2344047261450006 steps:2042[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 473: episode_reward:0.3959398276825965 steps:2044[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 474: episode_reward:1.2033237249674036 steps:2046[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 475: episode_reward:1.8084223633576677 steps:2048[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.67866
[RDDPG] Episode Done
[92m [RDDPG] 476: episode_reward:3.4415359241866237 steps:2050[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 477: episode_reward:-2.535481438825504 steps:2052[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 478: episode_reward:16.50968723020239 steps:2054[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 479: episode_reward:-3.1602930198160726 steps:2056[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 480: episode_reward:-0.28129594574086125 steps:2058[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.42515
[RDDPG] Episode Done
[92m [RDDPG] 481: episode_reward:-1.8218626845220212 steps:2060[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 482: episode_reward:-0.43800219979256916 steps:2062[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 483: episode_reward:-0.7385811012763115 steps:2064[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 484: episode_reward:-0.8385879543484476 steps:2066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 485: episode_reward:-2.203898934594805 steps:2068[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.90266
[RDDPG] Episode Done
[92m [RDDPG] 486: episode_reward:-3.0773751721860108 steps:2070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 487: episode_reward:-3.986029443365095 steps:2071[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 488: episode_reward:-2.3031989843760377 steps:2072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 489: episode_reward:-4.405820068367386 steps:2073[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 490: episode_reward:-0.25128483832219684 steps:2075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 491: episode_reward:-2.8295218437228735 steps:2077[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 492: episode_reward:-0.993531323860616 steps:2079[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.11687
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 493: episode_reward:-1.3072057722946748 steps:2081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 494: episode_reward:-1.7670048884229783 steps:2083[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 495: episode_reward:-1.9481789800319649 steps:2085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 496: episode_reward:-1.8417732582302886 steps:2087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 497: episode_reward:-4.0801626384426415 steps:2089[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.95541
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 498: episode_reward:500.3573044571903 steps:2091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 499: episode_reward:-3.6741951643604223 steps:2093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 500: episode_reward:-2.770581806634918 steps:2094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 501: episode_reward:-4.327780312494575 steps:2095[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 502: episode_reward:3.0511554672558803 steps:2097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 503: episode_reward:-5.135601054672765 steps:2098[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.20806
[RDDPG] Episode Done
[92m [RDDPG] 504: episode_reward:-3.898298980920227 steps:2100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 505: episode_reward:-5.272925292960812 steps:2101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 506: episode_reward:-1.5891125099229764 steps:2103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 507: episode_reward:-2.124397721965118 steps:2105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 508: episode_reward:-4.220270312494826 steps:2106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 509: episode_reward:-2.461223114078 steps:2108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23265
[RDDPG] Episode Done
[92m [RDDPG] 510: episode_reward:-1.6618867345044734 steps:2110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 511: episode_reward:-4.058388372201037 steps:2112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 512: episode_reward:18.14061726765215 steps:2114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 513: episode_reward:-0.6682030066774183 steps:2116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 514: episode_reward:0.027179766016436346 steps:2118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31096
[RDDPG] Episode Done
[92m [RDDPG] 515: episode_reward:-3.2161487873614787 steps:2120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 516: episode_reward:-0.6947843673636005 steps:2122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 517: episode_reward:-0.7605905008888336 steps:2124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 518: episode_reward:-4.075114431133403 steps:2126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 519: episode_reward:-1.9691197804171026 steps:2128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.28138
[RDDPG] Episode Done
[92m [RDDPG] 520: episode_reward:-0.9771130308691673 steps:2130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 521: episode_reward:0.2356260121495728 steps:2132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 522: episode_reward:-3.3646869217054984 steps:2134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 523: episode_reward:-1.8295548061391316 steps:2136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 524: episode_reward:-4.292220136720388 steps:2137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 525: episode_reward:-3.0937565563919245 steps:2139[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64451
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 526: episode_reward:-2.2414086331712437 steps:2141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 527: episode_reward:-1.1481497190368506 steps:2143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 528: episode_reward:-1.0012136267227887 steps:2145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 529: episode_reward:-1.6072255315259165 steps:2147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 530: episode_reward:-1.0116398142507566 steps:2149[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46251
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 531: episode_reward:-2.144663880372614 steps:2151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 532: episode_reward:-2.4062587316038364 steps:2153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 533: episode_reward:-1.5032201736216104 steps:2155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 534: episode_reward:3.5896360253173527 steps:2157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 535: episode_reward:-4.045219667970212 steps:2158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 536: episode_reward:-4.974077329097906 steps:2159[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58654
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 537: episode_reward:3.91659581270458 steps:2161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 538: episode_reward:-3.232491968997154 steps:2162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 539: episode_reward:-4.256934035007767 steps:2164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 540: episode_reward:4.278589976163534 steps:2166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 541: episode_reward:-0.8015669249988946 steps:2168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13283
[RDDPG] Episode Done
[92m [RDDPG] 542: episode_reward:-2.2317818424081617 steps:2170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 543: episode_reward:-2.1377453815467424 steps:2172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 544: episode_reward:-3.3025403906219646 steps:2173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 545: episode_reward:20.026259993140577 steps:2175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 546: episode_reward:-2.4151025789731797 steps:2177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 547: episode_reward:-1.0917241440790126 steps:2179[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.90429
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 548: episode_reward:0.546683452554031 steps:2181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 549: episode_reward:-2.2224669086812945 steps:2183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 550: episode_reward:-3.3377543684335134 steps:2185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 551: episode_reward:-3.475293620423395 steps:2187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 552: episode_reward:-0.6980885434221489 steps:2189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.37085
[RDDPG] Episode Done
[92m [RDDPG] 553: episode_reward:-3.722461972657481 steps:2190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 554: episode_reward:2.015453009736147 steps:2192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 555: episode_reward:-0.9151824715021368 steps:2194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 556: episode_reward:-0.030163698238744985 steps:2196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 557: episode_reward:-2.2614255461884603 steps:2198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.98966
[RDDPG] Episode Done
[92m [RDDPG] 558: episode_reward:-0.36030364894713074 steps:2200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 559: episode_reward:0.12114170044548711 steps:2202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 560: episode_reward:3.0370097274717693 steps:2204[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 561: episode_reward:-5.009337185046785 steps:2206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 562: episode_reward:55.50858686932334 steps:2208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32591
[RDDPG] Episode Done
[92m [RDDPG] 563: episode_reward:-1.2997714998826808 steps:2210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 564: episode_reward:-4.4060024669700635 steps:2212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 565: episode_reward:-4.422708275276341 steps:2214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 566: episode_reward:-2.5931078973248463 steps:2216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 567: episode_reward:1.1691803360863826 steps:2218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48988
[RDDPG] Episode Done
[92m [RDDPG] 568: episode_reward:1.1060101009223415 steps:2220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 569: episode_reward:-2.486574335897457 steps:2222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 570: episode_reward:-0.7914620385695335 steps:2224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 571: episode_reward:-3.8148873444446796 steps:2226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 572: episode_reward:-4.910386435547191 steps:2227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 573: episode_reward:0.13105530004739663 steps:2229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71947
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 574: episode_reward:-5.3518464838638655 steps:2231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 575: episode_reward:-5.199907109380174 steps:2232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 576: episode_reward:-1.2051877396800095 steps:2234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 577: episode_reward:-2.8587799985437794 steps:2236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 578: episode_reward:-3.2143682260538355 steps:2238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13986
[RDDPG] Episode Done
[92m [RDDPG] 579: episode_reward:-4.485701862680331 steps:2240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 580: episode_reward:-1.2632813795288933 steps:2242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 581: episode_reward:-1.2454592015966381 steps:2244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 582: episode_reward:-1.7025650517450333 steps:2246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 583: episode_reward:-2.0968870403738933 steps:2248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34325
[RDDPG] Episode Done
[92m [RDDPG] 584: episode_reward:0.6473472786000896 steps:2250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 585: episode_reward:-3.6750824877970647 steps:2251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 586: episode_reward:-4.131649609361876 steps:2252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 587: episode_reward:-1.2129027590571222 steps:2254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 588: episode_reward:-1.6672727085235244 steps:2256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 589: episode_reward:-3.6216696966353674 steps:2258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 590: episode_reward:-3.691342023931413 steps:2259[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72013
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 591: episode_reward:-4.559984026618458 steps:2261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 592: episode_reward:-1.9647706824625044 steps:2263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 593: episode_reward:-1.3749631902901946 steps:2265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 594: episode_reward:-1.8688825526221713 steps:2267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 595: episode_reward:-1.261397959349475 steps:2269[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.10603
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 596: episode_reward:-1.962499410193127 steps:2271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 597: episode_reward:0.3212359855739697 steps:2273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 598: episode_reward:-4.423714540021329 steps:2275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 599: episode_reward:-2.755545973359668 steps:2277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 600: episode_reward:-1.46837022601674 steps:2279[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31343
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 601: episode_reward:-0.28074548304800784 steps:2281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 602: episode_reward:-4.520119873042734 steps:2282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 603: episode_reward:-1.3514664096467113 steps:2284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 604: episode_reward:-4.061630934656522 steps:2286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 605: episode_reward:-4.3865332910235715 steps:2287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 606: episode_reward:-2.0332636114353067 steps:2289[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64091
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 607: episode_reward:-3.7653179490019055 steps:2291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 608: episode_reward:-1.99393749768753 steps:2293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 609: episode_reward:-2.641227945930765 steps:2295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 610: episode_reward:-4.762539013661973 steps:2296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 611: episode_reward:-2.1213741150902523 steps:2298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.61430
[RDDPG] Episode Done
[92m [RDDPG] 612: episode_reward:-0.29289263847428426 steps:2300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 613: episode_reward:3.3250798126403134 steps:2302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 614: episode_reward:-4.21356198729106 steps:2303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 615: episode_reward:88.71832796555134 steps:2305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 616: episode_reward:-3.5657196080956086 steps:2307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 617: episode_reward:5.423336368329533 steps:2309[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27483
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 618: episode_reward:-1.6570884365830232 steps:2311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 619: episode_reward:5.978734055038529 steps:2313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 620: episode_reward:-3.7268725117653685 steps:2315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 621: episode_reward:-4.079970378421332 steps:2316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 622: episode_reward:-0.5290198712396315 steps:2318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29950
[RDDPG] Episode Done
[92m [RDDPG] 623: episode_reward:-2.7521749928499126 steps:2320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 624: episode_reward:-4.383417046885755 steps:2322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 625: episode_reward:1.418970735451797 steps:2324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 626: episode_reward:-3.690223943684031 steps:2326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 627: episode_reward:-3.7499869476740644 steps:2328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54984
[RDDPG] Episode Done
[92m [RDDPG] 628: episode_reward:-0.7998519050971291 steps:2330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 629: episode_reward:-3.3042776145950175 steps:2332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 630: episode_reward:-1.152329006260711 steps:2334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 631: episode_reward:-0.8452779480752304 steps:2336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 632: episode_reward:-3.1713411097146675 steps:2338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.43470
[RDDPG] Episode Done
[92m [RDDPG] 633: episode_reward:1.7033006865549165 steps:2340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 634: episode_reward:2.970626079499137 steps:2342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 635: episode_reward:-3.1702004147363843 steps:2344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 636: episode_reward:-3.451342037509491 steps:2346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 637: episode_reward:-4.516151582030934 steps:2347[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 638: episode_reward:-4.2702428715069125 steps:2349[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.51607
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 639: episode_reward:-3.1713600511080497 steps:2351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 640: episode_reward:-4.146643133653162 steps:2353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 641: episode_reward:-2.506688065521797 steps:2355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 642: episode_reward:-0.7521592837141897 steps:2357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 643: episode_reward:1.063672361306386 steps:2359[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52931
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 644: episode_reward:-3.318943676109652 steps:2361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 645: episode_reward:-0.7989519716198099 steps:2363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 646: episode_reward:-0.4623531014984885 steps:2365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 647: episode_reward:-4.9393885498071555 steps:2366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 648: episode_reward:-4.001131697148054 steps:2368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73252
[RDDPG] Episode Done
[92m [RDDPG] 649: episode_reward:-1.8878248013654335 steps:2370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 650: episode_reward:-4.696366777328647 steps:2371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 651: episode_reward:-1.0952597411741833 steps:2373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 652: episode_reward:-1.9998578362297736 steps:2375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 653: episode_reward:-5.602827500001035 steps:2376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 654: episode_reward:-1.6130624932471374 steps:2378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09223
[RDDPG] Episode Done
[92m [RDDPG] 655: episode_reward:1.7077775051603181 steps:2380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 656: episode_reward:1.7405393323525589 steps:2382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 657: episode_reward:-3.115925468623228 steps:2384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 658: episode_reward:-1.4633372452543303 steps:2386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 659: episode_reward:2.5918382811652836 steps:2388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09514
[RDDPG] Episode Done
[92m [RDDPG] 660: episode_reward:-4.335930830371112 steps:2390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 661: episode_reward:-3.278114924321872 steps:2391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 662: episode_reward:-4.233549633182225 steps:2393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 663: episode_reward:-3.8481837207171 steps:2394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 664: episode_reward:-6.377721625971487 steps:2395[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 665: episode_reward:-3.9314812013942557 steps:2397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 666: episode_reward:-3.3088009680582466 steps:2399[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.74034
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 667: episode_reward:-3.5707702319303642 steps:2401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 668: episode_reward:-3.510307246410113 steps:2403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 669: episode_reward:-2.817489719238238 steps:2405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 670: episode_reward:-4.738409612285084 steps:2407[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 671: episode_reward:-3.8128918457097205 steps:2408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71581
[RDDPG] Episode Done
[92m [RDDPG] 672: episode_reward:-2.757413637541446 steps:2410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 673: episode_reward:-0.7824021195461497 steps:2412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 674: episode_reward:-3.8603677246011054 steps:2414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 675: episode_reward:-0.9990114400653931 steps:2416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 676: episode_reward:-0.9722514240068407 steps:2418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66066
[RDDPG] Episode Done
[92m [RDDPG] 677: episode_reward:-3.8250759996104233 steps:2420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 678: episode_reward:-2.9724032165514167 steps:2421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 679: episode_reward:-2.5699847363406954 steps:2423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 680: episode_reward:-3.729527535534876 steps:2425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 681: episode_reward:-1.9240994611564193 steps:2427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 682: episode_reward:1.6559557111628385 steps:2429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.88982
[RDDPG] Episode Done
[92m [RDDPG] 683: episode_reward:-3.7784000683564534 steps:2430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 684: episode_reward:-3.849058944040985 steps:2432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 685: episode_reward:-2.573641141528282 steps:2434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 686: episode_reward:-0.7304050556691504 steps:2436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 687: episode_reward:-2.500727199275935 steps:2438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29007
[RDDPG] Episode Done
[92m [RDDPG] 688: episode_reward:-2.868606539830407 steps:2440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 689: episode_reward:-3.6544407304093074 steps:2442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 690: episode_reward:-4.23171353474867 steps:2444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 691: episode_reward:-1.2501747061352266 steps:2446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 692: episode_reward:-1.4843608033305244 steps:2448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 693: episode_reward:-3.895708654786748 steps:2449[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.41990
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 694: episode_reward:15.279505907062415 steps:2451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 695: episode_reward:-0.39326545407379654 steps:2453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 696: episode_reward:16.811173301203112 steps:2455[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 697: episode_reward:-4.653578738904841 steps:2457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 698: episode_reward:-4.210581782226285 steps:2458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39756
[RDDPG] Episode Done
[92m [RDDPG] 699: episode_reward:-3.8702320432232664 steps:2460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 700: episode_reward:-3.1913882641691647 steps:2461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 701: episode_reward:12.521539195645337 steps:2463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 702: episode_reward:-1.640630982993765 steps:2465[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 703: episode_reward:-4.607302836792357 steps:2467[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 704: episode_reward:-3.194996356202175 steps:2468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64579
[RDDPG] Episode Done
[92m [RDDPG] 705: episode_reward:-1.3497651124978018 steps:2470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 706: episode_reward:0.24753300781435073 steps:2472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 707: episode_reward:-0.9114483476225157 steps:2474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 708: episode_reward:4.492697517865279 steps:2476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 709: episode_reward:-0.5965858627786442 steps:2478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05307
[RDDPG] Episode Done
[92m [RDDPG] 710: episode_reward:4.306489274655398 steps:2480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 711: episode_reward:-1.8931090718878876 steps:2482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 712: episode_reward:-2.861878776855085 steps:2483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 713: episode_reward:-3.0690565765209454 steps:2485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 714: episode_reward:6.3057656647116875 steps:2487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 715: episode_reward:-2.2800875663571567 steps:2489[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56259
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 716: episode_reward:-0.638923789643719 steps:2491[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 717: episode_reward:4.051997211593033 steps:2493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 718: episode_reward:-3.4141969848667393 steps:2494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 719: episode_reward:-0.16419529698147528 steps:2496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 720: episode_reward:-0.342351637176201 steps:2498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 721: episode_reward:-3.784514790043426 steps:2499[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57445
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 722: episode_reward:0.3485306621642037 steps:2501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 723: episode_reward:-3.3507191699253713 steps:2502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 724: episode_reward:1.2460567386435808 steps:2504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 725: episode_reward:-2.719585220320697 steps:2506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 726: episode_reward:-3.9757084155114253 steps:2508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59530
[RDDPG] Episode Done
[92m [RDDPG] 727: episode_reward:-3.5596572069469508 steps:2510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 728: episode_reward:-4.154173824262838 steps:2512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 729: episode_reward:-0.37202264972500165 steps:2514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 730: episode_reward:-2.706394851276886 steps:2516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 731: episode_reward:-3.9216188825755394 steps:2518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.65154
[RDDPG] Episode Done
[92m [RDDPG] 732: episode_reward:-3.706434753767787 steps:2520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 733: episode_reward:0.017927718975911944 steps:2522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 734: episode_reward:-0.8323473605160756 steps:2524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 735: episode_reward:-1.312191491952173 steps:2526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 736: episode_reward:15.264666401505718 steps:2528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.04174
[RDDPG] Episode Done
[92m [RDDPG] 737: episode_reward:-0.0504452603225074 steps:2530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 738: episode_reward:0.7547980209342375 steps:2532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 739: episode_reward:-2.9637872891202623 steps:2534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 740: episode_reward:-1.3356388115725084 steps:2536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 741: episode_reward:-3.9639134399355607 steps:2537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 742: episode_reward:-3.2408443295020217 steps:2539[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59035
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 743: episode_reward:-2.284778962605612 steps:2541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 744: episode_reward:-2.0008115769028674 steps:2542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 745: episode_reward:-3.6716102539074447 steps:2543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 746: episode_reward:0.5430413956331681 steps:2545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 747: episode_reward:0.8894889713693148 steps:2547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 748: episode_reward:-1.195568867469382 steps:2549[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.29505
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 749: episode_reward:-0.28639931642857874 steps:2551[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 750: episode_reward:-4.349018115236348 steps:2552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 751: episode_reward:1.9373471564888507 steps:2554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 752: episode_reward:-4.691654921056767 steps:2556[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 753: episode_reward:-3.431596427010429 steps:2558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.22148
[RDDPG] Episode Done
[92m [RDDPG] 754: episode_reward:-1.97407917782741 steps:2560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 755: episode_reward:0.14057642812619964 steps:2562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 756: episode_reward:-3.6038130904236976 steps:2564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 757: episode_reward:-2.1644663309728536 steps:2566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 758: episode_reward:-3.8143965894060745 steps:2568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 759: episode_reward:-4.36910483398222 steps:2569[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07397
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 760: episode_reward:-0.3791086067750338 steps:2571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 761: episode_reward:-4.619149633778173 steps:2572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 762: episode_reward:-1.5731848855215977 steps:2574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 763: episode_reward:-2.0068303133392305 steps:2575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 764: episode_reward:2.4525704581028838 steps:2577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 765: episode_reward:10.332211111982398 steps:2579[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.90524
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 766: episode_reward:2.416252755229227 steps:2581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 767: episode_reward:23.158749024441985 steps:2583[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 768: episode_reward:0.10884704694198799 steps:2585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 769: episode_reward:-3.3579554187659695 steps:2587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 770: episode_reward:1.5165285142456364 steps:2589[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24618
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 771: episode_reward:0.27136966019811926 steps:2591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 772: episode_reward:-1.1278856764401 steps:2593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 773: episode_reward:-1.1856931383893938 steps:2595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 774: episode_reward:-2.524451889036525 steps:2596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 775: episode_reward:-1.092229784240114 steps:2598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81393
[RDDPG] Episode Done
[92m [RDDPG] 776: episode_reward:184.57273915930688 steps:2600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 777: episode_reward:-2.686193631588359 steps:2601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 778: episode_reward:23.265714879604037 steps:2603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 779: episode_reward:-1.949805467303141 steps:2605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 780: episode_reward:0.7004571432424349 steps:2607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 781: episode_reward:7.372724343816696 steps:2609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78944
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 782: episode_reward:-2.2980424344957475 steps:2611[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 783: episode_reward:-0.7703824224884115 steps:2613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 784: episode_reward:-5.029994003895389 steps:2614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 785: episode_reward:48.44376907835984 steps:2616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 786: episode_reward:-3.9074335017317026 steps:2618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 787: episode_reward:-4.093548271483161 steps:2619[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48963
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 788: episode_reward:-0.8629801026409123 steps:2621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 789: episode_reward:-0.01217567114297502 steps:2623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 790: episode_reward:3.88443273942001 steps:2625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 791: episode_reward:-0.28126621490899373 steps:2627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 792: episode_reward:-0.1282705974066709 steps:2629[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31633
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 793: episode_reward:-0.09508339800219767 steps:2631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 794: episode_reward:-4.071114613935112 steps:2633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 795: episode_reward:-4.676614109032508 steps:2635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 796: episode_reward:-3.621144174277278 steps:2637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 797: episode_reward:-4.381571884756809 steps:2638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72828
[RDDPG] Episode Done
[92m [RDDPG] 798: episode_reward:-0.5018586711509065 steps:2640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 799: episode_reward:-2.9666171837120374 steps:2642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 800: episode_reward:-0.9297928066121646 steps:2644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 801: episode_reward:-2.911152064003569 steps:2646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 802: episode_reward:-0.20917217918885234 steps:2648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 803: episode_reward:-4.383327529288053 steps:2649[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68557
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 804: episode_reward:-0.40693688207628176 steps:2651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 805: episode_reward:-0.6569852648436909 steps:2653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 806: episode_reward:-2.4885861226259567 steps:2655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 807: episode_reward:-1.0440407357390047 steps:2657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 808: episode_reward:-4.428722246093445 steps:2658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.98564
[RDDPG] Episode Done
[92m [RDDPG] 809: episode_reward:-4.330055633861935 steps:2660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 810: episode_reward:44.63317398324888 steps:2662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 811: episode_reward:-6.174384693132216 steps:2664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 812: episode_reward:0.8607975208156198 steps:2666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 813: episode_reward:-0.9983006955701137 steps:2668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.91498
[RDDPG] Episode Done
[92m [RDDPG] 814: episode_reward:-2.3154826326532985 steps:2670[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 815: episode_reward:0.21773417344480972 steps:2672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 816: episode_reward:-2.5509431214550276 steps:2674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 817: episode_reward:-2.849920811709489 steps:2676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 818: episode_reward:-0.04620275450723765 steps:2678[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.06713
[RDDPG] Episode Done
[92m [RDDPG] 819: episode_reward:12.368534191111426 steps:2680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 820: episode_reward:-3.0741458273916193 steps:2682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 821: episode_reward:-2.272253539215078 steps:2684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 822: episode_reward:-0.6907687035739791 steps:2686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 823: episode_reward:-3.8780942578057678 steps:2687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 824: episode_reward:377.3493900436698 steps:2689[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80185
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 825: episode_reward:18.597716995967797 steps:2691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 826: episode_reward:-3.1629565656933845 steps:2693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 827: episode_reward:-3.018361971318721 steps:2695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 828: episode_reward:-2.8182670027508157 steps:2697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 829: episode_reward:-0.5672298341333875 steps:2699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12213
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 830: episode_reward:-2.9499609705953604 steps:2701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 831: episode_reward:-4.6711041992163205 steps:2702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 832: episode_reward:-3.213597384394823 steps:2704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 833: episode_reward:2.0911801562991164 steps:2706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 834: episode_reward:3.2305444735117894 steps:2708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46604
[RDDPG] Episode Done
[92m [RDDPG] 835: episode_reward:-3.7073000344918263 steps:2710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 836: episode_reward:1.1526047495427512 steps:2712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 837: episode_reward:-2.1855935873583 steps:2714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 838: episode_reward:-1.4334627955242167 steps:2716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 839: episode_reward:-4.807758437493456 steps:2717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 840: episode_reward:-1.2095180264146852 steps:2719[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62447
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 841: episode_reward:-0.845959086778616 steps:2721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 842: episode_reward:-0.37474683664349895 steps:2723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 843: episode_reward:-3.7866761091715357 steps:2725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 844: episode_reward:-3.587934770575814 steps:2727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 845: episode_reward:-2.8218226954417265 steps:2729[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88207
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 846: episode_reward:0.018728982199388344 steps:2731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 847: episode_reward:-1.7954080299662487 steps:2733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 848: episode_reward:-3.8283252807562764 steps:2734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 849: episode_reward:-2.354621191259505 steps:2736[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 850: episode_reward:1007.8854668869229 steps:2738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09899
[RDDPG] Episode Done
[92m [RDDPG] 851: episode_reward:-1.5670292747038643 steps:2740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 852: episode_reward:7.027684194767069 steps:2742[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 853: episode_reward:2.3803260487076616 steps:2744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 854: episode_reward:-3.593825698345708 steps:2746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 855: episode_reward:-3.321713017679239 steps:2748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07239
[RDDPG] Episode Done
[92m [RDDPG] 856: episode_reward:-2.0557881067926536 steps:2750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 857: episode_reward:-0.36799107674219056 steps:2752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 858: episode_reward:-2.205465872151683 steps:2754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 859: episode_reward:-4.564274609392102 steps:2755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 860: episode_reward:-3.0758094618652008 steps:2757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 861: episode_reward:2.679866975273505 steps:2759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.89288
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 862: episode_reward:-0.7085894003574096 steps:2761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 863: episode_reward:-3.9399434274633984 steps:2763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 864: episode_reward:-4.5407065918030876 steps:2764[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 865: episode_reward:-3.8982312627575944 steps:2766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 866: episode_reward:-3.1882725561488066 steps:2767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 867: episode_reward:-3.7738279948269606 steps:2769[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07550
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 868: episode_reward:-2.9366308239662904 steps:2771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 869: episode_reward:-4.02008026173357 steps:2773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 870: episode_reward:0.37218476820561186 steps:2775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 871: episode_reward:0.9587175498806184 steps:2777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 872: episode_reward:-2.9722963767631883 steps:2779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.28363
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 873: episode_reward:-4.110864773703667 steps:2781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 874: episode_reward:-3.8828924234408464 steps:2783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 875: episode_reward:-0.8542976646312037 steps:2785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 876: episode_reward:-1.8119548636411165 steps:2787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 877: episode_reward:-1.5301346953617778 steps:2789[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.88757
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 878: episode_reward:-0.1618772319494708 steps:2791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 879: episode_reward:153.2480266770531 steps:2793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 880: episode_reward:-3.784863901364255 steps:2794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 881: episode_reward:83.30539531559707 steps:2796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 882: episode_reward:-3.420265484128544 steps:2798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07459
[RDDPG] Episode Done
[92m [RDDPG] 883: episode_reward:0.9872148616145808 steps:2800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 884: episode_reward:-2.784240067693182 steps:2802[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 885: episode_reward:-1.367355787458638 steps:2804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 886: episode_reward:106.82106750166663 steps:2806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 887: episode_reward:20.546983200849546 steps:2808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.63358
[RDDPG] Episode Done
[92m [RDDPG] 888: episode_reward:73.3567651921705 steps:2810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 889: episode_reward:1.0211492189395361 steps:2812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 890: episode_reward:-2.392476370923064 steps:2814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 891: episode_reward:-0.7217355859494279 steps:2816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 892: episode_reward:0.05026324603736976 steps:2818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14126
[RDDPG] Episode Done
[92m [RDDPG] 893: episode_reward:-2.9419726806991497 steps:2820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 894: episode_reward:17.27196281850271 steps:2822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 895: episode_reward:-4.085516084898211 steps:2824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 896: episode_reward:0.0007398649221310727 steps:2826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 897: episode_reward:8.637647702550295 steps:2828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.92494
[RDDPG] Episode Done
[92m [RDDPG] 898: episode_reward:1.1400891554993207 steps:2830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 899: episode_reward:1.0282044531009809 steps:2832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 900: episode_reward:2.4605699157404173 steps:2834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 901: episode_reward:0.555123851262544 steps:2836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 902: episode_reward:1.5472710301224617 steps:2838[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49739
[RDDPG] Episode Done
[92m [RDDPG] 903: episode_reward:-2.06848801851998 steps:2840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 904: episode_reward:-3.5802358198384736 steps:2842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 905: episode_reward:0.7283129461916671 steps:2844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 906: episode_reward:-3.880854872054826 steps:2846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 907: episode_reward:-3.578605242546474 steps:2848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 908: episode_reward:-4.801005336914367 steps:2849[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12124
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 909: episode_reward:-4.142282270752406 steps:2851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 910: episode_reward:-4.059809564678575 steps:2853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 911: episode_reward:-3.6281258963421203 steps:2855[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 912: episode_reward:-3.3270204687521456 steps:2856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 913: episode_reward:-3.9995850488359506 steps:2857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 914: episode_reward:-0.331637829927903 steps:2859[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.63603
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 915: episode_reward:-2.8247599361173257 steps:2861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 916: episode_reward:-2.1545790345564453 steps:2863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 917: episode_reward:-0.23750899590531116 steps:2865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 918: episode_reward:-0.7169210192879545 steps:2867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 919: episode_reward:-1.0268961455456895 steps:2869[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08117
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 920: episode_reward:-3.6726725832105744 steps:2871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 921: episode_reward:-3.911763454592935 steps:2872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 922: episode_reward:-0.5445729805450095 steps:2874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 923: episode_reward:-4.58440042969552 steps:2875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 924: episode_reward:0.5337035923029347 steps:2877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 925: episode_reward:-3.224915843639955 steps:2879[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.99605
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 926: episode_reward:-1.6839479726285382 steps:2881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 927: episode_reward:9.306145857370101 steps:2883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 928: episode_reward:-4.196275626495401 steps:2885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 929: episode_reward:-3.6759973424777685 steps:2887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 930: episode_reward:-2.942060453973714 steps:2889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50505
[RDDPG] Episode Done
[92m [RDDPG] 931: episode_reward:-3.563938749995345 steps:2890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 932: episode_reward:0.33723253887980587 steps:2892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 933: episode_reward:-3.470650334466218 steps:2893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 934: episode_reward:-1.359490961828517 steps:2895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 935: episode_reward:-1.3669772514482208 steps:2897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 936: episode_reward:-0.38950508996240596 steps:2899[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.88617
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 937: episode_reward:-2.7882319054724913 steps:2901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 938: episode_reward:-2.646867574303938 steps:2903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 939: episode_reward:-4.352705022180671 steps:2905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 940: episode_reward:-2.3918057569859372 steps:2907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 941: episode_reward:-3.018644452755719 steps:2909[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59382
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 942: episode_reward:-2.8758238828017264 steps:2911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 943: episode_reward:-1.567801198885394 steps:2913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 944: episode_reward:-1.526740275679902 steps:2915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 945: episode_reward:-0.295419924022287 steps:2917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 946: episode_reward:-1.6100535153241342 steps:2919[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.61316
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 947: episode_reward:-1.0436947934809564 steps:2921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 948: episode_reward:-1.5426693299875402 steps:2923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 949: episode_reward:0.04204709095177028 steps:2925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 950: episode_reward:6.659407343088975 steps:2927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 951: episode_reward:-0.0043724664782773814 steps:2929[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40453
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 952: episode_reward:-1.6941186023924701 steps:2931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 953: episode_reward:27.885354350682636 steps:2933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 954: episode_reward:-3.3257590625021436 steps:2934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 955: episode_reward:-4.513207084956808 steps:2935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 956: episode_reward:-1.12110558351547 steps:2937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 957: episode_reward:-0.3188355084959671 steps:2939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.17567
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 958: episode_reward:-0.9991039532612669 steps:2941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 959: episode_reward:8.492763365803166 steps:2943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 960: episode_reward:5.371977856820764 steps:2945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 961: episode_reward:-4.003189018547272 steps:2946[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 962: episode_reward:25.863625498035905 steps:2948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68745
[RDDPG] Episode Done
[92m [RDDPG] 963: episode_reward:16.56354870607226 steps:2950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 964: episode_reward:-2.2606996609237013 steps:2952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 965: episode_reward:-0.7408126113998712 steps:2954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 966: episode_reward:-1.7927530717881022 steps:2956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 967: episode_reward:-3.773963874514587 steps:2957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 968: episode_reward:-4.19920270507407 steps:2958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.28985
[RDDPG] Episode Done
[92m [RDDPG] 969: episode_reward:-1.5033994072497296 steps:2960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 970: episode_reward:-0.9612325648780429 steps:2962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 971: episode_reward:-5.9010492187464525 steps:2963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 972: episode_reward:-0.6128404477566358 steps:2965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 973: episode_reward:-3.9238206786990935 steps:2966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 974: episode_reward:-0.9972954073566827 steps:2968[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.74033
[RDDPG] Episode Done
[92m [RDDPG] 975: episode_reward:-0.4830085125502366 steps:2970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 976: episode_reward:1.7347374251951506 steps:2972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 977: episode_reward:-3.2798797820632837 steps:2974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 978: episode_reward:-1.0714395441265931 steps:2976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 979: episode_reward:-4.35419118420268 steps:2978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31945
[RDDPG] Episode Done
[92m [RDDPG] 980: episode_reward:-4.076367165029367 steps:2980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 981: episode_reward:-3.2938212006200884 steps:2982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 982: episode_reward:-1.094176835003276 steps:2984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 983: episode_reward:-3.8935584643546255 steps:2985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 984: episode_reward:-1.0807339174214088 steps:2987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 985: episode_reward:-0.9713960517387927 steps:2989[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.16363
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 986: episode_reward:-4.447217825662969 steps:2991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 987: episode_reward:-2.597251312922318 steps:2993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 988: episode_reward:-2.9967913187264763 steps:2995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 989: episode_reward:-4.0039327191194465 steps:2997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 990: episode_reward:5.904719263498403 steps:2999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08592
[RDDPG] Episode Done
[92m [RDDPG] 991: episode_reward:-5.140714472665995 steps:3000[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0003000: mean_reward:-2.6728542007296463[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 234, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 277, in save
    self.plot(checkpoint_path, 'policy_loss_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 238, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 31, in plot_fit_curve_polymonial_5
    ax.scatter(x, y)
  File "/usr/lib/python3/dist-packages/matplotlib/__init__.py", line 1601, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/usr/lib/python3/dist-packages/matplotlib/axes/_axes.py", line 4441, in scatter
    y = np.ma.ravel(y)
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 6638, in __call__
    marr = asanyarray(a)
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 7873, in asanyarray
    return masked_array(a, dtype=dtype, copy=False, keep_mask=True, subok=True)
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 2822, in __new__
    mask = np.array([getmaskarray(m) for m in data],
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 2822, in <listcomp>
    mask = np.array([getmaskarray(m) for m in data],
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 1468, in getmaskarray
    mask = make_mask_none(np.shape(arr), getattr(arr, 'dtype', None))
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 1685, in make_mask_none
    result = np.zeros(newshape, dtype=make_mask_descr(dtype))
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 1354, in make_mask_descr
    return _replace_dtype_fields(ndtype, MaskType)
  File "/usr/lib/python3/dist-packages/numpy/ma/core.py", line 1319, in _replace_dtype_fields
    dtype = np.dtype(dtype)
TypeError: data type not understood
2021-05-04 22:08:12.151467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:12992): Gdk-CRITICAL **: 22:08:14.311: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620166097.077465446, 1.807000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620166097.078684764, 1.808000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620166097.078741535, 1.808000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620166098.303145596, 3.026000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620166099.016821811, 3.735000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620166099.817994345, 4.535000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620166100.618987325, 5.334000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:18361692.74709004[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.4702220120391596 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:11.572480330520612 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:22.723386141814032 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:8.7440394720409 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:34.1473155543398 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:355.20792878824034 steps:59[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:28.342837686442298 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:29.96010667266612 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:0.9942450623696915 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-1.2002479131480548 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:19.515659536801554 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-1.3557982004412923 steps:82[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.0360928868754686 steps:84[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-0.5835728124341881 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:5.3955812824054465 steps:106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:12.01394855765232 steps:123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:11.99197486805867 steps:132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:17.392838357975272 steps:151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-2.4089292994112803 steps:153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.853424583627155 steps:155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:3.9788350387918068 steps:165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:12.23314914356164 steps:176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:4.388506491902784 steps:189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-1.3686170604849117 steps:191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:3.1108210302744213 steps:196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:2.029548745935571 steps:201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:5.063669624293939 steps:207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:0.06989414607163003 steps:209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:1.3376253438134937 steps:211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:18.70098010470255 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:30.173044897195666 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:16.038169641615134 steps:239[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:0.2585693667783935 steps:241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-0.566764395992359 steps:243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:0.010547488819546036 steps:245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:11.536135482699475 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-2.514092507502364 steps:275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:3.948348504438354 steps:278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:30.72271086138007 steps:294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:1.4142876506761834 steps:308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:1.1713815988713834 steps:315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:8.230925662754052 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:8.033943382765209 steps:328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:37.78413095574139 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:10.560351344285827 steps:351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:7.5778042102233485 steps:359[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.623347099847099 steps:361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:4.7769697374450715 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-1.1291624086116419 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-0.8536823379510352 steps:374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-1.63265642915747 steps:376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-0.8803256271240685 steps:378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:4.495917023844912 steps:395[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-2.9313292663072366 steps:400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-1.5442974865132049 steps:402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:21.113250514284456 steps:422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-2.778914792466682 steps:424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-1.6886976243749543 steps:426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:18.55359446715691 steps:450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-0.2514790286147175 steps:452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:69.79139871122158 steps:474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:0.8573230408956918 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:1.2058845593567158 steps:483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:-0.500964468333577 steps:485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:160.55591967760887 steps:502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:28.499360383917814 steps:535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:311.6504164585629 steps:573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-0.07748313694545006 steps:577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:0.22841579325926809 steps:581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-1.7098269914926556 steps:583[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:22.154015696128248 steps:590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:1.0025536731366045 steps:594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-2.2364823659450304 steps:596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:7.210802470631563 steps:598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:9.979742714496563 steps:614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:7.3977432339610125 steps:630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-1.820181807216771 steps:632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:34.88058563112949 steps:642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:2.4784817246586766 steps:649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:20.173365170605155 steps:662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:15.04846594215997 steps:688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:24.912238484384563 steps:693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:10.775953970143963 steps:708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:6.296405719075796 steps:719[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:46.09031693079529 steps:726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-2.3080458625808795 steps:728[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-2.352778952122676 steps:730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-2.494774378066256 steps:732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-2.505419737325415 steps:735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:103.97689827264071 steps:768[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:16.821792359782513 steps:779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:65.8257392214055 steps:811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:2.915847232800034 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-1.2370203448116528 steps:831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:14.483349304264 steps:843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:4.956581325514797 steps:848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:22.960676016697494 steps:860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:325.8390177529787 steps:880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:7.239061168673931 steps:884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:182.89645588947712 steps:890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.2620865230394833 steps:892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-1.5228017211203544 steps:894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-1.451371560822849 steps:896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:1.8642121806599845 steps:898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:31.49880063038478 steps:912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-1.0498241429667656 steps:914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:74.50341175529834 steps:970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:41.15359472256052 steps:994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-0.7041732465198081 steps:996[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:5.90342600422187 steps:1002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:1.8875308990938824 steps:1004[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 184, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 467, in update_policy
    self.policy_loss.append(policy_loss_total.numpy())
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
2021-05-04 22:20:08.177255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:18819): Gdk-CRITICAL **: 22:20:10.312: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620166813.757779094, 2.354000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620166813.758697070, 2.355000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620166813.758765137, 2.355000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620166815.048775783, 3.629000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620166815.822828682, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620166816.623062609, 5.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620166817.424323778, 6.000000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:5161930.599419062[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.0266000677130873 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:6.372926810960081 steps:12[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:13.61760824325299 steps:33[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:303.7085679702701 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:12.407901448183468 steps:57[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:0.32518237930205585 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:4.559133667863785 steps:65[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.249925753590067 steps:67[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:41.12072219490192 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-1.5885044079319584 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:6.244358744179131 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-2.926492404823025 steps:118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-2.0886942945735556 steps:120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:26.677755827019787 steps:138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-2.2413051473213037 steps:140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:12.37869194636259 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:151.2550649951212 steps:642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:21.194682051441326 steps:662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:16.500807022262126 steps:669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-1.5420608716925868 steps:672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:42.10666688199319 steps:681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:0.5937486544851747 steps:684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:9.657948826110328 steps:698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-2.9374015590514317 steps:701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:2.566861513689944 steps:703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:2.6391858218442366 steps:705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:8.61320856615945 steps:712[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 184, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 467, in update_policy
    self.policy_loss.append(policy_loss_total.cpu().numpy())
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
2021-05-04 22:29:07.374460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:23729): Gdk-CRITICAL **: 22:29:09.504: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620167352.379941092, 1.779000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620167352.380688970, 1.779000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620167352.380741953, 1.779000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620167353.689098293, 3.065000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620167354.426602798, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620167355.227270328, 4.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620167356.030678494, 5.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:4270356.764493469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.615458590603758 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.6651461530300717 steps:4[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:2.6180257885871163 steps:13[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:44.12452303711582 steps:47[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-2.3700661275153694 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:66.24476322079731 steps:80[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:8.372513960402113 steps:100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-2.544364864699321 steps:102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1.5010628190532258 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:0.757961801042685 steps:106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:13.490796692670713 steps:133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-0.11919542689827889 steps:135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:3.4117008779600164 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.1428867481374345 steps:147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:12.205945253917848 steps:170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-2.9702483799271224 steps:172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-1.9584259033781644 steps:174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:17.44978800076591 steps:182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:0.5945978825520744 steps:184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:61.10607054609552 steps:195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:5.4369100640451915 steps:203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:38.23595657009261 steps:215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:105.35852353230182 steps:253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:3.826611367708291 steps:259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:74.96699575510027 steps:278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-2.113653263843009 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:9.042290523633678 steps:312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:4.606948794893917 steps:318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:3.9486544388728855 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-2.3307632891198056 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:10.256848014690751 steps:337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-2.6188348024427937 steps:339[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-1.7101460255747027 steps:341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-0.8122989236261486 steps:343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:59.16058505362847 steps:368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:43.60713995930202 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:0.010833107373865225 steps:372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:8.849093722999278 steps:382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:5.072450064691086 steps:400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-2.0499571437461945 steps:402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-1.1030773211894342 steps:404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:8.58789882800803 steps:413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:6.477708366695496 steps:427[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-4.120140107421723 steps:429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:10.27427622773839 steps:438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:4.818087974044605 steps:440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:5.9054045066237135 steps:447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:6.358631702120995 steps:457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:0.974332179632321 steps:462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:12.60433258303497 steps:478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:17.84702643534619 steps:489[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-1.22482476093377 steps:491[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-0.1482997727002493 steps:493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:144.5083101919282 steps:511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:9.784350352057071 steps:523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-2.55059278207247 steps:525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:16.360269615569045 steps:538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-2.688396120107042 steps:540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-2.1666668408896026 steps:542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:0.5365907521830389 steps:549[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-0.4601915222011079 steps:558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-1.6687495771097138 steps:560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-1.6377633815980461 steps:562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:4.141825382038342 steps:580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:3.5150325467538392 steps:587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:2.306615263319699 steps:592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-0.7192899647893425 steps:594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:109.35863669250516 steps:612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:34.997635501645505 steps:623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:19.23329263424332 steps:629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:6.464601221452175 steps:636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:3.900385852973504 steps:649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:3.5161592536249993 steps:656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:320.78191412137454 steps:672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:12.701878371506746 steps:680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:1.7533930867845529 steps:682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:37.62747940986406 steps:692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:11.444479298644824 steps:716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-2.77998758186824 steps:718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:3.330142408845111 steps:724[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:0.4636634389929175 steps:727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-1.8493957454865608 steps:730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:1.8524465784060027 steps:738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:4.482594007238767 steps:746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-0.8775908580540825 steps:749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:13.662185158876236 steps:769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:18.125302153352045 steps:774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:2.9880417661986645 steps:779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:174.8286494528582 steps:806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-1.8731785564129129 steps:808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-1.2192561525608352 steps:810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:0.46061020127993 steps:812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:260.47523049210616 steps:828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:23.79885514800163 steps:847[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:28: RuntimeWarning: invalid value encountered in true_divide
  dl = np.abs(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-4.818977364943076 steps:858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:3.7496213532818827 steps:863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:43.48328294165757 steps:880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:14.628323007487646 steps:894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-0.7223429714500134 steps:896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:34.352365805896255 steps:907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-0.1014166561627281 steps:921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:8.912301455666228 steps:936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:1.907727672153742 steps:940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:5.531350727746874 steps:959[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:9.053475329058514 steps:970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:69.8568165437445 steps:984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-2.6600652038726658 steps:986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:2.8656683531460354 steps:997[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 8.37430
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53855
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:15.149597661494699 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:3.4630312056976456 steps:1026[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.62998
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.56187
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:8.813792835059743 steps:1049[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.87609
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.68892
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29762
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:43.7033105077238 steps:1072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-2.4433180997027555 steps:1074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-0.8171355582240565 steps:1078[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.21065
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-2.7998502183201133 steps:1080[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:10.911074156865418 steps:1087[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.98021
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:1.5839321318270976 steps:1094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:4.8434977449026615 steps:1099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.74610
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:5.212354553392971 steps:1102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-1.508929916328731 steps:1104[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.27664
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:9.167179717925595 steps:1112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-2.4995938329231326 steps:1114[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.87589
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:9.425142396075517 steps:1121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-0.9833723131494769 steps:1123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-1.0897638227750712 steps:1125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-0.4651771859697349 steps:1127[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.68000
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:11.240946736406745 steps:1139[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40874
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:2.785383386804047 steps:1145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-0.7753630864136167 steps:1147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.04994
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:0.5984365328578969 steps:1150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-2.3519001692858508 steps:1152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-0.49013661444806855 steps:1155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-0.7996220571936705 steps:1157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-0.5174017748737902 steps:1159[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.23902
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:11.538153124170911 steps:1161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-2.428644744671769 steps:1163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-0.4981084897744781 steps:1165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-1.8253343025170978 steps:1167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-0.7084079231526565 steps:1169[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.01449
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:1.2971663475269306 steps:1172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-2.271757770896265 steps:1174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-1.9905889796239802 steps:1176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-0.7406342260652932 steps:1178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.61681
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-1.2927742818215626 steps:1180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-0.05442927618888138 steps:1183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-2.4704794655042925 steps:1185[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49157
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:50.37112739766073 steps:1197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-1.0275998604341379 steps:1199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08646
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-1.3464468888520573 steps:1201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:-1.083480626616687 steps:1203[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.54253
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:9.304289965322893 steps:1214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-1.839894983788233 steps:1216[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.82791
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:21.140581303641166 steps:1229[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.22360
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:-2.4644644143817 steps:1232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:1.4596853751384948 steps:1235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:11.874022468098431 steps:1238[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53726
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:1.1269542114122322 steps:1241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:3.98310407475359 steps:1249[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85139
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:4.9281445653967495 steps:1254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-0.8161595433113267 steps:1256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-1.364336120437335 steps:1258[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.95081
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:0.5095022545861099 steps:1263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-2.3481611716859616 steps:1266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-1.5748327009059744 steps:1268[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.74410
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:1.052051083640292 steps:1273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-1.7413392496715048 steps:1275[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93795
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01615
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72321
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.18011
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:50.347441565315506 steps:1311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:2.4385849277339644 steps:1316[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97862
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:1.47317128031216 steps:1321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:18.759520548167956 steps:1326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-0.1899615439747846 steps:1329[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.88982
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-0.777681585844908 steps:1332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-1.9380091441192446 steps:1335[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:0.8456057220719306 steps:1339[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.36044
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-3.083784100382886 steps:1341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-2.5336881888609977 steps:1343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:0.5835715470410454 steps:1346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-1.9988828454506882 steps:1349[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.94809
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-1.2509191770055086 steps:1351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-3.2196876754922625 steps:1353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:0.9108850976711205 steps:1358[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93188
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:-0.13776016228208832 steps:1362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-1.412962744179182 steps:1364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-2.6376799291046567 steps:1366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-1.7135920544922811 steps:1368[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80594
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:10.792465529755017 steps:1372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-1.064616170231004 steps:1377[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40183
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:4.691123508728008 steps:1382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-0.5614072137717074 steps:1388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44178
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-0.9603645968375729 steps:1390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:8.388104159588929 steps:1392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-1.0317206449753837 steps:1394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:0.9542346131563333 steps:1397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:-1.5335854927400905 steps:1399[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.19369
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:-1.5235111972921604 steps:1401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-0.12036155381467717 steps:1404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:-1.8592437332137326 steps:1406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:1.7010924467755153 steps:1408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.04983
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:2.067054672084935 steps:1410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:7.940182568057288 steps:1414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:14.337951773259011 steps:1418[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.24112
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:15.672457808210392 steps:1424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-1.8901566192557184 steps:1426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:-1.9511185551540413 steps:1428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:-3.3293915771482707 steps:1429[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.86649
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:-0.6558502164791691 steps:1432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:5.115151469218263 steps:1434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:-2.688858759764658 steps:1435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:0.6012557146402391 steps:1438[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.49499
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:1.7408115239532291 steps:1446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:-2.054760663252735 steps:1448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.22038
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:-1.3962918192606155 steps:1450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-0.7094095835981269 steps:1453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:-2.6924046775984394 steps:1455[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:-1.146771626410386 steps:1457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-2.069146251136055 steps:1459[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06170
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-0.5858984069864288 steps:1462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:0.8154010114925758 steps:1468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56083
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-2.5520534412042646 steps:1470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:-1.4003856072310872 steps:1472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:-0.5539214053478698 steps:1474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:0.05527395356814013 steps:1477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:-2.635404982148139 steps:1479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56015
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:1.066581516947049 steps:1481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:-1.9750457607882568 steps:1483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:6.505453317309643 steps:1486[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29804
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:0.26260105215216134 steps:1491[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:-1.3574820179566915 steps:1493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-1.4539000279301897 steps:1496[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05435
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:-0.6138209076083938 steps:1501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:-1.480733050669465 steps:1503[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:243.96217830013472 steps:1505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:63.74559919429644 steps:1509[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.92972
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:2.9558575690947277 steps:1511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-1.9547479335452662 steps:1514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-1.7933978824804302 steps:1516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-1.5588285779424123 steps:1518[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.97891
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:4.920089070034735 steps:1521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:0.6043080255044146 steps:1523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:6.204081637101014 steps:1526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-2.773062255858672 steps:1527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:-0.5507116168620518 steps:1529[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.19764
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:12.68549348687994 steps:1532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:-1.0279044484525828 steps:1534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:-2.4023172656238025 steps:1535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:2.335609168380728 steps:1538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29517
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:11.125694114656499 steps:1540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:3.0669221899326247 steps:1543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-1.0005275543516208 steps:1545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-2.706281445312527 steps:1546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:13.303676989227057 steps:1548[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.95367
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:9.30246519898296 steps:1552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-0.5862450742792014 steps:1554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:-0.9128745120905837 steps:1557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:-1.1212547977254494 steps:1559[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46996
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-0.7100117396514762 steps:1561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-0.07614601951562783 steps:1563[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-1.4168293346879766 steps:1565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:0.3500534884298312 steps:1567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:-0.5379049338648088 steps:1569[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64215
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:1.035359240895902 steps:1571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:5.066284052951298 steps:1575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:1.7647805633050289 steps:1578[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27129
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:11.942036234285576 steps:1581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:-0.8751489805733144 steps:1584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:-1.5989719995040812 steps:1587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:0.37459848698527765 steps:1589[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44167
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:9.878079480889221 steps:1596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-3.6735534765595146 steps:1597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:-3.3075704931638983 steps:1598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54056
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:-2.3886305613589904 steps:1600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:-0.7114351645566761 steps:1602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:0.3930656376045629 steps:1605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:-0.774771541133447 steps:1607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:-1.46438237170522 steps:1609[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14971
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:2.135712308264939 steps:1612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:-1.2056900122632435 steps:1615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:-0.20692447764590138 steps:1617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:4.361409492602663 steps:1619[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.51478
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-0.8267058232260578 steps:1621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:0.6397282804816746 steps:1624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:6.8661263920198365 steps:1627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:-2.136274003281439 steps:1629[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.91133
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-1.2170130632664158 steps:1631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:-2.1743042489691247 steps:1633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:-2.0930940933963815 steps:1635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:-4.092638620600873 steps:1636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-3.2516551649172243 steps:1638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.06811
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:-2.1682341055832035 steps:1640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-1.113397109026167 steps:1642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:-1.011916148220747 steps:1644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:24.57942106107804 steps:1646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:-0.6948933219263593 steps:1648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53437
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:-2.1108799564438225 steps:1650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:-0.3251759272056476 steps:1653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:-0.5625902050401608 steps:1655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:-1.742750511149044 steps:1657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:-2.7119945943540853 steps:1659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.12166
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 298: episode_reward:-1.457206406510945 steps:1661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 299: episode_reward:-3.9291253316090824 steps:1663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 300: episode_reward:-2.8607460008866155 steps:1665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 301: episode_reward:-1.0703138569388162 steps:1667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 302: episode_reward:-1.6792233327169293 steps:1669[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73786
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 303: episode_reward:20.33481879188787 steps:1672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 304: episode_reward:-1.682210399274655 steps:1674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 305: episode_reward:-0.6521965147750011 steps:1676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 306: episode_reward:13.897535690797875 steps:1678[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93619
[RDDPG] Episode Done
[92m [RDDPG] 307: episode_reward:-0.5899746817458453 steps:1680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 308: episode_reward:31.77088613090173 steps:1682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 309: episode_reward:1177.6591977613841 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 310: episode_reward:-2.924515425792988 steps:1686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 311: episode_reward:-1.9255461996301826 steps:1688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.06137
[RDDPG] Episode Done
[92m [RDDPG] 312: episode_reward:-0.41342555193332764 steps:1690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 313: episode_reward:-0.8079913232990501 steps:1692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 314: episode_reward:-0.9310380489670509 steps:1694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 315: episode_reward:-1.4390644035163895 steps:1696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 316: episode_reward:-3.732068984375066 steps:1697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 317: episode_reward:-4.537122724608045 steps:1698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14761
[RDDPG] Episode Done
[92m [RDDPG] 318: episode_reward:-1.9777700098797233 steps:1700[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 319: episode_reward:7.833357155693391 steps:1702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 320: episode_reward:1.5506719999918843 steps:1704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 321: episode_reward:-2.6910075976567436 steps:1705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 322: episode_reward:-0.47332836649100374 steps:1707[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 323: episode_reward:-1.6519883830499318 steps:1709[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.75283
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 324: episode_reward:-2.176774540475781 steps:1711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 325: episode_reward:21.638649436724616 steps:1713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 326: episode_reward:-3.241468520229406 steps:1715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 327: episode_reward:-1.4767989184174763 steps:1717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 328: episode_reward:-1.7774597069127867 steps:1719[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.06983
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 329: episode_reward:3.023510687673108 steps:1721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 330: episode_reward:-0.021072829038077057 steps:1723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 331: episode_reward:-0.2377527273702995 steps:1725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 332: episode_reward:3.044034864262581 steps:1727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 333: episode_reward:2.5609066597403136 steps:1729[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.43343
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 334: episode_reward:-0.7047905784897526 steps:1731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 335: episode_reward:-0.2473812648935616 steps:1733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 336: episode_reward:22.77504829923659 steps:1735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 337: episode_reward:-0.8133821266464212 steps:1737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 338: episode_reward:48.559283981031555 steps:1739[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.58626
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 339: episode_reward:-1.6687865751657687 steps:1741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 340: episode_reward:0.9611344793936238 steps:1743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 341: episode_reward:-3.7510327030085335 steps:1745[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 342: episode_reward:-1.1220486740005235 steps:1747[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 343: episode_reward:0.7547432869030071 steps:1749[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.44068
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 344: episode_reward:-0.5495602168135414 steps:1751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 345: episode_reward:0.16337051529171287 steps:1753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 346: episode_reward:-1.8545045424240927 steps:1755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 347: episode_reward:0.459229882776357 steps:1757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 348: episode_reward:-2.972548611616621 steps:1759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.46870
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 349: episode_reward:-2.8209934756173425 steps:1761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 350: episode_reward:-3.213059504570317 steps:1763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 351: episode_reward:-3.5712258759185804 steps:1765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 352: episode_reward:-1.6693508654009257 steps:1767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 353: episode_reward:-0.6317844612683359 steps:1769[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.22346
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 354: episode_reward:0.6627867765097877 steps:1771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 355: episode_reward:-1.1132469699409888 steps:1773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 356: episode_reward:-3.3114431250016025 steps:1774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 357: episode_reward:-1.023650851194541 steps:1776[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 358: episode_reward:7.533474420892883 steps:1778[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.01135
[RDDPG] Episode Done
[92m [RDDPG] 359: episode_reward:23.020590228422485 steps:1780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 360: episode_reward:4.308460963575614 steps:1782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 361: episode_reward:11.373553046906725 steps:1784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 362: episode_reward:-1.6371021789592521 steps:1786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 363: episode_reward:-3.3364376413745465 steps:1788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.62948
[RDDPG] Episode Done
[92m [RDDPG] 364: episode_reward:-1.9502554188649657 steps:1790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 365: episode_reward:-2.05817214650414 steps:1792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 366: episode_reward:-0.6785528682262589 steps:1794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 367: episode_reward:-1.7190501912980467 steps:1796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 368: episode_reward:-2.198126783352791 steps:1798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.26737
[RDDPG] Episode Done
[92m [RDDPG] 369: episode_reward:-1.3058314296841156 steps:1800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 370: episode_reward:-2.423258596990244 steps:1802[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 371: episode_reward:0.6035073130739557 steps:1804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 372: episode_reward:-1.297957542514078 steps:1806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 373: episode_reward:-2.098523608177067 steps:1808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.34191
[RDDPG] Episode Done
[92m [RDDPG] 374: episode_reward:2.143175456586516 steps:1810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 375: episode_reward:2.2214248237551484 steps:1812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 376: episode_reward:-2.1366730556150677 steps:1814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 377: episode_reward:12.231772684660466 steps:1816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 378: episode_reward:15.006180608433066 steps:1818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.03601
[RDDPG] Episode Done
[92m [RDDPG] 379: episode_reward:0.9784450908848505 steps:1820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 380: episode_reward:-0.9274245974738591 steps:1822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 381: episode_reward:-2.720238971974436 steps:1824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 382: episode_reward:-2.9191909919831462 steps:1826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 383: episode_reward:-1.8091552928556802 steps:1828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.92643
[RDDPG] Episode Done
[92m [RDDPG] 384: episode_reward:1.3514254777929153 steps:1830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 385: episode_reward:14.034657710315974 steps:1832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 386: episode_reward:-0.7429369929568512 steps:1834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 387: episode_reward:-1.4405375476696527 steps:1836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 388: episode_reward:-1.9396248434509438 steps:1838[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.05282
[RDDPG] Episode Done
[92m [RDDPG] 389: episode_reward:-2.3744326572177914 steps:1840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 390: episode_reward:-3.2190365596838713 steps:1842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 391: episode_reward:-0.09137843932207668 steps:1844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 392: episode_reward:-0.8262820500022523 steps:1846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 393: episode_reward:0.9060437878722221 steps:1848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.70855
[RDDPG] Episode Done
[92m [RDDPG] 394: episode_reward:17.860547052921486 steps:1850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 395: episode_reward:-1.7269759265933775 steps:1852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 396: episode_reward:-1.210572216738863 steps:1854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 397: episode_reward:-2.5518153705863598 steps:1856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 398: episode_reward:3.916949175400669 steps:1858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.42242
[RDDPG] Episode Done
[92m [RDDPG] 399: episode_reward:-0.7695035504320722 steps:1860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 400: episode_reward:-0.3596535077015943 steps:1862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 401: episode_reward:40.70209905867541 steps:1864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 402: episode_reward:12.152557023501936 steps:1866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 403: episode_reward:-0.9135756959389938 steps:1868[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.73548
[RDDPG] Episode Done
[92m [RDDPG] 404: episode_reward:2.3902547936596714 steps:1870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 405: episode_reward:-3.5933957421875604 steps:1871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 406: episode_reward:-2.606954002033713 steps:1873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 407: episode_reward:3.904942649402096 steps:1875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 408: episode_reward:-1.265676256166906 steps:1877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 409: episode_reward:-2.059124649259007 steps:1879[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.04113
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 410: episode_reward:-1.2942124819149066 steps:1881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 411: episode_reward:4.433065738828674 steps:1883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 412: episode_reward:40.04258574619969 steps:1885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 413: episode_reward:1.7128360409404157 steps:1887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 414: episode_reward:3.2884723829898537 steps:1889[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.61857
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 415: episode_reward:-0.39043676418421236 steps:1891[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 416: episode_reward:4.901922239763806 steps:1893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 417: episode_reward:-1.2669565321692586 steps:1895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 418: episode_reward:2.265705984499583 steps:1897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 419: episode_reward:0.8193211936453237 steps:1899[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.03710
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 420: episode_reward:-3.5093738546988735 steps:1901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 421: episode_reward:-3.2035391746757718 steps:1903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 422: episode_reward:-2.6534716633210897 steps:1905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 423: episode_reward:54.10914613507813 steps:1907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 424: episode_reward:-1.6399791407500908 steps:1909[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.88054
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 425: episode_reward:-2.1439278674948863 steps:1911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 426: episode_reward:7.809466719306903 steps:1913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 427: episode_reward:-3.186802296370879 steps:1915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 428: episode_reward:-1.718798294911886 steps:1917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 429: episode_reward:-3.665741940892624 steps:1919[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.58525
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 430: episode_reward:-2.8361468220472283 steps:1921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 431: episode_reward:11.986380648105404 steps:1923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 432: episode_reward:13.93971402988194 steps:1925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 433: episode_reward:-1.226330852562628 steps:1927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 434: episode_reward:-1.2521104838441686 steps:1929[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.03567
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 435: episode_reward:-0.2637434129721876 steps:1931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 436: episode_reward:1.0394167871093414 steps:1933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 437: episode_reward:-3.3011179834010713 steps:1934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 438: episode_reward:-2.987192203000493 steps:1936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 439: episode_reward:-2.1283284417563033 steps:1938[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.94599
[RDDPG] Episode Done
[92m [RDDPG] 440: episode_reward:-2.672038297935579 steps:1940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 441: episode_reward:1.7167728428012952 steps:1942[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 442: episode_reward:-2.522935233284197 steps:1944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 443: episode_reward:-0.11618979871885093 steps:1946[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 444: episode_reward:-2.1685941222820104 steps:1948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.78493
[RDDPG] Episode Done
[92m [RDDPG] 445: episode_reward:-4.795650176927409 steps:1950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 446: episode_reward:1.0548034849302903 steps:1952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 447: episode_reward:-1.2096838273398494 steps:1954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 448: episode_reward:-0.9296478116299736 steps:1956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 449: episode_reward:2.1060209491865014 steps:1958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.19558
[RDDPG] Episode Done
[92m [RDDPG] 450: episode_reward:-1.045431840665718 steps:1960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 451: episode_reward:-0.6544911023377962 steps:1962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 452: episode_reward:-0.6683248010777707 steps:1964[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 453: episode_reward:-0.48871444113919305 steps:1966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 454: episode_reward:-1.7860702548952843 steps:1968[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.85807
[RDDPG] Episode Done
[92m [RDDPG] 455: episode_reward:0.8036488128289263 steps:1970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 456: episode_reward:2.9331949924806304 steps:1973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 457: episode_reward:-2.074833473070213 steps:1975[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 458: episode_reward:-2.32350588893695 steps:1977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 459: episode_reward:7.230094487483764 steps:1979[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 5.85296
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 460: episode_reward:-0.017950428253532547 steps:1981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 461: episode_reward:-1.2949605008331733 steps:1983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 462: episode_reward:13.36698943658722 steps:1985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 463: episode_reward:-6.2368001831057525 steps:1986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 464: episode_reward:1.6904294257915407 steps:1988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.02405
[RDDPG] Episode Done
[92m [RDDPG] 465: episode_reward:-3.3278466313745705 steps:1990[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 466: episode_reward:-1.3863632670802424 steps:1992[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 467: episode_reward:15.91587674600168 steps:1994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 468: episode_reward:2.7478311625236187 steps:1996[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 469: episode_reward:115.58605751992518 steps:1998[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.22914
[RDDPG] Episode Done
[92m [RDDPG] 470: episode_reward:-3.5927982412639925 steps:2000[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0002000: mean_reward:2.0849091281697767[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 234, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 297, in save
    self.plot(checkpoint_path, 'd1_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 238, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 25, in plot_fit_curve_polymonial_5
    popt, _ = curve_fit(objective_polynomial_5, x, y)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 734, in curve_fit
    ydata = np.asarray_chkfinite(ydata, float)
  File "/usr/lib/python3/dist-packages/numpy/lib/function_base.py", line 495, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs
2021-05-04 23:03:56.544340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:5114): Gdk-CRITICAL **: 23:03:58.675: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620169442.274788810, 2.566000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620169442.275684224, 2.566000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620169442.275746873, 2.566000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620169443.477797869, 3.759000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620169444.121031548, 4.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620169444.926016856, 5.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620169445.727934710, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:9384311.453684267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.7171700697516648 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.17543259423978 steps:5[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.6875609663474922 steps:7[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:78.48464264263636 steps:17[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:0.5996227031817405 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:63.987605261095425 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:2.343727613443967 steps:50[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:2.5829677304347376 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:9.340048150068993 steps:55[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:5.4789247156994945 steps:64[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:7.548498407637572 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:3.445803051362245 steps:75[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:78.2529283844818 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:14.119240267866385 steps:111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-0.5413320542032407 steps:113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-0.9696534568849791 steps:115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-2.139039605962934 steps:117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:1.0464752597222087 steps:126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:51.679694333137114 steps:135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:2.3433953792797495 steps:142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:0.27781094185093735 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:101.76797933057617 steps:167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:7.900248949475776 steps:183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:399.88992263129103 steps:255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:5.420532321432977 steps:267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-1.7647695724131516 steps:273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:16.765054030551212 steps:283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-0.8697919079450511 steps:287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:10.221806265148448 steps:295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:8.249362392099126 steps:300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:400.4863940319672 steps:321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-0.27637764792113195 steps:323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-0.5774650268325368 steps:325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-0.17219820412014641 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-1.9593458716768375 steps:329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:16.796215957663478 steps:338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:51.188002239867494 steps:344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:13.036466573595446 steps:368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-0.3871211155678336 steps:370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:77.14840803719937 steps:392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:9.151782333511951 steps:399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:7.65445496738949 steps:406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:9.64492135235064 steps:413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-0.8481430721115844 steps:415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-1.3360092251011424 steps:417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:3.93545736353028 steps:431[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:16.06862381461776 steps:440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:30.856237626740594 steps:447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:21.111329378724022 steps:458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-1.6451723079354137 steps:460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-1.5904110454889913 steps:463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:35.379510898103035 steps:480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:34.49480616889741 steps:499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:42.78620887872998 steps:528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:14.978162594864756 steps:543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-2.509631666361373 steps:545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-1.3230504516408677 steps:547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:9.940037224601829 steps:555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-0.5577162668789901 steps:557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-0.45983217227311535 steps:559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:4.569374107417849 steps:574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:116.1472029164224 steps:588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:158.52048907155358 steps:627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:1.51782366567403 steps:631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-1.2368288619478411 steps:633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-1.2149917098347913 steps:635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:17.09347989272713 steps:652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:0.47683843500692635 steps:655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-0.09551341588822915 steps:660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:5.398260455898475 steps:666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:3.392118145115232 steps:678[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:16.151650428438575 steps:693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-1.1047310214904837 steps:699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:1.0598124259007338 steps:702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-0.6182968931445556 steps:704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:4.104641484645068 steps:709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:29.16845832722344 steps:727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:1.6351959992918719 steps:730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:41.80164571046239 steps:746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:-2.782658991538773 steps:748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-0.07730058460600198 steps:750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:1.1597748172893696 steps:752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:234.13659947311953 steps:757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:20.21957476303772 steps:772[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:18.065815404518023 steps:789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:8.143492691674021 steps:794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:0.7506801650964459 steps:796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:47.64063470010065 steps:816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:145.81284286694512 steps:862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:4.400425616437961 steps:869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:0.27036261718207477 steps:871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:16.252089688609615 steps:894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-0.03508110267735276 steps:896[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 9.48423
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.69886
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.90774
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50003
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.13843
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.93308
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64122
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.68918
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.91546
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.82858
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.31848
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.25540
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.34129
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.80561
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.12229
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.29419
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.88873
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.24729
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.43668
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.38364
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.74914
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.28518
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.64089
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.84217
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.66042
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.86659
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.10796
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.58261
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.44840
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.66395
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.92218
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.22628
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.97097
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.62754
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.73936
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.69641
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.55511
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.81619
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.53763
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:826.4090970525348 steps:1396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.14768
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:4.345272066105513 steps:1400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-1.5662507356882438 steps:1402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-2.3069966443077936 steps:1404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-1.7012510227777584 steps:1407[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.00377
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-0.7032341410471903 steps:1410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:0.3431048900623592 steps:1413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.3069490049269141 steps:1415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-0.3100928697879164 steps:1418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62629
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-1.2021489174061704 steps:1420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-1.6949330595123906 steps:1423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:73.39484090608991 steps:1429[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.04240
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40910
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:76.6244363002314 steps:1443[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-2.2701140691954995 steps:1445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:3.5264243921825056 steps:1448[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72084
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:10.160896433774035 steps:1453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97683
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:0.30164306738846136 steps:1460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-4.169393445904085 steps:1466[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20184
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-3.2615700523187527 steps:1471[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-1.9846395376292163 steps:1474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-2.1030142889941934 steps:1477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-2.8346080812915107 steps:1479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.50308
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-1.872813166038859 steps:1482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-0.17524324182367845 steps:1485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:5.441611653604709 steps:1489[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.57961
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:4.7546864243800595 steps:1492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:5.524405827746607 steps:1496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-0.915686557705248 steps:1498[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[W python_anomaly_mode.cpp:104] Warning: Error detected in DivBackward0. Traceback of forward call that caused the error:
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 186, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 437, in update_policy
    action, (robot_enc_state, z) = self.agent.actor(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 289, in forward
    action, robot_enc_state, z = self.cell(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 263, in forward
    self.pretrain_cell(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 203, in forward
    actions, Z, _, _ = self.rhythm_gen(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 189, in forward
    out = self.complex_mlp(z)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/app/layers/torch_l.py", line 66, in forward
    return complex_tanh(input)
  File "/app/layers/torch_l.py", line 38, in complex_tanh
    y = torch.sinh(2*y) / denominator
 (function _print_stack)
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 186, in train
    self.update_policy()
  File "/app/rl/torch/rdpg.py", line 463, in update_policy
    policy_loss_total.backward()
  File "/usr/local/lib/python3.8/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Function 'DivBackward0' returned nan values in its 1th output.
2021-05-04 23:31:51.500424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:13052): Gdk-CRITICAL **: 23:31:53.600: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620171116.491684079, 1.791000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620171116.492665589, 1.792000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620171116.492755196, 1.793000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620171117.786668435, 3.056000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620171118.537301646, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620171119.339282838, 4.601000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620171120.141625392, 5.401000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2504633.8583047492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:2.4575151590153257 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:1.9056716223519885 steps:9[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.7930148870228084 steps:11[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:27.734041858096425 steps:26[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:77.48069495299043 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:14.394015369736877 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:581.0263615060766 steps:85[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:40.67156304010382 steps:103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:8.12715845862962 steps:108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:8.199927911707825 steps:119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-3.185585993579664 steps:121[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 142, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1021, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/app/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 524, in call
    raise ServiceException("service [%s] returned no response"%self.resolved_name)
rospy.service.ServiceException: service [/compute_fk] returned no response
2021-05-04 23:35:06.018504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:15085): Gdk-CRITICAL **: 23:35:08.035: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620171310.741684802, 1.374000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620171310.742605506, 1.375000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620171310.742841730, 1.375000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620171312.038006483, 2.656000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620171312.784225387, 3.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620171313.583990774, 4.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620171314.386512424, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1908623.0123437382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.464098940333402 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-0.4294026042151624 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:66.68988675935931 steps:43[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-2.276466725573246 steps:45[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:1.637224774967427 steps:49[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:11.85057001539976 steps:53[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:164.56166840043184 steps:553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:28.99480267650208 steps:563[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:12.00566183317519 steps:569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-0.5639882804410381 steps:571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:4.378070890429207 steps:575[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:3389.796017385925 steps:694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:16.374463811574454 steps:711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:26.816108865822013 steps:730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:2.4418009688804267 steps:737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:348.5953623409402 steps:784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:35.76027470259211 steps:793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:11.584870435975986 steps:804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-4.4396873499657605 steps:811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-2.4560597829232105 steps:815[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-2.936422056784041 steps:819[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-0.7364365308039811 steps:822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:60.26998394434036 steps:829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:4.6501391492089885 steps:839[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:-2.03095817202097 steps:841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:33.35176380643949 steps:873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:2.6425912980554216 steps:883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:2.1170771558608648 steps:892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-2.2161216411557114 steps:894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:2.986397901673798 steps:898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:7.284057384903468 steps:902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:27.8142681669899 steps:935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:18.0774481488351 steps:950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-2.4763468377154108 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:63.72696554916216 steps:960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:6.7256689413278625 steps:966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-1.9027704133954084 steps:968[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-0.45810192663878624 steps:970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-0.6072241942430439 steps:972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:122.63278943833708 steps:983[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 6.23467
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:35.199951773752844 steps:1011[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.91537
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:15.27964342579956 steps:1021[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.41716
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.74801
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:8.43290989352336 steps:1041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-0.2552254604582125 steps:1043[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-2.2444549535187646 steps:1045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-1.8857100950604155 steps:1047[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-2.025038656634945 steps:1049[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.00092
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-1.0552793482957998 steps:1051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-2.7657109213675755 steps:1053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-0.981354245684328 steps:1055[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-0.4374245649036592 steps:1057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-0.48750879682629433 steps:1059[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.73688
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.03381
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.16013
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:276.0170525949558 steps:1081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-0.27835115632694496 steps:1083[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-1.9245900041422521 steps:1085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-1.6704290249692244 steps:1087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-2.096714651399402 steps:1089[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.59407
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-0.9980508612591334 steps:1091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:0.4683480980820942 steps:1093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:10.198947589012729 steps:1097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:2.0490254368497904 steps:1099[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.14863
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:0.4095768183686843 steps:1101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:0.07884897395479573 steps:1104[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.98732
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:0.8486798103132878 steps:1115[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.05197
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-0.16403277327154897 steps:1123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:1.2500760974123435 steps:1128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.42182
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-2.037539224569852 steps:1130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-2.641369441908065 steps:1133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-3.3722105755958283 steps:1135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-2.867825229641231 steps:1137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-2.1804805683673614 steps:1139[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.98674
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:26.835254895007562 steps:1141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:0.04693753821242019 steps:1144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-0.6119949535690896 steps:1147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07520
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-2.8715208155210603 steps:1150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-0.7256014127111508 steps:1152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:1.7720992032003986 steps:1156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-1.699539821544882 steps:1158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40105
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-0.4607293474493841 steps:1160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:3.029248335771909 steps:1165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53833
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:11.32407168185718 steps:1170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-0.40403359804171224 steps:1172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-0.2510835768202484 steps:1175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-2.204213473281427 steps:1177[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.48671
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:4.300401450586467 steps:1181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-1.1737056425391041 steps:1184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-0.7584795086992582 steps:1186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:4.406496228749973 steps:1188[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.78420
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-2.5518218055185256 steps:1191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-3.244629247621062 steps:1193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-3.202509925670498 steps:1195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-1.8950282599536625 steps:1197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.01745
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-0.00038425626961657855 steps:1200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-0.9197311967109627 steps:1202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-3.973609124769697 steps:1204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:118.71136712775446 steps:1207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.70601
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-2.419058404057775 steps:1210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:62.888906918064656 steps:1213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-3.8468696826197784 steps:1214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-3.0490738754813944 steps:1216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-1.203844088643859 steps:1219[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.91665
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:-2.2354758570882076 steps:1221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-4.387000431488598 steps:1224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-2.409792273065822 steps:1226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:4.05151630683807 steps:1228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81291
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:13.174689123796174 steps:1230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-4.660471119609334 steps:1232[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.99338
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-1.655333446711613 steps:1241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-1.363132755595965 steps:1243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-3.0057983983300467 steps:1245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-3.402277002298507 steps:1247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-1.9406772045527205 steps:1249[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.20867
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-3.993138716438852 steps:1251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-3.2374065429691052 steps:1252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:0.40190364726042827 steps:1254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-3.052811054987341 steps:1256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:1.5636831670400948 steps:1258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.84304
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-2.4439817586935915 steps:1260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:159.16721390179228 steps:1262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-1.684679979012778 steps:1264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:75.33048514178874 steps:1267[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.72573
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:46.38723269770527 steps:1273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-4.27438681928427 steps:1275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-2.4446573201837296 steps:1277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-3.052277757618729 steps:1279[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.03013
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-4.644567290037362 steps:1281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-2.879479723545131 steps:1283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:-3.2419477392064846 steps:1285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-2.6900767939912877 steps:1287[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:-2.749374854797941 steps:1289[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.42932
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:-1.0234867524812556 steps:1291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-3.3559481724451974 steps:1293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:-3.4123679345290086 steps:1296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:3.685206300722315 steps:1298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.07216
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-2.8373166151535076 steps:1300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:0.20514190878865834 steps:1303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-4.021707246093497 steps:1304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:-0.11514077256892774 steps:1307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-3.852081440044447 steps:1309[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90117
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-3.868235461194841 steps:1311[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-3.5722256548784146 steps:1313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:6.928068166173694 steps:1315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-3.7859210149808527 steps:1317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-3.8857213971820808 steps:1319[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12815
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-1.7658805703330076 steps:1321[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 126, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 964, in reset
    A, B = AB
ValueError: not enough values to unpack (expected 2, got 1)
2021-05-04 23:51:58.305798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:22703): Gdk-CRITICAL **: 23:52:00.541: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620172324.527244749, 3.000000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620172324.528120345, 3.001000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620172324.528305301, 3.001000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620172325.810080075, 4.275000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620172326.537821248, 5.001000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620172327.339579003, 5.801000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620172328.142460910, 6.601000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:6065965.309341299[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-0.613442259979261 steps:2[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:8.875890859818924 steps:52[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-1.7676788732005473 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:8.477528818757861 steps:61[00m
[RDDPG] Resetting Environment
[0m[ INFO] [1620172377.147852116, 53.561000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620172377.147898066, 53.561000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620172378.149872085, 53.561000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620172378.149915730, 53.561000000]: Failed to fetch current robot state[0m
[0m[ INFO] [1620172379.790387043, 53.561000000]: Didn't received robot state (joint angles) with recent timestamp within 1 seconds.
Check clock synchronization if your are running ROS across multiple machines![0m
[31m[ERROR] [1620172379.790434038, 53.561000000]: Failed to fetch current robot state[0m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 126, in train
    state0 = deepcopy(self.env.reset())
  File "/app/rl/torch/env.py", line 16, in reset
    self._state, self._reward = self.quadruped.reset()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 958, in reset
    rospy.sleep(0.35)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/timer.py", line 165, in sleep
    raise rospy.exceptions.ROSInterruptException("ROS shutdown request")
rospy.exceptions.ROSInterruptException: ROS shutdown request
2021-05-04 23:53:06.834470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:23526): Gdk-CRITICAL **: 23:53:08.935: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620172392.401803186, 2.390000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620172392.402904784, 2.391000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620172392.402966935, 2.391000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620172393.595960363, 3.575000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620172394.628357692, 4.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620172395.430124706, 5.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620172396.231803291, 6.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:14235843.010157015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.6027918547969886 steps:3[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:3.241245679745311 steps:8[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:15.77222549070852 steps:19[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:2.7442191458909138 steps:22[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:10.497300774140022 steps:27[00m
[RDDPG] Resetting Environment
/app/reward/support_plane.py:112: RuntimeWarning: invalid value encountered in true_divide
  return temp/np.linalg.norm(temp)
/app/reward/support_plane.py:115: RuntimeWarning: invalid value encountered in true_divide
  return self.AB/np.linalg.norm(self.AB)
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:119.30393417065841 steps:112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:117.46607529901576 steps:134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:33.09254583714389 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:1.3634660318480663 steps:156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:36.43606953063398 steps:169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-0.1212860304115253 steps:171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:20.65252404711903 steps:187[00m
[RDDPG] Resetting Environment
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 560, in connect
    self.socket.connect((dest_addr, dest_port))
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 509, in call
    transport.connect(dest_addr, dest_port, service_uri)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_base.py", line 589, in connect
    raise TransportInitError(str(e)) #re-raise i/o error
rospy.exceptions.TransportInitError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 142, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 43, in step
    self.quadruped.set_support_lines()
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1025, in set_support_lines
    current_pose = self.kinematics.get_end_effector_fk(
  File "/app/simulations/ws/src/quadruped/scripts/kinematics.py", line 84, in get_end_effector_fk
    msg = self.compute_fk_proxy(
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 442, in __call__
    return self.call(*args, **kwds)
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 512, in call
    raise ServiceException("unable to connect to service: %s"%e)
rospy.service.ServiceException: unable to connect to service: [Errno 111] Connection refused
2021-05-04 23:55:52.656605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:25688): Gdk-CRITICAL **: 23:55:54.768: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620172558.327520187, 2.566000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620172558.328368194, 2.566000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620172558.328813155, 2.566000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620172559.623903334, 3.850000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620172560.375422063, 4.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620172561.176283596, 5.400000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620172561.976933988, 6.200000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1333871.294240109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-3.2243933384595205 steps:2[00m
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:26.02752520933648 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:12.843265142373898 steps:41[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:5.543706122797891 steps:51[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 3.57977
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-1.1656107968939726 steps:54[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.42311
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.45657
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:5.023117150136155 steps:63[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.51465
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-0.3812664308787266 steps:66[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.46553
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.50711
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:0.9407020926385492 steps:73[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1.3621629882014146 steps:75[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000075: mean_reward:-2.1312276675817254[00m
/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py:828: OptimizeWarning: Covariance of the parameters could not be estimated
  warnings.warn('Covariance of the parameters could not be estimated',
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 239, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 302, in save
    self.plot(checkpoint_path, 'd1_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 243, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 25, in plot_fit_curve_polymonial_5
    popt, _ = curve_fit(objective_polynomial_5, x, y)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 734, in curve_fit
    ydata = np.asarray_chkfinite(ydata, float)
  File "/usr/lib/python3/dist-packages/numpy/lib/function_base.py", line 495, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs
2021-05-05 00:00:04.929360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:26854): Gdk-CRITICAL **: 00:00:07.109: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620172809.797628894, 1.823000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620172809.798464275, 1.823000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620172809.798764778, 1.823000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620172811.064100659, 3.083000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620172811.731438783, 3.749000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620172812.532146201, 4.548000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620172813.333588972, 5.349000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:9083295.518213619[00m
[RDDPG] Resetting Environment
0.14972133449576602
0.05667977805611888
5.7813647560797214
0.05910093245237588
[RDDPG] Quadruped Not Upright
5.7813647560797214
0.05910093245237588
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-2.1868985542955204 steps:3[00m
[RDDPG] Resetting Environment
0.926223072366384
0.04330641528403301
3.4460656469569306
0.0583870923252702
3.8125268908433334
0.05777936771846471
0.634606760730995
0.03427842876710482
0.6295932377630398
0.03193285434834398
0.6399507821924463
0.03018106383792617
0.6554556686483333
0.028782042170614492
0.6931582800571747
0.026441078213784826
0.7021524852513991
0.025975467766397437
0.7258156740884367
0.024843121624182122
0.6989980849777483
0.01442223808254782
0.9192776622376301
0.021607492357539344
0.919202262455086
0.02160039869076739
0.9191131951299121
0.021592029580007423
0.9191002682241832
0.021590809596014605
[RDDPG] Quadruped Not Upright
0.9191002682241832
0.021590809596014605
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-5.4505685197537765 steps:19[00m
[RDDPG] Resetting Environment
3.62780406898476
0.05935132835727055
5.437658225621075
0.05918002298337398
3.7542065945948355
0.05529207107769898
18.82581920154039
0.05927912119849374
4.212171991727429
0.054519299722140625
3.4163174473773665
0.052775969787725925
3.4093247479224966
0.05280337085402332
3.4118175288809596
0.05279362614563903
3.4240269243347927
0.0527455948970326
3.424757735447237
0.05274271171825166
[RDDPG] Quadruped Not Upright
3.424757735447237
0.05274271171825166
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:16.99650981481162 steps:30[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000030: mean_reward:-2.993494310792689[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 241, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 273, in save
    self.plot(checkpoint_path, 'total_rewards_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 245, in plot
    plot_fit_curve_polymonial_5(
  File "/app/plot.py", line 25, in plot_fit_curve_polymonial_5
    popt, _ = curve_fit(objective_polynomial_5, x, y)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 784, in curve_fit
    res = leastsq(func, p0, Dfun=jac, full_output=1, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 414, in leastsq
    raise TypeError('Improper input: N=%s must not exceed M=%s' % (n, m))
TypeError: Improper input: N=6 must not exceed M=3
2021-05-05 00:03:27.922668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:27675): Gdk-CRITICAL **: 00:03:29.961: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620173013.365151716, 2.418000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620173013.366048570, 2.418000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620173013.366089017, 2.418000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620173014.725818096, 3.760000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620173015.486545602, 4.519000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620173016.290043566, 5.320000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620173017.092371732, 6.119000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:8507589.25148886[00m
[RDDPG] Resetting Environment
0.9150224314912565
0.05847109770182709
1.4623424119905044
0.05768583684002501
[RDDPG] Quadruped Not Upright
1.4623424119905044
0.05768583684002501
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-4.283981944333176 steps:3[00m
[RDDPG] Resetting Environment
3.6471372150596073
0.05935488764455041
2.287429136691113
0.05014996081649337
[RDDPG] Quadruped Not Upright
2.287429136691113
0.05014996081649337
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.5274503755196176 steps:6[00m
[RDDPG] Resetting Environment
2.2576641797338386
0.05867667373717926
[RDDPG] Quadruped Not Upright
2.2576641797338386
0.05867667373717926
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-3.228543890752593 steps:8[00m
[RDDPG] Resetting Environment
2.2476260943851303
0.05798761841090537
2.2714937327804066
0.059378616706831006
2.3324220884740923
0.04794132256356401
2.3902741933948892
0.03213243830390894
0.45425408800724776
0.015465957579740123
0.4566604844208483
0.013460656499654715
0.45814052531804017
0.012853261432630148
2.0293888634508335
0.03902366968945919
0.4383578557817954
0.02514068730361679
[RDDPG] Quadruped Not Upright
0.4383578557817954
0.02514068730361679
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-4.506677067379777 steps:18[00m
[RDDPG] Resetting Environment
0.3245541291231132
0.028952566928980256
1.3933614466488227
0.0585691001361774
1.4005267790817042
0.05839068496978923
1.4285376126981628
0.057277770282092764
1.4425609097503804
0.05658179434762494
3.1992200317001087
0.05620676628244738
0.5913836987121167
0.020440553499830077
0.5908362854444715
0.02038019034391861
2.460229411156557
0.05240379380310847
1.255630791406161
0.05573959367761578
2.829164121574675
0.05789266388809011
0.5786858833897578
0.03640555910301517
5.531698124723918
0.05902860899741401
5.223751921653283
0.058984327604061394
4.814475329060203
0.05891201470190528
0.20576625715619606
0.053879252241459494
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
1.4289211879531496
0.05564082892756383
[RDDPG] Last Step of episode
1.4289211879531496
0.05564082892756383
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:7.04139460684925 steps:43[00m
[RDDPG] Resetting Environment
4.888540308125393
0.05939886667595661
2.575965731724294
0.05913086587439979
1.439002136818274
0.0499822351485215
1.8617549548730974
0.029689391028122257
0.9657553500590699
0.03591537753650748
[RDDPG] Quadruped Not Upright
0.9657553500590699
0.03591537753650748
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-0.5937309176728496 steps:49[00m
[RDDPG] Resetting Environment
3.627746049062523
0.059387355821374485
3.8887403579398514
0.059300385248621
4.285720463793881
0.05895315591307935
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 3.67678
4.4334730769086095
0.05884866284759875
4.692203350172594
0.058719236946806606
5.017421354759758
0.05863204483999747
1.0257045076829172
0.039649680955421936
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.23300
0.8924727392223317
0.02793660146064031
0.8009450350767751
0.03512373645192874
1.8134661193760444
0.03723862753691184
0.7302800730356105
0.04441810167620836
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.00903
2.794754548788142
0.05411192820998983
4.4671517064968835
0.05817542780921324
3.9511215570480887
0.057716156912396
2.7600935251707277
0.053814480821687126
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.53284
8.220551798352847
0.059095173934537
1.8106979386725326
0.04988606217119435
[RDDPG] Quadruped Not Upright
1.8106979386725326
0.04988606217119435
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:15.774573253942165 steps:67[00m
[RDDPG] Resetting Environment
3.1662679238003992
0.058983513706588976
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.39302
0.22884203321286473
0.021404017623758858
[RDDPG] Quadruped Not Upright
0.22884203321286473
0.021404017623758858
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-3.7439751371156853 steps:70[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000070: mean_reward:-3.123592556787615[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 241, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 259, in save
    self.plot(checkpoint_path, 'rewards_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 245, in plot
    fig, ax = plt.subplots(1,1, figsize = (7.5, 7.5))
NameError: name 'plt' is not defined
2021-05-05 00:05:49.869629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:28704): Gdk-CRITICAL **: 00:05:52.009: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620173154.636830059, 1.598000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620173154.637777530, 1.599000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620173154.637832912, 1.599000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620173156.042603211, 2.970000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620173156.675519876, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620173157.479173467, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620173158.283813908, 5.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000000: mean_reward:16603026.22090811[00m
[RDDPG] Resetting Environment
4.786707050989286
0.05901384951463818
0.6654413837818476
0.03548839500244271
2.070264784592538
0.047111058227464565
2.070199249078879
0.047113935981543266
2.0700991986532626
0.047118348780654615
2.070118787300323
0.04711747630465357
2.070146228677291
0.04711627187845224
2.070144605696048
0.047116343250876144
2.0701113125804698
0.047117808836435245
2.070121791361123
0.047117343853416795
2.0701092553890894
0.04711789942040915
2.0700628612154266
0.047119950869531205
2.070053229115711
0.04712037304304573
2.070034390722946
0.04712121663336699
2.0699873330552228
0.04712329992453252
2.0699750734094344
0.04712384114399949
2.069960887373396
0.047124472798544606
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
2.069938690583599
0.04712546610694321
[RDDPG] Last Step of episode
2.069938690583599
0.04712546610694321
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:10.040423022609303 steps:25[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000025: mean_reward:3.3700196420455035[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 242, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 260, in save
    self.plot(checkpoint_path, 'rewards_{st}.png'.format(
  File "/app/rl/torch/rdpg.py", line 248, in plot
    ax.set_xlabel(xlabel)
NameError: name 'xlabel' is not defined
2021-05-05 00:07:33.025699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:29666): Gdk-CRITICAL **: 00:07:35.097: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620173257.630613904, 1.468000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620173257.631833279, 1.468000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620173257.631890670, 1.468000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620173259.074961053, 2.905000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620173259.772011347, 3.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620173260.573270263, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620173261.382037925, 5.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:1561872.9491614734[00m
[RDDPG] Resetting Environment
29.10245902241316
0.059315965778260406
38.862705031936216
0.059385897862635685
0.6698214123325268
0.012521507688632022
0.6706442530335044
0.012571321363624904
11.737172320781589
0.05930701308791943
5728.848250754603
0.059399999755760026
295.3514094707209
0.059399910653237034
342.9821537451195
0.05939993349505427
331.1405910365375
0.05939992871329747
336.9743369624272
0.059399931129056005
323.76302512514536
0.059399925465130655
310.80555044274485
0.05939991920735229
293.6277393808332
0.05939990961654137
289.50610743004495
0.05939990706125532
288.02676991321937
0.05939990611726619
288.1739705781805
0.05939990621484188
294.51176424272614
0.059399910151563304
0.641234177545597
0.04102106811083397
[RDDPG] Quadruped Not Upright
0.641234177545597
0.04102106811083397
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:5944.364778005312 steps:19[00m
[RDDPG] Resetting Environment
2.3947917580294096
0.05939588099127358
2.5512283092895234
0.05935460064497177
3.912777469467028
0.05522745594819228
0.9049392248173607
0.013225203651398346
4.728530692218591
0.05256117387197362
0.5285085546372055
0.04293879446872414
0.9590086645009153
0.011414852839405252
0.9540352369304421
0.01104580829713613
0.3302175515437819
0.02742556986777694
1.2464423190517135
0.04830682740313088
1.255636805509853
0.0489701683376889
1.2635340065525693
0.04949615745138917
1.0905756444833714
0.03129033151438326
1.097174140972011
0.03169390256565184
1.1060705063353797
0.03234481713034901
1.1131589568003877
0.032936249076992864
1.120019182910843
0.03355748270153978
1.1261810881093446
0.03414756798626839
[RDDPG] Quadruped Not Upright
1.1261810881093446
0.03414756798626839
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-1.2402891653677213 steps:38[00m
[RDDPG] Resetting Environment
0.45403543181801953
0.03290702701073741
[RDDPG] Quadruped Not Upright
0.45403543181801953
0.03290702701073741
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-3.6898776468984025 steps:40[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[93m [RDDPG] Step_0000040: mean_reward:11.037660051340577[00m
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 242, in train
    self.save(checkpoint_path, step)
  File "/app/rl/torch/rdpg.py", line 329, in save
    pickle.dump(self.stabilily, pkl)
AttributeError: 'RDPG' object has no attribute 'stabilily'
2021-05-05 00:09:17.812871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:30614): Gdk-CRITICAL **: 00:09:19.880: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620173363.487057898, 2.494000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620173363.487821794, 2.495000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620173363.487897949, 2.495000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620173364.635619580, 3.636000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620173365.404437996, 4.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620173366.206440537, 5.200000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620173367.009118550, 6.001000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:7852249.3483745875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
1.9342662085485807
0.023040136910553576
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:-4.668813857421948 steps:1[00m
[RDDPG] Resetting Environment
2.0342467317219954
0.0500369130924394
2.02936357740169
0.05001575569934755
2.064918351051232
0.05659799451430811
0.8318044558050256
0.03743772322613253
0.8127178319784907
0.03598367760187129
0.8097192803306928
0.0346656238645389
0.8214799049409857
0.032743305999998217
0.923218296394221
0.027761998473209402
[RDDPG] Quadruped Not Upright
0.923218296394221
0.027761998473209402
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-5.349741084018882 steps:10[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000010: mean_reward:0.538957643004917[00m
[RDDPG] Resetting Environment
1.659720794237887
0.05890563249133563
8.662819834902555
0.058785877427609365
[RDDPG] Quadruped Not Upright
8.662819834902555
0.058785877427609365
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:3.280901403896351 steps:13[00m
[RDDPG] Resetting Environment
1.1476788247306176
0.04096157779937629
1.3743539509618903
0.04666174413693014
0.561893067359297
0.035953637999060956
0.6410118250491407
0.05584043997316014
1.6260979448302173
0.056785576492641245
0.7714270351117483
0.05917936513159735
7.832078927579807
0.05828450069156889
9.434461475215382
0.05865443151372747
11.794993337722216
0.05893618085736847
13.885446883122334
0.05907263767253464
15.48311160293435
0.0591401618654673
15.854687249165206
0.05915285741628459
16.54999481009979
0.059174237798922676
[RDDPG] Quadruped Not Upright
16.54999481009979
0.059174237798922676
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:53.909140612716044 steps:27[00m
[RDDPG] Resetting Environment
0.9224107504489283
0.03643465186198603
[RDDPG] Quadruped Not Upright
0.9224107504489283
0.03643465186198603
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-3.9100213708342686 steps:29[00m
[RDDPG] Resetting Environment
1.4087357383637609
0.05933574311537147
0.9524063690666437
0.047054424050119496
1.8661083505156553
0.054210536473518964
1.865193493280574
0.054206833184160155
1.8646788884790015
0.05420474818485895
1.8649557058963184
0.05420586847836991
1.8652361436400353
0.05420700543895409
1.8662036381812979
0.05421092149333453
1.2902417969946116
0.052488677153345265
0.1687592421623786
0.04648531078338709
0.16859050138252404
0.04643462418328285
0.16816758673069196
0.046306606437872315
0.14655353121507303
0.03570798163859077
0.14628483563520922
0.03566289463500226
0.724756829913515
0.04286884872774164
0.31530973837130893
0.03014438167006637
0.3061358841709417
0.022011942843260683
0.3047616421653446
0.020676537413733022
0.3046506066926965
0.020567574991149345
0.3046416421853266
0.020558387039624686
0.3046284396911939
0.020545396946053767
0.3046481890595262
0.020564721040257875
0.30471991315420066
0.02063534462832995
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 4.05942
[RDDPG] Quadruped Not Upright
0.30471991315420066
0.02063534462832995
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-12.343361364723489 steps:53[00m
[RDDPG] Resetting Environment
0.533725693391039
0.003303245413225709
[RDDPG] Quadruped Not Upright
0.533725693391039
0.003303245413225709
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:-3.617704049281553 steps:55[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000055: mean_reward:4.057938668865047[00m
[RDDPG] Resetting Environment
0.3438395686228074
0.055850677707155225
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.18186
[RDDPG] Quadruped Not Upright
0.3438395686228074
0.055850677707155225
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-5.039396611566405 steps:57[00m
[RDDPG] Resetting Environment
1.2696742807711574
0.046143934231190856
1.2901717630512006
0.04638905098523476
2.6602479513988317
0.057901115916242876
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.03569
49.050724924148994
0.059398628287395706
0.94558895020229
0.03923797718012983
0.9456123931099745
0.039238850972038365
0.9456199341189364
0.039239131734248006
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.53958
13.766602836715114
0.05899820961808602
16.62553083401783
0.05911526603852656
[RDDPG] Quadruped Not Upright
16.62553083401783
0.05911526603852656
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:49.63163549496034 steps:67[00m
[RDDPG] Resetting Environment
3.4032409275886075
0.05524837164749901
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.17869
1.3546179100360753
0.038894377352629246
4.443665277194971
0.05421619029528874
4.443484652350609
0.05421587061757557
[RDDPG] Quadruped Not Upright
4.443484652350609
0.05421587061757557
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.02400
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:1.9445993653469644 steps:72[00m
[RDDPG] Resetting Environment
1.8401678315062895
0.05107058038915779
1.8604102858971598
0.05162390875077835
1.7353870917808514
0.03155890277910114
[RDDPG] Quadruped Not Upright
1.7353870917808514
0.03155890277910114
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.55120
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-3.6966897847237448 steps:76[00m
[RDDPG] Resetting Environment
5.324152059823964
0.05722463429040883
[RDDPG] Quadruped Not Upright
5.324152059823964
0.05722463429040883
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:-1.6836247289660164 steps:78[00m
[RDDPG] Resetting Environment
5.491522830345373
0.057236155223065244
[RDDPG] Quadruped Not Upright
5.491522830345373
0.057236155223065244
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.08344
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-0.8848355949322668 steps:80[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000080: mean_reward:-4.085447379999185[00m
/app/rl/torch/rdpg.py:246: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(1,1, figsize = (7.5, 7.5))
[RDDPG] Resetting Environment
0.8444868419890408
0.05669988573584498
[RDDPG] Quadruped Not Upright
0.8444868419890408
0.05669988573584498
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:-3.920300280106314 steps:82[00m
[RDDPG] Resetting Environment
0.7063653313490077
0.03648058009926558
0.8869208905321747
0.05909085259282106
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.30992
[RDDPG] Quadruped Not Upright
0.8869208905321747
0.05909085259282106
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-4.2244342125435566 steps:85[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000085: mean_reward:-2.374678378448214[00m
[RDDPG] Resetting Environment
4.063841338403744
0.059243800392178
1.278173039730981
0.047523719913825986
[RDDPG] Quadruped Not Upright
1.278173039730981
0.047523719913825986
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.05926
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:-1.0554571947969626 steps:88[00m
[RDDPG] Resetting Environment
0.6915239344285314
0.037691100219584155
0.7392092598752111
0.05808809241226639
1.1220202170937805
0.04505731204494629
1.1215407534722797
0.04504393413951114
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.70452
[RDDPG] Quadruped Not Upright
1.1215407534722797
0.04504393413951114
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-5.65368747394348 steps:93[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
1.1215407534722797
0.04504393413951114
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:-3.656603445286433 steps:94[00m
[RDDPG] Resetting Environment
0.6239859481152973
0.035110845170731014
[RDDPG] Quadruped Not Upright
0.6239859481152973
0.035110845170731014
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.46942
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:-4.603147456039325 steps:96[00m
[RDDPG] Resetting Environment
2.5245710222667324
0.05065404635059291
[RDDPG] Quadruped Not Upright
2.5245710222667324
0.05065404635059291
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:-4.0549251722750475 steps:98[00m
[RDDPG] Resetting Environment
2.4512575408369512
0.04504229700261429
[RDDPG] Quadruped Not Upright
2.4512575408369512
0.04504229700261429
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.39105
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-2.832461859815824 steps:100[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000100: mean_reward:-4.3761268163304194[00m
[RDDPG] Resetting Environment
2.4762950558280403
0.04384241987000471
[RDDPG] Quadruped Not Upright
2.4762950558280403
0.04384241987000471
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-4.578036164099625 steps:102[00m
[RDDPG] Resetting Environment
2.771558517706108
0.055252575690203753
2.7100476218143355
0.05501158077256347
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.34942
2.5836723042419623
0.054418162256831173
2.462226886034535
0.053680115470183996
2.403774883556863
0.053244983159355296
2.322120563757945
0.052520246525932436
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.03715
[RDDPG] Quadruped Not Upright
2.322120563757945
0.052520246525932436
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:1.334643661962216 steps:109[00m
[RDDPG] Resetting Environment
1.167221058741744
0.04085438030439565
[RDDPG] Quadruped Not Upright
1.167221058741744
0.04085438030439565
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:-4.200732019232541 steps:111[00m
[RDDPG] Resetting Environment
32.622598528681216
0.059331502007286846
[RDDPG] Updating Policy
[RDDPG] Update Time: 4.11389
1.7863247860891864
0.05296858974523693
[RDDPG] Quadruped Not Upright
1.7863247860891864
0.05296858974523693
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:16.032474995879273 steps:114[00m
[RDDPG] Resetting Environment
4.376778319570434
0.059399705559650136
[RDDPG] Quadruped Not Upright
4.376778319570434
0.059399705559650136
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.08222
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:-3.390963038095488 steps:116[00m
[RDDPG] Resetting Environment
0.33073401736074615
0.01143494556786874
[RDDPG] Quadruped Not Upright
0.33073401736074615
0.01143494556786874
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-5.559778240766873 steps:118[00m
[RDDPG] Resetting Environment
0.7498796110439593
0.05907083249081623
[RDDPG] Quadruped Not Upright
0.7498796110439593
0.05907083249081623
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.42523
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:-4.818624894282095 steps:120[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000120: mean_reward:-5.226260644680793[00m
[RDDPG] Resetting Environment
1.184257294397507
0.059355134964655415
[RDDPG] Quadruped Not Upright
1.184257294397507
0.059355134964655415
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:-4.391853612782965 steps:122[00m
[RDDPG] Resetting Environment
2.5336053459619343
0.05388077714735424
[RDDPG] Quadruped Not Upright
2.5336053459619343
0.05388077714735424
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.04944
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:-4.998502305984655 steps:124[00m
[RDDPG] Resetting Environment
26.3021358075374
0.05931603597725305
[RDDPG] Quadruped Not Upright
26.3021358075374
0.05931603597725305
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:9.116677052046512 steps:126[00m
[RDDPG] Resetting Environment
2.1740671123196966
0.059201496033514225
[RDDPG] Quadruped Not Upright
2.1740671123196966
0.059201496033514225
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.46074
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-4.9113969980548156 steps:128[00m
[RDDPG] Resetting Environment
4.073841285857956
0.057892748298084586
[RDDPG] Quadruped Not Upright
4.073841285857956
0.057892748298084586
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-3.221118142155826 steps:130[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000130: mean_reward:-4.479780668237648[00m
[RDDPG] Resetting Environment
8.291366834665638
0.059230871499019316
[RDDPG] Quadruped Not Upright
8.291366834665638
0.059230871499019316
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.14337
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:0.033614329951377364 steps:132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
8.291366834665638
0.059230871499019316
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:-5.759354941405526 steps:133[00m
[RDDPG] Resetting Environment
1.4790101405474827
0.059397441813763406
[RDDPG] Quadruped Not Upright
1.4790101405474827
0.059397441813763406
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-4.830414121108058 steps:135[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000135: mean_reward:-4.1856399419517505[00m
[RDDPG] Resetting Environment
1.5964629320064598
0.058990669241609076
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.87223
[RDDPG] Quadruped Not Upright
1.5964629320064598
0.058990669241609076
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:-5.3609313095107645 steps:137[00m
[RDDPG] Resetting Environment
3.585365867356489
0.05757512387474034
[RDDPG] Quadruped Not Upright
3.585365867356489
0.05757512387474034
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-4.13821826815332 steps:139[00m
[RDDPG] Resetting Environment
3.346371155534032
0.056492209107793484
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.93211
[RDDPG] Quadruped Not Upright
3.346371155534032
0.056492209107793484
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-2.9843674660779858 steps:141[00m
[RDDPG] Resetting Environment
3.6299208298022094
0.05937401341804054
[RDDPG] Quadruped Not Upright
3.6299208298022094
0.05937401341804054
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:-2.5974099153482078 steps:143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
3.6299208298022094
0.05937401341804054
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.15689
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:-4.795082114258635 steps:144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
3.6299208298022094
0.05937401341804054
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:-5.651759765626484 steps:145[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000145: mean_reward:-2.1843051413214942[00m
[RDDPG] Resetting Environment
1.7794235584465667
0.047346082554570464
[RDDPG] Quadruped Not Upright
1.7794235584465667
0.047346082554570464
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-2.88838273316582 steps:147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
1.7794235584465667
0.047346082554570464
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.34295
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-6.395626669923054 steps:148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
1.7794235584465667
0.047346082554570464
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-5.607772460938197 steps:149[00m
[RDDPG] Resetting Environment
2.371985260118692
0.05429615277615846
[RDDPG] Quadruped Not Upright
2.371985260118692
0.05429615277615846
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-2.7377834457838826 steps:151[00m
[RDDPG] Resetting Environment
2.7143939552245064
0.049189154073697165
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.95794
[RDDPG] Quadruped Not Upright
2.7143939552245064
0.049189154073697165
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-3.4464118015303056 steps:153[00m
[RDDPG] Resetting Environment
7.337286546560706
0.05864909790805276
[RDDPG] Quadruped Not Upright
7.337286546560706
0.05864909790805276
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:-2.5301024636591065 steps:155[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000155: mean_reward:-4.747540896416303[00m
[RDDPG] Resetting Environment
2.689066799911407
0.04879510303121841
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.55085
[RDDPG] Quadruped Not Upright
2.689066799911407
0.04879510303121841
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-1.8521416237001853 steps:157[00m
[RDDPG] Resetting Environment
16.777546102133684
0.05915059870196064
[RDDPG] Quadruped Not Upright
16.777546102133684
0.05915059870196064
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:5.6630759237667725 steps:159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
16.777546102133684
0.05915059870196064
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.14851
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-5.152520498047565 steps:160[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000160: mean_reward:-3.4667395908121024[00m
[RDDPG] Resetting Environment
1.5728287161812502
0.04974248264608841
[RDDPG] Quadruped Not Upright
1.5728287161812502
0.04974248264608841
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-3.782834594341722 steps:162[00m
[RDDPG] Resetting Environment
0.5534434897733479
0.05933843342403373
[RDDPG] Quadruped Not Upright
0.5534434897733479
0.05933843342403373
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.84327
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-5.095637758944928 steps:164[00m
[RDDPG] Resetting Environment
1.9193074942837178
0.05479828079796061
[RDDPG] Quadruped Not Upright
1.9193074942837178
0.05479828079796061
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-4.1556785476552 steps:166[00m
[RDDPG] Resetting Environment
1.350010840989972
0.05243691674084279
[RDDPG] Quadruped Not Upright
1.350010840989972
0.05243691674084279
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.25510
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:-4.46887373006758 steps:168[00m
[RDDPG] Resetting Environment
2.1949103198102016
0.054391336603240616
[RDDPG] Quadruped Not Upright
2.1949103198102016
0.054391336603240616
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-3.945647855658465 steps:170[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000170: mean_reward:-4.2489012641027415[00m
[RDDPG] Resetting Environment
1.4183355395499795
0.0593990275348807
[RDDPG] Quadruped Not Upright
1.4183355395499795
0.0593990275348807
[RDDPG] Updating Policy
[RDDPG] Update Time: 3.21786
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:-6.216784120305942 steps:172[00m
[RDDPG] Resetting Environment
1.38522693073717
0.05893143169441133
[RDDPG] Quadruped Not Upright
1.38522693073717
0.05893143169441133
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-4.483768061854022 steps:174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
1.38522693073717
0.05893143169441133
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:-4.951067810058261 steps:175[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000175: mean_reward:-3.64081058898349[00m
[RDDPG] Resetting Environment
3.6990476427759957
0.059386350845523996
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.80478
[RDDPG] Quadruped Not Upright
3.6990476427759957
0.059386350845523996
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:-3.054013957976484 steps:177[00m
[RDDPG] Resetting Environment
7.075002555804609
0.059390240562378904
[RDDPG] Quadruped Not Upright
7.075002555804609
0.059390240562378904
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-1.3285264356676891 steps:179[00m
[RDDPG] Resetting Environment
4.415833001542687
0.05735638708230354
[RDDPG] Updating Policy
[RDDPG] Update Time: 2.78685
Traceback (most recent call last):
  File "rddpg_torch.py", line 35, in <module>
    rdpg.train(params['train_episode_count'], checkpoint_path, True)
  File "/app/rl/torch/rdpg.py", line 143, in train
    state, reward, done, info = self.env.step(
  File "/app/rl/torch/env.py", line 36, in step
    observation =  self.quadruped.step(
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1221, in step
    self.set_observation(action, desired_motion)
  File "/app/simulations/ws/src/quadruped/scripts/quadruped_torch.py", line 1076, in set_observation
    rospy.wait_for_service('/gazebo/get_model_state')
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py", line 166, in wait_for_service
    raise ROSInterruptException("rospy shutdown")
rospy.exceptions.ROSInterruptException: rospy shutdown
2021-05-05 00:16:22.135558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(rddpg_torch.py:1521): Gdk-CRITICAL **: 00:16:24.241: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1620173786.957454964, 1.600000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1620173786.958724530, 1.602000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1620173786.958828016, 1.602000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1620173788.195009686, 2.819000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1620173788.977599906, 3.601000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1620173789.780675144, 4.401000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1620173790.586805994, 5.201000000]: Ready to take commands for planning group back_left_leg.[0m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
/app/reward/__init__.py:45: RuntimeWarning: invalid value encountered in true_divide
  d11 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
/app/reward/__init__.py:49: RuntimeWarning: invalid value encountered in true_divide
  d12 = np.linalg.norm(np.cross(
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0000000: mean_reward:2880907.0046661673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 0: episode_reward:3.604240927734307 steps:2[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1: episode_reward:-9.646980396053447 steps:25[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2: episode_reward:-2.529532360265169 steps:27[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 3: episode_reward:-7.003143410933381 steps:42[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 4: episode_reward:-5.402572301978436 steps:46[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 5: episode_reward:-4.660967871021409 steps:48[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 6: episode_reward:46.40295301929503 steps:68[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 7: episode_reward:-3.884168968550004 steps:70[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 8: episode_reward:-1.9767521022592396 steps:72[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 9: episode_reward:-5.176762942905386 steps:86[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 10: episode_reward:-0.31109499744004276 steps:88[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 11: episode_reward:15.720191296362124 steps:102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 12: episode_reward:-1.5747180088142267 steps:104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 13: episode_reward:186.0130927593649 steps:175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 14: episode_reward:-1.3838050443417265 steps:177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 15: episode_reward:17.195333357186193 steps:220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 16: episode_reward:-0.5870855579201639 steps:222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 17: episode_reward:0.714678813118971 steps:224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 18: episode_reward:4839.185958916306 steps:254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 19: episode_reward:6.320874268502058 steps:263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 20: episode_reward:-1.5432790746691363 steps:267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 21: episode_reward:-2.7740172577818436 steps:269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 22: episode_reward:30.02698015785694 steps:280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 23: episode_reward:62.29148917673075 steps:327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 24: episode_reward:321.83630459583236 steps:388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 25: episode_reward:90.79793031136653 steps:400[00m
[RDDPG] Resetting Environment
[RDDPG] Last Step of episode
[RDDPG] Episode Done
[92m [RDDPG] 26: episode_reward:-8.572572721534009 steps:900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 27: episode_reward:19.455676600524093 steps:902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 28: episode_reward:22.1794978634632 steps:911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 29: episode_reward:17.02933385112308 steps:917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 30: episode_reward:-2.7333837021552583 steps:921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 31: episode_reward:-2.193350858978068 steps:923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 32: episode_reward:-15.333395246868303 steps:948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 33: episode_reward:-3.8832986744591054 steps:953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 34: episode_reward:5.166564090693189 steps:971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 35: episode_reward:-1.7310010294625897 steps:973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 36: episode_reward:13.11958746537611 steps:993[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
rddpg_torch.py:35: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rdpg.train(params['train_episode_count'], checkpoint_path, True)
[RDDPG] Update Time: 9.44635
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 37: episode_reward:-4.8401208953145085 steps:1013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 38: episode_reward:-2.315682967901063 steps:1019[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.28235
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 39: episode_reward:36.152296933013744 steps:1029[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.45184
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.04937
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 40: episode_reward:14.714718575620168 steps:1045[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.17807
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 41: episode_reward:37.60183198088151 steps:1066[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.58301
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 42: episode_reward:-6.456177142265935 steps:1070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 43: episode_reward:-6.002838410404023 steps:1074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 44: episode_reward:-3.221306447602733 steps:1079[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.75120
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 45: episode_reward:-5.399087248793765 steps:1084[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 46: episode_reward:-4.111384578557034 steps:1086[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.57078
[RDDPG] Episode Done
[92m [RDDPG] 47: episode_reward:30.673601600582888 steps:1092[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 48: episode_reward:-5.504249339268869 steps:1097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 49: episode_reward:-5.755806457613833 steps:1102[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 11.15439
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 50: episode_reward:-3.8630205006521785 steps:1106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 51: episode_reward:-5.654110440281624 steps:1110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 52: episode_reward:-6.841038239452753 steps:1115[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.31098
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 53: episode_reward:-1.7886194184085202 steps:1119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 54: episode_reward:2.233305806922884 steps:1123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36949
[RDDPG] Episode Done
[92m [RDDPG] 55: episode_reward:-1.2283942285672511 steps:1128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 56: episode_reward:5.420404570638654 steps:1133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 57: episode_reward:-1.6826754146435037 steps:1137[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34985
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 58: episode_reward:3.3151040411332824 steps:1141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 59: episode_reward:12.609489453927946 steps:1145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 60: episode_reward:-6.698591053852514 steps:1149[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.70478
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 61: episode_reward:-6.1106027982567195 steps:1153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 62: episode_reward:-4.579123558610759 steps:1156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 63: episode_reward:13.406771093351143 steps:1160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.33651
[RDDPG] Episode Done
[92m [RDDPG] 64: episode_reward:-3.322142880898284 steps:1164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 65: episode_reward:-3.087875182103356 steps:1168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 66: episode_reward:-5.44456648029646 steps:1171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 67: episode_reward:-4.3564420411247955 steps:1175[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.43797
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 68: episode_reward:-7.085991809612262 steps:1179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 69: episode_reward:-4.574291023517608 steps:1182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 70: episode_reward:-5.050720456712218 steps:1184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 71: episode_reward:-6.382447519664572 steps:1187[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.99202
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 72: episode_reward:-5.598466785854663 steps:1191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 73: episode_reward:-5.9948167803276515 steps:1194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 74: episode_reward:-4.910812967658162 steps:1197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.81230
[RDDPG] Episode Done
[92m [RDDPG] 75: episode_reward:-5.268040975868255 steps:1200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 76: episode_reward:-5.865255386928801 steps:1203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 77: episode_reward:-4.0959024269589275 steps:1206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 78: episode_reward:-5.724814511540482 steps:1209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31182
[RDDPG] Episode Done
[92m [RDDPG] 79: episode_reward:0.5799791651360708 steps:1212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 80: episode_reward:-2.3292542388128545 steps:1216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 81: episode_reward:-1.6041460542036226 steps:1219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 82: episode_reward:-4.789947003015353 steps:1223[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.10514
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 83: episode_reward:-5.322355533372454 steps:1226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 84: episode_reward:-5.0561647269317875 steps:1229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 85: episode_reward:-1.4727710682964479 steps:1232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.33473
[RDDPG] Episode Done
[92m [RDDPG] 86: episode_reward:-5.601625166611113 steps:1236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 87: episode_reward:-5.28842764112818 steps:1241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 88: episode_reward:-4.112621939626059 steps:1244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 89: episode_reward:-2.7202463475243546 steps:1247[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.71508
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 90: episode_reward:-6.474638171065237 steps:1251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 91: episode_reward:-5.9003911105202915 steps:1254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 92: episode_reward:-2.345142400450328 steps:1258[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.21114
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 93: episode_reward:-2.6870862847533985 steps:1261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 94: episode_reward:-3.8654265046979956 steps:1265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 95: episode_reward:-4.5808455370421095 steps:1269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97989
[RDDPG] Episode Done
[92m [RDDPG] 96: episode_reward:-4.829525897496878 steps:1272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 97: episode_reward:-4.7519040684243485 steps:1276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 98: episode_reward:-3.86358436793501 steps:1280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 99: episode_reward:-5.252218420751438 steps:1283[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 10.13495
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 100: episode_reward:-4.475511377918137 steps:1286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 101: episode_reward:0.914400128481772 steps:1289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 102: episode_reward:-3.802996345286546 steps:1292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30322
[RDDPG] Episode Done
[92m [RDDPG] 103: episode_reward:-5.508683825853712 steps:1296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 104: episode_reward:1.7871249448062931 steps:1299[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 105: episode_reward:-3.132529026585688 steps:1301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 106: episode_reward:-0.8876058760479535 steps:1304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 107: episode_reward:-2.6942043643304903 steps:1307[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.62195
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 108: episode_reward:-2.633999986399086 steps:1310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 109: episode_reward:-2.9589482949880113 steps:1313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 110: episode_reward:-5.512456171527809 steps:1317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08899
[RDDPG] Episode Done
[92m [RDDPG] 111: episode_reward:-2.979984050332482 steps:1320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 112: episode_reward:-5.892321423071483 steps:1323[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 113: episode_reward:-4.071105282312278 steps:1327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 114: episode_reward:-3.212709527771457 steps:1330[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06977
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 115: episode_reward:-3.953902063059129 steps:1334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 116: episode_reward:-4.48669914022938 steps:1338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 117: episode_reward:-2.807887204409978 steps:1341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90914
[RDDPG] Episode Done
[92m [RDDPG] 118: episode_reward:-5.1481552010111535 steps:1344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 119: episode_reward:-2.2439009591703276 steps:1348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 120: episode_reward:-2.373174992265125 steps:1352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 121: episode_reward:-4.06826321892188 steps:1355[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.76877
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 122: episode_reward:-5.005506095245916 steps:1358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 123: episode_reward:-1.8363922634111662 steps:1361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 124: episode_reward:-1.922478498251328 steps:1364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.23279
[RDDPG] Episode Done
[92m [RDDPG] 125: episode_reward:-6.877867526384316 steps:1368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 126: episode_reward:-5.319491303930416 steps:1371[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 127: episode_reward:6.451576806955034 steps:1376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 128: episode_reward:-6.0787218921945705 steps:1379[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 9.39377
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 129: episode_reward:8.26734461452668 steps:1382[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20826
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 130: episode_reward:4.352239461154508 steps:1394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 131: episode_reward:-2.697625708608763 steps:1399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.32005
[RDDPG] Episode Done
[92m [RDDPG] 132: episode_reward:12.365406355916615 steps:1404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 133: episode_reward:-6.197975330321342 steps:1407[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 134: episode_reward:-2.870089911300626 steps:1410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 135: episode_reward:-1.9922349007016311 steps:1413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37743
[RDDPG] Episode Done
[92m [RDDPG] 136: episode_reward:-7.372974041001166 steps:1416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 137: episode_reward:1.0795770232554718 steps:1421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 138: episode_reward:-3.090591406608487 steps:1424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 139: episode_reward:-2.443192328649557 steps:1427[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.89957
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 140: episode_reward:-6.276861601355794 steps:1433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 141: episode_reward:-5.841911849092742 steps:1438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.47643
[RDDPG] Episode Done
[92m [RDDPG] 142: episode_reward:-4.676803580950869 steps:1440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 143: episode_reward:-2.8910143496722465 steps:1442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 144: episode_reward:-5.910536634762883 steps:1445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 145: episode_reward:-5.052275919010636 steps:1450[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.46580
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 146: episode_reward:-6.232170725739751 steps:1453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 147: episode_reward:-1.7972690612867033 steps:1457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 148: episode_reward:-1.9557568556497462 steps:1460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 149: episode_reward:8.763652185797081 steps:1463[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.25666
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 150: episode_reward:23.50338775792057 steps:1466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 151: episode_reward:-5.16777966432426 steps:1470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 152: episode_reward:-1.0980950104826894 steps:1473[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39331
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 153: episode_reward:-1.8245832049163602 steps:1477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 154: episode_reward:1.0544093385180116 steps:1480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 155: episode_reward:-0.38827795747679383 steps:1483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 156: episode_reward:12.089597452558568 steps:1486[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90166
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 157: episode_reward:-1.3875525498690595 steps:1490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 158: episode_reward:-4.354163254241056 steps:1493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 159: episode_reward:-5.2060668353624715 steps:1497[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.60413
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 160: episode_reward:-2.598322394693118 steps:1501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 161: episode_reward:-2.6161970571035598 steps:1505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 162: episode_reward:-0.9566310228145332 steps:1508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 163: episode_reward:-2.6593024274691683 steps:1510[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.51998
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 164: episode_reward:-0.36120901859757204 steps:1513[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 165: episode_reward:-3.7327314368591336 steps:1516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 166: episode_reward:-1.0462143839168898 steps:1519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 167: episode_reward:-5.211733098402593 steps:1521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.57215
[RDDPG] Episode Done
[92m [RDDPG] 168: episode_reward:-4.692102035497625 steps:1524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 169: episode_reward:-5.407336573081895 steps:1527[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 170: episode_reward:-3.0559600468584858 steps:1530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 171: episode_reward:-3.0858444765580226 steps:1533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.65060
[RDDPG] Episode Done
[92m [RDDPG] 172: episode_reward:-1.5955609692205344 steps:1536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 173: episode_reward:-3.521644522250667 steps:1539[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 174: episode_reward:-3.243867445851814 steps:1541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 175: episode_reward:-2.580301553354653 steps:1544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 176: episode_reward:-1.3184585908110313 steps:1547[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.20214
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 177: episode_reward:-5.063244500646983 steps:1549[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 178: episode_reward:-2.2316147199818874 steps:1552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 179: episode_reward:-2.53222593428929 steps:1555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 180: episode_reward:20.903968892158606 steps:1558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34781
[RDDPG] Episode Done
[92m [RDDPG] 181: episode_reward:-2.491899562789979 steps:1560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 182: episode_reward:-5.638980682370786 steps:1561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 183: episode_reward:-4.574799703425381 steps:1564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 184: episode_reward:-0.47413759499248176 steps:1566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 185: episode_reward:-5.412316688549138 steps:1569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.63932
[RDDPG] Episode Done
[92m [RDDPG] 186: episode_reward:-4.135114888809527 steps:1572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 187: episode_reward:-5.341299892322829 steps:1575[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 188: episode_reward:-2.181557542504737 steps:1577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 189: episode_reward:-3.2197899947745108 steps:1579[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 190: episode_reward:-1.967795988716507 steps:1581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 191: episode_reward:-5.162603481216126 steps:1583[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77495
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 192: episode_reward:-5.377804497001387 steps:1585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 193: episode_reward:-5.923788341083798 steps:1587[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 194: episode_reward:-3.8858919809688888 steps:1589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 195: episode_reward:-4.836391566941156 steps:1591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 196: episode_reward:-4.719966728311386 steps:1594[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37692
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 197: episode_reward:-3.382772762888052 steps:1597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 198: episode_reward:-5.400569983402203 steps:1599[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 199: episode_reward:1.296006834695576 steps:1601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 200: episode_reward:-4.315961229934302 steps:1603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 201: episode_reward:-6.151887907059032 steps:1605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64417
[RDDPG] Episode Done
[92m [RDDPG] 202: episode_reward:-2.203365379798983 steps:1608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 203: episode_reward:3.2747674785806065 steps:1611[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 204: episode_reward:-4.414232182042887 steps:1613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 205: episode_reward:-4.31995270928138 steps:1615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 206: episode_reward:-4.26052165781251 steps:1617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 207: episode_reward:-4.550879244746111 steps:1619[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.22731
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 208: episode_reward:-4.559614341362846 steps:1622[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 209: episode_reward:-4.376198524324032 steps:1624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 210: episode_reward:-3.9757875481832166 steps:1626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 211: episode_reward:-5.465268636397262 steps:1628[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 212: episode_reward:-3.0339341317024937 steps:1631[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.45785
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 213: episode_reward:-3.550680297529155 steps:1634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 214: episode_reward:-1.6268824707008636 steps:1636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 215: episode_reward:-5.1364610036336495 steps:1638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 216: episode_reward:-3.8736238292163563 steps:1640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 217: episode_reward:-7.201144161662454 steps:1642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.61850
[RDDPG] Episode Done
[92m [RDDPG] 218: episode_reward:-4.908346103184531 steps:1644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 219: episode_reward:-1.8756238518861519 steps:1646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 220: episode_reward:-5.7484960214957175 steps:1648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 221: episode_reward:-2.424017067431989 steps:1650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 222: episode_reward:-4.305550412971254 steps:1652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 223: episode_reward:-3.179788476033653 steps:1654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.51052
[RDDPG] Episode Done
[92m [RDDPG] 224: episode_reward:-3.0672199814415775 steps:1656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 225: episode_reward:-0.7812185275376207 steps:1658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 226: episode_reward:-4.2536452775759095 steps:1660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 227: episode_reward:-1.954549951493587 steps:1662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 228: episode_reward:-3.601422784640428 steps:1664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 229: episode_reward:-2.9703346364210335 steps:1666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55329
[RDDPG] Episode Done
[92m [RDDPG] 230: episode_reward:-1.8100595821748948 steps:1668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 231: episode_reward:1.8371051372440617 steps:1670[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 232: episode_reward:-4.146999692647764 steps:1672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 233: episode_reward:-1.468519979124411 steps:1674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 234: episode_reward:-3.6621515490604546 steps:1676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 235: episode_reward:-2.6557700545922858 steps:1678[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.87977
[RDDPG] Episode Done
[92m [RDDPG] 236: episode_reward:-1.579863374967212 steps:1680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 237: episode_reward:-0.4033423340903135 steps:1682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 238: episode_reward:-1.9420676074950245 steps:1684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 239: episode_reward:-1.8759107375121784 steps:1686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 240: episode_reward:-4.078941870212933 steps:1688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 241: episode_reward:-0.09617494465693621 steps:1690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23373
[RDDPG] Episode Done
[92m [RDDPG] 242: episode_reward:-3.1161724782585596 steps:1692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 243: episode_reward:-1.8610018611729455 steps:1694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 244: episode_reward:-2.270542343516514 steps:1696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 245: episode_reward:-0.7497245499087906 steps:1698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 246: episode_reward:-0.7087254174408137 steps:1700[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 247: episode_reward:-2.9255729188752935 steps:1702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.38892
[RDDPG] Episode Done
[92m [RDDPG] 248: episode_reward:-2.4610669638418647 steps:1704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 249: episode_reward:-3.335730726546503 steps:1706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 250: episode_reward:-1.9485946569482033 steps:1708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 251: episode_reward:-1.4518745465459697 steps:1710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 252: episode_reward:-2.080133799315902 steps:1712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 253: episode_reward:-2.7993539594335637 steps:1714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.93894
[RDDPG] Episode Done
[92m [RDDPG] 254: episode_reward:-2.7690754894748077 steps:1716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 255: episode_reward:-3.855037933271894 steps:1718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 256: episode_reward:-8.050547718466934 steps:1720[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 257: episode_reward:-2.427025224143804 steps:1722[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 258: episode_reward:-3.927718218899076 steps:1724[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 259: episode_reward:-0.674127026720285 steps:1726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.10338
[RDDPG] Episode Done
[92m [RDDPG] 260: episode_reward:-0.7025996010824125 steps:1728[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 261: episode_reward:0.6651976328992584 steps:1730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 262: episode_reward:5.206555958089533 steps:1732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 263: episode_reward:4.283312613719932 steps:1734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 264: episode_reward:1.867501916773194 steps:1736[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 265: episode_reward:-2.500429412881693 steps:1738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.11502
[RDDPG] Episode Done
[92m [RDDPG] 266: episode_reward:-0.9260281087272109 steps:1740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 267: episode_reward:26.825423915345183 steps:1742[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 268: episode_reward:-1.080794151796249 steps:1744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 269: episode_reward:1.0510074312835496 steps:1746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 270: episode_reward:0.7003007153363017 steps:1748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 271: episode_reward:1.5106656161901717 steps:1750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.04956
[RDDPG] Episode Done
[92m [RDDPG] 272: episode_reward:-0.32275390633925527 steps:1752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 273: episode_reward:31.943193802251656 steps:1754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 274: episode_reward:3.996971950095206 steps:1756[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 275: episode_reward:-0.6777433101458037 steps:1758[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 276: episode_reward:1.7103285191997517 steps:1760[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 277: episode_reward:1.858457191116159 steps:1762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.55062
[RDDPG] Episode Done
[92m [RDDPG] 278: episode_reward:-2.128511240334424 steps:1764[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 279: episode_reward:-5.423712259401308 steps:1766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 280: episode_reward:-0.5661961890586529 steps:1768[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 281: episode_reward:-0.8687473293047097 steps:1770[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 282: episode_reward:-0.9754548829178598 steps:1772[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 283: episode_reward:-2.648542975412578 steps:1774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57898
[RDDPG] Episode Done
[92m [RDDPG] 284: episode_reward:1.1581279756290623 steps:1776[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 285: episode_reward:6.886806198787431 steps:1778[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 286: episode_reward:-3.1808052666246875 steps:1780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 287: episode_reward:-0.15725481795164953 steps:1782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 288: episode_reward:-2.4529398760052095 steps:1784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 289: episode_reward:-6.193970572763245 steps:1786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68998
[RDDPG] Episode Done
[92m [RDDPG] 290: episode_reward:-2.1896005705764874 steps:1788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 291: episode_reward:7.223795014013489 steps:1790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 292: episode_reward:-2.5208943342299466 steps:1792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 293: episode_reward:7.035989128164514 steps:1794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 294: episode_reward:1.6497077084725906 steps:1796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 295: episode_reward:1.6490648706366375 steps:1798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.22563
[RDDPG] Episode Done
[92m [RDDPG] 296: episode_reward:26.9395150230644 steps:1800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 297: episode_reward:23.064009575971657 steps:1802[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 298: episode_reward:9.906463117985153 steps:1804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 299: episode_reward:-2.466146800820548 steps:1806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 300: episode_reward:-2.234225501529096 steps:1808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 301: episode_reward:507.8061114557718 steps:1810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.96202
[RDDPG] Episode Done
[92m [RDDPG] 302: episode_reward:10.062995927767973 steps:1812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 303: episode_reward:194.59956423586257 steps:1814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 304: episode_reward:-1.4229870248077021 steps:1816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 305: episode_reward:3.796241842828397 steps:1818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 306: episode_reward:1.1086206362095563 steps:1820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 307: episode_reward:-2.4796380376351395 steps:1822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.95336
[RDDPG] Episode Done
[92m [RDDPG] 308: episode_reward:-1.7009580280943242 steps:1824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 309: episode_reward:31.053452178096244 steps:1826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 310: episode_reward:7.610261557081806 steps:1828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 311: episode_reward:6.826169141850847 steps:1830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 312: episode_reward:-2.982674030675292 steps:1832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 313: episode_reward:13.604747244396595 steps:1834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05807
[RDDPG] Episode Done
[92m [RDDPG] 314: episode_reward:-1.5040312013570227 steps:1836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 315: episode_reward:-4.235464806544998 steps:1838[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 316: episode_reward:25.64694373426761 steps:1840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 317: episode_reward:-0.1896330064840015 steps:1842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 318: episode_reward:-0.4341779730765811 steps:1844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 319: episode_reward:50.920661407799415 steps:1846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36762
[RDDPG] Episode Done
[92m [RDDPG] 320: episode_reward:0.2707323313475132 steps:1848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 321: episode_reward:0.7932279637572517 steps:1850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 322: episode_reward:-1.226357761938495 steps:1852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 323: episode_reward:8.719969514601535 steps:1854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 324: episode_reward:2.7102289694266135 steps:1856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 325: episode_reward:15.110604596081078 steps:1858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.89241
[RDDPG] Episode Done
[92m [RDDPG] 326: episode_reward:10.75884514589523 steps:1860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 327: episode_reward:7.605285092011918 steps:1862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 328: episode_reward:1.8205561554911363 steps:1864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 329: episode_reward:4.063414687136752 steps:1866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 330: episode_reward:2.866309061772483 steps:1868[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 331: episode_reward:1.9373548364173043 steps:1870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.95981
[RDDPG] Episode Done
[92m [RDDPG] 332: episode_reward:0.993407822120222 steps:1872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 333: episode_reward:10.035520769936944 steps:1874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 334: episode_reward:-1.2649080771161767 steps:1876[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 335: episode_reward:-3.0754929508860327 steps:1878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 336: episode_reward:-1.6930845732503828 steps:1880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 337: episode_reward:0.7079999569528246 steps:1882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.65189
[RDDPG] Episode Done
[92m [RDDPG] 338: episode_reward:-5.634160915690988 steps:1884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 339: episode_reward:8.331985443717336 steps:1886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 340: episode_reward:-2.8971645031558424 steps:1888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 341: episode_reward:-0.0896818138553992 steps:1890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 342: episode_reward:5.395094372027431 steps:1892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 343: episode_reward:4.359404990425906 steps:1894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90735
[RDDPG] Episode Done
[92m [RDDPG] 344: episode_reward:28.459293476990375 steps:1896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 345: episode_reward:8.27749777112655 steps:1898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 346: episode_reward:2.1165667930947487 steps:1900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 347: episode_reward:1.9766391089918809 steps:1902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 348: episode_reward:2.909709209272438 steps:1904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 349: episode_reward:0.13475762756263698 steps:1906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09112
[RDDPG] Episode Done
[92m [RDDPG] 350: episode_reward:32.15189592052137 steps:1908[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 351: episode_reward:-0.9324497216380658 steps:1910[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 352: episode_reward:-0.40874850804323826 steps:1912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 353: episode_reward:0.7518230367610874 steps:1914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 354: episode_reward:1.587694218358767 steps:1916[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 355: episode_reward:34.61033397806472 steps:1918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.63044
[RDDPG] Episode Done
[92m [RDDPG] 356: episode_reward:-1.0026957798482616 steps:1920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 357: episode_reward:-1.1645104954387662 steps:1922[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 358: episode_reward:-0.20717759320356244 steps:1924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 359: episode_reward:-0.9574351343746543 steps:1926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 360: episode_reward:17.518878159578005 steps:1928[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 361: episode_reward:4.520430911272079 steps:1930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68135
[RDDPG] Episode Done
[92m [RDDPG] 362: episode_reward:17.901160570947003 steps:1932[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 363: episode_reward:-7.762554295858355 steps:1934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 364: episode_reward:-1.451684046478368 steps:1936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 365: episode_reward:-2.216899466467695 steps:1938[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 366: episode_reward:0.4908537657404253 steps:1940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 367: episode_reward:2.884415179737098 steps:1942[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.25725
[RDDPG] Episode Done
[92m [RDDPG] 368: episode_reward:-2.2894410297432883 steps:1944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 369: episode_reward:147.65529608965548 steps:1946[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 370: episode_reward:0.38077223519864756 steps:1948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 371: episode_reward:0.8649976790555307 steps:1950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 372: episode_reward:-4.572335387406824 steps:1952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 373: episode_reward:1.839964856318261 steps:1954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.25327
[RDDPG] Episode Done
[92m [RDDPG] 374: episode_reward:-1.861547325141255 steps:1956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 375: episode_reward:-1.6118672087638526 steps:1958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 376: episode_reward:19.158297614022764 steps:1960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 377: episode_reward:2.6192686539685073 steps:1962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 378: episode_reward:-0.22690442890715534 steps:1964[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 379: episode_reward:-0.13603889645971234 steps:1966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64297
[RDDPG] Episode Done
[92m [RDDPG] 380: episode_reward:4.352531782835808 steps:1968[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 381: episode_reward:133.33241166065127 steps:1970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 382: episode_reward:5.785303386519347 steps:1972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 383: episode_reward:17.141816472022295 steps:1974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 384: episode_reward:-6.308067273833624 steps:1976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 385: episode_reward:15.356710643064094 steps:1978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.54960
[RDDPG] Episode Done
[92m [RDDPG] 386: episode_reward:5.7812424900440345 steps:1980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 387: episode_reward:3.8035152501573197 steps:1982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 388: episode_reward:-2.9127366074208814 steps:1984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 389: episode_reward:1.0748961301678417 steps:1986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 390: episode_reward:-7.7527065320978865 steps:1988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 391: episode_reward:3.5633726789367604 steps:1990[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59427
[RDDPG] Episode Done
[92m [RDDPG] 392: episode_reward:-4.661075690039172 steps:1992[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 393: episode_reward:-3.252631941983044 steps:1994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 394: episode_reward:103.63730433224401 steps:1996[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 395: episode_reward:293.65906521860103 steps:1998[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 396: episode_reward:0.9870373528329974 steps:2000[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0002000: mean_reward:0.942540656091127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 397: episode_reward:13.425318459577767 steps:2002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64281
[RDDPG] Episode Done
[92m [RDDPG] 398: episode_reward:23.263299745676676 steps:2004[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 399: episode_reward:-3.2246080840767384 steps:2006[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 400: episode_reward:-4.57162242416126 steps:2008[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 401: episode_reward:0.718669988836246 steps:2010[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 402: episode_reward:4.295445651983273 steps:2012[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 403: episode_reward:48.16034518194192 steps:2014[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78957
[RDDPG] Episode Done
[92m [RDDPG] 404: episode_reward:9.718114305621919 steps:2016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 405: episode_reward:4.931043913044074 steps:2018[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 406: episode_reward:0.9163927604915081 steps:2020[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 407: episode_reward:5.545431267783048 steps:2022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 408: episode_reward:51.6865188113303 steps:2024[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 409: episode_reward:-0.9284997472664704 steps:2026[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26821
[RDDPG] Episode Done
[92m [RDDPG] 410: episode_reward:9.581374342005809 steps:2028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 411: episode_reward:-1.4996701156230416 steps:2030[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 412: episode_reward:-1.182986837446375 steps:2032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 413: episode_reward:-1.445149722411437 steps:2034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 414: episode_reward:-1.7605439416729423 steps:2036[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 415: episode_reward:-1.0401121660701056 steps:2038[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.31060
[RDDPG] Episode Done
[92m [RDDPG] 416: episode_reward:128.80585955046678 steps:2040[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 417: episode_reward:8.710667382002242 steps:2042[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 418: episode_reward:-2.1925988984782347 steps:2044[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 419: episode_reward:2.7373060398263025 steps:2046[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 420: episode_reward:-3.0592168727597215 steps:2048[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 421: episode_reward:-1.3425836033161787 steps:2050[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78281
[RDDPG] Episode Done
[92m [RDDPG] 422: episode_reward:-1.1904062535490818 steps:2052[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 423: episode_reward:10.450355131465646 steps:2054[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 424: episode_reward:1.6835000270680514 steps:2056[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 425: episode_reward:5.896173069361131 steps:2058[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 426: episode_reward:1.1354940325438414 steps:2060[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 427: episode_reward:-2.3712742100596493 steps:2062[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69029
[RDDPG] Episode Done
[92m [RDDPG] 428: episode_reward:14.640137957883129 steps:2064[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 429: episode_reward:-1.879216610210604 steps:2066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 430: episode_reward:-1.7454355461245081 steps:2068[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 431: episode_reward:-0.3109004538581277 steps:2070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 432: episode_reward:754.4878275930232 steps:2072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 433: episode_reward:-4.647476145637393 steps:2074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81818
[RDDPG] Episode Done
[92m [RDDPG] 434: episode_reward:4.240475197308375 steps:2076[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 435: episode_reward:-5.182605520921316 steps:2078[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 436: episode_reward:2.5206259967345996 steps:2080[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 437: episode_reward:1.0492330108485008 steps:2082[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 438: episode_reward:4.753869559220078 steps:2084[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 439: episode_reward:-2.2587970035967437 steps:2086[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71206
[RDDPG] Episode Done
[92m [RDDPG] 440: episode_reward:-2.485712291462672 steps:2088[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 441: episode_reward:5.124756844198876 steps:2090[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 442: episode_reward:16.4656806742218 steps:2092[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 443: episode_reward:-5.497786163200564 steps:2094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 444: episode_reward:2.858893464428784 steps:2096[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 445: episode_reward:-2.2951055341186573 steps:2098[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81192
[RDDPG] Episode Done
[92m [RDDPG] 446: episode_reward:52.678435969528536 steps:2100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 447: episode_reward:-1.5718887265189454 steps:2102[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 448: episode_reward:35.32004453387271 steps:2104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 449: episode_reward:-0.1839970566257194 steps:2106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 450: episode_reward:-2.154421563141668 steps:2108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 451: episode_reward:-2.0860799109052888 steps:2110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.12983
[RDDPG] Episode Done
[92m [RDDPG] 452: episode_reward:-3.642955820782437 steps:2112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 453: episode_reward:1.7134852905473625 steps:2114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 454: episode_reward:-5.203254758079974 steps:2116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 455: episode_reward:-0.5340509063334427 steps:2118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 456: episode_reward:169.30977532809402 steps:2120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 457: episode_reward:5.641398434134727 steps:2122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.96343
[RDDPG] Episode Done
[92m [RDDPG] 458: episode_reward:5.81207139547273 steps:2124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 459: episode_reward:37.50219412901283 steps:2126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 460: episode_reward:-5.75259596574063 steps:2128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 461: episode_reward:-2.899694076214713 steps:2130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 462: episode_reward:-0.8434696902082495 steps:2132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 463: episode_reward:8.646741648224644 steps:2134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50007
[RDDPG] Episode Done
[92m [RDDPG] 464: episode_reward:6.657483931241229 steps:2136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 465: episode_reward:102.59667297488386 steps:2138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 466: episode_reward:-2.3059373070382847 steps:2140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 467: episode_reward:-0.15360219969292377 steps:2142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 468: episode_reward:-1.3440382782921736 steps:2144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 469: episode_reward:20.39702983703999 steps:2146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14074
[RDDPG] Episode Done
[92m [RDDPG] 470: episode_reward:-6.805082013980485 steps:2148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 471: episode_reward:24.510139338271053 steps:2150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 472: episode_reward:0.04511881035545029 steps:2152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 473: episode_reward:-2.469347167178403 steps:2154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 474: episode_reward:1.6817303536981867 steps:2156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 475: episode_reward:16.997179491865136 steps:2158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73376
[RDDPG] Episode Done
[92m [RDDPG] 476: episode_reward:1221.7971835768424 steps:2160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 477: episode_reward:-1.7520612280331864 steps:2162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 478: episode_reward:4.9555604467512575 steps:2164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 479: episode_reward:-1.524240469117131 steps:2166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 480: episode_reward:5.071255074820374 steps:2168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 481: episode_reward:8.557285393282779 steps:2170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85434
[RDDPG] Episode Done
[92m [RDDPG] 482: episode_reward:-0.06995820150480059 steps:2172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 483: episode_reward:14.82896082256728 steps:2174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 484: episode_reward:13.892508570830742 steps:2176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 485: episode_reward:15.526512522859342 steps:2178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 486: episode_reward:4.757650980947314 steps:2180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 487: episode_reward:4.313204237912373 steps:2182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24010
[RDDPG] Episode Done
[92m [RDDPG] 488: episode_reward:55.28694028646553 steps:2184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 489: episode_reward:-0.8094769051889847 steps:2186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 490: episode_reward:12.640119799682969 steps:2188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 491: episode_reward:-7.387619660328272 steps:2190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 492: episode_reward:2.829017010423704 steps:2192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 493: episode_reward:-4.352790017819541 steps:2194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34002
[RDDPG] Episode Done
[92m [RDDPG] 494: episode_reward:-5.222720582351377 steps:2196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 495: episode_reward:6.622061515857021 steps:2198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 496: episode_reward:13.857342927893628 steps:2200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 497: episode_reward:7.885218656715891 steps:2202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 498: episode_reward:8.426081536303329 steps:2204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 499: episode_reward:5.504821042094715 steps:2206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.49889
[RDDPG] Episode Done
[92m [RDDPG] 500: episode_reward:16.795123803462225 steps:2208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 501: episode_reward:-0.5282675040055418 steps:2210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 502: episode_reward:51.36730013672172 steps:2212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 503: episode_reward:2.2606623243231434 steps:2214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 504: episode_reward:-4.606269860083481 steps:2216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 505: episode_reward:-6.603553975979126 steps:2218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.22795
[RDDPG] Episode Done
[92m [RDDPG] 506: episode_reward:371.0591132792145 steps:2220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 507: episode_reward:1.0389327681836678 steps:2222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 508: episode_reward:-1.3252467136210744 steps:2224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 509: episode_reward:10.378274295826506 steps:2226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 510: episode_reward:8.986481821916701 steps:2228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 511: episode_reward:2.5961322949085295 steps:2230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88461
[RDDPG] Episode Done
[92m [RDDPG] 512: episode_reward:1.924963978338634 steps:2232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 513: episode_reward:-0.2308469889136857 steps:2234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 514: episode_reward:26.740209791517 steps:2236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 515: episode_reward:18.78755185315126 steps:2238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 516: episode_reward:1.7086904573615453 steps:2240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 517: episode_reward:0.18313515339873243 steps:2242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32471
[RDDPG] Episode Done
[92m [RDDPG] 518: episode_reward:76.63226553154054 steps:2244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 519: episode_reward:2.605100859332988 steps:2246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 520: episode_reward:-2.1957239371756696 steps:2248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 521: episode_reward:-4.470709086193544 steps:2250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 522: episode_reward:0.9170909731228014 steps:2252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 523: episode_reward:11.704165648211 steps:2254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.16546
[RDDPG] Episode Done
[92m [RDDPG] 524: episode_reward:-1.2803092139296242 steps:2256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 525: episode_reward:5.32654635526523 steps:2258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 526: episode_reward:16.776841043715653 steps:2260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 527: episode_reward:8.379103577211447 steps:2262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 528: episode_reward:22.60852204219633 steps:2264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 529: episode_reward:13.269767763018486 steps:2266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44748
[RDDPG] Episode Done
[92m [RDDPG] 530: episode_reward:2.232302633302992 steps:2268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 531: episode_reward:17.00781996547627 steps:2270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 532: episode_reward:29.252007792920026 steps:2272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 533: episode_reward:34.51394228140826 steps:2274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 534: episode_reward:-1.3362592207706498 steps:2276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 535: episode_reward:-0.8591261595366095 steps:2278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40776
[RDDPG] Episode Done
[92m [RDDPG] 536: episode_reward:-6.662661631212849 steps:2280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 537: episode_reward:15.756876170563125 steps:2282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 538: episode_reward:24.561281774241824 steps:2284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 539: episode_reward:11.040319738084735 steps:2286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 540: episode_reward:22.015114774468575 steps:2288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 541: episode_reward:-1.1342209033537345 steps:2290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.78661
[RDDPG] Episode Done
[92m [RDDPG] 542: episode_reward:6.482926635293974 steps:2292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 543: episode_reward:-2.553122096663697 steps:2294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 544: episode_reward:3.723844343453056 steps:2296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 545: episode_reward:39.14081428764223 steps:2298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 546: episode_reward:6.995318640860277 steps:2300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 547: episode_reward:2544.275476610994 steps:2302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50937
[RDDPG] Episode Done
[92m [RDDPG] 548: episode_reward:3.246153277238543 steps:2304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 549: episode_reward:-0.7112860568472867 steps:2306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 550: episode_reward:-2.271565795933973 steps:2308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 551: episode_reward:-0.22032784926463034 steps:2310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 552: episode_reward:-1.6384521146054611 steps:2312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 553: episode_reward:5.21939505426757 steps:2314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44046
[RDDPG] Episode Done
[92m [RDDPG] 554: episode_reward:6.8900937885793425 steps:2316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 555: episode_reward:-2.3928012358525708 steps:2318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 556: episode_reward:11.945909070957587 steps:2320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 557: episode_reward:11.95950778381071 steps:2322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 558: episode_reward:6.508201609688272 steps:2324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 559: episode_reward:3.640160473536678 steps:2326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93369
[RDDPG] Episode Done
[92m [RDDPG] 560: episode_reward:-1.2661585729219338 steps:2328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 561: episode_reward:-1.1023164356852067 steps:2330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 562: episode_reward:-4.044132860361652 steps:2332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 563: episode_reward:-0.22869563803153303 steps:2334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 564: episode_reward:12.88919796364457 steps:2336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 565: episode_reward:0.6182452781669907 steps:2338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55065
[RDDPG] Episode Done
[92m [RDDPG] 566: episode_reward:1.4558109388968061 steps:2340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 567: episode_reward:4.250473313222689 steps:2342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 568: episode_reward:-2.2507081288608823 steps:2344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 569: episode_reward:11.320314869701429 steps:2346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 570: episode_reward:-4.191774460714258 steps:2348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 571: episode_reward:15.612790903502676 steps:2350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14385
[RDDPG] Episode Done
[92m [RDDPG] 572: episode_reward:-4.363199561967975 steps:2352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 573: episode_reward:9.646267766680193 steps:2354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 574: episode_reward:1.440059148700103 steps:2356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 575: episode_reward:1.490346302892041 steps:2358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 576: episode_reward:533.9318139292916 steps:2360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 577: episode_reward:-3.810819706578484 steps:2362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01210
[RDDPG] Episode Done
[92m [RDDPG] 578: episode_reward:-3.8466825191891587 steps:2364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 579: episode_reward:20.68253043498252 steps:2366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 580: episode_reward:55.91206119138225 steps:2368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 581: episode_reward:25.577033149567267 steps:2370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 582: episode_reward:-2.9831854011417778 steps:2372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 583: episode_reward:37.143187010225816 steps:2374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54458
[RDDPG] Episode Done
[92m [RDDPG] 584: episode_reward:1.5708935465289269 steps:2376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 585: episode_reward:0.17424976469194053 steps:2378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 586: episode_reward:6.121788470510774 steps:2380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 587: episode_reward:2.3462710254029484 steps:2382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 588: episode_reward:0.32829483640386625 steps:2384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 589: episode_reward:5.1566584404129525 steps:2386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29262
[RDDPG] Episode Done
[92m [RDDPG] 590: episode_reward:37.91208500616367 steps:2388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 591: episode_reward:21.21921184014257 steps:2390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 592: episode_reward:-5.732268237756204 steps:2392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 593: episode_reward:-6.221297315114171 steps:2394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 594: episode_reward:-1.732226271989135 steps:2396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 595: episode_reward:-1.4665674351874858 steps:2398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35608
[RDDPG] Episode Done
[92m [RDDPG] 596: episode_reward:-0.21993848726232557 steps:2400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 597: episode_reward:62.379181664690975 steps:2402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 598: episode_reward:13.76000077815776 steps:2404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 599: episode_reward:75.76982144408063 steps:2406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 600: episode_reward:-0.863012900369152 steps:2408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 601: episode_reward:27.771303332620416 steps:2410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34699
[RDDPG] Episode Done
[92m [RDDPG] 602: episode_reward:-5.6079639000299295 steps:2412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 603: episode_reward:0.605223050226003 steps:2414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 604: episode_reward:-6.569828898969131 steps:2416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 605: episode_reward:1.9316052139351179 steps:2418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 606: episode_reward:2.932187043306172 steps:2420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 607: episode_reward:35.10581580240646 steps:2422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57157
[RDDPG] Episode Done
[92m [RDDPG] 608: episode_reward:-1.870835612507886 steps:2424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 609: episode_reward:-2.7707990232247903 steps:2426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 610: episode_reward:0.41964595854574815 steps:2428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 611: episode_reward:-2.902823477999728 steps:2430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 612: episode_reward:12.265677556958549 steps:2432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 613: episode_reward:-2.9799361625495466 steps:2434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59844
[RDDPG] Episode Done
[92m [RDDPG] 614: episode_reward:13.276647432287398 steps:2436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 615: episode_reward:7.309903819140039 steps:2438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 616: episode_reward:-6.278784546852411 steps:2440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 617: episode_reward:2.1207833335727315 steps:2442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 618: episode_reward:0.2538861492297899 steps:2444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 619: episode_reward:516.2563948903155 steps:2446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37624
[RDDPG] Episode Done
[92m [RDDPG] 620: episode_reward:10.425269374273588 steps:2448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 621: episode_reward:3.5422092001256953 steps:2450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 622: episode_reward:-3.632062287334964 steps:2452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 623: episode_reward:0.8247140697244744 steps:2454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 624: episode_reward:11.980405792321474 steps:2456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 625: episode_reward:10.59891361949815 steps:2458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.03988
[RDDPG] Episode Done
[92m [RDDPG] 626: episode_reward:-0.45164570302053475 steps:2460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 627: episode_reward:0.18177317850684815 steps:2462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 628: episode_reward:55.769626794241034 steps:2464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 629: episode_reward:5.039964990990887 steps:2466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 630: episode_reward:22.34584144640452 steps:2468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 631: episode_reward:5.137752013318344 steps:2470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.28419
[RDDPG] Episode Done
[92m [RDDPG] 632: episode_reward:4.247500607809016 steps:2472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 633: episode_reward:-1.4967108418266966 steps:2474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 634: episode_reward:0.8112189195979571 steps:2476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 635: episode_reward:3.624299481838681 steps:2478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 636: episode_reward:3.937319850409749 steps:2480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 637: episode_reward:15.59200985846524 steps:2482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64510
[RDDPG] Episode Done
[92m [RDDPG] 638: episode_reward:6.723996227582019 steps:2484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 639: episode_reward:2.818742862664532 steps:2486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 640: episode_reward:34.651499944314395 steps:2488[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 641: episode_reward:15.805731433310255 steps:2490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 642: episode_reward:8.40245858875398 steps:2492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 643: episode_reward:48.17374374735435 steps:2494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.03921
[RDDPG] Episode Done
[92m [RDDPG] 644: episode_reward:-1.2468180950626324 steps:2496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 645: episode_reward:37.722964090548224 steps:2498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 646: episode_reward:162.94021049201854 steps:2500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 647: episode_reward:2.0885140380893574 steps:2502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 648: episode_reward:5.785176888507492 steps:2504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 649: episode_reward:17.996400078678487 steps:2506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75624
[RDDPG] Episode Done
[92m [RDDPG] 650: episode_reward:-2.301265086476429 steps:2508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 651: episode_reward:9.013759019193614 steps:2510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 652: episode_reward:18.150193192652555 steps:2512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 653: episode_reward:-6.6183984063178265 steps:2514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 654: episode_reward:-5.709339778724445 steps:2516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 655: episode_reward:1.1899986422678834 steps:2518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.45978
[RDDPG] Episode Done
[92m [RDDPG] 656: episode_reward:11.410547671583165 steps:2520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 657: episode_reward:-1.1275952577811794 steps:2522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 658: episode_reward:0.9641940469834194 steps:2524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 659: episode_reward:-0.10504383452291854 steps:2526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 660: episode_reward:31.639263156444304 steps:2528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 661: episode_reward:245.2902127743729 steps:2530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.45492
[RDDPG] Episode Done
[92m [RDDPG] 662: episode_reward:54.69938473142412 steps:2532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 663: episode_reward:0.8445190464685206 steps:2534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 664: episode_reward:48.02734504420924 steps:2536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 665: episode_reward:0.9555613378171537 steps:2538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 666: episode_reward:-1.4884596924986695 steps:2540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 667: episode_reward:2.1227031197119004 steps:2542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.05457
[RDDPG] Episode Done
[92m [RDDPG] 668: episode_reward:398.89686473852635 steps:2544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 669: episode_reward:111.10803935258248 steps:2546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 670: episode_reward:38.74673800887319 steps:2548[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 671: episode_reward:5.460719984632597 steps:2550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 672: episode_reward:2.9429646573663444 steps:2552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 673: episode_reward:-0.3290006755793211 steps:2554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23111
[RDDPG] Episode Done
[92m [RDDPG] 674: episode_reward:2.9930525866145072 steps:2556[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 675: episode_reward:0.35681117224751624 steps:2558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 676: episode_reward:-0.991492844026006 steps:2560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 677: episode_reward:18.383696111708304 steps:2562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 678: episode_reward:0.516372541335318 steps:2564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 679: episode_reward:-2.5555780201490563 steps:2566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.00963
[RDDPG] Episode Done
[92m [RDDPG] 680: episode_reward:6.830781729072012 steps:2568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 681: episode_reward:-0.9418960955692928 steps:2570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 682: episode_reward:1.5584777355712838 steps:2572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 683: episode_reward:22.699848168947085 steps:2574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 684: episode_reward:-1.53940068357071 steps:2576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 685: episode_reward:-0.9774749505653886 steps:2578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27048
[RDDPG] Episode Done
[92m [RDDPG] 686: episode_reward:-0.38581510207224 steps:2580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 687: episode_reward:2.2306264023094715 steps:2582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 688: episode_reward:-1.1297061669836521 steps:2584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 689: episode_reward:0.3452463514452875 steps:2586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 690: episode_reward:39.03745140422725 steps:2588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 691: episode_reward:8.957937484129944 steps:2590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50118
[RDDPG] Episode Done
[92m [RDDPG] 692: episode_reward:-1.2055561333709943 steps:2592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 693: episode_reward:-3.184101345277993 steps:2594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 694: episode_reward:0.027330953136452507 steps:2596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 695: episode_reward:-0.638438159643441 steps:2598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 696: episode_reward:9.763366745538672 steps:2600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 697: episode_reward:0.035232210643053374 steps:2602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27983
[RDDPG] Episode Done
[92m [RDDPG] 698: episode_reward:0.2732967328410356 steps:2604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 699: episode_reward:5.587765284411516 steps:2606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 700: episode_reward:2.572628995813731 steps:2608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 701: episode_reward:210.78875858783508 steps:2610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 702: episode_reward:-1.8967243021317066 steps:2612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 703: episode_reward:3.94296203294266 steps:2614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24047
[RDDPG] Episode Done
[92m [RDDPG] 704: episode_reward:3.341252307345459 steps:2616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 705: episode_reward:-3.863751052466886 steps:2618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 706: episode_reward:9.261901723827133 steps:2620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 707: episode_reward:6.234980147978552 steps:2622[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 708: episode_reward:-2.310290766436702 steps:2624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 709: episode_reward:6.558906474811174 steps:2626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.02359
[RDDPG] Episode Done
[92m [RDDPG] 710: episode_reward:-1.454878409631731 steps:2628[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 711: episode_reward:7.490979709422968 steps:2630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 712: episode_reward:-3.508739354094646 steps:2632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 713: episode_reward:5.124484363788612 steps:2634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 714: episode_reward:16.139333657922023 steps:2636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 715: episode_reward:19.94890744668078 steps:2638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.31891
[RDDPG] Episode Done
[92m [RDDPG] 716: episode_reward:2.4176807387340093 steps:2640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 717: episode_reward:-0.46747030980338256 steps:2642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 718: episode_reward:-0.7188591886184756 steps:2644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 719: episode_reward:1.8124319080878122 steps:2646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 720: episode_reward:-6.04788102079382 steps:2648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 721: episode_reward:21.925303535722996 steps:2650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18479
[RDDPG] Episode Done
[92m [RDDPG] 722: episode_reward:2.7384463734668536 steps:2652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 723: episode_reward:2.2118981964813744 steps:2654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 724: episode_reward:2.830630260403478 steps:2656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 725: episode_reward:2.0634040837730927 steps:2658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 726: episode_reward:1.8425124499273 steps:2660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 727: episode_reward:-1.2915482358841732 steps:2662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.38098
[RDDPG] Episode Done
[92m [RDDPG] 728: episode_reward:5.691738934626409 steps:2664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 729: episode_reward:1.3509805818555805 steps:2666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 730: episode_reward:11.511680489955719 steps:2668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 731: episode_reward:-7.550870475315857 steps:2669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 732: episode_reward:5.142373353966134 steps:2671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 733: episode_reward:-6.002767145311131 steps:2673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 734: episode_reward:25.988823140094457 steps:2675[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66753
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 735: episode_reward:18.971349366961633 steps:2677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 736: episode_reward:38.988457394113475 steps:2679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 737: episode_reward:19.198528715784782 steps:2681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 738: episode_reward:-5.948487570085291 steps:2683[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 739: episode_reward:82.27779525028447 steps:2685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 740: episode_reward:9.711293014981123 steps:2687[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32238
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 741: episode_reward:12.707010650011863 steps:2689[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 742: episode_reward:3.8312927036864872 steps:2691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 743: episode_reward:8.316544778563307 steps:2693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 744: episode_reward:133.13879987269857 steps:2695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 745: episode_reward:4.139071362734951 steps:2697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 746: episode_reward:-3.392037345033271 steps:2699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56254
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 747: episode_reward:-2.0633714924411763 steps:2701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 748: episode_reward:6.320389777006143 steps:2703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 749: episode_reward:5.9547098944533605 steps:2705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 750: episode_reward:4.206638760908404 steps:2707[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 751: episode_reward:31.828306425710668 steps:2709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 752: episode_reward:13.866303408762406 steps:2711[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.43930
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 753: episode_reward:0.16238016872463046 steps:2713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 754: episode_reward:49.96067457039715 steps:2715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 755: episode_reward:70.59101835629329 steps:2717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 756: episode_reward:-2.4025584906793105 steps:2719[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 757: episode_reward:-0.5517266259779134 steps:2721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 758: episode_reward:-6.851783000496768 steps:2723[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59172
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 759: episode_reward:-1.7879495323595633 steps:2725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 760: episode_reward:-0.1868726258932618 steps:2727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 761: episode_reward:1.0550340758664567 steps:2729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 762: episode_reward:5.169385990209557 steps:2731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 763: episode_reward:8.559400173538355 steps:2733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 764: episode_reward:-1.5222628793278121 steps:2735[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70376
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 765: episode_reward:189.59423511818247 steps:2737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 766: episode_reward:1.4495122967682041 steps:2739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 767: episode_reward:30.420168421519502 steps:2741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 768: episode_reward:-2.365831739759643 steps:2743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 769: episode_reward:9.962985620109382 steps:2745[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 770: episode_reward:-7.902703778035288 steps:2747[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48033
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 771: episode_reward:43.20529722551383 steps:2749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 772: episode_reward:14.560762916813628 steps:2751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 773: episode_reward:0.4610581264186866 steps:2753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 774: episode_reward:279.76745701689464 steps:2755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 775: episode_reward:-1.7310926931326933 steps:2757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 776: episode_reward:3.7671950979895734 steps:2759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.15967
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 777: episode_reward:16.401382129984732 steps:2761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 778: episode_reward:-0.14346437507609844 steps:2763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 779: episode_reward:1.0317246066881753 steps:2765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 780: episode_reward:6.850627034046831 steps:2767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 781: episode_reward:539.9508014911579 steps:2769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 782: episode_reward:10.66827662871092 steps:2771[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52089
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 783: episode_reward:28.780780883975392 steps:2773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 784: episode_reward:-4.683277516460936 steps:2775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 785: episode_reward:-2.1592039996159142 steps:2777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 786: episode_reward:-2.189284057508938 steps:2779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 787: episode_reward:2.107535720497264 steps:2781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 788: episode_reward:1.7472706474315212 steps:2783[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31969
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 789: episode_reward:2.646871822070854 steps:2785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 790: episode_reward:-4.296633518905666 steps:2787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 791: episode_reward:2.4248741667176814 steps:2789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 792: episode_reward:30.31159834775871 steps:2791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 793: episode_reward:208.66811274979275 steps:2793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 794: episode_reward:-0.807811157809498 steps:2795[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49797
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 795: episode_reward:15.458350670700138 steps:2797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 796: episode_reward:60.356977566340326 steps:2799[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 797: episode_reward:6.497713970197312 steps:2801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 798: episode_reward:-1.5069252820893269 steps:2803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 799: episode_reward:4.402373193261353 steps:2805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 800: episode_reward:109.1347621888062 steps:2807[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48603
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 801: episode_reward:25.961958567779128 steps:2809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 802: episode_reward:60.55340852443194 steps:2811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 803: episode_reward:-0.9123408535889164 steps:2813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 804: episode_reward:1.0189655464461902 steps:2815[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 805: episode_reward:37.1677577962638 steps:2817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 806: episode_reward:7.381104586356928 steps:2819[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.10727
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 807: episode_reward:5.040960542322199 steps:2821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 808: episode_reward:369.5160597313999 steps:2823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 809: episode_reward:-0.4362007120655762 steps:2825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 810: episode_reward:-1.6047757754062362 steps:2827[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 811: episode_reward:3.1474097690729033 steps:2829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 812: episode_reward:7.926032431296039 steps:2831[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56451
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 813: episode_reward:11.827314654741057 steps:2833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 814: episode_reward:-1.173732229956538 steps:2835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 815: episode_reward:6.440402823932465 steps:2837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 816: episode_reward:4.953249004382973 steps:2839[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 817: episode_reward:6.048718576393404 steps:2841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 818: episode_reward:-9.411366751647138 steps:2843[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27986
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 819: episode_reward:32.802996715405094 steps:2845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 820: episode_reward:9.39744841895105 steps:2847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 821: episode_reward:-1.9964683344182417 steps:2849[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 822: episode_reward:5.965746695838099 steps:2851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 823: episode_reward:142.46957319824293 steps:2853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 824: episode_reward:26.50192622617723 steps:2855[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.15747
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 825: episode_reward:1.3714930314137908 steps:2857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 826: episode_reward:238.34515686416705 steps:2859[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 827: episode_reward:0.4992309598018485 steps:2861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 828: episode_reward:5.981896401091268 steps:2863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 829: episode_reward:4.632822059030357 steps:2865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 830: episode_reward:-1.674632935491711 steps:2867[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.22531
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 831: episode_reward:8.599658168883026 steps:2869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 832: episode_reward:-2.3713846828942815 steps:2871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 833: episode_reward:16.558479642504984 steps:2873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 834: episode_reward:5.21399449143094 steps:2875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 835: episode_reward:-3.1636896028753205 steps:2877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 836: episode_reward:-6.796273142051557 steps:2879[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57387
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 837: episode_reward:-2.737380061546829 steps:2881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 838: episode_reward:3.5977294038222265 steps:2883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 839: episode_reward:-2.317702603178913 steps:2885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 840: episode_reward:6.008056734021054 steps:2887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 841: episode_reward:20.1834536998493 steps:2889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 842: episode_reward:43.511550943279744 steps:2891[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50197
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 843: episode_reward:223.3593945470388 steps:2893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 844: episode_reward:3.3440449883891077 steps:2895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 845: episode_reward:10.879623832670093 steps:2897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 846: episode_reward:467.32564324755765 steps:2899[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 847: episode_reward:57.98127397923817 steps:2901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 848: episode_reward:46.16672815659762 steps:2903[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.02571
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 849: episode_reward:5.0681870021841915 steps:2905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 850: episode_reward:4.102528015222616 steps:2907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 851: episode_reward:-0.27305755609662175 steps:2909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 852: episode_reward:-0.4318349557687604 steps:2911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 853: episode_reward:5.7818148249748305 steps:2913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 854: episode_reward:0.6637971355516319 steps:2915[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49573
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 855: episode_reward:-0.5223915572836053 steps:2917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 856: episode_reward:53.333816755816194 steps:2919[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 857: episode_reward:3.3850497588929067 steps:2921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 858: episode_reward:-0.48124592329367744 steps:2923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 859: episode_reward:-1.1985960020242905 steps:2925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 860: episode_reward:-7.019490539108981 steps:2927[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.04078
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 861: episode_reward:-0.7161379774539358 steps:2929[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 862: episode_reward:-1.5231233472175996 steps:2931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 863: episode_reward:1.5359891654785498 steps:2933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 864: episode_reward:9.105613100913018 steps:2935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 865: episode_reward:0.0990331411337455 steps:2937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 866: episode_reward:21.52446901012716 steps:2939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.86915
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 867: episode_reward:-4.502518628331184 steps:2941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 868: episode_reward:-4.4591543015387956 steps:2943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 869: episode_reward:63.58283004009478 steps:2945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 870: episode_reward:-0.7272992501535156 steps:2947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 871: episode_reward:2.0975874721542342 steps:2949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 872: episode_reward:6.269062010774254 steps:2951[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55170
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 873: episode_reward:5.952424120765059 steps:2953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 874: episode_reward:1.8710583788072048 steps:2955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 875: episode_reward:4.156059977148477 steps:2957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 876: episode_reward:-0.2727207728132295 steps:2959[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 877: episode_reward:12.346802962696817 steps:2961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 878: episode_reward:34.96527585141145 steps:2963[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75758
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 879: episode_reward:-0.37175653917769536 steps:2965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 880: episode_reward:-3.7481700347564755 steps:2967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 881: episode_reward:1.2644870104820125 steps:2969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 882: episode_reward:-2.484029984301369 steps:2971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 883: episode_reward:0.39886018528308753 steps:2973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 884: episode_reward:-0.9273766063173356 steps:2975[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.19834
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 885: episode_reward:3.0537767207580453 steps:2977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 886: episode_reward:0.7316628156795923 steps:2979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 887: episode_reward:4.849655060590901 steps:2981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 888: episode_reward:1.6794587867447746 steps:2983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 889: episode_reward:8.319658828776706 steps:2985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 890: episode_reward:27.769069071269126 steps:2987[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52592
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 891: episode_reward:73.36594535035731 steps:2989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 892: episode_reward:9.40978310015167 steps:2991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 893: episode_reward:-4.660416556986543 steps:2993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 894: episode_reward:-1.3647151133855715 steps:2995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 895: episode_reward:-1.2776314598813592 steps:2997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 896: episode_reward:-0.8816185130134269 steps:2999[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.85297
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 897: episode_reward:4.070252648507214 steps:3001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 898: episode_reward:11.124876784235441 steps:3003[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 899: episode_reward:0.5397745006454988 steps:3005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 900: episode_reward:10.788135657204945 steps:3007[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 901: episode_reward:-2.645764107247799 steps:3009[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 902: episode_reward:10.26972442014873 steps:3011[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54747
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 903: episode_reward:-1.5191423709412342 steps:3013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 904: episode_reward:-3.1209571549300343 steps:3015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 905: episode_reward:42.448135616321586 steps:3017[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 906: episode_reward:65.39516522903848 steps:3019[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 907: episode_reward:6.407472091254285 steps:3021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 908: episode_reward:2.2986474560506034 steps:3023[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57265
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 909: episode_reward:-2.754607470299497 steps:3025[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 910: episode_reward:3.3063495022995113 steps:3027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 911: episode_reward:-3.765806554214689 steps:3029[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 912: episode_reward:-2.3539154466898733 steps:3031[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 913: episode_reward:-2.5672746821977954 steps:3033[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 914: episode_reward:13.544042229748559 steps:3035[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62783
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 915: episode_reward:2.672675611126664 steps:3037[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 916: episode_reward:-1.417493841490439 steps:3039[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 917: episode_reward:2.1264664657802603 steps:3041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 918: episode_reward:-0.8679074581550026 steps:3043[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 919: episode_reward:0.24107691831200073 steps:3045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 920: episode_reward:-2.6816299221118545 steps:3047[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13545
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 921: episode_reward:-0.6762277208904051 steps:3049[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 922: episode_reward:15.793978997022219 steps:3051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 923: episode_reward:0.5471526566484677 steps:3053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 924: episode_reward:10.43157061394719 steps:3055[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 925: episode_reward:-2.638839772146926 steps:3057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 926: episode_reward:5.108004237391891 steps:3059[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.20407
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 927: episode_reward:-7.678202859653562 steps:3061[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 928: episode_reward:-4.338770424234759 steps:3063[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 929: episode_reward:120.32642744453292 steps:3065[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 930: episode_reward:-0.29692309122743765 steps:3067[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 931: episode_reward:280.22373329690134 steps:3069[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 932: episode_reward:2.232997982089284 steps:3071[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35166
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 933: episode_reward:12.947654654836423 steps:3073[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 934: episode_reward:-3.502036242703492 steps:3075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 935: episode_reward:-1.590473740778569 steps:3077[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 936: episode_reward:4.306814766540348 steps:3079[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 937: episode_reward:23.667947785905582 steps:3081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 938: episode_reward:89.97757942350951 steps:3083[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.22640
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 939: episode_reward:-0.9175693103026337 steps:3085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 940: episode_reward:-1.721050799265698 steps:3087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 941: episode_reward:103.47885230238204 steps:3089[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 942: episode_reward:-0.2551697482459523 steps:3091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 943: episode_reward:5.573235543807584 steps:3093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 944: episode_reward:1.7928064226210227 steps:3095[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70473
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 945: episode_reward:16.596866772606628 steps:3097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 946: episode_reward:10.188897379744112 steps:3099[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 947: episode_reward:2.3286596213553077 steps:3101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 948: episode_reward:47.47577243086093 steps:3103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 949: episode_reward:-0.10766834389733804 steps:3105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 950: episode_reward:7.024092487636352 steps:3107[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36151
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 951: episode_reward:489.1987361698193 steps:3109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 952: episode_reward:6.109989237860897 steps:3111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 953: episode_reward:-0.2296383952182861 steps:3113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 954: episode_reward:-4.09108084633377 steps:3115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 955: episode_reward:30.903099008972504 steps:3117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 956: episode_reward:-1.9857619506078104 steps:3119[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36392
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 957: episode_reward:6.712106733253334 steps:3121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 958: episode_reward:2.9647784735152385 steps:3123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 959: episode_reward:-0.8097562939226042 steps:3125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 960: episode_reward:14.583862126922732 steps:3127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 961: episode_reward:18.909775621446077 steps:3129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 962: episode_reward:3.583880316250536 steps:3131[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81825
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 963: episode_reward:-5.021295475399846 steps:3133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 964: episode_reward:-0.11256877575484525 steps:3135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 965: episode_reward:2.55381743546669 steps:3137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 966: episode_reward:42.588048162591036 steps:3139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 967: episode_reward:4.247249029578132 steps:3141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 968: episode_reward:-5.809043245413439 steps:3143[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01285
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 969: episode_reward:3.603798219614414 steps:3145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 970: episode_reward:7.448299175069174 steps:3147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 971: episode_reward:10.591462624783782 steps:3149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 972: episode_reward:3.972713004243089 steps:3151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 973: episode_reward:-7.050612480565106 steps:3153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 974: episode_reward:2.5541411389386033 steps:3155[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.28952
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 975: episode_reward:60.794961182393 steps:3157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 976: episode_reward:1.1492936644660472 steps:3159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 977: episode_reward:15.567016556885937 steps:3161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 978: episode_reward:9.11992132690363 steps:3163[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 979: episode_reward:-9.268077386394662 steps:3165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 980: episode_reward:0.6460753860807062 steps:3167[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13332
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 981: episode_reward:22.711657070352196 steps:3169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 982: episode_reward:11.536862602578559 steps:3171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 983: episode_reward:5.8122632753161625 steps:3173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 984: episode_reward:1.742459758745285 steps:3175[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 985: episode_reward:-2.0084353076628894 steps:3177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 986: episode_reward:5.032809879409289 steps:3179[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32433
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 987: episode_reward:-0.575435452710491 steps:3181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 988: episode_reward:2.5844500515038784 steps:3183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 989: episode_reward:4.615518304148379 steps:3185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 990: episode_reward:8.643632416180637 steps:3187[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 991: episode_reward:74.76426385577972 steps:3189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 992: episode_reward:3.515501756736374 steps:3191[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34283
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 993: episode_reward:7.403628807109578 steps:3193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 994: episode_reward:3.638623509440588 steps:3195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 995: episode_reward:2.1241661128202054 steps:3197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 996: episode_reward:-1.9627872611151822 steps:3199[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 997: episode_reward:2.0972217012704384 steps:3201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 998: episode_reward:-15.823153478019359 steps:3203[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48935
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 999: episode_reward:9.972587642347683 steps:3205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1000: episode_reward:1013.7057843436971 steps:3207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1001: episode_reward:7.891959911509941 steps:3209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1002: episode_reward:5.870929333516498 steps:3211[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1003: episode_reward:175.58426559057114 steps:3213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1004: episode_reward:-1.1923516991501788 steps:3215[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18499
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1005: episode_reward:9.910124511875921 steps:3217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1006: episode_reward:10.07392497517404 steps:3219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1007: episode_reward:9.700891041141798 steps:3221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1008: episode_reward:-2.9143355901137946 steps:3223[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1009: episode_reward:-5.8101068629469825 steps:3225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1010: episode_reward:-2.634178562171945 steps:3227[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.33614
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1011: episode_reward:-0.2120464936261408 steps:3229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1012: episode_reward:4.256852370492754 steps:3231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1013: episode_reward:9.394688180728991 steps:3233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1014: episode_reward:12.43033712133597 steps:3235[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1015: episode_reward:81.25627285557134 steps:3237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1016: episode_reward:14.606872772516965 steps:3239[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.82413
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1017: episode_reward:-5.247896530660873 steps:3241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1018: episode_reward:6.96138798930771 steps:3243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1019: episode_reward:2.104219043988409 steps:3245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1020: episode_reward:10.837842789233228 steps:3247[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1021: episode_reward:-1.313795506847252 steps:3249[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1022: episode_reward:2.0120887105154086 steps:3251[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77140
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1023: episode_reward:-1.4990640372881017 steps:3253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1024: episode_reward:2.214783960193822 steps:3255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1025: episode_reward:9.795698030855567 steps:3257[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1026: episode_reward:-0.773719231308454 steps:3259[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1027: episode_reward:4.754033508909241 steps:3261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1028: episode_reward:3.296076294510989 steps:3263[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.19715
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1029: episode_reward:4.007641592552755 steps:3265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1030: episode_reward:-1.0138593373693918 steps:3267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1031: episode_reward:4.237594139991358 steps:3269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1032: episode_reward:4.1938276825453045 steps:3271[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1033: episode_reward:57.33292866723645 steps:3273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1034: episode_reward:2.364703127982325 steps:3275[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52040
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1035: episode_reward:-0.11573437715524149 steps:3277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1036: episode_reward:14.918547663325732 steps:3279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1037: episode_reward:-0.8140424916975908 steps:3281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1038: episode_reward:11.004512556891125 steps:3283[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1039: episode_reward:26.634944223576543 steps:3285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1040: episode_reward:26.197146311050922 steps:3287[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78915
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1041: episode_reward:-4.890268998529838 steps:3289[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1042: episode_reward:-5.119910013995408 steps:3291[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1043: episode_reward:-0.10692045355768309 steps:3293[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1044: episode_reward:26.89811802297897 steps:3295[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1045: episode_reward:9.133182758762153 steps:3297[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1046: episode_reward:-1.0605949419593323 steps:3299[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62755
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1047: episode_reward:-0.48766928559023626 steps:3301[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1048: episode_reward:-7.232528768595248 steps:3303[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1049: episode_reward:3.735463965944065 steps:3305[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1050: episode_reward:2.0857585437119806 steps:3307[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1051: episode_reward:11.52633857262975 steps:3309[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1052: episode_reward:7.206208418017631 steps:3311[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.96741
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1053: episode_reward:3.3874467828373303 steps:3313[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1054: episode_reward:27.014305275580817 steps:3315[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1055: episode_reward:-0.5146331852742434 steps:3317[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1056: episode_reward:33.514792053990725 steps:3319[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1057: episode_reward:6.341219090788693 steps:3321[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1058: episode_reward:-6.548222898319638 steps:3323[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.15343
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1059: episode_reward:3.6507362249535102 steps:3325[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1060: episode_reward:71.19133944938432 steps:3327[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1061: episode_reward:-1.2904320961853326 steps:3329[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1062: episode_reward:1.1975663801951861 steps:3331[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1063: episode_reward:0.24406049272012398 steps:3333[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1064: episode_reward:-0.7080401323251992 steps:3335[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23846
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1065: episode_reward:-2.0055510086116803 steps:3337[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1066: episode_reward:12.033494064268066 steps:3339[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1067: episode_reward:-4.131060647185421 steps:3341[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1068: episode_reward:5.7975473218099545 steps:3343[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1069: episode_reward:81.65663764674196 steps:3345[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1070: episode_reward:0.4817746801317506 steps:3347[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41322
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1071: episode_reward:3.931872236518926 steps:3349[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1072: episode_reward:15.576346410740793 steps:3351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1073: episode_reward:12.817668069785926 steps:3353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1074: episode_reward:2.5880278637874645 steps:3355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1075: episode_reward:2.5838377888612962 steps:3357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1076: episode_reward:3.6051910386250716 steps:3359[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29313
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1077: episode_reward:23.753419092918367 steps:3361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1078: episode_reward:10.727646128575604 steps:3363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1079: episode_reward:0.6039952489159508 steps:3365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1080: episode_reward:0.6604903216690863 steps:3367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1081: episode_reward:31.476771553940633 steps:3369[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1082: episode_reward:6.290380819850291 steps:3371[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67729
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1083: episode_reward:1.1013411397067467 steps:3373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1084: episode_reward:16.31410008426722 steps:3375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1085: episode_reward:-1.7090605808049903 steps:3377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1086: episode_reward:30.34710655496579 steps:3379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1087: episode_reward:-0.97581891112605 steps:3381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1088: episode_reward:25.841095392190446 steps:3383[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.05124
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1089: episode_reward:63.33770149462641 steps:3385[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1090: episode_reward:15.148679052912359 steps:3387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1091: episode_reward:-1.3893137379277225 steps:3389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1092: episode_reward:1.8283060273295906 steps:3391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1093: episode_reward:-6.345487730118995 steps:3393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1094: episode_reward:0.12382804504439715 steps:3395[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46586
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1095: episode_reward:0.45688035530830184 steps:3397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1096: episode_reward:31.510321956300736 steps:3399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1097: episode_reward:7.580325572052454 steps:3401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1098: episode_reward:6.341865542607904 steps:3403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1099: episode_reward:113.85041567815193 steps:3405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1100: episode_reward:5.968284306433269 steps:3407[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46374
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1101: episode_reward:-0.4041427327599365 steps:3409[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1102: episode_reward:-3.1829236800535865 steps:3411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1103: episode_reward:4.273377950711622 steps:3413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1104: episode_reward:49.53303393041509 steps:3415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1105: episode_reward:1.1411652264712986 steps:3417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1106: episode_reward:15.490132644060353 steps:3419[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.91797
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1107: episode_reward:24.050096981791842 steps:3421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1108: episode_reward:35.425388788054185 steps:3423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1109: episode_reward:10.304312667934104 steps:3425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1110: episode_reward:4.263563763569819 steps:3427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1111: episode_reward:11.245789270132798 steps:3429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1112: episode_reward:2.307705183634873 steps:3431[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.98885
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1113: episode_reward:6.59495176248809 steps:3433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1114: episode_reward:32.5238266254025 steps:3435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1115: episode_reward:-0.9132865872852283 steps:3437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1116: episode_reward:5.1129130914678615 steps:3439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1117: episode_reward:5.555022732915834 steps:3441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1118: episode_reward:10.455381251143827 steps:3443[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30133
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1119: episode_reward:9.534835252963033 steps:3445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1120: episode_reward:-0.8989736437681981 steps:3447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1121: episode_reward:0.5631014858717185 steps:3449[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1122: episode_reward:14.121363876466967 steps:3451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1123: episode_reward:1399.0139346271674 steps:3453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1124: episode_reward:21.90142000806276 steps:3455[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67368
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1125: episode_reward:6.020655866955645 steps:3457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1126: episode_reward:15.01566460876375 steps:3459[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1127: episode_reward:1.9496885894235216 steps:3461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1128: episode_reward:12.700534906529246 steps:3463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1129: episode_reward:-0.9168107256558735 steps:3465[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1130: episode_reward:-1.981018805249494 steps:3467[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29878
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1131: episode_reward:-2.173617475474834 steps:3469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1132: episode_reward:143.77784409496772 steps:3471[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1133: episode_reward:1.3229790439407032 steps:3473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1134: episode_reward:18.504208340208045 steps:3475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1135: episode_reward:6.472798949775538 steps:3477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1136: episode_reward:17.910788848982104 steps:3479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93235
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1137: episode_reward:-5.970353901183106 steps:3481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1138: episode_reward:5.339296775275095 steps:3483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1139: episode_reward:-0.7820945583004435 steps:3485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1140: episode_reward:1511.7339172244472 steps:3487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1141: episode_reward:94.71679860851528 steps:3489[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1142: episode_reward:-1.2318977548695211 steps:3491[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56403
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1143: episode_reward:10.237966455941242 steps:3493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1144: episode_reward:-2.135156547629617 steps:3495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1145: episode_reward:12.33709047917619 steps:3497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1146: episode_reward:0.017752080306960405 steps:3499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1147: episode_reward:0.03767307342145099 steps:3501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1148: episode_reward:5.7444904211342624 steps:3503[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.23959
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1149: episode_reward:0.6000162806124014 steps:3505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1150: episode_reward:101.2459750861619 steps:3507[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1151: episode_reward:11.051050342692472 steps:3509[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1152: episode_reward:0.8178318175150268 steps:3511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1153: episode_reward:3.966189039259399 steps:3513[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1154: episode_reward:46.26229588470314 steps:3515[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.03938
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1155: episode_reward:-1.8049811375286582 steps:3517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1156: episode_reward:-7.40118436581146 steps:3519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1157: episode_reward:175.17130888952855 steps:3521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1158: episode_reward:-1.264496760089285 steps:3523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1159: episode_reward:834.7572753602882 steps:3525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1160: episode_reward:8.157197033662387 steps:3527[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.30916
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1161: episode_reward:1.7872849833664564 steps:3529[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1162: episode_reward:0.42539780443803954 steps:3531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1163: episode_reward:-1.7051582238728717 steps:3533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1164: episode_reward:3.20568263000906 steps:3535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1165: episode_reward:37.60273250237047 steps:3537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1166: episode_reward:28.681673365347375 steps:3539[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01127
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1167: episode_reward:-0.8108695162607717 steps:3541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1168: episode_reward:-0.04022810191893322 steps:3543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1169: episode_reward:132.02338772544223 steps:3545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1170: episode_reward:-3.668135984065296 steps:3547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1171: episode_reward:6.851863667655824 steps:3549[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1172: episode_reward:5.119209335987973 steps:3551[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.16059
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1173: episode_reward:2.58121412370532 steps:3553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1174: episode_reward:20.485295975312727 steps:3555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1175: episode_reward:2.5184534190335075 steps:3557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1176: episode_reward:36.39401378189623 steps:3559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1177: episode_reward:-6.633433606626084 steps:3561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1178: episode_reward:-1.1872828166869995 steps:3563[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.42814
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1179: episode_reward:-1.2310831246549139 steps:3565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1180: episode_reward:1.1436706805623524 steps:3567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1181: episode_reward:117.77082570563303 steps:3569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1182: episode_reward:1.0240894630583979 steps:3571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1183: episode_reward:109.20609267087451 steps:3573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1184: episode_reward:-0.43298792291843524 steps:3575[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46120
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1185: episode_reward:4.555058098667473 steps:3577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1186: episode_reward:0.09731399970205734 steps:3579[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1187: episode_reward:29.260161664651733 steps:3581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1188: episode_reward:6.097458684729963 steps:3583[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1189: episode_reward:7.46250965065884 steps:3585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1190: episode_reward:2.7096025750525676 steps:3587[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27695
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1191: episode_reward:3.427701956352374 steps:3589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1192: episode_reward:-3.0144198426542186 steps:3591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1193: episode_reward:10.672706839758892 steps:3593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1194: episode_reward:10.270485547384578 steps:3595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1195: episode_reward:11.570263736306996 steps:3597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1196: episode_reward:-7.616982036556692 steps:3599[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93542
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1197: episode_reward:-2.191115583360803 steps:3601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1198: episode_reward:-1.0776503133113084 steps:3603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1199: episode_reward:8.579551983776739 steps:3605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1200: episode_reward:-1.1699582494231069 steps:3607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1201: episode_reward:0.4957496309705447 steps:3609[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1202: episode_reward:237.01376093825814 steps:3611[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56637
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1203: episode_reward:5.4663056638808865 steps:3613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1204: episode_reward:16.45584795625244 steps:3615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1205: episode_reward:8.241756650485074 steps:3617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1206: episode_reward:5.2862828745391655 steps:3619[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1207: episode_reward:-0.006212591913291821 steps:3621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1208: episode_reward:343.48942602674117 steps:3623[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31218
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1209: episode_reward:1.7378009832455108 steps:3625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1210: episode_reward:-3.7844786943551507 steps:3627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1211: episode_reward:6.9558378680929005 steps:3629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1212: episode_reward:-2.3479684156378884 steps:3631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1213: episode_reward:-1.0860491807564985 steps:3633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1214: episode_reward:-0.4445578310611613 steps:3635[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90662
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1215: episode_reward:5.152445631739342 steps:3637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1216: episode_reward:5.149181359453394 steps:3639[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1217: episode_reward:-6.93583502248082 steps:3641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1218: episode_reward:2.5348968062598516 steps:3643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1219: episode_reward:25.898599647712505 steps:3645[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1220: episode_reward:10.133569376387271 steps:3647[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55928
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1221: episode_reward:-2.5076648326402013 steps:3649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1222: episode_reward:12.879871309130197 steps:3651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1223: episode_reward:728.5853397217494 steps:3653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1224: episode_reward:4.910472163283387 steps:3655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1225: episode_reward:38.421119285179024 steps:3657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1226: episode_reward:30.015887641541347 steps:3659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54490
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1227: episode_reward:1.7088377228818201 steps:3661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1228: episode_reward:2.4923039325824003 steps:3663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1229: episode_reward:10.539912075372726 steps:3665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1230: episode_reward:-6.605260037798201 steps:3667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1231: episode_reward:-7.2459326782829265 steps:3669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1232: episode_reward:10.970316926722914 steps:3671[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.42148
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1233: episode_reward:49.46816301585108 steps:3673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1234: episode_reward:5.965726412596681 steps:3675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1235: episode_reward:3.321772090886954 steps:3677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1236: episode_reward:48.9308755667711 steps:3679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1237: episode_reward:24.016025678050205 steps:3681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1238: episode_reward:3.812595375840752 steps:3683[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.96407
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1239: episode_reward:9.850283490232759 steps:3685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1240: episode_reward:-1.8376379443541868 steps:3687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1241: episode_reward:4.689657488922198 steps:3689[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1242: episode_reward:-3.361440901487605 steps:3691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1243: episode_reward:4.676722643681426 steps:3693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1244: episode_reward:6.892723580490493 steps:3695[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48664
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1245: episode_reward:9.105418037309658 steps:3697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1246: episode_reward:1.5063763254152769 steps:3699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1247: episode_reward:13.481603459468312 steps:3701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1248: episode_reward:8.097182232056443 steps:3703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1249: episode_reward:21.612715486843598 steps:3705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1250: episode_reward:30.351494027604797 steps:3707[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48174
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1251: episode_reward:4.465148070301739 steps:3709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1252: episode_reward:55.245869084714116 steps:3711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1253: episode_reward:5.482589021760347 steps:3713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1254: episode_reward:8.611019693533112 steps:3715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1255: episode_reward:-3.611605680290398 steps:3717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1256: episode_reward:11.864039361396372 steps:3719[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69055
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1257: episode_reward:0.9994660151913943 steps:3721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1258: episode_reward:-1.7824050419267623 steps:3723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1259: episode_reward:0.2822669912991831 steps:3725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1260: episode_reward:2.0175536088272814 steps:3727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1261: episode_reward:-5.619977960593191 steps:3729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1262: episode_reward:0.49935385822768374 steps:3731[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39445
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1263: episode_reward:0.9309125533679636 steps:3733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1264: episode_reward:317.6621595014795 steps:3735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1265: episode_reward:1448.1747105142385 steps:3737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1266: episode_reward:13.125098343328293 steps:3739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1267: episode_reward:-1.2718847425006157 steps:3741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1268: episode_reward:9.362297778327633 steps:3743[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72735
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1269: episode_reward:-0.40971828574144986 steps:3745[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1270: episode_reward:41.492017596364846 steps:3747[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1271: episode_reward:0.6267056206355575 steps:3749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1272: episode_reward:6.141583288503818 steps:3751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1273: episode_reward:16.550281739285346 steps:3753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1274: episode_reward:33.067088278250964 steps:3755[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.06699
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1275: episode_reward:-5.426047003039885 steps:3757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1276: episode_reward:4.739194618782214 steps:3759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1277: episode_reward:1.9637770550714553 steps:3761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1278: episode_reward:10.556541324327586 steps:3763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1279: episode_reward:0.9633383525901911 steps:3765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1280: episode_reward:244.0591333830444 steps:3767[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.60372
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1281: episode_reward:-0.9021249752568063 steps:3769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1282: episode_reward:219.7261251376596 steps:3771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1283: episode_reward:0.10150541649105627 steps:3773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1284: episode_reward:46.744060896549925 steps:3775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1285: episode_reward:-1.159438370336205 steps:3777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1286: episode_reward:-2.2736131136580746 steps:3779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75102
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1287: episode_reward:-1.161542058403062 steps:3781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1288: episode_reward:1.5822184666671988 steps:3783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1289: episode_reward:-0.3134301592230586 steps:3785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1290: episode_reward:-1.4504139160768998 steps:3787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1291: episode_reward:7.038780959213815 steps:3789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1292: episode_reward:7.439173258468392 steps:3791[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39154
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1293: episode_reward:9.973488980769224 steps:3793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1294: episode_reward:2.6613626364042426 steps:3795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1295: episode_reward:-5.5240887665358605 steps:3797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1296: episode_reward:-3.228701042261406 steps:3799[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1297: episode_reward:66.39795641954304 steps:3801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1298: episode_reward:0.026075394586864586 steps:3803[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77625
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1299: episode_reward:0.743351013006524 steps:3805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1300: episode_reward:7.563838289628469 steps:3807[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1301: episode_reward:0.5487756829849437 steps:3809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1302: episode_reward:-9.544849912078504 steps:3811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1303: episode_reward:6.110030462610908 steps:3813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1304: episode_reward:41.36630789298057 steps:3815[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.47828
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1305: episode_reward:-0.8345128666211026 steps:3817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1306: episode_reward:1.4237165450517786 steps:3819[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1307: episode_reward:38.108778981594256 steps:3821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1308: episode_reward:15.63098652855392 steps:3823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1309: episode_reward:72.79723571605217 steps:3825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1310: episode_reward:140.69752401835288 steps:3827[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14399
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1311: episode_reward:51.787857962355076 steps:3829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1312: episode_reward:9.237209690994653 steps:3831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1313: episode_reward:-1.6421114659770233 steps:3833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1314: episode_reward:14.074778650248636 steps:3835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1315: episode_reward:35.45127717778704 steps:3837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1316: episode_reward:7.950276436701365 steps:3839[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.89228
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1317: episode_reward:1.9088208664354251 steps:3841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1318: episode_reward:-0.685820272454412 steps:3843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1319: episode_reward:-3.6562683359273302 steps:3845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1320: episode_reward:29.016068164089987 steps:3847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1321: episode_reward:24.754595028013668 steps:3849[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1322: episode_reward:4.2262079217098645 steps:3851[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90603
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1323: episode_reward:13.095762981767832 steps:3853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1324: episode_reward:-2.511826002623146 steps:3855[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1325: episode_reward:7.987143041181347 steps:3857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1326: episode_reward:-3.189858286223263 steps:3859[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1327: episode_reward:1.0813006536567542 steps:3861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1328: episode_reward:2.3836408266801588 steps:3863[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.72707
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1329: episode_reward:3.497688859906085 steps:3865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1330: episode_reward:143.24937077567878 steps:3867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1331: episode_reward:15.454799240237074 steps:3869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1332: episode_reward:57.91209457236372 steps:3871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1333: episode_reward:4.647619929383559 steps:3873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1334: episode_reward:-0.8529424440238855 steps:3875[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21710
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1335: episode_reward:29.056918788430515 steps:3877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1336: episode_reward:-2.278562053961905 steps:3879[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1337: episode_reward:8.443075465051155 steps:3881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1338: episode_reward:4.626974719802469 steps:3883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1339: episode_reward:50.634563299723744 steps:3885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1340: episode_reward:-6.734061998370642 steps:3887[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53457
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1341: episode_reward:10.492001033796203 steps:3889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1342: episode_reward:2.8034648407151703 steps:3891[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1343: episode_reward:8.365643490514193 steps:3893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1344: episode_reward:12.49075514001508 steps:3895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1345: episode_reward:0.1978353558424586 steps:3897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1346: episode_reward:-0.05267161680558097 steps:3899[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32499
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1347: episode_reward:1.1780461908322857 steps:3901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1348: episode_reward:18.514035447772347 steps:3903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1349: episode_reward:-1.5105548769865036 steps:3905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1350: episode_reward:1.6319830804911946 steps:3907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1351: episode_reward:-1.8584531504016988 steps:3909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1352: episode_reward:1.2667644450742626 steps:3911[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.36671
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1353: episode_reward:0.5723581146353274 steps:3913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1354: episode_reward:20.042296469464173 steps:3915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1355: episode_reward:0.734178518391154 steps:3917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1356: episode_reward:47.71869934629197 steps:3919[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1357: episode_reward:5.252898195056071 steps:3921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1358: episode_reward:20.556216000075892 steps:3923[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41232
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1359: episode_reward:1.4178586491829615 steps:3925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1360: episode_reward:14.191105141940895 steps:3927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1361: episode_reward:-0.487136480795372 steps:3929[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1362: episode_reward:-8.3456837206907 steps:3931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1363: episode_reward:35.40999507093499 steps:3933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1364: episode_reward:0.9183716670721038 steps:3935[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59011
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1365: episode_reward:27.22425101916605 steps:3937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1366: episode_reward:10.79515830413344 steps:3939[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1367: episode_reward:1.499613157069362 steps:3941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1368: episode_reward:-1.3570236224145635 steps:3943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1369: episode_reward:-7.818242254810203 steps:3945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1370: episode_reward:14.330474715866018 steps:3947[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39682
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1371: episode_reward:-0.7790809627519448 steps:3949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1372: episode_reward:16.166842535554267 steps:3951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1373: episode_reward:4.326855063674376 steps:3953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1374: episode_reward:4.114643991060604 steps:3955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1375: episode_reward:4.517126631484945 steps:3957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1376: episode_reward:-0.30659059453485193 steps:3959[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37426
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1377: episode_reward:0.3109455674294317 steps:3961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1378: episode_reward:3.276963039423218 steps:3963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1379: episode_reward:0.055079944589608854 steps:3965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1380: episode_reward:-0.6078230236912945 steps:3967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1381: episode_reward:1.930119711508513 steps:3969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1382: episode_reward:2.0188300213247468 steps:3971[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41394
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1383: episode_reward:-3.4580075136353265 steps:3973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1384: episode_reward:18.240086747182424 steps:3975[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1385: episode_reward:6.846764240437686 steps:3977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1386: episode_reward:13.174547448697227 steps:3979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1387: episode_reward:0.41077766153395645 steps:3981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1388: episode_reward:-1.9169202030533852 steps:3983[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50323
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1389: episode_reward:-5.310481742211165 steps:3985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1390: episode_reward:76.37386808221629 steps:3987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1391: episode_reward:-2.2505424918089245 steps:3989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1392: episode_reward:0.1406112373239048 steps:3991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1393: episode_reward:52.18426051034357 steps:3993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1394: episode_reward:4.841947177929137 steps:3995[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68024
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1395: episode_reward:26.586391752228657 steps:3997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1396: episode_reward:2.6298354673639337 steps:3999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1397: episode_reward:0.17964933079323364 steps:4001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1398: episode_reward:3.6417935571481697 steps:4003[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1399: episode_reward:4.861251061169227 steps:4005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1400: episode_reward:14.064618175456014 steps:4007[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53354
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1401: episode_reward:-6.349933884808282 steps:4009[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1402: episode_reward:-4.489965743402523 steps:4011[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1403: episode_reward:-4.6440520385145 steps:4013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1404: episode_reward:-0.9487929926964254 steps:4015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1405: episode_reward:-1.6888010878713957 steps:4017[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1406: episode_reward:2.719800546026868 steps:4019[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.92532
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1407: episode_reward:3.753450461827321 steps:4021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1408: episode_reward:6.22775937926747 steps:4023[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1409: episode_reward:15.139167392056468 steps:4025[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1410: episode_reward:3.1298047197609664 steps:4027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1411: episode_reward:9.74965959844975 steps:4029[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1412: episode_reward:1.662928830872537 steps:4031[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.60726
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1413: episode_reward:63.663163258496176 steps:4033[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1414: episode_reward:91.43746562190387 steps:4035[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1415: episode_reward:-2.467077537641857 steps:4037[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1416: episode_reward:-0.35460679335912415 steps:4039[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1417: episode_reward:-1.9884801571513657 steps:4041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1418: episode_reward:0.17476913395066118 steps:4043[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.08985
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1419: episode_reward:3.1231951261020097 steps:4045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1420: episode_reward:4.789430535940563 steps:4047[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1421: episode_reward:-1.2052495481838328 steps:4049[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1422: episode_reward:-0.42780634474331647 steps:4051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1423: episode_reward:8.123289923155019 steps:4053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1424: episode_reward:-1.481591581817315 steps:4055[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.34062
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1425: episode_reward:101.41521540626592 steps:4057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1426: episode_reward:1.1819656417457352 steps:4059[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1427: episode_reward:-1.7056383322245279 steps:4061[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1428: episode_reward:0.3384591304452913 steps:4063[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1429: episode_reward:12.453181290747098 steps:4065[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1430: episode_reward:-1.697876135349486 steps:4067[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08753
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1431: episode_reward:-3.6656935786449614 steps:4069[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1432: episode_reward:4.227957670733485 steps:4071[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1433: episode_reward:1.1614320143536174 steps:4073[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1434: episode_reward:6.300400350311726 steps:4075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1435: episode_reward:16.04164705517087 steps:4077[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1436: episode_reward:8.562542697566249 steps:4079[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31242
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1437: episode_reward:98.70469112468997 steps:4081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1438: episode_reward:3.186611822536564 steps:4083[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1439: episode_reward:9.864661737206166 steps:4085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1440: episode_reward:1.1830845240314867 steps:4087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1441: episode_reward:4.466018651531772 steps:4089[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1442: episode_reward:6.271820452414714 steps:4091[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68859
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1443: episode_reward:36.09904833834362 steps:4093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1444: episode_reward:9.016390313144305 steps:4095[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1445: episode_reward:-6.315865910618179 steps:4097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1446: episode_reward:0.8197597920654616 steps:4099[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1447: episode_reward:-2.429093322161056 steps:4101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1448: episode_reward:5.059518413340336 steps:4103[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85102
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1449: episode_reward:1.7029998826633483 steps:4105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1450: episode_reward:7.193471066500516 steps:4107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1451: episode_reward:5.354958415911141 steps:4109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1452: episode_reward:-1.2945064509250577 steps:4111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1453: episode_reward:-6.664226129308568 steps:4113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1454: episode_reward:-3.4456557143333826 steps:4115[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.00569
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1455: episode_reward:6.117335871944793 steps:4117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1456: episode_reward:5.611083666094767 steps:4119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1457: episode_reward:33.59501732353916 steps:4121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1458: episode_reward:-2.2693536809275754 steps:4123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1459: episode_reward:13.897092103769651 steps:4125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1460: episode_reward:3.5238956875936878 steps:4127[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62431
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1461: episode_reward:1.0723201910221132 steps:4129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1462: episode_reward:-0.9087268956209233 steps:4131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1463: episode_reward:7.713092987999369 steps:4133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1464: episode_reward:-1.4281922167302623 steps:4135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1465: episode_reward:-3.176140480321752 steps:4137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1466: episode_reward:-1.7667637025109868 steps:4139[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49119
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1467: episode_reward:-0.9821991340420668 steps:4141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1468: episode_reward:6.950604584067978 steps:4143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1469: episode_reward:-5.1275828205350305 steps:4145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1470: episode_reward:-1.6148776203589772 steps:4147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1471: episode_reward:213.7226538198774 steps:4149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1472: episode_reward:17.90369652605372 steps:4151[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30575
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1473: episode_reward:148.84653526593513 steps:4153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1474: episode_reward:14.510587146095496 steps:4155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1475: episode_reward:2.783873789580312 steps:4157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1476: episode_reward:-3.5759112831993014 steps:4159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1477: episode_reward:-0.25408568356404926 steps:4161[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1478: episode_reward:4.323438976587039 steps:4163[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85817
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1479: episode_reward:9.757091567796694 steps:4165[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1480: episode_reward:88.17802686087563 steps:4167[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1481: episode_reward:7.600674498625587 steps:4169[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1482: episode_reward:-1.3470222721266836 steps:4171[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1483: episode_reward:-1.1035342249903506 steps:4173[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1484: episode_reward:-1.8126001870049304 steps:4175[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.33392
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1485: episode_reward:5.854350778691238 steps:4177[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1486: episode_reward:-2.7728995663180447 steps:4179[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1487: episode_reward:7.225807516397531 steps:4181[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1488: episode_reward:9.605231309390533 steps:4183[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1489: episode_reward:4.0550950523582605 steps:4185[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1490: episode_reward:2.513149119065104 steps:4187[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56772
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1491: episode_reward:18.082854986862767 steps:4189[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1492: episode_reward:-1.4983368778095898 steps:4191[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1493: episode_reward:19.43389107029989 steps:4193[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1494: episode_reward:8.342773369323087 steps:4195[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1495: episode_reward:3.7772907148571413 steps:4197[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1496: episode_reward:24.377661571434146 steps:4199[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62375
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1497: episode_reward:31.857758517891718 steps:4201[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1498: episode_reward:8.717246515087599 steps:4203[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1499: episode_reward:1.6951968692107418 steps:4205[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1500: episode_reward:30.25964515519944 steps:4207[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1501: episode_reward:3.342804749173429 steps:4209[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1502: episode_reward:-6.543222305286298 steps:4211[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07303
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1503: episode_reward:-1.384262060099958 steps:4213[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1504: episode_reward:6.235943242682801 steps:4215[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1505: episode_reward:34.434669162531215 steps:4217[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1506: episode_reward:7.3482977358838975 steps:4219[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1507: episode_reward:11.792987555959979 steps:4221[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1508: episode_reward:-0.806515416802752 steps:4223[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.02903
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1509: episode_reward:10.818573696784618 steps:4225[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1510: episode_reward:0.20265399742100243 steps:4227[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1511: episode_reward:115.19967671503413 steps:4229[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1512: episode_reward:7.620845933782048 steps:4231[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1513: episode_reward:9.681381511023698 steps:4233[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1514: episode_reward:6.247522003967348 steps:4235[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24812
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1515: episode_reward:-2.667177131419911 steps:4237[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1516: episode_reward:-5.50702668062907 steps:4239[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1517: episode_reward:-5.081282137923388 steps:4241[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1518: episode_reward:5.73962661129932 steps:4243[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1519: episode_reward:-0.7055153362996416 steps:4245[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1520: episode_reward:21.949386618945052 steps:4247[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.00816
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1521: episode_reward:-0.6027503207708738 steps:4249[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1522: episode_reward:25.956879112220662 steps:4251[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1523: episode_reward:-2.2532997895437754 steps:4253[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1524: episode_reward:79.1853929924622 steps:4255[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1525: episode_reward:2.711609316354212 steps:4257[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1526: episode_reward:-4.495733818998613 steps:4259[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46093
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1527: episode_reward:-4.141083210940596 steps:4261[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1528: episode_reward:-4.331121454481344 steps:4263[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1529: episode_reward:-4.998087637858477 steps:4265[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1530: episode_reward:-5.627814147051197 steps:4267[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1531: episode_reward:-1.7312027250964257 steps:4269[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1532: episode_reward:3.1560845997827336 steps:4271[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78757
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1533: episode_reward:4.524518731654012 steps:4273[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1534: episode_reward:0.9972542749753339 steps:4275[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1535: episode_reward:-0.31756285787422867 steps:4277[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1536: episode_reward:20.703559893932987 steps:4279[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1537: episode_reward:67.34467829368856 steps:4281[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1538: episode_reward:-2.1525078598709126 steps:4283[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.38463
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1539: episode_reward:5.132661610983976 steps:4285[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1540: episode_reward:-5.829471838371621 steps:4286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1541: episode_reward:-1.3651810147933081 steps:4288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1542: episode_reward:11.174842041725693 steps:4290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1543: episode_reward:0.7379718523344723 steps:4292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1544: episode_reward:21.90448504684167 steps:4294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06364
[RDDPG] Episode Done
[92m [RDDPG] 1545: episode_reward:-1.2264536893920868 steps:4296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1546: episode_reward:1.3406324420031241 steps:4298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1547: episode_reward:0.15636633475967043 steps:4300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1548: episode_reward:1.4379421442176077 steps:4302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1549: episode_reward:26.202214384599777 steps:4304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1550: episode_reward:-4.281007572428253 steps:4306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70485
[RDDPG] Episode Done
[92m [RDDPG] 1551: episode_reward:-2.6145509273555945 steps:4308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1552: episode_reward:0.36520551330418005 steps:4310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1553: episode_reward:24.99814774911393 steps:4312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1554: episode_reward:-1.444930979453185 steps:4314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1555: episode_reward:28.484664679288247 steps:4316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1556: episode_reward:73.21079158123521 steps:4318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.82572
[RDDPG] Episode Done
[92m [RDDPG] 1557: episode_reward:11.793725548844728 steps:4320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1558: episode_reward:-7.659923946687716 steps:4322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1559: episode_reward:2.0379694041294285 steps:4324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1560: episode_reward:17.87237493650561 steps:4326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1561: episode_reward:-2.4372908464885894 steps:4328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1562: episode_reward:-7.655861673915934 steps:4330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58702
[RDDPG] Episode Done
[92m [RDDPG] 1563: episode_reward:8.462674286353174 steps:4332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1564: episode_reward:34.411515431363966 steps:4334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1565: episode_reward:16.552350937810168 steps:4336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1566: episode_reward:2.59181121752017 steps:4338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1567: episode_reward:6.54962372097361 steps:4340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1568: episode_reward:22.82064070664253 steps:4342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64623
[RDDPG] Episode Done
[92m [RDDPG] 1569: episode_reward:-2.4322927172301116 steps:4344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1570: episode_reward:8.828212146434948 steps:4346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1571: episode_reward:-2.263928505203723 steps:4348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1572: episode_reward:-0.1143619604550059 steps:4350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1573: episode_reward:8.404419061928568 steps:4352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1574: episode_reward:23.276664869045046 steps:4354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76310
[RDDPG] Episode Done
[92m [RDDPG] 1575: episode_reward:17.768079042883993 steps:4356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1576: episode_reward:21.54720410217128 steps:4358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1577: episode_reward:-1.1695071236654928 steps:4360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1578: episode_reward:-0.33445453528534186 steps:4362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1579: episode_reward:9.63500401430829 steps:4364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1580: episode_reward:4.8363196175126895 steps:4366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57019
[RDDPG] Episode Done
[92m [RDDPG] 1581: episode_reward:0.8131121721988452 steps:4368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1582: episode_reward:-3.0524113019114827 steps:4370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1583: episode_reward:4.7251286141715445 steps:4372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1584: episode_reward:6.415894144368883 steps:4374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1585: episode_reward:14.673753040050652 steps:4376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1586: episode_reward:-1.207931884073715 steps:4378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78899
[RDDPG] Episode Done
[92m [RDDPG] 1587: episode_reward:1.1711873283394807 steps:4380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1588: episode_reward:3.9840337337009784 steps:4382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1589: episode_reward:4.156721502796922 steps:4384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1590: episode_reward:1.0365104396880764 steps:4386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1591: episode_reward:2.8572506012849876 steps:4388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1592: episode_reward:9.648550229591642 steps:4390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.98889
[RDDPG] Episode Done
[92m [RDDPG] 1593: episode_reward:0.12643123802359124 steps:4392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1594: episode_reward:12.84975606217619 steps:4394[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1595: episode_reward:19.01321860795651 steps:4396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1596: episode_reward:-0.4327941526631651 steps:4398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1597: episode_reward:12.583380905064752 steps:4400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1598: episode_reward:1.2218529243244634 steps:4402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58617
[RDDPG] Episode Done
[92m [RDDPG] 1599: episode_reward:6.479883002684138 steps:4404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1600: episode_reward:6.913230786465391 steps:4406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1601: episode_reward:3.7175867001397216 steps:4408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1602: episode_reward:-2.274814071178598 steps:4410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1603: episode_reward:1.564109984722494 steps:4412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1604: episode_reward:14.81621572503494 steps:4414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.94331
[RDDPG] Episode Done
[92m [RDDPG] 1605: episode_reward:-0.01622775047303815 steps:4416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1606: episode_reward:19.580939898719485 steps:4418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1607: episode_reward:8.93655436351566 steps:4420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1608: episode_reward:0.8985171579846818 steps:4422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1609: episode_reward:0.4416733149488765 steps:4424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1610: episode_reward:-1.6638694678158852 steps:4426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.60816
[RDDPG] Episode Done
[92m [RDDPG] 1611: episode_reward:-7.80070407368811 steps:4428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1612: episode_reward:4141.757797962449 steps:4430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1613: episode_reward:7.24180823800726 steps:4432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1614: episode_reward:4.618425478086321 steps:4434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1615: episode_reward:-0.6922721044705806 steps:4436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1616: episode_reward:0.2841173689846528 steps:4438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53378
[RDDPG] Episode Done
[92m [RDDPG] 1617: episode_reward:14.355635714098769 steps:4440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1618: episode_reward:-1.039834218884601 steps:4442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1619: episode_reward:5.797402930599373 steps:4444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1620: episode_reward:-7.347020042127154 steps:4446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1621: episode_reward:5.906205061900303 steps:4448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1622: episode_reward:78.80366012560339 steps:4450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14717
[RDDPG] Episode Done
[92m [RDDPG] 1623: episode_reward:13.426599763361956 steps:4452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1624: episode_reward:10.868773807667434 steps:4454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1625: episode_reward:90.72444719583427 steps:4456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1626: episode_reward:-3.718957468345375 steps:4458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1627: episode_reward:-2.529884288138059 steps:4460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1628: episode_reward:-2.8905876699504276 steps:4462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.40415
[RDDPG] Episode Done
[92m [RDDPG] 1629: episode_reward:5.855876328866576 steps:4464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1630: episode_reward:1.1002332339035559 steps:4466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1631: episode_reward:2.0693547943607395 steps:4468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1632: episode_reward:-5.697793864526343 steps:4470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1633: episode_reward:-2.780044166792922 steps:4472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1634: episode_reward:-4.089892840810076 steps:4474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.32686
[RDDPG] Episode Done
[92m [RDDPG] 1635: episode_reward:-6.568057390653346 steps:4476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1636: episode_reward:16.3538531536616 steps:4478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1637: episode_reward:2.284034580317501 steps:4480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1638: episode_reward:2.526152307071345 steps:4482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1639: episode_reward:1.1333612303572682 steps:4484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1640: episode_reward:22.226232944117765 steps:4486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68489
[RDDPG] Episode Done
[92m [RDDPG] 1641: episode_reward:62.17448559782904 steps:4488[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1642: episode_reward:0.5376378424478485 steps:4490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1643: episode_reward:-0.9590447765121679 steps:4492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1644: episode_reward:-2.2543303931337295 steps:4494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1645: episode_reward:514.9281119241523 steps:4496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1646: episode_reward:-1.9565022607492553 steps:4498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90230
[RDDPG] Episode Done
[92m [RDDPG] 1647: episode_reward:7.085527922589392 steps:4500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1648: episode_reward:9.82827395306075 steps:4502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1649: episode_reward:15.008582738644657 steps:4504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1650: episode_reward:29.732274599878348 steps:4506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1651: episode_reward:1.7184600252340436 steps:4508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1652: episode_reward:11.378243843629708 steps:4510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.74177
[RDDPG] Episode Done
[92m [RDDPG] 1653: episode_reward:1.1348642558202302 steps:4512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1654: episode_reward:3.0602528638609634 steps:4514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1655: episode_reward:-4.080951312688099 steps:4516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1656: episode_reward:0.23223377757366048 steps:4518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1657: episode_reward:-1.2004294231260393 steps:4520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1658: episode_reward:213.60356424101514 steps:4522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35487
[RDDPG] Episode Done
[92m [RDDPG] 1659: episode_reward:-1.2333032518373788 steps:4524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1660: episode_reward:2.6950822854111616 steps:4526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1661: episode_reward:-1.8019341359559728 steps:4528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1662: episode_reward:-1.65274446142379 steps:4530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1663: episode_reward:179.23125103188048 steps:4532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1664: episode_reward:26.41462800939032 steps:4534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.10954
[RDDPG] Episode Done
[92m [RDDPG] 1665: episode_reward:56.50722949377474 steps:4536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1666: episode_reward:7.84535972062243 steps:4538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1667: episode_reward:-2.7668500978105466 steps:4540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1668: episode_reward:62.259515780916544 steps:4542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1669: episode_reward:12.25398174051368 steps:4544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1670: episode_reward:0.005165636428742015 steps:4546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.83213
[RDDPG] Episode Done
[92m [RDDPG] 1671: episode_reward:46.92020549471046 steps:4548[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1672: episode_reward:34.52928424031589 steps:4550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1673: episode_reward:1.712704162505465 steps:4552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1674: episode_reward:1.2855350237119336 steps:4554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1675: episode_reward:-0.05544101434773019 steps:4556[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1676: episode_reward:1.563738369224716 steps:4558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.97161
[RDDPG] Episode Done
[92m [RDDPG] 1677: episode_reward:11.977081132507458 steps:4560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1678: episode_reward:7.713601270008996 steps:4562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1679: episode_reward:1.7065251336620473 steps:4564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1680: episode_reward:-3.3942203922112464 steps:4566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1681: episode_reward:1.4708463506548521 steps:4568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1682: episode_reward:-0.43991687861659834 steps:4570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.20280
[RDDPG] Episode Done
[92m [RDDPG] 1683: episode_reward:53.2058321915311 steps:4572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1684: episode_reward:-4.80775080333935 steps:4574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1685: episode_reward:5.8472828195041595 steps:4576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1686: episode_reward:3.8521448658314785 steps:4578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1687: episode_reward:0.8121763543987619 steps:4580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1688: episode_reward:13.455327458567414 steps:4582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69379
[RDDPG] Episode Done
[92m [RDDPG] 1689: episode_reward:-2.518028656331675 steps:4584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1690: episode_reward:67.76378170002869 steps:4586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1691: episode_reward:-1.8010005913345992 steps:4588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1692: episode_reward:-0.2942730689075246 steps:4590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1693: episode_reward:5.145706326555267 steps:4592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1694: episode_reward:-1.6391508803094659 steps:4594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46462
[RDDPG] Episode Done
[92m [RDDPG] 1695: episode_reward:3.8922261468344383 steps:4596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1696: episode_reward:-1.296547742763696 steps:4598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1697: episode_reward:0.1769168145990947 steps:4600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1698: episode_reward:-1.4705602704173935 steps:4602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1699: episode_reward:2.528525390027996 steps:4604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1700: episode_reward:26.76987818863427 steps:4606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.86632
[RDDPG] Episode Done
[92m [RDDPG] 1701: episode_reward:-1.6110582589723825 steps:4608[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1702: episode_reward:-1.4046721218578622 steps:4610[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1703: episode_reward:0.3981595380616323 steps:4612[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1704: episode_reward:6.620131407889464 steps:4614[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1705: episode_reward:54.15059896726484 steps:4616[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1706: episode_reward:-5.16025911729346 steps:4618[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54393
[RDDPG] Episode Done
[92m [RDDPG] 1707: episode_reward:2.1910945098847723 steps:4620[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1708: episode_reward:18.556584996181023 steps:4622[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1709: episode_reward:-1.0952889703592912 steps:4624[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1710: episode_reward:-0.33161322540821336 steps:4626[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1711: episode_reward:16.268747793678525 steps:4628[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1712: episode_reward:-1.8641542244197227 steps:4630[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56241
[RDDPG] Episode Done
[92m [RDDPG] 1713: episode_reward:-0.8680661291631173 steps:4632[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1714: episode_reward:-6.821501706380476 steps:4634[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1715: episode_reward:-3.650790021849807 steps:4636[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1716: episode_reward:5.25803569792034 steps:4638[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1717: episode_reward:-1.7031562999226937 steps:4640[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1718: episode_reward:-1.8415649352224535 steps:4642[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.96610
[RDDPG] Episode Done
[92m [RDDPG] 1719: episode_reward:-8.124871515894048 steps:4644[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1720: episode_reward:-0.029874654738912376 steps:4646[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1721: episode_reward:9.832283550908862 steps:4648[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1722: episode_reward:36.16559479964158 steps:4650[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1723: episode_reward:72.99138056985647 steps:4652[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1724: episode_reward:3.0978753668818677 steps:4654[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.87124
[RDDPG] Episode Done
[92m [RDDPG] 1725: episode_reward:0.7894049935880902 steps:4656[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1726: episode_reward:5.335625000637901 steps:4658[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1727: episode_reward:2.4096093184981022 steps:4660[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1728: episode_reward:32.49083946180196 steps:4662[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1729: episode_reward:9.91949267552696 steps:4664[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1730: episode_reward:6.717474121348683 steps:4666[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01325
[RDDPG] Episode Done
[92m [RDDPG] 1731: episode_reward:2.166529904187223 steps:4668[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1732: episode_reward:14.918293581779576 steps:4670[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1733: episode_reward:-2.312994075869219 steps:4672[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1734: episode_reward:-1.210617629718477 steps:4674[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1735: episode_reward:3.3842065068956946 steps:4676[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1736: episode_reward:2.043351844951801 steps:4678[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.01951
[RDDPG] Episode Done
[92m [RDDPG] 1737: episode_reward:-0.5555037463620995 steps:4680[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1738: episode_reward:89.52406753163763 steps:4682[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1739: episode_reward:-1.6436963520114047 steps:4684[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1740: episode_reward:-2.418449131003656 steps:4686[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1741: episode_reward:-4.835759135408112 steps:4688[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1742: episode_reward:-3.2826047457531335 steps:4690[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81548
[RDDPG] Episode Done
[92m [RDDPG] 1743: episode_reward:0.6617348184475418 steps:4692[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1744: episode_reward:-1.2589225979838579 steps:4694[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1745: episode_reward:-3.5584773703185437 steps:4696[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1746: episode_reward:0.16335838890390075 steps:4698[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1747: episode_reward:5.3463560205118785 steps:4700[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1748: episode_reward:2.5991075529008896 steps:4702[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.87652
[RDDPG] Episode Done
[92m [RDDPG] 1749: episode_reward:3.2164182934292134 steps:4704[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1750: episode_reward:2.8054311710328577 steps:4706[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1751: episode_reward:-0.1758807080726812 steps:4708[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1752: episode_reward:19.431249050035035 steps:4710[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1753: episode_reward:3.9782886268569966 steps:4712[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1754: episode_reward:-1.4826265839116415 steps:4714[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72211
[RDDPG] Episode Done
[92m [RDDPG] 1755: episode_reward:6.592855095306785 steps:4716[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1756: episode_reward:-5.51296267364174 steps:4718[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1757: episode_reward:1.7248244616058468 steps:4720[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1758: episode_reward:-1.3536512692966536 steps:4722[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1759: episode_reward:-3.0046671884393565 steps:4724[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1760: episode_reward:14.95701755402646 steps:4726[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.47640
[RDDPG] Episode Done
[92m [RDDPG] 1761: episode_reward:9.54942510907271 steps:4728[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1762: episode_reward:5.57218867518588 steps:4730[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1763: episode_reward:16.92974160329379 steps:4732[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1764: episode_reward:0.30815555071670175 steps:4734[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1765: episode_reward:3.5243797840203497 steps:4736[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1766: episode_reward:12.615129762305504 steps:4738[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.11154
[RDDPG] Episode Done
[92m [RDDPG] 1767: episode_reward:8.769281087439545 steps:4740[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1768: episode_reward:228.89586677414198 steps:4742[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1769: episode_reward:24.144324583257095 steps:4744[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1770: episode_reward:0.9665547594718076 steps:4746[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1771: episode_reward:-0.9973746294930952 steps:4748[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1772: episode_reward:7.436138569935045 steps:4750[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.65664
[RDDPG] Episode Done
[92m [RDDPG] 1773: episode_reward:3.3108048318186634 steps:4752[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1774: episode_reward:0.8977112864416399 steps:4754[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1775: episode_reward:4.27258868465829 steps:4756[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1776: episode_reward:4.860059537746259 steps:4758[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1777: episode_reward:61.83218790830058 steps:4760[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1778: episode_reward:-0.8718053713528984 steps:4762[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.10072
[RDDPG] Episode Done
[92m [RDDPG] 1779: episode_reward:3.994416750678731 steps:4764[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1780: episode_reward:-3.442473068491698 steps:4766[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1781: episode_reward:-2.9850651686397773 steps:4768[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1782: episode_reward:0.8001618833239585 steps:4770[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1783: episode_reward:0.09345380050089247 steps:4772[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1784: episode_reward:17.99211954808899 steps:4774[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.11781
[RDDPG] Episode Done
[92m [RDDPG] 1785: episode_reward:2.0633238653104033 steps:4776[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1786: episode_reward:3.943228869568766 steps:4778[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1787: episode_reward:6.524431661874272 steps:4780[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1788: episode_reward:73.14019309064611 steps:4782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1789: episode_reward:-1.9259247785116642 steps:4784[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1790: episode_reward:9.701220369820568 steps:4786[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81896
[RDDPG] Episode Done
[92m [RDDPG] 1791: episode_reward:3.1274190421042247 steps:4788[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1792: episode_reward:-6.002509333779443 steps:4790[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1793: episode_reward:0.5410669797789831 steps:4792[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1794: episode_reward:11.354029117988757 steps:4794[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1795: episode_reward:-2.480145667529856 steps:4796[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1796: episode_reward:2.5907883151376625 steps:4798[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.79785
[RDDPG] Episode Done
[92m [RDDPG] 1797: episode_reward:-1.9324378821857324 steps:4800[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1798: episode_reward:21.255290796476185 steps:4802[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1799: episode_reward:-1.1375843693367427 steps:4804[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1800: episode_reward:4.649524554723338 steps:4806[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1801: episode_reward:-6.705197706974458 steps:4808[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1802: episode_reward:3.8565452206485267 steps:4810[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.38493
[RDDPG] Episode Done
[92m [RDDPG] 1803: episode_reward:6.982366355675019 steps:4812[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1804: episode_reward:8.25517060086903 steps:4814[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1805: episode_reward:-1.975659043392651 steps:4816[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1806: episode_reward:0.2762958209493007 steps:4818[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1807: episode_reward:15.347875811597504 steps:4820[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1808: episode_reward:0.6694642464200928 steps:4822[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44200
[RDDPG] Episode Done
[92m [RDDPG] 1809: episode_reward:-7.1491370620629535 steps:4824[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1810: episode_reward:15.299897690670829 steps:4826[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1811: episode_reward:1.4048929310504827 steps:4828[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1812: episode_reward:-0.5739689857495636 steps:4830[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1813: episode_reward:-2.583616665232619 steps:4832[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1814: episode_reward:3.169504669335235 steps:4834[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.91128
[RDDPG] Episode Done
[92m [RDDPG] 1815: episode_reward:1.6401143590422582 steps:4836[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1816: episode_reward:4.724723701179655 steps:4838[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1817: episode_reward:-1.4882552645075375 steps:4840[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1818: episode_reward:1.75314251001386 steps:4842[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1819: episode_reward:16.423218099955758 steps:4844[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1820: episode_reward:0.7171397345896278 steps:4846[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.77472
[RDDPG] Episode Done
[92m [RDDPG] 1821: episode_reward:29.192046417489312 steps:4848[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1822: episode_reward:5.767141574082786 steps:4850[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1823: episode_reward:3.239510738500187 steps:4852[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1824: episode_reward:8.672949006918346 steps:4854[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1825: episode_reward:-0.7848348081147156 steps:4856[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1826: episode_reward:30.879469013421545 steps:4858[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.02999
[RDDPG] Episode Done
[92m [RDDPG] 1827: episode_reward:-2.287311069084556 steps:4860[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1828: episode_reward:2.4648235723925214 steps:4862[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1829: episode_reward:1.2094098571633296 steps:4864[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1830: episode_reward:-4.537467493111004 steps:4866[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1831: episode_reward:9.199852683790262 steps:4868[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1832: episode_reward:75.95837866842683 steps:4870[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.92754
[RDDPG] Episode Done
[92m [RDDPG] 1833: episode_reward:0.9542757416148371 steps:4872[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1834: episode_reward:2.460514650933923 steps:4874[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1835: episode_reward:64.69429280136359 steps:4876[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1836: episode_reward:-1.9112432457788464 steps:4878[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1837: episode_reward:29.148031111337875 steps:4880[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1838: episode_reward:-0.5194315137359085 steps:4882[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66022
[RDDPG] Episode Done
[92m [RDDPG] 1839: episode_reward:-0.42367474428917085 steps:4884[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1840: episode_reward:-1.6232598334802588 steps:4886[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1841: episode_reward:119.4197763213162 steps:4888[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1842: episode_reward:0.3964813889628216 steps:4890[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1843: episode_reward:288.24061252100086 steps:4892[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1844: episode_reward:10.477303716521195 steps:4894[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.27365
[RDDPG] Episode Done
[92m [RDDPG] 1845: episode_reward:22.203552804352654 steps:4896[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1846: episode_reward:2.8802466904304183 steps:4898[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1847: episode_reward:15.114047037573096 steps:4900[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1848: episode_reward:-7.495726037196739 steps:4902[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1849: episode_reward:0.7592231441641006 steps:4904[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1850: episode_reward:-7.842809743555605 steps:4906[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.90102
[RDDPG] Episode Done
[92m [RDDPG] 1851: episode_reward:1.5430579522477021 steps:4908[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1852: episode_reward:-0.9974852306266526 steps:4910[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1853: episode_reward:11.195126577944992 steps:4912[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1854: episode_reward:-0.45611247735459237 steps:4914[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1855: episode_reward:0.9396455263642642 steps:4916[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1856: episode_reward:5.65508409215169 steps:4918[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57927
[RDDPG] Episode Done
[92m [RDDPG] 1857: episode_reward:6.021188218385404 steps:4920[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1858: episode_reward:-0.6384914257885752 steps:4922[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1859: episode_reward:10.375129945213542 steps:4924[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1860: episode_reward:1.9591057640040894 steps:4926[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1861: episode_reward:14.985958103872445 steps:4928[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1862: episode_reward:-3.103985051457756 steps:4930[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75831
[RDDPG] Episode Done
[92m [RDDPG] 1863: episode_reward:33.84043136171582 steps:4932[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1864: episode_reward:8.693770206103249 steps:4934[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1865: episode_reward:-0.6738984055143922 steps:4936[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1866: episode_reward:0.6129869269601143 steps:4938[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1867: episode_reward:0.04690905836942916 steps:4940[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1868: episode_reward:-7.172545048442579 steps:4942[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35393
[RDDPG] Episode Done
[92m [RDDPG] 1869: episode_reward:-1.9234761156268563 steps:4944[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1870: episode_reward:4.247965626656469 steps:4946[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1871: episode_reward:7.998787302757908 steps:4948[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1872: episode_reward:-5.162022921403598 steps:4950[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1873: episode_reward:4.942144550275998 steps:4952[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1874: episode_reward:0.6926614828040476 steps:4954[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76835
[RDDPG] Episode Done
[92m [RDDPG] 1875: episode_reward:0.854735811624161 steps:4956[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1876: episode_reward:-2.1271950097010754 steps:4958[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1877: episode_reward:-1.7868556113252363 steps:4960[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1878: episode_reward:40.183016953949284 steps:4962[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1879: episode_reward:1.0801496489227902 steps:4964[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1880: episode_reward:29.043608052703703 steps:4966[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.94131
[RDDPG] Episode Done
[92m [RDDPG] 1881: episode_reward:2.0656384363631473 steps:4968[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1882: episode_reward:-0.8817551362837 steps:4970[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1883: episode_reward:14.312413053161197 steps:4972[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1884: episode_reward:-1.8969364260762764 steps:4974[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1885: episode_reward:3.897663274493492 steps:4976[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1886: episode_reward:-4.103488062440733 steps:4978[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75978
[RDDPG] Episode Done
[92m [RDDPG] 1887: episode_reward:-0.4095375092382114 steps:4980[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1888: episode_reward:26.75919432429031 steps:4982[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1889: episode_reward:-0.07599501052181656 steps:4984[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1890: episode_reward:-2.196432268778938 steps:4986[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1891: episode_reward:-8.69994015280429 steps:4988[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1892: episode_reward:-2.324629260727604 steps:4990[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41692
[RDDPG] Episode Done
[92m [RDDPG] 1893: episode_reward:2.625801071352016 steps:4992[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1894: episode_reward:28.536434321551035 steps:4994[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1895: episode_reward:-3.036956990561865 steps:4996[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1896: episode_reward:41.77301366159561 steps:4998[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1897: episode_reward:19.99056460084527 steps:5000[00m
[RDDPG] Start Evaluation
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[93m [RDDPG] Step_0005000: mean_reward:-0.08557034341716782[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1898: episode_reward:-2.4087309328783624 steps:5002[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39683
[RDDPG] Episode Done
[92m [RDDPG] 1899: episode_reward:-0.12413985554766294 steps:5004[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1900: episode_reward:-4.444589413128291 steps:5006[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1901: episode_reward:-0.2537638343599098 steps:5008[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1902: episode_reward:14.549203550445588 steps:5010[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1903: episode_reward:0.008691562912770845 steps:5012[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1904: episode_reward:42.474062207054125 steps:5014[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68502
[RDDPG] Episode Done
[92m [RDDPG] 1905: episode_reward:1.5852490526307124 steps:5016[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1906: episode_reward:-2.325225058689963 steps:5018[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1907: episode_reward:3.7468744864710466 steps:5020[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1908: episode_reward:31.54594044513038 steps:5022[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1909: episode_reward:-0.20756533395125487 steps:5024[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1910: episode_reward:1.0846535106394501 steps:5026[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07656
[RDDPG] Episode Done
[92m [RDDPG] 1911: episode_reward:67.37532069110924 steps:5028[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1912: episode_reward:1.6766549562640072 steps:5030[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1913: episode_reward:-0.7139620245214235 steps:5032[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1914: episode_reward:3.131143587158218 steps:5034[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1915: episode_reward:-2.246196024092498 steps:5036[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1916: episode_reward:-1.344225586794307 steps:5038[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81682
[RDDPG] Episode Done
[92m [RDDPG] 1917: episode_reward:-0.2979341781657796 steps:5040[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1918: episode_reward:-0.6342578869875393 steps:5042[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1919: episode_reward:6.6861981332542975 steps:5044[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1920: episode_reward:16.347669287545212 steps:5046[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1921: episode_reward:4.442103706274764 steps:5048[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1922: episode_reward:-1.463954707599334 steps:5050[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.11229
[RDDPG] Episode Done
[92m [RDDPG] 1923: episode_reward:-0.3605931242840681 steps:5052[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1924: episode_reward:-5.7838719425080205 steps:5054[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1925: episode_reward:2.1200034279739404 steps:5056[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1926: episode_reward:44.74860670536292 steps:5058[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1927: episode_reward:7.925072876119453 steps:5060[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1928: episode_reward:-5.4081079903268146 steps:5062[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84505
[RDDPG] Episode Done
[92m [RDDPG] 1929: episode_reward:17.09819891750501 steps:5064[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1930: episode_reward:-2.159640471837934 steps:5066[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1931: episode_reward:585.6914115986475 steps:5068[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1932: episode_reward:7.797792750734782 steps:5070[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1933: episode_reward:-0.891655460136076 steps:5072[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1934: episode_reward:11.706224675155942 steps:5074[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.10534
[RDDPG] Episode Done
[92m [RDDPG] 1935: episode_reward:5.48061851412876 steps:5076[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1936: episode_reward:86.05208898113949 steps:5078[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1937: episode_reward:1.2109764049844722 steps:5080[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1938: episode_reward:51.40720876525508 steps:5082[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1939: episode_reward:-2.7201541367170488 steps:5084[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1940: episode_reward:12.688809950694644 steps:5086[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.03784
[RDDPG] Episode Done
[92m [RDDPG] 1941: episode_reward:-2.8094219704483834 steps:5088[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1942: episode_reward:0.2678994292693151 steps:5090[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1943: episode_reward:5.204523044893711 steps:5092[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1944: episode_reward:-0.6524716668847548 steps:5094[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1945: episode_reward:1207.190030472029 steps:5096[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1946: episode_reward:-1.223848016679379 steps:5098[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66142
[RDDPG] Episode Done
[92m [RDDPG] 1947: episode_reward:23.5925512412649 steps:5100[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1948: episode_reward:-0.8104170142049929 steps:5102[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1949: episode_reward:29.334223353922518 steps:5104[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1950: episode_reward:10.004368241024075 steps:5106[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1951: episode_reward:24.195943638129446 steps:5108[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1952: episode_reward:7.0155100576238505 steps:5110[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62749
[RDDPG] Episode Done
[92m [RDDPG] 1953: episode_reward:-0.978224786711015 steps:5112[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1954: episode_reward:-2.6170733599575158 steps:5114[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1955: episode_reward:-6.1195948618489275 steps:5116[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1956: episode_reward:22.84697263015866 steps:5118[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1957: episode_reward:-2.5838867914371217 steps:5120[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1958: episode_reward:1.7741289845788177 steps:5122[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39970
[RDDPG] Episode Done
[92m [RDDPG] 1959: episode_reward:1.6411690610462686 steps:5124[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1960: episode_reward:-1.637082413038617 steps:5126[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1961: episode_reward:26.97095468429343 steps:5128[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1962: episode_reward:-0.12656543847363544 steps:5130[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1963: episode_reward:-4.513560861641148 steps:5132[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1964: episode_reward:-3.600674200171637 steps:5134[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06313
[RDDPG] Episode Done
[92m [RDDPG] 1965: episode_reward:2.353024983988652 steps:5136[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1966: episode_reward:42.35454462764898 steps:5138[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1967: episode_reward:-1.370845999636642 steps:5140[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1968: episode_reward:10.224426718725105 steps:5142[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1969: episode_reward:-3.5719531024364635 steps:5144[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1970: episode_reward:11.104213661202525 steps:5146[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88933
[RDDPG] Episode Done
[92m [RDDPG] 1971: episode_reward:-3.9454350777176876 steps:5148[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1972: episode_reward:-0.5195537165847091 steps:5150[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1973: episode_reward:2.5290753766375866 steps:5152[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1974: episode_reward:17.128271898234505 steps:5154[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1975: episode_reward:3.429408763984722 steps:5156[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1976: episode_reward:-5.714567153308549 steps:5158[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49123
[RDDPG] Episode Done
[92m [RDDPG] 1977: episode_reward:0.9707225371807451 steps:5160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1978: episode_reward:3.0329032303078307 steps:5162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1979: episode_reward:-4.632085170409571 steps:5164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1980: episode_reward:-1.177317845540489 steps:5166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1981: episode_reward:-0.3147863914673765 steps:5168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1982: episode_reward:11.982929340133651 steps:5170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72834
[RDDPG] Episode Done
[92m [RDDPG] 1983: episode_reward:-4.209454739352278 steps:5172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1984: episode_reward:36.455344981471754 steps:5174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1985: episode_reward:2.3107676775499826 steps:5176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1986: episode_reward:5.506149831301632 steps:5178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1987: episode_reward:3.2408631464635276 steps:5180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1988: episode_reward:-3.170856534790958 steps:5182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62536
[RDDPG] Episode Done
[92m [RDDPG] 1989: episode_reward:4.090852921453373 steps:5184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1990: episode_reward:6.377459851734155 steps:5186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1991: episode_reward:2.5620178041598725 steps:5188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1992: episode_reward:9.240058871361143 steps:5190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1993: episode_reward:4.3003701623198936 steps:5192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1994: episode_reward:17.53114953432099 steps:5194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58978
[RDDPG] Episode Done
[92m [RDDPG] 1995: episode_reward:-5.9107899380634255 steps:5196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1996: episode_reward:-5.250789895460974 steps:5198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1997: episode_reward:-2.732189592468294 steps:5200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1998: episode_reward:-2.543317131616355 steps:5202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 1999: episode_reward:-2.191107054051959 steps:5204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2000: episode_reward:-1.861877101649216 steps:5206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75385
[RDDPG] Episode Done
[92m [RDDPG] 2001: episode_reward:13.288020027845988 steps:5208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2002: episode_reward:-1.5378038150186633 steps:5210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2003: episode_reward:-0.9440145118958194 steps:5212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2004: episode_reward:4.458528255411653 steps:5214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2005: episode_reward:1.274262175801077 steps:5216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2006: episode_reward:5.811321674725882 steps:5218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35338
[RDDPG] Episode Done
[92m [RDDPG] 2007: episode_reward:223.85916254360615 steps:5220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2008: episode_reward:-0.9881656566643033 steps:5222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2009: episode_reward:164.93537057650894 steps:5224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2010: episode_reward:39.335665971122616 steps:5226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2011: episode_reward:2.8384187292207237 steps:5228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2012: episode_reward:-1.0496567532930683 steps:5230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66544
[RDDPG] Episode Done
[92m [RDDPG] 2013: episode_reward:82.98291168189468 steps:5232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2014: episode_reward:4.747278743676635 steps:5234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2015: episode_reward:-2.2799488119032034 steps:5236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2016: episode_reward:-2.3541548747717727 steps:5238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2017: episode_reward:-0.12128234226384338 steps:5240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2018: episode_reward:4.23716848925505 steps:5242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58624
[RDDPG] Episode Done
[92m [RDDPG] 2019: episode_reward:32.54660803325815 steps:5244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2020: episode_reward:41.36753398371974 steps:5246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2021: episode_reward:-0.18349275350244154 steps:5248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2022: episode_reward:29.236535929962304 steps:5250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2023: episode_reward:8.90804506386501 steps:5252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2024: episode_reward:0.137065958806887 steps:5254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.15233
[RDDPG] Episode Done
[92m [RDDPG] 2025: episode_reward:29.050140422616828 steps:5256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2026: episode_reward:7.481811417961595 steps:5258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2027: episode_reward:25.129341289168153 steps:5260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2028: episode_reward:-3.8636720082569185 steps:5262[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2029: episode_reward:-0.13025270021260527 steps:5264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2030: episode_reward:-0.5710061464718899 steps:5266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62203
[RDDPG] Episode Done
[92m [RDDPG] 2031: episode_reward:-1.2679484103455083 steps:5268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2032: episode_reward:-0.46654908616600377 steps:5270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2033: episode_reward:30.714824292611134 steps:5272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2034: episode_reward:1.3841786789652208 steps:5274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2035: episode_reward:-1.8289049744461376 steps:5276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2036: episode_reward:6.422052261637986 steps:5278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.33660
[RDDPG] Episode Done
[92m [RDDPG] 2037: episode_reward:-2.4346743557423154 steps:5280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2038: episode_reward:0.07885131025055037 steps:5282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2039: episode_reward:-4.9776620328684125 steps:5284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2040: episode_reward:0.37091495494039295 steps:5286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2041: episode_reward:6.543871208135837 steps:5288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2042: episode_reward:-5.957449237948596 steps:5290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.06111
[RDDPG] Episode Done
[92m [RDDPG] 2043: episode_reward:0.6101828866479724 steps:5292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2044: episode_reward:5.568427105644086 steps:5294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2045: episode_reward:-6.974990234460281 steps:5296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2046: episode_reward:15.321283026868961 steps:5298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2047: episode_reward:6.319104423896928 steps:5300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2048: episode_reward:0.12896714592068736 steps:5302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55969
[RDDPG] Episode Done
[92m [RDDPG] 2049: episode_reward:3.155426818705393 steps:5304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2050: episode_reward:0.7273989697036258 steps:5306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2051: episode_reward:2.4294967906772897 steps:5308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2052: episode_reward:-5.863363554948997 steps:5310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2053: episode_reward:-4.0676641934717335 steps:5312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2054: episode_reward:1.674346666903002 steps:5314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.19212
[RDDPG] Episode Done
[92m [RDDPG] 2055: episode_reward:0.8903051646961915 steps:5316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2056: episode_reward:8.440171782770605 steps:5318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2057: episode_reward:-1.7496008260182359 steps:5320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2058: episode_reward:-4.279294935853651 steps:5322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2059: episode_reward:21.42057545830246 steps:5324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2060: episode_reward:2.5747264639502285 steps:5326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69336
[RDDPG] Episode Done
[92m [RDDPG] 2061: episode_reward:4.876415002415983 steps:5328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2062: episode_reward:5.675844160249049 steps:5330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2063: episode_reward:-5.0070372007373205 steps:5332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2064: episode_reward:3.3210198499618393 steps:5334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2065: episode_reward:46.14956241399064 steps:5336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2066: episode_reward:0.3571401965856329 steps:5338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.08028
[RDDPG] Episode Done
[92m [RDDPG] 2067: episode_reward:-0.42825597213314914 steps:5340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2068: episode_reward:3.167387756748842 steps:5342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2069: episode_reward:162.5880925913881 steps:5344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2070: episode_reward:4.488329662311983 steps:5346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2071: episode_reward:3.5113241630633705 steps:5348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2072: episode_reward:-8.63391792563269 steps:5350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78470
[RDDPG] Episode Done
[92m [RDDPG] 2073: episode_reward:-0.5316571069368461 steps:5352[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2074: episode_reward:11.299392843236122 steps:5354[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2075: episode_reward:0.06196783290006502 steps:5356[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2076: episode_reward:1.898411195080242 steps:5358[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2077: episode_reward:15.969258295700131 steps:5360[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2078: episode_reward:15.984865040561566 steps:5362[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52050
[RDDPG] Episode Done
[92m [RDDPG] 2079: episode_reward:0.05614429705657953 steps:5364[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2080: episode_reward:8.79683286559452 steps:5366[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2081: episode_reward:11.760773895754937 steps:5368[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2082: episode_reward:9.129356933297135 steps:5370[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2083: episode_reward:26.08875117505516 steps:5372[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2084: episode_reward:6.076128560222484 steps:5374[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.68947
[RDDPG] Episode Done
[92m [RDDPG] 2085: episode_reward:2.2795521076404537 steps:5376[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2086: episode_reward:3.054494932177663 steps:5378[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2087: episode_reward:-5.547735783018773 steps:5380[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2088: episode_reward:0.20159695355604557 steps:5382[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2089: episode_reward:187.38078007383973 steps:5384[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2090: episode_reward:4.0533267083555025 steps:5386[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53469
[RDDPG] Episode Done
[92m [RDDPG] 2091: episode_reward:-3.9894508731214025 steps:5388[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2092: episode_reward:1.6567008285091829 steps:5390[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2093: episode_reward:35.44436222498515 steps:5392[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2094: episode_reward:0.8871269755864342 steps:5394[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2095: episode_reward:6.318705521737093 steps:5396[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2096: episode_reward:4.066238616436095 steps:5398[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75683
[RDDPG] Episode Done
[92m [RDDPG] 2097: episode_reward:1.4563531387556106 steps:5400[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2098: episode_reward:-4.117217535637614 steps:5402[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2099: episode_reward:4.926547825207413 steps:5404[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2100: episode_reward:3.3384143995168754 steps:5406[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2101: episode_reward:-2.2536017739162415 steps:5408[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2102: episode_reward:-2.814317727636776 steps:5410[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46108
[RDDPG] Episode Done
[92m [RDDPG] 2103: episode_reward:-0.15790347871099142 steps:5412[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2104: episode_reward:3.5543898302660195 steps:5414[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2105: episode_reward:5.754345991448533 steps:5416[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2106: episode_reward:-2.0430800655213037 steps:5418[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2107: episode_reward:26.05925516772692 steps:5420[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2108: episode_reward:36.63751092230056 steps:5422[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.94158
[RDDPG] Episode Done
[92m [RDDPG] 2109: episode_reward:3.7100972284349636 steps:5424[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2110: episode_reward:-2.260139617839889 steps:5426[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2111: episode_reward:2.0118391071981403 steps:5428[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2112: episode_reward:2.1521511669807647 steps:5430[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2113: episode_reward:43.348419872245316 steps:5432[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2114: episode_reward:-1.7641624917155065 steps:5434[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71345
[RDDPG] Episode Done
[92m [RDDPG] 2115: episode_reward:1.7425243057732294 steps:5436[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2116: episode_reward:2.9504395370489136 steps:5438[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2117: episode_reward:-2.7943642370510107 steps:5440[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2118: episode_reward:1.2072313067453733 steps:5442[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2119: episode_reward:-7.972124607817922 steps:5444[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2120: episode_reward:0.4713022200634658 steps:5446[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.47335
[RDDPG] Episode Done
[92m [RDDPG] 2121: episode_reward:2.085418113193657 steps:5448[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2122: episode_reward:5.900849723418221 steps:5450[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2123: episode_reward:77.07222101974696 steps:5452[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2124: episode_reward:14.973037472307166 steps:5454[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2125: episode_reward:9.349076238089857 steps:5456[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2126: episode_reward:5.509066146105605 steps:5458[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.65569
[RDDPG] Episode Done
[92m [RDDPG] 2127: episode_reward:3.396502316810394 steps:5460[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2128: episode_reward:-2.5537274131381427 steps:5462[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2129: episode_reward:3.8082936251529955 steps:5464[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2130: episode_reward:-2.4377601000334765 steps:5466[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2131: episode_reward:-1.4480938401782297 steps:5468[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2132: episode_reward:186.83696052327525 steps:5470[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67526
[RDDPG] Episode Done
[92m [RDDPG] 2133: episode_reward:8.730630428838998 steps:5472[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2134: episode_reward:11.261710705441498 steps:5474[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2135: episode_reward:24.482999378811392 steps:5476[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2136: episode_reward:8.327371281839085 steps:5478[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2137: episode_reward:5.518065248049237 steps:5480[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2138: episode_reward:5.582044926872255 steps:5482[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93086
[RDDPG] Episode Done
[92m [RDDPG] 2139: episode_reward:7.667645925956617 steps:5484[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2140: episode_reward:58.07899910681992 steps:5486[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2141: episode_reward:0.31391746886832284 steps:5488[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2142: episode_reward:1.3751060887969317 steps:5490[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2143: episode_reward:0.7494523358961702 steps:5492[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2144: episode_reward:0.7353394012752608 steps:5494[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56802
[RDDPG] Episode Done
[92m [RDDPG] 2145: episode_reward:-3.2460998020340943 steps:5496[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2146: episode_reward:8.316630464949029 steps:5498[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2147: episode_reward:37.4085306014715 steps:5500[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2148: episode_reward:3.993437976534888 steps:5502[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2149: episode_reward:-1.6165182765065926 steps:5504[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2150: episode_reward:10.17776751188426 steps:5506[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70597
[RDDPG] Episode Done
[92m [RDDPG] 2151: episode_reward:-5.7670180039332966 steps:5508[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2152: episode_reward:-0.9460087895835594 steps:5510[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2153: episode_reward:475.4349199464954 steps:5512[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2154: episode_reward:-1.8325108829101622 steps:5514[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2155: episode_reward:-6.540382879733814 steps:5516[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2156: episode_reward:25.01630567109663 steps:5518[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.30312
[RDDPG] Episode Done
[92m [RDDPG] 2157: episode_reward:12.68272534622402 steps:5520[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2158: episode_reward:-1.6900833806201403 steps:5522[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2159: episode_reward:1.3204573642323965 steps:5524[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2160: episode_reward:-6.255043387521418 steps:5526[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2161: episode_reward:5.2734764430091925 steps:5528[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2162: episode_reward:-0.5005779025975374 steps:5530[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76988
[RDDPG] Episode Done
[92m [RDDPG] 2163: episode_reward:2.9402472286510606 steps:5532[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2164: episode_reward:8.6497424758398 steps:5534[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2165: episode_reward:3.4738754954934405 steps:5536[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2166: episode_reward:6.927833803341102 steps:5538[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2167: episode_reward:-1.888843691471592 steps:5540[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2168: episode_reward:0.05214462717793111 steps:5542[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39375
[RDDPG] Episode Done
[92m [RDDPG] 2169: episode_reward:-1.2415515826718408 steps:5544[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2170: episode_reward:4.934407263659782 steps:5546[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2171: episode_reward:13.444692929948278 steps:5548[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2172: episode_reward:1.1328848492688683 steps:5550[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2173: episode_reward:10.804989025798202 steps:5552[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2174: episode_reward:-1.8159208929249153 steps:5554[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69184
[RDDPG] Episode Done
[92m [RDDPG] 2175: episode_reward:15.615368922425928 steps:5556[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2176: episode_reward:-3.6229818878210382 steps:5558[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2177: episode_reward:1.5974227760413005 steps:5560[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2178: episode_reward:19.579227113663656 steps:5562[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2179: episode_reward:241.16152554398045 steps:5564[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2180: episode_reward:-0.6605313789987952 steps:5566[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18761
[RDDPG] Episode Done
[92m [RDDPG] 2181: episode_reward:4.521435841258244 steps:5568[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2182: episode_reward:-0.03581058727641073 steps:5570[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2183: episode_reward:1.1013231588910033 steps:5572[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2184: episode_reward:9.591619238894182 steps:5574[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2185: episode_reward:1.6527041678014527 steps:5576[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2186: episode_reward:-1.4143855536795136 steps:5578[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64493
[RDDPG] Episode Done
[92m [RDDPG] 2187: episode_reward:8.919396518053208 steps:5580[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2188: episode_reward:-6.795134713464755 steps:5582[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2189: episode_reward:1.6529362809987722 steps:5584[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2190: episode_reward:-0.5934499715505561 steps:5586[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2191: episode_reward:-1.7285762085281382 steps:5588[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2192: episode_reward:-4.770786846074854 steps:5590[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50867
[RDDPG] Episode Done
[92m [RDDPG] 2193: episode_reward:354.8598348800376 steps:5592[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2194: episode_reward:-2.550155241215652 steps:5594[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2195: episode_reward:16.696511018664143 steps:5596[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2196: episode_reward:1.552480426588812 steps:5598[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2197: episode_reward:-0.27543980598898843 steps:5600[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2198: episode_reward:-0.8740447059562517 steps:5602[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.21895
[RDDPG] Episode Done
[92m [RDDPG] 2199: episode_reward:-0.00932810165672393 steps:5604[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2200: episode_reward:8.794523346380188 steps:5606[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2201: episode_reward:-5.1821936450214325 steps:5607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2202: episode_reward:36.66714303249733 steps:5609[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2203: episode_reward:-2.3107467801633765 steps:5611[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2204: episode_reward:-4.465303423592548 steps:5613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2205: episode_reward:0.3393850348293741 steps:5615[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.97928
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2206: episode_reward:7.9665386220763645 steps:5617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2207: episode_reward:4.408244159788065 steps:5619[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2208: episode_reward:1.9426137768111174 steps:5621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2209: episode_reward:1.5392360450499165 steps:5623[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2210: episode_reward:4.768150323280451 steps:5625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2211: episode_reward:23.413817343614195 steps:5627[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69486
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2212: episode_reward:-5.911689662148751 steps:5629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2213: episode_reward:0.30599994026224664 steps:5631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2214: episode_reward:37.5547681078116 steps:5633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2215: episode_reward:-0.9335020178827866 steps:5635[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2216: episode_reward:-3.3616816113585273 steps:5637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2217: episode_reward:6.764808503674347 steps:5639[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75871
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2218: episode_reward:7.127689240789678 steps:5641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2219: episode_reward:-1.8100632412824116 steps:5643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2220: episode_reward:-0.9977091038823263 steps:5645[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2221: episode_reward:27.972094686589166 steps:5647[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2222: episode_reward:15.184133715783839 steps:5649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2223: episode_reward:20.6337968789661 steps:5651[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55158
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2224: episode_reward:81.88749189878196 steps:5653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2225: episode_reward:13.671308007285717 steps:5655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2226: episode_reward:68.04853165462936 steps:5657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2227: episode_reward:14.008461694176509 steps:5659[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2228: episode_reward:2.6043993374664254 steps:5661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2229: episode_reward:21.655557244454364 steps:5663[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.14867
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2230: episode_reward:7.821989676855488 steps:5665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2231: episode_reward:15.391833818123864 steps:5667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2232: episode_reward:11.67172680250527 steps:5669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2233: episode_reward:190.61945178216084 steps:5671[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2234: episode_reward:7.441102497339724 steps:5673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2235: episode_reward:0.6847992131233753 steps:5675[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48410
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2236: episode_reward:85.62116444046906 steps:5677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2237: episode_reward:11.910847933382788 steps:5679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2238: episode_reward:2.2153586073101685 steps:5681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2239: episode_reward:3.412289334432246 steps:5683[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2240: episode_reward:0.8840223149568889 steps:5685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2241: episode_reward:2.449095907341074 steps:5687[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64554
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2242: episode_reward:-0.4901504933016634 steps:5689[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2243: episode_reward:25.276523631202576 steps:5691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2244: episode_reward:58.13917569821635 steps:5693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2245: episode_reward:7.149653678838664 steps:5695[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2246: episode_reward:-4.8652285460067635 steps:5697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2247: episode_reward:0.04329001869066129 steps:5699[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52367
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2248: episode_reward:101.93556815868534 steps:5701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2249: episode_reward:5.209407037957861 steps:5703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2250: episode_reward:30.444488443892336 steps:5705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2251: episode_reward:23.86675044572977 steps:5707[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2252: episode_reward:8.197605275663387 steps:5709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2253: episode_reward:5.0271371543955095 steps:5711[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07389
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2254: episode_reward:-0.8829727822937432 steps:5713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2255: episode_reward:14.801402697334705 steps:5715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2256: episode_reward:6.35371704555357 steps:5717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2257: episode_reward:44.26773890364453 steps:5719[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2258: episode_reward:15.676381905719289 steps:5721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2259: episode_reward:5.830935226595855 steps:5723[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85861
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2260: episode_reward:24.127362552240065 steps:5725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2261: episode_reward:4.998556842513465 steps:5727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2262: episode_reward:1.7998324428946422 steps:5729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2263: episode_reward:26.417447937619574 steps:5731[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2264: episode_reward:-2.8760265914960454 steps:5733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2265: episode_reward:-1.558260232770162 steps:5735[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59073
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2266: episode_reward:0.014621581426337737 steps:5737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2267: episode_reward:24.66057885580329 steps:5739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2268: episode_reward:-0.5064376739015786 steps:5741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2269: episode_reward:51.315474491366125 steps:5743[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2270: episode_reward:1.1000664071971546 steps:5745[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2271: episode_reward:0.22190815510283857 steps:5747[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.04626
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2272: episode_reward:31.8248431171781 steps:5749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2273: episode_reward:279.5111699856011 steps:5751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2274: episode_reward:-1.1965692246297388 steps:5753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2275: episode_reward:2.4459773076830698 steps:5755[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2276: episode_reward:0.40222237926843496 steps:5757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2277: episode_reward:-1.3124480687504216 steps:5759[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.13604
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2278: episode_reward:-0.6327575099425018 steps:5761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2279: episode_reward:0.7117209758489493 steps:5763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2280: episode_reward:4.228443457573875 steps:5765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2281: episode_reward:-4.802897348956803 steps:5767[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2282: episode_reward:2.145105599288417 steps:5769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2283: episode_reward:-0.5742703138797012 steps:5771[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41566
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2284: episode_reward:18.279867048146343 steps:5773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2285: episode_reward:10.086550272150825 steps:5775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2286: episode_reward:-1.958162553934721 steps:5777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2287: episode_reward:-2.232927322445934 steps:5779[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2288: episode_reward:10.417506136464596 steps:5781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2289: episode_reward:27.347991247526334 steps:5783[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.64995
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2290: episode_reward:25.14953683379816 steps:5785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2291: episode_reward:1.4496656868332085 steps:5787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2292: episode_reward:1.2456594523668034 steps:5789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2293: episode_reward:1.048330529144942 steps:5791[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2294: episode_reward:121.76411889144875 steps:5793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2295: episode_reward:13.069383581512398 steps:5795[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.31897
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2296: episode_reward:25.536347872936073 steps:5797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2297: episode_reward:7.578066933767788 steps:5799[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2298: episode_reward:-1.3996325404975891 steps:5801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2299: episode_reward:22.730261853258817 steps:5803[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2300: episode_reward:229.02812920503234 steps:5805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2301: episode_reward:-1.138100011008027 steps:5807[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26592
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2302: episode_reward:-1.2960272980249345 steps:5809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2303: episode_reward:7.620639382676004 steps:5811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2304: episode_reward:0.4220189392951781 steps:5813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2305: episode_reward:-1.4591402611959645 steps:5815[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2306: episode_reward:254.9671794006906 steps:5817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2307: episode_reward:5.1007129806787646 steps:5819[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.53723
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2308: episode_reward:2.4728521189802057 steps:5821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2309: episode_reward:2.5774949473517346 steps:5823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2310: episode_reward:51.20325385090299 steps:5825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2311: episode_reward:8.413893771919655 steps:5827[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2312: episode_reward:-0.6597392920808995 steps:5829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2313: episode_reward:10.398443496580688 steps:5831[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93139
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2314: episode_reward:3.7948016416205577 steps:5833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2315: episode_reward:9.12295466930901 steps:5835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2316: episode_reward:-6.690794138281388 steps:5837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2317: episode_reward:1.3863630642686777 steps:5839[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2318: episode_reward:6.159461319391939 steps:5841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2319: episode_reward:0.41818020139443535 steps:5843[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.70922
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2320: episode_reward:7.893750055324862 steps:5845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2321: episode_reward:4.986098717248998 steps:5847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2322: episode_reward:0.14380826826357884 steps:5849[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2323: episode_reward:0.4616612380956324 steps:5851[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2324: episode_reward:16.348022750070925 steps:5853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2325: episode_reward:-1.9295672655538856 steps:5855[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.30189
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2326: episode_reward:-6.586061851505041 steps:5857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2327: episode_reward:6.4723010427931875 steps:5859[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2328: episode_reward:1.5460883323670522 steps:5861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2329: episode_reward:-2.450355157918649 steps:5863[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2330: episode_reward:17.951659498743926 steps:5865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2331: episode_reward:3.84982370567215 steps:5867[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18204
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2332: episode_reward:20.546221088096175 steps:5869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2333: episode_reward:-1.8974897104292 steps:5871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2334: episode_reward:0.8684485443757075 steps:5873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2335: episode_reward:-1.358095507595272 steps:5875[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2336: episode_reward:-1.3301140066782597 steps:5877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2337: episode_reward:-3.992637332664601 steps:5879[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88456
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2338: episode_reward:2.1932424346108252 steps:5881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2339: episode_reward:5.543965198626147 steps:5883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2340: episode_reward:-6.2420941977314435 steps:5885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2341: episode_reward:1.5423499154839786 steps:5887[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2342: episode_reward:-0.025626752909112316 steps:5889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2343: episode_reward:125.87245788606104 steps:5891[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35831
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2344: episode_reward:1.5928481567533415 steps:5893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2345: episode_reward:-0.350865556829675 steps:5895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2346: episode_reward:13.84734622222663 steps:5897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2347: episode_reward:7.2003033992898 steps:5899[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2348: episode_reward:0.7065693162966036 steps:5901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2349: episode_reward:7.292220522482943 steps:5903[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.55422
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2350: episode_reward:-0.9231783273639578 steps:5905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2351: episode_reward:22.2387840976189 steps:5907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2352: episode_reward:16.65900446005739 steps:5909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2353: episode_reward:20.495765154778088 steps:5911[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2354: episode_reward:-0.9919773065280779 steps:5913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2355: episode_reward:2.2165519885983076 steps:5915[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.33402
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2356: episode_reward:4.307865884508175 steps:5917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2357: episode_reward:-5.4501713306504325 steps:5919[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2358: episode_reward:-2.117754440059938 steps:5921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2359: episode_reward:16.978705608865404 steps:5923[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2360: episode_reward:1.9380326927139335 steps:5925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2361: episode_reward:-8.008972872342353 steps:5927[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.76304
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2362: episode_reward:1.3263158982513161 steps:5929[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2363: episode_reward:15.837419482093718 steps:5931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2364: episode_reward:2.4110478718934343 steps:5933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2365: episode_reward:-2.516818532997691 steps:5935[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2366: episode_reward:1.5314326798273283 steps:5937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2367: episode_reward:-0.836188436778373 steps:5939[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80216
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2368: episode_reward:1.5509432505904135 steps:5941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2369: episode_reward:169.57456901091538 steps:5943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2370: episode_reward:-2.1269826873511617 steps:5945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2371: episode_reward:7.1145513178456286 steps:5947[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2372: episode_reward:-1.849139255866778 steps:5949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2373: episode_reward:0.6071110623355378 steps:5951[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.60930
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2374: episode_reward:39.89777337809954 steps:5953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2375: episode_reward:-0.7875663662142753 steps:5955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2376: episode_reward:-1.6183103706028068 steps:5957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2377: episode_reward:14.446505642001663 steps:5959[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2378: episode_reward:-2.6740616224265 steps:5961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2379: episode_reward:2.0541524557798976 steps:5963[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.39620
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2380: episode_reward:9.431541559831022 steps:5965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2381: episode_reward:0.9962989684798464 steps:5967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2382: episode_reward:69.31097493811573 steps:5969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2383: episode_reward:10.933179601656349 steps:5971[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2384: episode_reward:20.95300823178485 steps:5973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2385: episode_reward:0.5006260783018992 steps:5975[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.99797
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2386: episode_reward:4.381079655437096 steps:5977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2387: episode_reward:6.554424337075412 steps:5979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2388: episode_reward:18.29004753547623 steps:5981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2389: episode_reward:-3.5684534303933195 steps:5983[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2390: episode_reward:128.52386727834266 steps:5985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2391: episode_reward:6.053709201342545 steps:5987[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.22132
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2392: episode_reward:51.552716753156574 steps:5989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2393: episode_reward:9.639437876832702 steps:5991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2394: episode_reward:-0.88584423273341 steps:5993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2395: episode_reward:-2.4840243098654113 steps:5995[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2396: episode_reward:-0.20555991968156428 steps:5997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2397: episode_reward:166.31905292711454 steps:5999[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.67715
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2398: episode_reward:18.270114543909138 steps:6001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2399: episode_reward:3.8894759184798193 steps:6003[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2400: episode_reward:810.4239001716338 steps:6005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2401: episode_reward:2.3340959300999558 steps:6007[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2402: episode_reward:-0.6203805681621666 steps:6009[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2403: episode_reward:27.07431542810352 steps:6011[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56273
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2404: episode_reward:-3.1522650183241216 steps:6013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2405: episode_reward:17.114449957934003 steps:6015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2406: episode_reward:-2.377577999956899 steps:6017[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2407: episode_reward:21.96334246944298 steps:6019[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2408: episode_reward:9.705474171601418 steps:6021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2409: episode_reward:5.5200503015351075 steps:6023[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.41372
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2410: episode_reward:-3.245749991644341 steps:6025[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2411: episode_reward:-1.9562681072822112 steps:6027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2412: episode_reward:-7.2268028389417225 steps:6029[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2413: episode_reward:2.296577775104416 steps:6031[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2414: episode_reward:6.393074794369939 steps:6033[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2415: episode_reward:-0.08366509883420514 steps:6035[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77718
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2416: episode_reward:4.150119713008561 steps:6037[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2417: episode_reward:12.377849584306608 steps:6039[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2418: episode_reward:165.6758836721467 steps:6041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2419: episode_reward:-0.03947085355167346 steps:6043[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2420: episode_reward:0.061448543398020306 steps:6045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2421: episode_reward:1.1332345407764493 steps:6047[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.70791
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2422: episode_reward:-1.4072767099858536 steps:6049[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2423: episode_reward:40.90110939192329 steps:6051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2424: episode_reward:16.67253374004668 steps:6053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2425: episode_reward:2.9009095953759876 steps:6055[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2426: episode_reward:1.9835820692922135 steps:6057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2427: episode_reward:-0.6888012028026615 steps:6059[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.72841
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2428: episode_reward:0.6558616798983952 steps:6061[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2429: episode_reward:2.197717578520185 steps:6063[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2430: episode_reward:-1.7882275593461536 steps:6065[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2431: episode_reward:3.5158477788915334 steps:6067[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2432: episode_reward:14.051438815699752 steps:6069[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2433: episode_reward:-1.7005068426953807 steps:6071[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.49404
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2434: episode_reward:0.28489589177892327 steps:6073[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2435: episode_reward:3.0235047263477366 steps:6075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2436: episode_reward:5.327724155895697 steps:6077[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2437: episode_reward:1.5298827826391728 steps:6079[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2438: episode_reward:0.20184593722585564 steps:6081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2439: episode_reward:5.849831582645607 steps:6083[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64124
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2440: episode_reward:7.372779910047772 steps:6085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2441: episode_reward:1.2909189228724536 steps:6087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2442: episode_reward:20.67572832545256 steps:6089[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2443: episode_reward:14.54095814392849 steps:6091[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2444: episode_reward:-0.9165106075742515 steps:6093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2445: episode_reward:-2.4789514123414635 steps:6095[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44401
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2446: episode_reward:2.3597663693395714 steps:6097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2447: episode_reward:14.509391830639334 steps:6099[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2448: episode_reward:-6.232046027157645 steps:6101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2449: episode_reward:74.71757035427869 steps:6103[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2450: episode_reward:18.047883134982683 steps:6105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2451: episode_reward:-1.3009850118981396 steps:6107[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34144
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2452: episode_reward:3.0933111673000266 steps:6109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2453: episode_reward:-3.7416482172861762 steps:6111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2454: episode_reward:7.072604070998521 steps:6113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2455: episode_reward:53.125482508608904 steps:6115[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2456: episode_reward:20.53821963278057 steps:6117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2457: episode_reward:6.63783608978226 steps:6119[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.79030
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2458: episode_reward:34.164994108132824 steps:6121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2459: episode_reward:1.954357891312097 steps:6123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2460: episode_reward:-2.605169424390027 steps:6125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2461: episode_reward:9.388924000764352 steps:6127[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2462: episode_reward:13.455888867873078 steps:6129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2463: episode_reward:1.4415017517608768 steps:6131[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84505
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2464: episode_reward:-7.600940730427647 steps:6133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2465: episode_reward:43.78149339346267 steps:6135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2466: episode_reward:17.536353634050613 steps:6137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2467: episode_reward:5.041609756931571 steps:6139[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2468: episode_reward:1.6221112973654197 steps:6141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2469: episode_reward:3.403080724748468 steps:6143[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80411
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2470: episode_reward:5.715899061100534 steps:6145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2471: episode_reward:-0.4387382086633673 steps:6147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2472: episode_reward:26.78563782614435 steps:6149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2473: episode_reward:-4.378269718211211 steps:6151[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2474: episode_reward:1.4428971523127645 steps:6153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2475: episode_reward:-1.0883137169991501 steps:6155[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.81503
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2476: episode_reward:-1.887382648915672 steps:6157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2477: episode_reward:32.8249347941868 steps:6159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2478: episode_reward:-5.02455457030489 steps:6160[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2479: episode_reward:4.896373916114385 steps:6162[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2480: episode_reward:3.525176392226693 steps:6164[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2481: episode_reward:6.972936744651157 steps:6166[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.78593
[RDDPG] Episode Done
[92m [RDDPG] 2482: episode_reward:0.0788960445621627 steps:6168[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2483: episode_reward:-1.0244757083495097 steps:6170[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2484: episode_reward:29.038643919012344 steps:6172[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2485: episode_reward:3.737608004493604 steps:6174[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2486: episode_reward:26.825420474718527 steps:6176[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2487: episode_reward:0.24201447842006818 steps:6178[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26718
[RDDPG] Episode Done
[92m [RDDPG] 2488: episode_reward:-0.49182699577362277 steps:6180[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2489: episode_reward:-1.5442400439599409 steps:6182[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2490: episode_reward:8.493430122616457 steps:6184[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2491: episode_reward:6.8615879564104 steps:6186[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2492: episode_reward:1.8448704126556659 steps:6188[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2493: episode_reward:7.621719849181289 steps:6190[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.79539
[RDDPG] Episode Done
[92m [RDDPG] 2494: episode_reward:10.355738010167414 steps:6192[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2495: episode_reward:7.984322844985955 steps:6194[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2496: episode_reward:-3.251181850750165 steps:6196[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2497: episode_reward:9.634391394035635 steps:6198[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2498: episode_reward:2410.4733512457196 steps:6200[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2499: episode_reward:-0.711581422147535 steps:6202[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.22439
[RDDPG] Episode Done
[92m [RDDPG] 2500: episode_reward:5.296053282061672 steps:6204[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2501: episode_reward:7.404672865176743 steps:6206[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2502: episode_reward:286.5367164619506 steps:6208[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2503: episode_reward:14.426176002668903 steps:6210[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2504: episode_reward:-0.8018640267807453 steps:6212[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2505: episode_reward:14.085757563874107 steps:6214[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.47710
[RDDPG] Episode Done
[92m [RDDPG] 2506: episode_reward:-0.008229706018198613 steps:6216[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2507: episode_reward:7.248480161269972 steps:6218[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2508: episode_reward:-4.5813809821743785 steps:6220[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2509: episode_reward:-1.5053759162633353 steps:6222[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2510: episode_reward:-2.73698192305881 steps:6224[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2511: episode_reward:1.0518830108446915 steps:6226[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.89528
[RDDPG] Episode Done
[92m [RDDPG] 2512: episode_reward:0.22657019871256523 steps:6228[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2513: episode_reward:3.3799316225157474 steps:6230[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2514: episode_reward:-0.06984655446308308 steps:6232[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2515: episode_reward:0.5772726330038354 steps:6234[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2516: episode_reward:83.97480944574586 steps:6236[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2517: episode_reward:8.299166755393959 steps:6238[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26152
[RDDPG] Episode Done
[92m [RDDPG] 2518: episode_reward:-1.9225892093622974 steps:6240[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2519: episode_reward:-2.1875100890728865 steps:6242[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2520: episode_reward:1.1908390417887431 steps:6244[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2521: episode_reward:1.1415762630881754 steps:6246[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2522: episode_reward:11.955447987467734 steps:6248[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2523: episode_reward:16.08638203873482 steps:6250[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84224
[RDDPG] Episode Done
[92m [RDDPG] 2524: episode_reward:14.338550527834322 steps:6252[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2525: episode_reward:1.0247748618321593 steps:6254[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2526: episode_reward:3.670151481609506 steps:6256[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2527: episode_reward:2.5823352388624095 steps:6258[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2528: episode_reward:-0.6725161245551954 steps:6260[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2529: episode_reward:-2.018457132440875 steps:6262[00m
[RDDPG] Resetting Environment
[DDPG] Error in Resetting End Training
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.26507
[RDDPG] Episode Done
[92m [RDDPG] 2530: episode_reward:2.3016488383356055 steps:6264[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2531: episode_reward:26.464459231376075 steps:6266[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2532: episode_reward:-2.8094196187411127 steps:6268[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2533: episode_reward:3.603950391684047 steps:6270[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2534: episode_reward:1.588801239700894 steps:6272[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2535: episode_reward:-0.8921331745288512 steps:6274[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64340
[RDDPG] Episode Done
[92m [RDDPG] 2536: episode_reward:244.92105932427427 steps:6276[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2537: episode_reward:4.915622942457954 steps:6278[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2538: episode_reward:109.62031537485217 steps:6280[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2539: episode_reward:20.005181696566613 steps:6282[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2540: episode_reward:-3.3041260983344065 steps:6284[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2541: episode_reward:6.065667886351218 steps:6286[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52711
[RDDPG] Episode Done
[92m [RDDPG] 2542: episode_reward:-0.5716347867105975 steps:6288[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2543: episode_reward:-2.3281992502939017 steps:6290[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2544: episode_reward:7.422691335898559 steps:6292[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2545: episode_reward:28.677354491185408 steps:6294[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2546: episode_reward:-0.4140840123006493 steps:6296[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2547: episode_reward:4.662490952064834 steps:6298[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52745
[RDDPG] Episode Done
[92m [RDDPG] 2548: episode_reward:-0.2505651010534127 steps:6300[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2549: episode_reward:-2.4932066108324613 steps:6302[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2550: episode_reward:0.15886265652546694 steps:6304[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2551: episode_reward:4.942221622173841 steps:6306[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2552: episode_reward:-4.293781384220914 steps:6308[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2553: episode_reward:2.2715538113069895 steps:6310[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57250
[RDDPG] Episode Done
[92m [RDDPG] 2554: episode_reward:20.666061621970808 steps:6312[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2555: episode_reward:1.994028655965364 steps:6314[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2556: episode_reward:-2.5484811128238665 steps:6316[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2557: episode_reward:3.5539444156777957 steps:6318[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2558: episode_reward:9.227202590399159 steps:6320[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2559: episode_reward:34.90674496210395 steps:6322[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67989
[RDDPG] Episode Done
[92m [RDDPG] 2560: episode_reward:-2.393465668839265 steps:6324[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2561: episode_reward:8.735176652971969 steps:6326[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2562: episode_reward:5.333476419966179 steps:6328[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2563: episode_reward:-0.22439398044429737 steps:6330[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2564: episode_reward:2.1749943044250153 steps:6332[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2565: episode_reward:-7.0638544171899635 steps:6334[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.09410
[RDDPG] Episode Done
[92m [RDDPG] 2566: episode_reward:-0.04160490871463818 steps:6336[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2567: episode_reward:-1.4168291917514377 steps:6338[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2568: episode_reward:19.44375933468143 steps:6340[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2569: episode_reward:5.577423886443238 steps:6342[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2570: episode_reward:4.859996173167496 steps:6344[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2571: episode_reward:12.469168987823199 steps:6346[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40547
[RDDPG] Episode Done
[92m [RDDPG] 2572: episode_reward:35.59182145171674 steps:6348[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2573: episode_reward:3.8823005349252946 steps:6350[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2574: episode_reward:-7.8387523803745385 steps:6351[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2575: episode_reward:-1.6423892426781388 steps:6353[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2576: episode_reward:2.2870635727587567 steps:6355[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2577: episode_reward:5.582113508425154 steps:6357[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2578: episode_reward:1.115642769174773 steps:6359[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.44810
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2579: episode_reward:-4.9291287680039435 steps:6361[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2580: episode_reward:1.1144012267428587 steps:6363[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2581: episode_reward:32.70820941041817 steps:6365[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2582: episode_reward:-0.42322324893831764 steps:6367[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2583: episode_reward:10.096291909284579 steps:6369[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2584: episode_reward:-1.1781626301211636 steps:6371[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59789
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2585: episode_reward:0.1701130619080118 steps:6373[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2586: episode_reward:-8.82262257142191 steps:6375[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2587: episode_reward:2.8215690011442165 steps:6377[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2588: episode_reward:1.012347605916251 steps:6379[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2589: episode_reward:1.2966196339137976 steps:6381[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2590: episode_reward:-1.6114169457070773 steps:6383[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48370
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2591: episode_reward:1.956851331850702 steps:6385[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2592: episode_reward:19.5953837579168 steps:6387[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2593: episode_reward:2.599273155580143 steps:6389[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2594: episode_reward:0.20280621247623953 steps:6391[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2595: episode_reward:23.201209400461682 steps:6393[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2596: episode_reward:-4.803472866378539 steps:6395[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73053
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2597: episode_reward:150.93162656584872 steps:6397[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2598: episode_reward:-1.9978958408529623 steps:6399[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2599: episode_reward:3.778454355289178 steps:6401[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2600: episode_reward:1.2884059210406624 steps:6403[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2601: episode_reward:-0.6614081333029294 steps:6405[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2602: episode_reward:3.219311869921269 steps:6407[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.75352
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2603: episode_reward:-1.1833413513874527 steps:6409[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2604: episode_reward:-1.829927082732575 steps:6411[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2605: episode_reward:3.3645157735695337 steps:6413[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2606: episode_reward:12.306211999472456 steps:6415[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2607: episode_reward:10.689673079096549 steps:6417[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2608: episode_reward:0.8147423242676046 steps:6419[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.42884
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2609: episode_reward:-1.792463179872583 steps:6421[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2610: episode_reward:0.8363359883121007 steps:6423[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2611: episode_reward:3.7868817487235438 steps:6425[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2612: episode_reward:7.92088008693852 steps:6427[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2613: episode_reward:4.308273088348489 steps:6429[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2614: episode_reward:4.218483636366616 steps:6431[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67433
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2615: episode_reward:38.665790695712666 steps:6433[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2616: episode_reward:-3.522067631567429 steps:6435[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2617: episode_reward:9.946451885531625 steps:6437[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2618: episode_reward:3.1387833038264947 steps:6439[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2619: episode_reward:1.5241230415252307 steps:6441[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2620: episode_reward:-1.1645998826743074 steps:6443[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.61347
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2621: episode_reward:9.553973847946349 steps:6445[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2622: episode_reward:38.176579819709666 steps:6447[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2623: episode_reward:18.755183350823053 steps:6449[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2624: episode_reward:-10.982589058222434 steps:6451[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2625: episode_reward:5.217536411200346 steps:6453[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2626: episode_reward:17.10163703030408 steps:6455[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.39528
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2627: episode_reward:26.443352824868946 steps:6457[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2628: episode_reward:4.174728581629925 steps:6459[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2629: episode_reward:11.021719254272575 steps:6461[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2630: episode_reward:64.76431771905982 steps:6463[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2631: episode_reward:710.3380855030802 steps:6465[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2632: episode_reward:0.41373338271923066 steps:6467[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.34296
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2633: episode_reward:-1.151088248281302 steps:6469[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2634: episode_reward:-4.9466450690480945 steps:6471[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2635: episode_reward:2.4808753398271466 steps:6473[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2636: episode_reward:-4.442402719774593 steps:6475[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2637: episode_reward:13.709163602539402 steps:6477[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2638: episode_reward:4.906159498753665 steps:6479[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84700
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2639: episode_reward:1.943225831840623 steps:6481[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2640: episode_reward:-4.975391099470986 steps:6483[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2641: episode_reward:-1.2294806916284267 steps:6485[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2642: episode_reward:8.290377341172693 steps:6487[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2643: episode_reward:2.319929017593385 steps:6489[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2644: episode_reward:3.474765883222956 steps:6491[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 6.91391
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2645: episode_reward:-6.310268464513502 steps:6493[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2646: episode_reward:116.16239577519613 steps:6495[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2647: episode_reward:12.476011851694754 steps:6497[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2648: episode_reward:32.618726722414095 steps:6499[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2649: episode_reward:1.10746417552674 steps:6501[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2650: episode_reward:10.09126426953281 steps:6503[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29348
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2651: episode_reward:253.19192843235882 steps:6505[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2652: episode_reward:-1.6356675901261282 steps:6507[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2653: episode_reward:8.456013311213988 steps:6509[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2654: episode_reward:-5.269074476979659 steps:6511[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2655: episode_reward:19.93079128756694 steps:6513[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2656: episode_reward:-0.8279614669053288 steps:6515[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24783
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2657: episode_reward:537.5180652900592 steps:6517[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2658: episode_reward:2.0018099728384495 steps:6519[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2659: episode_reward:39.95773031956816 steps:6521[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2660: episode_reward:-2.066003422559742 steps:6523[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2661: episode_reward:1.2614999264882858 steps:6525[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2662: episode_reward:0.3076112613906239 steps:6527[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.66976
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2663: episode_reward:7.229034007261717 steps:6529[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2664: episode_reward:76.74237232190106 steps:6531[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2665: episode_reward:0.17984198292737696 steps:6533[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2666: episode_reward:2.390006103330053 steps:6535[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2667: episode_reward:193.28041554012137 steps:6537[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2668: episode_reward:-0.9063509150008005 steps:6539[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.50551
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2669: episode_reward:2.1745784284077363 steps:6541[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2670: episode_reward:3.310949942799734 steps:6543[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2671: episode_reward:142.55216498022156 steps:6545[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2672: episode_reward:6.286840341848142 steps:6547[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2673: episode_reward:19.011477497286005 steps:6549[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2674: episode_reward:-0.9203195153405441 steps:6551[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.49999
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2675: episode_reward:15.791614328440811 steps:6553[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2676: episode_reward:-5.825441382502927 steps:6555[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2677: episode_reward:1.622560408200707 steps:6557[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2678: episode_reward:7.254524261596927 steps:6559[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2679: episode_reward:0.964265011436324 steps:6561[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2680: episode_reward:0.15883050548248967 steps:6563[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.00497
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2681: episode_reward:16.504759151981382 steps:6565[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2682: episode_reward:1.5355369743316007 steps:6567[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2683: episode_reward:6.704442853277765 steps:6569[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2684: episode_reward:22.458900048533565 steps:6571[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2685: episode_reward:379.4796268460587 steps:6573[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2686: episode_reward:4.564593258723443 steps:6575[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.57097
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2687: episode_reward:14.11263815458097 steps:6577[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2688: episode_reward:-1.056717206560095 steps:6579[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2689: episode_reward:4.053944043259412 steps:6581[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2690: episode_reward:8.324224279967213 steps:6583[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2691: episode_reward:1.141559615033223 steps:6585[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2692: episode_reward:-1.3054668910672775 steps:6587[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.71418
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2693: episode_reward:8.05477839404865 steps:6589[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2694: episode_reward:0.09934754220363695 steps:6591[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2695: episode_reward:31.792368476033534 steps:6593[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2696: episode_reward:4.006176323259897 steps:6595[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2697: episode_reward:20.853980436902074 steps:6597[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2698: episode_reward:-2.178772923972731 steps:6599[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.59514
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2699: episode_reward:5.589548629485882 steps:6601[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2700: episode_reward:11.060400864169932 steps:6603[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2701: episode_reward:1.5636504694073032 steps:6605[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2702: episode_reward:-1.8994901602149958 steps:6607[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2703: episode_reward:111.66111821886798 steps:6609[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2704: episode_reward:5.531684467408137 steps:6611[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.84431
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2705: episode_reward:18.545837738438877 steps:6613[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2706: episode_reward:23.42616348330917 steps:6615[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2707: episode_reward:-0.867672536369644 steps:6617[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2708: episode_reward:-7.670948224015828 steps:6619[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2709: episode_reward:245.6967764613113 steps:6621[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2710: episode_reward:0.6372965015821883 steps:6623[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.18297
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2711: episode_reward:-0.5340043870557456 steps:6625[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2712: episode_reward:3.8524231631644996 steps:6627[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2713: episode_reward:3.5233206937885733 steps:6629[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2714: episode_reward:18.724295971134815 steps:6631[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2715: episode_reward:11.28724763893881 steps:6633[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2716: episode_reward:25.61108628789314 steps:6635[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.35726
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2717: episode_reward:5.41936259474299 steps:6637[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2718: episode_reward:11.828668035925098 steps:6639[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2719: episode_reward:-0.6833360119334628 steps:6641[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2720: episode_reward:66.22467376198405 steps:6643[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2721: episode_reward:5.974759936108018 steps:6645[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2722: episode_reward:0.7432030163158747 steps:6647[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52719
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2723: episode_reward:-1.1501649114876258 steps:6649[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2724: episode_reward:-6.043703982686248 steps:6651[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2725: episode_reward:0.5408873225029049 steps:6653[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2726: episode_reward:4.852129951110728 steps:6655[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2727: episode_reward:-1.7955077409542377 steps:6657[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2728: episode_reward:357.82144808176554 steps:6659[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.56684
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2729: episode_reward:3.2446246359938073 steps:6661[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2730: episode_reward:-2.438633530106811 steps:6663[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2731: episode_reward:19.48270800595818 steps:6665[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2732: episode_reward:278.147129894799 steps:6667[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2733: episode_reward:-1.5260554844959584 steps:6669[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2734: episode_reward:-0.334710666561262 steps:6671[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.80818
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2735: episode_reward:2.046573566943348 steps:6673[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2736: episode_reward:16.64131451707106 steps:6675[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2737: episode_reward:-0.15809777972692407 steps:6677[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2738: episode_reward:13.634884840473493 steps:6679[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2739: episode_reward:7.44471102568211 steps:6681[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2740: episode_reward:30.04941176148681 steps:6683[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.58326
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2741: episode_reward:16.551865026844762 steps:6685[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2742: episode_reward:336.7036450126891 steps:6687[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2743: episode_reward:-1.0948684462104943 steps:6689[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2744: episode_reward:-1.536334705668285 steps:6691[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2745: episode_reward:48.62524346596085 steps:6693[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2746: episode_reward:22.36729539775441 steps:6695[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.52424
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2747: episode_reward:3.8773055935970584 steps:6697[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2748: episode_reward:19.900393734481124 steps:6699[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2749: episode_reward:1.6007027522017214 steps:6701[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2750: episode_reward:5.91397346928639 steps:6703[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2751: episode_reward:0.10283847083300746 steps:6705[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2752: episode_reward:8.560476170285238 steps:6707[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.62831
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2753: episode_reward:0.6910813562912845 steps:6709[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2754: episode_reward:-2.3924699471976156 steps:6711[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2755: episode_reward:-3.9969382859241267 steps:6713[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2756: episode_reward:-0.4010471911024629 steps:6715[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2757: episode_reward:1.90209627570459 steps:6717[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2758: episode_reward:2.591610779446558 steps:6719[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67417
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2759: episode_reward:9.18904884480116 steps:6721[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2760: episode_reward:-0.8756452989054155 steps:6723[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2761: episode_reward:73.52591839480637 steps:6725[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2762: episode_reward:55.00803994896143 steps:6727[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2763: episode_reward:14.902743335733879 steps:6729[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2764: episode_reward:-0.7947203706472266 steps:6731[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54229
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2765: episode_reward:-3.2247001644362405 steps:6733[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2766: episode_reward:38.731320119785366 steps:6735[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2767: episode_reward:0.026890860613024703 steps:6737[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2768: episode_reward:0.4741325061445827 steps:6739[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2769: episode_reward:4.100226457529368 steps:6741[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2770: episode_reward:164.35875304133015 steps:6743[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.38937
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2771: episode_reward:0.7577517346683629 steps:6745[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2772: episode_reward:-1.5603833138704817 steps:6747[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2773: episode_reward:-3.0535901030829686 steps:6749[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2774: episode_reward:92.96661286429621 steps:6751[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2775: episode_reward:3.5808086655259403 steps:6753[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2776: episode_reward:-6.047464545251067 steps:6755[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.46085
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2777: episode_reward:12.734354005720576 steps:6757[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2778: episode_reward:4.066531732377987 steps:6759[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2779: episode_reward:-5.4345180646799145 steps:6761[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2780: episode_reward:4.732505121483647 steps:6763[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2781: episode_reward:1.8444474786991054 steps:6765[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2782: episode_reward:-1.912626229516818 steps:6767[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.03146
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2783: episode_reward:17.13727954081939 steps:6769[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2784: episode_reward:172.84707522672238 steps:6771[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2785: episode_reward:3.4518828787367504 steps:6773[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2786: episode_reward:3.854672953820528 steps:6775[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2787: episode_reward:3.777692983164621 steps:6777[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2788: episode_reward:191.02204387768043 steps:6779[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.64385
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2789: episode_reward:2.690405206332507 steps:6781[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2790: episode_reward:-3.8554619796850584 steps:6783[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2791: episode_reward:-4.759098329709042 steps:6785[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2792: episode_reward:1.0145495169207903 steps:6787[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2793: episode_reward:-5.175767324015627 steps:6789[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2794: episode_reward:-0.46380226342159236 steps:6791[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.18493
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2795: episode_reward:10.066809918772444 steps:6793[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2796: episode_reward:2.4777064337442614 steps:6795[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2797: episode_reward:10.23283568489947 steps:6797[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2798: episode_reward:5.411891640396698 steps:6799[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2799: episode_reward:-2.433864682884205 steps:6801[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2800: episode_reward:4.481153968295318 steps:6803[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.69728
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2801: episode_reward:0.08125185696075832 steps:6805[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2802: episode_reward:-1.9047386506190773 steps:6807[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2803: episode_reward:27.311814580400192 steps:6809[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2804: episode_reward:0.4143668206359781 steps:6811[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2805: episode_reward:0.5997480339228924 steps:6813[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2806: episode_reward:-6.092481334973277 steps:6815[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.40693
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2807: episode_reward:112.02893664832514 steps:6817[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2808: episode_reward:5.064818269427989 steps:6819[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2809: episode_reward:4.072057533356894 steps:6821[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2810: episode_reward:28.011279622835545 steps:6823[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2811: episode_reward:-3.356493349616497 steps:6825[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2812: episode_reward:9.378543893011154 steps:6827[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.32196
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2813: episode_reward:13.662061713564622 steps:6829[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2814: episode_reward:-8.498477142789564 steps:6831[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2815: episode_reward:29.183704398455006 steps:6833[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2816: episode_reward:6.377878874812767 steps:6835[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2817: episode_reward:7.444885364464732 steps:6837[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2818: episode_reward:-3.0581732944133067 steps:6839[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.07844
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2819: episode_reward:-1.7207645820544366 steps:6841[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2820: episode_reward:9.367416119158598 steps:6843[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2821: episode_reward:15.713751123289828 steps:6845[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2822: episode_reward:-1.1623499501332277 steps:6847[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2823: episode_reward:2.5563252368733034 steps:6849[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2824: episode_reward:0.3564430917144703 steps:6851[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67747
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2825: episode_reward:-2.892731613299089 steps:6853[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2826: episode_reward:12.918576229832993 steps:6855[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2827: episode_reward:-2.8197378274263185 steps:6857[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2828: episode_reward:-2.2362549731183603 steps:6859[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2829: episode_reward:11.45529634062767 steps:6861[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2830: episode_reward:-0.5495292986857327 steps:6863[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.48092
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2831: episode_reward:16.138578503088418 steps:6865[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2832: episode_reward:-1.785543805119121 steps:6867[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2833: episode_reward:9.447856531685233 steps:6869[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2834: episode_reward:-6.283664969352083 steps:6871[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2835: episode_reward:1.3158729803533031 steps:6873[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2836: episode_reward:-2.1956736298981956 steps:6875[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.15430
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2837: episode_reward:111.07921629723408 steps:6877[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2838: episode_reward:24.171985350087308 steps:6879[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2839: episode_reward:0.6682195781140581 steps:6881[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2840: episode_reward:0.7806379286904699 steps:6883[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2841: episode_reward:-1.8065859080383588 steps:6885[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2842: episode_reward:-1.9039225807939595 steps:6887[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.11912
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2843: episode_reward:12.734721820789273 steps:6889[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2844: episode_reward:11.87727178001656 steps:6891[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2845: episode_reward:-1.0933217151784795 steps:6893[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2846: episode_reward:6.666433969115156 steps:6895[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2847: episode_reward:-0.21942209015758207 steps:6897[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2848: episode_reward:2.522832815400454 steps:6899[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.26351
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2849: episode_reward:-6.2906869211311225 steps:6901[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2850: episode_reward:-3.4610837444633376 steps:6903[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2851: episode_reward:-0.7930383794251679 steps:6905[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2852: episode_reward:-2.2205143229341338 steps:6907[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2853: episode_reward:0.17145730694743033 steps:6909[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2854: episode_reward:1.9740447567649086 steps:6911[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.37150
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2855: episode_reward:-1.8026872187664644 steps:6913[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2856: episode_reward:-4.279517929755013 steps:6915[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2857: episode_reward:-0.22006072209826888 steps:6917[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2858: episode_reward:11.805757731179304 steps:6919[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2859: episode_reward:5.091495392850381 steps:6921[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2860: episode_reward:-4.523355984126145 steps:6923[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.93238
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2861: episode_reward:14.564449053084285 steps:6925[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2862: episode_reward:-0.6882360627068378 steps:6927[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2863: episode_reward:43.40038381061956 steps:6929[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2864: episode_reward:1.3217693869150784 steps:6931[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2865: episode_reward:12.87730947081692 steps:6933[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2866: episode_reward:-0.5524085695417393 steps:6935[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.89183
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2867: episode_reward:22.36233176753545 steps:6937[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2868: episode_reward:48.31180427940838 steps:6939[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2869: episode_reward:4.363032917314973 steps:6941[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2870: episode_reward:6.0032651683487135 steps:6943[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2871: episode_reward:0.6440543441812325 steps:6945[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2872: episode_reward:3.076334918859125 steps:6947[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77080
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2873: episode_reward:-2.3907588558845494 steps:6949[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2874: episode_reward:-7.796383565018464 steps:6951[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2875: episode_reward:-3.7890446879332407 steps:6953[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2876: episode_reward:-0.891596064270666 steps:6955[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2877: episode_reward:4.557583637883483 steps:6957[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2878: episode_reward:3.2218328447387137 steps:6959[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.82467
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2879: episode_reward:24.99043863544078 steps:6961[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2880: episode_reward:25.123653480411146 steps:6963[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2881: episode_reward:-0.07644674939482776 steps:6965[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2882: episode_reward:-6.730546144469695 steps:6967[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2883: episode_reward:8.121563048011451 steps:6969[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2884: episode_reward:62.05586496091534 steps:6971[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.67691
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2885: episode_reward:1.9312905339495998 steps:6973[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2886: episode_reward:22.15750617522388 steps:6975[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2887: episode_reward:-3.7554278896755795 steps:6977[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2888: episode_reward:6.073003905698372 steps:6979[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2889: episode_reward:4.968708180277959 steps:6981[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2890: episode_reward:-1.1828345455449347 steps:6983[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.85967
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2891: episode_reward:130.24939237060389 steps:6985[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2892: episode_reward:-2.239108880080547 steps:6987[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2893: episode_reward:2.25885192938531 steps:6989[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2894: episode_reward:-7.234397538501797 steps:6991[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2895: episode_reward:11.003003456888631 steps:6993[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2896: episode_reward:12.473307487927652 steps:6995[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.54907
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2897: episode_reward:19.57797006789069 steps:6997[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2898: episode_reward:6.075692207464642 steps:6999[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2899: episode_reward:-2.9705592472892035 steps:7001[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2900: episode_reward:82.99435976482778 steps:7003[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2901: episode_reward:28.88387258566462 steps:7005[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2902: episode_reward:-1.0227233067774038 steps:7007[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.25157
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2903: episode_reward:-4.954787774469309 steps:7009[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2904: episode_reward:-0.9095505787455267 steps:7011[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2905: episode_reward:3.3023262418595003 steps:7013[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2906: episode_reward:8.75317501417412 steps:7015[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2907: episode_reward:6.1724796099307335 steps:7017[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2908: episode_reward:11.041088827755269 steps:7019[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.29109
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2909: episode_reward:4.215524262369662 steps:7021[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2910: episode_reward:3.1816382470387055 steps:7023[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2911: episode_reward:-7.2772264527077395 steps:7025[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2912: episode_reward:0.8564043836015869 steps:7027[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2913: episode_reward:25.691754764993973 steps:7029[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2914: episode_reward:-0.9938417223726539 steps:7031[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.24139
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2915: episode_reward:0.1235010187868939 steps:7033[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2916: episode_reward:43.91548658413071 steps:7035[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2917: episode_reward:-1.0772282768752102 steps:7037[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2918: episode_reward:-4.763660735623381 steps:7039[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2919: episode_reward:78.20572555385367 steps:7041[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2920: episode_reward:-4.072733999649044 steps:7043[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77462
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2921: episode_reward:4.36330900836244 steps:7045[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2922: episode_reward:3.0800167613850924 steps:7047[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2923: episode_reward:-6.686461992903442 steps:7049[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2924: episode_reward:1.6640956647119438 steps:7051[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2925: episode_reward:-0.860761478292827 steps:7053[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2926: episode_reward:-2.79183541262556 steps:7055[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.86256
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2927: episode_reward:4.981189925827567 steps:7057[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2928: episode_reward:5.626083674934324 steps:7059[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2929: episode_reward:-1.009223503449297 steps:7061[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2930: episode_reward:16.28201595619571 steps:7063[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2931: episode_reward:13.468325032955455 steps:7065[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2932: episode_reward:-3.8440800002353144 steps:7067[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88233
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2933: episode_reward:8.688059356937643 steps:7069[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2934: episode_reward:123.12055479309005 steps:7071[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2935: episode_reward:85.66546492649795 steps:7073[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2936: episode_reward:2.885429119604897 steps:7075[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2937: episode_reward:7.189969246665431 steps:7077[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2938: episode_reward:3.7601784356310044 steps:7079[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.26511
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2939: episode_reward:19.943105529623317 steps:7081[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2940: episode_reward:1.7112096490008923 steps:7083[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2941: episode_reward:11.052182806077436 steps:7085[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2942: episode_reward:10.76430375323046 steps:7087[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2943: episode_reward:223.03976299058212 steps:7089[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2944: episode_reward:-3.882925065339444 steps:7091[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 8.62873
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2945: episode_reward:-1.5820427556964272 steps:7093[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2946: episode_reward:2.863900654968021 steps:7095[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2947: episode_reward:7.580825404108547 steps:7097[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2948: episode_reward:9.835210044957153 steps:7099[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2949: episode_reward:19.169277550627058 steps:7101[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2950: episode_reward:44.55701594059212 steps:7103[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73899
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2951: episode_reward:4.502583354230524 steps:7105[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2952: episode_reward:7.693785000447497 steps:7107[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2953: episode_reward:65.91462967584717 steps:7109[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2954: episode_reward:2.3373443335695576 steps:7111[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2955: episode_reward:3.2403301757954823 steps:7113[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2956: episode_reward:-4.990505923817575 steps:7115[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.77058
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2957: episode_reward:-0.4767838345540323 steps:7117[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2958: episode_reward:-0.7392332891471654 steps:7119[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2959: episode_reward:-2.213148471827645 steps:7121[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2960: episode_reward:-3.3673296555128274 steps:7123[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2961: episode_reward:1.7268628384111926 steps:7125[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2962: episode_reward:1.3638491068615215 steps:7127[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.10741
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2963: episode_reward:78.03398628122204 steps:7129[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2964: episode_reward:-1.2709371030742924 steps:7131[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2965: episode_reward:48.88527911427229 steps:7133[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2966: episode_reward:14.174971813718187 steps:7135[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2967: episode_reward:356.2350767698786 steps:7137[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2968: episode_reward:10.859755587093883 steps:7139[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.88554
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2969: episode_reward:7.0909889127521435 steps:7141[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2970: episode_reward:0.4029287340741936 steps:7143[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2971: episode_reward:25.012329897629144 steps:7145[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2972: episode_reward:103.69681637902207 steps:7147[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2973: episode_reward:-6.166818851772986 steps:7149[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2974: episode_reward:11.465026794028349 steps:7151[00m
[RDDPG] Resetting Environment
[RDDPG] Updating Policy
[RDDPG] Update Time: 7.73500
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2975: episode_reward:-7.390772085500755 steps:7153[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2976: episode_reward:-1.636407755424622 steps:7155[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2977: episode_reward:4.753137231215893 steps:7157[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2978: episode_reward:23.345046885836002 steps:7159[00m
[RDDPG] Resetting Environment
[RDDPG] Quadruped Not Upright
[RDDPG] Episode Done
[92m [RDDPG] 2979: episode_reward:2.5012698776642184 steps:7161[00m
[RDDPG] Resetting Environment
