2021-03-29 14:43:35.944638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:20068): Gdk-CRITICAL **: 14:43:39.038: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 14:43:39.263483: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:43:39.264701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 14:43:39.291952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.292798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:43:39.292834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:43:39.296712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:43:39.296835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:43:39.298412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:43:39.298876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:43:39.302549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:43:39.303404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:43:39.303671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:43:39.303902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.304640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.305351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 14:43:39.525342: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 14:43:39.525604: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:43:39.525901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.526761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:43:39.526790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:43:39.526972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:43:39.527078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:43:39.527121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:43:39.527165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:43:39.527214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:43:39.527270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:43:39.527323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:43:39.527458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.528245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:39.528802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 14:43:39.528844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:43:40.322285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 14:43:40.322329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 14:43:40.322341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 14:43:40.322717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:40.323725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:40.324564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:43:40.325300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617029023.814284714, 33405.021000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617029023.815371362, 33405.021000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617029023.815431955, 33405.021000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617029025.100184904, 33406.254000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617029025.380949504, 33406.519000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617029025.587863027, 33406.719000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617029026.007416140, 33407.119000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-29 14:43:58.710326: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 14:44:02.896224: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
2021-03-29 14:44:09.632077: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 14:44:13.754234: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 14:44:16.268281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:44:17.054188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2788.36572265625
[Actor] Episode 0 Step 1 Loss: 2589.9130859375
[Actor] Episode 0 Step 2 Loss: 2612.578369140625
[Actor] Episode 0 Step 3 Loss: 2720.1181640625
[Actor] Episode 0 Step 4 Loss: 2823.734619140625
[Actor] Episode 0 Step 5 Loss: 2909.966064453125
[Actor] Episode 0 Step 6 Loss: 2814.09130859375
[Actor] Episode 0 Step 7 Loss: 2816.003173828125
[Actor] Episode 0 Step 8 Loss: 2556.062255859375
[Actor] Episode 0 Step 9 Loss: 2840.120849609375
[Actor] Episode 0 Step 10 Loss: 2915.994140625
[Actor] Episode 0 Step 11 Loss: 2925.847412109375
[Actor] Episode 0 Step 12 Loss: 2807.322021484375
[Actor] Episode 0 Step 13 Loss: 2742.275634765625
[Actor] Episode 0 Step 14 Loss: 2887.508056640625
[Actor] Episode 0 Step 15 Loss: 2657.504638671875
[Actor] Episode 0 Step 16 Loss: 2693.994873046875
[Actor] Episode 0 Step 17 Loss: 2782.414794921875
[Actor] Episode 0 Step 18 Loss: 2669.56201171875
[Actor] Episode 0 Step 19 Loss: 2960.2021484375
[Actor] Episode 0 Step 20 Loss: 2706.525146484375
[Actor] Episode 0 Step 21 Loss: 2804.487548828125
[Actor] Episode 0 Step 22 Loss: 2581.5966796875
[Actor] Episode 0 Step 23 Loss: 2726.267578125
[Actor] Episode 0 Step 24 Loss: 2878.724853515625
[Actor] Episode 0 Step 25 Loss: 2755.33251953125
[Actor] Episode 0 Step 26 Loss: 2691.71630859375
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2765.11962890625
[Actor] Learning Rate: 0.0009957347065210342
[Actor] Epoch Time: 1331.8740048408508s
-------------------------------------------------
[Actor] Starting Episode 1
2021-03-29 15:06:25.818760: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Episode 1 Step 0 Loss: 2736.52001953125
[Actor] Episode 1 Step 1 Loss: 2800.67333984375
[Actor] Episode 1 Step 2 Loss: 2618.5625
[Actor] Episode 1 Step 3 Loss: 2775.91796875
[Actor] Episode 1 Step 4 Loss: 2848.64404296875
[Actor] Episode 1 Step 5 Loss: 2609.881103515625
[Actor] Episode 1 Step 6 Loss: 2514.91748046875
[Actor] Episode 1 Step 7 Loss: 2527.19775390625
[Actor] Episode 1 Step 8 Loss: 2710.339111328125
[Actor] Episode 1 Step 9 Loss: 2551.183837890625
[Actor] Episode 1 Step 10 Loss: 2437.619140625
[Actor] Episode 1 Step 11 Loss: 2886.11083984375
[Actor] Episode 1 Step 12 Loss: 2774.226806640625
[Actor] Episode 1 Step 13 Loss: 2432.4306640625
[Actor] Episode 1 Step 14 Loss: 2623.988037109375
[Actor] Episode 1 Step 15 Loss: 2780.80712890625
[Actor] Episode 1 Step 16 Loss: 2623.990234375
[Actor] Episode 1 Step 17 Loss: 2759.53564453125
[Actor] Episode 1 Step 18 Loss: 2939.614013671875
[Actor] Episode 1 Step 19 Loss: 2764.3330078125
[Actor] Episode 1 Step 20 Loss: 2801.852783203125
[Actor] Episode 1 Step 21 Loss: 2875.702880859375
[Actor] Episode 1 Step 22 Loss: 2859.83544921875
2021-03-29 15:28:10.673354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:20974): Gdk-CRITICAL **: 15:28:13.784: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:28:14.021149: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:28:14.022437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:28:14.053877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.054678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:28:14.054713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:28:14.058509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:28:14.058622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:28:14.060256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:28:14.060674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:28:14.064856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:28:14.065826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:28:14.066068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:28:14.066252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.067102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.067882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:28:14.299366: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:28:14.299643: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:28:14.300125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.301169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:28:14.301208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:28:14.301409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:28:14.301458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:28:14.301501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:28:14.301543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:28:14.301585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:28:14.301626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:28:14.301668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:28:14.301869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.303166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:14.303921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:28:14.303981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:28:15.074881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:28:15.074925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:28:15.074936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:28:15.075326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:15.076344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:15.077170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:28:15.077944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13727 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617031698.613757935, 35683.550000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617031698.615258816, 35683.551000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617031698.615405622, 35683.551000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617031699.884330666, 35684.558000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617031700.255431379, 35684.877000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617031700.696190509, 35685.277000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617031701.113712554, 35685.678000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 15:28:51.599382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:28:52.570049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 0.7861345410346985
2021-03-29 15:30:50.740852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:21153): Gdk-CRITICAL **: 15:30:53.904: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:30:54.135043: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:30:54.136189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:30:54.166384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.167141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:30:54.167170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:30:54.170737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:30:54.170851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:30:54.172486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:30:54.172911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:30:54.176601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:30:54.177506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:30:54.177751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:30:54.177917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.178767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.179474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:30:54.393107: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:30:54.393402: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:30:54.393734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.394554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:30:54.394590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:30:54.394794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:30:54.394883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:30:54.394948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:30:54.395005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:30:54.395054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:30:54.395108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:30:54.395157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:30:54.395314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.396186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:54.396901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:30:54.396947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:30:55.241780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:30:55.241826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:30:55.241837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:30:55.242233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:55.243335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:55.244194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:30:55.244911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617031858.764512123, 35821.656000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617031858.765682442, 35821.660000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617031858.765742210, 35821.660000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617031859.957129372, 35822.800000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617031860.240536185, 35823.076000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617031860.657221443, 35823.477000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617031861.074909461, 35823.876000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-29 15:31:13.895226: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:31:17.973319: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
2021-03-29 15:31:24.734783: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 15:31:28.811101: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:31:31.848407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:31:32.772789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2757.704345703125
[Actor] Episode 0 Step 1 Loss: 2546.035400390625
[Actor] Episode 0 Step 2 Loss: 2614.950439453125
[Actor] Episode 0 Step 3 Loss: 2928.336669921875
[Actor] Episode 0 Step 4 Loss: 2616.763427734375
[Actor] Episode 0 Step 5 Loss: 2554.659912109375
[Actor] Episode 0 Step 6 Loss: 2768.5048828125
[Actor] Episode 0 Step 7 Loss: 2564.6279296875
[Actor] Episode 0 Step 8 Loss: 2793.903564453125
2021-03-29 15:40:32.749843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:21358): Gdk-CRITICAL **: 15:40:35.886: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:40:36.114894: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:40:36.116088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:40:36.145627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.146418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:40:36.146465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:40:36.150845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:40:36.150964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:40:36.152936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:40:36.153376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:40:36.157954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:40:36.159008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:40:36.159253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:40:36.159447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.160404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.161099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:40:36.404476: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:40:36.404766: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:40:36.405072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.405898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:40:36.405943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:40:36.406180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:40:36.406315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:40:36.406388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:40:36.406454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:40:36.406513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:40:36.406569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:40:36.406619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:40:36.406799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.407632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:36.408374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:40:36.408427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:40:37.200111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:40:37.200160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:40:37.200172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:40:37.200518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:37.201557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:37.202545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:40:37.203295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617032440.790008400, 36319.843000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617032440.790830959, 36319.843000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617032440.790967253, 36319.843000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617032441.986599253, 36320.990000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617032442.295294646, 36321.277000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617032442.717361361, 36321.677000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617032442.928236803, 36321.877000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-29 15:40:55.771589: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:40:59.887884: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
2021-03-29 15:41:06.491390: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 15:41:10.546660: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:41:13.146373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:41:13.867739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 0.7853811383247375
[Actor] Episode 0 Step 1 Loss: 1.6496858596801758
2021-03-29 15:43:59.892929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:21556): Gdk-CRITICAL **: 15:44:03.064: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:44:03.292790: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:44:03.293949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:44:03.325307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.326039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:44:03.326074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:44:03.329693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:44:03.329829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:44:03.331457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:44:03.331828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:44:03.335596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:44:03.336534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:44:03.336788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:44:03.336973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.337812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.338558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:44:03.552333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:44:03.552600: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:44:03.552913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.553643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:44:03.553691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:44:03.553896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:44:03.554004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:44:03.554073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:44:03.554129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:44:03.554199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:44:03.554237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:44:03.554270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:44:03.554436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.555259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:03.555912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:44:03.555959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:44:04.401980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:44:04.402027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:44:04.402038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:44:04.402466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:04.403480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:04.404297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:44:04.405007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617032647.911047539, 36499.462000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617032647.912284027, 36499.464000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617032647.912424062, 36499.464000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617032649.107397758, 36500.599000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617032649.393284280, 36500.876000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617032649.806934889, 36501.276000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617032650.014739295, 36501.477000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-29 15:44:22.710027: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:44:26.905663: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
2021-03-29 15:44:32.984841: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 15:44:37.152990: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-29 15:44:40.069163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:44:40.776746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 0.7858254313468933
[Actor] Episode 0 Step 1 Loss: 0.7833783030509949
[Actor] Episode 0 Step 2 Loss: 0.7821491360664368
[Actor] Episode 0 Step 3 Loss: 0.7843989729881287
[Actor] Episode 0 Step 4 Loss: 0.7826201915740967
[Actor] Episode 0 Step 5 Loss: 0.7836158871650696
[Actor] Episode 0 Step 6 Loss: 0.7836992740631104
[Actor] Episode 0 Step 7 Loss: 0.7827826738357544
[Actor] Episode 0 Step 8 Loss: 0.7811499238014221
[Actor] Episode 0 Step 9 Loss: 0.7826412320137024
[Actor] Episode 0 Step 10 Loss: 0.7825413346290588
[Actor] Episode 0 Step 11 Loss: 0.7828078866004944
[Actor] Episode 0 Step 12 Loss: 0.7828525304794312
[Actor] Episode 0 Step 13 Loss: 0.7814189195632935
[Actor] Episode 0 Step 14 Loss: 0.7829190492630005
[Actor] Episode 0 Step 15 Loss: 0.7828900814056396
[Actor] Episode 0 Step 16 Loss: 0.7828667759895325
[Actor] Episode 0 Step 17 Loss: 0.7825295329093933
[Actor] Episode 0 Step 18 Loss: 0.782389760017395
[Actor] Episode 0 Step 19 Loss: 0.7814751863479614
[Actor] Episode 0 Step 20 Loss: 0.7841254472732544
[Actor] Episode 0 Step 21 Loss: 0.7813505530357361
[Actor] Episode 0 Step 22 Loss: 0.7823766469955444
[Actor] Episode 0 Step 23 Loss: 0.7812362909317017
[Actor] Episode 0 Step 24 Loss: 0.7818691730499268
[Actor] Episode 0 Step 25 Loss: 0.7822892665863037
[Actor] Episode 0 Step 26 Loss: 0.781604528427124
-------------------------------------------------
[Actor] Episode 0 Average Loss: 0.7826594070152
[Actor] Learning Rate: 0.0009957347065210342
[Actor] Epoch Time: 1329.5081017017365s
-------------------------------------------------
[Actor] Starting Episode 1
2021-03-29 16:06:46.915545: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Episode 1 Step 0 Loss: 0.7814308404922485
[Actor] Episode 1 Step 1 Loss: 0.782016396522522
[Actor] Episode 1 Step 2 Loss: 0.7809651494026184
[Actor] Episode 1 Step 3 Loss: 0.7823407053947449
[Actor] Episode 1 Step 4 Loss: 0.7828924059867859
[Actor] Episode 1 Step 5 Loss: 0.7805900573730469
[Actor] Episode 1 Step 6 Loss: 0.7818419337272644
[Actor] Episode 1 Step 7 Loss: 0.7805600166320801
[Actor] Episode 1 Step 8 Loss: 0.7817218899726868
[Actor] Episode 1 Step 9 Loss: 0.7813695073127747
[Actor] Episode 1 Step 10 Loss: 0.7802557945251465
[Actor] Episode 1 Step 11 Loss: 0.782556414604187
[Actor] Episode 1 Step 12 Loss: 0.7809352874755859
[Actor] Episode 1 Step 13 Loss: 0.7818698287010193
[Actor] Episode 1 Step 14 Loss: 0.7817848324775696
[Actor] Episode 1 Step 15 Loss: 0.7800793051719666
[Actor] Episode 1 Step 16 Loss: 0.7808634638786316
[Actor] Episode 1 Step 17 Loss: 0.7812349796295166
[Actor] Episode 1 Step 18 Loss: 0.7803492546081543
[Actor] Episode 1 Step 19 Loss: 0.7799771428108215
[Actor] Episode 1 Step 20 Loss: 0.7819079160690308
[Actor] Episode 1 Step 21 Loss: 0.7807655334472656
[Actor] Episode 1 Step 22 Loss: 0.78094083070755
[Actor] Episode 1 Step 23 Loss: 0.7803086042404175
[Actor] Episode 1 Step 24 Loss: 0.7817615270614624
[Actor] Episode 1 Step 25 Loss: 0.7816430330276489
[Actor] Episode 1 Step 26 Loss: 0.7831065654754639
-------------------------------------------------
[Actor] Episode 1 Average Loss: 0.7813358969158597
[Actor] Learning Rate: 0.0009914875263348222
[Actor] Epoch Time: 1312.126255273819s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 0.780828058719635
[Actor] Episode 2 Step 1 Loss: 0.7808025479316711
[Actor] Episode 2 Step 2 Loss: 0.7804310917854309
[Actor] Episode 2 Step 3 Loss: 0.7818217873573303
[Actor] Episode 2 Step 4 Loss: 0.7804375290870667
[Actor] Episode 2 Step 5 Loss: 0.7806243896484375
[Actor] Episode 2 Step 6 Loss: 0.7809846997261047
[Actor] Episode 2 Step 7 Loss: 0.7803871631622314
[Actor] Episode 2 Step 8 Loss: 0.7806073427200317
[Actor] Episode 2 Step 9 Loss: 0.779910683631897
[Actor] Episode 2 Step 10 Loss: 0.7805293202400208
[Actor] Episode 2 Step 11 Loss: 0.7815922498703003
[Actor] Episode 2 Step 12 Loss: 0.7824942469596863
[Actor] Episode 2 Step 13 Loss: 0.7815901041030884
[Actor] Episode 2 Step 14 Loss: 0.7781385779380798
[Actor] Episode 2 Step 15 Loss: 0.7812559604644775
[Actor] Episode 2 Step 16 Loss: 0.7797181606292725
[Actor] Episode 2 Step 17 Loss: 0.7809402346611023
[Actor] Episode 2 Step 18 Loss: 0.7821040153503418
[Actor] Episode 2 Step 19 Loss: 0.7806901335716248
[Actor] Episode 2 Step 20 Loss: 0.7805370688438416
[Actor] Episode 2 Step 21 Loss: 0.7821072936058044
[Actor] Episode 2 Step 22 Loss: 0.7803971171379089
[Actor] Episode 2 Step 23 Loss: 0.7806118130683899
[Actor] Episode 2 Step 24 Loss: 0.7802212238311768
[Actor] Episode 2 Step 25 Loss: 0.7809774875640869
[Actor] Episode 2 Step 26 Loss: 0.7806845903396606
-------------------------------------------------
[Actor] Episode 2 Average Loss: 0.7807935145166185
[Actor] Learning Rate: 0.000987258623354137
[Actor] Epoch Time: 1331.0976388454437s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 0.7813231348991394
[Actor] Episode 3 Step 1 Loss: 0.7797636985778809
[Actor] Episode 3 Step 2 Loss: 0.7824521064758301
[Actor] Episode 3 Step 3 Loss: 0.7807140350341797
[Actor] Episode 3 Step 4 Loss: 0.781713604927063
[Actor] Episode 3 Step 5 Loss: 0.7808551788330078
[Actor] Episode 3 Step 6 Loss: 0.781841516494751
[Actor] Episode 3 Step 7 Loss: 0.7807211875915527
[Actor] Episode 3 Step 8 Loss: 0.7809738516807556
[Actor] Episode 3 Step 9 Loss: 0.7811501026153564
[Actor] Episode 3 Step 10 Loss: 0.7802775502204895
[Actor] Episode 3 Step 11 Loss: 0.7813103199005127
[Actor] Episode 3 Step 12 Loss: 0.7815605998039246
[Actor] Episode 3 Step 13 Loss: 0.7811195254325867
[Actor] Episode 3 Step 14 Loss: 0.780828595161438
