2021-03-29 11:22:45.262286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:10902): Gdk-CRITICAL **: 11:22:48.657: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:22:48.992265: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:22:48.993648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:22:49.093593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.095865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:22:49.095919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:22:49.104685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:22:49.104848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:22:49.109013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:22:49.109448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:22:49.114895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:22:49.122568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:22:49.122889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:22:49.123166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.124244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.125153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:22:49.467943: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:22:49.468212: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:22:49.468556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.469572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:22:49.469955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:22:49.470370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:22:49.470573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:22:49.470810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:22:49.471142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:22:49.472304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:22:49.473026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:22:49.474241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:22:49.475158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.477695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:49.479355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:22:49.479448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:22:50.459306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:22:50.459349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:22:50.459362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:22:50.459742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:50.460742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:50.461610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:22:50.462574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 11:23:07.499828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:11136): Gdk-CRITICAL **: 11:23:10.606: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:23:11.085261: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:23:11.086875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:23:11.175923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.178467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:23:11.178572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:23:11.186260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:23:11.186430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:23:11.189957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:23:11.190345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:23:11.199104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:23:11.201092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:23:11.202523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:23:11.202766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.204601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.206386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:23:11.577839: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:23:11.579183: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:23:11.580745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.582799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:23:11.583309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:23:11.583810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:23:11.584062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:23:11.584611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:23:11.584753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:23:11.584890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:23:11.585091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:23:11.585238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:23:11.585489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.586843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:11.587777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:23:11.587901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:23:12.347845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:23:12.347887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:23:12.347896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:23:12.348237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:12.349061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:12.349957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:23:12.350907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617016995.367828390, 21760.294000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617016995.368742201, 21760.295000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617016995.368796568, 21760.295000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617016996.649754230, 21761.573000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617016996.950061691, 21761.872000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617016997.150619976, 21762.072000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617016997.551882324, 21762.472000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 11:23:42.151594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:23:42.758253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2822.91845703125
[Actor] Episode 0 Step 1 Loss: 2731.326904296875
[Actor] Episode 0 Step 2 Loss: 2800.947509765625
[Actor] Episode 0 Step 3 Loss: 2604.9677734375
[Actor] Episode 0 Step 4 Loss: 2701.36865234375
[Actor] Episode 0 Step 5 Loss: 2739.811279296875
[Actor] Episode 0 Step 6 Loss: 2757.145751953125
[Actor] Episode 0 Step 7 Loss: 2479.405029296875
[Actor] Episode 0 Step 8 Loss: 2634.036865234375
[Actor] Episode 0 Step 9 Loss: 2721.565673828125
[Actor] Episode 0 Step 10 Loss: 2716.44091796875
[Actor] Episode 0 Step 11 Loss: 2609.22119140625
[Actor] Episode 0 Step 12 Loss: 2837.034912109375
[Actor] Episode 0 Step 13 Loss: 2832.051513671875
[Actor] Episode 0 Step 14 Loss: 2938.108642578125
[Actor] Episode 0 Step 15 Loss: 2896.865478515625
[Actor] Episode 0 Step 16 Loss: 2961.62841796875
[Actor] Episode 0 Step 17 Loss: 3049.576904296875
2021-03-29 11:30:46.294080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:11728): Gdk-CRITICAL **: 11:30:49.375: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:30:49.828739: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:30:49.829926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:30:49.944948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:49.947719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:30:49.947813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:30:49.957210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:30:49.957999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:30:49.961781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:30:49.963133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:30:49.972677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:30:49.975529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:30:49.976109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:30:49.976555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:49.979182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:49.980755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:30:50.407635: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:30:50.407891: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:30:50.408210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:50.409190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:30:50.409238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:30:50.409437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:30:50.409543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:30:50.409618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:30:50.409691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:30:50.409762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:30:50.409939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:30:50.410033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:30:50.410239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:50.411248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:50.412174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:30:50.412231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:30:51.327647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:30:51.327695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:30:51.327706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:30:51.328061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:51.329036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:51.329881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:30:51.330669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 11:31:11.605506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:11978): Gdk-CRITICAL **: 11:31:15.095: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:31:15.382394: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:31:15.383591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:31:15.443680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.444597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:31:15.444644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:31:15.448580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:31:15.448736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:31:15.450378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:31:15.450807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:31:15.455563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:31:15.458851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:31:15.459864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:31:15.464293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.467394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.468319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:31:15.791272: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:31:15.791667: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:31:15.792008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.792864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:31:15.792906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:31:15.793082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:31:15.793180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:31:15.793256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:31:15.793337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:31:15.793380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:31:15.793424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:31:15.793468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:31:15.793623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.794454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:15.795079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:31:15.795141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:31:16.529036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:31:16.529210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:31:16.529235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:31:16.529603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:16.530549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:16.531279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:31:16.531986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617017479.525931953, 22235.163000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617017479.526664069, 22235.163000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617017479.526766573, 22235.163000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617017480.619004317, 22236.253000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617017480.831505445, 22236.463000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617017481.033104640, 22236.664000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617017481.232302101, 22236.863000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 11:31:45.477106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:31:46.075105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2958.59228515625
[Actor] Episode 0 Step 1 Loss: 2776.624267578125
[Actor] Episode 0 Step 2 Loss: 2752.046142578125
[Actor] Episode 0 Step 3 Loss: 3042.799072265625
[Actor] Episode 0 Step 4 Loss: 2698.462646484375
[Actor] Episode 0 Step 5 Loss: 2573.46533203125
[Actor] Episode 0 Step 6 Loss: 2720.638671875
[Actor] Episode 0 Step 7 Loss: 2883.693359375
[Actor] Episode 0 Step 8 Loss: 2840.561279296875
[Actor] Episode 0 Step 9 Loss: 2766.087646484375
[Actor] Episode 0 Step 10 Loss: 2573.260009765625
[Actor] Episode 0 Step 11 Loss: 2866.46533203125
[Actor] Episode 0 Step 12 Loss: 2639.644775390625
[Actor] Episode 0 Step 13 Loss: 2937.7216796875
[Actor] Episode 0 Step 14 Loss: 2556.9453125
[Actor] Episode 0 Step 15 Loss: 2821.885986328125
[Actor] Episode 0 Step 16 Loss: 2645.480712890625
[Actor] Episode 0 Step 17 Loss: 2678.859375
[Actor] Episode 0 Step 18 Loss: 2646.377685546875
[Actor] Episode 0 Step 19 Loss: 2853.634765625
[Actor] Episode 0 Step 20 Loss: 2783.4990234375
[Actor] Episode 0 Step 21 Loss: 2747.72998046875
[Actor] Episode 0 Step 22 Loss: 2849.249267578125
[Actor] Episode 0 Step 23 Loss: 2636.882080078125
[Actor] Episode 0 Step 24 Loss: 2662.853271484375
[Actor] Episode 0 Step 25 Loss: 2861.137451171875
[Actor] Episode 0 Step 26 Loss: 2595.95263671875
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2754.4648166232637
[Actor] Learning Rate: 0.009957346133887768
[Actor] Epoch Time: 591.982129573822s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 2792.473388671875
[Actor] Episode 1 Step 1 Loss: 2564.046142578125
[Actor] Episode 1 Step 2 Loss: 2743.173095703125
[Actor] Episode 1 Step 3 Loss: 2771.5244140625
[Actor] Episode 1 Step 4 Loss: 2884.955078125
[Actor] Episode 1 Step 5 Loss: 2475.915771484375
[Actor] Episode 1 Step 6 Loss: 2888.153564453125
[Actor] Episode 1 Step 7 Loss: 2712.619140625
[Actor] Episode 1 Step 8 Loss: 2706.12060546875
[Actor] Episode 1 Step 9 Loss: 2642.10986328125
[Actor] Episode 1 Step 10 Loss: 2881.69873046875
[Actor] Episode 1 Step 11 Loss: 3134.092529296875
[Actor] Episode 1 Step 12 Loss: 2802.285888671875
[Actor] Episode 1 Step 13 Loss: 2709.224853515625
[Actor] Episode 1 Step 14 Loss: 2926.834228515625
[Actor] Episode 1 Step 15 Loss: 2795.728271484375
[Actor] Episode 1 Step 16 Loss: 2887.117919921875
[Actor] Episode 1 Step 17 Loss: 2515.20068359375
[Actor] Episode 1 Step 18 Loss: 2797.818603515625
[Actor] Episode 1 Step 19 Loss: 2777.312744140625
[Actor] Episode 1 Step 20 Loss: 2925.75634765625
[Actor] Episode 1 Step 21 Loss: 2668.82568359375
[Actor] Episode 1 Step 22 Loss: 2726.951416015625
[Actor] Episode 1 Step 23 Loss: 2539.512451171875
[Actor] Episode 1 Step 24 Loss: 2799.239501953125
[Actor] Episode 1 Step 25 Loss: 2706.93798828125
[Actor] Episode 1 Step 26 Loss: 2941.256591796875
-------------------------------------------------
[Actor] Episode 1 Average Loss: 2767.2920554832176
[Actor] Learning Rate: 0.009914875030517578
[Actor] Epoch Time: 692.3682334423065s
-------------------------------------------------
[Actor] Starting Episode 2
2021-03-29 11:54:35.431207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:14731): Gdk-CRITICAL **: 11:54:39.110: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:54:39.464239: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:54:39.465497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:54:39.557088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.557993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:54:39.558032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:54:39.562117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:54:39.562279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:54:39.563965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:54:39.564365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:54:39.568599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:54:39.569613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:54:39.569885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:54:39.570155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.571216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.572078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:54:39.865087: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:54:39.865359: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:54:39.865686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.866615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:54:39.866646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:54:39.866842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:54:39.866911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:54:39.866953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:54:39.866991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:54:39.867035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:54:39.867073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:54:39.867110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:54:39.867304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.868275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:39.869097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:54:39.869140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:54:40.626808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:54:40.626850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:54:40.626859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:54:40.627174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:40.627998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:40.628701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:54:40.629306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 11:55:18.714704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:14966): Gdk-CRITICAL **: 11:55:22.450: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 11:55:22.829668: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:55:22.830879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 11:55:22.887998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:22.888777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:55:22.888815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:55:22.892247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:55:22.892543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:55:22.894093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:55:22.894497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:55:22.898363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:55:22.899320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:55:22.899569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:55:22.899766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:22.900745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:22.901487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 11:55:23.118485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 11:55:23.119025: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 11:55:23.119343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.120204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 11:55:23.120244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:55:23.120418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:55:23.120494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 11:55:23.120562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 11:55:23.120618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 11:55:23.120672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 11:55:23.120730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 11:55:23.120795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 11:55:23.120982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.121943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.122735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 11:55:23.122801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 11:55:23.835977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 11:55:23.836037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 11:55:23.836051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 11:55:23.836382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.837252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.837943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 11:55:23.838566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617018926.938719583, 23590.364000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617018926.939605055, 23590.365000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617018926.939768121, 23590.365000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617018928.141867503, 23591.565000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617018928.420941631, 23591.844000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617018928.621354919, 23592.043000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617018928.821411107, 23592.244000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 11:55:53.925872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 11:55:54.526055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2847.579345703125
[Actor] Episode 0 Step 1 Loss: 2904.695556640625
[Actor] Episode 0 Step 2 Loss: 2517.5224609375
[Actor] Episode 0 Step 3 Loss: 2778.82568359375
[Actor] Episode 0 Step 4 Loss: 2586.4873046875
[Actor] Episode 0 Step 5 Loss: 2661.273681640625
[Actor] Episode 0 Step 6 Loss: 2602.46337890625
[Actor] Episode 0 Step 7 Loss: 2769.66162109375
[Actor] Episode 0 Step 8 Loss: 2434.402587890625
[Actor] Episode 0 Step 9 Loss: 2619.56982421875
[Actor] Episode 0 Step 10 Loss: 2453.202880859375
[Actor] Episode 0 Step 11 Loss: 2238.110595703125
[Actor] Episode 0 Step 12 Loss: 2346.3203125
[Actor] Episode 0 Step 13 Loss: 2134.582275390625
[Actor] Episode 0 Step 14 Loss: 2022.4534912109375
[Actor] Episode 0 Step 15 Loss: 1664.9940185546875
[Actor] Episode 0 Step 16 Loss: 1601.974609375
[Actor] Episode 0 Step 17 Loss: 1521.251708984375
[Actor] Episode 0 Step 18 Loss: 1266.76611328125
[Actor] Episode 0 Step 19 Loss: 1369.6878662109375
[Actor] Episode 0 Step 20 Loss: 1203.921875
[Actor] Episode 0 Step 21 Loss: 1042.8223876953125
[Actor] Episode 0 Step 22 Loss: 954.876220703125
[Actor] Episode 0 Step 23 Loss: 867.9854125976562
[Actor] Episode 0 Step 24 Loss: 1030.7696533203125
[Actor] Episode 0 Step 25 Loss: 967.9642333984375
[Actor] Episode 0 Step 26 Loss: 1022.2627563476562
-------------------------------------------------
[Actor] Episode 0 Average Loss: 1941.9417724609375
[Actor] Learning Rate: 0.009957346133887768
[Actor] Epoch Time: 598.0073320865631s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1110.6097412109375
[Actor] Episode 1 Step 1 Loss: 1153.285888671875
[Actor] Episode 1 Step 2 Loss: 1090.4713134765625
[Actor] Episode 1 Step 3 Loss: 977.7395629882812
[Actor] Episode 1 Step 4 Loss: 973.3612060546875
[Actor] Episode 1 Step 5 Loss: 982.396728515625
[Actor] Episode 1 Step 6 Loss: 963.5922241210938
[Actor] Episode 1 Step 7 Loss: 867.2364501953125
[Actor] Episode 1 Step 8 Loss: 853.6422729492188
[Actor] Episode 1 Step 9 Loss: 870.5802001953125
[Actor] Episode 1 Step 10 Loss: 921.9742431640625
[Actor] Episode 1 Step 11 Loss: 981.742431640625
[Actor] Episode 1 Step 12 Loss: 901.234619140625
[Actor] Episode 1 Step 13 Loss: 886.7730712890625
[Actor] Episode 1 Step 14 Loss: 917.5892333984375
[Actor] Episode 1 Step 15 Loss: 840.1699829101562
[Actor] Episode 1 Step 16 Loss: 907.9117431640625
[Actor] Episode 1 Step 17 Loss: 851.3845825195312
[Actor] Episode 1 Step 18 Loss: 976.8154907226562
[Actor] Episode 1 Step 19 Loss: 898.4563598632812
[Actor] Episode 1 Step 20 Loss: 808.4248657226562
[Actor] Episode 1 Step 21 Loss: 952.6575317382812
[Actor] Episode 1 Step 22 Loss: 826.8793334960938
[Actor] Episode 1 Step 23 Loss: 833.5022583007812
[Actor] Episode 1 Step 24 Loss: 937.2106323242188
[Actor] Episode 1 Step 25 Loss: 866.6038208007812
[Actor] Episode 1 Step 26 Loss: 838.4423828125
-------------------------------------------------
[Actor] Episode 1 Average Loss: 925.5810433846933
[Actor] Learning Rate: 0.009914875030517578
[Actor] Epoch Time: 597.2504880428314s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 808.606201171875
[Actor] Episode 2 Step 1 Loss: 945.66015625
[Actor] Episode 2 Step 2 Loss: 937.00732421875
[Actor] Episode 2 Step 3 Loss: 742.4495849609375
[Actor] Episode 2 Step 4 Loss: 856.9138793945312
[Actor] Episode 2 Step 5 Loss: 769.9121704101562
[Actor] Episode 2 Step 6 Loss: 905.2955322265625
[Actor] Episode 2 Step 7 Loss: 842.2354736328125
[Actor] Episode 2 Step 8 Loss: 764.8172607421875
[Actor] Episode 2 Step 9 Loss: 726.7734375
[Actor] Episode 2 Step 10 Loss: 781.7955322265625
[Actor] Episode 2 Step 11 Loss: 835.6787719726562
[Actor] Episode 2 Step 12 Loss: 779.8541259765625
[Actor] Episode 2 Step 13 Loss: 776.4295043945312
[Actor] Episode 2 Step 14 Loss: 836.8441162109375
[Actor] Episode 2 Step 15 Loss: 849.294921875
[Actor] Episode 2 Step 16 Loss: 735.4261474609375
[Actor] Episode 2 Step 17 Loss: 802.6954956054688
[Actor] Episode 2 Step 18 Loss: 731.0262451171875
[Actor] Episode 2 Step 19 Loss: 853.3369140625
[Actor] Episode 2 Step 20 Loss: 736.0565185546875
[Actor] Episode 2 Step 21 Loss: 813.642578125
[Actor] Episode 2 Step 22 Loss: 663.2765502929688
[Actor] Episode 2 Step 23 Loss: 706.2730102539062
[Actor] Episode 2 Step 24 Loss: 661.2645263671875
[Actor] Episode 2 Step 25 Loss: 620.2680053710938
[Actor] Episode 2 Step 26 Loss: 767.1080322265625
-------------------------------------------------
[Actor] Episode 2 Average Loss: 787.0348895037615
[Actor] Learning Rate: 0.009872585535049438
[Actor] Epoch Time: 575.7803678512573s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 724.5133666992188
[Actor] Episode 3 Step 1 Loss: 751.2781982421875
[Actor] Episode 3 Step 2 Loss: 664.4991455078125
[Actor] Episode 3 Step 3 Loss: 694.4290161132812
[Actor] Episode 3 Step 4 Loss: 687.64208984375
[Actor] Episode 3 Step 5 Loss: 670.943115234375
[Actor] Episode 3 Step 6 Loss: 703.4284057617188
[Actor] Episode 3 Step 7 Loss: 622.4506225585938
[Actor] Episode 3 Step 8 Loss: 618.72900390625
[Actor] Episode 3 Step 9 Loss: 674.3793334960938
[Actor] Episode 3 Step 10 Loss: 624.370849609375
[Actor] Episode 3 Step 11 Loss: 579.9887084960938
[Actor] Episode 3 Step 12 Loss: 599.8197021484375
[Actor] Episode 3 Step 13 Loss: 580.2559814453125
[Actor] Episode 3 Step 14 Loss: 595.5353393554688
[Actor] Episode 3 Step 15 Loss: 629.1690673828125
[Actor] Episode 3 Step 16 Loss: 602.281005859375
[Actor] Episode 3 Step 17 Loss: 472.7088317871094
[Actor] Episode 3 Step 18 Loss: 499.284912109375
[Actor] Episode 3 Step 19 Loss: 475.34063720703125
[Actor] Episode 3 Step 20 Loss: 454.19757080078125
[Actor] Episode 3 Step 21 Loss: 476.9172668457031
[Actor] Episode 3 Step 22 Loss: 439.6282043457031
[Actor] Episode 3 Step 23 Loss: 520.2371215820312
[Actor] Episode 3 Step 24 Loss: 475.26788330078125
[Actor] Episode 3 Step 25 Loss: 394.9096374511719
[Actor] Episode 3 Step 26 Loss: 415.99224853515625
-------------------------------------------------
[Actor] Episode 3 Average Loss: 579.5628616898148
[Actor] Learning Rate: 0.009830474853515625
[Actor] Epoch Time: 581.3327763080597s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 444.9508972167969
[Actor] Episode 4 Step 1 Loss: 359.14739990234375
[Actor] Episode 4 Step 2 Loss: 337.3023986816406
[Actor] Episode 4 Step 3 Loss: 307.81939697265625
[Actor] Episode 4 Step 4 Loss: 333.5974426269531
[Actor] Episode 4 Step 5 Loss: 315.49652099609375
[Actor] Episode 4 Step 6 Loss: 291.1368408203125
[Actor] Episode 4 Step 7 Loss: 262.3897399902344
[Actor] Episode 4 Step 8 Loss: 238.2148895263672
[Actor] Episode 4 Step 9 Loss: 201.20797729492188
[Actor] Episode 4 Step 10 Loss: 174.02590942382812
[Actor] Episode 4 Step 11 Loss: 161.1482391357422
[Actor] Episode 4 Step 12 Loss: 156.00999450683594
[Actor] Episode 4 Step 13 Loss: 121.2495346069336
[Actor] Episode 4 Step 14 Loss: 110.34774780273438
[Actor] Episode 4 Step 15 Loss: 91.80764770507812
[Actor] Episode 4 Step 16 Loss: 67.67169952392578
[Actor] Episode 4 Step 17 Loss: 55.006141662597656
[Actor] Episode 4 Step 18 Loss: 41.841800689697266
[Actor] Episode 4 Step 19 Loss: 33.075714111328125
[Actor] Episode 4 Step 20 Loss: 22.63088607788086
[Actor] Episode 4 Step 21 Loss: 12.581764221191406
[Actor] Episode 4 Step 22 Loss: 7.050412654876709
[Actor] Episode 4 Step 23 Loss: 2.9043641090393066
[Actor] Episode 4 Step 24 Loss: 0.6676095724105835
[Actor] Episode 4 Step 25 Loss: 0.1494278758764267
[Actor] Episode 4 Step 26 Loss: 0.7516219615936279
-------------------------------------------------
[Actor] Episode 4 Average Loss: 153.71051924703298
[Actor] Learning Rate: 0.009788545779883862
[Actor] Epoch Time: 574.7860498428345s
-------------------------------------------------
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 1.9319522380828857
[Actor] Episode 5 Step 1 Loss: 3.970778226852417
[Actor] Episode 5 Step 2 Loss: 5.562802314758301
[Actor] Episode 5 Step 3 Loss: 7.473144054412842
[Actor] Episode 5 Step 4 Loss: 8.813035011291504
[Actor] Episode 5 Step 5 Loss: 9.534040451049805
[Actor] Episode 5 Step 6 Loss: 10.509159088134766
[Actor] Episode 5 Step 7 Loss: 8.617586135864258
[Actor] Episode 5 Step 8 Loss: 9.425996780395508
[Actor] Episode 5 Step 9 Loss: 7.327831745147705
[Actor] Episode 5 Step 10 Loss: 7.328417778015137
[Actor] Episode 5 Step 11 Loss: 4.763833999633789
[Actor] Episode 5 Step 12 Loss: 4.00832986831665
[Actor] Episode 5 Step 13 Loss: 3.295306444168091
[Actor] Episode 5 Step 14 Loss: 3.391413688659668
[Actor] Episode 5 Step 15 Loss: 3.0909063816070557
[Actor] Episode 5 Step 16 Loss: 3.064626455307007
[Actor] Episode 5 Step 17 Loss: 3.202522039413452
[Actor] Episode 5 Step 18 Loss: 3.363083839416504
[Actor] Episode 5 Step 19 Loss: 3.6147494316101074
[Actor] Episode 5 Step 20 Loss: 3.6941137313842773
[Actor] Episode 5 Step 21 Loss: 3.7391245365142822
[Actor] Episode 5 Step 22 Loss: 4.099466800689697
[Actor] Episode 5 Step 23 Loss: 3.829779863357544
[Actor] Episode 5 Step 24 Loss: 3.589510440826416
[Actor] Episode 5 Step 25 Loss: 3.5281686782836914
[Actor] Episode 5 Step 26 Loss: 3.549088716506958
-------------------------------------------------
[Actor] Episode 5 Average Loss: 5.122917360729641
[Actor] Learning Rate: 0.009746793657541275
[Actor] Epoch Time: 603.798600435257s
-------------------------------------------------
[Actor] Starting Episode 6
[Actor] Episode 6 Step 0 Loss: 3.281437635421753
[Actor] Episode 6 Step 1 Loss: 3.0155441761016846
[Actor] Episode 6 Step 2 Loss: 2.8063430786132812
[Actor] Episode 6 Step 3 Loss: 2.618389844894409
[Actor] Episode 6 Step 4 Loss: 2.39631986618042
[Actor] Episode 6 Step 5 Loss: 2.247291326522827
[Actor] Episode 6 Step 6 Loss: 1.9426361322402954
[Actor] Episode 6 Step 7 Loss: 1.9770259857177734
[Actor] Episode 6 Step 8 Loss: 1.7694079875946045
[Actor] Episode 6 Step 9 Loss: 1.5691192150115967
[Actor] Episode 6 Step 10 Loss: 1.6734930276870728
[Actor] Episode 6 Step 11 Loss: 1.4497148990631104
[Actor] Episode 6 Step 12 Loss: 1.336016058921814
[Actor] Episode 6 Step 13 Loss: 1.2685348987579346
[Actor] Episode 6 Step 14 Loss: 1.1841171979904175
[Actor] Episode 6 Step 15 Loss: 1.1406633853912354
[Actor] Episode 6 Step 16 Loss: 1.120911955833435
[Actor] Episode 6 Step 17 Loss: 0.9826454520225525
[Actor] Episode 6 Step 18 Loss: 1.037247657775879
[Actor] Episode 6 Step 19 Loss: 0.9041044116020203
[Actor] Episode 6 Step 20 Loss: 0.947641134262085
[Actor] Episode 6 Step 21 Loss: 0.8589718341827393
[Actor] Episode 6 Step 22 Loss: 0.8737093210220337
[Actor] Episode 6 Step 23 Loss: 0.8731238842010498
[Actor] Episode 6 Step 24 Loss: 0.8529062867164612
[Actor] Episode 6 Step 25 Loss: 0.8333150148391724
[Actor] Episode 6 Step 26 Loss: 0.9048529267311096
-------------------------------------------------
[Actor] Episode 6 Average Loss: 1.550573503529584
[Actor] Learning Rate: 0.009705220349133015
[Actor] Epoch Time: 579.9445235729218s
-------------------------------------------------
[Actor] Starting Episode 7
[Actor] Episode 7 Step 0 Loss: 0.8140974640846252
[Actor] Episode 7 Step 1 Loss: 0.855606198310852
[Actor] Episode 7 Step 2 Loss: 0.8681845664978027
[Actor] Episode 7 Step 3 Loss: 0.8815204501152039
[Actor] Episode 7 Step 4 Loss: 0.8807314038276672
[Actor] Episode 7 Step 5 Loss: 0.9060611128807068
[Actor] Episode 7 Step 6 Loss: 0.8521240949630737
[Actor] Episode 7 Step 7 Loss: 0.8372002243995667
[Actor] Episode 7 Step 8 Loss: 0.8376628160476685
[Actor] Episode 7 Step 9 Loss: 0.8112800717353821
[Actor] Episode 7 Step 10 Loss: 0.7592924237251282
[Actor] Episode 7 Step 11 Loss: 0.7848509550094604
[Actor] Episode 7 Step 12 Loss: 0.7869810461997986
[Actor] Episode 7 Step 13 Loss: 0.7475804090499878
[Actor] Episode 7 Step 14 Loss: 0.8054928183555603
[Actor] Episode 7 Step 15 Loss: 0.813511848449707
[Actor] Episode 7 Step 16 Loss: 0.8584814667701721
[Actor] Episode 7 Step 17 Loss: 0.7947593927383423
[Actor] Episode 7 Step 18 Loss: 0.7285060286521912
[Actor] Episode 7 Step 19 Loss: 0.7489449381828308
[Actor] Episode 7 Step 20 Loss: 0.7471464276313782
[Actor] Episode 7 Step 21 Loss: 0.7939664721488953
[Actor] Episode 7 Step 22 Loss: 0.7095596790313721
[Actor] Episode 7 Step 23 Loss: 0.6762566566467285
[Actor] Episode 7 Step 24 Loss: 0.7625177502632141
[Actor] Episode 7 Step 25 Loss: 0.732241153717041
[Actor] Episode 7 Step 26 Loss: 0.7585165500640869
-------------------------------------------------
[Actor] Episode 7 Average Loss: 0.7982620155369794
[Actor] Learning Rate: 0.009663824923336506
[Actor] Epoch Time: 594.3829593658447s
-------------------------------------------------
[Actor] Starting Episode 8
[Actor] Episode 8 Step 0 Loss: 0.731012761592865
[Actor] Episode 8 Step 1 Loss: 0.7073788642883301
[Actor] Episode 8 Step 2 Loss: 0.6405766010284424
[Actor] Episode 8 Step 3 Loss: 0.6299082040786743
[Actor] Episode 8 Step 4 Loss: 0.6498858332633972
[Actor] Episode 8 Step 5 Loss: 0.652130663394928
[Actor] Episode 8 Step 6 Loss: 0.6521800756454468
[Actor] Episode 8 Step 7 Loss: 0.6074814200401306
[Actor] Episode 8 Step 8 Loss: 0.6592065691947937
[Actor] Episode 8 Step 9 Loss: 0.6368042230606079
[Actor] Episode 8 Step 10 Loss: 0.5982142090797424
[Actor] Episode 8 Step 11 Loss: 0.6165066957473755
[Actor] Episode 8 Step 12 Loss: 0.6058681607246399
[Actor] Episode 8 Step 13 Loss: 0.5415894985198975
[Actor] Episode 8 Step 14 Loss: 0.5790721774101257
[Actor] Episode 8 Step 15 Loss: 0.5464078187942505
[Actor] Episode 8 Step 16 Loss: 0.522191047668457
[Actor] Episode 8 Step 17 Loss: 0.5204995274543762
[Actor] Episode 8 Step 18 Loss: 0.5197969675064087
[Actor] Episode 8 Step 19 Loss: 0.5106034278869629
[Actor] Episode 8 Step 20 Loss: 0.5029547810554504
[Actor] Episode 8 Step 21 Loss: 0.48501521348953247
[Actor] Episode 8 Step 22 Loss: 0.44360145926475525
[Actor] Episode 8 Step 23 Loss: 0.41971302032470703
[Actor] Episode 8 Step 24 Loss: 0.4397726356983185
[Actor] Episode 8 Step 25 Loss: 0.4256489872932434
[Actor] Episode 8 Step 26 Loss: 0.40722784399986267
-------------------------------------------------
[Actor] Episode 8 Average Loss: 0.564861062500212
[Actor] Learning Rate: 0.0096226055175066
[Actor] Epoch Time: 582.9244103431702s
-------------------------------------------------
[Actor] Starting Episode 9
[Actor] Episode 9 Step 0 Loss: 0.4128430187702179
[Actor] Episode 9 Step 1 Loss: 0.36170223355293274
[Actor] Episode 9 Step 2 Loss: 0.3539299964904785
[Actor] Episode 9 Step 3 Loss: 0.3723517954349518
[Actor] Episode 9 Step 4 Loss: 0.3376937508583069
[Actor] Episode 9 Step 5 Loss: 0.33697864413261414
[Actor] Episode 9 Step 6 Loss: 0.3140866458415985
[Actor] Episode 9 Step 7 Loss: 0.305343359708786
[Actor] Episode 9 Step 8 Loss: 0.29077696800231934
[Actor] Episode 9 Step 9 Loss: 0.28564688563346863
[Actor] Episode 9 Step 10 Loss: 0.2611479163169861
[Actor] Episode 9 Step 11 Loss: 0.25264203548431396
[Actor] Episode 9 Step 12 Loss: 0.24490396678447723
[Actor] Episode 9 Step 13 Loss: 0.23344632983207703
[Actor] Episode 9 Step 14 Loss: 0.19906070828437805
[Actor] Episode 9 Step 15 Loss: 0.18685099482536316
[Actor] Episode 9 Step 16 Loss: 0.17899003624916077
[Actor] Episode 9 Step 17 Loss: 0.16130629181861877
[Actor] Episode 9 Step 18 Loss: 0.14309892058372498
[Actor] Episode 9 Step 19 Loss: 0.14409111440181732
[Actor] Episode 9 Step 20 Loss: 0.12689362466335297
[Actor] Episode 9 Step 21 Loss: 0.11300507932901382
[Actor] Episode 9 Step 22 Loss: 0.10529986768960953
[Actor] Episode 9 Step 23 Loss: 0.0883791521191597
[Actor] Episode 9 Step 24 Loss: 0.08067504316568375
[Actor] Episode 9 Step 25 Loss: 0.07640063762664795
[Actor] Episode 9 Step 26 Loss: 0.06822755932807922
-------------------------------------------------
[Actor] Episode 9 Average Loss: 0.22354713247881997
[Actor] Learning Rate: 0.009581562131643295
[Actor] Epoch Time: 581.7502419948578s
-------------------------------------------------
[Actor] Starting Episode 10
[Actor] Episode 10 Step 0 Loss: 0.060434386134147644
[Actor] Episode 10 Step 1 Loss: 0.04923171550035477
[Actor] Episode 10 Step 2 Loss: 0.04486655816435814
[Actor] Episode 10 Step 3 Loss: 0.040454793721437454
[Actor] Episode 10 Step 4 Loss: 0.03542429953813553
[Actor] Episode 10 Step 5 Loss: 0.028986411169171333
[Actor] Episode 10 Step 6 Loss: 0.02362900599837303
[Actor] Episode 10 Step 7 Loss: 0.02178630605340004
[Actor] Episode 10 Step 8 Loss: 0.016965901479125023
[Actor] Episode 10 Step 9 Loss: 0.014604507014155388
[Actor] Episode 10 Step 10 Loss: 0.013556744903326035
[Actor] Episode 10 Step 11 Loss: 0.011905179359018803
[Actor] Episode 10 Step 12 Loss: 0.008721895515918732
[Actor] Episode 10 Step 13 Loss: 0.008476020768284798
[Actor] Episode 10 Step 14 Loss: 0.006709079258143902
[Actor] Episode 10 Step 15 Loss: 0.005118653178215027
[Actor] Episode 10 Step 16 Loss: 0.0037933876737952232
[Actor] Episode 10 Step 17 Loss: 0.003545707557350397
[Actor] Episode 10 Step 18 Loss: 0.003652046900242567
[Actor] Episode 10 Step 19 Loss: 0.002032705582678318
[Actor] Episode 10 Step 20 Loss: 0.002069120993837714
[Actor] Episode 10 Step 21 Loss: 0.0019967106636613607
[Actor] Episode 10 Step 22 Loss: 0.0013172123581171036
[Actor] Episode 10 Step 23 Loss: 0.0010175076313316822
[Actor] Episode 10 Step 24 Loss: 0.0012652305886149406
[Actor] Episode 10 Step 25 Loss: 0.0008467596489936113
[Actor] Episode 10 Step 26 Loss: 0.000592433731071651
-------------------------------------------------
[Actor] Episode 10 Average Loss: 0.015296306706861489
[Actor] Learning Rate: 0.009540693834424019
[Actor] Epoch Time: 582.8109114170074s
-------------------------------------------------
[Actor] Starting Episode 11
[Actor] Episode 11 Step 0 Loss: 0.0007789935916662216
[Actor] Episode 11 Step 1 Loss: 0.0006997555028647184
[Actor] Episode 11 Step 2 Loss: 0.0004579118103720248
[Actor] Episode 11 Step 3 Loss: 0.00043789210030809045
[Actor] Episode 11 Step 4 Loss: 0.0004500499926507473
[Actor] Episode 11 Step 5 Loss: 0.0004378459707368165
[Actor] Episode 11 Step 6 Loss: 0.0003376939566805959
[Actor] Episode 11 Step 7 Loss: 0.00036780134541913867
[Actor] Episode 11 Step 8 Loss: 0.0003671979939099401
[Actor] Episode 11 Step 9 Loss: 0.0002922553685493767
[Actor] Episode 11 Step 10 Loss: 0.00030403363052755594
[Actor] Episode 11 Step 11 Loss: 0.0003326997102703899
[Actor] Episode 11 Step 12 Loss: 0.00028134346939623356
[Actor] Episode 11 Step 13 Loss: 0.00028241565451025963
[Actor] Episode 11 Step 14 Loss: 0.00029261544113978744
[Actor] Episode 11 Step 15 Loss: 0.00029318933957256377
[Actor] Episode 11 Step 16 Loss: 0.00028741706046275795
[Actor] Episode 11 Step 17 Loss: 0.00030100918957032263
[Actor] Episode 11 Step 18 Loss: 0.00030772131867706776
[Actor] Episode 11 Step 19 Loss: 0.00028779770946130157
[Actor] Episode 11 Step 20 Loss: 0.0002787474950309843
[Actor] Episode 11 Step 21 Loss: 0.00028867230867035687
[Actor] Episode 11 Step 22 Loss: 0.0002859493251889944
[Actor] Episode 11 Step 23 Loss: 0.0002674225834198296
[Actor] Episode 11 Step 24 Loss: 0.0002816499909386039
[Actor] Episode 11 Step 25 Loss: 0.00028404322802089155
[Actor] Episode 11 Step 26 Loss: 0.0002777723711915314
-------------------------------------------------
[Actor] Episode 11 Average Loss: 0.0003541443503410038
[Actor] Learning Rate: 0.009499998763203621
[Actor] Epoch Time: 626.7858037948608s
-------------------------------------------------
[Actor] Starting Episode 12
[Actor] Episode 12 Step 0 Loss: 0.00027830430190078914
[Actor] Episode 12 Step 1 Loss: 0.0002826835843734443
[Actor] Episode 12 Step 2 Loss: 0.00027943216264247894
[Actor] Episode 12 Step 3 Loss: 0.0002754756424110383
[Actor] Episode 12 Step 4 Loss: 0.00027806562138721347
[Actor] Episode 12 Step 5 Loss: 0.0002886699512600899
[Actor] Episode 12 Step 6 Loss: 0.00027308586868457496
[Actor] Episode 12 Step 7 Loss: 0.0002743555814959109
[Actor] Episode 12 Step 8 Loss: 0.00028366013430058956
[Actor] Episode 12 Step 9 Loss: 0.00027673880686052144
[Actor] Episode 12 Step 10 Loss: 0.0002715383016038686
[Actor] Episode 12 Step 11 Loss: 0.0002831426099874079
[Actor] Episode 12 Step 12 Loss: 0.0002812518214341253
[Actor] Episode 12 Step 13 Loss: 0.0002712177229113877
[Actor] Episode 12 Step 14 Loss: 0.0002798883942887187
[Actor] Episode 12 Step 15 Loss: 0.0002875790814869106
[Actor] Episode 12 Step 16 Loss: 0.0002735892776399851
[Actor] Episode 12 Step 17 Loss: 0.0002719225885812193
[Actor] Episode 12 Step 18 Loss: 0.00027367594884708524
[Actor] Episode 12 Step 19 Loss: 0.00027798619703389704
[Actor] Episode 12 Step 20 Loss: 0.00027390947798267007
[Actor] Episode 12 Step 21 Loss: 0.00027076510014012456
[Actor] Episode 12 Step 22 Loss: 0.0002800783549901098
[Actor] Episode 12 Step 23 Loss: 0.00026928572333417833
[Actor] Episode 12 Step 24 Loss: 0.0002700049080885947
[Actor] Episode 12 Step 25 Loss: 0.0002827628923114389
[Actor] Episode 12 Step 26 Loss: 0.00026792087010107934
-------------------------------------------------
[Actor] Episode 12 Average Loss: 0.00027692558985479453
[Actor] Learning Rate: 0.00945947878062725
[Actor] Epoch Time: 588.8521845340729s
-------------------------------------------------
[Actor] Starting Episode 13
[Actor] Episode 13 Step 0 Loss: 0.0002753867011051625
[Actor] Episode 13 Step 1 Loss: 0.00026976040680892766
[Actor] Episode 13 Step 2 Loss: 0.0002716169983614236
[Actor] Episode 13 Step 3 Loss: 0.00028455417486838996
[Actor] Episode 13 Step 4 Loss: 0.0002725326339714229
[Actor] Episode 13 Step 5 Loss: 0.0002748557017184794
[Actor] Episode 13 Step 6 Loss: 0.00027480386779643595
[Actor] Episode 13 Step 7 Loss: 0.0002690351102501154
[Actor] Episode 13 Step 8 Loss: 0.00026646291371434927
[Actor] Episode 13 Step 9 Loss: 0.0002744882076513022
[Actor] Episode 13 Step 10 Loss: 0.00026818024343810976
[Actor] Episode 13 Step 11 Loss: 0.000269185722572729
[Actor] Episode 13 Step 12 Loss: 0.0002739506307989359
[Actor] Episode 13 Step 13 Loss: 0.00027493940433487296
[Actor] Episode 13 Step 14 Loss: 0.00027259133639745414
[Actor] Episode 13 Step 15 Loss: 0.0002709828841034323
[Actor] Episode 13 Step 16 Loss: 0.00027651264099404216
[Actor] Episode 13 Step 17 Loss: 0.00028055079746991396
[Actor] Episode 13 Step 18 Loss: 0.00025818723952397704
[Actor] Episode 13 Step 19 Loss: 0.0002688871754799038
[Actor] Episode 13 Step 20 Loss: 0.0002843570546247065
[Actor] Episode 13 Step 21 Loss: 0.0002782545634545386
[Actor] Episode 13 Step 22 Loss: 0.0002823826507665217
[Actor] Episode 13 Step 23 Loss: 0.0002692020498216152
[Actor] Episode 13 Step 24 Loss: 0.00027706826222129166
[Actor] Episode 13 Step 25 Loss: 0.0002771365689113736
[Actor] Episode 13 Step 26 Loss: 0.0002687735832296312
-------------------------------------------------
[Actor] Episode 13 Average Loss: 0.0002735051675699651
[Actor] Learning Rate: 0.009419132024049759
[Actor] Epoch Time: 647.0357213020325s
-------------------------------------------------
[Actor] Starting Episode 14
[Actor] Episode 14 Step 0 Loss: 0.00027239471091888845
[Actor] Episode 14 Step 1 Loss: 0.00027455700910650194
[Actor] Episode 14 Step 2 Loss: 0.00027533198590390384
[Actor] Episode 14 Step 3 Loss: 0.00026640098076313734
[Actor] Episode 14 Step 4 Loss: 0.00027683863299898803
[Actor] Episode 14 Step 5 Loss: 0.0002725974773056805
[Actor] Episode 14 Step 6 Loss: 0.0002699597680475563
[Actor] Episode 14 Step 7 Loss: 0.00027782897814176977
[Actor] Episode 14 Step 8 Loss: 0.0002727681421674788
[Actor] Episode 14 Step 9 Loss: 0.00027267131372354925
[Actor] Episode 14 Step 10 Loss: 0.00028505915543064475
[Actor] Episode 14 Step 11 Loss: 0.00027549159131012857
[Actor] Episode 14 Step 12 Loss: 0.0002749442937783897
[Actor] Episode 14 Step 13 Loss: 0.00028128630947321653
[Actor] Episode 14 Step 14 Loss: 0.00027483460144139826
[Actor] Episode 14 Step 15 Loss: 0.0002748059923760593
[Actor] Episode 14 Step 16 Loss: 0.0002857482177205384
[Actor] Episode 14 Step 17 Loss: 0.0002647573419380933
[Actor] Episode 14 Step 18 Loss: 0.0002676366420928389
[Actor] Episode 14 Step 19 Loss: 0.00026988665922544897
[Actor] Episode 14 Step 20 Loss: 0.00027496341499499977
[Actor] Episode 14 Step 21 Loss: 0.00028031101101078093
[Actor] Episode 14 Step 22 Loss: 0.00026567355962470174
[Actor] Episode 14 Step 23 Loss: 0.0002711931592784822
[Actor] Episode 14 Step 24 Loss: 0.0002823821851052344
[Actor] Episode 14 Step 25 Loss: 0.0002796470944304019
[Actor] Episode 14 Step 26 Loss: 0.00026905201957561076
-------------------------------------------------
[Actor] Episode 14 Average Loss: 0.00027440823140312677
[Actor] Learning Rate: 0.009378955699503422
[Actor] Epoch Time: 607.0559651851654s
-------------------------------------------------
[Actor] Starting Episode 15
[Actor] Episode 15 Step 0 Loss: 0.00026654789689928293
[Actor] Episode 15 Step 1 Loss: 0.00028341353754512966
[Actor] Episode 15 Step 2 Loss: 0.00027595824212767184
[Actor] Episode 15 Step 3 Loss: 0.0002726177335716784
[Actor] Episode 15 Step 4 Loss: 0.00026261573657393456
[Actor] Episode 15 Step 5 Loss: 0.00027561828028410673
[Actor] Episode 15 Step 6 Loss: 0.0002757097245194018
[Actor] Episode 15 Step 7 Loss: 0.00027477164985612035
[Actor] Episode 15 Step 8 Loss: 0.0002777287445496768
[Actor] Episode 15 Step 9 Loss: 0.0002650496317073703
[Actor] Episode 15 Step 10 Loss: 0.0002702669007703662
[Actor] Episode 15 Step 11 Loss: 0.00026969521422870457
[Actor] Episode 15 Step 12 Loss: 0.0002837143256329
[Actor] Episode 15 Step 13 Loss: 0.000265848619164899
[Actor] Episode 15 Step 14 Loss: 0.00026802433421835303
[Actor] Episode 15 Step 15 Loss: 0.0002698912867344916
[Actor] Episode 15 Step 16 Loss: 0.0002737312752287835
[Actor] Episode 15 Step 17 Loss: 0.0002801899681799114
[Actor] Episode 15 Step 18 Loss: 0.0002681580954231322
[Actor] Episode 15 Step 19 Loss: 0.0002772855223156512
[Actor] Episode 15 Step 20 Loss: 0.0002789026184473187
[Actor] Episode 15 Step 21 Loss: 0.00027626074734143913
[Actor] Episode 15 Step 22 Loss: 0.0002676591102499515
[Actor] Episode 15 Step 23 Loss: 0.00027501024305820465
[Actor] Episode 15 Step 24 Loss: 0.00027720496291294694
[Actor] Episode 15 Step 25 Loss: 0.000271331868134439
[Actor] Episode 15 Step 26 Loss: 0.0002782294759526849
-------------------------------------------------
[Actor] Episode 15 Average Loss: 0.0002733865090973537
[Actor] Learning Rate: 0.009338951669633389
[Actor] Epoch Time: 622.2438864707947s
-------------------------------------------------
[Actor] Starting Episode 16
2021-03-29 14:37:18.647603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:18986): Gdk-CRITICAL **: 14:37:21.824: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 14:37:22.279268: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:37:22.281371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 14:37:22.401935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.403852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:37:22.404883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:37:22.416083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:37:22.417043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:37:22.421855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:37:22.423864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:37:22.430840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:37:22.432276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:37:22.432601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:37:22.432840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.434394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.435534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 14:37:22.711077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 14:37:22.711413: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:37:22.711864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.712754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:37:22.712802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:37:22.713091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:37:22.713358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:37:22.713493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:37:22.713606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:37:22.713723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:37:22.713828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:37:22.713953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:37:22.714157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.715138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:22.716100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 14:37:22.716157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:37:23.580903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 14:37:23.580944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 14:37:23.580953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 14:37:23.581283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:23.582271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:23.583123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:37:23.583877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617028646.778547631, 33035.135000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617028646.779818149, 33035.136000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617028646.780083497, 33035.136000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617028647.966211855, 33036.320000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617028648.337576213, 33036.691000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617028648.740214785, 33037.091000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617028648.940806248, 33037.291000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 14:37:56.510675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:37:57.118318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
Y Pred
tf.Tensor(
[[[-1.4566654   0.03186938  1.3990915  ...  1.0638102   0.3703447
    0.08899603]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]

 [[-1.633518    0.07482602  1.4987856  ...  1.5641348  -0.1726768
   -0.42869928]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]

 [[-0.8692656  -1.272283    0.81224763 ...  0.36024916 -0.12541777
    1.2806077 ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]

 ...

 [[-1.3300343   0.12155276  1.2318702  ...  1.2198278   0.28485566
   -0.05422505]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]

 [[-1.1074485   0.00400239  1.3232207  ...  1.3239406   0.51368016
   -0.09786341]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]

 [[-1.7235801  -0.15690976  0.8412343  ...  1.1622303  -0.11356064
    0.20510758]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  ...
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]
  [ 0.          0.          0.         ...  0.          0.
    0.        ]]], shape=(1125, 350, 12), dtype=float32)
omega
tf.Tensor(
[[30.206013]
 [78.54021 ]
 [17.071724]
 ...
 [25.333616]
 [23.798069]
 [41.335594]], shape=(1125, 1), dtype=float32)
mu
tf.Tensor(
[[0.5000001  0.09999996 0.50000024 ... 0.5000002  0.10000014 0.5000006 ]
 [0.50000006 0.09999959 0.4999997  ... 0.49999967 0.0999996  0.5       ]
 [0.5000001  0.09999996 0.5000001  ... 0.5000003  0.10000015 0.5000004 ]
 ...
 [0.5000002  0.10000005 0.5000001  ... 0.50000024 0.10000008 0.5000003 ]
 [0.5000001  0.09999992 0.50000006 ... 0.50000024 0.10000008 0.50000036]
 [0.49999994 0.09999985 0.50000006 ... 0.50000006 0.09999986 0.50000036]], shape=(1125, 12), dtype=float32)
mean
tf.Tensor(
[[-3.4662303e-02  1.7558137e-01  1.7535537e-03 ... -3.3325404e-02
   1.6777694e-01  1.7686186e-02]
 [-3.3129182e-02  1.7118561e-01  1.7414242e-04 ... -3.2917671e-02
   1.6727334e-01  8.8099362e-03]
 [-3.5078887e-02  1.7677593e-01  2.1829382e-03 ... -3.3435762e-02
   1.6791396e-01  2.0098217e-02]
 ...
 [-3.4816612e-02  1.7602438e-01  1.9126832e-03 ... -3.3366337e-02
   1.6782758e-01  1.8580915e-02]
 [-3.4865353e-02  1.7616427e-01  1.9628704e-03 ... -3.3379134e-02
   1.6784382e-01  1.8862966e-02]
 [-3.4309302e-02  1.7456904e-01  1.3898313e-03 ... -3.3231676e-02
   1.6766089e-01  1.5642200e-02]], shape=(1125, 12), dtype=float32)
grads
[<tf.Tensor: shape=(6, 30), dtype=float32, numpy=
array([[ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan],
       [ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan],
       [ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan],
       [ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan],
       [ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan],
       [ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
        nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
         0.,  0., nan, nan]], dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([ 0., nan, nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,
       nan,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0., nan, nan,  0.,
        0.,  0., nan, nan], dtype=float32)>, <tf.Tensor: shape=(30, 60), dtype=float32, numpy=
array([[nan, nan, nan, ...,  0.,  0.,  0.],
       [nan, nan, nan, ...,  0.,  0.,  0.],
       [nan, nan, nan, ...,  0.,  0.,  0.],
       ...,
       [nan, nan, nan, ...,  0.,  0.,  0.],
       [nan, nan, nan, ...,  0.,  0.,  0.],
       [nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([nan, nan, nan,  0., nan, nan, nan,  0.,  0., nan, nan, nan,  0.,
        0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,
       nan, nan, nan,  0., nan,  0., nan,  0., nan, nan, nan,  0., nan,
       nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,  0., nan, nan, nan,
       nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[ 0.,  0.,  0., ..., nan,  0., nan],
       [ 0.,  0.,  0., ..., nan,  0., nan],
       [ 0.,  0.,  0., ..., nan,  0., nan],
       ...,
       [ 0.,  0.,  0., ..., nan,  0., nan],
       [ 0.,  0.,  0., ..., nan,  0., nan],
       [ 0.,  0.,  0., ..., nan,  0., nan]], dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([ 0.,  0.,  0.,  0., nan,  0., nan, nan,  0.,  0.,  0., nan,  0.,
        0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,
        0., nan,  0., nan], dtype=float32)>, <tf.Tensor: shape=(30, 25), dtype=float32, numpy=
array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.1993681e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.0871571e-07,
         1.4037857e-07,  1.0563585e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.1662958e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.4386711e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.8234749e-07,
         1.5803558e-07,  1.2004313e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.6628713e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.9159660e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.2830489e-07,
         1.2165427e-07,  9.1246818e-08,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         3.6179023e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.3512032e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.4345971e-07,
         1.4772563e-07,  1.1006257e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.4113639e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.0724104e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.8179631e-07,
         1.3492186e-07,  1.0277383e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         3.9738421e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.1419427e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.9876834e-07,
         1.3862811e-07,  1.0521879e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.0922740e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.4749761e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.8732533e-07,
         1.5872006e-07,  1.1979067e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.7020029e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.2576714e-07,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.2773364e-07,
         1.4502780e-07,  1.0957063e-07,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         4.2935838e-07]], dtype=float32)>, <tf.Tensor: shape=(25,), dtype=float32, numpy=
array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.4924908e-08,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -4.4176254e-08,
        1.8001966e-08,  2.6487916e-08,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        2.1701362e-08], dtype=float32)>, <tf.Tensor: shape=(25, 12), dtype=float32, numpy=
array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 1.2008550e-09, -4.3457984e-09,  3.4322643e-09,  4.1599453e-09,
        -1.6094636e-09, -3.0170528e-09, -2.4868343e-09,  2.7532407e-09,
         2.1769457e-09, -5.7018782e-11, -7.3383233e-10,  1.3493731e-08],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 9.0547830e-10, -3.2768714e-09,  2.5880309e-09,  3.1367233e-09,
        -1.2135790e-09, -2.2749382e-09, -1.8751318e-09,  2.0760349e-09,
         1.6415006e-09, -4.3015518e-11, -5.5335281e-10,  1.0174688e-08],
       [ 9.5135155e-10, -3.4428798e-09,  2.7191451e-09,  3.2956302e-09,
        -1.2750601e-09, -2.3902000e-09, -1.9701369e-09,  2.1812085e-09,
         1.7246480e-09, -4.5178181e-11, -5.8137328e-10,  1.0690153e-08],
       [ 2.0741402e-09, -7.5062392e-09,  5.9282987e-09,  7.1851978e-09,
        -2.7799176e-09, -5.2111253e-09, -4.2953303e-09,  4.7555089e-09,
         3.7601424e-09, -9.8553082e-11, -1.2675410e-09,  2.3306804e-08],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 8.7443985e-10, -3.1646443e-09,  2.4992945e-09,  3.0292620e-09,
        -1.1720220e-09, -2.1969679e-09, -1.8109341e-09,  2.0049209e-09,
         1.5852893e-09, -4.1596684e-11, -5.3439342e-10,  9.8260076e-09]],
      dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=
array([ 6.0399366e-09, -2.1858348e-08,  1.7263272e-08,  2.0923437e-08,
       -8.0951938e-09, -1.5174901e-08, -1.2508144e-08,  1.3848146e-08,
        1.0949593e-08, -2.8698549e-10, -3.6910726e-09,  6.7869820e-08],
      dtype=float32)>, <tf.Tensor: shape=(30, 25), dtype=float32, numpy=
array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.6815687e-03,  0.0000000e+00, -1.9828914e-04,  0.0000000e+00,
         0.0000000e+00,  1.1309276e-03, -1.5413638e-03,  1.5988892e-03,
         1.1178772e-03,  6.1127497e-04,  1.7052693e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -6.4744102e-04,  0.0000000e+00,  0.0000000e+00,  2.9438015e-04,
         0.0000000e+00,  5.4088188e-05, -1.1104778e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.8840818e-03,  0.0000000e+00, -2.2363289e-04,  0.0000000e+00,
         0.0000000e+00,  1.2687448e-03, -1.7265884e-03,  1.7938101e-03,
         1.2535431e-03,  6.8635296e-04,  1.9131682e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -7.2596018e-04,  0.0000000e+00,  0.0000000e+00,  3.2796242e-04,
         0.0000000e+00,  5.8298727e-05, -1.2448976e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 1.4596735e-03,  0.0000000e+00, -1.7173286e-04,  0.0000000e+00,
         0.0000000e+00,  9.8126160e-04, -1.3380775e-03,  1.3872734e-03,
         9.7008789e-04,  5.3022290e-04,  1.4795710e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -5.6186045e-04,  0.0000000e+00,  0.0000000e+00,  2.5603359e-04,
         0.0000000e+00,  4.7565365e-05, -9.6375996e-04,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.7784273e-03,  0.0000000e+00, -2.0827047e-04,  0.0000000e+00,
         0.0000000e+00,  1.1944767e-03, -1.6305437e-03,  1.6886597e-03,
         1.1812449e-03,  6.4504705e-04,  1.8010027e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -6.8419543e-04,  0.0000000e+00,  0.0000000e+00,  3.1317637e-04,
         0.0000000e+00,  5.9469465e-05, -1.1737691e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.6062121e-03,  0.0000000e+00, -1.9102884e-04,  0.0000000e+00,
         0.0000000e+00,  1.0820446e-03, -1.4718419e-03,  1.5298638e-03,
         1.0689350e-03,  5.8550492e-04,  1.6316626e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -6.1903486e-04,  0.0000000e+00,  0.0000000e+00,  2.7911091e-04,
         0.0000000e+00,  4.9106271e-05, -1.0614730e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.6533713e-03,  0.0000000e+00, -1.9614013e-04,  0.0000000e+00,
         0.0000000e+00,  1.1132639e-03, -1.5151930e-03,  1.5739781e-03,
         1.0999667e-03,  6.0219911e-04,  1.6787087e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -6.3702400e-04,  0.0000000e+00,  0.0000000e+00,  2.8794102e-04,
         0.0000000e+00,  5.1330611e-05, -1.0924061e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.8984450e-03,  0.0000000e+00, -2.2432380e-04,  0.0000000e+00,
         0.0000000e+00,  1.2772958e-03, -1.7400306e-03,  1.8058472e-03,
         1.2623798e-03,  6.9057307e-04,  1.9259995e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -7.3111558e-04,  0.0000000e+00,  0.0000000e+00,  3.3175811e-04,
         0.0000000e+00,  6.0338731e-05, -1.2539146e-03,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.7337573e-03,  0.0000000e+00, -2.0501296e-04,  0.0000000e+00,
         0.0000000e+00,  1.1666567e-03, -1.5890442e-03,  1.6494329e-03,
         1.1529757e-03,  6.3081551e-04,  1.7591798e-03,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        -6.6774781e-04,  0.0000000e+00,  0.0000000e+00,  3.0278816e-04,
         0.0000000e+00,  5.4869961e-05, -1.1452086e-03,  0.0000000e+00,
         0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(25,), dtype=float32, numpy=
array([ 1.1171593e-04,  0.0000000e+00, -3.0083347e-05,  0.0000000e+00,
        0.0000000e+00,  9.3832045e-05, -9.7737182e-05,  1.3353715e-04,
        8.6268992e-05,  5.7492965e-05,  1.4253872e-04,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
       -4.9334187e-05,  0.0000000e+00,  0.0000000e+00, -2.0487951e-06,
        0.0000000e+00, -2.3014383e-05, -8.1672821e-05,  0.0000000e+00,
        0.0000000e+00], dtype=float32)>, <tf.Tensor: shape=(25, 12), dtype=float32, numpy=
array([[ 3.28458613e-04,  2.28777921e-04,  1.66954575e-04,
         2.79390253e-04,  2.06206008e-04,  3.64081701e-04,
        -5.25867450e-04, -1.99594084e-04, -3.75738018e-04,
         1.24681945e-04,  2.89997435e-04,  2.96644343e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.15890143e-04,  8.11072532e-05,  5.83616165e-05,
         9.87193635e-05,  7.24135170e-05,  1.27884501e-04,
        -1.85585173e-04, -7.07832733e-05, -1.32033616e-04,
         4.41095362e-05,  1.02025399e-04,  1.05379644e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.37032082e-04,  9.58955352e-05,  6.90201559e-05,
         1.16725816e-04,  8.56312399e-05,  1.51226792e-04,
        -2.19440786e-04, -8.36886757e-05, -1.56132068e-04,
         5.21539841e-05,  1.20644261e-04,  1.24588987e-04],
       [ 1.14771747e-03,  7.98567547e-04,  5.84563124e-04,
         9.75952251e-04,  7.21278135e-04,  1.27343962e-03,
        -1.83742039e-03, -6.96650473e-04, -1.31409068e-03,
         4.35414346e-04,  1.01396278e-03,  1.03500020e-03],
       [ 1.58191688e-04,  1.08477878e-04,  8.28073535e-05,
         1.33934256e-04,  1.00818965e-04,  1.77877417e-04,
        -2.53077102e-04, -9.45415668e-05, -1.83330994e-04,
         5.95297279e-05,  1.40964185e-04,  1.39723736e-04],
       [ 4.45041253e-04,  3.08248505e-04,  2.28648743e-04,
         3.77921911e-04,  2.80925742e-04,  4.95875895e-04,
        -7.12325040e-04, -2.68827105e-04, -5.11506689e-04,
         1.68409111e-04,  3.94244533e-04,  3.98741337e-04],
       [ 4.03036072e-04,  2.81442917e-04,  2.03848918e-04,
         3.43090651e-04,  2.52389611e-04,  4.45679441e-04,
        -6.45347522e-04, -2.45582545e-04, -4.60050040e-04,
         1.53210640e-04,  3.55294760e-04,  3.65326530e-04],
       [ 1.11290559e-04,  7.77003515e-05,  5.63094654e-05,
         9.47324297e-05,  6.97053620e-05,  1.23087331e-04,
        -1.78198505e-04, -6.77992139e-05, -1.27054140e-04,
         4.23016900e-05,  9.81187914e-05,  1.00850826e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.40384858e-04,  9.63101193e-05,  7.34257337e-05,
         1.18873722e-04,  8.94323166e-05,  1.57790942e-04,
        -2.24594376e-04, -8.39395216e-05, -1.62634678e-04,
         5.28418677e-05,  1.25063918e-04,  1.24075057e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 8.58979649e-04,  5.98512241e-04,  4.36313421e-04,
         7.30736065e-04,  5.39076165e-04,  9.51820752e-04,
        -1.37526449e-03, -5.22175978e-04, -9.82324360e-04,
         3.26131907e-04,  7.58232607e-04,  7.76177272e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.64232333e-04,  1.13170332e-04,  8.51957957e-05,
         1.39250275e-04,  1.04182989e-04,  1.83854208e-04,
        -2.62802409e-04, -9.86633968e-05, -1.89567741e-04,
         6.19704151e-05,  1.45928992e-04,  1.46073711e-04],
       [ 2.41245143e-04,  1.65798396e-04,  1.25765699e-04,
         2.04386888e-04,  1.53426037e-04,  2.70721153e-04,
        -3.85988125e-04, -1.44519552e-04, -2.79072527e-04,
         9.08958464e-05,  2.14693486e-04,  2.13759267e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=
array([ 8.4765867e-05,  7.6584030e-05,  1.8413250e-05,  7.8532801e-05,
        3.7723312e-05,  6.7949033e-05, -1.3766863e-04, -6.7827263e-05,
       -7.2606228e-05,  3.7518417e-05,  6.1510000e-05,  1.0890652e-04],
      dtype=float32)>, <tf.Tensor: shape=(30, 1), dtype=float32, numpy=
array([[nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan],
       [nan]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>, <tf.Tensor: shape=(34, 40), dtype=float32, numpy=
array([[-3.92979700e-06,  7.10045356e-08,  1.07932033e-06, ...,
         1.30140904e-07,  1.39944859e-07, -3.32695066e-07],
       [ 1.27194255e-06, -4.90786420e-07,  3.89234401e-06, ...,
        -2.91487225e-07, -1.22095571e-07,  8.76996694e-07],
       [ 1.14442482e-05,  1.48446679e-06, -1.21813391e-05, ...,
        -1.34712036e-06,  1.95793902e-07,  5.89588990e-06],
       ...,
       [-4.35807378e-05, -9.13960230e-06,  1.06593536e-04, ...,
        -1.46865368e-05, -1.10673318e-05, -5.06917204e-05],
       [-1.78716309e-05, -2.20714137e-05,  3.81402351e-05, ...,
        -1.09146849e-05, -6.63504079e-06, -5.79688640e-05],
       [ 3.37333709e-04,  5.83465589e-06, -3.44931264e-04, ...,
        -4.56711587e-06, -5.75084596e-06, -9.18374863e-05]], dtype=float32)>, <tf.Tensor: shape=(40,), dtype=float32, numpy=
array([ 3.4581073e-05,  3.6094887e-06, -3.2316100e-05,  5.2822668e-07,
        2.1360487e-05,  2.7627813e-05, -1.0154995e-06, -2.6615531e-05,
        9.6217036e-07,  1.7077404e-06,  9.9468707e-08,  1.3123423e-06,
       -2.2539065e-05,  9.2668643e-07,  1.6788079e-05,  2.3790767e-06,
       -4.5419558e-05,  4.3708114e-06,  8.1951239e-06, -9.2742243e-07,
        2.5709810e-06, -2.0661516e-06,  2.5424808e-05,  3.4146593e-05,
        8.5437341e-06,  9.1220099e-06,  1.9485489e-05,  2.8436009e-05,
        4.6013447e-06, -2.5609479e-05,  7.0716969e-06,  2.9032701e-06,
        8.1480842e-08, -7.8363964e-06, -4.5508179e-05, -1.1775321e-06,
        1.9637384e-05,  1.6784721e-06, -4.9218056e-07, -2.9605887e-06],
      dtype=float32)>, <tf.Tensor: shape=(40, 80), dtype=float32, numpy=
array([[-9.44991771e-05, -3.51061544e-06, -4.82473297e-06, ...,
         0.00000000e+00,  8.33613649e-06, -1.16066885e-05],
       [-1.39846259e-06,  4.95379754e-06, -8.85189422e-07, ...,
         0.00000000e+00, -3.59218461e-07, -2.22402491e-06],
       [-5.86863025e-05, -4.18945820e-06, -9.60108878e-07, ...,
         0.00000000e+00,  1.55862399e-05, -8.67563449e-06],
       ...,
       [-1.81726568e-06,  2.17579577e-06, -2.88120941e-06, ...,
         0.00000000e+00, -4.77003141e-06, -2.50707308e-06],
       [-4.68646476e-07,  1.84731761e-07, -5.44686678e-08, ...,
        -2.77310246e-08, -1.76282278e-08, -2.33763515e-07],
       [-6.58738136e-05, -5.61094157e-06, -7.26291063e-08, ...,
         0.00000000e+00,  2.26215634e-05, -1.91124600e-05]], dtype=float32)>, <tf.Tensor: shape=(80,), dtype=float32, numpy=
array([-3.69689078e-05,  1.73508886e-06, -3.72802356e-06, -3.41020714e-05,
       -6.44358579e-07, -5.22062237e-06, -7.35019421e-06,  8.08765071e-06,
       -1.26381055e-05, -4.56920825e-05, -3.89450506e-05, -1.71088672e-07,
       -3.32604077e-06,  4.15860541e-06, -9.27474139e-06,  5.16432738e-05,
       -2.33545634e-05, -1.05635818e-05, -6.52118297e-06,  4.64065743e-05,
        2.08699312e-05, -1.43861262e-05, -2.31173772e-06, -1.52931079e-05,
        4.25204735e-06, -4.28941848e-06, -9.05029793e-08, -1.06619111e-04,
       -1.33403432e-06, -7.92781975e-07, -2.45764168e-05, -2.75093007e-05,
       -3.45434137e-06,  4.01032376e-05, -6.34377284e-05,  5.09734527e-05,
        9.12017413e-07,  1.15746934e-05,  3.61272978e-05,  4.15479963e-06,
        3.88669832e-07,  3.93064767e-07,  3.96769319e-05,  1.95061830e-07,
       -2.05990527e-05, -2.15250247e-06, -1.41024657e-06, -1.44763203e-06,
       -2.68358963e-05,  3.74100127e-05,  4.32931665e-05, -3.13794499e-06,
        3.21640391e-06, -2.85613060e-05,  6.28748376e-06, -6.13663906e-06,
       -6.94050905e-05,  1.16246451e-06, -1.23769212e-07, -1.06775781e-06,
       -5.00675233e-05, -2.27726487e-05,  3.60346644e-06, -7.88979548e-09,
        5.51546837e-05, -5.36576465e-07,  6.47047855e-05,  1.93836659e-05,
       -7.10229187e-07, -4.53837602e-05,  3.58441469e-07,  2.12982959e-05,
       -3.38969076e-05, -1.37605298e-06, -4.35954234e-07,  1.36045958e-06,
        1.69692757e-05,  4.80391634e-07, -9.09262599e-06,  5.33759066e-06],
      dtype=float32)>, <tf.Tensor: shape=(80, 30), dtype=float32, numpy=
array([[-6.72823353e-06,  6.65594271e-05, -6.07143738e-05, ...,
        -5.42186208e-05,  3.36732483e-05, -4.60867659e-06],
       [ 3.55020347e-06,  2.27155761e-06, -4.50601829e-06, ...,
        -1.31406450e-05, -3.69972804e-06,  9.36112315e-07],
       [-1.85272688e-06, -1.98482333e-08, -4.55742679e-07, ...,
        -1.71590307e-06,  1.92157529e-07,  7.91426885e-07],
       ...,
       [-2.51951082e-08, -2.59334287e-09,  3.31746430e-09, ...,
        -1.24476962e-09, -3.74426463e-08,  8.51421544e-10],
       [ 1.49798461e-06,  1.33698995e-05, -9.13678650e-06, ...,
        -1.90990431e-05, -9.83321911e-07,  3.64000158e-07],
       [ 1.09667474e-06,  2.27881628e-05, -1.39416143e-05, ...,
        -1.67536600e-05,  5.96787140e-06, -7.32210538e-07]], dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([-5.6240551e-06,  3.1703530e-05, -4.0954190e-05,  2.5217807e-05,
        8.6770902e-05, -3.6068483e-05, -3.3752483e-05, -5.2563081e-07,
       -9.1518777e-05,  3.7261880e-06, -2.6332420e-05, -2.4799250e-05,
       -3.1668351e-06,  9.0775757e-05, -1.4338664e-05, -4.0615108e-05,
       -8.5037464e-06,  2.3922108e-05,  1.0389611e-05, -3.6872072e-05,
       -1.6934158e-04, -2.2554761e-05,  8.7639137e-08,  4.0999498e-07,
        4.4162232e-05,  7.0323636e-05,  1.5574764e-04, -4.0604056e-05,
        3.0341613e-05, -6.6872308e-06], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[-3.38864513e-04,  2.69867189e-04, -1.10275170e-04,
        -7.80073460e-05, -9.64363426e-05,  2.24513627e-04,
         1.47935762e-05, -6.25070606e-05,  3.72309209e-04,
         5.64481015e-05,  3.75050622e-05, -2.91734723e-05,
        -5.93241712e-05,  6.70822847e-05, -5.62163914e-05,
        -1.19067416e-04, -2.20216782e-04,  9.62579506e-05,
        -4.88389560e-05, -9.56779331e-06,  1.49596279e-04,
         1.04927067e-05,  2.02105603e-05,  7.16819122e-05,
         1.69752093e-04,  1.15573184e-05, -1.85265508e-05,
         6.38301644e-05, -1.09641704e-04,  2.65071640e-06],
       [ 2.76496195e-07, -2.55884424e-06,  9.77415257e-05,
        -1.23143545e-04, -8.38448250e-06, -1.07954384e-05,
         5.24878317e-07,  2.00188151e-06, -4.66124312e-08,
        -4.81857678e-05, -2.55429750e-05, -7.34944042e-05,
        -9.54176649e-05,  1.30100700e-04,  7.93651488e-05,
         1.63904383e-06,  4.47307315e-07, -2.78322434e-04,
         3.74724823e-06,  4.87048128e-05,  1.99883907e-05,
        -1.71225366e-07,  2.01763214e-06,  7.46592195e-05,
        -5.81223176e-05,  2.07803714e-06,  1.19620267e-06,
        -1.14304610e-04, -1.01196783e-04, -5.30380532e-07],
       [-3.24938650e-04,  2.63859052e-04, -1.73736698e-04,
         4.92675972e-05, -8.01294736e-05,  2.32958439e-04,
        -1.45024605e-05, -5.58626707e-05,  3.79076024e-04,
         9.18588194e-05,  6.03879998e-05,  2.49580480e-05,
         1.65980291e-05, -5.40683650e-05, -1.44265636e-04,
        -1.06600070e-04, -1.95682238e-04,  3.30272538e-04,
        -4.16136900e-05, -3.55262018e-05,  1.22278027e-04,
         1.19978267e-05,  1.29365581e-05, -7.99115605e-06,
         2.28315082e-04,  7.97490884e-06, -1.62866745e-05,
         1.63890872e-04,  1.33935209e-05,  2.44763078e-06],
       [-7.88112811e-04,  6.35665958e-04, -3.65751912e-04,
         4.37664930e-05, -2.16941175e-04,  6.32975891e-04,
         1.21880759e-04, -1.65517282e-04,  8.49110715e-04,
         2.46990472e-04,  1.51544155e-04,  4.17215706e-05,
         1.66013633e-05, -5.32709309e-05, -1.07654021e-04,
        -3.10705480e-04, -5.70718606e-04,  8.01615068e-04,
        -1.57825474e-04, -1.02129990e-04,  3.16643243e-04,
         1.95963476e-05,  5.95683487e-05,  4.12303270e-05,
         5.25572454e-04,  3.20528452e-05, -5.17870030e-05,
         2.78883585e-04, -6.84405240e-05,  9.38793892e-06],
       [-1.74237182e-04,  1.50395266e-04, -9.52737973e-05,
         2.82814472e-05, -4.22364647e-05,  1.17640717e-04,
        -4.07581183e-06, -3.33441531e-05,  1.96970155e-04,
         4.14002425e-05,  3.20837062e-05,  8.52700759e-06,
         4.38562256e-06, -4.05315186e-05, -9.61332262e-05,
        -6.04836750e-05, -1.17298419e-04,  1.54404988e-04,
        -2.21409482e-05, -3.62287938e-05,  8.15816602e-05,
         7.43849932e-06,  6.75673209e-06,  1.36383960e-06,
         9.82879938e-05,  4.86323643e-06, -1.13444239e-05,
         9.21636165e-05, -1.98285088e-05,  1.32766093e-06],
       [-1.65027421e-04,  1.45777449e-04, -2.31770755e-05,
        -1.10389301e-04, -6.34033786e-05,  4.93264852e-05,
        -1.98533198e-05, -2.49226487e-05,  1.96425317e-04,
        -2.90691460e-05, -1.20553050e-05, -6.05552777e-05,
        -8.58043932e-05,  8.06232274e-05, -5.60649642e-05,
        -4.84949633e-05, -9.05920679e-05, -1.67373364e-04,
        -5.37551477e-06,  1.23833997e-05,  1.04470761e-04,
         7.94428342e-06,  2.84626390e-06,  8.22850707e-05,
         1.11008558e-06,  4.96558869e-06, -8.02792056e-06,
         2.41159069e-05, -1.07277017e-04, -7.39515826e-09],
       [-2.69701172e-06, -4.51617143e-06,  7.81297422e-05,
        -2.54037877e-04, -1.33799831e-05, -7.22095720e-05,
         2.49062350e-06,  2.89510194e-06,  8.48112336e-07,
        -9.00835439e-05, -6.92593603e-05, -9.71483023e-05,
        -1.13974180e-04,  2.06752360e-04,  6.98043550e-06,
         1.13705141e-06, -1.81882626e-06, -4.18724230e-04,
         1.03320326e-05,  5.04967502e-05,  4.29821630e-05,
        -1.05977142e-06,  3.47328819e-06,  1.56188878e-04,
        -1.39271971e-04,  2.65943299e-06,  1.76236733e-06,
        -1.12230300e-04, -1.44027406e-04, -1.21746166e-06],
       [-2.38514942e-04,  1.81635987e-04, -1.21252087e-04,
         3.56088603e-05, -6.34893440e-05,  1.69325198e-04,
         8.08307777e-06, -4.24635582e-05,  2.70444405e-04,
         6.41951847e-05,  4.43747485e-05,  1.95501252e-05,
         1.26336308e-05, -3.07406663e-05, -8.18653789e-05,
        -8.10225465e-05, -1.43346479e-04,  2.45218369e-04,
        -3.40699589e-05, -2.49935347e-05,  8.88237264e-05,
         8.15687690e-06,  8.28240081e-06, -6.02535283e-06,
         1.68897765e-04,  6.52392646e-06, -1.13271244e-05,
         1.15862887e-04,  1.15838666e-05,  2.11217480e-06],
       [-1.08260647e-05,  5.04112086e-06,  1.91445106e-05,
        -6.31098237e-06, -5.51162566e-06,  4.84859447e-06,
         4.88641854e-06, -1.64728283e-06,  7.33775050e-06,
        -3.92019228e-06, -4.54046130e-07, -1.08497943e-05,
        -1.74433899e-05,  1.45361428e-05,  2.40431218e-05,
        -3.62781111e-06, -4.67717064e-06, -2.17954675e-05,
        -4.09592758e-06,  8.75778915e-06,  5.82214761e-06,
        -8.14149985e-07,  1.69779400e-06,  4.65489893e-06,
         4.00213139e-06,  1.04919582e-06, -1.26993382e-06,
        -1.70705698e-05, -4.58274781e-06,  2.15130825e-07],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [-9.06937348e-04,  7.39774026e-04, -4.92352003e-04,
         1.44702237e-04, -2.18988280e-04,  6.75600721e-04,
        -4.36703303e-05, -1.59898045e-04,  1.07366848e-03,
         2.71949015e-04,  1.77658920e-04,  7.14551570e-05,
         4.84892880e-05, -1.54478927e-04, -4.17535775e-04,
        -3.03165696e-04, -5.62413014e-04,  9.51162539e-04,
        -1.20105680e-04, -1.02236983e-04,  3.35045828e-04,
         3.25358196e-05,  3.92323054e-05, -2.33322335e-05,
         6.52353105e-04,  2.32834464e-05, -4.72627544e-05,
         4.62738448e-04,  3.88383269e-05,  6.83017652e-06],
       [ 6.72429906e-07, -2.92635332e-06,  8.73677200e-05,
        -2.45237752e-04, -3.10302457e-05, -8.47929768e-05,
         3.45437820e-06,  3.34199126e-06, -2.10060591e-07,
        -9.16940990e-05, -5.87178693e-05, -9.88712272e-05,
        -1.31341279e-04,  2.02092910e-04,  3.78578152e-05,
         2.12835971e-06,  7.69639655e-07, -5.03726013e-04,
         1.21296125e-05,  4.70742671e-05,  4.71649037e-05,
        -1.01869648e-06,  2.26085490e-06,  1.49143802e-04,
        -1.54685069e-04,  3.04834111e-06,  2.27125224e-06,
        -9.72446214e-05, -2.14179250e-04, -1.08357381e-06],
       [ 1.52041721e-08,  9.17417253e-08,  3.80077563e-06,
        -4.69368888e-06, -1.96056544e-06, -1.30518833e-06,
        -5.55666873e-08,  6.90561706e-08, -8.70104266e-10,
        -2.87997182e-06, -1.24032510e-06, -3.29390673e-06,
        -6.16893476e-06,  7.01432646e-06,  7.05965385e-06,
         7.58844578e-08,  1.41675143e-08, -2.62657595e-05,
         3.31705337e-07,  3.31981664e-06,  1.28581451e-06,
        -4.33675718e-09,  8.88381919e-08,  2.77670142e-06,
        -5.88140347e-06,  1.53193369e-07,  2.17360441e-09,
        -4.29921965e-06, -1.56330516e-05, -1.94686791e-08],
       [-2.05082688e-04,  1.72094049e-04, -1.03062310e-04,
        -1.68894621e-05, -4.90525854e-05,  1.33975744e-04,
        -1.40239063e-05, -3.84250525e-05,  2.30293561e-04,
         4.10944813e-05,  3.19230276e-05,  4.67726477e-06,
        -3.85936255e-06,  1.60537820e-06, -6.48239220e-05,
        -7.14895723e-05, -1.28292158e-04,  1.52175155e-04,
        -2.58737709e-05, -1.84771452e-05,  8.39711283e-05,
         7.94998323e-06,  8.65247421e-06,  2.32802049e-05,
         1.25092440e-04,  4.92678100e-06, -1.31250772e-05,
         7.59039322e-05, -2.23129973e-07,  1.47726223e-06],
       [-1.05584040e-04,  9.64663268e-05, -6.80384765e-05,
         7.80064875e-06, -2.84507296e-05,  3.60622143e-05,
        -4.53204157e-05, -1.01066689e-05,  1.37126786e-04,
         6.65639163e-06,  7.50229992e-06,  4.00726640e-06,
        -5.74942050e-08, -1.73464159e-05, -1.10850146e-04,
        -2.03704458e-05, -3.80613674e-05,  4.31219996e-05,
        -1.81208998e-06, -9.15947021e-06,  3.58998841e-05,
         4.34876165e-06, -1.95773868e-08, -5.09572715e-07,
         5.12993865e-05,  4.73884882e-07, -2.46766922e-06,
         8.01242059e-05,  6.34214587e-07,  8.63404068e-08],
       [ 3.27096821e-08, -1.06138778e-07,  2.74308732e-05,
        -1.02991935e-05, -7.05241519e-08,  3.47229388e-06,
        -7.11735311e-08,  1.87492645e-07, -1.14959837e-08,
        -7.89748992e-06, -1.29906857e-06, -1.50347532e-05,
        -1.97314675e-05,  1.88235426e-05,  1.93902833e-05,
         2.17251909e-07,  3.47551463e-08, -3.62463943e-05,
        -1.77978507e-07,  1.29633854e-05,  2.04978892e-06,
        -1.33087905e-08,  2.02199942e-07,  7.10014410e-06,
        -3.51015387e-06,  4.56562873e-07,  1.35492826e-07,
        -2.26547672e-05, -4.78023458e-06, -2.17768044e-08],
       [-2.35207030e-04,  1.28082916e-04, -3.49849724e-05,
        -1.65919992e-04, -7.63600910e-05,  2.17286637e-04,
         1.43461148e-04, -5.79189218e-05,  2.45188858e-04,
         7.34472778e-05,  1.24637445e-05, -3.97716503e-05,
        -5.46387128e-05,  1.56280177e-04,  6.45862456e-05,
        -1.16037627e-04, -2.15637570e-04,  6.54008472e-05,
        -7.98406400e-05,  3.04511741e-06,  1.12317888e-04,
        -4.27410623e-06,  3.82629732e-05,  1.27905092e-04,
         1.10797424e-04,  2.01320508e-05, -1.36008503e-05,
        -9.12024552e-06, -1.35255672e-04,  4.32151910e-06],
       [-2.87971488e-04,  2.74696446e-04, -1.53231536e-04,
         5.54810249e-05, -7.72377971e-05,  2.35013402e-04,
         6.97550604e-08, -6.06875910e-05,  3.16780439e-04,
         8.52229277e-05,  6.88979708e-05,  2.55159466e-05,
         1.55711077e-05, -6.09807357e-05, -3.69214831e-05,
        -1.10760564e-04, -2.02812153e-04,  3.22660286e-04,
        -4.58475151e-05, -4.37724011e-05,  1.12192232e-04,
         1.22416041e-05,  1.40591892e-05, -9.81955145e-06,
         2.00814524e-04,  7.98470865e-06, -2.25129406e-05,
         1.05716819e-04,  1.30847866e-05,  2.89054060e-06],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [-9.91074485e-04,  7.93654472e-04, -5.08639438e-04,
         1.63557968e-04, -2.46188167e-04,  7.79713737e-04,
         3.59037876e-05, -1.87624712e-04,  1.13497826e-03,
         3.19690444e-04,  2.02496914e-04,  8.14624873e-05,
         5.75353115e-05, -1.56238690e-04, -3.22560256e-04,
        -3.54093732e-04, -6.51995302e-04,  1.10690831e-03,
        -1.63237273e-04, -1.23100399e-04,  3.72764014e-04,
         3.02549888e-05,  5.67385323e-05, -2.05826072e-05,
         7.28285231e-04,  3.15147990e-05, -5.64171569e-05,
         4.55315778e-04,  3.37778838e-05,  9.51744096e-06],
       [-1.61524949e-04,  1.40454940e-04, -2.10874641e-05,
        -3.09909461e-04, -8.10428755e-05, -5.78478721e-05,
        -5.05756225e-06, -2.41255075e-05,  1.82875068e-04,
        -1.03202372e-04, -7.17878429e-05, -1.09628993e-04,
        -1.44316757e-04,  2.00357288e-04, -1.42346966e-04,
        -4.92010477e-05, -9.55964133e-05, -5.17536071e-04,
         9.22064464e-06,  2.07989797e-06,  1.57239920e-04,
         7.44635918e-06,  1.71606416e-06,  2.08225843e-04,
        -1.56338967e-04,  6.12324038e-06, -6.06114963e-06,
         1.36195813e-05, -2.79852131e-04, -1.13831106e-06],
       [-2.40072222e-05,  1.98731286e-05, -1.26972109e-05,
         1.38139421e-06, -2.35263883e-06,  4.61709578e-06,
        -1.36778799e-05, -1.22698464e-06,  3.14887693e-05,
         1.10382666e-06,  1.39094857e-06,  4.17295354e-07,
         2.67923980e-07, -3.79900575e-06, -3.60635750e-05,
        -3.00709303e-06, -5.81857830e-06,  5.17238004e-06,
        -9.24256369e-08, -1.39223948e-06,  4.27364876e-06,
         5.59428599e-07, -1.54992374e-09, -3.07095789e-08,
         1.42264016e-05,  3.17953948e-08, -1.98154765e-07,
         2.26861357e-05,  7.82358498e-08,  6.23626972e-09],
       [-1.15154064e-04,  5.73346588e-05,  3.08122777e-04,
        -7.97552289e-04, -1.19998156e-04, -1.12686786e-04,
         1.17048694e-04, -2.64338269e-05,  8.46618277e-05,
        -2.30274978e-04, -1.63244404e-04, -3.28081107e-04,
        -4.34253045e-04,  6.85640785e-04,  2.81630812e-04,
        -6.34331373e-05, -1.21495701e-04, -1.42859912e-03,
        -1.87678706e-05,  1.52111155e-04,  1.97676593e-04,
        -5.98262022e-06,  3.13428791e-05,  5.04243188e-04,
        -3.81373160e-04,  2.05804172e-05, -6.69096335e-06,
        -3.86382686e-04, -6.55886426e-04, -2.68481926e-07],
       [-1.11802852e-04,  1.02266102e-04, -7.77673631e-05,
         1.01791411e-05, -2.83384907e-05,  4.39438882e-05,
        -5.58999564e-05, -1.11128793e-05,  1.52953871e-04,
         1.22218380e-05,  1.01386931e-05,  4.26281349e-06,
         4.26168299e-07, -2.29756806e-05, -1.37411364e-04,
        -2.23753323e-05, -4.39991745e-05,  5.17524131e-05,
        -1.77458958e-06, -1.06265579e-05,  3.52437637e-05,
         4.85033343e-06,  1.31611984e-07, -6.83575763e-07,
         5.82344983e-05,  4.22570679e-07, -3.06731090e-06,
         9.05308989e-05,  5.51031121e-07,  5.75831010e-08],
       [ 1.71945385e-06, -6.95367225e-06,  3.62740946e-04,
        -1.03156408e-03, -1.24071084e-04, -3.78735771e-04,
         7.61700721e-06,  1.43029092e-05, -8.71145147e-08,
        -3.89181514e-04, -2.58537824e-04, -4.19649994e-04,
        -5.54120692e-04,  8.21426976e-04,  1.11277652e-04,
         1.00558154e-05,  3.99701912e-06, -2.12291768e-03,
         6.29447459e-05,  1.83628872e-04,  2.26294665e-04,
        -9.00975863e-07,  3.38532459e-06,  6.34391909e-04,
        -6.68985129e-04,  1.00335083e-05,  8.06990920e-06,
        -4.06095583e-04, -8.76620878e-04, -5.54512690e-06],
       [ 2.83760556e-07, -2.37782024e-06,  7.33065390e-05,
        -1.32677465e-04, -1.54242280e-05, -2.45014016e-05,
         1.06373432e-06,  1.98642374e-06, -1.27009329e-07,
        -4.99335838e-05, -2.59641001e-05, -6.01005231e-05,
        -8.49549760e-05,  1.28270767e-04,  6.90273664e-05,
         1.43048896e-06,  4.72339821e-07, -2.98253464e-04,
         5.57580188e-06,  4.17578485e-05,  2.10254657e-05,
        -2.34480922e-07,  8.26480630e-07,  8.08965851e-05,
        -7.07935105e-05,  1.23739937e-06,  1.36506310e-06,
        -8.90547526e-05, -1.13785660e-04, -5.36827542e-07],
       [-3.43379288e-05,  2.09710033e-05,  6.52453600e-05,
        -1.54302325e-04, -3.13458513e-05, -1.99181231e-05,
         2.86234044e-05, -7.38832205e-06,  1.64321009e-05,
        -4.40965923e-05, -2.92465847e-05, -6.64395848e-05,
        -9.15757919e-05,  1.31153865e-04,  5.90071650e-05,
        -1.71544652e-05, -3.27626112e-05, -2.93186575e-04,
        -8.47749288e-06,  2.46585096e-05,  4.44793368e-05,
        -1.04580590e-06,  8.56663519e-06,  1.00071127e-04,
        -7.38692834e-05,  4.71339581e-06, -2.18870491e-06,
        -8.30486169e-05, -1.59439107e-04,  4.05672210e-07],
       [ 9.55538098e-07,  8.10902065e-07,  1.45508355e-04,
        -5.24966221e-04, -6.43481035e-05, -2.33345243e-04,
         5.35678600e-06,  6.94288019e-06,  1.21422227e-06,
        -2.05766148e-04, -1.46851205e-04, -2.04202515e-04,
        -2.64549861e-04,  3.88437358e-04, -3.80116180e-05,
         4.28146086e-06,  1.79166943e-06, -1.06000109e-03,
         3.33658390e-05,  6.16892285e-05,  1.32625399e-04,
        -1.01208093e-06,  3.90247078e-06,  3.28389520e-04,
        -3.70094582e-04,  5.34384480e-06,  3.45830085e-06,
        -1.67658291e-04, -4.69508377e-04, -2.96637768e-06],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[ 1.66500817e-04, -1.38225456e-04,  2.00129347e-04,
        -3.49022215e-04,  5.27348675e-06, -2.30072983e-04,
         1.34681468e-05,  3.31584706e-05, -1.90129475e-04,
        -1.55723726e-04, -1.15266150e-04, -1.41894707e-04,
        -1.76013127e-04,  2.86408816e-04,  9.30924143e-05,
         5.52849451e-05,  9.75880612e-05, -8.04006704e-04,
         3.34370925e-05,  7.23651756e-05,  1.65357051e-06,
        -8.44891565e-06,  2.00299041e-07,  2.04674609e-04,
        -3.17726459e-04,  3.71155011e-07,  1.12282123e-05,
        -2.14579792e-04, -2.77091283e-04, -2.60419847e-06],
       [ 2.18386849e-04, -1.89641316e-04,  1.31491630e-04,
        -2.12866926e-05,  5.85247944e-05, -9.26304783e-05,
         6.83033650e-05,  2.76202754e-05, -2.73722428e-04,
        -1.94360691e-05, -2.49298209e-05, -1.12493080e-05,
        -1.20036998e-06,  3.48579342e-05,  1.80875373e-04,
         5.41118497e-05,  9.26891080e-05, -1.19112068e-04,
         7.10468885e-06,  2.41092766e-05, -7.98772599e-05,
        -1.00648012e-05,  4.69212580e-07,  2.43444947e-06,
        -1.15152026e-04, -1.58217244e-06,  8.13549104e-06,
        -1.46350343e-04, -3.20668619e-06, -4.04748647e-07],
       [ 5.25219093e-07, -1.65483334e-06,  1.16755218e-04,
        -2.82358495e-04, -3.29532013e-05, -9.44443673e-05,
         1.68766883e-06,  4.01164834e-06, -3.75674212e-08,
        -1.08474633e-04, -7.13917834e-05, -1.22261757e-04,
        -1.63686971e-04,  2.38194698e-04,  4.66715137e-05,
         3.00650436e-06,  1.08714312e-06, -6.02368731e-04,
         1.65142392e-05,  5.96924947e-05,  6.00856365e-05,
        -2.61931064e-07,  1.70471276e-06,  1.73813867e-04,
        -1.80968622e-04,  3.08186463e-06,  2.09482732e-06,
        -1.36462986e-04, -2.45187606e-04, -1.52419341e-06],
       [ 7.85826123e-05, -4.25088037e-05,  2.29429003e-04,
        -8.75612139e-04, -7.34295900e-05, -4.66193917e-04,
        -6.15783792e-05,  3.48151661e-05, -5.90205564e-05,
        -3.76495213e-04, -2.67090567e-04, -3.35285993e-04,
        -4.19900171e-04,  6.29663409e-04, -1.61753487e-04,
         5.15551801e-05,  7.72297208e-05, -1.82170048e-03,
         9.33565316e-05,  1.10394525e-04,  1.83722994e-04,
         1.30656440e-06, -1.07018832e-05,  5.35797910e-04,
        -6.78846147e-04,  7.07486379e-07,  1.34176389e-05,
        -2.61495967e-04, -7.21669989e-04, -7.42366547e-06],
       [ 5.51682433e-06,  9.28392546e-06,  4.60193951e-05,
        -1.77288908e-04, -1.67938961e-05, -7.48997627e-05,
        -2.66529478e-05,  3.92724905e-06,  3.11240819e-06,
        -7.59625618e-05, -4.55509689e-05, -7.09705273e-05,
        -9.37786681e-05,  1.23653866e-04, -1.55343914e-05,
         6.04692241e-06,  8.07282959e-06, -3.66687047e-04,
         2.73713285e-05,  2.66901170e-05,  4.64543227e-05,
         4.77690037e-06, -7.85095745e-06,  1.08895925e-04,
        -1.28851912e-04, -1.67780763e-06,  1.36600420e-08,
        -6.57469136e-05, -1.42389850e-04, -1.98495468e-06],
       [ 1.85873752e-04, -1.34235626e-04,  1.45297236e-04,
        -1.50909560e-04,  3.04056975e-05, -1.40419215e-04,
         2.21413320e-05,  2.91893957e-05, -2.14024854e-04,
        -9.31381073e-05, -6.14960591e-05, -7.14562630e-05,
        -8.50225988e-05,  1.35610811e-04,  1.46956678e-04,
         5.66998460e-05,  9.48888774e-05, -4.20915661e-04,
         3.58268189e-05,  4.99491725e-05, -2.65372073e-05,
        -3.70134740e-06, -8.03251260e-06,  8.13648003e-05,
        -2.05494347e-04, -3.92896845e-06,  8.93105152e-06,
        -1.86211037e-04, -1.12249989e-04, -2.68411213e-06],
       [ 2.70169403e-04, -2.61354493e-04,  1.50011023e-04,
        -5.00653114e-05,  8.33942904e-05, -1.84876073e-04,
         1.54446643e-05,  5.34647006e-05, -2.96480546e-04,
        -6.22307416e-05, -5.74659207e-05, -2.38478115e-05,
        -9.95058963e-06,  5.44265567e-05,  4.73669497e-05,
         9.80228069e-05,  1.72263986e-04, -2.62716465e-04,
         3.85536332e-05,  4.25435610e-05, -1.04480503e-04,
        -1.19455090e-05, -1.05945792e-05,  1.11463014e-05,
        -1.72214175e-04, -6.46209628e-06,  2.12662362e-05,
        -1.04815263e-04, -9.86080158e-06, -2.57598708e-06],
       [ 4.08589358e-07,  8.25281177e-10,  8.10646598e-05,
        -2.02181996e-04, -2.36038140e-05, -7.70362094e-05,
         1.25660335e-06,  2.95876589e-06, -2.60153925e-08,
        -8.11395876e-05, -5.57100029e-05, -9.09516020e-05,
        -1.20697121e-04,  1.70041225e-04,  1.59460560e-05,
         2.29263446e-06,  8.05305547e-07, -4.44414065e-04,
         1.19862798e-05,  3.52816314e-05,  5.00178357e-05,
        -1.81124804e-07,  2.88132787e-06,  1.25858438e-04,
        -1.36805786e-04,  2.31190847e-06,  1.26666168e-06,
        -1.01467886e-04, -2.03695439e-04, -1.20274251e-06],
       [ 3.79060111e-05, -2.73266414e-05,  2.25351760e-05,
        -3.78611799e-06,  7.05928642e-06, -7.08568950e-06,
         2.05432480e-05,  2.04093885e-06, -5.07244295e-05,
        -5.73446323e-06, -4.11419069e-06, -2.93675612e-06,
        -1.88533181e-06,  8.31475973e-06,  4.92500585e-05,
         5.33700268e-06,  8.00448379e-06, -2.01345229e-05,
         8.02779255e-07,  2.48515539e-06, -5.43392480e-06,
        -9.92349328e-07, -2.09864368e-07,  2.30410024e-06,
        -2.86795002e-05,  2.93805229e-08,  5.12390443e-07,
        -3.90377136e-05, -5.70845259e-06, -5.91303326e-08],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.45273816e-06, -5.81195218e-06,  3.34512326e-04,
        -8.19006178e-04, -9.50615067e-05, -2.75638537e-04,
         5.30090711e-06,  1.15332805e-05, -1.00988338e-07,
        -3.10960924e-04, -2.02649491e-04, -3.51856841e-04,
        -4.67439328e-04,  6.78066630e-04,  1.41503304e-04,
         8.43532143e-06,  3.14866134e-06, -1.73637085e-03,
         4.75652414e-05,  1.66296333e-04,  1.75535271e-04,
        -7.43950238e-07,  4.14522401e-06,  5.02039795e-04,
        -5.22157003e-04,  8.85932423e-06,  6.32765295e-06,
        -3.76324519e-04, -7.08504405e-04, -4.35158609e-06],
       [ 2.42194801e-04, -2.04198062e-04,  1.35607595e-04,
        -4.34444228e-05,  5.48709504e-05, -2.08760612e-04,
         7.82703228e-06,  4.73569089e-05, -2.97663384e-04,
        -8.91799427e-05, -5.62496753e-05, -2.16034605e-05,
        -1.48128192e-05,  4.55436093e-05,  9.41900580e-05,
         8.82540262e-05,  1.65931764e-04, -2.89039803e-04,
         3.41329505e-05,  2.83500340e-05, -9.34194977e-05,
        -9.79826109e-06, -1.23707332e-05,  7.53066524e-06,
        -1.87426849e-04, -7.02657144e-06,  1.49520865e-05,
        -1.17246578e-04, -1.30821099e-05, -1.82965744e-06],
       [ 1.12204416e-05,  3.86977007e-07,  5.96675454e-06,
        -6.59311070e-07,  1.57679108e-06, -2.05661672e-06,
         1.20515074e-06,  1.04729452e-06, -1.33721842e-05,
        -4.66237316e-06, -8.62658794e-07, -5.38723043e-07,
        -3.70451119e-07,  1.22371921e-06,  1.89779494e-05,
         2.49736377e-06,  4.41838483e-06, -1.21656922e-05,
         7.24692143e-07,  1.26004602e-06, -5.24491770e-06,
        -3.75533091e-07, -4.52232200e-07,  7.34707939e-08,
        -8.67989002e-06, -9.18413292e-08,  2.31139069e-07,
        -7.76882825e-06, -2.50419021e-07, -3.56639944e-08],
       [ 3.08079470e-05, -5.11569779e-05,  9.25236527e-05,
        -1.94293709e-04, -1.20767236e-05, -8.93706310e-05,
         1.46291131e-05,  1.18559601e-05, -3.91033973e-05,
        -7.71390041e-05, -5.92076321e-05, -7.80413175e-05,
        -9.67414890e-05,  1.75295325e-04,  3.13607125e-05,
         1.52508746e-05,  3.09453972e-05, -3.96279676e-04,
         1.33408594e-05,  4.82192372e-05,  2.01075491e-05,
        -2.98086320e-06, -9.47902834e-07,  1.15108392e-04,
        -1.31018576e-04,  1.38933865e-06,  6.45386763e-06,
        -9.07247741e-05, -1.36890754e-04, -1.08804102e-06],
       [ 1.02112168e-07, -6.03029775e-07,  5.36275184e-05,
        -4.63487959e-05, -3.49913967e-06,  4.02454089e-06,
         5.48814683e-09,  7.21633114e-07, -2.55160444e-08,
        -1.96683213e-05, -6.85206396e-06, -3.33828502e-05,
        -4.55032678e-05,  5.64449547e-05,  5.35101317e-05,
         6.41496172e-07,  1.47705506e-07, -1.23992999e-04,
         8.82355835e-07,  2.41430098e-05,  6.63901574e-06,
        -6.51695871e-08,  4.65039108e-07,  2.88573901e-05,
        -1.97725658e-05,  9.13313954e-07,  4.62897844e-07,
        -5.81916975e-05, -3.29258582e-05, -1.32129500e-07],
       [ 4.48734281e-05, -4.22058401e-05,  2.97938095e-05,
        -1.98833163e-06,  1.06168554e-05, -1.12879934e-05,
         2.59223216e-05,  2.98752730e-06, -6.56707998e-05,
        -1.75754167e-06, -2.38040479e-06, -1.63964603e-06,
         1.52888511e-08,  5.74349542e-06,  5.32903105e-05,
         7.32260560e-06,  1.16488072e-05, -7.06143555e-06,
         2.82755678e-07,  3.76472008e-06, -1.10103019e-05,
        -1.37389350e-06, -2.01765493e-10,  7.57060192e-08,
        -2.08333659e-05, -5.79999764e-08,  6.62791820e-07,
        -4.18750242e-05, -4.69543373e-08, -1.50913912e-08],
       [ 1.91975618e-04, -1.64920944e-04,  1.39549578e-04,
        -3.61577433e-04,  7.29347812e-06, -3.80350190e-04,
        -3.74401170e-05,  4.90762250e-05, -1.92663298e-04,
        -2.19553680e-04, -1.54379057e-04, -1.38903211e-04,
        -1.68828497e-04,  2.34081803e-04, -1.52199631e-04,
         8.45058603e-05,  1.51354834e-04, -9.79072764e-04,
         7.42823395e-05,  2.92211971e-05,  3.50271366e-05,
        -5.48623348e-06, -1.53365036e-05,  2.12797182e-04,
        -4.39333962e-04, -5.56378109e-06,  1.82440308e-05,
        -7.84498989e-05, -3.76006879e-04, -5.17137551e-06],
       [ 5.29272370e-07, -5.73422312e-06,  8.23471200e-05,
        -3.10765347e-04, -2.37325585e-05, -1.02613238e-04,
         2.83428585e-06,  4.42600685e-06, -1.63704730e-08,
        -1.07108208e-04, -8.09234843e-05, -1.11824185e-04,
        -1.35018796e-04,  2.39376983e-04, -4.30068440e-07,
         2.85263241e-06,  1.23935865e-06, -5.23003051e-04,
         1.80263032e-05,  5.30607176e-05,  5.64349648e-05,
        -3.64291765e-07,  1.26155015e-07,  1.89873448e-04,
        -1.78257760e-04,  2.35116590e-06,  3.04895229e-06,
        -1.10717912e-04, -1.90536259e-04, -1.74843353e-06],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.29654700e-05, -5.53790414e-07,  3.25849833e-04,
        -9.54349933e-04, -1.06440173e-04, -3.76483775e-04,
        -1.21526027e-05,  1.57325831e-05,  7.75076444e-07,
        -3.75833479e-04, -2.52594153e-04, -3.94740578e-04,
        -5.16570406e-04,  7.48021295e-04,  3.54065050e-05,
         1.46409457e-05,  1.14065115e-05, -2.00785766e-03,
         7.48941820e-05,  1.54603593e-04,  2.28577555e-04,
         2.35757216e-06, -1.14212162e-06,  5.89188538e-04,
        -6.57468219e-04,  6.92465528e-06,  6.56485281e-06,
        -3.75049509e-04, -8.39302375e-04, -6.53380130e-06],
       [ 2.86211492e-04, -2.08957877e-04,  1.64592260e-04,
        -2.03692704e-04,  5.95456368e-05, -3.25515604e-04,
        -9.14399061e-05,  6.66563865e-05, -2.83975533e-04,
        -1.84716890e-04, -1.11128822e-04, -9.39043239e-05,
        -1.08823580e-04,  1.49481828e-04, -3.44266082e-05,
         1.24183731e-04,  2.24352829e-04, -7.11988658e-04,
         9.48946908e-05,  6.04644229e-05, -5.72031058e-05,
        -2.45167939e-07, -3.41170962e-05,  1.00103629e-04,
        -3.40028171e-04, -1.44017913e-05,  2.07775647e-05,
        -1.51863060e-04, -1.40355914e-04, -6.20317360e-06],
       [ 9.92338212e-09,  7.33489784e-08,  1.46988423e-05,
        -6.90331080e-06, -9.24027063e-07,  1.67317171e-06,
        -2.83403523e-09,  5.45574892e-08, -3.40874529e-09,
        -3.43751708e-06, -4.75365511e-07, -8.95714129e-06,
        -1.10261090e-05,  8.47621232e-06,  1.48092458e-05,
         5.38066480e-08,  1.64735177e-08, -2.33795272e-05,
         3.36891866e-08,  6.33460240e-06,  1.20360482e-06,
        -1.61742553e-09,  3.02211873e-08,  4.89500007e-06,
        -3.68043607e-06,  3.18839824e-07,  3.35552528e-08,
        -1.09363555e-05, -2.53155804e-06, -7.27369187e-09],
       [ 9.07405396e-04, -7.64595810e-04,  4.94008826e-04,
        -3.39774590e-04,  2.01057963e-04, -8.07907316e-04,
         5.30032885e-05,  1.68332714e-04, -1.06253568e-03,
        -3.50282993e-04, -2.53167353e-04, -1.33190726e-04,
        -1.12242866e-04,  2.63265538e-04,  2.51274148e-04,
         3.10542964e-04,  5.72932069e-04, -1.29251264e-03,
         1.43633835e-04,  1.00193218e-04, -2.72368197e-04,
        -3.40893494e-05, -4.02216647e-05,  1.46981052e-04,
        -8.20429064e-04, -2.25160857e-05,  5.50446130e-05,
        -4.30932734e-04, -2.06041354e-04, -8.96610527e-06],
       [ 9.90580702e-08, -1.00426053e-06,  6.17946571e-05,
        -5.70204065e-05, -4.59430476e-06,  3.43688589e-06,
         1.13550819e-07,  7.95266828e-07, -2.48233878e-08,
        -2.36094656e-05, -7.37326172e-06, -3.87780674e-05,
        -5.21462316e-05,  6.47053530e-05,  6.73639297e-05,
         6.36587458e-07,  1.74464219e-07, -1.48798630e-04,
         9.18239152e-07,  3.05631402e-05,  8.26525138e-06,
        -7.76913041e-08,  2.17433993e-07,  3.54066360e-05,
        -2.26161337e-05,  1.02882655e-06,  6.14224291e-07,
        -6.31932708e-05, -4.02337391e-05, -1.44440776e-07],
       [ 1.04249804e-03, -8.55379738e-04,  5.52967773e-04,
        -1.84756776e-04,  2.37772503e-04, -8.62636894e-04,
         5.53387690e-06,  1.98495196e-04, -1.22199429e-03,
        -3.55861383e-04, -2.29385187e-04, -8.92130774e-05,
        -6.69130895e-05,  1.85046039e-04,  3.86280648e-04,
         3.71025963e-04,  6.96976786e-04, -1.20299170e-03,
         1.62239128e-04,  1.21557445e-04, -3.80098762e-04,
        -3.56008932e-05, -5.67081152e-05,  3.07486407e-05,
        -7.91949453e-04, -3.16541846e-05,  6.03208864e-05,
        -4.94184904e-04, -5.10644095e-05, -9.31042450e-06],
       [ 1.67009843e-04, -1.55361398e-04,  1.16977484e-04,
        -2.48986235e-05,  4.28550702e-05, -1.12845344e-04,
         4.55345798e-05,  2.63907732e-05, -2.20611561e-04,
        -4.09993772e-05, -2.80659751e-05, -1.06195903e-05,
        -4.94672986e-06,  3.72406394e-05,  1.35313428e-04,
         4.83087933e-05,  9.61187034e-05, -1.43974205e-04,
         9.63655748e-06,  2.05211163e-05, -6.98607037e-05,
        -9.18007936e-06, -2.04384673e-06,  3.05081562e-06,
        -1.01679718e-04, -2.39653673e-06,  8.33350987e-06,
        -1.05032632e-04, -4.12702138e-06, -4.38116643e-07],
       [ 1.81173629e-04, -1.38723379e-04,  9.11790848e-05,
        -8.82050517e-05,  3.73249968e-05, -1.77459442e-04,
        -3.12399516e-06,  3.30533549e-05, -2.08507976e-04,
        -7.55116198e-05, -5.71490273e-05, -3.06585025e-05,
        -2.83158442e-05,  5.36060288e-05,  3.88249609e-05,
         6.10350216e-05,  1.14250775e-04, -2.80363194e-04,
         3.10997129e-05,  1.58316343e-05, -4.87899306e-05,
        -6.29660326e-06, -6.53045572e-06,  4.29900319e-05,
        -1.78566363e-04, -4.72455167e-06,  8.19909746e-06,
        -8.75546320e-05, -4.29917163e-05, -2.06795357e-06],
       [ 4.92446299e-04, -3.83499864e-04,  2.27374185e-04,
        -9.45939246e-05,  1.23145001e-04, -4.51238622e-04,
        -7.64653669e-05,  1.01491620e-04, -5.38644497e-04,
        -1.90045597e-04, -1.19613884e-04, -4.88603328e-05,
        -4.00253302e-05,  6.82609243e-05,  4.35569636e-05,
         1.90856124e-04,  3.52519419e-04, -6.37774996e-04,
         1.05599989e-04,  5.13037958e-05, -1.64618599e-04,
        -1.15004077e-05, -3.53803880e-05,  1.79069721e-05,
        -4.00490972e-04, -1.99793722e-05,  2.90661410e-05,
        -1.89368977e-04, -3.21668595e-05, -6.50796619e-06],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([ 0.01129764, -0.02194433,  0.02414241, -0.00300789,  0.00689281,
       -0.00666341,  0.00169055,  0.00936435, -0.01592837, -0.00412298,
       -0.00672776, -0.00021379,  0.0028269 , -0.0019414 , -0.01214884,
        0.02001996,  0.00144549,  0.01166914, -0.00703936,  0.01161101,
       -0.01018716, -0.00375274,  0.00569467,  0.00224752,  0.00616473,
       -0.00041243,  0.00865251, -0.00309424,  0.0112273 , -0.00243288,
       -0.0114943 ,  0.02213091, -0.02418632,  0.00281822, -0.00697092,
        0.00674791, -0.00165435, -0.0094086 ,  0.01613683,  0.00410129,
        0.00671419,  0.00015307, -0.00291382,  0.00207611,  0.01215593,
       -0.02010494, -0.00159352, -0.01180097,  0.00701373, -0.01161305,
        0.01031245,  0.00376055, -0.00567973, -0.00211844, -0.00615125,
        0.00042277, -0.00866742,  0.00308504, -0.01136826,  0.00243393],
      dtype=float32)>, <tf.Tensor: shape=(30, 45), dtype=float32, numpy=
array([[ 1.8104884e-05, -3.1850144e-05,  3.9230647e-05, ...,
        -1.6767807e-04,  9.5423326e-05, -8.2236664e-05],
       [ 8.3959727e-05,  2.3527351e-05, -9.5829870e-05, ...,
         8.9521272e-05, -5.6410918e-05,  7.4229058e-05],
       [ 1.9319396e-04, -3.8352257e-05, -1.1828457e-04, ...,
        -1.7071549e-04,  8.2027909e-06,  5.8460093e-05],
       ...,
       [-2.1746336e-04,  1.0366295e-05,  1.2036145e-04, ...,
         1.8202905e-04, -2.7068632e-05, -1.1979604e-05],
       [-2.7805875e-04,  4.4696182e-05,  1.2789892e-04, ...,
         2.4139311e-04, -1.5693720e-05, -3.9670333e-05],
       [-2.9807800e-04,  5.2932468e-05,  1.3355096e-04, ...,
         2.4215091e-04, -1.9968793e-06, -6.7972840e-05]], dtype=float32)>, <tf.Tensor: shape=(30, 45), dtype=float32, numpy=
array([[ 2.85340706e-04, -2.14955999e-05, -1.35981245e-04, ...,
        -2.43047703e-04,  3.09029019e-05,  1.22494394e-05],
       [-2.57106352e-04,  1.91128693e-05,  1.23829654e-04, ...,
         2.37682645e-04, -5.32939048e-05,  1.76535905e-05],
       [-2.28908684e-04,  2.56215990e-05,  1.07185631e-04, ...,
         1.92597028e-04, -1.02061531e-04,  6.36291879e-05],
       ...,
       [ 1.84930468e-05, -2.21634946e-05,  9.97064490e-06, ...,
        -1.46289953e-04,  8.26302858e-05, -6.25322209e-05],
       [ 1.34348957e-04, -2.65608505e-05, -4.36768460e-05, ...,
        -2.00483875e-04,  1.06171625e-04, -8.50106444e-05],
       [ 2.51920486e-04, -2.94968486e-05, -1.08915214e-04, ...,
        -2.48657016e-04,  1.34789589e-04, -9.21039318e-05]], dtype=float32)>, <tf.Tensor: shape=(90,), dtype=float32, numpy=
array([-2.46187174e-05,  1.21727917e-05,  1.30418930e-05, -3.30382900e-05,
        1.45821004e-05,  1.47277853e-04, -8.25478201e-05,  3.49659695e-06,
       -2.22166054e-05, -3.06050642e-05, -2.86043869e-05, -1.92710786e-06,
       -1.15052808e-05, -5.92550205e-05, -6.15312674e-05, -1.38316518e-05,
        2.75235856e-04,  1.18189173e-05,  8.50671313e-06, -6.26186666e-05,
       -6.87888096e-05,  3.97903495e-05, -4.89454942e-06, -8.39135851e-07,
        6.27174541e-06, -2.21114533e-04,  1.21414369e-05, -9.23353673e-06,
       -2.39561200e-06, -8.04514493e-05, -1.20218632e-04, -3.71596761e-05,
        1.15656076e-04, -7.20262688e-05, -1.97786430e-05,  7.52611668e-05,
       -3.39783619e-05, -2.59822209e-05, -6.35428751e-06,  8.58685380e-05,
        2.04418939e-06, -1.03547507e-04, -2.74456443e-06,  6.64807158e-05,
       -8.04185256e-05, -1.08946022e-02, -6.72965217e-03, -1.25121633e-02,
        7.86201679e-04,  6.14009611e-03,  1.03620011e-02,  9.51796595e-04,
       -5.88987768e-03, -1.71601388e-03, -4.71814210e-03, -1.95280481e-02,
       -5.77223999e-03,  1.00842584e-03, -2.57193297e-03,  6.86323596e-03,
        1.20744966e-02,  4.93473373e-03, -1.09075112e-02, -2.69731437e-03,
       -1.19680539e-02, -6.59811636e-03,  8.83811712e-03,  2.29524914e-03,
        1.39167737e-02,  7.69823603e-03, -1.03900712e-02, -2.13473709e-03,
       -1.36027690e-02,  1.51861319e-02, -1.36909285e-03,  4.59971651e-03,
       -6.93621580e-03,  1.28372135e-02,  1.41102104e-02, -6.13337988e-03,
        4.52079112e-03, -2.65105837e-03, -1.76102612e-02,  3.34152021e-03,
       -2.89703067e-03,  3.40234442e-03,  7.26825837e-03,  5.17941406e-03,
        9.10552312e-03, -1.74694299e-03], dtype=float32)>, <tf.Tensor: shape=(45, 24), dtype=float32, numpy=
array([[ 2.61741632e-04, -5.77608735e-05, -1.12600843e-04, ...,
        -5.82199209e-05, -1.14595081e-04,  2.04251919e-04],
       [ 2.18637724e-05, -3.60515969e-06, -8.59258871e-05, ...,
         7.98987821e-06, -8.56043698e-05,  2.85281247e-04],
       [ 2.80055712e-04, -5.10218852e-05, -1.62400247e-05, ...,
        -4.76969399e-05, -8.53380043e-05,  1.07899752e-04],
       ...,
       [ 7.22946308e-04, -5.53980899e-05, -2.91696517e-04, ...,
        -7.67816236e-05, -2.67306779e-04,  4.43090481e-04],
       [-2.08147103e-05,  2.78587286e-05, -6.32000010e-05, ...,
         3.48554750e-05, -7.35609647e-05,  2.87068950e-04],
       [ 2.93854973e-05, -4.75361230e-05,  1.28856424e-04, ...,
        -4.97458532e-05,  1.01759375e-04, -3.78989585e-04]], dtype=float32)>, <tf.Tensor: shape=(45, 24), dtype=float32, numpy=
array([[ 1.3065335e-04,  4.8986760e-05, -1.3709720e-04, ...,
         1.0413785e-05, -1.3376757e-05, -1.3387478e-04],
       [ 5.3163787e-04, -5.2601108e-06, -3.0639640e-04, ...,
        -4.2111045e-05, -1.8126747e-04,  2.3812288e-04],
       [-1.7585942e-04, -5.1628685e-05,  1.7212678e-04, ...,
        -3.3776611e-05,  1.0513376e-04, -2.5818532e-04],
       ...,
       [ 2.9887509e-05, -7.0327253e-05,  1.5282480e-04, ...,
        -6.8183908e-05,  9.4696043e-05, -3.6792285e-04],
       [ 5.2014552e-04, -7.2896597e-05, -1.8129355e-04, ...,
        -8.0755686e-05, -1.8793627e-04,  3.1849067e-04],
       [-7.2706700e-04,  4.8972623e-05,  3.1731138e-04, ...,
         7.8067867e-05,  2.6531087e-04, -4.2088312e-04]], dtype=float32)>, <tf.Tensor: shape=(48,), dtype=float32, numpy=
array([ 6.5127360e-03, -2.4311452e-03, -9.9678859e-03,  2.5995393e-04,
       -1.3764126e-03, -6.8242387e-03,  8.9050308e-03, -1.2247485e-02,
       -6.7266395e-05,  1.2143163e-03, -9.8131141e-03,  8.4452992e-03,
       -1.2625805e-03,  7.6144976e-03,  4.7699036e-03,  9.1443362e-04,
       -2.9898351e-03, -8.1658261e-03,  3.6660451e-05,  8.5028820e-03,
        5.5341166e-03,  9.7998255e-04,  3.6436000e-03, -5.2576400e-03,
        6.2040812e-03, -2.3863746e-03, -9.9597247e-03,  2.3035958e-04,
       -1.5466064e-03, -6.8008066e-03,  8.7966118e-03, -1.2262803e-02,
        3.2965658e-05,  1.2315067e-03, -9.6264994e-03,  8.4460955e-03,
       -1.2659875e-03,  7.4871043e-03,  4.6913652e-03,  7.9554430e-04,
       -3.0043628e-03, -8.3695650e-03,  3.3694498e-05,  8.5994694e-03,
        5.4950654e-03,  1.0575880e-03,  3.6251547e-03, -4.9247155e-03],
      dtype=float32)>, <tf.Tensor: shape=(24, 12), dtype=float32, numpy=
array([[-1.23163874e-04,  9.65616346e-06,  1.85133162e-04,
        -1.52038061e-04, -1.66895752e-05,  5.41060472e-05,
         4.75945126e-05, -1.63521501e-04,  7.93287763e-05,
         1.63929391e-04,  2.23919997e-05,  3.50073351e-05],
       [-5.43186616e-07,  9.43526975e-05, -5.43181814e-05,
         2.89020281e-05, -3.70379780e-07, -1.65234142e-05,
         8.86045018e-05,  2.92252644e-05,  4.54084602e-06,
         2.03513864e-05, -2.33811952e-05, -4.70215309e-05],
       [ 4.49569325e-06,  6.25865578e-05, -6.02568398e-05,
         5.33661077e-05,  7.07913387e-06, -8.70529766e-06,
         6.69235742e-05,  3.34737852e-05, -9.86209443e-07,
         2.85130182e-06, -7.40076257e-06, -4.48039791e-05],
       [ 4.57035203e-04,  1.47327461e-04, -5.80313150e-04,
         3.68758570e-04,  1.28589299e-05, -1.89077255e-04,
        -2.14686861e-06,  5.37873362e-04, -2.53058388e-04,
        -4.67834063e-04, -1.54766632e-04, -2.69693148e-04],
       [-4.53672663e-04, -1.49512693e-04,  5.60484361e-04,
        -3.51432653e-04, -8.12420330e-06,  1.79015464e-04,
         6.61245394e-07, -5.27117751e-04,  2.59821711e-04,
         4.70458384e-04,  1.54238427e-04,  2.68971198e-04],
       [-4.27915133e-04, -9.33007250e-05,  5.31157712e-04,
        -3.38810874e-04, -1.60879481e-05,  1.81483032e-04,
         4.87019315e-05, -4.96001216e-04,  2.37217973e-04,
         4.44907229e-04,  1.44017496e-04,  2.28540070e-04],
       [-1.29409367e-04,  2.70529184e-04,  5.78949330e-05,
        -3.84221785e-05, -5.40063083e-05,  6.89160806e-05,
         3.21481086e-04, -8.61777226e-05,  7.95066662e-05,
         1.66076381e-04,  2.69466254e-05, -2.87379207e-05],
       [-5.20099311e-05,  8.99045699e-06,  2.24324413e-05,
         2.40430950e-06,  3.88275384e-06,  1.57158847e-05,
         1.39520371e-05, -3.50414921e-05,  1.09817684e-05,
         2.64022710e-05,  1.46621105e-05,  1.52046705e-05],
       [-2.22374030e-04, -1.23751990e-04,  3.25497647e-04,
        -2.15353662e-04,  1.80168172e-07,  9.73701244e-05,
        -4.89354570e-05, -2.85339076e-04,  1.20069824e-04,
         2.25957250e-04,  8.11602731e-05,  1.42041303e-04],
       [-2.85112299e-04, -7.55588117e-05,  3.66364722e-04,
        -2.32106337e-04, -1.12235302e-05,  1.25170001e-04,
         1.56965871e-05, -3.35436052e-04,  1.60631826e-04,
         2.92335928e-04,  1.06061751e-04,  1.79249735e-04],
       [-4.72808111e-04, -1.42661913e-04,  5.84280118e-04,
        -3.61417944e-04, -1.08984113e-05,  1.95809407e-04,
         1.35203218e-05, -5.49332122e-04,  2.65556679e-04,
         4.85282246e-04,  1.64016266e-04,  2.75686296e-04],
       [-2.21114067e-04, -2.73724945e-05,  2.52937258e-04,
        -1.62901852e-04, -9.34021227e-06,  8.81863816e-05,
         4.90291532e-05, -2.48887111e-04,  1.40632357e-04,
         2.49145844e-04,  7.11085449e-05,  1.16849165e-04],
       [-3.43312859e-04, -9.63415805e-05,  4.41614713e-04,
        -2.83779751e-04, -1.08473214e-05,  1.43250887e-04,
         1.44800060e-05, -4.05011611e-04,  1.89120561e-04,
         3.54861957e-04,  1.12056652e-04,  1.94479333e-04],
       [-1.50053937e-04,  4.86057252e-05,  1.59228919e-04,
        -1.20646888e-04, -2.05697670e-05,  5.15499123e-05,
         9.53931885e-05, -1.61443590e-04,  1.03918435e-04,
         1.96378620e-04,  2.49697314e-05,  5.37670167e-05],
       [-1.59267380e-04, -3.03040688e-05,  1.80564239e-04,
        -1.04362371e-04, -2.44856977e-07,  6.14710807e-05,
         1.69796549e-05, -1.70505649e-04,  8.17479740e-05,
         1.54419002e-04,  5.65873415e-05,  9.90314875e-05],
       [ 4.24243044e-04,  1.20878249e-04, -5.06587385e-04,
         3.18719802e-04,  6.37437915e-06, -1.59229356e-04,
        -1.38821160e-05,  4.82830510e-04, -2.42421898e-04,
        -4.44863137e-04, -1.34326750e-04, -2.42876704e-04],
       [ 7.55316578e-05,  7.18976935e-06, -9.49354580e-05,
         5.83129731e-05,  8.14876057e-06, -3.96691248e-05,
        -3.43938627e-05,  8.92964890e-05, -5.63132817e-05,
        -9.40790342e-05, -3.78373988e-05, -3.75956297e-05],
       [ 4.65260935e-04,  9.75151270e-05, -5.59311942e-04,
         3.48382280e-04,  1.82526273e-05, -1.96927256e-04,
        -5.96088321e-05,  5.32542414e-04, -2.67666677e-04,
        -4.89228638e-04, -1.59329909e-04, -2.62499234e-04],
       [-3.08271556e-04,  5.11270969e-07,  3.28476512e-04,
        -1.96398512e-04, -2.18121586e-05,  1.33440801e-04,
         1.09400557e-04, -3.32782249e-04,  1.86960853e-04,
         3.36956902e-04,  1.02766389e-04,  1.49531959e-04],
       [-3.47694324e-04, -2.09705206e-04,  4.41013079e-04,
        -2.74956983e-04,  1.52553857e-05,  1.21387216e-04,
        -1.00255740e-04, -4.13510803e-04,  1.99983086e-04,
         3.55157710e-04,  1.16168914e-04,  2.31975777e-04],
       [ 2.01989023e-04,  1.26123094e-04, -2.55395978e-04,
         1.49154541e-04, -3.54823442e-08, -7.48607272e-05,
         6.75874253e-05,  2.34758772e-04, -1.10622379e-04,
        -1.86327015e-04, -8.06798562e-05, -1.69644220e-04],
       [ 1.64801604e-04,  7.76527741e-05, -1.90746374e-04,
         1.14131122e-04, -1.01274372e-05, -5.35889048e-05,
         2.18928508e-05,  1.86483201e-04, -9.79316537e-05,
        -1.71710708e-04, -5.26101576e-05, -8.95421981e-05],
       [ 3.18261649e-04,  9.28750669e-05, -3.64467793e-04,
         2.22571223e-04,  4.94390042e-06, -1.20121913e-04,
        -5.96081554e-06,  3.56081873e-04, -1.80517105e-04,
        -3.26067791e-04, -1.00296536e-04, -1.82160642e-04],
       [-4.79210052e-04, -1.58150622e-04,  5.93089324e-04,
        -3.72504990e-04, -7.97474513e-06,  1.90829160e-04,
        -6.36592267e-06, -5.56848419e-04,  2.65898474e-04,
         4.89377417e-04,  1.59015995e-04,  2.84927490e-04]], dtype=float32)>, <tf.Tensor: shape=(24, 12), dtype=float32, numpy=
array([[-4.38234012e-04, -1.31565685e-04,  5.44426730e-04,
        -3.45436070e-04, -1.00471570e-05,  1.76072645e-04,
         9.50945196e-06, -5.09564299e-04,  2.48896977e-04,
         4.60699172e-04,  1.43956146e-04,  2.52206839e-04],
       [-5.00810507e-04, -1.74677567e-04,  6.18310529e-04,
        -3.86166677e-04, -4.82613223e-06,  1.95268207e-04,
        -1.82902240e-05, -5.80072170e-04,  2.77251296e-04,
         5.09620178e-04,  1.66903512e-04,  3.01168126e-04],
       [ 1.09876615e-04,  3.67245448e-05, -1.45994010e-04,
         9.88598695e-05,  1.31506442e-06, -4.79683004e-05,
        -1.28684569e-05,  1.36345378e-04, -8.02069553e-05,
        -1.44165082e-04, -3.61892817e-05, -5.32410704e-05],
       [ 2.11913735e-04,  4.28411076e-05, -2.66289251e-04,
         1.77829948e-04,  9.46822820e-06, -9.00689483e-05,
        -4.15060058e-05,  2.53571896e-04, -1.39200245e-04,
        -2.50620564e-04, -6.87659413e-05, -1.07955020e-04],
       [ 2.15972337e-04,  3.05971480e-05, -2.64550326e-04,
         1.57871837e-04,  4.42461715e-06, -9.77555173e-05,
        -3.39006183e-05,  2.42174108e-04, -1.07764950e-04,
        -2.16743952e-04, -7.15267524e-05, -1.20025696e-04],
       [-4.10524401e-04, -9.08945585e-05,  4.95961227e-04,
        -3.06747388e-04, -1.31823272e-05,  1.68974628e-04,
         4.00664467e-05, -4.67095932e-04,  2.31821847e-04,
         4.34326008e-04,  1.34067566e-04,  2.34968116e-04],
       [-5.38372668e-04, -1.75521302e-04,  6.62142294e-04,
        -4.15102084e-04, -8.46538205e-06,  2.11608800e-04,
        -4.40240547e-06, -6.23952365e-04,  3.01662367e-04,
         5.51852980e-04,  1.79026043e-04,  3.20348132e-04],
       [ 8.60477594e-05,  9.60519101e-05, -1.38991833e-04,
         9.58424134e-05,  9.52153982e-08, -2.37043587e-05,
         6.77973949e-05,  1.17940239e-04, -4.64254081e-05,
        -7.86776218e-05, -2.57976608e-05, -7.86033561e-05],
       [-4.60436335e-04, -1.60904296e-04,  5.77561616e-04,
        -3.64846986e-04, -5.07002096e-06,  1.85706129e-04,
        -1.06976795e-05, -5.40329493e-04,  2.61871930e-04,
         4.78503527e-04,  1.56665192e-04,  2.72273785e-04],
       [ 4.64529556e-04,  1.02964492e-04, -5.64958784e-04,
         3.49353912e-04,  1.55389098e-05, -1.94262830e-04,
        -4.21521290e-05,  5.30070916e-04, -2.46962300e-04,
        -4.63534932e-04, -1.56852882e-04, -2.64825794e-04],
       [ 1.76266185e-04,  1.03199985e-04, -2.46821088e-04,
         1.69720093e-04,  5.14052886e-07, -6.69466535e-05,
         4.65672201e-05,  2.23527546e-04, -1.05456755e-04,
        -1.90549996e-04, -5.46724623e-05, -1.17731222e-04],
       [-2.14827189e-04, -1.15740113e-05,  2.49033852e-04,
        -1.54554888e-04, -1.38999903e-05,  9.59971367e-05,
         5.98788793e-05, -2.40932102e-04,  1.20972247e-04,
         2.23266092e-04,  7.57214948e-05,  1.06887921e-04],
       [-3.58377816e-04, -1.02306396e-04,  4.42611519e-04,
        -2.79710453e-04, -6.23570577e-06,  1.44709338e-04,
         1.48022391e-05, -4.17138392e-04,  2.09152524e-04,
         3.84919898e-04,  1.18661439e-04,  2.03309610e-04],
       [ 4.73332737e-04,  1.29966546e-04, -5.78528270e-04,
         3.61653394e-04,  8.72574401e-06, -1.91875166e-04,
        -2.41531034e-05,  5.45953109e-04, -2.67741241e-04,
        -4.93246014e-04, -1.58184615e-04, -2.68408796e-04],
       [ 3.21033061e-04,  9.86162850e-05, -3.94434202e-04,
         2.47201096e-04,  8.03329294e-06, -1.32247325e-04,
        -9.72341604e-06,  3.73930496e-04, -1.85424287e-04,
        -3.35243967e-04, -1.10794965e-04, -1.91582483e-04],
       [ 7.43186174e-05,  7.34988425e-05, -8.58095082e-05,
         6.02741129e-05, -4.54456358e-06, -4.78700395e-06,
         5.24938514e-05,  8.81184242e-05, -5.35067702e-05,
        -8.19355337e-05, -1.57463182e-05, -6.11828364e-05],
       [-3.11067037e-04, -1.12570677e-04,  3.69592308e-04,
        -2.25326396e-04,  6.14498094e-06,  1.16824667e-04,
        -1.49093648e-05, -3.54358635e-04,  1.77736554e-04,
         3.23048560e-04,  1.02625592e-04,  1.84337026e-04],
       [-2.74785962e-05, -1.46450620e-05,  3.09435200e-05,
        -2.48834349e-05,  1.81432051e-06, -1.67508415e-06,
        -1.30434792e-05, -3.33138196e-05,  1.61989410e-05,
         2.92711666e-05,  1.90613514e-06,  7.83234100e-06],
       [-2.52938538e-04, -1.31188017e-07,  2.83239759e-04,
        -1.63167308e-04, -1.59035590e-05,  1.14202980e-04,
         7.89121768e-05, -2.71478493e-04,  1.31053894e-04,
         2.51101796e-04,  8.62396410e-05,  1.41979763e-04],
       [ 8.33263039e-05, -1.43882280e-05, -7.19855889e-05,
         4.09649438e-05,  1.08830363e-05, -3.55540578e-05,
        -5.42317284e-05,  8.60414148e-05, -5.51427001e-05,
        -8.43524977e-05, -3.14914651e-05, -3.85650092e-05],
       [-2.14954009e-04,  3.78187397e-05,  2.51088204e-04,
        -1.49659609e-04, -2.00868799e-05,  1.04232175e-04,
         9.42333863e-05, -2.29737387e-04,  9.63286584e-05,
         2.08709069e-04,  6.89336302e-05,  1.00490412e-04],
       [ 5.69917145e-04,  1.78449351e-04, -7.02417979e-04,
         4.41047188e-04,  1.01711667e-05, -2.25813419e-04,
        -2.11902989e-06,  6.60409103e-04, -3.18670587e-04,
        -5.86577924e-04, -1.88220409e-04, -3.36401019e-04],
       [ 2.59396445e-04,  7.60563271e-05, -3.08437680e-04,
         1.93119253e-04,  2.18857804e-06, -9.82747588e-05,
        -6.54943142e-06,  2.98561819e-04, -1.50395150e-04,
        -2.73818063e-04, -8.28369230e-05, -1.52148365e-04],
       [-1.60995769e-04, -1.01753743e-04,  1.94394423e-04,
        -1.23737118e-04,  1.55430753e-05,  5.54881044e-05,
        -4.68667349e-05, -1.91361774e-04,  1.06771251e-04,
         1.80058909e-04,  5.99893392e-05,  9.81542689e-05]], dtype=float32)>, <tf.Tensor: shape=(24,), dtype=float32, numpy=
array([-1.1326433e-02,  5.5277939e-03,  1.6758760e-03,  1.3165935e-02,
       -5.5126906e-03,  1.1951015e-03,  1.3611306e-02, -6.1683902e-03,
       -1.1239265e-04, -8.1400096e-05,  9.3894801e-04,  8.4572164e-03,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
      dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[ 6.96864081e-05,  1.78163071e-04,  0.00000000e+00,
        -9.83879872e-05,  3.19557766e-05, -8.15194042e-04,
        -4.24375350e-04,  0.00000000e+00,  1.71679421e-04,
         0.00000000e+00,  0.00000000e+00,  9.21145664e-04,
         6.90701534e-04,  9.30353533e-04,  0.00000000e+00,
         8.38335254e-05, -1.72565269e-04,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -1.81995565e-04,
         1.69978233e-03,  0.00000000e+00,  1.40280841e-04,
         0.00000000e+00,  5.48895623e-04, -1.43832876e-04,
        -9.21421088e-05, -7.04270715e-05,  0.00000000e+00],
       [-3.10370197e-05, -1.81808082e-05,  1.32395035e-05,
         1.93195319e-05, -1.18491189e-05, -1.04026476e-04,
         2.76130813e-05,  3.60851845e-06,  3.31154297e-05,
         0.00000000e+00, -7.06017545e-06,  8.89336297e-05,
         1.26308863e-04,  7.83267460e-05,  1.80260690e-06,
         2.16431235e-05, -1.42397876e-05,  6.33640593e-06,
         0.00000000e+00,  0.00000000e+00, -1.99046826e-06,
         1.67179445e-04,  1.67601527e-07,  3.15038924e-05,
         6.15776003e-07,  6.23047963e-05,  6.05919013e-05,
        -2.52580958e-06, -4.98417967e-06,  0.00000000e+00],
       [ 9.01062740e-05,  3.81844438e-06, -2.14049105e-05,
        -5.00503229e-05,  3.15556063e-05,  4.45143742e-05,
        -1.61617972e-05,  3.20042309e-05, -2.24650080e-06,
         0.00000000e+00, -6.44437314e-05,  6.88689761e-06,
        -1.82162512e-06, -1.11224745e-05,  4.06585750e-05,
        -6.38229167e-08, -1.35369346e-05, -2.89738218e-05,
         0.00000000e+00,  0.00000000e+00, -2.04118514e-05,
        -1.81260657e-05, -1.42100498e-05, -2.21769606e-05,
         4.79614610e-05,  5.64001994e-06, -7.35996082e-06,
         7.60723651e-06,  2.94902270e-06,  0.00000000e+00],
       [ 1.14464943e-04,  0.00000000e+00,  5.51760641e-05,
        -9.00953019e-05, -1.58952446e-06, -2.89128366e-07,
         7.64431024e-06,  1.14647788e-04, -1.35654209e-05,
         0.00000000e+00, -8.78171049e-05, -2.91272556e-07,
         0.00000000e+00,  7.24956626e-05,  2.93515877e-05,
         0.00000000e+00,  7.41218464e-05, -4.13753332e-06,
         0.00000000e+00,  0.00000000e+00, -4.58380673e-05,
        -2.98791601e-05, -1.70582389e-05, -2.96765465e-05,
         3.14950339e-05,  0.00000000e+00,  1.44389571e-06,
         3.90088717e-05, -2.37888867e-06,  0.00000000e+00],
       [ 5.68199612e-04,  0.00000000e+00,  6.84729457e-05,
        -3.02548928e-04,  1.21493373e-04,  1.70373693e-04,
         1.21485291e-05,  3.37860722e-04, -4.91817700e-05,
         0.00000000e+00, -4.47882805e-04, -5.59581110e-07,
         0.00000000e+00,  1.00227262e-04,  2.28311706e-04,
         0.00000000e+00,  1.01844969e-04, -8.47123592e-05,
         0.00000000e+00,  0.00000000e+00, -1.19609773e-04,
        -1.43703408e-04, -7.86574092e-05, -1.99295668e-04,
         2.22912058e-04,  0.00000000e+00,  1.58041883e-06,
         1.04035367e-04, -1.05020968e-06,  0.00000000e+00],
       [ 2.50794255e-04,  0.00000000e+00,  3.82274593e-05,
        -1.34442467e-04,  4.86793579e-05,  6.35307224e-05,
         6.82351128e-06,  1.39077223e-04, -2.48777542e-05,
         0.00000000e+00, -2.02747935e-04, -4.32826539e-07,
         0.00000000e+00,  5.19063433e-05,  1.05432795e-04,
         0.00000000e+00,  4.23686142e-05, -3.02304197e-05,
         0.00000000e+00,  0.00000000e+00, -4.66894562e-05,
        -4.71099083e-05, -3.11263830e-05, -9.30402821e-05,
         9.38458834e-05,  0.00000000e+00,  7.75996909e-07,
         4.57683127e-05, -3.54598768e-07,  0.00000000e+00],
       [ 9.62606209e-05, -6.71043699e-06,  9.09828959e-05,
        -8.04349111e-05, -1.48056643e-05, -5.08655903e-05,
         2.18828245e-05,  9.57265802e-05, -1.02100548e-05,
         0.00000000e+00, -9.55196811e-05,  6.91154355e-06,
         1.73740100e-05,  9.27940055e-05,  3.01571945e-05,
         6.35306742e-06,  7.55462534e-05,  3.22981577e-05,
         0.00000000e+00,  0.00000000e+00, -2.26382836e-05,
         3.70109956e-05, -5.73606712e-06, -3.86747270e-05,
         2.44523235e-05,  9.77810032e-06,  1.54253885e-05,
         4.18999225e-05,  9.40405243e-07,  0.00000000e+00],
       [ 1.52333814e-05, -1.27900985e-05,  3.85522872e-05,
        -2.13250423e-05, -9.39390611e-06, -5.43688620e-05,
         2.45956035e-05,  3.03803899e-05,  1.63788281e-05,
         0.00000000e+00, -3.60235608e-05,  2.91671531e-05,
         5.16662440e-05,  5.17841509e-05,  1.15162293e-05,
         1.33035301e-05,  2.51805614e-05,  1.61443841e-05,
         0.00000000e+00,  0.00000000e+00, -5.05965909e-06,
         7.19191739e-05, -1.52448069e-06, -2.13182830e-06,
         1.41830660e-05,  2.53070393e-05,  3.69453628e-05,
         1.58661151e-05,  1.22302254e-06,  0.00000000e+00],
       [-3.23539098e-05, -1.13869646e-05,  5.01515888e-06,
         2.02106748e-05, -9.83999144e-07, -1.08104832e-04,
         8.85052259e-07, -1.36878157e-07,  3.19007850e-05,
         0.00000000e+00, -3.24010603e-06,  1.21320685e-04,
         1.33649504e-04,  1.05414809e-04,  1.11195004e-06,
         1.60865256e-05, -1.77546062e-05,  2.51626534e-06,
         0.00000000e+00,  0.00000000e+00, -5.44824343e-06,
         1.96963316e-04,  7.85487373e-08,  3.14125100e-05,
         3.46461178e-07,  7.54556386e-05,  5.11357648e-05,
        -1.11080626e-05, -7.82543611e-06,  0.00000000e+00],
       [ 6.81774764e-05,  2.56674866e-05, -2.01152307e-05,
        -4.96758003e-05,  8.02651539e-06, -3.23737768e-05,
        -8.02512732e-05,  1.05650724e-05, -1.87520868e-06,
         0.00000000e+00, -1.33791464e-05,  5.72834688e-05,
         9.70423571e-06,  7.40226169e-05,  7.22512732e-06,
        -2.70714310e-07, -3.09091993e-05, -2.29873131e-05,
         0.00000000e+00,  0.00000000e+00, -4.86937060e-05,
         1.15985429e-04, -4.35220818e-06,  8.30236786e-06,
         1.50413562e-05,  3.81771133e-05, -9.26914727e-05,
         7.80177379e-06, -4.01481066e-06,  0.00000000e+00],
       [ 7.32902190e-05, -1.22683127e-06,  2.97727711e-05,
        -3.90972709e-05,  1.07158257e-05,  4.66452821e-06,
         3.92304082e-06,  4.26101396e-05, -8.59868123e-06,
         0.00000000e+00, -6.42973537e-05,  2.82221595e-06,
         2.64587379e-06,  2.42581973e-05,  3.12383272e-05,
         1.42482133e-06,  2.35977623e-05,  8.97565769e-06,
         0.00000000e+00,  0.00000000e+00, -4.75778006e-06,
         2.92350160e-06, -7.05594357e-06, -3.47196947e-05,
         2.97231527e-05,  2.06484242e-06,  2.18317291e-06,
         1.77924267e-05,  6.31517707e-07,  0.00000000e+00],
       [-9.76026149e-06,  6.55275653e-05,  1.34828113e-07,
         1.80631480e-06,  1.46884295e-05, -3.40115017e-04,
        -6.24427048e-05,  1.32530245e-08,  8.00869311e-05,
         0.00000000e+00, -2.90136256e-07,  3.48828005e-04,
         3.53255804e-04,  3.32236057e-04,  0.00000000e+00,
         4.94821979e-05, -7.05176717e-05,  1.36395869e-07,
         0.00000000e+00,  0.00000000e+00, -4.26956613e-05,
         6.76952826e-04,  0.00000000e+00,  5.76581297e-05,
         0.00000000e+00,  2.09829392e-04,  7.07371510e-05,
        -3.19991377e-05, -3.08447743e-05,  0.00000000e+00],
       [-1.64079174e-05,  5.69818585e-05,  1.00957642e-09,
         5.48014168e-06,  2.02975389e-05, -4.29027947e-04,
        -1.38972886e-04,  9.92370283e-11,  1.09702603e-04,
         0.00000000e+00, -2.17250484e-09,  4.75282839e-04,
         4.16463532e-04,  4.57653281e-04,  0.00000000e+00,
         5.57205931e-05, -9.74277136e-05,  1.02131559e-09,
         0.00000000e+00,  0.00000000e+00, -6.92623944e-05,
         8.63338064e-04,  0.00000000e+00,  8.59782522e-05,
         0.00000000e+00,  2.90038472e-04, -6.26262590e-07,
        -5.07666591e-05, -3.42699677e-05,  0.00000000e+00],
       [ 1.69518418e-04,  0.00000000e+00,  2.93167213e-05,
        -8.85121553e-05,  3.09544812e-05,  4.01093566e-05,
         5.03763977e-06,  8.34916355e-05, -2.23523821e-05,
         0.00000000e+00, -1.37040639e-04, -2.64354476e-08,
         0.00000000e+00,  3.13382625e-05,  7.47506710e-05,
         0.00000000e+00,  2.79102278e-05, -8.56340284e-06,
         0.00000000e+00,  0.00000000e+00, -2.12260693e-05,
        -2.31577378e-05, -1.95901266e-05, -6.87704669e-05,
         6.32448064e-05,  0.00000000e+00,  4.95752829e-07,
         3.22511260e-05, -3.18948679e-07,  0.00000000e+00],
       [ 1.16767792e-03,  0.00000000e+00,  2.12425410e-04,
        -6.27318921e-04,  2.18211120e-04,  2.78850843e-04,
         3.52739626e-05,  6.74779178e-04, -1.22239289e-04,
         0.00000000e+00, -9.40568279e-04, -1.17652337e-06,
         0.00000000e+00,  2.58683634e-04,  4.76965914e-04,
         0.00000000e+00,  2.34206396e-04, -1.07845379e-04,
         0.00000000e+00,  0.00000000e+00, -2.15502558e-04,
        -2.18948699e-04, -1.49027386e-04, -4.39458585e-04,
         4.38662275e-04,  0.00000000e+00,  3.93976325e-06,
         2.25238065e-04, -3.46183629e-06,  0.00000000e+00],
       [ 1.71870604e-04, -7.94623318e-08,  1.16698946e-04,
        -1.24630329e-04, -8.84564815e-06, -3.13634191e-05,
         1.53324763e-05,  1.52854569e-04, -2.59570661e-05,
         0.00000000e+00, -1.47038183e-04, -3.99496770e-07,
         5.58106770e-08,  1.25862862e-04,  5.09083875e-05,
         3.93970652e-08,  1.11673209e-04,  2.94040001e-05,
         0.00000000e+00,  0.00000000e+00, -4.16622897e-05,
         3.73144780e-06, -1.86084253e-05, -6.78201468e-05,
         4.36264600e-05,  7.85395216e-08,  2.07792027e-06,
         5.99556988e-05, -2.52035647e-06,  0.00000000e+00],
       [-6.46061308e-05,  3.84443192e-05,  5.88072453e-08,
         3.47026471e-05,  2.88317642e-05, -6.22183084e-04,
        -2.01470102e-04, -7.39808925e-08,  1.67965380e-04,
         0.00000000e+00, -6.97334457e-08,  7.37813185e-04,
         6.26067282e-04,  6.83662598e-04,  0.00000000e+00,
         7.94472362e-05, -1.27714593e-04,  9.61764357e-08,
         0.00000000e+00,  0.00000000e+00, -1.00534613e-04,
         1.24310574e-03,  0.00000000e+00,  1.47917584e-04,
         0.00000000e+00,  4.44059027e-04,  7.91132243e-06,
        -7.91851271e-05, -5.91897187e-05,  0.00000000e+00],
       [ 3.97968251e-04,  0.00000000e+00,  1.45310914e-05,
        -2.03469346e-04,  9.80640107e-05,  1.45888102e-04,
         5.17297258e-06,  2.18044413e-04, -3.08987728e-05,
         0.00000000e+00, -3.10823816e-04, -1.34092204e-07,
         0.00000000e+00,  4.01232464e-05,  1.66833663e-04,
         0.00000000e+00,  4.50728257e-05, -7.89880651e-05,
         0.00000000e+00,  0.00000000e+00, -8.12818398e-05,
        -1.13827940e-04, -5.75329032e-05, -1.36881223e-04,
         1.64888523e-04,  1.80553117e-09,  7.76291643e-07,
         6.44267348e-05, -2.15800952e-07,  0.00000000e+00],
       [ 3.20459912e-05, -2.01151647e-06,  2.51855345e-05,
        -2.33673181e-05, -7.02132752e-07, -1.38760379e-05,
         6.25764369e-06,  2.99775820e-05, -4.18108812e-06,
         0.00000000e+00, -3.01569416e-05,  4.13345560e-06,
         6.40980261e-06,  2.39866913e-05,  9.92463265e-06,
         2.47384446e-06,  2.16009375e-05,  9.10754807e-06,
         0.00000000e+00,  0.00000000e+00, -8.46466719e-06,
         9.68661334e-06, -1.95819439e-06, -1.30520793e-05,
         8.48688887e-06,  3.98269913e-06,  5.03186084e-06,
         1.23791078e-05, -4.11213023e-07,  0.00000000e+00],
       [ 6.70716618e-05,  1.54632016e-05, -2.25307540e-05,
        -4.62402786e-05,  1.72348318e-05,  8.09451012e-06,
        -4.51618107e-05,  1.30912267e-05, -2.94129745e-06,
         0.00000000e+00, -3.07823248e-05,  2.24582946e-05,
        -2.37377753e-06,  1.57560426e-05,  2.16062308e-05,
        -4.20342907e-08, -2.26033790e-05, -2.53649996e-05,
         0.00000000e+00,  0.00000000e+00, -2.99975709e-05,
         3.52764655e-05, -8.37993230e-06, -5.59518730e-06,
         2.74580980e-05,  1.68688930e-05, -3.81397476e-05,
         1.11801990e-06,  3.95961069e-06,  0.00000000e+00],
       [ 4.02806210e-04,  0.00000000e+00,  1.04074970e-04,
        -2.23056442e-04,  6.47291454e-05,  7.43186756e-05,
         1.53748824e-05,  2.40062582e-04, -4.38508396e-05,
         0.00000000e+00, -3.30727838e-04, -4.65592620e-07,
         0.00000000e+00,  1.12074820e-04,  1.63390068e-04,
         0.00000000e+00,  1.03274077e-04, -1.13310634e-05,
         0.00000000e+00,  0.00000000e+00, -6.47465058e-05,
        -5.43211900e-05, -4.97119618e-05, -1.59708987e-04,
         1.50604537e-04,  0.00000000e+00,  1.67185374e-06,
         8.76323247e-05, -1.22554593e-06,  0.00000000e+00],
       [-3.34044707e-05,  2.18747482e-05,  2.26305772e-07,
         1.83746415e-05,  1.14184240e-05, -2.50640762e-04,
        -4.86943900e-05,  2.01657969e-07,  6.88660803e-05,
         0.00000000e+00, -1.99763249e-07,  2.80904351e-04,
         2.65968847e-04,  2.50174635e-04,  0.00000000e+00,
         3.78082113e-05, -5.27330449e-05, -1.57271884e-07,
         0.00000000e+00,  0.00000000e+00, -2.90338176e-05,
         4.90771781e-04,  0.00000000e+00,  5.30045108e-05,
         0.00000000e+00,  1.71401814e-04,  5.25698888e-05,
        -3.29854993e-05, -2.20492657e-05,  0.00000000e+00],
       [ 3.00803047e-04,  0.00000000e+00,  4.59437506e-05,
        -1.61500662e-04,  5.59019936e-05,  7.33595953e-05,
         8.63217883e-06,  1.76258764e-04, -3.39069011e-05,
         0.00000000e+00, -2.40232155e-04, -1.30234810e-07,
         0.00000000e+00,  6.55247568e-05,  1.20997269e-04,
         0.00000000e+00,  5.39558132e-05, -4.09381792e-05,
         0.00000000e+00,  0.00000000e+00, -6.47180786e-05,
        -6.39452919e-05, -3.85836611e-05, -1.08063425e-04,
         1.07635300e-04,  0.00000000e+00,  9.88186116e-07,
         5.33019120e-05, -1.41292969e-06,  0.00000000e+00],
       [ 7.26000930e-04,  0.00000000e+00,  2.21756825e-04,
        -4.20188502e-04,  9.88184329e-05,  1.04473664e-04,
         3.18968741e-05,  4.70712199e-04, -8.34845050e-05,
         0.00000000e+00, -5.93472796e-04, -1.23806728e-06,
         0.00000000e+00,  2.42882728e-04,  2.77876097e-04,
         0.00000000e+00,  2.23731913e-04, -1.24787348e-05,
         0.00000000e+00,  0.00000000e+00, -1.37447365e-04,
        -1.00522084e-04, -8.82870081e-05, -2.80597276e-04,
         2.56448344e-04,  0.00000000e+00,  3.42850262e-06,
         1.68705330e-04, -4.00189992e-06,  0.00000000e+00],
       [ 3.57827266e-05,  4.37414928e-05,  0.00000000e+00,
        -2.73912010e-05,  7.48728507e-06, -2.14865271e-04,
        -1.43145517e-04,  0.00000000e+00,  4.00455028e-05,
         0.00000000e+00,  0.00000000e+00,  2.50889279e-04,
         1.61642442e-04,  2.78594700e-04,  0.00000000e+00,
         1.62593533e-05, -5.96765167e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -6.24409295e-05,
         4.67932114e-04,  0.00000000e+00,  4.22443954e-05,
         0.00000000e+00,  1.51942368e-04, -1.18803611e-04,
        -1.40854736e-05, -2.71651279e-05,  0.00000000e+00],
       [ 4.66999540e-04,  0.00000000e+00, -2.26204065e-07,
        -2.33499857e-04,  1.16796444e-04,  1.84949851e-04,
         3.38911195e-06,  2.61640147e-04, -3.82274593e-05,
         0.00000000e+00, -3.56652454e-04,  5.59740897e-07,
         0.00000000e+00,  3.11950353e-05,  1.90625113e-04,
         0.00000000e+00,  4.33942696e-05, -1.07550804e-04,
         0.00000000e+00,  0.00000000e+00, -1.03897648e-04,
        -1.57206960e-04, -7.13985428e-05, -1.52450695e-04,
         1.94971886e-04,  1.89013264e-07,  1.39605186e-06,
         7.07356667e-05, -1.11856571e-06,  0.00000000e+00],
       [ 3.36351921e-04,  0.00000000e+00,  1.24557657e-04,
        -1.92352425e-04,  4.58654431e-05,  3.13176970e-05,
         1.75456025e-05,  2.00135328e-04, -3.72952491e-05,
         0.00000000e+00, -2.88058887e-04, -1.16272520e-06,
         0.00000000e+00,  1.23524384e-04,  1.38716263e-04,
         0.00000000e+00,  1.02938910e-04,  1.89199418e-05,
         0.00000000e+00,  0.00000000e+00, -4.53967259e-05,
        -1.27572921e-05, -3.54577423e-05, -1.44709775e-04,
         1.19721903e-04,  0.00000000e+00,  1.14232296e-06,
         8.04466108e-05, -7.28901341e-07,  0.00000000e+00],
       [ 3.36274279e-05,  1.47974861e-04,  0.00000000e+00,
        -6.61588201e-05,  3.38374375e-05, -6.71562389e-04,
        -2.80955632e-04,  0.00000000e+00,  1.49752348e-04,
         0.00000000e+00,  0.00000000e+00,  7.25395686e-04,
         6.03721594e-04,  7.22855912e-04,  0.00000000e+00,
         7.95720916e-05, -1.28878470e-04,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -1.28258500e-04,
         1.37299253e-03,  0.00000000e+00,  1.09873246e-04,
         0.00000000e+00,  4.31199791e-04, -2.11516872e-05,
        -7.91645216e-05, -4.61274831e-05,  0.00000000e+00],
       [ 4.29449792e-05,  4.97668734e-05, -6.73928557e-09,
        -4.76028727e-05,  1.05638292e-05, -1.33896538e-04,
        -1.26201878e-04, -1.17188810e-08,  1.79844719e-05,
         0.00000000e+00, -3.70565467e-09,  1.51706496e-04,
         7.33416382e-05,  1.77344889e-04,  7.62834773e-09,
         7.57680209e-06, -3.04298410e-05, -1.03919575e-08,
         0.00000000e+00,  0.00000000e+00, -4.70658633e-05,
         2.95753038e-04, -5.09608489e-09,  1.50462711e-05,
        -5.38563860e-09,  8.83980538e-05, -8.93870674e-05,
        -1.79815634e-05, -4.59139892e-06,  0.00000000e+00],
       [ 3.60400445e-05,  6.93148540e-05,  4.27881730e-07,
        -4.16344847e-05,  9.62848389e-06, -1.25584193e-04,
        -5.11480503e-05,  5.81609996e-08,  1.65885504e-05,
         0.00000000e+00, -4.78555648e-07,  1.01571961e-04,
         9.75311341e-05,  1.11268884e-04,  1.02853562e-07,
         1.65419751e-05, -2.30088826e-05,  3.09988138e-07,
         0.00000000e+00,  0.00000000e+00, -2.29238558e-05,
         2.56703788e-04,  0.00000000e+00,  1.31639538e-07,
         0.00000000e+00,  5.87695686e-05,  1.70776784e-05,
        -1.51299619e-05,  5.10957534e-07,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[-9.35107004e-04,  0.00000000e+00, -1.97315036e-04,
         5.18628280e-04, -1.63999997e-04, -2.03680815e-04,
        -3.16577862e-05, -5.56743878e-04,  9.92916830e-05,
         0.00000000e+00,  7.55709014e-04,  1.19856770e-06,
         0.00000000e+00, -2.33099723e-04, -3.76485841e-04,
         0.00000000e+00, -2.15721870e-04,  7.10207678e-05,
         0.00000000e+00,  0.00000000e+00,  1.76266898e-04,
         1.67574326e-04,  1.17426644e-04,  3.52163159e-04,
        -3.45324574e-04,  0.00000000e+00, -3.54813392e-06,
        -1.92211810e-04,  3.76833941e-06,  0.00000000e+00],
       [-9.70141191e-05,  4.66460915e-06,  3.03398920e-05,
         2.82829697e-05, -4.01480938e-05, -8.64887043e-05,
        -2.60872512e-05, -3.65023843e-05,  6.51697655e-06,
         0.00000000e+00,  7.80389673e-05,  9.69781649e-06,
        -7.39095958e-06,  3.75772506e-05, -4.95028871e-05,
         0.00000000e+00,  1.44876685e-05,  4.11821202e-05,
         0.00000000e+00,  0.00000000e+00,  9.83215978e-06,
         7.85775192e-05,  1.67953494e-05,  3.71359456e-05,
        -5.72605786e-05,  1.03972734e-05, -1.22960873e-05,
        -1.20584746e-05,  6.66698907e-06,  0.00000000e+00],
       [-3.39797552e-05, -1.25202841e-05, -9.52534447e-06,
         3.00594456e-05,  8.24644576e-06, -6.44581232e-05,
         1.12241160e-05, -2.31481499e-06,  3.42462954e-05,
         0.00000000e+00,  6.13963402e-06,  7.42527409e-05,
         9.40502650e-05,  4.31620138e-05, -1.47359935e-06,
         1.66577938e-05, -2.88558040e-05, -4.49121399e-06,
         0.00000000e+00,  0.00000000e+00, -1.31519528e-07,
         1.25010949e-04, -1.32275972e-07,  2.82215315e-05,
         1.72667072e-08,  5.26210133e-05,  3.75600139e-05,
        -8.71896827e-06, -4.38034658e-06,  0.00000000e+00],
       [ 5.17032313e-05,  8.30373101e-05,  0.00000000e+00,
        -5.83664259e-05,  1.03662314e-05, -1.52226014e-04,
        -9.61953701e-05,  0.00000000e+00,  2.04811276e-05,
         0.00000000e+00,  0.00000000e+00,  1.35680093e-04,
         9.58905293e-05,  1.48653664e-04,  0.00000000e+00,
         1.68237420e-05, -3.25530636e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -3.68303663e-05,
         3.21025145e-04,  0.00000000e+00,  1.85043552e-06,
         0.00000000e+00,  8.08394470e-05, -2.47419612e-05,
        -2.19146823e-05,  3.33161552e-08,  0.00000000e+00],
       [ 8.85514964e-06,  9.86815066e-05,  0.00000000e+00,
        -2.47269363e-05,  2.32141701e-05, -5.10672224e-04,
        -1.78429269e-04,  0.00000000e+00,  1.18649783e-04,
         0.00000000e+00,  0.00000000e+00,  5.53131802e-04,
         4.85737139e-04,  5.42745111e-04,  0.00000000e+00,
         6.35661854e-05, -1.04287814e-04,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -8.84331312e-05,
         1.03657553e-03,  0.00000000e+00,  8.97103819e-05,
         0.00000000e+00,  3.29899252e-04,  9.10745348e-06,
        -5.57970998e-05, -4.17218253e-05,  0.00000000e+00],
       [ 4.15363957e-07,  3.48070498e-05,  0.00000000e+00,
        -1.39050871e-05,  1.19856486e-05, -2.13782696e-04,
        -1.00698606e-04,  0.00000000e+00,  5.03378069e-05,
         0.00000000e+00,  0.00000000e+00,  2.50401674e-04,
         1.92389110e-04,  2.40760346e-04,  0.00000000e+00,
         2.14362281e-05, -3.75935706e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -4.23878846e-05,
         4.34467627e-04,  0.00000000e+00,  4.20046854e-05,
         0.00000000e+00,  1.46863094e-04, -1.38091536e-05,
        -3.06663605e-05, -1.52640368e-05,  0.00000000e+00],
       [ 6.26701803e-05,  6.87957945e-05,  1.04756364e-05,
        -7.53613640e-05,  6.97158430e-06, -1.30834102e-04,
        -1.53451096e-04, -2.74137415e-06,  3.35905997e-06,
         0.00000000e+00,  5.73117177e-06,  1.17294054e-04,
         2.07454123e-05,  1.71020001e-04, -3.76617140e-06,
        -1.42157671e-06, -1.27339945e-05,  1.08083150e-05,
         0.00000000e+00,  0.00000000e+00, -5.30696379e-05,
         2.81303772e-04,  6.94435812e-07,  6.24563336e-06,
        -9.49747118e-06,  6.91245659e-05, -1.23071004e-04,
        -1.18050884e-05,  3.39506096e-06,  0.00000000e+00],
       [-9.40677637e-06,  2.11415463e-05,  1.98333491e-05,
        -1.78673326e-05, -5.89917136e-06, -7.62967538e-05,
        -7.15688584e-05, -8.71781504e-06,  5.50561299e-06,
         0.00000000e+00,  2.42395017e-05,  4.10908324e-05,
        -8.50834840e-06,  7.80536502e-05, -1.74315937e-05,
        -4.61038667e-07,  4.24515747e-06,  2.20739639e-05,
         0.00000000e+00,  0.00000000e+00, -1.95974008e-05,
         1.25166262e-04,  5.68902715e-06,  1.48978534e-05,
        -2.39900801e-05,  2.89431919e-05, -6.76219424e-05,
        -5.75893091e-06,  8.36084837e-06,  0.00000000e+00],
       [-1.28996893e-04,  2.21868021e-07,  1.93750329e-05,
         5.06218821e-05, -4.42287419e-05, -7.21628021e-05,
        -1.18641410e-05, -5.35215513e-05,  1.02705317e-05,
         0.00000000e+00,  1.00203390e-04,  4.91709443e-06,
        -3.13299870e-06,  1.40079828e-05, -5.92845390e-05,
         9.27479604e-08,  6.57872488e-06,  4.00053468e-05,
         0.00000000e+00,  0.00000000e+00,  2.15197906e-05,
         5.39977373e-05,  1.88593622e-05,  4.77508183e-05,
        -5.94720041e-05,  6.36852246e-06, -3.84543182e-06,
        -1.62058732e-05,  3.22449523e-06,  0.00000000e+00],
       [-8.46149705e-05, -2.07723565e-06, -5.12726110e-05,
         5.11778344e-05,  2.70604414e-06, -2.88708088e-05,
         1.22897136e-05, -4.58779905e-05,  2.34204999e-05,
         0.00000000e+00,  6.17507612e-05,  2.77521685e-05,
         5.16289219e-05, -2.79464402e-05, -2.14921183e-05,
         1.21589683e-05, -3.60716294e-05, -2.38184930e-05,
         0.00000000e+00,  0.00000000e+00,  3.70835278e-06,
         5.73737270e-05,  3.24176608e-06,  4.44724683e-05,
        -2.59157860e-05,  2.10811031e-05,  4.67079190e-05,
        -2.45639712e-05,  1.95117423e-07,  0.00000000e+00],
       [ 1.47698802e-05,  7.94552579e-06,  1.33934054e-06,
        -1.07915776e-05,  2.97560121e-07, -5.39282228e-05,
        -5.29146128e-05,  5.68483287e-08,  9.78482967e-06,
         0.00000000e+00,  1.30986098e-06,  6.24150343e-05,
         3.07805822e-05,  8.24110248e-05, -1.19739593e-06,
         1.77732136e-06, -1.42684239e-05,  1.67392136e-06,
         0.00000000e+00,  0.00000000e+00, -2.10849321e-05,
         1.24060476e-04, -1.08452546e-07,  1.04718056e-05,
        -1.07600567e-06,  3.87786786e-05, -5.73913785e-05,
        -7.84684744e-07, -6.57894543e-06,  0.00000000e+00],
       [-3.64178210e-04,  0.00000000e+00, -1.55503476e-05,
         1.87069556e-04, -8.82599488e-05, -1.34793387e-04,
        -3.71702777e-06, -2.19616035e-04,  2.41510897e-05,
         0.00000000e+00,  2.77781743e-04, -4.37405276e-08,
         0.00000000e+00, -4.07750667e-05, -1.42445235e-04,
         0.00000000e+00, -5.13868436e-05,  7.76978995e-05,
         0.00000000e+00,  0.00000000e+00,  8.67046037e-05,
         1.21129662e-04,  5.66100680e-05,  1.17494448e-04,
        -1.49413114e-04,  3.41720821e-08, -9.59380259e-07,
        -6.05903733e-05, -7.44576596e-08,  0.00000000e+00],
       [-5.00441529e-04,  0.00000000e+00, -4.31190783e-05,
         2.59324821e-04, -1.19245000e-04, -1.69293053e-04,
        -8.71498469e-06, -2.80217908e-04,  3.60971208e-05,
         0.00000000e+00,  3.96945397e-04,  7.91082812e-07,
         0.00000000e+00, -6.67361237e-05, -2.09465492e-04,
         0.00000000e+00, -7.31755936e-05,  7.74665823e-05,
         0.00000000e+00,  0.00000000e+00,  9.41002654e-05,
         1.27686071e-04,  7.04658232e-05,  1.78630973e-04,
        -2.11366161e-04,  2.55876376e-10, -1.01883938e-06,
        -8.98592334e-05, -2.74069322e-07,  0.00000000e+00],
       [-1.63884238e-06,  9.33728188e-06,  0.00000000e+00,
        -2.44567877e-06, -6.34359139e-07, -1.26799161e-04,
        -6.95130802e-05,  0.00000000e+00,  3.28589595e-05,
         0.00000000e+00,  0.00000000e+00,  1.61615506e-04,
         1.13483999e-04,  1.50779786e-04,  0.00000000e+00,
         1.39498416e-05, -2.92400418e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -2.86155046e-05,
         2.68752803e-04,  0.00000000e+00,  2.64948430e-05,
         0.00000000e+00,  9.93164285e-05, -3.12814627e-05,
        -1.66335267e-05, -1.84387027e-05,  0.00000000e+00],
       [ 5.27022203e-05,  1.92247622e-04,  0.00000000e+00,
        -9.18419828e-05,  4.24794634e-05, -1.00170576e-03,
        -4.80004877e-04,  0.00000000e+00,  2.20229049e-04,
         0.00000000e+00,  0.00000000e+00,  1.13780494e-03,
         8.81759508e-04,  1.14259892e-03,  0.00000000e+00,
         1.04166800e-04, -2.02514610e-04,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -2.13202205e-04,
         2.07438716e-03,  0.00000000e+00,  1.83164855e-04,
         0.00000000e+00,  6.74664741e-04, -1.33870271e-04,
        -1.11883724e-04, -8.78080100e-05,  0.00000000e+00],
       [ 9.04171247e-05,  1.00445148e-04,  7.63492167e-08,
        -9.57988159e-05,  1.49428124e-05, -1.80402538e-04,
        -1.91589032e-04, -3.19452091e-08,  9.75904914e-06,
         0.00000000e+00,  4.80884026e-08,  1.85890894e-04,
         7.17774165e-05,  2.36630789e-04, -3.80715619e-08,
         5.80307733e-06, -3.84205996e-05,  7.94034989e-08,
         0.00000000e+00,  0.00000000e+00, -7.04646154e-05,
         4.08035470e-04, -1.89172980e-08,  6.00644444e-06,
        -4.02486720e-08,  1.06235995e-04, -1.35098424e-04,
        -2.06733748e-05, -4.70770010e-06,  0.00000000e+00],
       [-7.79128575e-04,  0.00000000e+00, -5.15132051e-05,
         3.86474072e-04, -1.91019615e-04, -2.66307237e-04,
        -1.28488109e-05, -3.89966270e-04,  6.38267156e-05,
         0.00000000e+00,  6.24360284e-04,  9.34234095e-07,
        -2.28906174e-07, -8.29533528e-05, -3.41984443e-04,
         0.00000000e+00, -7.49388637e-05,  1.19774384e-04,
         0.00000000e+00,  0.00000000e+00,  1.26100422e-04,
         1.75026114e-04,  1.04860854e-04,  2.92679819e-04,
        -3.23579268e-04,  1.88291978e-07, -1.00375439e-06,
        -1.24283921e-04, -1.02321189e-06,  0.00000000e+00],
       [-3.26649060e-05,  3.76667667e-05, -7.12383708e-09,
         1.42588005e-05,  1.70125459e-05, -3.45341250e-04,
        -8.69221549e-05, -7.00242642e-10,  9.53792623e-05,
         0.00000000e+00,  1.53297677e-08,  3.85490479e-04,
         3.55891738e-04,  3.53370706e-04,  0.00000000e+00,
         4.98096597e-05, -7.16343930e-05, -7.20667215e-09,
         0.00000000e+00,  0.00000000e+00, -4.66962338e-05,
         6.82659331e-04,  0.00000000e+00,  7.16813083e-05,
         0.00000000e+00,  2.33095503e-04,  4.86883509e-05,
        -4.57741335e-05, -2.65757008e-05,  0.00000000e+00],
       [ 1.78120245e-05,  1.96798464e-05,  2.84262455e-06,
        -2.03967102e-05, -7.78735625e-07, -4.09260610e-05,
        -4.34565154e-05, -1.37631935e-06,  3.45511125e-07,
         0.00000000e+00,  3.06842867e-06,  3.76078897e-05,
         1.38774258e-05,  5.58995707e-05, -2.10352596e-06,
        -9.68766244e-07, -6.25015309e-06,  3.08478843e-06,
         0.00000000e+00,  0.00000000e+00, -1.59421070e-05,
         9.02440588e-05,  5.91361982e-07,  3.00191937e-06,
        -3.23767017e-06,  2.22592571e-05, -3.28183014e-05,
        -2.45401623e-07, -1.82786789e-06,  0.00000000e+00],
       [-4.49913459e-05, -1.19675169e-05, -2.61748701e-05,
         3.49259863e-05,  1.09432231e-05, -3.41875275e-05,
         1.41870223e-05, -1.76832473e-05,  2.84930502e-05,
         0.00000000e+00,  1.95110351e-05,  4.02151163e-05,
         6.41820588e-05, -2.88644515e-07, -4.80870176e-06,
         1.35302998e-05, -2.77557192e-05, -1.13963688e-05,
         0.00000000e+00,  0.00000000e+00,  3.05595859e-06,
         7.28173254e-05,  2.22555798e-07,  2.72866419e-05,
        -4.85088640e-06,  3.09414827e-05,  4.18623131e-05,
        -1.37655761e-05,  1.86045486e-06,  0.00000000e+00],
       [ 4.19208809e-05,  7.29247840e-05,  0.00000000e+00,
        -4.79202754e-05,  1.28802021e-05, -3.35318677e-04,
        -2.04345066e-04,  0.00000000e+00,  6.71333473e-05,
         0.00000000e+00,  0.00000000e+00,  3.85969906e-04,
         2.63614231e-04,  4.05219413e-04,  0.00000000e+00,
         3.08187809e-05, -7.87884419e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -8.55570761e-05,
         7.13911955e-04,  0.00000000e+00,  5.77480350e-05,
         0.00000000e+00,  2.32388833e-04, -1.14624840e-04,
        -3.46927372e-05, -3.36084231e-05,  0.00000000e+00],
       [-2.91687262e-04,  0.00000000e+00, -1.28303304e-06,
         1.45054568e-04, -7.44448917e-05, -1.14189163e-04,
        -2.30305363e-06, -1.56554437e-04,  2.09914033e-05,
         0.00000000e+00,  2.25928437e-04, -3.02540059e-07,
         2.50925098e-07, -2.07975936e-05, -1.22527403e-04,
         0.00000000e+00, -2.65240851e-05,  6.30217110e-05,
         0.00000000e+00,  0.00000000e+00,  5.95863457e-05,
         8.85746849e-05,  4.37948765e-05,  9.95219307e-05,
        -1.22592508e-04,  1.31104258e-07, -7.16017894e-07,
        -4.45228179e-05, -2.12941316e-07,  0.00000000e+00],
       [ 6.31865987e-06,  5.42956332e-05,  0.00000000e+00,
        -2.69342054e-05,  1.59751798e-05, -2.69641954e-04,
        -1.18517077e-04,  0.00000000e+00,  6.09728304e-05,
         0.00000000e+00,  0.00000000e+00,  3.03890469e-04,
         2.46285868e-04,  2.98862869e-04,  0.00000000e+00,
         2.78883745e-05, -4.26290571e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -5.25980213e-05,
         5.47818374e-04,  0.00000000e+00,  4.95301465e-05,
         0.00000000e+00,  1.75082721e-04,  8.18272383e-07,
        -3.49755428e-05, -1.65624751e-05,  0.00000000e+00],
       [ 1.25278762e-04,  1.90336403e-04,  0.00000000e+00,
        -1.36246526e-04,  2.80008971e-05, -6.47969777e-04,
        -4.14760085e-04,  0.00000000e+00,  1.12029331e-04,
         0.00000000e+00,  0.00000000e+00,  7.13802350e-04,
         4.86080884e-04,  7.74658751e-04,  0.00000000e+00,
         5.59267464e-05, -1.42561825e-04,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -1.73328037e-04,
         1.38948904e-03,  0.00000000e+00,  9.16477657e-05,
         0.00000000e+00,  4.22360143e-04, -2.21273367e-04,
        -6.21329964e-05, -5.46966512e-05,  0.00000000e+00],
       [-2.76920706e-04,  0.00000000e+00, -8.00024936e-05,
         1.49084837e-04, -5.01053510e-05, -5.14127059e-05,
        -1.08842742e-05, -1.57927643e-04,  2.47573244e-05,
         0.00000000e+00,  2.33120751e-04,  8.41650433e-07,
         0.00000000e+00, -7.50966501e-05, -1.16269381e-04,
         0.00000000e+00, -6.91922905e-05, -5.08887661e-06,
         0.00000000e+00,  0.00000000e+00,  3.27567614e-05,
         2.68725325e-05,  3.34181350e-05,  1.17805997e-04,
        -1.11690875e-04,  0.00000000e+00, -5.77417381e-07,
        -6.15975368e-05, -2.72013665e-07,  0.00000000e+00],
       [-4.37419767e-05,  5.14870917e-05, -1.38331245e-07,
         2.13357907e-05,  1.74212164e-05, -4.20603988e-04,
        -6.35994365e-05, -1.41421204e-08,  1.17942931e-04,
         0.00000000e+00,  1.74552468e-07,  4.46096004e-04,
         4.55407891e-04,  4.02053818e-04,  0.00000000e+00,
         6.77588978e-05, -8.18726621e-05, -9.74069678e-08,
         0.00000000e+00,  0.00000000e+00, -4.69740735e-05,
         8.26893258e-04,  0.00000000e+00,  8.34840248e-05,
         0.00000000e+00,  2.72024510e-04,  1.09227651e-04,
        -4.55794871e-05, -3.75769414e-05,  0.00000000e+00],
       [ 6.44798856e-05,  7.35587018e-05,  0.00000000e+00,
        -6.48704372e-05,  1.25042598e-05, -2.71748257e-04,
        -2.26843695e-04,  0.00000000e+00,  4.04472667e-05,
         0.00000000e+00,  0.00000000e+00,  3.25458735e-04,
         1.74765330e-04,  3.65232700e-04,  0.00000000e+00,
         1.04409219e-05, -6.33564341e-05,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00, -8.88333525e-05,
         5.94261684e-04,  0.00000000e+00,  4.78890870e-05,
         0.00000000e+00,  1.90764258e-04, -1.68709143e-04,
        -2.68940385e-05, -2.49563873e-05,  0.00000000e+00],
       [-7.33354711e-04,  0.00000000e+00, -1.18333461e-04,
         4.02258069e-04, -1.34361457e-04, -1.87081518e-04,
        -2.03259970e-05, -4.52287146e-04,  7.49411920e-05,
         0.00000000e+00,  5.80569205e-04,  6.07104312e-07,
         0.00000000e+00, -1.63533216e-04, -2.87706993e-04,
         0.00000000e+00, -1.56974536e-04,  9.49087407e-05,
         0.00000000e+00,  0.00000000e+00,  1.59126532e-04,
         1.70826621e-04,  9.97107200e-05,  2.57898617e-04,
        -2.74724793e-04,  0.00000000e+00, -3.15183661e-06,
        -1.41979341e-04,  3.01554996e-06,  0.00000000e+00],
       [-1.47691666e-04,  6.67535804e-09, -6.90731249e-05,
         9.50017784e-05, -9.98212272e-06, -9.13831457e-07,
        -9.55482028e-06, -1.06954147e-04,  1.93760461e-05,
         0.00000000e+00,  1.25818478e-04,  2.04303376e-07,
         1.79041368e-08, -7.45448197e-05, -5.34159371e-05,
        -2.56720067e-09, -6.59493380e-05, -1.11951804e-05,
         0.00000000e+00,  0.00000000e+00,  2.77680538e-05,
         5.12911765e-06,  1.64669727e-05,  6.05494388e-05,
        -4.74908484e-05,  2.72590839e-09, -8.77777552e-07,
        -4.17438860e-05,  1.30466958e-06,  0.00000000e+00],
       [-8.44956521e-05,  2.78225599e-07, -2.89106065e-05,
         6.39283826e-05, -2.80969584e-06, -9.68598943e-06,
        -3.69155691e-06, -9.27529982e-05,  7.17037074e-06,
         0.00000000e+00,  6.02014952e-05,  2.06708833e-07,
         0.00000000e+00, -4.63685537e-05, -1.64245721e-05,
         0.00000000e+00, -5.09722086e-05,  1.69544583e-05,
         0.00000000e+00,  0.00000000e+00,  4.30355103e-05,
         3.76587450e-05,  1.52235034e-05,  1.52291477e-05,
        -2.34876807e-05, -3.37884742e-08, -1.00962166e-06,
        -2.60327979e-05,  1.44195292e-06,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([ 2.08965976e-05,  8.02328577e-06,  0.00000000e+00, -3.24981011e-05,
        3.02531771e-06, -1.62286029e-04, -1.51867658e-04,  0.00000000e+00,
        3.82342914e-05,  0.00000000e+00,  0.00000000e+00,  2.09075151e-04,
        1.01745638e-04,  2.29693178e-04,  0.00000000e+00, -1.05295356e-07,
       -2.34282088e-05,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
       -4.97080291e-05,  3.43020918e-04,  0.00000000e+00,  3.77041106e-05,
        0.00000000e+00,  1.32554269e-04, -1.14602895e-04, -2.40510999e-05,
       -5.63379808e-06,  0.00000000e+00,  2.18319736e-04,  0.00000000e+00,
        6.19347338e-05, -1.15611707e-04,  3.88306544e-05,  3.40163024e-05,
        7.71085161e-06,  1.18876975e-04, -2.71884946e-05,  0.00000000e+00,
       -1.91858373e-04, -1.31052190e-07,  0.00000000e+00,  6.16536345e-05,
        1.02454738e-04,  0.00000000e+00,  4.61575546e-05,  5.07989671e-06,
        0.00000000e+00,  0.00000000e+00, -2.16519620e-05, -5.15413694e-06,
       -1.45406375e-05, -9.45684951e-05,  8.55719773e-05,  0.00000000e+00,
        8.98048313e-07,  4.75471352e-05, -4.10497876e-07,  0.00000000e+00],
      dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[ 3.15066951e-04,  1.21113495e-04, -1.00462319e-04, ...,
         1.70997489e-04, -1.02987637e-04, -1.17517615e-04],
       [ 9.96330436e-06,  7.61230012e-06, -3.79329163e-06, ...,
         5.52859683e-06, -2.97500742e-06, -4.63576498e-06],
       [ 2.23136885e-04,  2.96809139e-05, -3.22979540e-05, ...,
         6.86072090e-05, -9.64661831e-06, -3.47206842e-05],
       ...,
       [ 1.15973887e-03,  5.80371416e-04, -1.80375588e-04, ...,
         3.47966910e-04, -1.01875732e-04, -4.78745438e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 1.05965312e-03,  5.30467485e-04, -1.64982674e-04, ...,
         3.18347273e-04, -9.33666161e-05, -4.37425915e-04]], dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[ 0.0000000e+00, -3.8773866e-05,  3.6104815e-04, ...,
         0.0000000e+00,  1.5447814e-08,  4.9186783e-06],
       [ 0.0000000e+00, -9.5050115e-07,  1.6129427e-05, ...,
         0.0000000e+00, -8.7817398e-10, -9.0532076e-08],
       [ 0.0000000e+00, -1.3141212e-05,  1.3369411e-04, ...,
         0.0000000e+00,  5.2297651e-09, -2.9205808e-07],
       ...,
       [ 0.0000000e+00, -6.8572517e-05,  1.3357371e-03, ...,
         0.0000000e+00,  5.4862846e-07,  8.6534928e-06],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00, -6.2731044e-05,  1.2209562e-03, ...,
         0.0000000e+00,  5.0115057e-07,  7.9116517e-06]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([ 1.2715221e-04,  8.4276093e-05, -3.9433697e-05,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00, -4.2908323e-05, -8.2960192e-05,
        6.4636261e-05, -3.9014476e-06,  8.3470240e-06,  1.4337295e-04,
        6.3043677e-05,  0.0000000e+00,  0.0000000e+00,  1.3582653e-06,
       -1.5711316e-04, -1.5645267e-07,  2.9257650e-05, -5.1740193e-05,
        0.0000000e+00, -9.9150391e-05,  0.0000000e+00,  0.0000000e+00,
        1.7535462e-04,  1.5142634e-06,  0.0000000e+00,  8.4586849e-05,
       -4.3199387e-05, -5.2074312e-05,  0.0000000e+00,  1.6165499e-05,
       -2.0233968e-04, -1.0492009e-04,  7.0532522e-05,  1.2307867e-04,
       -3.6481728e-05, -1.5037702e-04, -1.9679128e-05, -3.1616571e-06,
        6.5672633e-05,  1.6256178e-07,  7.5197129e-08, -1.8827026e-04,
       -6.2920204e-05, -3.6718309e-05,  6.4723508e-08, -7.4505792e-06,
       -6.2147396e-05, -3.8125374e-05, -1.7562404e-04,  2.7130452e-06,
       -5.1870855e-05,  1.4062566e-04,  0.0000000e+00,  7.5367614e-05,
        3.3073418e-05,  0.0000000e+00, -4.5295238e-08, -1.5102548e-06],
      dtype=float32)>]
[Actor] Episode 0 Step 0 Loss: 0.7838887572288513
Y Pred
tf.Tensor(
[[[-0.93455464 -0.09153514 -0.626893   ... -0.22612369 -1.1001152
   -0.45443022]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]

 [[-0.80231506  0.36288393 -0.28306526 ...  0.10152648 -1.3063331
   -1.0194316 ]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]

 [[-0.2169865   0.52406895  0.5057043  ... -0.6877716  -1.1597282
   -1.5417168 ]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]

 ...

 [[-0.3516879   0.41202274  0.10575035 ...  0.22472665 -0.8489367
   -0.6567102 ]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]

 [[-0.13546887  0.26567373 -0.02103345 ...  0.23316915 -0.41803062
   -0.33253002]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]

 [[-0.97469133  0.3977434  -0.28537846 ...  0.24998344 -1.3355985
   -0.95959574]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  ...
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]
  [ 0.03996284  0.00292142  0.02461121 ...  0.00316564 -0.00624834
   -0.03713499]]], shape=(1125, 350, 12), dtype=float32)
omega
tf.Tensor(
[[0.]
 [0.]
 [0.]
 ...
 [0.]
 [0.]
 [0.]], shape=(1125, 1), dtype=float32)
mu
tf.Tensor(
[[0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]
 [0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]
 [0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]
 ...
 [0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]
 [0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]
 [0.49952608 0.07044471 0.47703323 ... 0.49236965 0.09949996 0.49885964]], shape=(1125, 12), dtype=float32)
mean
tf.Tensor(
[[ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]
 [ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]
 [ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]
 ...
 [ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]
 [ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]
 [ 0.06655901  0.14857088  0.08771461 ... -0.04749795  0.08427627
   0.02294761]], shape=(1125, 12), dtype=float32)
grads
[<tf.Tensor: shape=(6, 30), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(30, 60), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,
        0.,  0.,  0., nan, nan,  0.,  0., nan,  0.,  0., nan,  0.,  0.,
        0.,  0.,  0.,  0.], dtype=float32)>, <tf.Tensor: shape=(30, 25), dtype=float32, numpy=
array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.8190804e-05,  1.9102496e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.9038327e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.4661911e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -3.3472723e-05,
         8.2446068e-06, -2.2288252e-05,  0.0000000e+00,  0.0000000e+00,
         2.5567100e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         3.7499958e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.5097092e-05,  1.5853733e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.5800466e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.0467643e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.7780010e-05,
         6.8424397e-06, -1.8497674e-05,  0.0000000e+00,  0.0000000e+00,
         2.1218868e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         3.1122338e-05],
       [ 2.6024677e-06,  2.7329006e-06,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.7237195e-06,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  3.5282624e-06,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -4.7887770e-06,
         1.1795154e-06, -3.1886691e-06,  0.0000000e+00,  0.0000000e+00,
         3.6577587e-06,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         5.3649333e-06],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 2.4602519e-05,  2.5835554e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.5748741e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  3.3354470e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -4.5270845e-05,
         1.1150572e-05, -3.0144181e-05,  0.0000000e+00,  0.0000000e+00,
         3.4578683e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         5.0717557e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.7128950e-05,  1.7987408e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.7926983e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.3222341e-05,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -3.1518823e-05,
         7.7633485e-06, -2.0987207e-05,  0.0000000e+00,  0.0000000e+00,
         2.4074656e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         3.5310935e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(25,), dtype=float32, numpy=
array([ 0.00253286,  0.0026598 ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        , -0.00265087,  0.        ,  0.        ,
        0.        ,  0.00343389,  0.        ,  0.        ,  0.        ,
       -0.00466069,  0.00114797, -0.00310338,  0.        ,  0.        ,
        0.00355992,  0.        ,  0.        ,  0.        ,  0.00522144],
      dtype=float32)>, <tf.Tensor: shape=(25, 12), dtype=float32, numpy=
array([[-1.4381476e-06, -8.9688518e-05, -6.9695023e-05,  4.6549816e-05,
        -3.0959971e-05,  3.7918362e-05, -7.8031095e-05,  5.8083708e-05,
         5.0230046e-05, -2.3155075e-05, -1.5174177e-06, -3.4605275e-06],
       [-6.9008998e-08, -4.3036730e-06, -3.3442882e-06,  2.2336746e-06,
        -1.4856038e-06,  1.8194983e-06, -3.7442978e-06,  2.7871254e-06,
         2.4102737e-06, -1.1110874e-06, -7.2812739e-08, -1.6605213e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-1.5081636e-05, -9.4055024e-04, -7.3088182e-04,  4.8816041e-04,
        -3.2467319e-04,  3.9764465e-04, -8.1830064e-04,  6.0911506e-04,
         5.2675582e-04, -2.4282369e-04, -1.5912918e-05, -3.6290035e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-5.9501167e-07, -3.7107220e-05, -2.8835202e-05,  1.9259256e-05,
        -1.2809211e-05,  1.5688129e-05, -3.2284184e-05,  2.4031213e-05,
         2.0781925e-05, -9.5800478e-06, -6.2780725e-07, -1.4317400e-06],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-1.1537821e-05, -7.1954250e-04, -5.5914151e-04,  3.7345459e-04,
        -2.4838239e-04,  3.0420744e-04, -6.2601932e-04,  4.6598745e-04,
         4.0298008e-04, -1.8576581e-04, -1.2173754e-05, -2.7762742e-05],
       [-1.1659262e-05, -7.2711741e-04, -5.6502677e-04,  3.7738559e-04,
        -2.5099673e-04,  3.0740938e-04, -6.3260866e-04,  4.7089256e-04,
         4.0722213e-04, -1.8772113e-04, -1.2301903e-05, -2.8054965e-05],
       [-2.4790759e-05, -1.5460493e-03, -1.2014003e-03,  8.0242392e-04,
        -5.3368730e-04,  6.5363583e-04, -1.3450988e-03,  1.0012446e-03,
         8.6586503e-04, -3.9914661e-04, -2.6157160e-05, -5.9652455e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-2.7169261e-07, -1.6943806e-05, -1.3166669e-05,  8.7941116e-06,
        -5.8489122e-06,  7.1634790e-06, -1.4741501e-05,  1.0973067e-05,
         9.4893749e-06, -4.3744180e-06, -2.8666787e-07, -6.5375696e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-1.6539743e-05, -1.0314845e-03, -8.0154394e-04,  5.3535693e-04,
        -3.5606290e-04,  4.3608871e-04, -8.9741586e-04,  6.6800520e-04,
         5.7768280e-04, -2.6630022e-04, -1.7451395e-05, -3.9798600e-05]],
      dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=
array([-7.8986064e-05, -4.9258806e-03, -3.8277954e-03,  2.5566118e-03,
       -1.7003883e-03,  2.0825560e-03, -4.2856331e-03,  3.1900776e-03,
        2.7587423e-03, -1.2717246e-03, -8.3339692e-05, -1.9005936e-04],
      dtype=float32)>, <tf.Tensor: shape=(30, 25), dtype=float32, numpy=
array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.5722224e-05,  0.0000000e+00, -8.9162364e-05, -3.1842154e-07,
        -2.2135780e-05,  9.2120106e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  3.6370897e-05,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.5541979e-05,
         5.0786137e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.3048335e-05,  0.0000000e+00, -7.3998446e-05, -2.6426727e-07,
        -1.8371131e-05,  7.6453187e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  3.0185269e-05,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -4.6095913e-05,
         4.2148899e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 2.2493009e-06,  0.0000000e+00, -1.2756016e-05, -4.5554977e-08,
        -3.1668560e-06,  1.3179167e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  5.2034038e-06,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -7.9461161e-06,
         7.2657203e-06,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 2.1263821e-05,  0.0000000e+00, -1.2058929e-04, -4.3065498e-07,
        -2.9937943e-05,  1.2458955e-04,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  4.9190501e-05,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -7.5118805e-05,
         6.8686655e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 1.4804460e-05,  0.0000000e+00, -8.3957617e-05, -2.9983400e-07,
        -2.0843634e-05,  8.6742737e-05,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  3.4247794e-05,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.2299794e-05,
         4.7821562e-05,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(25,), dtype=float32, numpy=
array([ 2.1891380e-03,  0.0000000e+00, -1.2414826e-02, -4.4336502e-05,
       -3.0821520e-03,  1.2826658e-02,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  5.0642267e-03,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -7.7335788e-03,
        7.0713814e-03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00], dtype=float32)>, <tf.Tensor: shape=(25, 12), dtype=float32, numpy=
array([[ 2.9901986e-04, -7.6059412e-05,  2.5610780e-04,  5.4222743e-05,
        -3.0619913e-04,  8.8997454e-05,  6.3869760e-05, -7.7929333e-05,
         5.1100171e-05, -4.1541196e-05, -2.4395876e-04,  2.2048942e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 9.4236028e-05, -2.3970109e-05,  8.0712322e-05,  1.7088285e-05,
        -9.6498588e-05,  2.8047532e-05,  2.0128540e-05, -2.4559413e-05,
         1.6104210e-05, -1.3091699e-05, -7.6883531e-05,  6.9487196e-06],
       [ 1.0782703e-05, -2.7427145e-06,  9.2352884e-06,  1.9552810e-06,
        -1.1041592e-05,  3.2092626e-06,  2.3031544e-06, -2.8101440e-06,
         1.8426807e-06, -1.4979826e-06, -8.7971903e-06,  7.9508834e-07],
       [ 6.4908127e-05, -1.6510190e-05,  5.5593238e-05,  1.1770110e-05,
        -6.6466542e-05,  1.9318648e-05,  1.3864187e-05, -1.6916098e-05,
         1.1092297e-05, -9.0173344e-06, -5.2956035e-05,  4.7861568e-06],
       [ 5.5166148e-04, -1.4032196e-04,  4.7249315e-04,  1.0003551e-04,
        -5.6490663e-04,  1.6419137e-04,  1.1783330e-04, -1.4377179e-04,
         9.4274685e-05, -7.6639335e-05, -4.5007930e-04,  4.0678089e-05],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 3.3889159e-05, -8.6201271e-06,  2.9025756e-05,  6.1452874e-06,
        -3.4702822e-05,  1.0086452e-05,  7.2386260e-06, -8.8320539e-06,
         5.7913940e-06, -4.7080357e-06, -2.7648857e-05,  2.4988981e-06],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 1.8614966e-04, -4.7349484e-05,  1.5943548e-04,  3.3755434e-05,
        -1.9061903e-04,  5.5403834e-05,  3.9761020e-05, -4.8513564e-05,
         3.1811534e-05, -2.5860758e-05, -1.5187231e-04,  1.3726190e-05],
       [ 1.3398035e-05, -3.4079565e-06,  1.1475297e-05,  2.4295314e-06,
        -1.3719717e-05,  3.9876650e-06,  2.8617815e-06, -3.4917412e-06,
         2.2896206e-06, -1.8613162e-06, -1.0930939e-05,  9.8793612e-07],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],
      dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=
array([ 0.01690556, -0.00430014,  0.01447946,  0.00306557, -0.01731145,
        0.00503161,  0.00361098, -0.00440586,  0.00288903, -0.0023486 ,
       -0.01379259,  0.00124657], dtype=float32)>, <tf.Tensor: shape=(30, 1), dtype=float32, numpy=
array([[0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.],
       [0.]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Tensor: shape=(34, 40), dtype=float32, numpy=
array([[-1.8294717e-05, -1.8726946e-06,  6.2249501e-07, ...,
        -1.3067343e-07,  2.2323636e-07,  1.2091827e-05],
       [-8.6581022e-06, -1.1357905e-06,  8.0972950e-06, ...,
         6.0820116e-07,  4.7380743e-07, -2.6405309e-05],
       [ 1.7926710e-05,  1.3513870e-06, -2.6639986e-05, ...,
        -2.8576235e-07,  3.3013962e-06,  4.1029140e-05],
       ...,
       [-3.3548736e-04, -1.4424762e-04,  1.6384492e-04, ...,
         1.9290268e-05,  8.0163973e-06, -6.6887558e-04],
       [-4.7306993e-04, -8.5877080e-05,  1.7222136e-04, ...,
         1.8921239e-05, -2.2056685e-05, -2.8990814e-04],
       [ 1.8011972e-03,  1.5244925e-04, -3.9264993e-04, ...,
        -9.7475786e-06,  3.9379498e-05, -3.4367078e-04]], dtype=float32)>, <tf.Tensor: shape=(40,), dtype=float32, numpy=
array([ 1.98182737e-04,  2.40596437e-05, -4.97990623e-05, -1.76503846e-07,
        6.78367360e-05,  4.87277503e-05,  1.84495582e-06, -3.72047589e-06,
        1.82058614e-06,  4.59491366e-06, -3.12226848e-06, -1.21530629e-05,
       -1.21574987e-04,  3.15962825e-05, -6.19529674e-05,  2.26731936e-05,
       -4.90392413e-05, -6.18869599e-05, -3.84249506e-05,  1.17638374e-05,
       -6.37539733e-06, -1.08381146e-05,  5.74984224e-05, -6.70548106e-05,
       -3.71945316e-05, -1.84024611e-05, -1.30624494e-05,  1.35187802e-04,
       -3.52111965e-05,  1.34497286e-05, -1.53756391e-05, -8.75972401e-05,
        9.50236972e-06, -1.05305320e-04,  8.39326822e-05,  1.27734961e-06,
       -1.40671855e-05,  9.20888283e-07, -5.87751219e-06, -1.83067950e-05],
      dtype=float32)>, <tf.Tensor: shape=(40, 80), dtype=float32, numpy=
array([[ 8.14607774e-05,  6.66802953e-05, -2.07875655e-05, ...,
         1.43118598e-07, -2.33769315e-05,  1.68899976e-04],
       [ 3.69673103e-06,  1.60180025e-06,  3.38685481e-07, ...,
         2.04146602e-07,  2.90211847e-06, -6.22664516e-08],
       [ 5.46926458e-05,  4.76272799e-05, -6.48584819e-06, ...,
         4.65549874e-08, -4.21629829e-06,  6.72921669e-05],
       ...,
       [-1.02827153e-05,  2.40441432e-06, -9.82791062e-06, ...,
         9.77264989e-08, -1.59408091e-06,  8.25785901e-06],
       [ 1.90110526e-07, -7.60302919e-06, -5.33791251e-07, ...,
        -5.26122903e-07, -7.43286677e-08,  1.16550495e-07],
       [ 5.52945494e-05,  8.03021248e-05, -1.92486868e-06, ...,
         0.00000000e+00, -3.38271684e-06,  1.18057062e-04]], dtype=float32)>, <tf.Tensor: shape=(80,), dtype=float32, numpy=
array([ 3.57764766e-05,  1.39437025e-05, -1.21900612e-05, -1.29213135e-04,
       -2.46152626e-06, -2.06465847e-05,  1.93239219e-04, -2.74595932e-05,
       -9.85918887e-05, -4.76554524e-05, -1.05511332e-04,  6.87154579e-06,
       -1.18115549e-05,  2.22705626e-06, -5.86780443e-05,  5.92594843e-05,
        5.66735871e-05,  6.47559282e-05, -3.13500568e-05, -2.00111263e-05,
        1.35293332e-04,  3.16749502e-05,  1.36351737e-04,  5.69022886e-05,
       -1.28305919e-06,  1.21480894e-04, -2.99967451e-06, -4.85778328e-05,
       -5.74377873e-06,  8.23377832e-06,  1.37276540e-04,  6.41533188e-06,
        9.42694896e-05, -9.91718916e-05, -2.27107332e-04,  1.82140211e-04,
       -3.93733571e-05, -7.07877698e-05,  6.74192488e-05,  1.29298896e-05,
        2.64663981e-06,  1.25688427e-06, -1.63933328e-05, -1.32288196e-05,
       -1.16458450e-05, -1.05014478e-05, -3.13719793e-05,  4.76067981e-07,
       -5.32513659e-05, -7.74037253e-05, -5.31661353e-05, -2.01521834e-05,
       -1.18472817e-04,  4.68243707e-06, -1.63074830e-04,  3.04872242e-06,
        6.34773387e-05, -1.28771467e-06, -8.19863635e-06, -5.58826241e-06,
        9.46113869e-05, -1.09324239e-04,  2.18542627e-05,  1.24701296e-06,
       -3.44961772e-05, -4.91521450e-06,  1.76380883e-04, -2.21912269e-05,
        2.10680901e-06, -8.65574693e-05, -1.35705413e-05,  5.84512491e-05,
       -9.96662711e-05,  3.24965476e-05,  6.20348055e-06, -5.31780461e-06,
        1.77482743e-05, -2.47149785e-08, -1.09750245e-05,  8.05623713e-05],
      dtype=float32)>, <tf.Tensor: shape=(80, 30), dtype=float32, numpy=
array([[-1.1212875e-04,  4.0449504e-05, -4.6368168e-06, ...,
         3.1403956e-04,  4.6856887e-05,  5.9369893e-07],
       [ 1.2873508e-05,  4.9274918e-06, -1.8834644e-05, ...,
         7.4899690e-05,  3.0458925e-05, -1.7852772e-06],
       [-1.5276488e-06, -3.4552428e-07, -3.9301567e-06, ...,
         5.2947271e-06,  6.7408860e-06, -2.2795011e-07],
       ...,
       [ 4.7549321e-08, -1.4063692e-08,  9.3430039e-08, ...,
        -5.2088112e-08, -3.6859660e-08, -8.1047808e-08],
       [-1.1530731e-06,  1.9584561e-05, -4.9133709e-05, ...,
         8.6130174e-05,  4.5722838e-05,  1.8309961e-06],
       [-3.6380781e-05,  1.9711506e-05, -3.4393510e-05, ...,
         9.5535645e-05,  3.5339268e-05, -1.4360218e-08]], dtype=float32)>, <tf.Tensor: shape=(30,), dtype=float32, numpy=
array([-1.93889660e-04,  1.87504884e-05,  2.89414311e-04, -1.91836443e-04,
        1.42920879e-04,  4.22848534e-05, -2.03756339e-04, -2.39772731e-07,
       -6.00584826e-05,  1.27842777e-05, -2.20878748e-04, -1.43496582e-04,
       -1.69577361e-05,  1.01801146e-04, -1.31938781e-04, -6.51232840e-05,
        5.61828892e-06,  3.25481233e-04,  1.38740397e-05,  2.29867917e-04,
        2.47106818e-05, -6.67524728e-05,  8.14577797e-05, -1.91861000e-06,
       -2.42009992e-04, -5.10073914e-05, -5.61462039e-05,  2.18916655e-04,
       -5.08768644e-05, -7.01970112e-06], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[-6.68685752e-05, -7.49397295e-05, -7.51729885e-07,
        -3.69244335e-05, -2.17236584e-06, -3.32775526e-05,
        -3.92732982e-05,  4.49611543e-05,  1.59574265e-05,
         2.93958456e-05, -1.20919925e-04, -1.23194104e-05,
         1.33253332e-06,  3.03007746e-05, -7.72431595e-05,
         2.40605114e-05, -2.26902666e-05, -9.93142476e-06,
        -1.35046270e-04,  7.20500102e-05,  4.98068721e-06,
        -4.75704983e-05,  5.05858261e-05,  2.65599538e-05,
        -1.16556639e-05,  5.27161683e-05,  3.74868505e-05,
         1.92109965e-05, -1.70165731e-06, -4.72024931e-06],
       [-1.37014649e-06,  1.51577951e-05,  3.74327533e-06,
         1.97457957e-05, -8.04191473e-07,  4.88591286e-06,
         5.04005493e-06,  3.08281742e-05,  1.65185270e-06,
        -1.75453970e-05,  9.46118089e-05, -5.14988733e-06,
         6.62580396e-06, -2.08652327e-05,  4.50641164e-05,
         1.91768777e-05,  4.19532353e-06,  2.12730411e-05,
         1.00893645e-04, -7.27071747e-05, -3.03673005e-05,
        -9.15867895e-06, -1.13007036e-05,  2.22303825e-05,
         3.65452593e-06,  1.03502944e-05,  1.82985241e-05,
        -1.07638402e-06, -1.14765044e-07,  6.99105658e-06],
       [ 3.23613790e-07,  7.46043440e-07, -5.49920628e-07,
         8.30032093e-07,  2.50385824e-07,  4.25639882e-07,
        -1.03086677e-07, -5.60606509e-07,  1.70987562e-08,
        -4.28142712e-08,  9.90825924e-07,  1.52328141e-07,
        -1.11183489e-07, -5.39218831e-07,  3.84003556e-07,
        -4.67550308e-07, -5.99747096e-09,  3.88715250e-07,
         5.56611099e-07, -5.45456658e-07, -1.03519248e-07,
         3.17374088e-07, -2.28273933e-08, -4.79071559e-07,
        -8.02352460e-08, -3.68582562e-07, -3.41437044e-07,
        -2.96741263e-07, -2.08653091e-07,  7.40967394e-08],
       [-6.29598275e-04, -7.21617544e-04, -2.48169781e-05,
        -2.58527172e-04,  3.02423655e-06, -3.70582886e-04,
        -4.79075476e-04,  5.00627444e-04,  1.77271868e-04,
         3.28682538e-04, -1.29964505e-03, -1.42387464e-04,
         3.13345527e-06,  2.45893752e-04, -8.40833702e-04,
         2.62334856e-04, -2.74791644e-04, -9.08468428e-05,
        -1.39393925e-03,  6.31771924e-04,  3.31070260e-05,
        -5.19784866e-04,  5.45005081e-04,  2.69664743e-04,
        -1.36986913e-04,  5.83124172e-04,  3.14605713e-04,
         1.93133368e-04, -1.23530888e-04, -8.57610721e-05],
       [-4.70025634e-06, -5.50738969e-06,  5.95806000e-07,
         3.50500295e-06,  1.13893793e-06, -3.73501371e-06,
        -6.52036897e-06,  5.77631499e-06, -1.42273962e-07,
         4.40841313e-06,  7.26079270e-06, -8.82588438e-07,
        -2.03506352e-06, -7.69798589e-07, -3.88160925e-06,
         1.98262524e-06, -2.91998708e-06,  4.83303529e-06,
         3.65285814e-06, -1.22985366e-05,  2.80520089e-06,
        -6.41089036e-06,  8.66273513e-06, -4.66546453e-07,
        -2.18064019e-06,  5.88688636e-06,  1.20706204e-06,
        -1.88529839e-07, -7.51401240e-06, -1.37657889e-06],
       [ 5.97040125e-05,  1.34770584e-04,  2.00896568e-04,
         1.09678098e-04,  5.21264010e-05,  1.08328160e-04,
         3.29951690e-05,  4.22660050e-05, -2.39629935e-05,
        -2.46447686e-04,  8.10308673e-04,  1.79900762e-05,
         1.44700651e-04, -2.12420011e-04,  3.94264353e-04,
         1.30669941e-05,  6.70193622e-05,  2.45113159e-04,
         8.98784143e-04, -4.76164074e-04, -3.35260411e-04,
         3.54529911e-05, -7.85747616e-05,  1.05873245e-04,
         1.35108145e-04, -2.89646414e-05,  8.26905380e-05,
        -1.91100162e-06,  1.01491103e-04,  1.09331253e-04],
       [-1.53609042e-04, -1.19105534e-04,  1.61999546e-04,
         4.55294794e-05,  5.31985243e-05, -3.19445535e-05,
        -1.78448783e-04,  1.76612186e-04,  2.95109785e-05,
        -8.16390966e-05,  3.10779229e-04, -1.59674964e-05,
         1.26091865e-04, -1.26472121e-04,  5.09197998e-05,
         8.90784358e-05, -4.48812061e-05,  2.14000494e-04,
         3.33542528e-04, -2.21150724e-04, -2.80476263e-04,
        -1.35272712e-04,  1.60573749e-04,  1.53534289e-04,
         6.56390621e-05,  1.64848330e-04,  1.39243726e-04,
         8.05172094e-05,  3.27448288e-05,  6.68664143e-05],
       [-3.29021859e-05, -2.43231480e-05, -3.95925917e-06,
        -2.88636711e-05, -6.11259475e-06, -1.51114709e-05,
        -6.91570176e-06,  2.93419944e-05,  1.20518625e-05,
         8.59919328e-06, -5.70413249e-05, -9.31452723e-06,
        -3.75592606e-07,  1.86762099e-05, -2.56652293e-05,
         1.26707428e-05, -7.40651149e-06, -1.44521082e-05,
        -5.27099364e-05,  3.24495450e-05, -5.02612465e-07,
        -2.20484289e-05,  5.39145685e-06,  2.42521237e-05,
        -6.93696575e-06,  2.47872067e-05,  3.02423705e-05,
         8.31464422e-06,  6.83419557e-07,  1.97939329e-07],
       [-1.32040339e-04, -5.73791694e-05, -4.80208255e-05,
        -2.26608299e-05, -2.34692834e-05, -7.23267149e-05,
        -7.04709746e-05,  3.78909499e-05,  4.20674914e-05,
         5.44047434e-05, -1.84946766e-04, -1.92290263e-05,
        -7.60520152e-06,  4.27656123e-05, -1.11203888e-04,
         1.06538591e-05, -4.78513466e-05, -3.23616550e-05,
        -2.27944372e-04,  8.44500755e-05,  4.23039528e-05,
        -6.93137918e-05,  7.77091191e-05,  3.62572719e-05,
        -3.14197205e-05,  8.70609656e-05,  5.71470482e-05,
         4.80933704e-05, -4.28158637e-05, -4.07071013e-07],
       [-5.95118877e-07, -4.32446910e-07,  3.56663207e-07,
        -5.68586074e-07, -5.18356501e-07, -4.90905620e-07,
         7.57447708e-07,  9.61769501e-07,  1.14121974e-07,
        -2.04260033e-07, -5.04826176e-07, -5.19132414e-07,
         6.77575684e-08,  7.24097958e-07, -3.13954530e-07,
         7.31337821e-07,  8.18058012e-08, -2.04457592e-07,
        -9.86562782e-07,  3.80674095e-07,  2.95936331e-07,
        -4.59665358e-07, -4.30493458e-07,  1.06437551e-06,
         4.05293328e-08,  5.00748399e-07,  8.54846064e-07,
         1.59342761e-07,  3.37156678e-07,  4.90980838e-08],
       [-4.39463719e-08, -3.58687746e-09, -1.92080503e-08,
        -2.42084397e-08, -4.20870876e-08, -6.33309849e-09,
         8.17507217e-09,  3.28855521e-09,  3.18937019e-08,
         3.68437476e-08, -6.95724633e-09, -6.96816782e-09,
         2.63049560e-09, -2.11568434e-08, -1.40540735e-09,
        -1.44606735e-08, -1.09965992e-09,  1.24602231e-08,
        -1.58465383e-08,  2.92371194e-09,  1.69501639e-08,
         2.40607267e-09,  2.70753535e-08, -1.07141780e-07,
        -2.16899121e-09, -1.32261178e-07,  1.33007703e-08,
         2.25810073e-08, -1.15704395e-07, -9.29095023e-08],
       [-1.93000567e-04, -2.84740992e-04,  1.05541825e-04,
        -1.26518818e-04,  4.37441995e-05, -1.00299192e-04,
        -1.52092631e-04,  3.10216856e-04,  3.42574785e-05,
         4.24116297e-06, -2.14868080e-04, -7.85104421e-05,
         7.73222491e-05,  3.55277298e-05, -1.77835274e-04,
         2.09336678e-04, -7.06185820e-05,  5.31842816e-05,
        -1.65810372e-04,  6.34932658e-05, -1.95279747e-04,
        -2.20487564e-04,  1.76487301e-04,  2.26815624e-04,
         2.95667633e-06,  2.51392485e-04,  2.16094253e-04,
         5.80994238e-05,  4.29438733e-05,  4.82921678e-06],
       [ 6.81637524e-10,  2.28494486e-08, -1.03400710e-08,
         1.56944537e-08,  3.50525564e-09,  2.48205523e-09,
        -2.56375421e-10, -4.71604622e-09,  5.51749271e-11,
         5.95662852e-10,  3.45311761e-08,  8.48007997e-10,
        -1.06585372e-08, -8.45047854e-09,  1.83926279e-08,
        -2.58534261e-09,  8.48516757e-10,  9.90218663e-09,
         4.38418866e-08, -3.61774184e-08, -4.28782387e-09,
         1.35374272e-08,  5.50837598e-09, -1.49218131e-08,
        -2.64577915e-09, -2.63090327e-09, -9.56825286e-09,
        -4.05187217e-09, -1.09313936e-08, -9.26017985e-10],
       [-5.68270370e-05, -7.30727425e-06, -3.18115926e-05,
         2.00140494e-05, -1.44078731e-05, -2.52411210e-05,
        -5.39481553e-05, -2.06996119e-05,  1.79511444e-05,
         3.10278774e-05, -2.98449868e-05,  7.43896499e-06,
        -4.19833259e-06,  5.97339010e-07, -4.32958877e-05,
        -2.89906729e-05, -2.68818221e-05, -3.76298999e-07,
        -7.45557700e-05,  1.68177776e-05,  3.32864438e-05,
        -1.16337242e-05,  5.38545683e-05, -1.64728044e-05,
        -1.36601093e-05,  2.16825993e-05, -1.68777424e-05,
         3.39851649e-05, -3.25900728e-05,  1.43064995e-06],
       [ 5.43544900e-07,  7.27228155e-07, -2.40273351e-07,
         9.19838897e-07,  1.70295550e-07,  4.36846932e-07,
        -1.06559206e-12, -3.48711694e-07, -1.52913586e-07,
        -1.82692560e-07,  1.12393286e-06,  1.99166308e-07,
        -5.54791022e-08, -6.43294698e-07,  6.27259112e-07,
        -1.80285852e-07,  6.20170795e-08,  4.10348292e-07,
         8.46483545e-07, -6.58408624e-07, -1.06213591e-07,
         3.97203110e-07, -1.02348494e-07, -4.02742899e-07,
         9.98572318e-08, -3.19998492e-07, -3.27892081e-07,
        -3.39551207e-07, -7.21513729e-08,  3.14154853e-08],
       [-2.55148689e-06, -2.12401847e-06,  1.22086692e-06,
        -2.96848202e-06, -1.49048810e-06, -2.23109896e-06,
         2.45306910e-06,  3.38116752e-06,  1.05018535e-06,
        -4.70252246e-07, -2.58506020e-06, -1.96631891e-06,
         4.33175813e-07,  2.64395908e-06, -1.37475274e-06,
         2.93802555e-06,  5.04432762e-07, -1.02386286e-06,
        -3.08070867e-06,  1.75862795e-06,  1.04222306e-06,
        -1.57618285e-06, -9.64524247e-07,  4.08457481e-06,
        -3.10115951e-08,  1.69050134e-06,  2.40993359e-06,
         1.10962981e-06,  1.06486641e-06, -3.37174697e-08],
       [-4.63029661e-04, -6.32949348e-04,  7.36694928e-05,
        -2.54720158e-04,  4.23012971e-05, -2.97869992e-04,
        -3.30234034e-04,  6.24096778e-04,  1.10894092e-04,
         1.90783045e-04, -9.06842237e-04, -1.80105562e-04,
         4.50778025e-05,  1.86003948e-04, -6.07886002e-04,
         4.43664670e-04, -1.92216350e-04, -1.19057804e-05,
        -8.80190171e-04,  3.21602682e-04, -1.41069933e-04,
        -4.78156842e-04,  4.00043820e-04,  3.76797660e-04,
        -7.90588820e-05,  5.53769991e-04,  4.09330794e-04,
         1.17010364e-04, -2.91722718e-05, -6.14057644e-05],
       [-1.47123821e-04, -9.69800458e-05, -3.11095828e-05,
         4.98541067e-06, -1.33569174e-05, -6.71245434e-05,
        -1.41025885e-04,  7.11009852e-06,  4.59647999e-05,
         7.84834338e-05, -1.44900798e-04,  9.41090912e-06,
         8.45882823e-07,  1.24609451e-05, -1.38510615e-04,
        -5.44018949e-05, -6.80142402e-05,  9.10470135e-06,
        -2.21778464e-04,  9.60848120e-05,  3.02678945e-05,
        -8.20013229e-05,  1.38709351e-04, -8.13440965e-06,
        -2.93108315e-05,  8.28855991e-05, -3.02225089e-08,
         6.99121520e-05, -6.50162401e-05, -5.37062988e-07],
       [-2.47110031e-04, -3.31885763e-04,  5.22413029e-06,
        -1.50677894e-04,  1.57264567e-05, -1.60854135e-04,
        -1.74167741e-04,  2.57356849e-04,  5.88336516e-05,
         1.20137141e-04, -6.32717856e-04, -8.40104331e-05,
         3.84012901e-06,  1.31937035e-04, -3.79061676e-04,
         1.81404816e-04, -1.07261469e-04, -6.46222979e-05,
        -6.47153181e-04,  3.06619157e-04, -2.38093207e-06,
        -2.20982489e-04,  2.22427683e-04,  1.60070122e-04,
        -5.32561498e-05,  2.62615475e-04,  1.68773273e-04,
         6.44701067e-05, -1.64956127e-05, -4.66896745e-05],
       [-1.09182220e-05, -5.17832405e-06,  1.98983059e-07,
        -4.95828954e-06, -5.97335111e-06, -8.99840779e-06,
         4.51899768e-06,  5.00194210e-06,  4.13754924e-06,
         1.01526371e-06, -1.04802084e-05, -5.66093604e-06,
         4.32203592e-07,  7.10194035e-06, -6.30618933e-06,
         2.90137336e-06, -1.02025956e-06, -2.30190335e-06,
        -1.49151056e-05,  4.58495697e-06,  7.09483629e-06,
        -6.05946161e-06,  5.42849534e-08,  9.53461858e-06,
        -1.87156928e-07,  6.34266326e-06,  5.28300052e-06,
         3.59524529e-06, -3.06234574e-06, -2.92081154e-07],
       [-4.51310007e-05, -1.05114595e-05,  1.56572874e-04,
         3.98111079e-05,  3.42778803e-05,  2.42659953e-05,
        -1.52280154e-05,  2.13014398e-04,  1.06598382e-05,
        -1.54728521e-04,  5.19258436e-04, -3.41030900e-05,
         1.23016463e-04, -1.41210359e-04,  2.42882670e-04,
         1.46682185e-04,  2.41618836e-05,  2.08132420e-04,
         6.20992621e-04, -3.71375936e-04, -3.26047186e-04,
        -8.40890934e-05, -1.66336758e-05,  1.95782151e-04,
         9.25490385e-05,  1.06599924e-04,  1.91010564e-04,
         1.76278918e-05,  7.48797611e-05,  8.48557756e-05],
       [ 5.16949804e-05,  7.73074571e-05,  1.59573945e-04,
         6.79975274e-05,  5.19625683e-05,  8.35745886e-05,
         2.46488507e-05,  3.39476064e-05, -2.15870277e-05,
        -1.88229722e-04,  5.28629927e-04,  9.48973138e-06,
         1.06347565e-04, -1.41511031e-04,  2.54981278e-04,
         2.14999600e-05,  4.86759709e-05,  1.57045899e-04,
         5.97090344e-04, -3.03793233e-04, -2.45334755e-04,
         3.06014299e-05, -5.25587857e-05,  8.08080149e-05,
         9.71442496e-05, -2.04786211e-05,  5.25638170e-05,
        -9.10507515e-06,  9.87506428e-05,  6.59430443e-05],
       [-1.05642334e-06, -6.69775261e-07,  3.85762718e-07,
        -9.99372901e-07, -6.99336852e-07, -8.40055520e-07,
         8.84718531e-07,  1.07668529e-06,  3.53515929e-07,
        -1.76100968e-07, -9.11418169e-07, -7.02251896e-07,
         7.84353489e-08,  9.86075747e-07, -3.92183068e-07,
         8.99612303e-07,  1.12592716e-07, -3.11926158e-07,
        -1.22950121e-06,  6.01992383e-07,  4.59788453e-07,
        -5.31067769e-07, -4.15826577e-07,  1.43306715e-06,
         9.19413026e-08,  6.44775810e-07,  9.85456268e-07,
         3.95912707e-07,  4.07490234e-07,  1.10091982e-07],
       [-5.80237480e-04, -5.48298645e-04,  3.10873467e-04,
        -1.15027855e-04,  9.06014247e-05, -2.38070643e-04,
        -4.85650613e-04,  6.10058021e-04,  1.41527795e-04,
        -4.21929872e-05, -6.98636286e-05, -1.28801868e-04,
         2.48631608e-04, -7.69588514e-05, -2.84702110e-04,
         3.27846996e-04, -1.96868001e-04,  3.11788986e-04,
        -2.46674754e-05, -1.19791192e-04, -5.15509862e-04,
        -5.01704577e-04,  4.88723628e-04,  4.74259403e-04,
         6.87166175e-05,  5.89016767e-04,  4.75336186e-04,
         2.25325770e-04,  2.84483249e-05,  8.96660567e-05],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [-5.99410996e-05,  1.90969149e-05,  2.76554347e-04,
         1.03281112e-04,  8.57329796e-05,  5.20595349e-05,
        -9.49967216e-05,  1.85570476e-04, -4.12277586e-06,
        -2.57680251e-04,  8.74379301e-04, -1.14196482e-05,
         2.04798780e-04, -2.45483971e-04,  3.39041522e-04,
         1.18212978e-04,  2.05923425e-05,  3.41185660e-04,
         9.62073158e-04, -5.70663949e-04, -4.64739191e-04,
        -7.04864433e-05,  6.09543204e-05,  2.13942199e-04,
         1.50907668e-04,  1.06834967e-04,  1.78631963e-04,
         5.81991953e-05,  1.06371597e-04,  1.27122912e-04],
       [-9.91064189e-06, -3.52410498e-05,  3.99196579e-05,
        -2.53057315e-05,  1.23480486e-05, -1.54190002e-05,
         5.72955105e-06,  9.70376859e-05, -2.35070559e-07,
        -1.39158146e-05, -7.96982204e-06, -2.97273564e-05,
         1.56502356e-05,  4.76604328e-06, -1.76386093e-05,
         9.10071612e-05,  9.95999017e-07,  2.11404840e-05,
         3.23111599e-05, -4.36200098e-05, -5.07336590e-05,
        -3.70688940e-05, -3.05722551e-06,  6.16369507e-05,
         7.89054138e-06,  4.77421490e-05,  6.50332295e-05,
        -2.84929183e-06,  2.12579034e-05, -4.18925993e-07],
       [-2.02667696e-04, -2.04752418e-04,  6.91540299e-06,
        -4.40536969e-05,  3.24867642e-07, -9.85311708e-05,
        -1.68523067e-04,  1.52028428e-04,  5.43432543e-05,
         8.71913071e-05, -2.47073651e-04, -2.61935929e-05,
         1.55770649e-05,  3.39312173e-05, -1.92589854e-04,
         4.96009889e-05, -8.48563068e-05,  2.28986828e-05,
        -2.86513939e-04,  1.08681488e-04, -3.03646266e-05,
        -1.65804857e-04,  1.78733229e-04,  7.66382436e-05,
        -2.84996713e-05,  1.76337911e-04,  1.01214595e-04,
         6.74267649e-05, -5.20492504e-05, -4.43086356e-06],
       [-3.62513529e-04, -3.33260832e-04,  4.12235931e-05,
        -2.41827365e-05,  1.26565046e-05, -1.77216629e-04,
        -2.90407275e-04,  3.71014350e-04,  9.88907705e-05,
         1.10897869e-04, -1.84963748e-04, -7.67606180e-05,
         5.04861855e-05,  8.69152427e-06, -2.39314133e-04,
         1.91544968e-04, -1.41725061e-04,  1.17945856e-04,
        -2.24594725e-04, -4.72474785e-05, -1.46150545e-04,
        -3.26974870e-04,  3.03625158e-04,  2.08320387e-04,
        -3.68278452e-05,  3.67602595e-04,  2.53235456e-04,
         1.14437309e-04, -9.34258424e-05,  6.30652357e-06],
       [ 1.76364465e-05,  5.33001730e-05,  4.60146657e-05,
         3.08452363e-05,  3.91172671e-06,  3.16304613e-05,
         1.30184153e-05,  2.61031437e-05, -5.21745733e-06,
        -7.10384120e-05,  2.98045663e-04,  7.11834764e-06,
         4.95329186e-05, -7.64986253e-05,  1.54894675e-04,
         9.42674524e-06,  2.33915689e-05,  8.95699341e-05,
         3.30879004e-04, -1.61415534e-04, -1.34108268e-04,
        -1.25302995e-06, -3.71752940e-05,  4.97686415e-05,
         3.76291355e-05, -6.92612366e-06,  4.31314947e-05,
         7.80143182e-06,  3.16847618e-05,  4.72294123e-05]], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[ 1.70987078e-05,  3.15719117e-05,  1.62036958e-05,
         4.29763713e-05,  8.08054665e-06,  1.72041509e-05,
         5.27178645e-06,  6.42587452e-07, -5.71506007e-06,
        -3.10788892e-05,  1.16103918e-04,  4.03572722e-06,
         1.14595341e-05, -3.87306864e-05,  6.43636013e-05,
         1.66060158e-06,  1.01174264e-05,  3.57947429e-05,
         1.27519423e-04, -7.66306257e-05, -3.75130185e-05,
         1.14259656e-05, -1.08136210e-05,  7.87378758e-06,
         1.57274371e-05, -7.23673202e-06, -2.33185148e-07,
        -7.01164754e-06,  6.36492086e-06,  1.09301955e-05],
       [ 4.58605027e-05,  1.03907361e-04, -1.72051259e-05,
         5.54101607e-05, -1.16913934e-05,  3.19366591e-05,
         2.86349314e-05, -6.42491868e-05, -9.24226060e-06,
        -2.90619992e-05,  1.79984927e-04,  2.05582983e-05,
        -6.83957023e-06, -3.71603383e-05,  9.36695287e-05,
        -5.73726866e-05,  1.77598376e-05,  1.49652906e-05,
         1.67858932e-04, -1.02714737e-04,  1.71186894e-05,
         5.18956658e-05, -4.73513901e-05, -4.02014812e-05,
         3.53368932e-06, -5.54205835e-05, -4.40846597e-05,
        -8.26836367e-06, -1.95098219e-05,  1.32249133e-05],
       [ 6.18334866e-07,  5.76107823e-07, -5.94591114e-08,
         7.69697124e-07,  3.33408764e-07,  5.13345412e-07,
        -3.93719290e-07, -6.20991727e-07, -3.21601590e-07,
        -7.23435676e-08,  7.34232742e-07,  3.85680551e-07,
        -1.68752692e-08, -5.49189565e-07,  2.70266639e-07,
        -6.04417437e-07, -1.00350988e-07,  2.58301640e-07,
         5.68701125e-07, -2.10945274e-07, -6.65676936e-08,
         3.21292731e-07,  5.81065649e-08, -8.57586713e-07,
         2.65497953e-08, -3.19762250e-07, -3.11212972e-07,
        -2.27023207e-07, -3.87705654e-08,  2.85982011e-08],
       [ 1.35124108e-04,  2.88907526e-04,  2.62269372e-04,
         2.44421390e-04,  6.64632025e-05,  1.86125093e-04,
         6.49823050e-05,  1.82111071e-05, -5.28988967e-05,
        -3.65898421e-04,  1.42344215e-03,  4.74086773e-05,
         1.90840146e-04, -3.49761336e-04,  6.70507841e-04,
        -3.33107528e-06,  1.09395529e-04,  3.87543172e-04,
         1.51466811e-03, -8.53983918e-04, -4.66616475e-04,
         9.54668358e-05, -1.40721648e-04,  1.08936903e-04,
         1.84212331e-04, -8.53051097e-05,  7.31749315e-05,
        -1.38668347e-05,  1.18735130e-04,  1.62037977e-04],
       [ 2.74643594e-06,  1.62925044e-05, -4.74390799e-06,
         1.32285841e-05, -3.01722071e-06,  5.78997970e-06,
         4.22092228e-07, -2.07743687e-05, -7.73020332e-08,
        -3.75258651e-06,  4.56190683e-05,  6.93362199e-06,
         2.46993181e-06, -1.06998559e-05,  2.33813371e-05,
        -1.72502641e-05,  2.95351856e-06,  8.55121652e-06,
         3.66511813e-05, -2.05053730e-05,  6.18073045e-07,
         9.08389120e-06, -2.48828178e-06, -1.09465018e-05,
         2.81188022e-06, -1.10019482e-05, -1.02846025e-05,
         3.47425862e-06, -3.63774393e-06,  5.27298016e-06],
       [ 4.41097887e-04,  4.43250989e-04,  5.67977222e-05,
         1.50974869e-04,  2.29528705e-05,  2.56604835e-04,
         3.38414131e-04, -2.70395132e-04, -1.26801984e-04,
        -2.45656120e-04,  8.40227760e-04,  7.22487966e-05,
         1.19119304e-05, -1.59694420e-04,  5.52281272e-04,
        -9.21044193e-05,  1.94760039e-04,  6.76481795e-05,
         9.47731780e-04, -4.38669667e-04, -6.60400910e-05,
         3.40557192e-04, -3.72885930e-04, -1.41548924e-04,
         1.08204491e-04, -3.67406174e-04, -1.75937923e-04,
        -1.49878848e-04,  1.26367348e-04,  4.60063929e-05],
       [ 4.28526197e-04,  4.87519952e-04,  1.49190542e-04,
         1.69167208e-04,  2.52772661e-05,  2.87997944e-04,
         3.34920653e-04, -2.26837088e-04, -1.19261764e-04,
        -3.45982611e-04,  1.24506443e-03,  8.51379373e-05,
         8.82210297e-05, -2.58871703e-04,  7.59204035e-04,
        -1.25806779e-04,  2.15360458e-04,  1.95017870e-04,
         1.39385322e-03, -6.39411504e-04, -2.56918138e-04,
         3.04795190e-04, -4.08371736e-04, -5.85017769e-05,
         1.59825839e-04, -3.55702767e-04, -9.98511678e-05,
        -1.29739579e-04,  1.48595704e-04,  1.20661745e-04],
       [ 9.37952973e-06,  1.40239663e-05,  1.27627354e-05,
         2.80634904e-05,  7.01023282e-06,  6.76723084e-06,
         1.05490687e-06, -1.50911103e-06, -3.81993641e-06,
        -1.17270947e-05,  4.46508202e-05,  2.03839977e-06,
         1.02724891e-06, -1.70008771e-05,  1.92306106e-05,
         2.74110675e-06,  3.51805966e-06,  1.83133252e-05,
         4.51688429e-05, -4.06898071e-05, -3.04805803e-06,
         8.08510140e-06, -3.86281442e-08, -4.57829674e-06,
         6.87960528e-06, -3.06311995e-06, -3.67199868e-06,
        -7.37922028e-06, -4.17109322e-06,  7.32972069e-07],
       [ 3.25611763e-05,  1.90750252e-05,  8.84669935e-05,
         1.40266211e-05,  3.08989402e-05,  3.21700390e-05,
         6.77994149e-06,  8.82886070e-06, -1.40386173e-05,
        -6.51892915e-05,  1.59359741e-04,  2.69370071e-06,
         3.92802322e-05, -4.30869113e-05,  6.98985532e-05,
         1.25519236e-05,  1.85364897e-05,  6.49275316e-05,
         1.97280737e-04, -1.05168911e-04, -7.06667925e-05,
         1.80232710e-05, -5.82580196e-06,  1.78886767e-05,
         4.06786348e-05, -1.04642122e-05,  1.67046292e-05,
        -7.02437728e-06,  3.89805064e-05,  1.66233931e-05],
       [ 1.31011817e-07,  4.41787506e-07, -2.10463597e-07,
         5.24479617e-07,  2.42680898e-07,  1.85006613e-07,
        -5.63735938e-08, -1.78893018e-07, -6.74812117e-09,
        -2.77493282e-08,  8.72329053e-07,  7.91443142e-08,
        -9.74691901e-08, -3.51757279e-07,  2.78516609e-07,
        -1.04724364e-07,  2.65184301e-08,  2.86652210e-07,
         1.20731886e-06, -8.82083100e-07, -3.23243000e-07,
         2.86305834e-07,  1.03477909e-07, -4.38867204e-07,
        -4.28986091e-08, -1.62389142e-07, -2.73361792e-07,
        -1.68643240e-07, -1.48186956e-07, -1.02159767e-07],
       [ 4.47548345e-08,  7.64669927e-09,  1.64659220e-08,
         8.26179036e-09,  5.41826388e-08,  4.25204902e-08,
        -7.42952899e-09, -4.38095693e-09, -1.97657606e-08,
        -1.97862597e-08, -4.14718082e-09,  8.88560958e-09,
         1.17308219e-09, -7.73580666e-09, -1.26295827e-08,
         3.14175175e-09, -6.68955447e-10,  1.16765184e-08,
         2.60175064e-08,  8.65814584e-08, -4.73027804e-08,
        -8.57984794e-09,  6.51973986e-09, -1.42325849e-08,
         1.08215703e-08, -8.52739301e-09, -1.28147875e-08,
         1.11798366e-08,  1.76501125e-08, -1.63626996e-08],
       [ 2.13157124e-04,  3.81825375e-04,  8.02071954e-05,
         1.79089533e-04, -1.71809625e-05,  1.73626206e-04,
         1.83655749e-04, -1.25869905e-04, -5.45624316e-05,
        -2.21072434e-04,  1.03931269e-03,  6.14133896e-05,
         6.19585189e-05, -2.10257946e-04,  5.65715716e-04,
        -9.25839340e-05,  1.27715612e-04,  1.88531412e-04,
         1.11119938e-03, -6.08353759e-04, -1.69873456e-04,
         1.81390933e-04, -2.50875950e-04, -3.54195727e-05,
         1.03222243e-04, -1.98191527e-04, -3.13654127e-05,
        -4.29095635e-05,  4.94218402e-05,  1.07123087e-04],
       [ 4.12550794e-09,  2.15768914e-08, -2.39376963e-08,
         1.84084410e-08,  1.06688534e-08,  1.01473310e-08,
        -2.67376574e-08, -4.85526250e-08,  1.80384951e-09,
         9.78696502e-09,  1.44569983e-08,  1.65278102e-08,
        -6.35155972e-09, -1.66572143e-08,  2.13881926e-08,
        -4.13342320e-08, -3.98779187e-09,  5.98040906e-09,
         2.80099428e-08, -1.17515802e-08,  2.26197616e-09,
         2.37883420e-08,  1.59076468e-08, -3.83595768e-08,
        -1.44413237e-09, -1.28537057e-08, -3.28126717e-08,
        -9.37306677e-10, -1.61824296e-08,  6.35242703e-09],
       [ 1.37828283e-05, -4.08033156e-06,  4.74446933e-05,
        -2.16759508e-05,  1.35831888e-05,  1.41567743e-05,
         7.60641660e-06,  1.05817808e-05, -5.49442348e-06,
        -3.65996675e-05,  4.03760241e-05, -9.23090283e-07,
         2.57168413e-05, -1.44854221e-05,  3.22358028e-05,
         5.90117997e-06,  1.19392280e-05,  2.45293850e-05,
         7.32125773e-05,  5.03132682e-08, -5.81679160e-05,
         1.23890700e-07, -9.04875014e-06,  2.79002270e-05,
         2.11164061e-05, -3.61619050e-06,  2.13524854e-05,
        -2.32642856e-06,  3.53632131e-05,  1.59971678e-05],
       [ 7.24093866e-07,  7.43603266e-07, -1.82053952e-07,
         8.16439183e-07,  1.09668242e-07,  5.98158010e-07,
        -8.95480667e-08, -5.72291128e-07, -2.97736733e-07,
        -9.68621450e-08,  9.65625645e-07,  3.88630070e-07,
        -8.83735041e-08, -4.50964080e-07,  6.35959282e-07,
        -5.33706157e-07, -6.34410640e-08,  2.58682661e-07,
         7.59534657e-07, -5.00846340e-07, -8.29684197e-08,
         4.40417381e-07, -1.33550373e-07, -7.26181725e-07,
         5.85062843e-08, -4.11002958e-07, -3.06450431e-07,
        -3.25916005e-07, -1.31260677e-07,  7.31332435e-08],
       [ 1.58082548e-06,  2.42475971e-06, -9.17359444e-07,
         2.69972566e-06,  1.30256808e-06,  1.51124186e-06,
        -4.16601154e-07, -1.13915962e-06, -3.85098673e-07,
        -4.80255267e-07,  3.97248459e-06,  5.10063785e-07,
        -3.26077270e-07, -2.05459764e-06,  1.27035617e-06,
        -7.04862259e-07,  1.75878881e-07,  1.13512624e-06,
         4.25964845e-06, -2.92208438e-06, -1.01674038e-06,
         1.30824276e-06, -1.21811539e-08, -2.10812050e-06,
        -2.45992510e-07, -8.97765517e-07, -1.27965427e-06,
        -1.22587153e-06, -2.64358562e-07, -2.82580885e-07],
       [ 1.88963138e-04,  5.65590861e-04,  1.13915798e-04,
         3.80244543e-04, -3.11314361e-05,  2.29527359e-04,
         1.34262664e-04, -2.23004143e-04, -4.51030137e-05,
        -3.04739719e-04,  1.82269979e-03,  1.22350582e-04,
         1.14261667e-04, -3.82130529e-04,  8.60361848e-04,
        -2.23531999e-04,  1.32905174e-04,  3.90618428e-04,
         1.80007506e-03, -1.09095103e-03, -2.52693833e-04,
         2.20565998e-04, -2.37936416e-04, -9.47085719e-05,
         1.43532132e-04, -2.41895847e-04, -6.49742433e-05,
         1.48323124e-07, -2.20477596e-05,  1.80812858e-04],
       [ 4.35862894e-05,  1.31484394e-05,  9.64070423e-05,
        -2.14324173e-05,  3.16937439e-05,  4.83375770e-05,
         3.59460100e-05,  2.84597736e-05, -1.80227908e-05,
        -1.12200403e-04,  2.08776124e-04, -1.39577674e-06,
         6.84246188e-05, -5.97121216e-05,  1.31820270e-04,
         2.59329972e-05,  3.77507458e-05,  6.52509261e-05,
         2.79511209e-04, -8.11584905e-05, -1.61992968e-04,
         1.54268291e-05, -5.03396623e-05,  6.98537915e-05,
         6.13286466e-05, -1.95290577e-05,  4.52764543e-05,
        -1.12628650e-05,  8.55089747e-05,  4.17049487e-05],
       [ 4.52573004e-05,  1.26896368e-04,  1.02123908e-04,
         1.23183330e-04,  1.85889949e-05,  6.09527597e-05,
         1.84980327e-05,  1.97201971e-05, -1.66923401e-05,
        -1.20228979e-04,  5.81012457e-04,  1.63690947e-05,
         6.72696260e-05, -1.44766062e-04,  2.65167968e-04,
         6.80159656e-06,  3.87870714e-05,  1.79247232e-04,
         6.20611128e-04, -3.82122060e-04, -1.64810466e-04,
         2.65362269e-05, -4.44134348e-05,  3.36996382e-05,
         7.10785316e-05, -2.11823772e-05,  3.90636342e-05,
         1.49057223e-06,  2.02222855e-05,  6.57762430e-05],
       [ 2.57069405e-06,  4.73611090e-06,  1.32508831e-07,
         4.58212162e-06,  3.80634037e-06,  4.90403727e-06,
        -3.45389367e-07, -1.78654625e-06, -4.97890710e-07,
        -3.34042306e-06,  1.09954253e-05,  1.21882999e-06,
         1.50561743e-06, -4.08686265e-06,  3.77689389e-06,
        -1.52374673e-06,  7.98160329e-07,  3.65715346e-06,
         1.37768693e-05, -7.11015537e-06, -5.46772708e-06,
         3.46908200e-06,  3.00045429e-07, -3.95301686e-06,
        -2.02627803e-07, -2.18141736e-06, -1.76643846e-06,
        -2.24572045e-06,  3.72431532e-06, -2.40680009e-08],
       [ 3.84322746e-04,  5.91072370e-04,  6.27518057e-06,
         2.78246356e-04, -2.56129988e-05,  2.55990715e-04,
         3.12922581e-04, -3.47824913e-04, -9.25546483e-05,
        -2.49207282e-04,  1.21784571e-03,  1.05728694e-04,
         4.49346498e-06, -2.33217346e-04,  6.96218864e-04,
        -2.13623745e-04,  1.80207047e-04,  1.36066054e-04,
         1.24445604e-03, -6.85576117e-04, -3.03454181e-05,
         3.50979477e-04, -3.83500563e-04, -1.92626510e-04,
         9.47137596e-05, -3.83843813e-04, -1.96968758e-04,
        -1.12816109e-04,  2.45746833e-05,  8.51615696e-05],
       [ 3.29399161e-04,  2.78839056e-04,  6.01359970e-05,
         1.00736630e-04,  3.75408927e-05,  1.75775131e-04,
         2.33767074e-04, -1.48032108e-04, -1.05770436e-04,
        -1.75196285e-04,  5.45239192e-04,  3.94453491e-05,
         1.04590081e-05, -1.11044872e-04,  3.52670904e-04,
        -7.76460001e-06,  1.38293690e-04,  5.00268652e-05,
         6.34343887e-04, -2.92564771e-04, -7.12865804e-05,
         2.31630795e-04, -2.51501711e-04, -7.73818392e-05,
         7.87682002e-05, -2.44694704e-04, -1.15962095e-04,
        -1.14845454e-04,  1.10650581e-04,  2.06298573e-05],
       [ 4.73353566e-07,  7.29563510e-07, -3.53363021e-07,
         9.80503614e-07,  4.38153961e-07,  5.49577351e-07,
        -1.97715636e-07, -3.92268788e-07, -6.93991780e-08,
        -2.93577500e-08,  1.33011622e-06,  2.47765087e-07,
        -6.21201579e-08, -6.48402306e-07,  3.69882684e-07,
        -3.62793543e-07, -8.15615131e-09,  3.86050033e-07,
         1.44039973e-06, -1.10283554e-06, -4.09320648e-07,
         4.42336216e-07,  8.97614498e-08, -8.08548975e-07,
        -7.98644280e-08, -3.69644965e-07, -5.31302589e-07,
        -3.74880017e-07, -2.26837571e-07, -1.88286876e-07],
       [ 8.56015831e-04,  1.01373135e-03,  4.23943013e-04,
         4.08415624e-04,  8.95199555e-05,  6.24714419e-04,
         6.47774024e-04, -4.04472055e-04, -2.50037789e-04,
        -7.98235065e-04,  2.93155410e-03,  1.71900669e-04,
         2.43252391e-04, -6.12513919e-04,  1.66658615e-03,
        -1.92205509e-04,  4.53874032e-04,  5.35581436e-04,
         3.25351837e-03, -1.60840270e-03, -6.38988393e-04,
         6.28747279e-04, -7.92064762e-04, -8.60115688e-05,
         3.80578509e-04, -6.95053604e-04, -1.59273346e-04,
        -2.47887481e-04,  3.46447807e-04,  2.76038976e-04],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
       [ 6.42004656e-04,  7.30611093e-04,  1.42540172e-04,
         2.24097894e-04,  1.40662632e-05,  4.10420675e-04,
         5.06748154e-04, -4.03382175e-04, -1.73777371e-04,
        -4.33216890e-04,  1.62357674e-03,  1.26732310e-04,
         6.57496930e-05, -3.07860842e-04,  1.01739576e-03,
        -2.20528585e-04,  3.11047654e-04,  1.93463886e-04,
         1.81652606e-03, -8.30057077e-04, -2.04802229e-04,
         4.87136800e-04, -5.95336955e-04, -1.72604152e-04,
         1.87843820e-04, -5.56687999e-04, -2.14453466e-04,
        -1.95215500e-04,  1.78811257e-04,  1.38091506e-04],
       [ 3.63471845e-05,  1.06340362e-04, -1.78703667e-05,
         6.78337892e-05, -1.58886651e-05,  3.64868174e-05,
         2.24713003e-05, -7.85823067e-05, -6.49852109e-06,
        -1.64385237e-05,  2.67320342e-04,  3.10488322e-05,
        -9.13169151e-06, -4.49243962e-05,  1.22041449e-04,
        -6.83148464e-05,  1.99278729e-05,  4.09283093e-05,
         2.37729750e-04, -1.58184106e-04,  2.60931211e-05,
         5.18779307e-05, -3.61776365e-05, -6.55668700e-05,
         2.42980877e-06, -6.06509420e-05, -4.58786126e-05,
        -4.41290831e-06, -3.38559876e-05,  1.84282435e-05],
       [ 1.03491620e-04,  1.86764053e-04,  7.72283747e-05,
         1.12766444e-04,  1.42723511e-05,  1.01842743e-04,
         7.22663681e-05, -6.41351580e-05, -2.44356233e-05,
        -1.64322817e-04,  6.15115860e-04,  3.03735542e-05,
         6.77776843e-05, -1.50652922e-04,  3.30532086e-04,
        -4.42408345e-05,  6.78903161e-05,  1.31681765e-04,
         6.60646707e-04, -3.54251300e-04, -1.58052921e-04,
         9.38019075e-05, -1.12766968e-04,  7.68852988e-06,
         8.17718828e-05, -9.39353558e-05, -1.92078805e-05,
        -1.59743668e-05,  4.75412562e-05,  6.68668144e-05],
       [ 3.00901796e-04,  6.34109310e-04,  8.83897592e-05,
         3.62161547e-04, -1.83498887e-05,  2.82101537e-04,
         2.05043179e-04, -3.47980851e-04, -6.78852230e-05,
        -3.51308961e-04,  1.72135141e-03,  1.39328651e-04,
         1.05333616e-04, -3.78518365e-04,  8.92172742e-04,
        -2.92632409e-04,  1.70684594e-04,  3.04231799e-04,
         1.72916439e-03, -9.54172225e-04, -2.27562181e-04,
         3.20077030e-04, -3.23070912e-04, -1.41744735e-04,
         1.55498084e-04, -3.51277820e-04, -1.67328588e-04,
        -3.43749853e-05,  2.49549048e-05,  1.69478910e-04],
       [ 1.24139639e-04,  1.92011983e-04, -4.76823925e-06,
         4.27642044e-05, -1.99234964e-05,  7.75432418e-05,
         1.30962260e-04, -1.02854821e-04, -2.53814669e-05,
        -8.09913981e-05,  3.13809171e-04,  2.62723206e-05,
        -3.98783595e-06, -4.77746980e-05,  2.18565227e-04,
        -7.23374105e-05,  6.44012907e-05,  8.20522746e-06,
         3.48953065e-04, -1.59680858e-04, -1.26452278e-06,
         1.05043451e-04, -1.60279495e-04, -4.41609154e-05,
         2.42831265e-05, -1.24436076e-04, -3.66269123e-05,
        -4.37383751e-05,  1.31616926e-05,  2.97746119e-05]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([ 0.01170685,  0.00458155, -0.00239658,  0.01544786,  0.00309806,
        0.0113676 , -0.01014322, -0.01188595, -0.01294842,  0.01025681,
        0.02070685,  0.0160959 , -0.00275815, -0.00800323,  0.00666449,
       -0.01568286, -0.00464144,  0.00825904,  0.00441161,  0.0026695 ,
       -0.01005093, -0.00023652,  0.01067565, -0.01903039, -0.00262969,
       -0.0021872 , -0.00185012, -0.00661124, -0.00617512,  0.00835917,
       -0.01200343, -0.00480167,  0.00197158, -0.01496425, -0.00334417,
       -0.01137652,  0.00997445,  0.01230738,  0.01294721, -0.01082354,
       -0.02061875, -0.01615401,  0.00246368,  0.00804036, -0.00663775,
        0.01589285,  0.00416689, -0.00814394, -0.00395465, -0.00279272,
        0.00971982,  0.00062015, -0.0103669 ,  0.0196825 ,  0.00265596,
        0.00231611,  0.00159099,  0.0070291 ,  0.00654852, -0.0079623 ],
      dtype=float32)>, <tf.Tensor: shape=(30, 45), dtype=float32, numpy=
array([[ 4.68546757e-04,  1.41394878e-04,  1.28880405e-04, ...,
         8.52487792e-05,  5.21017500e-06, -4.44294601e-05],
       [-4.36509465e-04, -1.25675244e-04, -9.26651919e-05, ...,
        -8.08872574e-05, -1.21968405e-05,  5.74749320e-05],
       [-6.16559293e-04, -2.04584619e-04, -2.37143695e-06, ...,
        -2.51154299e-04, -1.83095253e-05,  9.20615348e-05],
       ...,
       [ 3.24708119e-04,  8.55263206e-05,  3.01643649e-06, ...,
         9.09145019e-05,  7.04631839e-06, -5.04412274e-05],
       [-6.09195849e-05, -4.94684537e-06, -2.90610260e-05, ...,
         3.30337680e-05,  3.86795909e-06, -2.45570106e-07],
       [-5.41802612e-04, -1.50860404e-04,  1.26930696e-04, ...,
        -2.56817555e-04, -2.50204139e-05,  1.04495441e-04]], dtype=float32)>, <tf.Tensor: shape=(30, 45), dtype=float32, numpy=
array([[-7.0507306e-04, -2.0633716e-04,  1.7400520e-04, ...,
        -3.6967205e-04, -3.7501362e-05,  1.4782809e-04],
       [ 5.1573670e-04,  1.4274604e-04, -1.3485446e-04, ...,
         2.7351442e-04,  2.6811944e-05, -1.0229945e-04],
       [ 5.9934851e-04,  1.5532124e-04, -6.7590619e-05, ...,
         2.1548117e-04,  2.2311295e-05, -1.0959314e-04],
       ...,
       [ 5.4814700e-05,  4.3496937e-05, -1.8578687e-05, ...,
         7.5983262e-05, -4.5271179e-07, -5.8261721e-06],
       [-3.1379235e-04, -1.1787527e-04,  1.4789868e-04, ...,
        -2.6880243e-04, -2.6073740e-05,  7.7472316e-05],
       [-6.6878228e-04, -2.1064407e-04, -4.6462530e-05, ...,
        -2.2263323e-04, -1.9430225e-05,  9.6629228e-05]], dtype=float32)>, <tf.Tensor: shape=(90,), dtype=float32, numpy=
array([ 1.16319723e-04, -6.65306379e-06,  1.49328218e-04, -9.39639285e-05,
        1.94156364e-05, -1.06977510e-04,  2.60740126e-05, -5.14449821e-05,
       -4.25622602e-05,  1.12075999e-04,  3.00763386e-05, -6.96864008e-05,
       -2.93371213e-05,  5.70598095e-05, -2.25812855e-05,  9.28668669e-05,
       -6.48290370e-05,  1.42351901e-05,  7.79566381e-06,  5.12010556e-05,
        1.35212569e-04, -8.11409409e-05,  5.97290018e-05,  1.39002650e-05,
       -1.61240576e-04,  8.25814932e-05, -1.31838271e-04,  7.73556967e-05,
        3.51827039e-05,  6.78745346e-05,  5.94867815e-05,  1.20654746e-04,
       -5.86603746e-05, -1.68627212e-05, -9.32233088e-05, -7.54116481e-05,
       -4.15137547e-05,  1.13293558e-04, -4.25729268e-05, -2.90174630e-05,
        2.46170748e-05,  7.96543318e-05,  3.24939137e-05, -2.68521108e-05,
        6.48593850e-05,  1.18317045e-02,  1.41624617e-03,  1.54742040e-02,
        1.99375814e-03, -1.02766063e-02, -1.83786149e-03, -5.11136977e-03,
       -5.69136767e-03,  4.77006426e-03, -2.71177245e-03, -4.01637633e-04,
       -6.43057283e-03,  2.38329070e-04,  2.73812423e-03, -7.34239211e-03,
       -5.37944166e-03, -4.41901339e-03,  8.48157611e-03, -1.01976767e-02,
        1.22398036e-02,  1.42613407e-02,  1.36907736e-04, -1.40897022e-03,
       -5.37455874e-03, -1.11896414e-02, -3.10391933e-03,  6.97261654e-03,
       -7.98172608e-04,  3.74990865e-03, -3.73774115e-03, -6.18065754e-03,
        6.77541830e-03, -5.38518652e-03, -6.05498208e-03, -4.54706652e-03,
        4.53699101e-03, -5.78448351e-04,  2.90909852e-03, -3.63804074e-03,
        6.88601378e-03,  3.38278944e-04, -2.15969291e-02, -1.28755383e-02,
        2.61668349e-03, -2.41006538e-03], dtype=float32)>, <tf.Tensor: shape=(45, 24), dtype=float32, numpy=
array([[ 2.34027211e-05,  4.36268077e-04,  1.01352925e-04, ...,
         7.36121146e-05,  1.17143395e-06, -1.19157383e-04],
       [ 1.47025039e-05,  3.13180033e-04,  1.20620847e-04, ...,
         6.38960410e-05, -9.47069930e-06, -4.17834613e-04],
       [-3.32095551e-05, -3.50485876e-04, -7.57380767e-05, ...,
         3.94681556e-05, -8.11194477e-05,  3.15105804e-04],
       ...,
       [ 6.29486967e-05,  4.78786213e-04,  8.18739281e-05, ...,
        -6.90419529e-06,  8.29217388e-05, -3.30259121e-04],
       [-1.17188993e-05, -1.81314797e-04,  3.44662294e-06, ...,
        -9.70137771e-05,  5.12186707e-05, -1.81258816e-04],
       [-7.07152958e-06, -6.50049003e-07, -1.82518688e-05, ...,
         5.28392447e-05, -4.85136734e-05,  2.52802507e-04]], dtype=float32)>, <tf.Tensor: shape=(45, 24), dtype=float32, numpy=
array([[-4.92158688e-05, -4.99721267e-04, -1.70100262e-04, ...,
        -2.49344375e-05, -5.00373972e-05,  5.35333529e-04],
       [ 1.18749929e-04,  4.08219348e-04, -4.07411608e-05, ...,
         5.01845425e-05,  4.08413653e-05, -3.36375670e-04],
       [-5.75157574e-05, -2.93548819e-05,  1.22516634e-04, ...,
         8.86515554e-05, -9.48461966e-05, -7.23444318e-05],
       ...,
       [ 3.42975982e-05, -8.90037991e-05, -1.40732460e-04, ...,
        -5.30051038e-05,  4.78861293e-05,  2.23252384e-04],
       [ 1.30767890e-04,  8.58650135e-04,  1.64401848e-04, ...,
         2.39256879e-05,  1.30615386e-04, -7.24033860e-04],
       [-1.02350066e-04, -6.27487607e-04, -8.87739807e-05, ...,
        -1.15536341e-05, -9.92901478e-05,  5.15294203e-04]], dtype=float32)>, <tf.Tensor: shape=(48,), dtype=float32, numpy=
array([-1.52849616e-03,  4.15315200e-03,  5.49893780e-03,  7.88360703e-05,
        5.83619531e-03,  1.49636506e-03,  1.56956771e-03,  1.77492877e-03,
       -9.51749389e-04, -1.23838719e-03, -2.14577327e-03, -1.06554478e-03,
        3.87811032e-03, -1.01735769e-03,  8.54634098e-04,  1.42726663e-03,
       -3.97124514e-03,  1.01192705e-02,  3.48703284e-03, -3.54021671e-03,
        8.30788573e-04,  1.17660509e-02, -9.20792762e-03, -2.75757723e-03,
       -1.52469648e-03,  4.10201307e-03,  5.56020532e-03,  8.04707015e-05,
        5.84156811e-03,  1.49313489e-03,  1.68066542e-03,  1.78423128e-03,
       -9.71846399e-04, -1.10242935e-03, -2.21362524e-03, -1.03475736e-03,
        3.78335896e-03, -9.63142433e-04,  8.57508276e-04,  1.48339663e-03,
       -3.93811148e-03,  1.00487424e-02,  3.30709922e-03, -3.46717006e-03,
        8.62539513e-04,  1.17346896e-02, -9.20435321e-03, -3.15025309e-03],
      dtype=float32)>, <tf.Tensor: shape=(24, 12), dtype=float32, numpy=
array([[-5.99859959e-05, -3.45486478e-05, -9.76754745e-05,
        -1.37092124e-04,  6.59670695e-05, -7.28712403e-05,
         1.81541127e-05,  2.29327525e-05,  6.23519591e-05,
         3.04217774e-05, -8.21723224e-05, -5.81559470e-05],
       [-1.66909915e-04,  4.27852101e-05, -1.03694350e-04,
        -2.39756366e-04,  1.82895645e-04, -1.46276172e-04,
         2.71183326e-05,  8.69084033e-05,  2.18979912e-05,
        -3.56247147e-05, -2.13641615e-04, -1.77816342e-04],
       [-2.00529656e-04,  1.28064115e-04, -5.78977269e-05,
        -3.35056073e-04,  2.91979697e-04, -2.83804548e-04,
        -1.06714906e-04,  1.95121422e-04,  7.55660494e-06,
        -9.21213868e-05, -3.63199826e-04, -3.39372869e-04],
       [ 9.60055841e-05, -5.26852200e-05, -4.41527800e-06,
         1.40321936e-04, -1.13698239e-04,  1.12221845e-04,
         6.03703520e-05, -8.78497813e-05,  2.57897937e-05,
         3.86995125e-05,  1.66041602e-04,  1.51549233e-04],
       [-5.57781368e-06,  1.02990898e-05,  1.76681115e-05,
         6.39331629e-05, -3.68182191e-05,  2.50982466e-05,
         2.52669633e-05, -2.83587651e-05, -1.25407905e-06,
         3.51380077e-05,  2.72857433e-05,  3.32974632e-05],
       [-3.50493849e-07,  6.60263595e-06,  2.06909372e-05,
        -6.00371131e-05,  3.77164506e-05, -2.02635511e-05,
        -4.07754851e-05,  4.13793459e-05, -3.84680352e-05,
        -5.26678268e-05, -4.83034964e-05, -4.44782345e-05],
       [ 2.24070405e-04, -1.61396703e-04,  3.41952068e-06,
         3.78364231e-04, -3.22431966e-04,  3.18548526e-04,
         1.47512881e-04, -2.31818791e-04,  1.60129075e-05,
         1.08479646e-04,  4.28652362e-04,  4.04991035e-04],
       [-4.53004614e-05,  7.16067298e-05,  2.57344036e-05,
        -2.39554356e-05,  5.28676646e-05, -7.42124248e-05,
        -4.83480690e-05,  5.61998131e-05, -1.74981578e-05,
        -1.81192286e-06, -9.19988524e-05, -7.64717333e-05],
       [ 1.56734284e-04, -1.85007848e-05,  1.34078640e-04,
         2.31779559e-04, -1.59474090e-04,  1.40437987e-04,
        -5.05774988e-05, -4.23238198e-05, -1.00111261e-04,
        -5.29279305e-06,  1.82501724e-04,  1.48578954e-04],
       [ 1.02553051e-04, -5.26941731e-05,  3.38687387e-05,
        -2.38857538e-05, -2.57872071e-05,  3.61866478e-05,
        -4.93750413e-05,  6.57753617e-06,  1.82914744e-06,
        -3.27534071e-05,  5.21742404e-05,  2.38973771e-05],
       [ 1.39951671e-05,  3.75628297e-05,  5.23033486e-05,
        -1.42447578e-04,  1.07064407e-04, -1.06055260e-04,
        -1.45555256e-04,  1.19981349e-04, -4.02385231e-05,
        -1.05525985e-04, -1.29239881e-04, -1.50844426e-04],
       [ 2.01602816e-05, -2.02538395e-05, -4.25776443e-06,
        -1.64425110e-05, -4.02035676e-06,  1.76314843e-05,
         4.46143804e-06, -8.67486392e-07,  4.61937680e-06,
        -7.97596840e-06,  1.71192751e-05,  1.04275014e-05],
       [ 2.75889324e-04, -7.31897599e-05,  1.63446923e-04,
         3.30343988e-04, -2.61932873e-04,  2.17742767e-04,
        -5.56243722e-05, -1.03488666e-04, -5.82241591e-05,
         3.40386541e-05,  3.18109087e-04,  2.55109335e-04],
       [-1.84640608e-04, -2.97568895e-05, -1.74093322e-04,
        -1.33128691e-04,  7.37107839e-05, -5.09336242e-05,
         1.61564050e-04, -4.06551881e-05,  9.17129946e-05,
         8.53609235e-05, -9.99268304e-05, -3.40552033e-05],
       [-2.02205701e-04,  2.37486183e-05, -1.61852222e-04,
        -4.28797357e-04,  2.92979123e-04, -2.37025204e-04,
        -1.01641344e-05,  1.46937964e-04,  5.79414082e-05,
        -8.82287350e-05, -3.26949317e-04, -2.88019888e-04],
       [ 2.27863755e-04, -1.05801380e-04,  7.68313257e-05,
         1.97164612e-04, -1.90683422e-04,  1.79065464e-04,
        -2.00134746e-05, -8.61941517e-05, -2.34004037e-05,
         5.75132708e-06,  2.57136708e-04,  2.06418292e-04],
       [-1.26805287e-04,  4.73261607e-05, -4.78385009e-05,
        -1.84036922e-04,  1.47784449e-04, -1.28537024e-04,
        -2.04844291e-05,  8.69807918e-05, -3.18543380e-06,
        -3.54334043e-05, -1.82969117e-04, -1.60835261e-04],
       [ 1.61938107e-04,  1.07660853e-05,  1.09514127e-04,
         1.17657815e-04, -7.31125474e-05,  2.55509658e-05,
        -1.15815768e-04,  2.10256458e-05, -3.05663380e-05,
        -9.32847615e-06,  9.52391274e-05,  4.11775691e-05],
       [ 6.52769813e-05,  2.58960881e-06,  8.28021075e-05,
         2.40394438e-04, -1.56433685e-04,  1.58155075e-04,
         5.51536104e-05, -1.05106650e-04, -4.14865463e-05,
         1.60203581e-05,  1.80328730e-04,  1.71769469e-04],
       [-1.67020014e-04,  3.79676239e-05, -7.95443266e-05,
        -3.19536834e-04,  2.26149117e-04, -1.67283462e-04,
        -2.13195181e-05,  1.26605562e-04, -4.43222598e-06,
        -9.90578919e-05, -2.59984517e-04, -2.35921747e-04],
       [-1.29116306e-04,  4.32424640e-05, -7.71288833e-05,
        -1.68005194e-04,  1.32366127e-04, -1.07153646e-04,
         2.19940030e-05,  5.96466925e-05,  1.81531523e-05,
        -2.81001667e-05, -1.63591991e-04, -1.25979685e-04],
       [ 2.08421494e-04, -5.55308325e-05,  1.32099129e-04,
         2.97396909e-04, -2.29183192e-04,  2.19454698e-04,
         8.65344282e-06, -1.20295932e-04, -4.28211206e-05,
         2.47536027e-05,  2.88783136e-04,  2.42497743e-04],
       [-2.72374076e-04,  3.85281273e-05, -2.24986754e-04,
        -4.97353787e-04,  3.45229579e-04, -2.98858504e-04,
         1.53823712e-05,  1.64468205e-04,  1.01292753e-04,
        -4.57747010e-05, -4.03456739e-04, -3.37890116e-04],
       [ 3.09584168e-04, -6.82294049e-05,  2.37330794e-04,
         6.09048700e-04, -4.28385451e-04,  3.90451052e-04,
         3.03071392e-05, -2.27111872e-04, -1.17544048e-04,
         6.73469694e-05,  5.06369630e-04,  4.44947480e-04]], dtype=float32)>, <tf.Tensor: shape=(24, 12), dtype=float32, numpy=
array([[-1.39535114e-04,  3.57056306e-05, -8.52775993e-05,
        -1.34730348e-04,  1.06972671e-04, -1.19401157e-04,
         2.54305451e-05,  3.02047556e-05,  7.13121481e-05,
         4.81644856e-05, -1.44244594e-04, -1.14766553e-04],
       [-1.89003375e-04,  5.59182954e-05, -6.21324871e-05,
        -3.36453057e-04,  2.34593332e-04, -1.68617247e-04,
         1.33237854e-05,  1.27365376e-04,  1.48287590e-05,
        -8.15389139e-05, -2.62995949e-04, -2.60557223e-04],
       [-4.50996013e-05,  5.98585320e-05,  2.72992547e-05,
        -1.14608869e-04,  1.05237043e-04, -9.65444051e-05,
        -5.74157166e-05,  8.86589551e-05, -1.90734954e-05,
        -5.95833008e-05, -1.21191712e-04, -1.41589233e-04],
       [ 1.64310724e-04, -8.69826035e-05,  7.71390041e-05,
         1.69233856e-04, -1.64603684e-04,  1.96076522e-04,
         4.46240338e-05, -9.27093279e-05, -3.41165251e-05,
        -3.26535301e-05,  2.40449444e-04,  1.81951822e-04],
       [-1.12473841e-04,  7.32360350e-05, -4.73461369e-05,
        -2.27913391e-04,  1.79720446e-04, -1.92875115e-04,
        -9.25638669e-05,  1.27189924e-04,  2.70457949e-05,
        -3.11586737e-05, -2.51440884e-04, -2.08191021e-04],
       [-2.95568199e-04,  1.23606937e-04, -1.07121814e-04,
        -2.52055499e-04,  2.27307537e-04, -2.12913757e-04,
         5.76150560e-05,  8.40126813e-05,  6.12870936e-05,
         2.41325251e-05, -3.13381868e-04, -2.46425305e-04],
       [-4.38030838e-04,  1.32138070e-04, -2.32551029e-04,
        -7.01321289e-04,  5.02411916e-04, -4.43411060e-04,
        -3.41501027e-06,  2.58749351e-04,  1.11207628e-04,
        -7.14526177e-05, -6.30580937e-04, -5.35951869e-04],
       [ 2.77868327e-04, -4.98571135e-05,  1.83493525e-04,
         4.35120746e-04, -3.03873967e-04,  2.52706523e-04,
        -2.73860987e-05, -1.36550516e-04, -6.78419383e-05,
         4.94287779e-05,  3.74643801e-04,  3.01067164e-04],
       [-2.26711036e-05,  3.19229039e-05,  2.42980750e-05,
        -2.20296861e-04,  1.63477423e-04, -1.36668357e-04,
        -1.45198370e-04,  1.63910270e-04, -7.74765649e-05,
        -1.19256059e-04, -1.77834896e-04, -1.98664988e-04],
       [ 2.57347681e-04, -1.52470398e-04,  3.60322883e-05,
         4.34688438e-04, -3.46046872e-04,  3.08087823e-04,
         8.83300163e-05, -2.35772895e-04,  1.43549487e-05,
         1.24933227e-04,  4.38669813e-04,  4.16417315e-04],
       [ 1.15500472e-04, -4.35398179e-05,  7.49319370e-05,
         3.25543602e-04, -2.29038764e-04,  2.25677475e-04,
         1.00489880e-04, -1.64346697e-04, -2.36385731e-05,
         6.49889116e-05,  2.82295601e-04,  2.61087553e-04],
       [ 2.18013265e-05, -3.17410850e-05,  3.83772522e-06,
         1.36398550e-04, -1.13349575e-04,  1.37099152e-04,
         1.29834647e-04, -1.13481263e-04,  2.28134231e-05,
         5.43443748e-05,  1.46672101e-04,  1.46243212e-04],
       [-3.52306408e-04,  1.77764887e-04, -9.92856221e-05,
        -4.62866185e-04,  3.75396747e-04, -3.71732836e-04,
        -5.61494053e-05,  2.18172820e-04,  5.96362552e-05,
        -3.83340921e-05, -5.08632744e-04, -4.44053992e-04],
       [ 2.56682077e-04, -1.17780997e-04,  7.78210961e-05,
         3.29359726e-04, -2.83149042e-04,  2.66467629e-04,
         4.87504767e-05, -1.66440572e-04, -1.24492199e-05,
         4.50644038e-05,  3.54706543e-04,  3.26836336e-04],
       [ 2.14611166e-04, -1.35329770e-04,  5.50825062e-05,
         4.07634332e-04, -3.25472414e-04,  3.53606592e-04,
         1.64614306e-04, -2.41542803e-04, -2.81169450e-05,
         5.48234748e-05,  4.37639828e-04,  4.04869701e-04],
       [ 2.92004173e-04, -1.31682085e-04,  1.35463037e-04,
         4.01868863e-04, -3.30092240e-04,  3.32787138e-04,
         4.98730551e-05, -1.82528165e-04, -7.11970570e-05,
         1.55923590e-05,  4.39604017e-04,  3.68272013e-04],
       [-2.02251889e-04,  6.86906205e-05, -7.05718630e-05,
        -1.15057650e-04,  1.13710637e-04, -9.48109810e-05,
         8.88680879e-05,  1.67930211e-05,  3.95004645e-05,
         3.44531072e-05, -1.52663459e-04, -1.15220020e-04],
       [ 3.48196481e-05,  6.09444214e-05,  1.02541992e-04,
        -1.57807779e-04,  1.26215687e-04, -1.56926064e-04,
        -2.18983943e-04,  1.73171167e-04, -6.17315163e-05,
        -1.14668386e-04, -1.54090783e-04, -2.16085056e-04],
       [-3.37391393e-04,  1.55490314e-04, -1.30920584e-04,
        -4.44033823e-04,  3.61012237e-04, -3.42257845e-04,
        -2.34149229e-05,  1.93947853e-04,  6.40528961e-05,
        -3.61336424e-05, -4.75171226e-04, -4.04629478e-04],
       [ 1.90794352e-04, -1.23286445e-04,  5.98614752e-05,
         4.07406711e-04, -3.25602130e-04,  3.45700100e-04,
         1.70839645e-04, -2.44260096e-04, -2.42412461e-05,
         7.08981097e-05,  4.20955272e-04,  3.98841832e-04],
       [ 4.05456922e-05, -2.90976677e-05,  2.12940322e-05,
         5.81418462e-05, -4.74405279e-05,  7.29083549e-05,
         3.33122443e-05, -3.32810523e-05, -3.00231877e-05,
        -2.48989927e-05,  8.66615810e-05,  5.73350735e-05],
       [ 4.36395931e-04, -1.70386847e-04,  1.86498801e-04,
         5.69301890e-04, -4.49064857e-04,  4.17685456e-04,
         7.59697696e-06, -2.29976518e-04, -8.63912719e-05,
         4.06614454e-05,  5.88215888e-04,  4.94435080e-04],
       [ 3.37493606e-04, -1.90692328e-04,  8.59143620e-05,
         4.77362861e-04, -3.93717200e-04,  4.01828118e-04,
         1.04056016e-04, -2.49730190e-04, -4.53937791e-05,
         5.40187066e-05,  5.37951943e-04,  4.74289816e-04],
       [-9.09685259e-05,  3.95622301e-05, -2.24750820e-05,
        -1.14484566e-04,  9.13967233e-05, -8.89812436e-05,
        -2.40064328e-05,  5.71745368e-05, -2.05875017e-06,
        -1.13957349e-05, -1.26715458e-04, -9.99206895e-05]], dtype=float32)>, <tf.Tensor: shape=(24,), dtype=float32, numpy=
array([ 7.1413582e-05,  7.9095624e-03,  8.9541916e-03,  8.4862076e-03,
       -1.1525732e-03, -2.7525877e-03, -6.5807658e-03,  2.6552351e-03,
       -3.8187788e-03,  3.2314353e-04, -1.9588030e-03, -3.2349722e-03,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,
        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
      dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[-8.82614404e-06,  1.91327432e-04, -2.93708723e-07,
         1.28771775e-04,  5.36738953e-05,  6.53722906e-04,
         1.07310807e-04, -9.16145471e-09,  5.11296093e-07,
         0.00000000e+00,  0.00000000e+00, -1.05609279e-03,
        -2.31790565e-07,  6.29580472e-06, -7.69377948e-06,
        -7.01979104e-07, -2.08208658e-04,  1.31532521e-04,
        -5.81766358e-07, -2.97979330e-09,  9.53334791e-04,
         2.92719313e-04, -6.40064313e-09, -2.11728067e-04,
         0.00000000e+00, -2.77507876e-04,  5.25002310e-04,
         1.34796777e-04,  6.09191076e-04, -7.76087923e-04],
       [ 1.55333510e-05, -2.01721268e-05,  4.70111203e-08,
        -1.51979286e-04, -3.74683168e-06, -4.81301981e-07,
        -5.36672887e-05,  1.19722805e-04, -1.99871458e-04,
         2.76975925e-06,  3.28334210e-07, -4.89555750e-05,
         0.00000000e+00, -1.20471144e-04,  2.99563645e-08,
        -4.13815587e-06, -1.99832830e-05, -2.52804341e-04,
        -7.71299456e-05, -4.95808990e-07,  5.00658862e-05,
        -1.06495863e-05, -2.95404834e-06,  7.88756297e-05,
         0.00000000e+00,  7.71194755e-06, -2.14779822e-04,
        -1.79232826e-04, -2.46936572e-04,  3.77070501e-05],
       [-1.15679322e-05,  1.52043227e-04, -1.51507186e-06,
         8.44750248e-05,  4.06944964e-05,  5.11866412e-04,
         8.69717987e-05, -1.49081352e-08,  1.89141792e-06,
         0.00000000e+00,  0.00000000e+00, -8.27804266e-04,
        -1.03273021e-06,  3.51904964e-06, -1.16239607e-05,
        -1.85746683e-06, -1.59198666e-04,  1.16238574e-04,
         2.95793512e-07,  1.81426021e-08,  7.51297630e-04,
         2.16053362e-04,  0.00000000e+00, -1.70243875e-04,
         0.00000000e+00, -2.21527836e-04,  4.36859031e-04,
         9.94291840e-05,  4.81896248e-04, -6.48967398e-04],
       [-6.37076955e-05, -1.31133402e-05,  5.56125258e-07,
        -7.27266015e-05,  3.05145682e-06,  1.04194532e-06,
        -5.62052774e-05,  7.79962793e-05, -1.40760138e-04,
         2.43374257e-06,  5.85861642e-07, -2.31119957e-05,
         0.00000000e+00, -2.72252946e-05, -2.45233196e-07,
        -2.33854462e-06,  3.51442977e-05, -1.48950538e-04,
        -3.20111649e-05,  4.20437573e-07,  3.07293303e-05,
         2.57865986e-06, -1.91524668e-06,  1.37825831e-04,
         0.00000000e+00,  4.61965647e-06, -1.77340669e-04,
        -3.24027787e-05, -1.91587751e-04,  2.95161735e-05],
       [-5.78648041e-06,  6.64425752e-05, -8.97533084e-07,
         4.37052186e-05,  1.34032653e-05,  2.65989715e-04,
         7.74004002e-06, -1.41220484e-08,  1.26218822e-06,
         0.00000000e+00,  0.00000000e+00, -3.01775552e-04,
        -6.60949581e-07,  1.73409819e-06, -7.60686771e-06,
        -8.73439376e-07, -8.12822836e-05,  3.89278175e-05,
         2.78932674e-07,  0.00000000e+00,  3.16858524e-04,
         1.06754473e-04,  0.00000000e+00, -4.13937087e-05,
         0.00000000e+00, -8.20097266e-05,  1.16895593e-04,
         5.38402455e-05,  1.24175000e-04, -2.20725095e-04],
       [ 5.94581616e-06,  6.74225248e-06,  8.92801566e-09,
        -6.42550822e-06,  4.09906806e-06,  1.98976413e-05,
         1.60846812e-05,  5.05928620e-06, -7.66689391e-06,
         1.00807966e-07,  4.19581809e-08, -4.01704419e-05,
         0.00000000e+00, -4.23522897e-06,  1.76392945e-08,
        -7.88226941e-07, -7.75609897e-06, -8.29268902e-06,
        -6.88199316e-06, -1.27314493e-07,  2.21976552e-05,
         6.47115485e-06, -2.24770062e-07, -4.50473999e-06,
         0.00000000e+00, -5.86503393e-06, -2.10642429e-06,
        -7.60812463e-06,  2.58713771e-06, -7.99848294e-06],
       [ 9.79968081e-06, -3.72468494e-05,  6.58967224e-07,
        -2.08189158e-04, -1.10768233e-05, -9.58360260e-07,
        -7.38954914e-05,  1.64188372e-04, -2.80206179e-04,
         2.11694510e-06,  9.74292448e-07, -8.06360404e-05,
         0.00000000e+00, -1.80283620e-04,  4.27739266e-08,
        -2.39349356e-06, -1.44263340e-05, -4.14563256e-04,
        -1.13113820e-04,  1.96542965e-06,  8.45808099e-05,
        -1.48809904e-05, -1.58254375e-06,  1.21506404e-04,
         0.00000000e+00, -2.35108837e-06, -3.17030761e-04,
        -2.65896728e-04, -3.74043884e-04,  5.24637253e-05],
       [ 2.08239344e-05, -2.72291145e-05,  6.89022272e-07,
        -1.38120842e-04, -8.66429036e-06,  3.11869826e-06,
        -3.74100091e-05,  1.00451405e-04, -1.75628680e-04,
         1.33860544e-06,  6.02432408e-07, -6.14446617e-05,
         0.00000000e+00, -1.17925803e-04,  3.78082383e-08,
        -2.04410162e-06, -1.44830492e-05, -2.63965980e-04,
        -8.51885416e-05,  1.12396935e-06,  5.28950404e-05,
        -1.35029240e-05, -1.08180166e-06,  6.46396438e-05,
         0.00000000e+00,  9.22347169e-07, -1.89573446e-04,
        -1.82026983e-04, -2.33579791e-04,  3.10204523e-05],
       [ 2.98269492e-06, -1.83077282e-05,  1.48196619e-08,
        -1.15033014e-04, -1.42314730e-06, -4.19077651e-06,
        -3.88495209e-05,  8.21259018e-05, -1.45180689e-04,
         3.58794478e-06,  4.51379350e-07, -4.18720811e-05,
         0.00000000e+00, -8.59688589e-05,  4.29535341e-08,
        -3.54627878e-06, -6.89499939e-06, -1.86985242e-04,
        -5.43704009e-05,  1.99601345e-07,  3.30364201e-05,
        -8.86732960e-06, -3.05928324e-06,  5.84405097e-05,
         0.00000000e+00,  6.51113942e-06, -1.74898669e-04,
        -1.28769825e-04, -1.79603812e-04,  2.80444365e-05],
       [-7.73463762e-06,  2.21299822e-04, -4.15110605e-07,
         1.31769935e-04,  4.48610808e-05,  6.17986429e-04,
         1.36902599e-04, -1.78425434e-08,  3.67954954e-07,
         0.00000000e+00,  0.00000000e+00, -9.84876999e-04,
        -4.02565121e-07,  6.28549697e-06, -6.61659806e-06,
        -4.22098566e-07, -1.61828779e-04,  1.47161365e-04,
        -2.53343927e-07,  1.39234102e-09,  8.82726104e-04,
         2.93576042e-04,  0.00000000e+00, -1.88175327e-04,
         0.00000000e+00, -2.66465941e-04,  4.79637296e-04,
         1.32701884e-04,  5.03322226e-04, -6.99860102e-04],
       [ 1.63825280e-05, -9.63772072e-06, -8.84093936e-07,
        -4.26259285e-05, -7.47695685e-06,  7.88908801e-06,
        -1.50214209e-05,  3.39016660e-05, -4.85259043e-05,
         0.00000000e+00,  0.00000000e+00, -2.21871633e-05,
        -3.74413702e-07, -5.61775232e-05, -3.48879485e-06,
        -1.12076759e-06, -1.10190331e-05, -1.06982370e-04,
        -2.26684588e-05, -6.36233835e-07,  4.09819186e-05,
         1.57540717e-06,  0.00000000e+00, -1.01093856e-05,
         0.00000000e+00, -7.82028837e-06, -4.07148800e-05,
        -8.41346773e-05, -5.66028175e-05, -4.75637717e-06],
       [ 7.04089107e-05, -2.16945737e-05, -5.24189687e-08,
        -1.38307922e-04, -8.31818306e-06, -3.09444204e-08,
        -1.79882227e-05,  8.54788304e-05, -1.38319738e-04,
         2.15231148e-06,  5.53311679e-07, -4.47450911e-05,
         0.00000000e+00, -1.39371870e-04,  3.92188326e-08,
        -2.70888177e-06, -5.85901216e-05, -2.19696289e-04,
        -7.07610016e-05, -2.68057477e-07,  3.96317810e-05,
        -9.90950957e-06, -2.06664345e-06, -1.83958437e-05,
         0.00000000e+00,  1.72652881e-06, -1.51938482e-04,
        -2.07153294e-04, -1.68042767e-04,  2.18211244e-05],
       [ 2.68809745e-05, -1.50432088e-05,  2.54075360e-07,
        -1.09412242e-04, -3.40216798e-06, -7.64783181e-07,
        -3.70465932e-05,  8.23897135e-05, -1.34904549e-04,
         2.17818479e-06,  1.08170707e-06, -2.72684956e-05,
         0.00000000e+00, -1.07504813e-04,  2.54375330e-08,
        -3.18106777e-06, -3.93693153e-05, -1.82929376e-04,
        -4.97895307e-05, -1.09979840e-06,  3.53655196e-05,
        -6.35955621e-06, -2.00594491e-06,  2.03268428e-05,
         0.00000000e+00,  9.81542826e-07, -1.53053115e-04,
        -1.50311113e-04, -1.66188402e-04,  2.80756540e-05],
       [ 3.87017171e-05, -4.78201446e-06, -3.27814917e-07,
        -5.98075967e-05, -2.23548204e-06, -2.40380996e-06,
        -8.17059299e-06,  3.38006284e-05, -5.37554697e-05,
         1.65338577e-07,  1.30316124e-07, -1.01996065e-05,
         0.00000000e+00, -5.56713203e-05, -1.68886984e-07,
        -2.81638336e-07, -3.65676824e-05, -6.59482757e-05,
        -2.28161225e-05,  7.30899160e-07,  9.61153000e-06,
        -2.41335397e-06, -8.68866721e-08, -2.55650939e-05,
         0.00000000e+00,  5.65262235e-06, -6.05044333e-05,
        -8.38445922e-05, -5.33000857e-05,  8.50469769e-06],
       [ 4.48154969e-05, -1.95212051e-05,  2.16438508e-07,
        -1.25647493e-04, -8.60621094e-06,  9.39195616e-07,
        -3.40679217e-05,  8.57886043e-05, -1.52743742e-04,
         2.00687327e-06,  5.72375654e-07, -4.32402667e-05,
         0.00000000e+00, -1.21135650e-04,  2.46405598e-08,
        -2.26651127e-06, -4.25538892e-05, -2.22392511e-04,
        -6.80157682e-05,  4.81892585e-07,  4.58949798e-05,
        -9.37615005e-06, -1.79947870e-06,  2.28950994e-05,
         0.00000000e+00, -1.50795267e-06, -1.59983741e-04,
        -1.78182556e-04, -1.92716252e-04,  2.78292064e-05],
       [-1.65804286e-05, -3.86728680e-05,  5.25969654e-07,
        -2.09624210e-04, -7.59306840e-06,  2.41939347e-06,
        -8.91468881e-05,  1.79694587e-04, -2.96518323e-04,
         3.39433291e-06,  7.49138792e-07, -7.83056385e-05,
         0.00000000e+00, -1.74906119e-04,  3.90296400e-08,
        -3.95306461e-06,  7.57515681e-06, -4.24205384e-04,
        -1.09993518e-04, -2.02552678e-06,  9.04681074e-05,
        -1.56005353e-05, -3.24136363e-06,  1.52819906e-04,
         0.00000000e+00, -1.46432910e-06, -3.35538934e-04,
        -2.53651844e-04, -3.92423273e-04,  5.54422586e-05],
       [-4.78777365e-05, -2.43765262e-05,  9.17101829e-07,
        -1.39068841e-04, -3.17748004e-06, -4.08931555e-08,
        -9.12880350e-05,  1.31896290e-04, -2.35958665e-04,
         2.91658489e-06,  1.49666562e-06, -3.93730443e-05,
         0.00000000e+00, -1.11221569e-04,  3.13909325e-08,
        -4.95836230e-06,  8.67289782e-06, -2.91811157e-04,
        -5.73162542e-05, -1.59353942e-06,  6.19552375e-05,
        -6.71532416e-06, -2.99312887e-06,  1.38265110e-04,
         0.00000000e+00, -2.95537575e-06, -2.74777296e-04,
        -1.48088671e-04, -3.03972512e-04,  5.26896692e-05],
       [-5.94497760e-06,  1.48166728e-04, -1.60379523e-06,
         7.58061578e-05,  3.39455655e-05,  4.59327246e-04,
         8.88588547e-05, -1.93013712e-08,  1.56276155e-06,
         0.00000000e+00,  0.00000000e+00, -7.32970540e-04,
        -7.49014589e-07,  4.82282667e-06, -1.04731880e-05,
        -1.69846544e-06, -1.24103055e-04,  9.79632314e-05,
        -1.72520913e-08,  0.00000000e+00,  6.54978561e-04,
         2.10135040e-04,  0.00000000e+00, -1.38124073e-04,
         0.00000000e+00, -1.96907306e-04,  3.52362462e-04,
         1.04415536e-04,  3.98272765e-04, -5.31316851e-04],
       [ 5.53541668e-06, -1.06782336e-05, -9.62040474e-08,
        -6.18675112e-05, -6.25402754e-06,  4.24839254e-06,
        -3.20392246e-05,  5.02835064e-05, -9.25867571e-05,
         0.00000000e+00,  3.99167561e-07, -2.65619201e-05,
        -3.27642766e-07, -6.24919267e-05, -1.12903047e-06,
        -1.76659370e-07, -9.13740678e-06, -1.37253373e-04,
        -3.17966333e-05,  5.95139937e-08,  3.90225687e-05,
        -3.31566935e-06, -1.58770863e-08,  3.00712436e-05,
         0.00000000e+00, -7.43873989e-06, -9.45612701e-05,
        -8.66083501e-05, -1.16067851e-04,  1.41371411e-05],
       [-8.04332467e-06,  1.72040469e-04, -1.21453400e-06,
         1.00477744e-04,  4.21097502e-05,  5.38503868e-04,
         1.05329964e-04, -3.82393850e-08,  9.80419031e-07,
         0.00000000e+00,  0.00000000e+00, -8.93432763e-04,
        -5.49143635e-07,  4.28065778e-06, -9.87300791e-06,
        -1.30264561e-06, -1.59340780e-04,  1.26897925e-04,
        -8.43239789e-08, -3.32290000e-08,  7.96596054e-04,
         2.45626725e-04,  0.00000000e+00, -1.77846130e-04,
         0.00000000e+00, -2.40523324e-04,  4.70996922e-04,
         1.14373717e-04,  5.08296536e-04, -6.76032447e-04],
       [ 3.06677321e-05, -2.01970379e-05, -3.20898550e-07,
        -1.27689331e-04, -7.36783795e-06,  1.28569047e-06,
        -3.81936807e-05,  8.96482306e-05, -1.51394488e-04,
         9.16461204e-07,  1.76668379e-07, -4.87029538e-05,
         0.00000000e+00, -1.18139680e-04, -1.10275130e-06,
        -6.90162778e-07, -2.33248757e-05, -2.24736359e-04,
        -6.46812696e-05,  4.63472958e-07,  5.02651455e-05,
        -9.94955099e-06, -5.89257127e-07,  2.55890227e-05,
         0.00000000e+00,  1.77637696e-06, -1.64106576e-04,
        -1.76701084e-04, -1.82997639e-04,  2.26149987e-05],
       [ 1.43818406e-05, -1.98782564e-05,  2.10605975e-07,
        -9.21319952e-05, -5.53592236e-06, -9.56533995e-07,
        -2.70864821e-05,  6.93095426e-05, -1.13957984e-04,
         8.58068802e-07,  6.98973167e-07, -3.02476437e-05,
         0.00000000e+00, -9.24275155e-05,  1.68441190e-08,
        -1.23902134e-06, -1.95579632e-05, -1.91943735e-04,
        -4.49997315e-05,  2.12448867e-07,  3.87783875e-05,
        -6.34203298e-06, -7.36579523e-07,  2.63081693e-05,
         0.00000000e+00, -2.49700270e-06, -1.36986535e-04,
        -1.38931093e-04, -1.56528069e-04,  2.02162846e-05],
       [ 2.10349981e-06,  6.22049265e-06,  1.36554178e-07,
        -9.69181747e-06,  3.10653945e-06,  3.67237226e-05,
        -4.99325233e-06,  1.76109788e-05, -2.85798124e-05,
         5.06684842e-07,  2.15380638e-07, -2.72380839e-05,
        -5.62564786e-08, -1.38390787e-05, -1.07258280e-07,
        -3.40470280e-07, -1.58344592e-05, -3.37738747e-05,
        -1.27506764e-05, -3.92989165e-07,  3.10099531e-05,
         8.28181237e-06, -3.93497203e-07,  1.95887806e-05,
         0.00000000e+00, -7.13262671e-06, -3.57690660e-05,
        -1.24969847e-05, -4.55782683e-05,  6.88709179e-06],
       [ 9.33287993e-06, -4.95171225e-05,  7.37447181e-07,
        -2.62034038e-04, -1.64604189e-05,  3.30038802e-07,
        -9.98470714e-05,  2.08063240e-04, -3.53988231e-04,
         2.06755249e-06,  1.35095763e-06, -9.57336306e-05,
         0.00000000e+00, -2.40022462e-04,  1.95015417e-08,
        -2.20459015e-06, -2.16730259e-05, -5.30450256e-04,
        -1.33988171e-04,  9.76049705e-07,  1.14483315e-04,
        -1.87000060e-05, -1.58287537e-06,  1.33544847e-04,
         0.00000000e+00, -3.51200788e-06, -4.05415252e-04,
        -3.50203889e-04, -4.67218546e-04,  6.65549014e-05],
       [-1.52290579e-06,  1.24051701e-04,  5.90325087e-08,
         7.41589465e-05,  2.00515042e-05,  3.19376064e-04,
         6.85619743e-05, -6.52076494e-07, -1.45921263e-06,
         6.49721756e-07,  1.38775121e-07, -4.60606185e-04,
         0.00000000e+00,  2.78257858e-06, -1.69892394e-06,
        -1.65087977e-06, -7.91401544e-05,  7.41639669e-05,
        -1.39042663e-06, -9.23761775e-07,  4.17329982e-04,
         1.53616886e-04, -9.50678896e-07, -8.08128170e-05,
         0.00000000e+00, -1.28029045e-04,  2.07274090e-04,
         7.70790139e-05,  1.92075648e-04, -2.91182281e-04],
       [-1.28011707e-05,  2.30262813e-04, -1.40953432e-07,
         1.51227287e-04,  5.02590228e-05,  7.60577037e-04,
         8.68322677e-05, -5.23891241e-09,  2.86669149e-07,
         0.00000000e+00,  0.00000000e+00, -1.06916367e-03,
        -1.82012428e-07,  6.21463414e-06, -7.38656081e-06,
        -7.66580911e-07, -2.31828148e-04,  1.50305772e-04,
        -1.53149870e-07,  0.00000000e+00,  1.03051926e-03,
         3.29721806e-04,  0.00000000e+00, -1.85465367e-04,
         0.00000000e+00, -2.92943238e-04,  5.15502179e-04,
         1.54872134e-04,  5.32800041e-04, -7.93813961e-04],
       [ 5.32701742e-05, -3.41625237e-05,  3.52213476e-07,
        -1.68149185e-04, -1.22699057e-05,  1.51730262e-06,
        -3.25338806e-05,  1.12920810e-04, -1.93881671e-04,
         3.58424302e-07,  6.62128230e-07, -7.30055035e-05,
         0.00000000e+00, -1.62718410e-04,  3.28941780e-08,
        -6.53526115e-07, -3.94075287e-05, -3.26202047e-04,
        -9.87901149e-05,  2.32834986e-06,  6.81118909e-05,
        -1.54320369e-05, -2.89830496e-07,  3.20901090e-05,
         0.00000000e+00, -1.08401196e-06, -2.13218547e-04,
        -2.55364663e-04, -2.58667686e-04,  3.01756209e-05],
       [ 1.07329688e-05,  1.46641578e-05, -4.98272129e-07,
        -6.72347278e-06,  1.51875065e-05,  4.35150141e-05,
         4.85529818e-05,  9.83374733e-08, -2.93907851e-06,
         0.00000000e+00,  3.57643692e-08, -2.39110435e-04,
        -6.57824216e-07, -7.59165550e-06, -1.57516797e-06,
        -4.98682766e-07, -3.74200827e-05,  3.02651442e-05,
        -4.47128059e-06,  7.45957777e-07,  1.45582788e-04,
         1.65706588e-05,  0.00000000e+00, -9.35560529e-05,
         0.00000000e+00, -5.40344481e-05,  1.66138343e-04,
        -9.52428036e-06,  2.19088455e-04, -1.98719368e-04],
       [-6.19493085e-06,  1.57757066e-04, -3.39332695e-09,
         9.95287119e-05,  4.46119520e-05,  4.86261299e-04,
         1.15593204e-04, -3.60485700e-07, -3.03675392e-07,
         2.93382030e-08,  0.00000000e+00, -8.49971315e-04,
        -1.04370542e-07,  3.81021118e-06, -3.95183361e-06,
        -1.26399289e-06, -1.56889902e-04,  1.24285536e-04,
        -3.28981599e-07, -2.04059248e-07,  7.33493071e-04,
         2.11440682e-04, -7.46398854e-08, -1.82932927e-04,
         0.00000000e+00, -2.24639036e-04,  4.54065099e-04,
         9.11704265e-05,  4.92493040e-04, -6.34667580e-04],
       [ 3.25712717e-05,  1.96718665e-05, -1.07842698e-06,
        -1.77289967e-05,  2.49032219e-05,  6.50566581e-05,
         7.81006020e-05,  4.77843014e-06, -7.84564509e-06,
         0.00000000e+00,  0.00000000e+00, -3.55137745e-04,
        -5.18609340e-07, -2.24698542e-05, -4.88953356e-06,
        -1.07411154e-06, -6.35309552e-05,  3.32521049e-05,
        -7.65947516e-06,  1.54638414e-07,  2.18822490e-04,
         2.78310599e-05,  0.00000000e+00, -1.50285283e-04,
         0.00000000e+00, -8.06824246e-05,  2.38050823e-04,
        -2.41442031e-05,  3.32571100e-04, -2.85175658e-04]], dtype=float32)>, <tf.Tensor: shape=(30, 30), dtype=float32, numpy=
array([[-2.85438146e-05,  2.64592636e-05, -5.03687374e-07,
         1.62890123e-04,  6.01679176e-06,  1.73943954e-06,
         4.70115010e-05, -1.14361457e-04,  2.05782257e-04,
        -1.09311361e-06, -1.23162340e-06,  5.56463128e-05,
         0.00000000e+00,  1.40511809e-04, -2.25049508e-08,
         9.94481297e-07,  3.52427014e-05,  2.82454479e-04,
         8.38190317e-05, -2.09976679e-06, -5.08522025e-05,
         1.03363964e-05,  6.47417892e-07, -5.79412299e-05,
         0.00000000e+00, -5.34233141e-06,  2.35458065e-04,
         2.04589538e-04,  2.60186731e-04, -4.01515754e-05],
       [-9.33114643e-06,  1.63720746e-04, -1.07416759e-06,
         1.00927726e-04,  5.35402287e-05,  5.86585142e-04,
         9.36424622e-05,  3.06990344e-09,  1.36409358e-06,
         0.00000000e+00,  0.00000000e+00, -9.60478326e-04,
        -1.08925815e-06,  2.57204852e-06, -8.83716439e-06,
        -1.39412941e-06, -2.03708420e-04,  1.29924229e-04,
         5.76043249e-08, -1.06606746e-09,  8.50871846e-04,
         2.36972439e-04,  0.00000000e+00, -2.06758603e-04,
         0.00000000e+00, -2.55154504e-04,  5.23491937e-04,
         1.16092197e-04,  5.76862483e-04, -7.36033020e-04],
       [-2.06545610e-05,  1.97624558e-05,  1.14693691e-07,
         1.25589751e-04,  5.26775557e-06, -7.13697489e-07,
         4.10117209e-05, -9.95715527e-05,  1.60084834e-04,
        -3.03675597e-06, -2.52489514e-07,  4.01762773e-05,
         0.00000000e+00,  1.13141621e-04, -7.37253600e-08,
         4.87748594e-06,  2.01425919e-05,  2.33540661e-04,
         6.41393999e-05,  2.53303097e-06, -5.03226584e-05,
         1.00081315e-05,  3.46219758e-06, -5.40534893e-05,
         0.00000000e+00,  3.78277923e-06,  1.74649031e-04,
         1.66843485e-04,  2.08378508e-04, -2.85022779e-05],
       [ 1.50825485e-07,  7.60103358e-05, -5.54249993e-07,
         3.08931958e-05,  4.07702246e-05,  2.19441150e-04,
         1.34539165e-04, -2.39491129e-07,  1.31262891e-06,
         0.00000000e+00,  4.38830139e-10, -6.91009627e-04,
        -5.20379956e-07,  2.88175693e-06, -4.25947746e-06,
        -5.53650864e-07, -7.70470142e-05,  8.98537764e-05,
         1.04537276e-06,  5.86914162e-09,  4.81140974e-04,
         9.57797311e-05,  0.00000000e+00, -2.00444949e-04,
         0.00000000e+00, -1.79685274e-04,  4.40357951e-04,
         5.08763042e-05,  5.47267322e-04, -5.23460563e-04],
       [-3.47013047e-05,  8.36977051e-06,  7.59641878e-08,
         5.88788680e-05,  4.94810365e-06,  1.16118883e-07,
         5.70958036e-06, -3.63976724e-05,  5.49462166e-05,
        -2.00326303e-06, -1.44396761e-08,  1.99768328e-05,
         0.00000000e+00,  6.25177563e-05, -5.69909027e-08,
         2.93648372e-06,  2.79974938e-05,  8.99446750e-05,
         2.87850053e-05,  1.16998046e-06, -1.73705266e-05,
         4.66625625e-06,  2.10987696e-06,  1.50900878e-05,
         0.00000000e+00,  4.28690072e-07,  6.12080257e-05,
         9.40249447e-05,  6.54700125e-05, -8.40770463e-06],
       [-3.19595620e-06,  4.89457489e-06, -4.86553120e-07,
         1.03923358e-05,  1.94484392e-06,  3.28456154e-05,
        -4.34699814e-06, -1.20333198e-06,  7.96580935e-06,
        -1.73944041e-08,  0.00000000e+00, -3.50328010e-05,
        -4.44085764e-08,  5.39295388e-06, -4.60670390e-06,
        -5.17294779e-07, -1.11559111e-05,  1.50598607e-05,
         4.91418859e-07,  2.69908639e-07,  5.57330459e-05,
         2.01262337e-05,  1.78272543e-08, -3.80662300e-06,
         0.00000000e+00, -1.34749180e-05,  4.07291009e-05,
         1.33701833e-05,  3.64664629e-05, -5.69264521e-05],
       [-1.19633878e-05,  2.74127902e-04, -7.95529957e-07,
         1.66149955e-04,  7.53415079e-05,  8.30285600e-04,
         2.00847397e-04, -2.28587744e-08,  1.18084063e-06,
         0.00000000e+00,  0.00000000e+00, -1.50481670e-03,
        -5.16881016e-07,  7.85253087e-06, -1.26873047e-05,
        -1.05542574e-06, -2.50011974e-04,  2.11493156e-04,
        -2.95257053e-07,  0.00000000e+00,  1.30569830e-03,
         3.91766313e-04,  0.00000000e+00, -3.25704255e-04,
         0.00000000e+00, -4.04286722e-04,  8.12511018e-04,
         1.73708017e-04,  9.12379997e-04, -1.13922928e-03],
       [-3.96953965e-06,  1.76533402e-04, -9.01649400e-07,
         1.28276777e-04,  4.63813303e-05,  5.55955805e-04,
         1.12752576e-04, -1.70742993e-08,  1.07239873e-06,
         0.00000000e+00,  0.00000000e+00, -9.36453580e-04,
        -2.36613445e-07,  3.61465572e-06, -9.01194107e-06,
        -1.14490399e-06, -1.75788067e-04,  1.37809970e-04,
        -1.46165462e-07, -9.29829440e-08,  8.47843359e-04,
         2.55848223e-04,  0.00000000e+00, -2.04279480e-04,
         0.00000000e+00, -2.56480474e-04,  5.13135456e-04,
         1.08562963e-04,  5.54714119e-04, -7.21292396e-04],
       [-3.17730155e-06,  1.27555380e-04, -7.30010470e-07,
         7.99236441e-05,  4.32192901e-05,  4.36888542e-04,
         8.90139490e-05, -8.50049986e-09,  1.45932302e-06,
         0.00000000e+00,  0.00000000e+00, -7.38716277e-04,
        -9.24562642e-07,  3.01014097e-06, -7.18771116e-06,
        -1.08220320e-06, -1.46865321e-04,  1.01126330e-04,
        -9.14372720e-08,  0.00000000e+00,  6.37483376e-04,
         1.82082251e-04,  0.00000000e+00, -1.69534382e-04,
         0.00000000e+00, -1.96181703e-04,  3.95225827e-04,
         9.23296029e-05,  4.43431956e-04, -5.30397112e-04],
       [-3.67166795e-05,  3.08917515e-05, -2.26572240e-07,
         1.38287156e-04,  1.49200041e-05, -3.17935928e-06,
         3.23292334e-05, -9.49744863e-05,  1.63419289e-04,
        -1.07929270e-06, -2.49978314e-07,  6.74098192e-05,
         0.00000000e+00,  1.46397288e-04, -1.04605988e-07,
         1.42617523e-06,  2.14475058e-05,  3.00648593e-04,
         8.02786744e-05, -2.54478152e-07, -6.98658841e-05,
         1.29746604e-05,  1.09269649e-06, -2.67674095e-05,
         0.00000000e+00,  9.94700986e-06,  1.84320204e-04,
         2.22906136e-04,  2.22613424e-04, -2.39187848e-05],
       [-5.18052957e-06,  7.92593200e-05, -7.86155567e-08,
         4.09569730e-05,  1.34214242e-05,  2.16514381e-04,
         4.99866474e-05,  1.38036080e-06,  2.44951684e-06,
        -1.78296273e-06, -3.82602650e-07, -3.12632066e-04,
         0.00000000e+00,  2.73018532e-06, -1.90907645e-06,
         2.32532966e-06, -4.84680204e-05,  4.67000900e-05,
         2.77838831e-06,  5.80115625e-07,  2.80106789e-04,
         9.29222078e-05,  1.53056214e-06, -5.06490069e-05,
         0.00000000e+00, -8.28980192e-05,  1.39187119e-04,
         4.26518927e-05,  1.35235037e-04, -2.10805214e-04],
       [-1.47157434e-05,  1.60934971e-04, -7.44077056e-07,
         1.13006477e-04,  3.35111108e-05,  6.05489942e-04,
         2.84876514e-05, -1.76518284e-08,  1.16729018e-06,
         0.00000000e+00,  0.00000000e+00, -7.37079477e-04,
        -6.59341765e-07,  4.83323856e-06, -1.04681512e-05,
        -8.20335060e-07, -1.89491489e-04,  9.54772404e-05,
        -6.97408780e-08,  0.00000000e+00,  7.61506089e-04,
         2.49761302e-04,  0.00000000e+00, -1.09858702e-04,
         0.00000000e+00, -2.00519338e-04,  3.16371705e-04,
         1.16315146e-04,  3.27205809e-04, -5.41185844e-04],
       [-8.36056006e-06,  1.28856787e-04, -1.20914615e-06,
         6.63821338e-05,  3.37106430e-05,  4.57391026e-04,
         5.82456414e-05, -2.36688393e-08,  1.58710213e-06,
         0.00000000e+00,  0.00000000e+00, -6.86089159e-04,
        -5.34140383e-07,  5.53247855e-06, -1.03710054e-05,
        -1.84459236e-06, -1.40671385e-04,  8.35812025e-05,
        -1.82982461e-07,  0.00000000e+00,  6.37039077e-04,
         2.07438585e-04,  0.00000000e+00, -1.17660020e-04,
         0.00000000e+00, -1.77107155e-04,  3.08075658e-04,
         1.00226032e-04,  3.72588576e-04, -5.11927006e-04],
       [-7.97594475e-06,  4.83890763e-05, -3.59530432e-08,
         3.98617267e-05,  1.34326892e-05,  2.63318623e-04,
        -1.07788255e-05,  1.36439766e-07,  4.78758182e-07,
        -2.01619898e-07,  0.00000000e+00, -2.44148338e-04,
        -1.77743917e-08,  1.29918840e-06, -4.81377037e-06,
         2.49636031e-07, -8.76260019e-05,  1.68759889e-05,
         5.51896733e-07,  1.35419938e-07,  2.73847778e-04,
         8.44359092e-05,  2.31822753e-07, -2.08916790e-05,
         0.00000000e+00, -6.29446076e-05,  6.39277787e-05,
         4.85600140e-05,  7.60986150e-05, -1.53403133e-04],
       [-1.31323795e-05,  1.58173119e-04, -6.39183440e-07,
         1.01511621e-04,  3.70752496e-05,  5.35019790e-04,
         6.67889835e-05, -1.01287645e-08,  1.06844436e-06,
         0.00000000e+00,  0.00000000e+00, -7.87345576e-04,
        -4.39102990e-07,  4.95968743e-06, -8.44044371e-06,
        -9.80055802e-07, -1.61286822e-04,  9.77212476e-05,
        -1.77344802e-07, -4.11440076e-10,  7.54374196e-04,
         2.37966087e-04,  0.00000000e+00, -1.45394602e-04,
         0.00000000e+00, -2.10763814e-04,  3.68358305e-04,
         1.03952880e-04,  4.24250524e-04, -5.94685320e-04],
       [-6.64143909e-06,  2.71028490e-04, -9.16112128e-07,
         1.47609084e-04,  8.26339019e-05,  8.09948309e-04,
         2.29237703e-04, -1.20186145e-08,  1.53535905e-06,
         0.00000000e+00,  0.00000000e+00, -1.55855226e-03,
        -1.04484502e-06,  6.62809907e-06, -1.00695743e-05,
        -1.58474461e-06, -2.54346989e-04,  2.24838761e-04,
        -6.36181028e-08,  0.00000000e+00,  1.28950435e-03,
         3.63573694e-04,  0.00000000e+00, -3.52353614e-04,
         0.00000000e+00, -4.12349124e-04,  8.70541553e-04,
         1.67777427e-04,  9.67947650e-04, -1.17273116e-03],
       [-5.60291073e-06,  1.85293466e-04, -1.85988631e-06,
         6.23762462e-05,  6.41644147e-05,  5.28620614e-04,
         2.02590352e-04, -1.87654674e-08,  2.09895757e-06,
         0.00000000e+00,  0.00000000e+00, -1.18256360e-03,
        -9.93775302e-07,  6.51420169e-06, -1.03302318e-05,
        -2.11167298e-06, -1.50718071e-04,  1.40260934e-04,
        -1.04887818e-07,  0.00000000e+00,  8.93931487e-04,
         2.42306633e-04,  0.00000000e+00, -2.74265360e-04,
         0.00000000e+00, -2.96328537e-04,  6.31386065e-04,
         1.20055018e-04,  7.87519151e-04, -8.52195721e-04],
       [-1.96452202e-05,  1.99483748e-05, -3.57242982e-07,
         1.04213716e-04,  8.04896445e-06,  1.56160274e-06,
         3.10560099e-05, -7.74085493e-05,  1.29902779e-04,
        -2.05602214e-06, -7.64645279e-07,  3.72865397e-05,
         0.00000000e+00,  1.03738465e-04, -5.66443958e-08,
         3.95428378e-06,  2.53250419e-05,  2.03522330e-04,
         5.18765737e-05,  2.95131258e-07, -4.21848963e-05,
         8.02106661e-06,  2.19083699e-06, -2.68128479e-05,
         0.00000000e+00,  2.31708100e-06,  1.50661988e-04,
         1.55780130e-04,  1.71684645e-04, -2.42722199e-05],
       [-5.90365744e-06,  8.80967564e-05,  1.04612177e-08,
         5.06074139e-05,  2.46363343e-05,  2.59987457e-04,
         7.40407850e-05,  5.58146667e-07,  1.05499555e-06,
        -1.02501758e-06,  0.00000000e+00, -4.83679294e-04,
         0.00000000e+00,  3.08001268e-06, -1.93851793e-06,
         9.78544676e-07, -7.01410827e-05,  5.24528259e-05,
         8.99509530e-07,  6.50311790e-07,  4.07589716e-04,
         1.23092279e-04,  1.08960853e-06, -1.00420999e-04,
         0.00000000e+00, -1.21377190e-04,  2.30098551e-04,
         4.97439942e-05,  2.89508258e-04, -3.49403446e-04],
       [-1.90611936e-05,  2.34443451e-05, -3.31342420e-07,
         1.28479252e-04,  8.70997519e-06, -7.68511541e-07,
         3.79279845e-05, -9.98863688e-05,  1.64534023e-04,
        -1.10428903e-06, -5.61867409e-07,  4.82493451e-05,
         0.00000000e+00,  1.20335280e-04, -3.71324802e-08,
         2.79341430e-06,  1.96881465e-05,  2.54031940e-04,
         7.02915277e-05, -1.69529443e-07, -5.29372119e-05,
         9.61211299e-06,  1.31127581e-06, -5.25527976e-05,
         0.00000000e+00,  1.62848971e-06,  1.81885800e-04,
         1.80466624e-04,  2.18902496e-04, -2.89969030e-05],
       [-7.05430330e-06,  1.61244694e-04,  0.00000000e+00,
         1.01133817e-04,  4.30063701e-05,  5.25128387e-04,
         8.97287609e-05,  1.18336104e-07,  4.51533708e-07,
        -2.84645507e-09,  0.00000000e+00, -7.87642959e-04,
        -1.98761342e-07,  3.69941608e-06, -4.22312723e-06,
        -7.63830599e-09, -1.65588135e-04,  1.08058113e-04,
        -1.55062736e-08,  7.66531230e-08,  7.05766492e-04,
         2.22332019e-04,  4.41630625e-08, -1.49396132e-04,
         0.00000000e+00, -2.05921315e-04,  3.75688862e-04,
         1.07561005e-04,  4.02557111e-04, -5.49715362e-04],
       [-6.93358561e-06,  1.41668745e-04, -5.43729925e-07,
         7.01542376e-05,  2.96183644e-05,  4.06876963e-04,
         8.65865295e-05, -1.81218489e-08,  5.54223732e-07,
         0.00000000e+00,  0.00000000e+00, -6.72576658e-04,
        -1.78510291e-07,  5.67804682e-06, -6.28118823e-06,
        -7.25559062e-07, -1.06341962e-04,  9.17110010e-05,
        -3.03121880e-07,  0.00000000e+00,  5.95843710e-04,
         1.93998014e-04,  0.00000000e+00, -1.24718790e-04,
         0.00000000e+00, -1.82453485e-04,  3.19854502e-04,
         9.54786592e-05,  3.61825427e-04, -4.83753742e-04],
       [-1.03544480e-05,  2.14370557e-05, -8.73348682e-08,
         1.92863208e-05,  7.42343627e-06,  6.52375966e-05,
         5.55478164e-06, -5.49074173e-07,  3.86565125e-06,
        -1.03149782e-08,  0.00000000e+00, -1.35337206e-04,
         0.00000000e+00,  5.85101088e-06, -2.75096181e-06,
        -3.76740672e-07, -1.98154848e-05,  2.56106541e-05,
         3.82966391e-06, -2.67516924e-08,  1.38273885e-04,
         4.16378934e-05,  1.79179942e-08, -2.25736658e-05,
         0.00000000e+00, -3.85469102e-05,  7.91606799e-05,
         2.32267193e-05,  1.14845570e-04, -1.46210121e-04],
       [-9.99882286e-06,  3.61981482e-04, -6.69718020e-07,
         1.95675340e-04,  9.67268206e-05,  1.07787480e-03,
         2.74743099e-04, -1.76530630e-08,  8.32460387e-07,
         0.00000000e+00,  0.00000000e+00, -1.92120485e-03,
        -5.66556537e-07,  1.01175274e-05, -9.72022553e-06,
        -1.41963687e-06, -3.13714176e-04,  2.61194189e-04,
        -5.29265037e-07,  0.00000000e+00,  1.62150443e-03,
         4.85486933e-04,  0.00000000e+00, -3.99068434e-04,
         0.00000000e+00, -5.05415141e-04,  9.80476034e-04,
         2.31555823e-04,  1.11060892e-03, -1.37951388e-03],
       [-2.63342426e-05,  1.70811654e-05, -5.29503268e-07,
         6.59912039e-05,  9.92835703e-06,  2.36482924e-06,
         7.47249305e-06, -3.82309991e-05,  6.87731372e-05,
        -6.24559959e-08,  3.62926023e-09,  3.86775682e-05,
        -2.50839776e-07,  7.63988064e-05, -2.98918417e-06,
        -4.05348828e-07,  1.05438667e-05,  1.49642001e-04,
         4.10728462e-05, -1.38622227e-06, -3.20350009e-05,
         8.28766133e-06,  0.00000000e+00,  3.70831117e-06,
         0.00000000e+00,  3.55093107e-06,  8.30663412e-05,
         1.22867088e-04,  1.00555735e-04, -1.27546409e-05],
       [-6.38303827e-05,  3.36541671e-05, -3.00938268e-07,
         1.74477813e-04,  1.05994995e-05, -3.08171843e-06,
         3.35578588e-05, -1.18290394e-04,  1.98384747e-04,
        -4.18643651e-07, -8.11851123e-07,  6.34874305e-05,
         0.00000000e+00,  1.69316016e-04, -1.10998180e-08,
         6.16486545e-07,  5.30767284e-05,  3.16324848e-04,
         9.84759681e-05, -8.25298002e-07, -6.40440921e-05,
         1.47170649e-05,  4.65206540e-07, -1.67317485e-05,
         0.00000000e+00, -3.26779764e-06,  2.10649276e-04,
         2.61768932e-04,  2.54890707e-04, -3.12667071e-05],
       [-1.20047735e-05,  2.37991684e-04, -3.44321307e-07,
         1.58038427e-04,  5.16760774e-05,  7.28689833e-04,
         1.09321758e-04, -1.55702864e-08,  2.95772935e-07,
        -3.20531690e-09,  0.00000000e+00, -1.09651336e-03,
        -1.41951787e-07,  6.86252179e-06, -9.17670604e-06,
        -8.44903013e-07, -2.13277817e-04,  1.61304895e-04,
        -3.52012961e-07,  5.16871257e-09,  1.03735738e-03,
         3.44383065e-04,  8.45751380e-09, -2.04876458e-04,
         0.00000000e+00, -3.03231471e-04,  5.46413765e-04,
         1.57945644e-04,  5.75748272e-04, -8.22297705e-04],
       [ 3.30192634e-05,  8.27484837e-06, -8.82996858e-08,
         3.21397965e-05, -1.10928204e-06,  4.05714090e-05,
         8.47109914e-06, -3.06183501e-05,  5.47440359e-05,
        -2.16734111e-06,  1.32928388e-08, -1.03884713e-06,
         0.00000000e+00,  2.71547378e-06, -5.20884271e-07,
         2.21969708e-06, -3.80621059e-05,  4.64495497e-05,
         8.90583851e-06,  1.63197467e-06,  1.75982350e-05,
         2.27344899e-05,  2.30759110e-06, -5.70921256e-05,
         0.00000000e+00, -1.03881177e-06,  4.28659805e-05,
         1.25760089e-05,  5.80359483e-05, -6.17160822e-06],
       [-1.06099851e-05,  2.21947139e-05, -6.47632419e-07,
         1.24770449e-04,  5.23574454e-06, -3.27681028e-06,
         4.45932528e-05, -9.85111037e-05,  1.61971984e-04,
        -1.03180253e-06,  4.32392833e-09,  4.72059146e-05,
         0.00000000e+00,  1.08987224e-04, -1.77388802e-06,
        -1.30935234e-07,  3.35305458e-06,  2.42848910e-04,
         6.84155675e-05,  1.04749665e-06, -5.18415109e-05,
         9.53284598e-06,  6.24252436e-07, -6.57987330e-05,
         0.00000000e+00,  2.45658384e-06,  1.82989272e-04,
         1.57372240e-04,  2.12410712e-04, -3.05003650e-05],
       [ 4.43577337e-05,  1.17830550e-05, -5.09713402e-07,
         4.85699456e-05, -4.66649590e-06,  9.43937921e-05,
         5.29065073e-06, -4.42319870e-05,  8.72403180e-05,
        -2.19300910e-06, -5.75401486e-07,  6.30757449e-06,
         0.00000000e+00,  3.85179465e-06, -1.55732732e-06,
         2.82003566e-06, -6.64074905e-05,  5.91408934e-05,
         1.40391930e-05,  1.45935905e-06,  4.58578434e-05,
         2.64607334e-05,  1.94372933e-06, -7.73262727e-05,
         0.00000000e+00, -2.26643988e-06,  5.31368933e-05,
         9.87605381e-06,  6.44252432e-05, -1.80580246e-05]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([-3.0835916e-05,  1.6434632e-04, -2.7959727e-06,  1.6503816e-04,
        3.6937556e-05,  6.4492272e-04,  7.7483441e-05, -6.5972600e-08,
        3.5691012e-06,  0.0000000e+00,  0.0000000e+00, -7.9120818e-04,
       -7.9420141e-07,  6.8035765e-06, -2.6057169e-05, -5.3336139e-06,
       -2.0090230e-04,  1.1380133e-04,  2.7239512e-06,  0.0000000e+00,
        9.0579654e-04,  3.2129136e-04,  0.0000000e+00, -1.4630595e-04,
        0.0000000e+00, -1.8658096e-04,  4.2705206e-04,  8.0913931e-05,
        3.9941713e-04, -6.2667363e-04,  9.1777154e-05, -2.3261156e-05,
       -2.4266095e-07, -1.6245568e-04, -2.2954824e-05,  6.2200616e-06,
       -2.8085340e-05,  6.8316163e-05, -1.7078627e-04,  2.5817985e-06,
        1.0620094e-07, -7.9300698e-05,  0.0000000e+00, -1.5733445e-04,
        1.6969803e-07, -5.8053174e-06, -7.1462906e-05, -2.6524792e-04,
       -9.9871831e-05, -2.7855795e-06,  5.5098531e-05, -1.2982020e-05,
       -2.9544190e-06, -1.3465305e-05,  0.0000000e+00, -1.3427774e-05,
       -1.6420375e-04, -2.2261392e-04, -2.0622426e-04,  2.1576559e-05],
      dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[-1.1460271e-03,  1.1733845e-06,  7.9718151e-04, ...,
         6.3461671e-04,  8.3840941e-04,  2.1309954e-04],
       [-2.7127651e-05,  2.4716275e-07,  1.4293630e-05, ...,
         2.5032543e-05,  1.7355103e-05,  1.7478890e-06],
       [-6.3719816e-04,  1.7718247e-07,  8.4235036e-04, ...,
         5.7187607e-04,  6.8720855e-04,  2.6522783e-04],
       ...,
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(60, 30), dtype=float32, numpy=
array([[ 1.7838758e-08, -4.5954986e-04,  1.4629848e-07, ...,
        -8.3462801e-05, -5.0671201e-07,  4.7399200e-05],
       [ 6.4970983e-08, -1.3216427e-05, -1.1072891e-08, ...,
        -1.7855384e-06, -1.7128752e-06,  3.6811646e-06],
       [ 9.4081656e-08, -2.7114982e-04, -7.3326206e-08, ...,
        -1.4130710e-05, -2.4872709e-06,  2.2459511e-05],
       ...,
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(60,), dtype=float32, numpy=
array([-5.5222795e-04,  2.0974462e-06,  3.4907047e-04,  2.1439962e-05,
        1.5149129e-04,  5.5995799e-05,  0.0000000e+00, -1.8032043e-07,
        0.0000000e+00,  1.3489202e-04, -1.4138409e-05,  0.0000000e+00,
        0.0000000e+00, -9.9226445e-06, -2.4276784e-07,  0.0000000e+00,
        0.0000000e+00,  4.2662185e-04, -1.7638728e-05,  3.0481850e-04,
       -5.1153302e-07,  0.0000000e+00,  1.8085405e-04,  0.0000000e+00,
       -3.0990673e-04, -5.4191553e-04, -9.1110235e-07,  3.0679771e-04,
        3.8486032e-04,  8.7585322e-05, -1.5572923e-07,  2.2918773e-04,
        5.9347769e-07,  2.0325222e-04,  1.5053337e-06, -2.1789090e-05,
        2.1316699e-04,  4.8442680e-04, -2.6232624e-04,  1.7919815e-07,
       -5.3677434e-04, -2.5765283e-04, -3.7041507e-04, -1.8597610e-04,
        4.3468815e-04, -1.7126238e-04, -3.9300666e-04,  0.0000000e+00,
       -3.0978260e-04,  1.0877491e-06,  2.8431613e-04,  1.1361423e-04,
        2.3151535e-04, -2.9395617e-04,  1.0654612e-06,  0.0000000e+00,
        3.4227830e-04,  4.3086453e-05,  2.8969578e-06, -1.8270670e-05],
      dtype=float32)>]
[Actor] Episode 0 Step 1 Loss: 2698.14892578125
2021-03-29 14:39:55.225269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:19402): Gdk-CRITICAL **: 14:39:59.202: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 14:39:59.558345: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:39:59.559573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 14:39:59.610744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.611419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:39:59.611462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:39:59.614566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:39:59.614712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:39:59.616069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:39:59.616442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:39:59.619693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:39:59.620479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:39:59.620720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:39:59.620897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.621643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.622252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 14:39:59.810709: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 14:39:59.810988: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:39:59.811293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.812093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:39:59.812137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:39:59.812358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:39:59.812436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:39:59.812492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:39:59.812541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:39:59.812594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:39:59.812671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:39:59.812733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:39:59.812922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.813708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:39:59.814467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 14:39:59.814514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:40:00.523429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 14:40:00.523500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 14:40:00.523514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 14:40:00.523893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:00.524721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:00.525417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:00.526067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 14:40:20.647825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:19653): Gdk-CRITICAL **: 14:40:24.423: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 14:40:24.688179: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:40:24.689572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 14:40:24.782917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:24.783760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:40:24.783812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:40:24.787716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:40:24.787885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:40:24.789374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:40:24.789818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:40:24.793638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:40:24.803185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:40:24.804048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:40:24.804235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:24.805660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:24.806341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 14:40:25.074346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 14:40:25.074773: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 14:40:25.075226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.076482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 14:40:25.076648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:40:25.076920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:40:25.077147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 14:40:25.077458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 14:40:25.077624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 14:40:25.077773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 14:40:25.077927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 14:40:25.078091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 14:40:25.078479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.079599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.080561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 14:40:25.080686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 14:40:25.825394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 14:40:25.825437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 14:40:25.825448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 14:40:25.825772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.826638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.827374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 14:40:25.827953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617028828.838800200, 33213.782000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617028828.839713813, 33213.782000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617028828.839821680, 33213.783000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617028830.038115429, 33214.979000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617028830.379071870, 33215.319000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617028830.784064317, 33215.720000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617028831.183867465, 33216.119000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 14:40:58.617996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 14:40:59.215671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 0.784602165222168
[Actor] Episode 0 Step 1 Loss: 2634.07470703125
[Actor] Episode 0 Step 2 Loss: 2882.213623046875
[Actor] Episode 0 Step 3 Loss: 2885.42236328125
[Actor] Episode 0 Step 4 Loss: 2890.66357421875
[Actor] Episode 0 Step 5 Loss: 2847.603515625
[Actor] Episode 0 Step 6 Loss: 2777.171630859375
[Actor] Episode 0 Step 7 Loss: 2774.152587890625
[Actor] Episode 0 Step 8 Loss: 2805.965087890625
[Actor] Episode 0 Step 9 Loss: 2545.5986328125
[Actor] Episode 0 Step 10 Loss: 3014.769775390625
[Actor] Episode 0 Step 11 Loss: 2892.41162109375
[Actor] Episode 0 Step 12 Loss: 2542.205322265625
[Actor] Episode 0 Step 13 Loss: 2707.935546875
[Actor] Episode 0 Step 14 Loss: 2685.337646484375
[Actor] Episode 0 Step 15 Loss: 2721.126708984375
[Actor] Episode 0 Step 16 Loss: 2641.05322265625
[Actor] Episode 0 Step 17 Loss: 2854.169677734375
[Actor] Episode 0 Step 18 Loss: 2646.73095703125
[Actor] Episode 0 Step 19 Loss: 2868.75537109375
[Actor] Episode 0 Step 20 Loss: 3200.611328125
[Actor] Episode 0 Step 21 Loss: 2747.690673828125
[Actor] Episode 0 Step 22 Loss: 2706.9228515625
[Actor] Episode 0 Step 23 Loss: 2649.318359375
[Actor] Episode 0 Step 24 Loss: 2812.113037109375
[Actor] Episode 0 Step 25 Loss: 2825.734619140625
[Actor] Episode 0 Step 26 Loss: 2695.005615234375
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2676.131209585402
[Actor] Learning Rate: 0.0009957347065210342
[Actor] Epoch Time: 1291.8839199543s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 2656.661865234375
[Actor] Episode 1 Step 1 Loss: 2711.47265625
[Actor] Episode 1 Step 2 Loss: 2917.884033203125
[Actor] Episode 1 Step 3 Loss: 2664.035400390625
[Actor] Episode 1 Step 4 Loss: 2423.982666015625
[Actor] Episode 1 Step 5 Loss: 2913.22705078125
[Actor] Episode 1 Step 6 Loss: 2503.03662109375
[Actor] Episode 1 Step 7 Loss: 2880.921142578125
[Actor] Episode 1 Step 8 Loss: 2724.920166015625
[Actor] Episode 1 Step 9 Loss: 2744.8984375
[Actor] Episode 1 Step 10 Loss: 2586.8212890625
[Actor] Episode 1 Step 11 Loss: 2832.767578125
[Actor] Episode 1 Step 12 Loss: 2879.869873046875
[Actor] Episode 1 Step 13 Loss: 2668.05615234375
[Actor] Episode 1 Step 14 Loss: 2961.615478515625
[Actor] Episode 1 Step 15 Loss: 2959.102294921875
[Actor] Episode 1 Step 16 Loss: 3012.142578125
[Actor] Episode 1 Step 17 Loss: 2601.85791015625
[Actor] Episode 1 Step 18 Loss: 2599.602783203125
[Actor] Episode 1 Step 19 Loss: 2817.77392578125
[Actor] Episode 1 Step 20 Loss: 2681.587158203125
[Actor] Episode 1 Step 21 Loss: 2874.747314453125
[Actor] Episode 1 Step 22 Loss: 2635.385009765625
[Actor] Episode 1 Step 23 Loss: 2833.231689453125
[Actor] Episode 1 Step 24 Loss: 2938.18798828125
[Actor] Episode 1 Step 25 Loss: 2665.984375
[Actor] Episode 1 Step 26 Loss: 2702.843505859375
-------------------------------------------------
[Actor] Episode 1 Average Loss: 2755.28210901331
[Actor] Learning Rate: 0.0009914875263348222
[Actor] Epoch Time: 1302.9082345962524s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 2677.9375
2021-03-29 15:27:07.982636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:20364): Gdk-CRITICAL **: 15:27:11.554: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:27:12.142353: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:27:12.145682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:27:12.278369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.280129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:27:12.280181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:12.291792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:27:12.291937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:27:12.296219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:27:12.296961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:27:12.306714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:27:12.309722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:27:12.309982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:27:12.310431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.312889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.313949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:27:12.581682: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:27:12.581951: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:27:12.582290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.583567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:27:12.583605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:12.583809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:27:12.583886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:27:12.583949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:27:12.584207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:27:12.584300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:27:12.584360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:27:12.584409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:27:12.584575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.585756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:12.586567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:27:12.586615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:13.384683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:27:13.384727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:27:13.384738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:27:13.385084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:13.385968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:13.386648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:13.387199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 15:27:42.283429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:20612): Gdk-CRITICAL **: 15:27:45.604: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 15:27:46.014410: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:27:46.015525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 15:27:46.085052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.086123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:27:46.086297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:46.091148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:27:46.091420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:27:46.093298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:27:46.093815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:27:46.098365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:27:46.099363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:27:46.099610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:27:46.099811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.100884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.102213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 15:27:46.370150: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 15:27:46.370421: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 15:27:46.370766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.371700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 15:27:46.371780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:46.372015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:27:46.372087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 15:27:46.372145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 15:27:46.372203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 15:27:46.372262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 15:27:46.372321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 15:27:46.372378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 15:27:46.372577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.373530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:46.374290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 15:27:46.374348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 15:27:47.179467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 15:27:47.179510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 15:27:47.179521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 15:27:47.179872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:47.180918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:47.181862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 15:27:47.182667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617031670.266987597, 35656.572000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617031670.267749448, 35656.573000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617031670.267910322, 35656.573000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617031671.468087533, 35657.771000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617031671.777142306, 35658.077000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617031671.976921227, 35658.277000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617031672.377481443, 35658.677000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 15:28:19.768219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 15:28:20.376568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 0.7850146889686584
[Actor] Episode 0 Step 1 Loss: 2807.43408203125
[Actor] Episode 0 Step 2 Loss: 2910.528076171875
[Actor] Episode 0 Step 3 Loss: 2455.925048828125
[Actor] Episode 0 Step 4 Loss: 2783.439697265625
[Actor] Episode 0 Step 5 Loss: 2735.2724609375
[Actor] Episode 0 Step 6 Loss: 2860.247314453125
[Actor] Episode 0 Step 7 Loss: 2770.573974609375
[Actor] Episode 0 Step 8 Loss: 2817.212646484375
[Actor] Episode 0 Step 9 Loss: 2809.62109375
[Actor] Episode 0 Step 10 Loss: 2739.06982421875
[Actor] Episode 0 Step 11 Loss: 2529.164306640625
[Actor] Episode 0 Step 12 Loss: 2652.62841796875
[Actor] Episode 0 Step 13 Loss: 2989.71240234375
[Actor] Episode 0 Step 14 Loss: 2770.28564453125
[Actor] Episode 0 Step 15 Loss: 2638.40380859375
[Actor] Episode 0 Step 16 Loss: 2900.63037109375
[Actor] Episode 0 Step 17 Loss: 2609.089599609375
[Actor] Episode 0 Step 18 Loss: 2813.238037109375
[Actor] Episode 0 Step 19 Loss: 2957.271484375
[Actor] Episode 0 Step 20 Loss: 2710.924072265625
[Actor] Episode 0 Step 21 Loss: 2846.9365234375
[Actor] Episode 0 Step 22 Loss: 3070.658935546875
[Actor] Episode 0 Step 23 Loss: 2844.218994140625
[Actor] Episode 0 Step 24 Loss: 2842.354736328125
[Actor] Episode 0 Step 25 Loss: 2905.108642578125
[Actor] Episode 0 Step 26 Loss: 2795.38916015625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2687.6342359317673
[Actor] Learning Rate: 0.0009957347065210342
[Actor] Epoch Time: 1323.7495000362396s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 2735.359375
[Actor] Episode 1 Step 1 Loss: 2633.061279296875
[Actor] Episode 1 Step 2 Loss: 2710.712890625
[Actor] Episode 1 Step 3 Loss: 2720.76806640625
[Actor] Episode 1 Step 4 Loss: 2659.333251953125
[Actor] Episode 1 Step 5 Loss: 2915.72314453125
[Actor] Episode 1 Step 6 Loss: 2650.26806640625
[Actor] Episode 1 Step 7 Loss: 2767.913818359375
[Actor] Episode 1 Step 8 Loss: 2933.443359375
[Actor] Episode 1 Step 9 Loss: 2887.366943359375
[Actor] Episode 1 Step 10 Loss: 2536.102294921875
[Actor] Episode 1 Step 11 Loss: 2811.71240234375
[Actor] Episode 1 Step 12 Loss: 2874.142333984375
[Actor] Episode 1 Step 13 Loss: 2520.751220703125
[Actor] Episode 1 Step 14 Loss: 2687.927490234375
[Actor] Episode 1 Step 15 Loss: 2697.168212890625
[Actor] Episode 1 Step 16 Loss: 2982.45654296875
[Actor] Episode 1 Step 17 Loss: 2758.6337890625
[Actor] Episode 1 Step 18 Loss: 2728.886962890625
[Actor] Episode 1 Step 19 Loss: 2926.54150390625
[Actor] Episode 1 Step 20 Loss: 2971.284912109375
[Actor] Episode 1 Step 21 Loss: 2540.18701171875
[Actor] Episode 1 Step 22 Loss: 2976.549072265625
[Actor] Episode 1 Step 23 Loss: 2881.11767578125
[Actor] Episode 1 Step 24 Loss: 2785.2275390625
[Actor] Episode 1 Step 25 Loss: 2568.015869140625
[Actor] Episode 1 Step 26 Loss: 2884.242919921875
-------------------------------------------------
[Actor] Episode 1 Average Loss: 2768.3295536747687
[Actor] Learning Rate: 0.0009914875263348222
[Actor] Epoch Time: 1355.8124969005585s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 2575.647216796875
[Actor] Episode 2 Step 1 Loss: 2775.248046875
[Actor] Episode 2 Step 2 Loss: 2752.381591796875
[Actor] Episode 2 Step 3 Loss: 2565.488037109375
[Actor] Episode 2 Step 4 Loss: 2892.7451171875
[Actor] Episode 2 Step 5 Loss: 2756.55322265625
[Actor] Episode 2 Step 6 Loss: 2845.16064453125
[Actor] Episode 2 Step 7 Loss: 2629.129638671875
[Actor] Episode 2 Step 8 Loss: 2901.593994140625
[Actor] Episode 2 Step 9 Loss: 2840.0263671875
[Actor] Episode 2 Step 10 Loss: 2538.029296875
[Actor] Episode 2 Step 11 Loss: 3002.857421875
[Actor] Episode 2 Step 12 Loss: 2557.41552734375
[Actor] Episode 2 Step 13 Loss: 2938.647705078125
[Actor] Episode 2 Step 14 Loss: 2910.64208984375
[Actor] Episode 2 Step 15 Loss: 2728.23779296875
[Actor] Episode 2 Step 16 Loss: 2774.638671875
[Actor] Episode 2 Step 17 Loss: 2867.695556640625
[Actor] Episode 2 Step 18 Loss: 2778.778564453125
[Actor] Episode 2 Step 19 Loss: 2881.791015625
[Actor] Episode 2 Step 20 Loss: 2833.400146484375
[Actor] Episode 2 Step 21 Loss: 2614.19921875
[Actor] Episode 2 Step 22 Loss: 2770.29248046875
[Actor] Episode 2 Step 23 Loss: 2481.44384765625
[Actor] Episode 2 Step 24 Loss: 2786.3779296875
[Actor] Episode 2 Step 25 Loss: 2813.927490234375
[Actor] Episode 2 Step 26 Loss: 2789.439697265625
-------------------------------------------------
[Actor] Episode 2 Average Loss: 2763.029197410301
[Actor] Learning Rate: 0.000987258623354137
[Actor] Epoch Time: 1358.3373234272003s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 2648.734619140625
[Actor] Episode 3 Step 1 Loss: 2597.596923828125
[Actor] Episode 3 Step 2 Loss: 2928.765380859375
[Actor] Episode 3 Step 3 Loss: 2778.327880859375
[Actor] Episode 3 Step 4 Loss: 2708.552001953125
[Actor] Episode 3 Step 5 Loss: 2727.910888671875
[Actor] Episode 3 Step 6 Loss: 2583.744140625
[Actor] Episode 3 Step 7 Loss: 2714.41357421875
[Actor] Episode 3 Step 8 Loss: 2739.4921875
[Actor] Episode 3 Step 9 Loss: 2906.41162109375
[Actor] Episode 3 Step 10 Loss: 2717.77978515625
[Actor] Episode 3 Step 11 Loss: 2698.0751953125
[Actor] Episode 3 Step 12 Loss: 2588.74462890625
[Actor] Episode 3 Step 13 Loss: 2861.548828125
[Actor] Episode 3 Step 14 Loss: 2709.001953125
[Actor] Episode 3 Step 15 Loss: 2739.898193359375
[Actor] Episode 3 Step 16 Loss: 2801.4423828125
[Actor] Episode 3 Step 17 Loss: 2707.47265625
[Actor] Episode 3 Step 18 Loss: 2828.22021484375
[Actor] Episode 3 Step 19 Loss: 3072.884765625
[Actor] Episode 3 Step 20 Loss: 2888.696533203125
[Actor] Episode 3 Step 21 Loss: 2710.633056640625
[Actor] Episode 3 Step 22 Loss: 2832.104248046875
[Actor] Episode 3 Step 23 Loss: 2769.385986328125
[Actor] Episode 3 Step 24 Loss: 2649.1728515625
[Actor] Episode 3 Step 25 Loss: 2518.283203125
[Actor] Episode 3 Step 26 Loss: 2649.31787109375
-------------------------------------------------
[Actor] Episode 3 Average Loss: 2743.5782063802085
[Actor] Learning Rate: 0.000983047648333013
[Actor] Epoch Time: 1361.6841464042664s
-------------------------------------------------
