2021-04-20 07:45:28.364909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:45:40.149619: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-20 07:45:40.151000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-20 07:45:40.184823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.185533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-20 07:45:40.185587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:45:40.195949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-20 07:45:40.196091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-20 07:45:40.198506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-20 07:45:40.198907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-20 07:45:40.207332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-20 07:45:40.210821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-20 07:45:40.211093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-20 07:45:40.211325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.215325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.215996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-20 07:45:40.225302: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-20 07:45:40.225553: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-20 07:45:40.225764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.228517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-20 07:45:40.228628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:45:40.228752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-20 07:45:40.228838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-20 07:45:40.228907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-20 07:45:40.228992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-20 07:45:40.229055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-20 07:45:40.229119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-20 07:45:40.229182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-20 07:45:40.229357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.230102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:40.230757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-20 07:45:40.235466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:45:43.581302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-20 07:45:43.583288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-20 07:45:43.583529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-20 07:45:43.585465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:43.587445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:43.590106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:45:43.592087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8521 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Starting Actor Test
Traceback (most recent call last):
  File "rddpg_v2.py", line 411, in <module>
    learner.pretrain_actor(
  File "rddpg_v2.py", line 358, in pretrain_actor
    self._pretrain_loop(
  File "rddpg_v2.py", line 156, in _pretrain_loop
    self.test_actor(os.path.join(
  File "rddpg_v2.py", line 102, in test_actor
    actions, omega, _ = self.actor.model(x)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 998, in __call__
    input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py", line 204, in assert_input_compatibility
    raise ValueError('Layer ' + layer_name + ' expects ' +
ValueError: Layer model expects 3 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor: shape=(15, 50, 6), dtype=float32, numpy=
array([[[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.020625  ,  0.        ]],

       [[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01756945,  0.        ]],

       [[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.03060484,  0.        ]],

       ...,

       [[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01860294,  0.        ]],

       [[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.02496711,  0.        ]],

       [[ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ],
        ...,
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ],
        [ 0.        , -1.        ,  0.        ,  0.        ,
         -0.01555328,  0.        ]]], dtype=float32)>, <tf.Tensor: shape=(15, 50, 50, 40), dtype=float64, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]],


       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]],


       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]],


       ...,


       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]],


       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]],


       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]])>, <tf.Tensor: shape=(15, 45), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(15, 45), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
      dtype=float32)>, <tf.Tensor: shape=(15, 40), dtype=float32, numpy=
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]
2021-04-20 07:46:59.774626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:47:11.255391: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-20 07:47:11.263944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-20 07:47:11.312503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.315480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-20 07:47:11.315825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:47:11.330743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-20 07:47:11.332125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-20 07:47:11.338354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-20 07:47:11.340294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-20 07:47:11.362101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-20 07:47:11.366077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-20 07:47:11.366442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-20 07:47:11.367389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.370909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.373623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-20 07:47:11.392639: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-20 07:47:11.393898: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-20 07:47:11.395259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.397658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-20 07:47:11.398081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:47:11.398260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-20 07:47:11.399068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-20 07:47:11.399447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-20 07:47:11.399704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-20 07:47:11.400132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-20 07:47:11.400411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-20 07:47:11.400953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-20 07:47:11.402648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.405393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:11.407917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-20 07:47:11.408672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-20 07:47:14.678869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-20 07:47:14.680090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-20 07:47:14.680128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-20 07:47:14.680759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:14.684799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:14.687015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-20 07:47:14.690264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8521 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Starting Actor Test
2021-04-20 07:47:22.091251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-20 07:47:23.880251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Finishing Actor Test
[Actor] Dataset <PrefetchDataset shapes: (((15, 50, 6), (15, 50, 50, 40), (15, 40)), ((15, 50, 50, 12), (15, 50, 1))), types: ((tf.float32, tf.float64, tf.float32), (tf.float32, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
[Actor] Episode 0 Step 0 Loss: 1.4243122339248657
[Actor] Episode 0 Step 1 Loss: 1.7315349578857422
[Actor] Episode 0 Step 2 Loss: 1.3921977281570435
[Actor] Episode 0 Step 3 Loss: 1.0022907257080078
[Actor] Episode 0 Step 4 Loss: 0.6781788468360901
[Actor] Episode 0 Step 5 Loss: 0.5937154293060303
[Actor] Episode 0 Step 6 Loss: 0.35263410210609436
[Actor] Episode 0 Step 7 Loss: 0.2285834401845932
[Actor] Episode 0 Step 8 Loss: 0.2971222996711731
-------------------------------------------------
[Actor] Episode 0 Average Loss: 0.8556188626421822
[Actor] Learning Rate: 0.009872585535049438
[Actor] Epoch Time: 1060.4231264591217s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 0.30454233288764954
[Actor] Episode 1 Step 1 Loss: 0.236516535282135
[Actor] Episode 1 Step 2 Loss: 0.13502851128578186
[Actor] Episode 1 Step 3 Loss: 0.1083466038107872
[Actor] Episode 1 Step 4 Loss: 0.14867839217185974
[Actor] Episode 1 Step 5 Loss: 0.17084960639476776
[Actor] Episode 1 Step 6 Loss: 0.14008896052837372
[Actor] Episode 1 Step 7 Loss: 0.09609154611825943
[Actor] Episode 1 Step 8 Loss: 0.08341735601425171
-------------------------------------------------
[Actor] Episode 1 Average Loss: 0.158173316054874
[Actor] Learning Rate: 0.009746793657541275
[Actor] Epoch Time: 1575.2545111179352s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 0.08711285144090652
[Actor] Episode 2 Step 1 Loss: 0.09316923469305038
[Actor] Episode 2 Step 2 Loss: 0.09565051645040512
[Actor] Episode 2 Step 3 Loss: 0.08699473738670349
[Actor] Episode 2 Step 4 Loss: 0.07311850041151047
[Actor] Episode 2 Step 5 Loss: 0.06724050641059875
[Actor] Episode 2 Step 6 Loss: 0.06368990242481232
[Actor] Episode 2 Step 7 Loss: 0.061908919364213943
[Actor] Episode 2 Step 8 Loss: 0.0675843358039856
-------------------------------------------------
[Actor] Episode 2 Average Loss: 0.07738550048735407
[Actor] Learning Rate: 0.0096226055175066
[Actor] Epoch Time: 1102.9101808071136s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 0.07205193489789963
[Actor] Episode 3 Step 1 Loss: 0.0680679902434349
[Actor] Episode 3 Step 2 Loss: 0.06158619746565819
[Actor] Episode 3 Step 3 Loss: 0.05562498793005943
[Actor] Episode 3 Step 4 Loss: 0.05356679484248161
[Actor] Episode 3 Step 5 Loss: 0.05454634875059128
[Actor] Episode 3 Step 6 Loss: 0.056979525834321976
[Actor] Episode 3 Step 7 Loss: 0.058666061609983444
[Actor] Episode 3 Step 8 Loss: 0.05758761242032051
-------------------------------------------------
[Actor] Episode 3 Average Loss: 0.05985305044386122
[Actor] Learning Rate: 0.009499998763203621
[Actor] Epoch Time: 1130.928361415863s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 0.05586686730384827
[Actor] Episode 4 Step 1 Loss: 0.055236417800188065
[Actor] Episode 4 Step 2 Loss: 0.05228839069604874
[Actor] Episode 4 Step 3 Loss: 0.05063754320144653
[Actor] Episode 4 Step 4 Loss: 0.0513104647397995
[Actor] Episode 4 Step 5 Loss: 0.05228746682405472
[Actor] Episode 4 Step 6 Loss: 0.05297749862074852
[Actor] Episode 4 Step 7 Loss: 0.053228508681058884
[Actor] Episode 4 Step 8 Loss: 0.05326395854353905
-------------------------------------------------
[Actor] Episode 4 Average Loss: 0.053010790712303586
[Actor] Learning Rate: 0.009378955699503422
[Actor] Epoch Time: 1117.2245588302612s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 0.052181486040353775
[Actor] Episode 5 Step 1 Loss: 0.050944920629262924
[Actor] Episode 5 Step 2 Loss: 0.05055836960673332
[Actor] Episode 5 Step 3 Loss: 0.05005871132016182
[Actor] Episode 5 Step 4 Loss: 0.05029577761888504
[Actor] Episode 5 Step 5 Loss: 0.05099513381719589
[Actor] Episode 5 Step 6 Loss: 0.051098987460136414
[Actor] Episode 5 Step 7 Loss: 0.051201947033405304
[Actor] Episode 5 Step 8 Loss: 0.051013365387916565
-------------------------------------------------
[Actor] Episode 5 Average Loss: 0.05092763321267234
[Actor] Learning Rate: 0.009259453974664211
[Actor] Epoch Time: 1106.0104885101318s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 6
[Actor] Episode 6 Step 0 Loss: 0.05038684234023094
[Actor] Episode 6 Step 1 Loss: 0.050233907997608185
[Actor] Episode 6 Step 2 Loss: 0.04975758492946625
[Actor] Episode 6 Step 3 Loss: 0.049911655485630035
[Actor] Episode 6 Step 4 Loss: 0.049965981394052505
[Actor] Episode 6 Step 5 Loss: 0.05007394403219223
[Actor] Episode 6 Step 6 Loss: 0.050378650426864624
[Actor] Episode 6 Step 7 Loss: 0.049962110817432404
[Actor] Episode 6 Step 8 Loss: 0.050053920596838
-------------------------------------------------
[Actor] Episode 6 Average Loss: 0.05008051089114613
[Actor] Learning Rate: 0.009141474962234497
[Actor] Epoch Time: 886.9258494377136s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 7
[Actor] Episode 7 Step 0 Loss: 0.04966871812939644
[Actor] Episode 7 Step 1 Loss: 0.049636099487543106
[Actor] Episode 7 Step 2 Loss: 0.04971076175570488
[Actor] Episode 7 Step 3 Loss: 0.04950389266014099
[Actor] Episode 7 Step 4 Loss: 0.04986413195729256
[Actor] Episode 7 Step 5 Loss: 0.04988756403326988
[Actor] Episode 7 Step 6 Loss: 0.04986405745148659
[Actor] Episode 7 Step 7 Loss: 0.04964768514037132
[Actor] Episode 7 Step 8 Loss: 0.04982108250260353
-------------------------------------------------
[Actor] Episode 7 Average Loss: 0.049733777013089925
[Actor] Learning Rate: 0.009024999104440212
[Actor] Epoch Time: 863.7025148868561s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 8
[Actor] Episode 8 Step 0 Loss: 0.049582671374082565
[Actor] Episode 8 Step 1 Loss: 0.049410682171583176
[Actor] Episode 8 Step 2 Loss: 0.049640338867902756
[Actor] Episode 8 Step 3 Loss: 0.04967104271054268
[Actor] Episode 8 Step 4 Loss: 0.04953961446881294
[Actor] Episode 8 Step 5 Loss: 0.049608319997787476
[Actor] Episode 8 Step 6 Loss: 0.04957088083028793
[Actor] Episode 8 Step 7 Loss: 0.04950132593512535
[Actor] Episode 8 Step 8 Loss: 0.04966774582862854
-------------------------------------------------
[Actor] Episode 8 Average Loss: 0.04957695802052816
[Actor] Learning Rate: 0.008910007774829865
[Actor] Epoch Time: 839.3999953269958s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 9
[Actor] Episode 9 Step 0 Loss: 0.04955839365720749
[Actor] Episode 9 Step 1 Loss: 0.049438558518886566
[Actor] Episode 9 Step 2 Loss: 0.049539923667907715
[Actor] Episode 9 Step 3 Loss: 0.0493287555873394
[Actor] Episode 9 Step 4 Loss: 0.04962731897830963
[Actor] Episode 9 Step 5 Loss: 0.04961175099015236
[Actor] Episode 9 Step 6 Loss: 0.04961014539003372
[Actor] Episode 9 Step 7 Loss: 0.049385640770196915
[Actor] Episode 9 Step 8 Loss: 0.04932401701807976
-------------------------------------------------
[Actor] Episode 9 Average Loss: 0.0494916116197904
[Actor] Learning Rate: 0.008796480484306812
[Actor] Epoch Time: 837.5389683246613s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 10
[Actor] Episode 10 Step 0 Loss: 0.049362726509571075
[Actor] Episode 10 Step 1 Loss: 0.049527887254953384
[Actor] Episode 10 Step 2 Loss: 0.049475155770778656
[Actor] Episode 10 Step 3 Loss: 0.049536749720573425
[Actor] Episode 10 Step 4 Loss: 0.04939483478665352
[Actor] Episode 10 Step 5 Loss: 0.04960068315267563
[Actor] Episode 10 Step 6 Loss: 0.049335312098264694
[Actor] Episode 10 Step 7 Loss: 0.049479275941848755
[Actor] Episode 10 Step 8 Loss: 0.049308158457279205
-------------------------------------------------
[Actor] Episode 10 Average Loss: 0.049446753743622035
[Actor] Learning Rate: 0.008684401400387287
[Actor] Epoch Time: 809.1145012378693s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 11
[Actor] Episode 11 Step 0 Loss: 0.049367211759090424
[Actor] Episode 11 Step 1 Loss: 0.049473829567432404
[Actor] Episode 11 Step 2 Loss: 0.04942001774907112
[Actor] Episode 11 Step 3 Loss: 0.04936157539486885
[Actor] Episode 11 Step 4 Loss: 0.04955199360847473
[Actor] Episode 11 Step 5 Loss: 0.049245961010456085
[Actor] Episode 11 Step 6 Loss: 0.04945620521903038
[Actor] Episode 11 Step 7 Loss: 0.049454670399427414
[Actor] Episode 11 Step 8 Loss: 0.04942237213253975
-------------------------------------------------
[Actor] Episode 11 Average Loss: 0.04941709298226568
[Actor] Learning Rate: 0.008573749102652073
[Actor] Epoch Time: 813.1515793800354s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 12
[Actor] Episode 12 Step 0 Loss: 0.04937500134110451
[Actor] Episode 12 Step 1 Loss: 0.049430571496486664
[Actor] Episode 12 Step 2 Loss: 0.049529027193784714
[Actor] Episode 12 Step 3 Loss: 0.04950476437807083
[Actor] Episode 12 Step 4 Loss: 0.04931981489062309
[Actor] Episode 12 Step 5 Loss: 0.049426548182964325
[Actor] Episode 12 Step 6 Loss: 0.049252402037382126
[Actor] Episode 12 Step 7 Loss: 0.04943779855966568
[Actor] Episode 12 Step 8 Loss: 0.049268703907728195
-------------------------------------------------
[Actor] Episode 12 Average Loss: 0.049393847998645574
[Actor] Learning Rate: 0.008464506827294827
[Actor] Epoch Time: 834.1007390022278s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 13
[Actor] Episode 13 Step 0 Loss: 0.049433670938014984
[Actor] Episode 13 Step 1 Loss: 0.049438778311014175
[Actor] Episode 13 Step 2 Loss: 0.0494961254298687
[Actor] Episode 13 Step 3 Loss: 0.04944882541894913
[Actor] Episode 13 Step 4 Loss: 0.04928457736968994
[Actor] Episode 13 Step 5 Loss: 0.049392618238925934
[Actor] Episode 13 Step 6 Loss: 0.04932526499032974
[Actor] Episode 13 Step 7 Loss: 0.04915736988186836
[Actor] Episode 13 Step 8 Loss: 0.0493994876742363
-------------------------------------------------
[Actor] Episode 13 Average Loss: 0.04937519091698858
[Actor] Learning Rate: 0.00835665687918663
[Actor] Epoch Time: 820.943615436554s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 14
[Actor] Episode 14 Step 0 Loss: 0.04926259070634842
[Actor] Episode 14 Step 1 Loss: 0.049476444721221924
[Actor] Episode 14 Step 2 Loss: 0.049237433820962906
[Actor] Episode 14 Step 3 Loss: 0.04938724264502525
[Actor] Episode 14 Step 4 Loss: 0.049373894929885864
[Actor] Episode 14 Step 5 Loss: 0.04948752745985985
[Actor] Episode 14 Step 6 Loss: 0.04933254420757294
[Actor] Episode 14 Step 7 Loss: 0.049418725073337555
[Actor] Episode 14 Step 8 Loss: 0.049214959144592285
-------------------------------------------------
[Actor] Episode 14 Average Loss: 0.04935459585653411
[Actor] Learning Rate: 0.008250180631875992
[Actor] Epoch Time: 822.9586758613586s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 15
[Actor] Episode 15 Step 0 Loss: 0.04930077865719795
[Actor] Episode 15 Step 1 Loss: 0.04939974471926689
[Actor] Episode 15 Step 2 Loss: 0.04926946014165878
[Actor] Episode 15 Step 3 Loss: 0.04941803961992264
[Actor] Episode 15 Step 4 Loss: 0.04938008263707161
[Actor] Episode 15 Step 5 Loss: 0.049332551658153534
[Actor] Episode 15 Step 6 Loss: 0.04919521138072014
[Actor] Episode 15 Step 7 Loss: 0.04940589889883995
[Actor] Episode 15 Step 8 Loss: 0.04942686855792999
-------------------------------------------------
[Actor] Episode 15 Average Loss: 0.049347626252306834
[Actor] Learning Rate: 0.008145061321556568
[Actor] Epoch Time: 819.7424664497375s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 16
[Actor] Episode 16 Step 0 Loss: 0.04951975494623184
[Actor] Episode 16 Step 1 Loss: 0.04942551255226135
[Actor] Episode 16 Step 2 Loss: 0.04940897971391678
[Actor] Episode 16 Step 3 Loss: 0.04932377487421036
[Actor] Episode 16 Step 4 Loss: 0.04937727376818657
[Actor] Episode 16 Step 5 Loss: 0.0492824912071228
[Actor] Episode 16 Step 6 Loss: 0.04918776825070381
[Actor] Episode 16 Step 7 Loss: 0.04918713867664337
[Actor] Episode 16 Step 8 Loss: 0.049340102821588516
-------------------------------------------------
[Actor] Episode 16 Average Loss: 0.04933919964565171
[Actor] Learning Rate: 0.008041282184422016
[Actor] Epoch Time: 854.1580226421356s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 17
[Actor] Episode 17 Step 0 Loss: 0.04933713749051094
[Actor] Episode 17 Step 1 Loss: 0.049368735402822495
[Actor] Episode 17 Step 2 Loss: 0.04936084523797035
[Actor] Episode 17 Step 3 Loss: 0.049219243228435516
[Actor] Episode 17 Step 4 Loss: 0.049229394644498825
[Actor] Episode 17 Step 5 Loss: 0.049434930086135864
[Actor] Episode 17 Step 6 Loss: 0.049353718757629395
[Actor] Episode 17 Step 7 Loss: 0.04940665885806084
[Actor] Episode 17 Step 8 Loss: 0.04922386631369591
-------------------------------------------------
[Actor] Episode 17 Average Loss: 0.04932605889108446
[Actor] Learning Rate: 0.007938823662698269
[Actor] Epoch Time: 832.0678110122681s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 18
[Actor] Episode 18 Step 0 Loss: 0.04927626997232437
[Actor] Episode 18 Step 1 Loss: 0.04934978112578392
[Actor] Episode 18 Step 2 Loss: 0.04948929324746132
[Actor] Episode 18 Step 3 Loss: 0.04920521005988121
[Actor] Episode 18 Step 4 Loss: 0.04928841441869736
[Actor] Episode 18 Step 5 Loss: 0.049363572150468826
[Actor] Episode 18 Step 6 Loss: 0.049262601882219315
[Actor] Episode 18 Step 7 Loss: 0.04927843064069748
[Actor] Episode 18 Step 8 Loss: 0.049345292150974274
-------------------------------------------------
[Actor] Episode 18 Average Loss: 0.04931765173872312
[Actor] Learning Rate: 0.007837671786546707
[Actor] Epoch Time: 822.4512145519257s
-------------------------------------------------
[Actor] Starting Actor Test
[Actor] Finishing Actor Test
[Actor] Starting Episode 19
