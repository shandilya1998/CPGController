2021-03-28 06:39:14.467728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 06:39:20.924288: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 06:39:20.926839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 06:39:20.995738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:20.996652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 06:39:20.996712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:39:21.028603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 06:39:21.028767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 06:39:21.050428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 06:39:21.057507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 06:39:21.084228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 06:39:21.091065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 06:39:21.093940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 06:39:21.094155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:21.094894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:21.096604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 06:39:21.096896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 06:39:21.097205: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 06:39:21.097359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:21.098051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 06:39:21.098079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:39:21.098178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 06:39:21.098236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 06:39:21.098311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 06:39:21.098386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 06:39:21.098450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 06:39:21.098503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 06:39:21.098550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 06:39:21.098640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:21.099503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:21.100116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 06:39:21.101345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:39:22.818500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 06:39:22.818571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 06:39:22.818587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 06:39:22.821041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:22.821998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:22.822669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:39:22.823344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616913566.293583820, 4.255000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616913566.294520351, 4.256000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616913566.294570800, 4.256000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616913567.469604618, 5.425000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616913568.246083242, 6.200000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616913569.048814679, 7.001000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616913569.856034871, 7.800000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
2021-03-28 06:40:01.911615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 06:40:04.657822: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 06:40:04.659128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 06:40:04.732250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.733246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 06:40:04.733390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:40:04.737223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 06:40:04.737477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 06:40:04.739137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 06:40:04.739616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 06:40:04.743557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 06:40:04.744568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 06:40:04.744892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 06:40:04.745151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.746211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.747116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 06:40:04.747579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 06:40:04.747873: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 06:40:04.748093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.748984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 06:40:04.749090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:40:04.749223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 06:40:04.749349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 06:40:04.749470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 06:40:04.749607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 06:40:04.749729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 06:40:04.749847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 06:40:04.749996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 06:40:04.750177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.751154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:04.752015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 06:40:04.752151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 06:40:05.403329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 06:40:05.403372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 06:40:05.403381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 06:40:05.403701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:05.404436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:05.405073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 06:40:05.405622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616913613.754268585, 1.563000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616913613.755092235, 1.564000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616913613.755147231, 1.564000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616913615.031860403, 2.836000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616913616.001844071, 3.801000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616913616.803118609, 4.600000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616913617.606686151, 5.400000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] Creating Data.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:04<00:00,  4.12s/it]100%|██████████| 1/1 [00:04<00:00,  4.12s/it]
[Actor] Number of Data Points: 135
0it [00:00, ?it/s]1it [00:04,  4.77s/it]2it [00:10,  5.13s/it]3it [00:15,  5.24s/it]4it [00:20,  5.24s/it]5it [00:26,  5.30s/it]6it [00:31,  5.30s/it]7it [00:36,  5.29s/it]8it [00:42,  5.30s/it]9it [00:47,  5.34s/it]10it [00:52,  5.34s/it]11it [00:58,  5.30s/it]12it [01:03,  5.29s/it]13it [01:08,  5.17s/it]14it [01:13,  5.06s/it]15it [01:18,  5.21s/it]16it [01:24,  5.32s/it]17it [01:29,  5.39s/it]18it [01:34,  5.27s/it]19it [01:40,  5.34s/it]20it [01:45,  5.31s/it]21it [01:50,  5.13s/it]22it [01:55,  5.22s/it]23it [02:00,  5.20s/it]24it [02:06,  5.35s/it]25it [02:11,  5.24s/it]26it [02:16,  5.16s/it]27it [02:21,  5.26s/it]28it [02:27,  5.27s/it]29it [02:31,  5.06s/it]30it [02:37,  5.17s/it]31it [02:42,  5.24s/it]32it [02:47,  5.16s/it]33it [02:53,  5.27s/it]34it [02:58,  5.36s/it]35it [03:03,  5.34s/it]36it [03:08,  5.24s/it]37it [03:13,  5.16s/it]38it [03:19,  5.14s/it]39it [03:24,  5.18s/it]40it [03:29,  5.26s/it]41it [03:35,  5.36s/it]42it [03:40,  5.37s/it]43it [03:46,  5.38s/it]44it [03:51,  5.40s/it]45it [03:56,  5.39s/it]46it [04:02,  5.33s/it]47it [04:07,  5.34s/it]48it [04:12,  5.23s/it]49it [04:17,  5.26s/it]50it [04:22,  5.14s/it]51it [04:27,  5.03s/it]52it [04:32,  5.10s/it]53it [04:38,  5.17s/it]54it [04:43,  5.18s/it]55it [04:48,  5.24s/it]56it [04:53,  5.23s/it]57it [04:59,  5.22s/it]58it [05:04,  5.28s/it]59it [05:09,  5.22s/it]60it [05:14,  5.28s/it]61it [05:20,  5.29s/it]62it [05:25,  5.27s/it]63it [05:30,  5.29s/it]64it [05:36,  5.38s/it]65it [05:41,  5.39s/it]66it [05:47,  5.45s/it]67it [05:52,  5.35s/it]68it [05:57,  5.31s/it]69it [06:03,  5.37s/it]70it [06:08,  5.40s/it]71it [06:14,  5.37s/it]72it [06:19,  5.28s/it]73it [06:24,  5.28s/it]74it [06:29,  5.39s/it]75it [06:35,  5.45s/it]76it [06:41,  5.44s/it]77it [06:46,  5.42s/it]78it [06:51,  5.40s/it]79it [06:57,  5.41s/it]80it [07:02,  5.43s/it]81it [07:07,  5.40s/it]82it [07:13,  5.37s/it]83it [07:18,  5.35s/it]84it [07:23,  5.27s/it]85it [07:29,  5.33s/it]86it [07:34,  5.36s/it]87it [07:40,  5.42s/it]88it [07:45,  5.40s/it]89it [07:51,  5.47s/it]90it [07:56,  5.52s/it]91it [08:01,  5.42s/it]92it [08:07,  5.34s/it]93it [08:12,  5.29s/it]94it [08:17,  5.28s/it]95it [08:22,  5.18s/it]96it [08:27,  5.09s/it]97it [08:32,  5.13s/it]98it [08:37,  5.22s/it]99it [08:42,  5.14s/it]100it [08:47,  5.06s/it]101it [08:53,  5.13s/it]102it [08:58,  5.18s/it]103it [09:03,  5.19s/it]104it [09:08,  5.23s/it]105it [09:14,  5.27s/it]106it [09:19,  5.31s/it]107it [09:25,  5.36s/it]108it [09:30,  5.37s/it]109it [09:36,  5.43s/it]110it [09:41,  5.40s/it]111it [09:46,  5.34s/it]112it [09:52,  5.34s/it]113it [09:57,  5.43s/it]114it [10:02,  5.33s/it]115it [10:08,  5.41s/it]116it [10:13,  5.40s/it]117it [10:18,  5.32s/it]118it [10:24,  5.27s/it]119it [10:28,  5.11s/it]120it [10:34,  5.24s/it]121it [10:39,  5.18s/it]122it [10:44,  5.15s/it]123it [10:49,  5.19s/it]124it [10:54,  5.19s/it]125it [10:59,  5.13s/it]126it [11:05,  5.29s/it]127it [11:11,  5.37s/it]128it [11:16,  5.30s/it]129it [11:21,  5.29s/it]130it [11:26,  5.30s/it]131it [11:31,  5.25s/it]132it [11:37,  5.20s/it]133it [11:42,  5.24s/it]134it [11:47,  5.18s/it]135it [11:53,  5.31s/it]135it [11:53,  5.28s/it]
[Actor] Y Shape : (47250, 350, 12)
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <BatchDataset shapes: (((1000, 6), (1000, 34), (1000, 60)), ((1000, 350, 12), (1000, 1), (1000, 12), (1000, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 06:53:06.691336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 06:53:07.932585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 3680.561279296875
[Actor] Episode 0 Step 1 Loss: 3890.193359375
[Actor] Episode 0 Step 2 Loss: 3412.11962890625
[Actor] Episode 0 Step 3 Loss: 2950.73779296875
[Actor] Episode 0 Step 4 Loss: 2794.904052734375
[Actor] Episode 0 Step 5 Loss: 2487.643798828125
[Actor] Episode 0 Step 6 Loss: 2969.366455078125
[Actor] Episode 0 Step 7 Loss: 2402.4287109375
[Actor] Episode 0 Step 8 Loss: 2220.24365234375
[Actor] Episode 0 Step 9 Loss: 2079.886474609375
[Actor] Episode 0 Step 10 Loss: 1828.6473388671875
[Actor] Episode 0 Step 11 Loss: 1889.455810546875
[Actor] Episode 0 Step 12 Loss: 2277.13037109375
[Actor] Episode 0 Step 13 Loss: 2478.652099609375
[Actor] Episode 0 Step 14 Loss: 2502.722900390625
[Actor] Episode 0 Step 15 Loss: 2498.008544921875
[Actor] Episode 0 Step 16 Loss: 2847.295166015625
[Actor] Episode 0 Step 17 Loss: 2576.20751953125
[Actor] Episode 0 Step 18 Loss: 2388.164306640625
[Actor] Episode 0 Step 19 Loss: 2294.8798828125
[Actor] Episode 0 Step 20 Loss: 2047.8931884765625
[Actor] Episode 0 Step 21 Loss: 2072.130126953125
[Actor] Episode 0 Step 22 Loss: 1737.145263671875
[Actor] Episode 0 Step 23 Loss: 1887.7154541015625
[Actor] Episode 0 Step 24 Loss: 1659.3001708984375
[Actor] Episode 0 Step 25 Loss: 1673.681884765625
[Actor] Episode 0 Step 26 Loss: 1428.73291015625
[Actor] Episode 0 Step 27 Loss: 1476.1756591796875
[Actor] Episode 0 Step 28 Loss: 1311.672119140625
[Actor] Episode 0 Step 29 Loss: 1319.6163330078125
[Actor] Episode 0 Step 30 Loss: 1585.1519775390625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 1503.584345391456
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 873.6062080860138s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 2734.730224609375
[Actor] Episode 1 Step 1 Loss: 2470.531982421875
[Actor] Episode 1 Step 2 Loss: 2354.74072265625
[Actor] Episode 1 Step 3 Loss: 2221.3193359375
[Actor] Episode 1 Step 4 Loss: 1961.3463134765625
[Actor] Episode 1 Step 5 Loss: 1975.0428466796875
[Actor] Episode 1 Step 6 Loss: 1895.6373291015625
[Actor] Episode 1 Step 7 Loss: 1672.83203125
[Actor] Episode 1 Step 8 Loss: 1900.268798828125
[Actor] Episode 1 Step 9 Loss: 1863.85498046875
[Actor] Episode 1 Step 10 Loss: 1474.3387451171875
[Actor] Episode 1 Step 11 Loss: 1475.0882568359375
[Actor] Episode 1 Step 12 Loss: 1897.076416015625
[Actor] Episode 1 Step 13 Loss: 2315.108642578125
[Actor] Episode 1 Step 14 Loss: 2161.60302734375
[Actor] Episode 1 Step 15 Loss: 1935.9189453125
[Actor] Episode 1 Step 16 Loss: 2079.56689453125
[Actor] Episode 1 Step 17 Loss: 1892.5584716796875
[Actor] Episode 1 Step 18 Loss: 1718.68017578125
[Actor] Episode 1 Step 19 Loss: 1637.6240234375
[Actor] Episode 1 Step 20 Loss: 1506.84033203125
[Actor] Episode 1 Step 21 Loss: 1496.3314208984375
[Actor] Episode 1 Step 22 Loss: 1502.2752685546875
[Actor] Episode 1 Step 23 Loss: 1401.0010986328125
[Actor] Episode 1 Step 24 Loss: 1222.693115234375
[Actor] Episode 1 Step 25 Loss: 1443.4271240234375
[Actor] Episode 1 Step 26 Loss: 1093.63525390625
[Actor] Episode 1 Step 27 Loss: 1037.8255615234375
[Actor] Episode 1 Step 28 Loss: 974.2298583984375
[Actor] Episode 1 Step 29 Loss: 1177.8662109375
2021-03-28 07:23:48.896842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 07:23:53.048291: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:23:53.051755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 07:23:53.141616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.142507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:23:53.142567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:23:53.146549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:23:53.146684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:23:53.148307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:23:53.148706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:23:53.152799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:23:53.153711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:23:53.153943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:23:53.154212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.155343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.156244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:23:53.156704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 07:23:53.156947: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:23:53.157172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.158055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:23:53.158091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:23:53.158186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:23:53.158293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:23:53.158364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:23:53.158435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:23:53.158514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:23:53.158580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:23:53.158645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:23:53.158768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.159757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:53.160623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:23:53.160677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:23:54.216939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 07:23:54.216989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 07:23:54.217003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 07:23:54.217319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:54.218163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:54.219005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:23:54.219744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-28 07:25:39.101518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 07:25:42.567870: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:25:42.569299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 07:25:42.708722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.710805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:25:42.710973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:25:42.716480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:25:42.716630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:25:42.717909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:25:42.718261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:25:42.721650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:25:42.722441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:25:42.722702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:25:42.722925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.723766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.724580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:25:42.724957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 07:25:42.725197: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:25:42.725409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.726222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:25:42.726255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:25:42.726390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:25:42.726490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:25:42.726582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:25:42.726665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:25:42.726735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:25:42.726812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:25:42.726896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:25:42.727033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.728036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:42.728927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:25:42.728986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:25:43.476897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 07:25:43.476982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 07:25:43.477000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 07:25:43.477359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:43.478227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:43.479008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:25:43.479713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616916347.066968607, 2633.342000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616916347.067811095, 2633.342000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616916347.067891242, 2633.342000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616916348.342694412, 2634.605000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616916348.739343861, 2634.994000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616916349.141207930, 2635.394000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616916349.545012462, 2635.795000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <BatchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 07:26:13.421549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:26:14.091766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2697.745361328125
[Actor] Episode 0 Step 1 Loss: 2727.200439453125
[Actor] Episode 0 Step 2 Loss: 2522.85888671875
[Actor] Episode 0 Step 3 Loss: 2575.9423828125
[Actor] Episode 0 Step 4 Loss: 2178.917236328125
[Actor] Episode 0 Step 5 Loss: 2262.262939453125
[Actor] Episode 0 Step 6 Loss: 2063.69384765625
[Actor] Episode 0 Step 7 Loss: 2083.207763671875
[Actor] Episode 0 Step 8 Loss: 2108.74609375
[Actor] Episode 0 Step 9 Loss: 1904.2633056640625
[Actor] Episode 0 Step 10 Loss: 2220.548583984375
[Actor] Episode 0 Step 11 Loss: 2156.465087890625
[Actor] Episode 0 Step 12 Loss: 1954.0792236328125
[Actor] Episode 0 Step 13 Loss: 1902.3746337890625
[Actor] Episode 0 Step 14 Loss: 1844.7373046875
[Actor] Episode 0 Step 15 Loss: 1834.8760986328125
[Actor] Episode 0 Step 16 Loss: 1952.0162353515625
[Actor] Episode 0 Step 17 Loss: 1772.466064453125
[Actor] Episode 0 Step 18 Loss: 1781.2584228515625
[Actor] Episode 0 Step 19 Loss: 1889.826416015625
[Actor] Episode 0 Step 20 Loss: 1780.91943359375
[Actor] Episode 0 Step 21 Loss: 1835.3519287109375
[Actor] Episode 0 Step 22 Loss: 1815.16845703125
[Actor] Episode 0 Step 23 Loss: 1778.8084716796875
[Actor] Episode 0 Step 24 Loss: 1735.5386962890625
[Actor] Episode 0 Step 25 Loss: 1699.3084716796875
[Actor] Episode 0 Step 26 Loss: 1831.2340087890625
[Actor] Episode 0 Step 27 Loss: 1571.1212158203125
[Actor] Episode 0 Step 28 Loss: 1663.3431396484375
[Actor] Episode 0 Step 29 Loss: 1395.0499267578125
[Actor] Episode 0 Step 30 Loss: 1771.181884765625
[Actor] Episode 0 Step 31 Loss: 1709.0616455078125
[Actor] Episode 0 Step 32 Loss: 1783.337158203125
[Actor] Episode 0 Step 33 Loss: 1646.290283203125
[Actor] Episode 0 Step 34 Loss: 1778.8529052734375
[Actor] Episode 0 Step 35 Loss: 1779.3719482421875
[Actor] Episode 0 Step 36 Loss: 1366.29931640625
[Actor] Episode 0 Step 37 Loss: 1521.920166015625
2021-03-28 07:54:52.363504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 07:54:58.652101: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:54:58.654596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 07:54:58.721507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.722120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:54:58.722145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:54:58.748533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:54:58.748626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:54:58.768893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:54:58.775538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:54:58.800569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:54:58.806918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:54:58.809048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:54:58.809212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.809998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.811723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:54:58.812005: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 07:54:58.812286: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 07:54:58.812423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.813001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 07:54:58.813019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:54:58.813095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:54:58.813133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 07:54:58.813167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 07:54:58.813200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 07:54:58.813233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 07:54:58.813266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 07:54:58.813299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 07:54:58.813380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.814009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:54:58.814558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 07:54:58.815553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 07:55:00.374967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 07:55:00.375008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 07:55:00.375017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 07:55:00.377278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:55:00.378088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:55:00.378767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 07:55:00.379517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616918104.043197360, 3.269000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616918104.044006859, 3.270000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616918104.044062623, 3.270000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616918105.313208483, 4.533000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616918106.186967498, 5.401000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616918106.991465289, 6.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616918107.820000293, 7.001000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <BatchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 07:55:37.222022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 07:55:38.756661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2594.2421875
[Actor] Episode 0 Step 1 Loss: 2793.396240234375
[Actor] Episode 0 Step 2 Loss: 2330.06640625
[Actor] Episode 0 Step 3 Loss: 2749.751220703125
[Actor] Episode 0 Step 4 Loss: 2451.32958984375
[Actor] Episode 0 Step 5 Loss: 2343.047607421875
[Actor] Episode 0 Step 6 Loss: 2278.588623046875
[Actor] Episode 0 Step 7 Loss: 2152.498291015625
[Actor] Episode 0 Step 8 Loss: 2239.195068359375
[Actor] Episode 0 Step 9 Loss: 2100.9140625
[Actor] Episode 0 Step 10 Loss: 2023.0809326171875
[Actor] Episode 0 Step 11 Loss: 2082.239013671875
[Actor] Episode 0 Step 12 Loss: 2169.805419921875
[Actor] Episode 0 Step 13 Loss: 2180.228515625
[Actor] Episode 0 Step 14 Loss: 1873.8009033203125
[Actor] Episode 0 Step 15 Loss: 1976.51513671875
[Actor] Episode 0 Step 16 Loss: 2152.37158203125
[Actor] Episode 0 Step 17 Loss: 1958.5400390625
[Actor] Episode 0 Step 18 Loss: 1946.2637939453125
[Actor] Episode 0 Step 19 Loss: 2082.732666015625
[Actor] Episode 0 Step 20 Loss: 1852.583740234375
[Actor] Episode 0 Step 21 Loss: 2114.319580078125
[Actor] Episode 0 Step 22 Loss: 1804.1280517578125
[Actor] Episode 0 Step 23 Loss: 1953.8890380859375
[Actor] Episode 0 Step 24 Loss: 1830.7635498046875
[Actor] Episode 0 Step 25 Loss: 1993.480712890625
[Actor] Episode 0 Step 26 Loss: 1913.4586181640625
[Actor] Episode 0 Step 27 Loss: 1870.237060546875
[Actor] Episode 0 Step 28 Loss: 1753.96044921875
[Actor] Episode 0 Step 29 Loss: 1776.6070556640625
[Actor] Episode 0 Step 30 Loss: 1599.7547607421875
[Actor] Episode 0 Step 31 Loss: 1733.1953125
[Actor] Episode 0 Step 32 Loss: 1708.8983154296875
[Actor] Episode 0 Step 33 Loss: 1671.9063720703125
[Actor] Episode 0 Step 34 Loss: 1627.0167236328125
[Actor] Episode 0 Step 35 Loss: 1748.95458984375
[Actor] Episode 0 Step 36 Loss: 1413.6298828125
[Actor] Episode 0 Step 37 Loss: 1473.9677734375
[Actor] Episode 0 Step 38 Loss: 1808.1505126953125
[Actor] Episode 0 Step 39 Loss: 1404.5008544921875
[Actor] Episode 0 Step 40 Loss: 1239.9036865234375
[Actor] Episode 0 Step 41 Loss: 1630.5836181640625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 1961.9642275855654
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 1483.9461119174957s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1630.4652099609375
[Actor] Episode 1 Step 1 Loss: 1641.9456787109375
[Actor] Episode 1 Step 2 Loss: 1370.7137451171875
[Actor] Episode 1 Step 3 Loss: 1402.74462890625
[Actor] Episode 1 Step 4 Loss: 1352.7451171875
[Actor] Episode 1 Step 5 Loss: 1430.9462890625
[Actor] Episode 1 Step 6 Loss: 1307.8824462890625
[Actor] Episode 1 Step 7 Loss: 1218.2554931640625
[Actor] Episode 1 Step 8 Loss: 1434.345703125
[Actor] Episode 1 Step 9 Loss: 1404.3731689453125
[Actor] Episode 1 Step 10 Loss: 1603.4544677734375
[Actor] Episode 1 Step 11 Loss: 1467.1103515625
[Actor] Episode 1 Step 12 Loss: 1441.49658203125
[Actor] Episode 1 Step 13 Loss: 1425.8192138671875
[Actor] Episode 1 Step 14 Loss: 1413.1409912109375
[Actor] Episode 1 Step 15 Loss: 1283.2520751953125
[Actor] Episode 1 Step 16 Loss: 1351.1104736328125
[Actor] Episode 1 Step 17 Loss: 1571.6800537109375
[Actor] Episode 1 Step 18 Loss: 1489.052734375
[Actor] Episode 1 Step 19 Loss: 1292.078857421875
[Actor] Episode 1 Step 20 Loss: 1497.2333984375
[Actor] Episode 1 Step 21 Loss: 1359.4136962890625
[Actor] Episode 1 Step 22 Loss: 1517.833984375
[Actor] Episode 1 Step 23 Loss: 1132.77294921875
[Actor] Episode 1 Step 24 Loss: 1214.049560546875
[Actor] Episode 1 Step 25 Loss: 1097.244140625
[Actor] Episode 1 Step 26 Loss: 1282.4515380859375
[Actor] Episode 1 Step 27 Loss: 1263.6123046875
[Actor] Episode 1 Step 28 Loss: 1219.02685546875
[Actor] Episode 1 Step 29 Loss: 1163.98828125
[Actor] Episode 1 Step 30 Loss: 1319.08447265625
[Actor] Episode 1 Step 31 Loss: 1166.1326904296875
[Actor] Episode 1 Step 32 Loss: 1204.1092529296875
[Actor] Episode 1 Step 33 Loss: 1318.5782470703125
[Actor] Episode 1 Step 34 Loss: 1412.5574951171875
[Actor] Episode 1 Step 35 Loss: 1298.5694580078125
[Actor] Episode 1 Step 36 Loss: 1107.0389404296875
[Actor] Episode 1 Step 37 Loss: 1288.57373046875
[Actor] Episode 1 Step 38 Loss: 1320.0992431640625
[Actor] Episode 1 Step 39 Loss: 1237.76025390625
[Actor] Episode 1 Step 40 Loss: 1174.4627685546875
[Actor] Episode 1 Step 41 Loss: 1209.68310546875
-------------------------------------------------
[Actor] Episode 1 Average Loss: 1341.354515438988
[Actor] Learning Rate: 0.009926991537213326
[Actor] Epoch Time: 1510.8040783405304s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 1020.91455078125
[Actor] Episode 2 Step 1 Loss: 1119.5614013671875
[Actor] Episode 2 Step 2 Loss: 1252.759765625
[Actor] Episode 2 Step 3 Loss: 1402.9605712890625
[Actor] Episode 2 Step 4 Loss: 1149.8050537109375
[Actor] Episode 2 Step 5 Loss: 1326.535400390625
[Actor] Episode 2 Step 6 Loss: 1187.0863037109375
[Actor] Episode 2 Step 7 Loss: 1237.7315673828125
[Actor] Episode 2 Step 8 Loss: 1106.560546875
[Actor] Episode 2 Step 9 Loss: 1154.2252197265625
[Actor] Episode 2 Step 10 Loss: 1027.1978759765625
[Actor] Episode 2 Step 11 Loss: 1060.814697265625
[Actor] Episode 2 Step 12 Loss: 1218.8326416015625
[Actor] Episode 2 Step 13 Loss: 1179.714111328125
[Actor] Episode 2 Step 14 Loss: 1055.0582275390625
[Actor] Episode 2 Step 15 Loss: 1050.061279296875
[Actor] Episode 2 Step 16 Loss: 1002.1636352539062
[Actor] Episode 2 Step 17 Loss: 1011.6309204101562
[Actor] Episode 2 Step 18 Loss: 990.6062622070312
[Actor] Episode 2 Step 19 Loss: 1026.473388671875
[Actor] Episode 2 Step 20 Loss: 1045.006591796875
[Actor] Episode 2 Step 21 Loss: 1082.077880859375
[Actor] Episode 2 Step 22 Loss: 1177.642578125
[Actor] Episode 2 Step 23 Loss: 1117.599853515625
[Actor] Episode 2 Step 24 Loss: 1283.99755859375
[Actor] Episode 2 Step 25 Loss: 1044.888916015625
[Actor] Episode 2 Step 26 Loss: 1136.6829833984375
[Actor] Episode 2 Step 27 Loss: 1204.89892578125
[Actor] Episode 2 Step 28 Loss: 1049.245849609375
[Actor] Episode 2 Step 29 Loss: 1081.8883056640625
[Actor] Episode 2 Step 30 Loss: 989.5901489257812
[Actor] Episode 2 Step 31 Loss: 1117.0272216796875
[Actor] Episode 2 Step 32 Loss: 988.1351928710938
[Actor] Episode 2 Step 33 Loss: 993.0540771484375
[Actor] Episode 2 Step 34 Loss: 1076.5289306640625
[Actor] Episode 2 Step 35 Loss: 1117.171875
[Actor] Episode 2 Step 36 Loss: 1174.9658203125
[Actor] Episode 2 Step 37 Loss: 948.7880859375
[Actor] Episode 2 Step 38 Loss: 1060.4193115234375
[Actor] Episode 2 Step 39 Loss: 1096.3133544921875
[Actor] Episode 2 Step 40 Loss: 1075.2420654296875
[Actor] Episode 2 Step 41 Loss: 1083.3697509765625
-------------------------------------------------
[Actor] Episode 2 Average Loss: 1107.7435404459636
[Actor] Learning Rate: 0.00989068765193224
[Actor] Epoch Time: 1518.9531705379486s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 1009.8180541992188
[Actor] Episode 3 Step 1 Loss: 1224.977294921875
[Actor] Episode 3 Step 2 Loss: 1017.8363647460938
[Actor] Episode 3 Step 3 Loss: 932.3054809570312
[Actor] Episode 3 Step 4 Loss: 1091.497802734375
[Actor] Episode 3 Step 5 Loss: 1018.1414794921875
[Actor] Episode 3 Step 6 Loss: 999.8524169921875
[Actor] Episode 3 Step 7 Loss: 1028.765625
[Actor] Episode 3 Step 8 Loss: 986.7770385742188
[Actor] Episode 3 Step 9 Loss: 1046.7230224609375
[Actor] Episode 3 Step 10 Loss: 1175.5093994140625
[Actor] Episode 3 Step 11 Loss: 1096.6717529296875
[Actor] Episode 3 Step 12 Loss: 897.7664794921875
[Actor] Episode 3 Step 13 Loss: 997.69140625
[Actor] Episode 3 Step 14 Loss: 989.6598510742188
[Actor] Episode 3 Step 15 Loss: 1001.9800415039062
[Actor] Episode 3 Step 16 Loss: 1019.5421752929688
[Actor] Episode 3 Step 17 Loss: 1059.0545654296875
[Actor] Episode 3 Step 18 Loss: 1057.3206787109375
[Actor] Episode 3 Step 19 Loss: 1103.52197265625
[Actor] Episode 3 Step 20 Loss: 1052.4539794921875
[Actor] Episode 3 Step 21 Loss: 973.6517333984375
[Actor] Episode 3 Step 22 Loss: 1092.68017578125
[Actor] Episode 3 Step 23 Loss: 1059.5694580078125
[Actor] Episode 3 Step 24 Loss: 972.1674194335938
[Actor] Episode 3 Step 25 Loss: 1136.5689697265625
[Actor] Episode 3 Step 26 Loss: 926.5264892578125
[Actor] Episode 3 Step 27 Loss: 998.9075317382812
[Actor] Episode 3 Step 28 Loss: 1084.59326171875
[Actor] Episode 3 Step 29 Loss: 992.1717529296875
[Actor] Episode 3 Step 30 Loss: 1118.541259765625
[Actor] Episode 3 Step 31 Loss: 1041.4169921875
[Actor] Episode 3 Step 32 Loss: 1142.2044677734375
[Actor] Episode 3 Step 33 Loss: 937.2651977539062
[Actor] Episode 3 Step 34 Loss: 1011.5714111328125
[Actor] Episode 3 Step 35 Loss: 951.4798583984375
[Actor] Episode 3 Step 36 Loss: 1005.21630859375
[Actor] Episode 3 Step 37 Loss: 960.6300659179688
[Actor] Episode 3 Step 38 Loss: 1014.3949584960938
[Actor] Episode 3 Step 39 Loss: 1091.287353515625
[Actor] Episode 3 Step 40 Loss: 1075.9879150390625
[Actor] Episode 3 Step 41 Loss: 967.3001708984375
-------------------------------------------------
[Actor] Episode 3 Average Loss: 1032.4285627092634
[Actor] Learning Rate: 0.009854516014456749
[Actor] Epoch Time: 1510.188066959381s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 1046.9969482421875
[Actor] Episode 4 Step 1 Loss: 990.5125122070312
[Actor] Episode 4 Step 2 Loss: 1028.713623046875
2021-03-28 09:39:03.601523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 09:39:07.500767: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:39:07.502217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 09:39:07.651319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.652226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:39:07.652263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:39:07.663408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:39:07.663556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:39:07.668548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:39:07.668948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:39:07.679745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:39:07.681070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:39:07.683155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:39:07.684163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.685774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.687967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:39:07.689298: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 09:39:07.689543: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:39:07.690591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.692296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:39:07.692336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:39:07.692479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:39:07.692554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:39:07.692609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:39:07.692661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:39:07.692712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:39:07.692763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:39:07.692815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:39:07.692921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.695569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:07.697460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:39:07.697511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:39:08.685531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 09:39:08.685571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 09:39:08.685582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 09:39:08.685926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:08.686945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:08.687722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:39:08.688358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-28 09:40:17.734682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[DDPG] Building the actor model
2021-03-28 09:40:21.763633: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:40:21.767400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 09:40:21.882381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.883599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:40:21.883653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:40:21.889006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:40:21.889160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:40:21.891213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:40:21.891643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:40:21.896187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:40:21.897382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:40:21.897620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:40:21.897828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.898998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.899953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:40:21.900342: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 09:40:21.900567: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:40:21.900754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.901820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:40:21.901853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:40:21.901970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:40:21.902056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:40:21.902135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:40:21.902187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:40:21.902236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:40:21.902282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:40:21.902339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:40:21.902467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.903482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:21.904448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:40:21.904501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:40:22.919926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 09:40:22.920020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 09:40:22.920058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 09:40:22.920431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:22.921667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:22.922646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:40:22.923427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616924426.560441499, 6071.212000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616924426.561587820, 6071.213000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616924426.561762456, 6071.213000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616924427.806810987, 6072.448000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616924428.046128097, 6072.686000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616924428.252581645, 6072.886000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616924428.859901894, 6073.486000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 09:40:54.290687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:40:54.967496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2828.79931640625
[Actor] Episode 0 Step 1 Loss: 2664.040771484375
2021-03-28 09:43:43.963744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:43:48.120971: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:43:48.122351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 09:43:48.242202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.243903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:43:48.243986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:43:48.256124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:43:48.256342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:43:48.261446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:43:48.261926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:43:48.272525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:43:48.275160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:43:48.275427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:43:48.276278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.278899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.279839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 09:43:48.470434: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 09:43:48.473786: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:43:48.474384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.476382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:43:48.476524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:43:48.477110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:43:48.478132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:43:48.478455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:43:48.478712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:43:48.478886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:43:48.479220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:43:48.479750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:43:48.480097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.485996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:48.487900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:43:48.488028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:43:49.639507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 09:43:49.639579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 09:43:49.639612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 09:43:49.639979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:49.641205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:49.642303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:43:49.643230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616924675.159503121, 6311.045000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616924675.160268290, 6311.046000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616924675.160336928, 6311.046000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
Traceback (most recent call last):
  File "learn.py", line 975, in <module>
    learner = Learner(params, False)
  File "learn.py", line 127, in __init__
    self.env = Env(
  File "/home/ubuntu/CPGController/src/rl/env.py", line 36, in __init__
    self.quadruped = Quadruped(params)
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 452, in __init__
    self.kinematics = Kinematics(
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 21, in __init__
    self.front_right_leg = moveit_commander.MoveGroupCommander(
  File "/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py", line 53, in __init__
    self._g = _moveit_move_group_interface.MoveGroupInterface(name, robot_description, ns, wait_for_servers)
RuntimeError: Unable to connect to move_group action server 'move_group' within allotted time (5s)
2021-03-28 09:44:49.841268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:44:53.246738: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:44:53.248196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 09:44:53.333546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.335585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:44:53.335640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:44:53.345269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:44:53.345433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:44:53.349594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:44:53.349984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:44:53.358363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:44:53.359481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:44:53.362044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:44:53.362289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.364206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.366670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 09:44:53.542822: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 09:44:53.543092: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 09:44:53.543493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.544539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 09:44:53.544685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:44:53.544955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:44:53.545145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 09:44:53.545320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 09:44:53.545635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 09:44:53.545806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 09:44:53.545953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 09:44:53.546102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 09:44:53.546505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.547714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:53.548771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 09:44:53.548900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 09:44:54.413554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 09:44:54.413742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 09:44:54.413810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 09:44:54.414230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:54.415328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:54.416336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 09:44:54.417140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616924697.834922051, 6332.847000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616924697.836168399, 6332.849000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616924697.836279083, 6332.849000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616924699.205083861, 6334.206000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616924699.685835512, 6334.679000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616924699.888349793, 6334.879000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616924700.090550606, 6335.079000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 09:45:24.884494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 09:45:25.587876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2542.689208984375
[Actor] Episode 0 Step 1 Loss: 2559.782958984375
[Actor] Episode 0 Step 2 Loss: 2428.234619140625
[Actor] Episode 0 Step 3 Loss: 2385.504638671875
[Actor] Episode 0 Step 4 Loss: 2333.70654296875
[Actor] Episode 0 Step 5 Loss: 2225.691162109375
[Actor] Episode 0 Step 6 Loss: 2123.822265625
shutdown request: [/joint_position_node] Reason: new node registered with same name
[Actor] Episode 0 Step 7 Loss: 2277.18212890625
[Actor] Episode 0 Step 8 Loss: 2233.636474609375
[Actor] Episode 0 Step 9 Loss: 2037.042236328125
[Actor] Episode 0 Step 10 Loss: 1993.7008056640625
[Actor] Episode 0 Step 11 Loss: 1921.6373291015625
[Actor] Episode 0 Step 12 Loss: 1976.592529296875
[Actor] Episode 0 Step 13 Loss: 2033.2188720703125
[Actor] Episode 0 Step 14 Loss: 1998.2518310546875
[Actor] Episode 0 Step 15 Loss: 1947.38818359375
[Actor] Episode 0 Step 16 Loss: 1946.5069580078125
[Actor] Episode 0 Step 17 Loss: 2074.338623046875
[Actor] Episode 0 Step 18 Loss: 2030.4891357421875
[Actor] Episode 0 Step 19 Loss: 1937.9866943359375
[Actor] Episode 0 Step 20 Loss: 1867.2930908203125
[Actor] Episode 0 Step 21 Loss: 1779.24658203125
[Actor] Episode 0 Step 22 Loss: 1928.2188720703125
[Actor] Episode 0 Step 23 Loss: 1707.8980712890625
[Actor] Episode 0 Step 24 Loss: 1752.6046142578125
[Actor] Episode 0 Step 25 Loss: 1604.56591796875
[Actor] Episode 0 Step 26 Loss: 1789.0308837890625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2053.1948603877313
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 441.60582399368286s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1557.8870849609375
[Actor] Episode 1 Step 1 Loss: 1687.8304443359375
[Actor] Episode 1 Step 2 Loss: 1772.30419921875
[Actor] Episode 1 Step 3 Loss: 1523.803955078125
[Actor] Episode 1 Step 4 Loss: 1607.53076171875
[Actor] Episode 1 Step 5 Loss: 1665.257568359375
[Actor] Episode 1 Step 6 Loss: 1739.410888671875
[Actor] Episode 1 Step 7 Loss: 1493.2998046875
[Actor] Episode 1 Step 8 Loss: 1602.847412109375
[Actor] Episode 1 Step 9 Loss: 1625.873046875
[Actor] Episode 1 Step 10 Loss: 1679.3238525390625
[Actor] Episode 1 Step 11 Loss: 1529.24169921875
[Actor] Episode 1 Step 12 Loss: 1512.763427734375
[Actor] Episode 1 Step 13 Loss: 1451.1314697265625
[Actor] Episode 1 Step 14 Loss: 1586.501220703125
[Actor] Episode 1 Step 15 Loss: 1455.48974609375
[Actor] Episode 1 Step 16 Loss: 1518.693359375
[Actor] Episode 1 Step 17 Loss: 1573.609130859375
[Actor] Episode 1 Step 18 Loss: 1358.06005859375
[Actor] Episode 1 Step 19 Loss: 1785.400146484375
[Actor] Episode 1 Step 20 Loss: 1250.0086669921875
[Actor] Episode 1 Step 21 Loss: 1401.2711181640625
[Actor] Episode 1 Step 22 Loss: 1394.935302734375
[Actor] Episode 1 Step 23 Loss: 1506.552490234375
[Actor] Episode 1 Step 24 Loss: 1398.7264404296875
[Actor] Episode 1 Step 25 Loss: 1577.9051513671875
[Actor] Episode 1 Step 26 Loss: 1529.78515625
-------------------------------------------------
[Actor] Episode 1 Average Loss: 1547.6090223524307
[Actor] Learning Rate: 0.009926991537213326
[Actor] Epoch Time: 237.56790375709534s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 1460.2030029296875
[Actor] Episode 2 Step 1 Loss: 1302.8441162109375
[Actor] Episode 2 Step 2 Loss: 1308.060302734375
[Actor] Episode 2 Step 3 Loss: 1472.843505859375
[Actor] Episode 2 Step 4 Loss: 1405.514892578125
[Actor] Episode 2 Step 5 Loss: 1539.5855712890625
[Actor] Episode 2 Step 6 Loss: 1204.44873046875
[Actor] Episode 2 Step 7 Loss: 1354.4305419921875
[Actor] Episode 2 Step 8 Loss: 1309.02978515625
[Actor] Episode 2 Step 9 Loss: 1183.328369140625
[Actor] Episode 2 Step 10 Loss: 1328.777587890625
[Actor] Episode 2 Step 11 Loss: 1234.2568359375
[Actor] Episode 2 Step 12 Loss: 1105.9266357421875
[Actor] Episode 2 Step 13 Loss: 1337.2010498046875
[Actor] Episode 2 Step 14 Loss: 1199.2745361328125
[Actor] Episode 2 Step 15 Loss: 1174.335693359375
[Actor] Episode 2 Step 16 Loss: 1226.4129638671875
[Actor] Episode 2 Step 17 Loss: 1357.7188720703125
[Actor] Episode 2 Step 18 Loss: 1128.0439453125
[Actor] Episode 2 Step 19 Loss: 1245.4229736328125
[Actor] Episode 2 Step 20 Loss: 1210.2269287109375
[Actor] Episode 2 Step 21 Loss: 1373.8157958984375
[Actor] Episode 2 Step 22 Loss: 1240.603759765625
[Actor] Episode 2 Step 23 Loss: 1266.5948486328125
[Actor] Episode 2 Step 24 Loss: 1025.198974609375
[Actor] Episode 2 Step 25 Loss: 1262.1827392578125
[Actor] Episode 2 Step 26 Loss: 1202.5047607421875
-------------------------------------------------
[Actor] Episode 2 Average Loss: 1276.2513970269097
[Actor] Learning Rate: 0.00989068765193224
[Actor] Epoch Time: 237.96924757957458s
-------------------------------------------------
[Actor] Starting Episode 3
2021-03-28 10:05:36.636901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:05:41.072209: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:05:41.075826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 10:05:41.176855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.178982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:05:41.179034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:05:41.188960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:05:41.189743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:05:41.194004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:05:41.194436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:05:41.202654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:05:41.205682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:05:41.205921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:05:41.206626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.208998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.211638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 10:05:41.464367: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 10:05:41.464671: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:05:41.465046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.466191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:05:41.466225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:05:41.466459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:05:41.466599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:05:41.466675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:05:41.466735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:05:41.466787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:05:41.466836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:05:41.466888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:05:41.467075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.467973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:41.468682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 10:05:41.468727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:05:42.296821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 10:05:42.296856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 10:05:42.296866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 10:05:42.297163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:42.297989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:42.298970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:05:42.299828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616926015.653415698, 7486.854000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616926015.654311520, 7486.855000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616926015.654380502, 7486.855000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616926016.786762056, 7487.985000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616926017.159302403, 7488.357000000]: Ready to take commands for planning group front_left_leg.[0m
Traceback (most recent call last):
  File "learn.py", line 976, in <module>
    learner = Learner(params, False)
  File "learn.py", line 127, in __init__
    self.env = Env(
  File "/home/ubuntu/CPGController/src/rl/env.py", line 37, in __init__
    self.quadruped = Quadruped(params, experiment)
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/quadruped.py", line 454, in __init__
    self.kinematics = Kinematics(
  File "/home/ubuntu/CPGController/src/simulations/ws/src/quadruped/scripts/kinematics.py", line 33, in __init__
    self.back_right_leg = moveit_commander.MoveGroupCommander(
  File "/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py", line 53, in __init__
    self._g = _moveit_move_group_interface.MoveGroupInterface(name, robot_description, ns, wait_for_servers)
RuntimeError: Unable to connect to move_group action server 'pickup' within allotted time (5s)
2021-03-28 10:10:27.965887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:10:31.846258: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:10:31.847588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 10:10:31.929805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:31.930865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:10:31.930912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:10:31.936658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:10:31.937048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:10:31.939744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:10:31.940144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:10:31.945929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:10:31.947172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:10:31.947527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:10:31.947906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:31.949259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:31.950493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 10:10:32.088887: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 10:10:32.089153: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:10:32.089495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.090182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:10:32.090219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:10:32.090468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:10:32.090604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:10:32.090680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:10:32.090750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:10:32.090819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:10:32.090878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:10:32.090945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:10:32.091105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.092086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.092834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 10:10:32.092885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:10:32.943618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 10:10:32.943665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 10:10:32.943679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 10:10:32.944040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.945045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.945889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:10:32.946822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616926236.327845629, 7706.486000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616926236.329018341, 7706.487000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616926236.329218996, 7706.488000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616926237.572173419, 7707.719000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616926237.829459978, 7707.975000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616926238.466037769, 7708.575000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616926238.872669891, 7708.975000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 10:11:04.176287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:11:04.894912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2781.18310546875
[Actor] Episode 0 Step 1 Loss: 2480.36669921875
[Actor] Episode 0 Step 2 Loss: 2466.3916015625
[Actor] Episode 0 Step 3 Loss: 2294.049072265625
[Actor] Episode 0 Step 4 Loss: 2382.485107421875
[Actor] Episode 0 Step 5 Loss: 2436.15771484375
[Actor] Episode 0 Step 6 Loss: 2304.69189453125
[Actor] Episode 0 Step 7 Loss: 2261.0283203125
[Actor] Episode 0 Step 8 Loss: 2159.330322265625
[Actor] Episode 0 Step 9 Loss: 2061.743896484375
[Actor] Episode 0 Step 10 Loss: 2017.5648193359375
[Actor] Episode 0 Step 11 Loss: 2306.249267578125
[Actor] Episode 0 Step 12 Loss: 2163.246826171875
[Actor] Episode 0 Step 13 Loss: 2018.396240234375
[Actor] Episode 0 Step 14 Loss: 1989.295166015625
[Actor] Episode 0 Step 15 Loss: 2059.38232421875
[Actor] Episode 0 Step 16 Loss: 1994.0828857421875
[Actor] Episode 0 Step 17 Loss: 1902.120361328125
[Actor] Episode 0 Step 18 Loss: 1951.6463623046875
[Actor] Episode 0 Step 19 Loss: 1908.040283203125
[Actor] Episode 0 Step 20 Loss: 2028.138671875
[Actor] Episode 0 Step 21 Loss: 1547.8944091796875
[Actor] Episode 0 Step 22 Loss: 1880.98779296875
[Actor] Episode 0 Step 23 Loss: 1981.273193359375
[Actor] Episode 0 Step 24 Loss: 1913.677978515625
[Actor] Episode 0 Step 25 Loss: 1952.0123291015625
[Actor] Episode 0 Step 26 Loss: 2099.503173828125
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2123.738511827257
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 1018.3747692108154s
-------------------------------------------------
[Actor] Starting Episode 1
shutdown request: [/joint_position_node_expFalse] Reason: new node registered with same name
[Actor] Episode 1 Step 0 Loss: 1823.9337158203125
[Actor] Episode 1 Step 1 Loss: 1852.011962890625
[Actor] Episode 1 Step 2 Loss: 1598.89111328125
[Actor] Episode 1 Step 3 Loss: 1732.4176025390625
[Actor] Episode 1 Step 4 Loss: 1782.8995361328125
[Actor] Episode 1 Step 5 Loss: 1868.6466064453125
[Actor] Episode 1 Step 6 Loss: 1548.029541015625
[Actor] Episode 1 Step 7 Loss: 1761.345947265625
[Actor] Episode 1 Step 8 Loss: 1531.8980712890625
[Actor] Episode 1 Step 9 Loss: 1600.4002685546875
[Actor] Episode 1 Step 10 Loss: 1472.4891357421875
[Actor] Episode 1 Step 11 Loss: 1819.910888671875
[Actor] Episode 1 Step 12 Loss: 1609.68212890625
[Actor] Episode 1 Step 13 Loss: 1598.789306640625
[Actor] Episode 1 Step 14 Loss: 1654.9049072265625
[Actor] Episode 1 Step 15 Loss: 1357.380615234375
[Actor] Episode 1 Step 16 Loss: 1373.375732421875
[Actor] Episode 1 Step 17 Loss: 1632.0447998046875
[Actor] Episode 1 Step 18 Loss: 1648.8021240234375
[Actor] Episode 1 Step 19 Loss: 1612.5709228515625
[Actor] Episode 1 Step 20 Loss: 1556.44482421875
[Actor] Episode 1 Step 21 Loss: 1492.882568359375
[Actor] Episode 1 Step 22 Loss: 1495.6441650390625
2021-03-28 10:46:24.677924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:46:28.100873: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:46:28.103119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 10:46:28.196769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.198774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:46:28.198833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:46:28.206137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:46:28.208386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:46:28.211054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:46:28.212597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:46:28.220459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:46:28.223509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:46:28.223808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:46:28.224037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.225815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.228683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 10:46:28.486877: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 10:46:28.487802: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 10:46:28.488263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.489171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 10:46:28.489208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:46:28.490560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:46:28.490634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 10:46:28.490679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 10:46:28.490720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 10:46:28.490761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 10:46:28.490800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 10:46:28.490841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 10:46:28.491018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.493825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:28.496184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 10:46:28.496233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 10:46:29.636996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 10:46:29.637042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 10:46:29.637054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 10:46:29.637506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:29.638674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:29.639691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 10:46:29.640690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616928392.890602591, 9773.976000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616928392.891550732, 9773.977000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616928392.891682824, 9773.977000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616928394.252997087, 9775.326000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616928394.797866571, 9775.864000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616928395.201643771, 9776.265000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616928395.610118574, 9776.664000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 10:47:00.654376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 10:47:01.304201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2772.87939453125
[Actor] Episode 0 Step 1 Loss: 2624.1962890625
[Actor] Episode 0 Step 2 Loss: 2392.762939453125
[Actor] Episode 0 Step 3 Loss: 2663.618896484375
[Actor] Episode 0 Step 4 Loss: 2186.825439453125
[Actor] Episode 0 Step 5 Loss: 2024.2774658203125
[Actor] Episode 0 Step 6 Loss: 2053.452880859375
[Actor] Episode 0 Step 7 Loss: 2050.622314453125
[Actor] Episode 0 Step 8 Loss: 2078.974609375
[Actor] Episode 0 Step 9 Loss: 2053.968017578125
[Actor] Episode 0 Step 10 Loss: 2123.048828125
[Actor] Episode 0 Step 11 Loss: 2169.9052734375
[Actor] Episode 0 Step 12 Loss: 2277.54638671875
[Actor] Episode 0 Step 13 Loss: 2043.64501953125
[Actor] Episode 0 Step 14 Loss: 1814.37109375
[Actor] Episode 0 Step 15 Loss: 1962.2803955078125
[Actor] Episode 0 Step 16 Loss: 1891.1348876953125
[Actor] Episode 0 Step 17 Loss: 1899.3275146484375
[Actor] Episode 0 Step 18 Loss: 1969.44873046875
[Actor] Episode 0 Step 19 Loss: 1918.6563720703125
[Actor] Episode 0 Step 20 Loss: 1747.099853515625
[Actor] Episode 0 Step 21 Loss: 1794.551025390625
[Actor] Episode 0 Step 22 Loss: 1748.8765869140625
[Actor] Episode 0 Step 23 Loss: 1857.4090576171875
[Actor] Episode 0 Step 24 Loss: 1730.74365234375
[Actor] Episode 0 Step 25 Loss: 1666.0341796875
[Actor] Episode 0 Step 26 Loss: 1634.500732421875
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2042.5984384042245
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 852.9163999557495s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1733.8729248046875
[Actor] Episode 1 Step 1 Loss: 1672.9862060546875
[Actor] Episode 1 Step 2 Loss: 1374.6884765625
[Actor] Episode 1 Step 3 Loss: 1932.5726318359375
[Actor] Episode 1 Step 4 Loss: 1598.92919921875
[Actor] Episode 1 Step 5 Loss: 1497.7540283203125
[Actor] Episode 1 Step 6 Loss: 1697.6529541015625
[Actor] Episode 1 Step 7 Loss: 1654.29833984375
[Actor] Episode 1 Step 8 Loss: 1574.9461669921875
[Actor] Episode 1 Step 9 Loss: 1521.2286376953125
[Actor] Episode 1 Step 10 Loss: 1689.7503662109375
[Actor] Episode 1 Step 11 Loss: 1732.0
[Actor] Episode 1 Step 12 Loss: 1709.6552734375
[Actor] Episode 1 Step 13 Loss: 1552.9051513671875
[Actor] Episode 1 Step 14 Loss: 1676.131103515625
[Actor] Episode 1 Step 15 Loss: 1423.1531982421875
[Actor] Episode 1 Step 16 Loss: 1687.9088134765625
[Actor] Episode 1 Step 17 Loss: 1639.8154296875
[Actor] Episode 1 Step 18 Loss: 1306.3212890625
[Actor] Episode 1 Step 19 Loss: 1546.29345703125
[Actor] Episode 1 Step 20 Loss: 1490.3050537109375
[Actor] Episode 1 Step 21 Loss: 1544.717041015625
[Actor] Episode 1 Step 22 Loss: 1158.12646484375
2021-03-28 11:40:12.594929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 11:40:19.108471: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 11:40:19.111093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 11:40:19.177825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.178422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 11:40:19.178445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 11:40:19.208229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 11:40:19.208331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 11:40:19.230539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 11:40:19.238407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 11:40:19.270635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 11:40:19.278202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 11:40:19.281008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 11:40:19.281152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.281901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.283474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 11:40:19.358492: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 11:40:19.358768: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 11:40:19.358920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.359482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 11:40:19.359499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 11:40:19.359573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 11:40:19.359610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 11:40:19.359642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 11:40:19.359674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 11:40:19.359706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 11:40:19.359737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 11:40:19.359770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 11:40:19.359861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.360507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:19.361039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 11:40:19.361979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 11:40:21.032713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 11:40:21.032756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 11:40:21.032763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 11:40:21.035249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:21.035985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:21.036635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 11:40:21.037196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616931624.221339364, 1.514000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616931624.222435283, 1.515000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616931624.222490365, 1.515000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616931625.488283765, 2.776000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616931626.115243966, 3.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616931626.922118344, 4.201000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616931627.726736917, 5.001000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 11:40:52.415946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 11:40:53.882292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2519.57763671875
[Actor] Episode 0 Step 1 Loss: 2732.8740234375
[Actor] Episode 0 Step 2 Loss: 2837.375732421875
[Actor] Episode 0 Step 3 Loss: 2799.92919921875
[Actor] Episode 0 Step 4 Loss: 3082.160888671875
[Actor] Episode 0 Step 5 Loss: 2647.90576171875
[Actor] Episode 0 Step 6 Loss: 2465.551513671875
[Actor] Episode 0 Step 7 Loss: 2333.645751953125
[Actor] Episode 0 Step 8 Loss: 2337.84619140625
[Actor] Episode 0 Step 9 Loss: 1955.3819580078125
[Actor] Episode 0 Step 10 Loss: 2213.352294921875
[Actor] Episode 0 Step 11 Loss: 1822.889892578125
[Actor] Episode 0 Step 12 Loss: 2124.681396484375
[Actor] Episode 0 Step 13 Loss: 2182.82421875
[Actor] Episode 0 Step 14 Loss: 2263.069091796875
[Actor] Episode 0 Step 15 Loss: 2247.785888671875
[Actor] Episode 0 Step 16 Loss: 2061.132568359375
[Actor] Episode 0 Step 17 Loss: 2054.84765625
[Actor] Episode 0 Step 18 Loss: 1908.6854248046875
[Actor] Episode 0 Step 19 Loss: 2160.161865234375
[Actor] Episode 0 Step 20 Loss: 2065.02734375
[Actor] Episode 0 Step 21 Loss: 1824.7449951171875
[Actor] Episode 0 Step 22 Loss: 1893.4139404296875
[Actor] Episode 0 Step 23 Loss: 1680.9471435546875
[Actor] Episode 0 Step 24 Loss: 2028.719482421875
[Actor] Episode 0 Step 25 Loss: 2057.48583984375
[Actor] Episode 0 Step 26 Loss: 1684.411865234375
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2221.719613534433
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 773.8519406318665s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1723.5947265625
[Actor] Episode 1 Step 1 Loss: 1821.4027099609375
[Actor] Episode 1 Step 2 Loss: 1600.206787109375
[Actor] Episode 1 Step 3 Loss: 1830.2537841796875
[Actor] Episode 1 Step 4 Loss: 1733.5277099609375
[Actor] Episode 1 Step 5 Loss: 1969.1767578125
[Actor] Episode 1 Step 6 Loss: 1689.0804443359375
[Actor] Episode 1 Step 7 Loss: 1837.27587890625
[Actor] Episode 1 Step 8 Loss: 1671.2467041015625
[Actor] Episode 1 Step 9 Loss: 1888.90869140625
[Actor] Episode 1 Step 10 Loss: 1578.12158203125
[Actor] Episode 1 Step 11 Loss: 1697.9166259765625
[Actor] Episode 1 Step 12 Loss: 1611.7490234375
[Actor] Episode 1 Step 13 Loss: 1546.441162109375
[Actor] Episode 1 Step 14 Loss: 1606.286376953125
[Actor] Episode 1 Step 15 Loss: 1449.97802734375
[Actor] Episode 1 Step 16 Loss: 1486.5152587890625
[Actor] Episode 1 Step 17 Loss: 1486.9678955078125
[Actor] Episode 1 Step 18 Loss: 1672.1600341796875
[Actor] Episode 1 Step 19 Loss: 1487.809326171875
[Actor] Episode 1 Step 20 Loss: 1383.2735595703125
[Actor] Episode 1 Step 21 Loss: 1499.2578125
[Actor] Episode 1 Step 22 Loss: 1335.3494873046875
[Actor] Episode 1 Step 23 Loss: 1504.2041015625
[Actor] Episode 1 Step 24 Loss: 1375.622802734375
[Actor] Episode 1 Step 25 Loss: 1550.7557373046875
[Actor] Episode 1 Step 26 Loss: 1257.200439453125
-------------------------------------------------
[Actor] Episode 1 Average Loss: 1603.4919795283565
[Actor] Learning Rate: 0.009926991537213326
[Actor] Epoch Time: 790.0707972049713s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 1492.83740234375
[Actor] Episode 2 Step 1 Loss: 1279.5638427734375
[Actor] Episode 2 Step 2 Loss: 1367.0965576171875
[Actor] Episode 2 Step 3 Loss: 1421.8155517578125
[Actor] Episode 2 Step 4 Loss: 1380.9930419921875
[Actor] Episode 2 Step 5 Loss: 1240.4844970703125
[Actor] Episode 2 Step 6 Loss: 1455.471435546875
[Actor] Episode 2 Step 7 Loss: 1385.40625
[Actor] Episode 2 Step 8 Loss: 1500.3760986328125
[Actor] Episode 2 Step 9 Loss: 1244.84716796875
[Actor] Episode 2 Step 10 Loss: 1283.4281005859375
[Actor] Episode 2 Step 11 Loss: 1378.54931640625
[Actor] Episode 2 Step 12 Loss: 1173.4547119140625
[Actor] Episode 2 Step 13 Loss: 1331.5836181640625
[Actor] Episode 2 Step 14 Loss: 1164.229248046875
[Actor] Episode 2 Step 15 Loss: 1360.6151123046875
[Actor] Episode 2 Step 16 Loss: 1255.284423828125
[Actor] Episode 2 Step 17 Loss: 1282.0126953125
[Actor] Episode 2 Step 18 Loss: 1123.1636962890625
[Actor] Episode 2 Step 19 Loss: 1175.3634033203125
[Actor] Episode 2 Step 20 Loss: 1325.8138427734375
[Actor] Episode 2 Step 21 Loss: 1341.6929931640625
[Actor] Episode 2 Step 22 Loss: 1374.074951171875
[Actor] Episode 2 Step 23 Loss: 1204.409912109375
[Actor] Episode 2 Step 24 Loss: 1208.27587890625
[Actor] Episode 2 Step 25 Loss: 1172.2606201171875
[Actor] Episode 2 Step 26 Loss: 1311.4710693359375
-------------------------------------------------
[Actor] Episode 2 Average Loss: 1304.9842755353009
[Actor] Learning Rate: 0.00989068765193224
[Actor] Epoch Time: 814.0309739112854s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 1364.14794921875
[Actor] Episode 3 Step 1 Loss: 1200.5582275390625
[Actor] Episode 3 Step 2 Loss: 1270.0845947265625
[Actor] Episode 3 Step 3 Loss: 1252.8326416015625
[Actor] Episode 3 Step 4 Loss: 1387.9755859375
[Actor] Episode 3 Step 5 Loss: 1273.7178955078125
[Actor] Episode 3 Step 6 Loss: 1153.2611083984375
[Actor] Episode 3 Step 7 Loss: 1088.81689453125
[Actor] Episode 3 Step 8 Loss: 1213.35546875
[Actor] Episode 3 Step 9 Loss: 1418.4697265625
[Actor] Episode 3 Step 10 Loss: 1126.899658203125
[Actor] Episode 3 Step 11 Loss: 1059.51806640625
[Actor] Episode 3 Step 12 Loss: 930.1143798828125
[Actor] Episode 3 Step 13 Loss: 1089.7176513671875
[Actor] Episode 3 Step 14 Loss: 1181.023193359375
[Actor] Episode 3 Step 15 Loss: 1086.44140625
[Actor] Episode 3 Step 16 Loss: 1039.806884765625
[Actor] Episode 3 Step 17 Loss: 1194.05859375
[Actor] Episode 3 Step 18 Loss: 1029.490966796875
[Actor] Episode 3 Step 19 Loss: 1178.638916015625
[Actor] Episode 3 Step 20 Loss: 1064.1629638671875
[Actor] Episode 3 Step 21 Loss: 1168.51416015625
[Actor] Episode 3 Step 22 Loss: 1009.0133666992188
[Actor] Episode 3 Step 23 Loss: 1323.858642578125
[Actor] Episode 3 Step 24 Loss: 1013.3875122070312
[Actor] Episode 3 Step 25 Loss: 995.8258666992188
[Actor] Episode 3 Step 26 Loss: 1039.0999755859375
-------------------------------------------------
[Actor] Episode 3 Average Loss: 1153.807122124566
[Actor] Learning Rate: 0.009854516014456749
[Actor] Epoch Time: 906.2147855758667s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 1185.8765869140625
[Actor] Episode 4 Step 1 Loss: 913.8716430664062
[Actor] Episode 4 Step 2 Loss: 1057.804443359375
[Actor] Episode 4 Step 3 Loss: 1105.33984375
[Actor] Episode 4 Step 4 Loss: 1036.6513671875
[Actor] Episode 4 Step 5 Loss: 1039.3199462890625
[Actor] Episode 4 Step 6 Loss: 1106.0633544921875
[Actor] Episode 4 Step 7 Loss: 997.8245239257812
[Actor] Episode 4 Step 8 Loss: 1122.100341796875
[Actor] Episode 4 Step 9 Loss: 1040.1016845703125
[Actor] Episode 4 Step 10 Loss: 1110.80859375
[Actor] Episode 4 Step 11 Loss: 927.2460327148438
[Actor] Episode 4 Step 12 Loss: 1079.0712890625
[Actor] Episode 4 Step 13 Loss: 1113.5279541015625
[Actor] Episode 4 Step 14 Loss: 1071.959228515625
[Actor] Episode 4 Step 15 Loss: 944.4171752929688
[Actor] Episode 4 Step 16 Loss: 1037.392822265625
[Actor] Episode 4 Step 17 Loss: 1059.0885009765625
[Actor] Episode 4 Step 18 Loss: 1101.8016357421875
[Actor] Episode 4 Step 19 Loss: 1045.4288330078125
[Actor] Episode 4 Step 20 Loss: 1044.385009765625
[Actor] Episode 4 Step 21 Loss: 1069.02880859375
[Actor] Episode 4 Step 22 Loss: 1131.2691650390625
[Actor] Episode 4 Step 23 Loss: 977.96337890625
[Actor] Episode 4 Step 24 Loss: 1028.046142578125
[Actor] Episode 4 Step 25 Loss: 1146.9986572265625
[Actor] Episode 4 Step 26 Loss: 1007.4403686523438
-------------------------------------------------
[Actor] Episode 4 Average Loss: 1055.5861974645543
[Actor] Learning Rate: 0.009818476624786854
[Actor] Epoch Time: 889.8743870258331s
-------------------------------------------------
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 1148.20751953125
[Actor] Episode 5 Step 1 Loss: 1061.212890625
[Actor] Episode 5 Step 2 Loss: 1080.083251953125
[Actor] Episode 5 Step 3 Loss: 1044.3101806640625
[Actor] Episode 5 Step 4 Loss: 1107.275390625
[Actor] Episode 5 Step 5 Loss: 1130.3397216796875
[Actor] Episode 5 Step 6 Loss: 1044.968017578125
[Actor] Episode 5 Step 7 Loss: 1070.498779296875
[Actor] Episode 5 Step 8 Loss: 1004.7055053710938
[Actor] Episode 5 Step 9 Loss: 1056.5836181640625
[Actor] Episode 5 Step 10 Loss: 901.27001953125
[Actor] Episode 5 Step 11 Loss: 1153.8785400390625
[Actor] Episode 5 Step 12 Loss: 1011.3582763671875
[Actor] Episode 5 Step 13 Loss: 1048.6864013671875
[Actor] Episode 5 Step 14 Loss: 918.6615600585938
[Actor] Episode 5 Step 15 Loss: 930.038330078125
[Actor] Episode 5 Step 16 Loss: 1100.541748046875
[Actor] Episode 5 Step 17 Loss: 861.390869140625
[Actor] Episode 5 Step 18 Loss: 1009.799072265625
[Actor] Episode 5 Step 19 Loss: 957.787841796875
[Actor] Episode 5 Step 20 Loss: 987.9075927734375
[Actor] Episode 5 Step 21 Loss: 923.3242797851562
[Actor] Episode 5 Step 22 Loss: 1009.9114990234375
[Actor] Episode 5 Step 23 Loss: 1040.425048828125
[Actor] Episode 5 Step 24 Loss: 1055.1966552734375
[Actor] Episode 5 Step 25 Loss: 978.4440307617188
[Actor] Episode 5 Step 26 Loss: 1014.7965087890625
-------------------------------------------------
[Actor] Episode 5 Average Loss: 1024.1334499782986
[Actor] Learning Rate: 0.009782569482922554
[Actor] Epoch Time: 880.4733436107635s
-------------------------------------------------
[Actor] Starting Episode 6
2021-03-28 13:21:35.483294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:3778): Gdk-CRITICAL **: 13:21:43.494: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-28 13:21:43.959283: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 13:21:43.960443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 13:21:44.020035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.020764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 13:21:44.020795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:21:44.042248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 13:21:44.042366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 13:21:44.068476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 13:21:44.077606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 13:21:44.111006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 13:21:44.118326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 13:21:44.121431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 13:21:44.121667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.122534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.123160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 13:21:44.308641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 13:21:44.308935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 13:21:44.309208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.309936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 13:21:44.309966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:21:44.310121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 13:21:44.310156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 13:21:44.310183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 13:21:44.310208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 13:21:44.310233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 13:21:44.310257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 13:21:44.310283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 13:21:44.310405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.311177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:44.311761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 13:21:44.312854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:21:46.104163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 13:21:46.104204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 13:21:46.104216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 13:21:46.104682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:46.105586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:46.106343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:21:46.107028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-28 13:22:14.652950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:4076): Gdk-CRITICAL **: 13:22:18.089: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-28 13:22:18.409493: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 13:22:18.410932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-28 13:22:18.474529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.475497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 13:22:18.475549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:22:18.480083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 13:22:18.480244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 13:22:18.482028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 13:22:18.482419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 13:22:18.486969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 13:22:18.488103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 13:22:18.488345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 13:22:18.488577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.489986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.490914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-28 13:22:18.746741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-28 13:22:18.747001: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-28 13:22:18.747326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.748294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-28 13:22:18.748342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:22:18.748640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 13:22:18.748724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-28 13:22:18.748781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-28 13:22:18.748836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-28 13:22:18.748895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-28 13:22:18.748964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-28 13:22:18.758632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-28 13:22:18.758863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.759836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:18.760605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-28 13:22:18.760661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-28 13:22:19.551324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-28 13:22:19.551369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-28 13:22:19.551382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-28 13:22:19.551761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:19.552810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:19.553806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-28 13:22:19.554612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616937742.859493096, 5134.336000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616937742.860295208, 5134.337000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616937742.860384904, 5134.337000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616937744.133529803, 5135.606000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616937744.546635471, 5136.017000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616937744.947823852, 5136.417000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616937745.551410002, 5137.017000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-28 13:22:54.913108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-28 13:22:56.329028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2774.3505859375
[Actor] Episode 0 Step 1 Loss: 2475.260498046875
[Actor] Episode 0 Step 2 Loss: 2664.55859375
[Actor] Episode 0 Step 3 Loss: 2384.437255859375
[Actor] Episode 0 Step 4 Loss: 2385.7890625
[Actor] Episode 0 Step 5 Loss: 2422.564697265625
[Actor] Episode 0 Step 6 Loss: 2046.2159423828125
[Actor] Episode 0 Step 7 Loss: 2012.869140625
[Actor] Episode 0 Step 8 Loss: 2211.612060546875
[Actor] Episode 0 Step 9 Loss: 2227.369873046875
[Actor] Episode 0 Step 10 Loss: 1970.7498779296875
[Actor] Episode 0 Step 11 Loss: 2264.541748046875
[Actor] Episode 0 Step 12 Loss: 2240.363525390625
[Actor] Episode 0 Step 13 Loss: 1965.9161376953125
[Actor] Episode 0 Step 14 Loss: 2000.9703369140625
[Actor] Episode 0 Step 15 Loss: 2097.94384765625
[Actor] Episode 0 Step 16 Loss: 2007.4534912109375
[Actor] Episode 0 Step 17 Loss: 1923.1455078125
[Actor] Episode 0 Step 18 Loss: 1886.8839111328125
[Actor] Episode 0 Step 19 Loss: 1721.098876953125
[Actor] Episode 0 Step 20 Loss: 1912.703369140625
[Actor] Episode 0 Step 21 Loss: 1763.2266845703125
[Actor] Episode 0 Step 22 Loss: 1958.1927490234375
[Actor] Episode 0 Step 23 Loss: 1773.9605712890625
[Actor] Episode 0 Step 24 Loss: 2028.6431884765625
[Actor] Episode 0 Step 25 Loss: 2013.9093017578125
[Actor] Episode 0 Step 26 Loss: 1821.03369140625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 2109.4727602358216
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 762.8515186309814s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 1752.91259765625
[Actor] Episode 1 Step 1 Loss: 1901.048095703125
[Actor] Episode 1 Step 2 Loss: 1837.4627685546875
[Actor] Episode 1 Step 3 Loss: 1673.2425537109375
[Actor] Episode 1 Step 4 Loss: 1812.09619140625
[Actor] Episode 1 Step 5 Loss: 1746.8319091796875
[Actor] Episode 1 Step 6 Loss: 1797.343017578125
[Actor] Episode 1 Step 7 Loss: 1823.693115234375
[Actor] Episode 1 Step 8 Loss: 1499.043701171875
[Actor] Episode 1 Step 9 Loss: 1625.0765380859375
[Actor] Episode 1 Step 10 Loss: 1637.9259033203125
[Actor] Episode 1 Step 11 Loss: 1601.1182861328125
[Actor] Episode 1 Step 12 Loss: 1825.2833251953125
[Actor] Episode 1 Step 13 Loss: 1937.989990234375
[Actor] Episode 1 Step 14 Loss: 1338.255126953125
[Actor] Episode 1 Step 15 Loss: 1524.553955078125
[Actor] Episode 1 Step 16 Loss: 1414.68896484375
[Actor] Episode 1 Step 17 Loss: 1579.222412109375
[Actor] Episode 1 Step 18 Loss: 1533.968017578125
[Actor] Episode 1 Step 19 Loss: 1506.7427978515625
[Actor] Episode 1 Step 20 Loss: 1599.6671142578125
[Actor] Episode 1 Step 21 Loss: 1476.5086669921875
[Actor] Episode 1 Step 22 Loss: 1276.981689453125
[Actor] Episode 1 Step 23 Loss: 1477.411376953125
[Actor] Episode 1 Step 24 Loss: 1502.468994140625
[Actor] Episode 1 Step 25 Loss: 1372.6300048828125
[Actor] Episode 1 Step 26 Loss: 1626.9669189453125
-------------------------------------------------
[Actor] Episode 1 Average Loss: 1618.560519748264
[Actor] Learning Rate: 0.009926991537213326
[Actor] Epoch Time: 758.3502988815308s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 1552.9498291015625
[Actor] Episode 2 Step 1 Loss: 1393.0413818359375
[Actor] Episode 2 Step 2 Loss: 1311.5302734375
[Actor] Episode 2 Step 3 Loss: 1290.1591796875
[Actor] Episode 2 Step 4 Loss: 1542.38671875
[Actor] Episode 2 Step 5 Loss: 1456.575927734375
[Actor] Episode 2 Step 6 Loss: 1300.463623046875
[Actor] Episode 2 Step 7 Loss: 1298.556396484375
[Actor] Episode 2 Step 8 Loss: 1425.39501953125
[Actor] Episode 2 Step 9 Loss: 1373.0283203125
[Actor] Episode 2 Step 10 Loss: 1413.656494140625
[Actor] Episode 2 Step 11 Loss: 1222.767578125
[Actor] Episode 2 Step 12 Loss: 1330.8978271484375
[Actor] Episode 2 Step 13 Loss: 1389.0701904296875
[Actor] Episode 2 Step 14 Loss: 1392.283935546875
[Actor] Episode 2 Step 15 Loss: 1226.4840087890625
[Actor] Episode 2 Step 16 Loss: 1340.502197265625
[Actor] Episode 2 Step 17 Loss: 1282.48828125
[Actor] Episode 2 Step 18 Loss: 1080.9427490234375
[Actor] Episode 2 Step 19 Loss: 1305.9749755859375
[Actor] Episode 2 Step 20 Loss: 1303.063720703125
[Actor] Episode 2 Step 21 Loss: 1222.1259765625
[Actor] Episode 2 Step 22 Loss: 1301.104736328125
[Actor] Episode 2 Step 23 Loss: 1128.978515625
[Actor] Episode 2 Step 24 Loss: 1135.3653564453125
[Actor] Episode 2 Step 25 Loss: 1247.703125
[Actor] Episode 2 Step 26 Loss: 1267.7777099609375
-------------------------------------------------
[Actor] Episode 2 Average Loss: 1316.1212610315395
[Actor] Learning Rate: 0.00989068765193224
[Actor] Epoch Time: 777.2099304199219s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 1234.6177978515625
[Actor] Episode 3 Step 1 Loss: 1359.7911376953125
[Actor] Episode 3 Step 2 Loss: 1047.8187255859375
[Actor] Episode 3 Step 3 Loss: 1182.8123779296875
[Actor] Episode 3 Step 4 Loss: 1285.7000732421875
[Actor] Episode 3 Step 5 Loss: 1140.55517578125
[Actor] Episode 3 Step 6 Loss: 1150.6455078125
[Actor] Episode 3 Step 7 Loss: 1139.906494140625
[Actor] Episode 3 Step 8 Loss: 1163.899169921875
[Actor] Episode 3 Step 9 Loss: 1271.750732421875
[Actor] Episode 3 Step 10 Loss: 1121.4453125
[Actor] Episode 3 Step 11 Loss: 1086.9150390625
[Actor] Episode 3 Step 12 Loss: 995.4105224609375
[Actor] Episode 3 Step 13 Loss: 1259.791259765625
[Actor] Episode 3 Step 14 Loss: 1028.285400390625
[Actor] Episode 3 Step 15 Loss: 1178.28857421875
[Actor] Episode 3 Step 16 Loss: 1178.2752685546875
[Actor] Episode 3 Step 17 Loss: 1261.645263671875
[Actor] Episode 3 Step 18 Loss: 1151.961181640625
[Actor] Episode 3 Step 19 Loss: 1285.22216796875
[Actor] Episode 3 Step 20 Loss: 1234.5228271484375
[Actor] Episode 3 Step 21 Loss: 1141.115478515625
[Actor] Episode 3 Step 22 Loss: 1034.9671630859375
[Actor] Episode 3 Step 23 Loss: 1177.094970703125
[Actor] Episode 3 Step 24 Loss: 1052.469482421875
[Actor] Episode 3 Step 25 Loss: 1283.7845458984375
[Actor] Episode 3 Step 26 Loss: 1117.4385986328125
-------------------------------------------------
[Actor] Episode 3 Average Loss: 1169.1159351490162
[Actor] Learning Rate: 0.009854516014456749
[Actor] Epoch Time: 803.4726121425629s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 1095.2720947265625
[Actor] Episode 4 Step 1 Loss: 1202.22802734375
[Actor] Episode 4 Step 2 Loss: 1202.2088623046875
[Actor] Episode 4 Step 3 Loss: 1141.2625732421875
[Actor] Episode 4 Step 4 Loss: 1074.880126953125
[Actor] Episode 4 Step 5 Loss: 1119.841064453125
[Actor] Episode 4 Step 6 Loss: 945.1276245117188
[Actor] Episode 4 Step 7 Loss: 1160.6126708984375
[Actor] Episode 4 Step 8 Loss: 1071.6827392578125
[Actor] Episode 4 Step 9 Loss: 1023.99853515625
[Actor] Episode 4 Step 10 Loss: 978.3493041992188
[Actor] Episode 4 Step 11 Loss: 1060.2724609375
[Actor] Episode 4 Step 12 Loss: 1077.65283203125
[Actor] Episode 4 Step 13 Loss: 1171.2926025390625
[Actor] Episode 4 Step 14 Loss: 1009.0658569335938
[Actor] Episode 4 Step 15 Loss: 1096.544189453125
[Actor] Episode 4 Step 16 Loss: 1066.5682373046875
[Actor] Episode 4 Step 17 Loss: 1110.137939453125
[Actor] Episode 4 Step 18 Loss: 1070.9691162109375
[Actor] Episode 4 Step 19 Loss: 1162.2255859375
[Actor] Episode 4 Step 20 Loss: 1018.2796020507812
[Actor] Episode 4 Step 21 Loss: 1031.765625
[Actor] Episode 4 Step 22 Loss: 1023.526611328125
[Actor] Episode 4 Step 23 Loss: 1016.6055908203125
[Actor] Episode 4 Step 24 Loss: 1047.923095703125
[Actor] Episode 4 Step 25 Loss: 1051.9346923828125
[Actor] Episode 4 Step 26 Loss: 1034.5025634765625
-------------------------------------------------
[Actor] Episode 4 Average Loss: 1076.4714898003472
[Actor] Learning Rate: 0.009818476624786854
[Actor] Epoch Time: 802.814567565918s
-------------------------------------------------
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 1084.4881591796875
[Actor] Episode 5 Step 1 Loss: 1063.9832763671875
[Actor] Episode 5 Step 2 Loss: 1025.4525146484375
[Actor] Episode 5 Step 3 Loss: 1013.2463989257812
[Actor] Episode 5 Step 4 Loss: 1140.2764892578125
[Actor] Episode 5 Step 5 Loss: 969.0383911132812
[Actor] Episode 5 Step 6 Loss: 1011.091064453125
[Actor] Episode 5 Step 7 Loss: 1041.4720458984375
[Actor] Episode 5 Step 8 Loss: 1044.414794921875
[Actor] Episode 5 Step 9 Loss: 1142.682861328125
[Actor] Episode 5 Step 10 Loss: 1024.18896484375
[Actor] Episode 5 Step 11 Loss: 1070.115234375
[Actor] Episode 5 Step 12 Loss: 1090.2830810546875
[Actor] Episode 5 Step 13 Loss: 928.8483276367188
[Actor] Episode 5 Step 14 Loss: 1124.974609375
[Actor] Episode 5 Step 15 Loss: 1092.050537109375
[Actor] Episode 5 Step 16 Loss: 1024.38427734375
[Actor] Episode 5 Step 17 Loss: 1072.4962158203125
[Actor] Episode 5 Step 18 Loss: 1094.44970703125
[Actor] Episode 5 Step 19 Loss: 1069.818603515625
[Actor] Episode 5 Step 20 Loss: 1062.2333984375
[Actor] Episode 5 Step 21 Loss: 1110.131591796875
[Actor] Episode 5 Step 22 Loss: 962.4551391601562
[Actor] Episode 5 Step 23 Loss: 995.6568603515625
[Actor] Episode 5 Step 24 Loss: 910.58056640625
[Actor] Episode 5 Step 25 Loss: 984.2081909179688
[Actor] Episode 5 Step 26 Loss: 1093.750244140625
-------------------------------------------------
[Actor] Episode 5 Average Loss: 1046.1767239040798
[Actor] Learning Rate: 0.009782569482922554
[Actor] Epoch Time: 772.7996459007263s
-------------------------------------------------
[Actor] Starting Episode 6
[Actor] Episode 6 Step 0 Loss: 882.2850341796875
[Actor] Episode 6 Step 1 Loss: 893.8287353515625
[Actor] Episode 6 Step 2 Loss: 1066.5416259765625
[Actor] Episode 6 Step 3 Loss: 978.9196166992188
[Actor] Episode 6 Step 4 Loss: 1022.8218383789062
[Actor] Episode 6 Step 5 Loss: 1037.0845947265625
[Actor] Episode 6 Step 6 Loss: 1123.5145263671875
[Actor] Episode 6 Step 7 Loss: 1099.7633056640625
[Actor] Episode 6 Step 8 Loss: 1011.3294067382812
[Actor] Episode 6 Step 9 Loss: 1008.0068359375
[Actor] Episode 6 Step 10 Loss: 1016.5218505859375
[Actor] Episode 6 Step 11 Loss: 1008.8030395507812
[Actor] Episode 6 Step 12 Loss: 962.6100463867188
[Actor] Episode 6 Step 13 Loss: 1044.3514404296875
[Actor] Episode 6 Step 14 Loss: 1014.9169311523438
[Actor] Episode 6 Step 15 Loss: 973.1903686523438
[Actor] Episode 6 Step 16 Loss: 1013.2695922851562
[Actor] Episode 6 Step 17 Loss: 1016.0960693359375
[Actor] Episode 6 Step 18 Loss: 915.5296020507812
[Actor] Episode 6 Step 19 Loss: 1090.40576171875
[Actor] Episode 6 Step 20 Loss: 1007.4552001953125
[Actor] Episode 6 Step 21 Loss: 1035.1307373046875
[Actor] Episode 6 Step 22 Loss: 1095.2135009765625
[Actor] Episode 6 Step 23 Loss: 996.4713134765625
[Actor] Episode 6 Step 24 Loss: 1075.2999267578125
[Actor] Episode 6 Step 25 Loss: 1032.310791015625
[Actor] Episode 6 Step 26 Loss: 1068.4232177734375
-------------------------------------------------
[Actor] Episode 6 Average Loss: 1018.1516633210359
[Actor] Learning Rate: 0.009746793657541275
[Actor] Epoch Time: 772.7979960441589s
-------------------------------------------------
[Actor] Starting Episode 7
[Actor] Episode 7 Step 0 Loss: 951.9398193359375
[Actor] Episode 7 Step 1 Loss: 945.6166381835938
[Actor] Episode 7 Step 2 Loss: 1071.824462890625
[Actor] Episode 7 Step 3 Loss: 999.8716430664062
[Actor] Episode 7 Step 4 Loss: 1105.660400390625
[Actor] Episode 7 Step 5 Loss: 1028.0753173828125
[Actor] Episode 7 Step 6 Loss: 1062.486083984375
[Actor] Episode 7 Step 7 Loss: 1047.0765380859375
[Actor] Episode 7 Step 8 Loss: 1145.3798828125
[Actor] Episode 7 Step 9 Loss: 903.0418701171875
[Actor] Episode 7 Step 10 Loss: 957.4008178710938
[Actor] Episode 7 Step 11 Loss: 1114.6160888671875
[Actor] Episode 7 Step 12 Loss: 869.2491455078125
[Actor] Episode 7 Step 13 Loss: 1095.0286865234375
[Actor] Episode 7 Step 14 Loss: 929.455322265625
[Actor] Episode 7 Step 15 Loss: 956.3887329101562
[Actor] Episode 7 Step 16 Loss: 1040.019287109375
[Actor] Episode 7 Step 17 Loss: 954.4307250976562
[Actor] Episode 7 Step 18 Loss: 1047.4569091796875
[Actor] Episode 7 Step 19 Loss: 1206.4346923828125
[Actor] Episode 7 Step 20 Loss: 963.280517578125
[Actor] Episode 7 Step 21 Loss: 1119.6201171875
[Actor] Episode 7 Step 22 Loss: 1148.6336669921875
[Actor] Episode 7 Step 23 Loss: 947.5458984375
[Actor] Episode 7 Step 24 Loss: 1072.8243408203125
[Actor] Episode 7 Step 25 Loss: 986.3435668945312
[Actor] Episode 7 Step 26 Loss: 1117.407958984375
-------------------------------------------------
[Actor] Episode 7 Average Loss: 1029.1521900318287
[Actor] Learning Rate: 0.009711148217320442
[Actor] Epoch Time: 780.6642270088196s
-------------------------------------------------
[Actor] Starting Episode 8
[Actor] Episode 8 Step 0 Loss: 1000.8855590820312
[Actor] Episode 8 Step 1 Loss: 963.6842041015625
[Actor] Episode 8 Step 2 Loss: 1033.451171875
[Actor] Episode 8 Step 3 Loss: 987.8272094726562
[Actor] Episode 8 Step 4 Loss: 895.1669921875
[Actor] Episode 8 Step 5 Loss: 1176.1552734375
[Actor] Episode 8 Step 6 Loss: 1057.6455078125
[Actor] Episode 8 Step 7 Loss: 970.5926513671875
[Actor] Episode 8 Step 8 Loss: 993.3270263671875
[Actor] Episode 8 Step 9 Loss: 1022.1553344726562
[Actor] Episode 8 Step 10 Loss: 1027.3853759765625
[Actor] Episode 8 Step 11 Loss: 1117.462646484375
[Actor] Episode 8 Step 12 Loss: 1013.650390625
[Actor] Episode 8 Step 13 Loss: 1016.606689453125
[Actor] Episode 8 Step 14 Loss: 1138.4310302734375
[Actor] Episode 8 Step 15 Loss: 914.1573486328125
[Actor] Episode 8 Step 16 Loss: 1032.544677734375
[Actor] Episode 8 Step 17 Loss: 1011.1806030273438
[Actor] Episode 8 Step 18 Loss: 1145.3348388671875
[Actor] Episode 8 Step 19 Loss: 951.2945556640625
[Actor] Episode 8 Step 20 Loss: 980.6587524414062
[Actor] Episode 8 Step 21 Loss: 958.2425537109375
[Actor] Episode 8 Step 22 Loss: 1041.30859375
[Actor] Episode 8 Step 23 Loss: 1104.884765625
[Actor] Episode 8 Step 24 Loss: 1037.0379638671875
[Actor] Episode 8 Step 25 Loss: 1026.173583984375
[Actor] Episode 8 Step 26 Loss: 937.4663696289062
-------------------------------------------------
[Actor] Episode 8 Average Loss: 1020.5448766637732
[Actor] Learning Rate: 0.00967563409358263
[Actor] Epoch Time: 815.4825389385223s
-------------------------------------------------
[Actor] Starting Episode 9
[Actor] Episode 9 Step 0 Loss: 1036.906005859375
[Actor] Episode 9 Step 1 Loss: 1106.7427978515625
[Actor] Episode 9 Step 2 Loss: 978.1980590820312
[Actor] Episode 9 Step 3 Loss: 970.6990356445312
[Actor] Episode 9 Step 4 Loss: 1025.5826416015625
[Actor] Episode 9 Step 5 Loss: 953.6622314453125
[Actor] Episode 9 Step 6 Loss: 894.5594482421875
[Actor] Episode 9 Step 7 Loss: 901.6516723632812
[Actor] Episode 9 Step 8 Loss: 1075.702880859375
[Actor] Episode 9 Step 9 Loss: 951.9440307617188
[Actor] Episode 9 Step 10 Loss: 1085.463134765625
[Actor] Episode 9 Step 11 Loss: 1050.3206787109375
[Actor] Episode 9 Step 12 Loss: 1104.3287353515625
[Actor] Episode 9 Step 13 Loss: 1113.6195068359375
[Actor] Episode 9 Step 14 Loss: 961.6961059570312
[Actor] Episode 9 Step 15 Loss: 1018.0540771484375
[Actor] Episode 9 Step 16 Loss: 972.297607421875
[Actor] Episode 9 Step 17 Loss: 903.9684448242188
[Actor] Episode 9 Step 18 Loss: 1079.48828125
[Actor] Episode 9 Step 19 Loss: 1157.3114013671875
[Actor] Episode 9 Step 20 Loss: 1015.6740112304688
[Actor] Episode 9 Step 21 Loss: 1087.3685302734375
[Actor] Episode 9 Step 22 Loss: 919.620849609375
[Actor] Episode 9 Step 23 Loss: 966.3878173828125
[Actor] Episode 9 Step 24 Loss: 967.9979248046875
[Actor] Episode 9 Step 25 Loss: 980.5845947265625
[Actor] Episode 9 Step 26 Loss: 998.2440185546875
-------------------------------------------------
[Actor] Episode 9 Average Loss: 1010.2990564416956
[Actor] Learning Rate: 0.00964024942368269
[Actor] Epoch Time: 782.4248168468475s
-------------------------------------------------
[Actor] Starting Episode 10
[Actor] Episode 10 Step 0 Loss: 1008.0958251953125
[Actor] Episode 10 Step 1 Loss: 949.1826171875
[Actor] Episode 10 Step 2 Loss: 928.8626098632812
[Actor] Episode 10 Step 3 Loss: 1011.8231201171875
[Actor] Episode 10 Step 4 Loss: 1012.123046875
[Actor] Episode 10 Step 5 Loss: 1047.3555908203125
[Actor] Episode 10 Step 6 Loss: 990.096923828125
[Actor] Episode 10 Step 7 Loss: 1096.367919921875
[Actor] Episode 10 Step 8 Loss: 1071.6898193359375
[Actor] Episode 10 Step 9 Loss: 1072.84521484375
[Actor] Episode 10 Step 10 Loss: 1004.1026000976562
[Actor] Episode 10 Step 11 Loss: 978.042236328125
[Actor] Episode 10 Step 12 Loss: 1127.5777587890625
[Actor] Episode 10 Step 13 Loss: 970.4354248046875
[Actor] Episode 10 Step 14 Loss: 1098.370361328125
[Actor] Episode 10 Step 15 Loss: 1096.5677490234375
[Actor] Episode 10 Step 16 Loss: 938.8865966796875
[Actor] Episode 10 Step 17 Loss: 1120.9541015625
[Actor] Episode 10 Step 18 Loss: 979.3488159179688
[Actor] Episode 10 Step 19 Loss: 1028.8887939453125
[Actor] Episode 10 Step 20 Loss: 1022.73681640625
[Actor] Episode 10 Step 21 Loss: 966.6942749023438
[Actor] Episode 10 Step 22 Loss: 1090.406982421875
[Actor] Episode 10 Step 23 Loss: 1037.09228515625
[Actor] Episode 10 Step 24 Loss: 955.4479370117188
[Actor] Episode 10 Step 25 Loss: 933.0567016601562
[Actor] Episode 10 Step 26 Loss: 925.295166015625
-------------------------------------------------
[Actor] Episode 10 Average Loss: 1017.1239737051504
[Actor] Learning Rate: 0.00960499420762062
[Actor] Epoch Time: 821.7918727397919s
-------------------------------------------------
[Actor] Starting Episode 11
[Actor] Episode 11 Step 0 Loss: 984.7398681640625
[Actor] Episode 11 Step 1 Loss: 981.7684936523438
[Actor] Episode 11 Step 2 Loss: 886.9944458007812
[Actor] Episode 11 Step 3 Loss: 907.6168212890625
[Actor] Episode 11 Step 4 Loss: 924.1117553710938
[Actor] Episode 11 Step 5 Loss: 987.8800659179688
[Actor] Episode 11 Step 6 Loss: 947.2980346679688
[Actor] Episode 11 Step 7 Loss: 980.0001831054688
[Actor] Episode 11 Step 8 Loss: 950.6248168945312
[Actor] Episode 11 Step 9 Loss: 1029.623291015625
[Actor] Episode 11 Step 10 Loss: 999.953369140625
[Actor] Episode 11 Step 11 Loss: 1076.0418701171875
[Actor] Episode 11 Step 12 Loss: 1036.5751953125
[Actor] Episode 11 Step 13 Loss: 993.06103515625
[Actor] Episode 11 Step 14 Loss: 1031.3052978515625
[Actor] Episode 11 Step 15 Loss: 1111.53369140625
[Actor] Episode 11 Step 16 Loss: 1094.6832275390625
[Actor] Episode 11 Step 17 Loss: 1065.5079345703125
[Actor] Episode 11 Step 18 Loss: 885.0320434570312
[Actor] Episode 11 Step 19 Loss: 1079.3162841796875
[Actor] Episode 11 Step 20 Loss: 935.3576049804688
[Actor] Episode 11 Step 21 Loss: 1035.0430908203125
[Actor] Episode 11 Step 22 Loss: 1032.4757080078125
[Actor] Episode 11 Step 23 Loss: 976.717041015625
[Actor] Episode 11 Step 24 Loss: 1080.6220703125
[Actor] Episode 11 Step 25 Loss: 935.751708984375
[Actor] Episode 11 Step 26 Loss: 1070.65234375
-------------------------------------------------
[Actor] Episode 11 Average Loss: 1000.7513812029803
[Actor] Learning Rate: 0.009569867514073849
[Actor] Epoch Time: 802.3516314029694s
-------------------------------------------------
[Actor] Starting Episode 12
[Actor] Episode 12 Step 0 Loss: 1031.0384521484375
[Actor] Episode 12 Step 1 Loss: 931.7540893554688
[Actor] Episode 12 Step 2 Loss: 1005.1841430664062
[Actor] Episode 12 Step 3 Loss: 929.7169189453125
[Actor] Episode 12 Step 4 Loss: 1033.38134765625
[Actor] Episode 12 Step 5 Loss: 944.7427978515625
[Actor] Episode 12 Step 6 Loss: 1007.7176513671875
[Actor] Episode 12 Step 7 Loss: 964.308837890625
[Actor] Episode 12 Step 8 Loss: 1092.5130615234375
[Actor] Episode 12 Step 9 Loss: 1016.9173583984375
[Actor] Episode 12 Step 10 Loss: 1010.6694946289062
[Actor] Episode 12 Step 11 Loss: 1049.4254150390625
[Actor] Episode 12 Step 12 Loss: 1052.5164794921875
[Actor] Episode 12 Step 13 Loss: 1000.33056640625
[Actor] Episode 12 Step 14 Loss: 996.4683837890625
[Actor] Episode 12 Step 15 Loss: 1053.6605224609375
[Actor] Episode 12 Step 16 Loss: 987.8096313476562
[Actor] Episode 12 Step 17 Loss: 1079.0887451171875
[Actor] Episode 12 Step 18 Loss: 1025.277587890625
[Actor] Episode 12 Step 19 Loss: 1075.7200927734375
[Actor] Episode 12 Step 20 Loss: 960.931396484375
[Actor] Episode 12 Step 21 Loss: 991.4620361328125
[Actor] Episode 12 Step 22 Loss: 1054.5567626953125
[Actor] Episode 12 Step 23 Loss: 1002.7849731445312
[Actor] Episode 12 Step 24 Loss: 1020.988525390625
[Actor] Episode 12 Step 25 Loss: 979.382568359375
[Actor] Episode 12 Step 26 Loss: 1031.396484375
-------------------------------------------------
[Actor] Episode 12 Average Loss: 1012.2127527307581
[Actor] Learning Rate: 0.009534869343042374
[Actor] Epoch Time: 784.0834724903107s
-------------------------------------------------
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
[Actor] Episode 0 Step 0 Loss: 980.7326049804688
[Actor] Episode 0 Step 1 Loss: 1040.017578125
[Actor] Episode 0 Step 2 Loss: 1021.612060546875
[Actor] Episode 0 Step 3 Loss: 1006.2457885742188
[Actor] Episode 0 Step 4 Loss: 1076.0618896484375
[Actor] Episode 0 Step 5 Loss: 1048.8531494140625
[Actor] Episode 0 Step 6 Loss: 996.2711791992188
[Actor] Episode 0 Step 7 Loss: 982.6234741210938
[Actor] Episode 0 Step 8 Loss: 1021.28466796875
[Actor] Episode 0 Step 9 Loss: 966.6441040039062
[Actor] Episode 0 Step 10 Loss: 998.489013671875
[Actor] Episode 0 Step 11 Loss: 976.8573608398438
[Actor] Episode 0 Step 12 Loss: 1050.038818359375
[Actor] Episode 0 Step 13 Loss: 1048.28076171875
[Actor] Episode 0 Step 14 Loss: 897.8130493164062
[Actor] Episode 0 Step 15 Loss: 1002.268798828125
[Actor] Episode 0 Step 16 Loss: 1036.6317138671875
[Actor] Episode 0 Step 17 Loss: 928.6390380859375
[Actor] Episode 0 Step 18 Loss: 839.2556762695312
[Actor] Episode 0 Step 19 Loss: 885.5805053710938
[Actor] Episode 0 Step 20 Loss: 858.7630615234375
[Actor] Episode 0 Step 21 Loss: 924.4806518554688
[Actor] Episode 0 Step 22 Loss: 800.6873168945312
[Actor] Episode 0 Step 23 Loss: 982.7637939453125
[Actor] Episode 0 Step 24 Loss: 786.265625
[Actor] Episode 0 Step 25 Loss: 849.8681030273438
[Actor] Episode 0 Step 26 Loss: 754.8438720703125
-------------------------------------------------
[Actor] Episode 0 Average Loss: 954.143468786169
[Actor] Learning Rate: 0.009963428601622581
[Actor] Epoch Time: 1406.1195158958435s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 728.4705200195312
[Actor] Episode 1 Step 1 Loss: 759.34619140625
[Actor] Episode 1 Step 2 Loss: 866.7373046875
[Actor] Episode 1 Step 3 Loss: 789.1583862304688
[Actor] Episode 1 Step 4 Loss: 647.1953735351562
[Actor] Episode 1 Step 5 Loss: 624.8218994140625
[Actor] Episode 1 Step 6 Loss: 575.8941040039062
[Actor] Episode 1 Step 7 Loss: 651.039794921875
[Actor] Episode 1 Step 8 Loss: 624.4269409179688
[Actor] Episode 1 Step 9 Loss: 660.3056030273438
[Actor] Episode 1 Step 10 Loss: 573.6567993164062
[Actor] Episode 1 Step 11 Loss: 655.295654296875
[Actor] Episode 1 Step 12 Loss: 570.4465942382812
[Actor] Episode 1 Step 13 Loss: 620.32568359375
[Actor] Episode 1 Step 14 Loss: 696.0257568359375
[Actor] Episode 1 Step 15 Loss: 573.6057739257812
[Actor] Episode 1 Step 16 Loss: 616.9788818359375
[Actor] Episode 1 Step 17 Loss: 557.21142578125
[Actor] Episode 1 Step 18 Loss: 672.7675170898438
[Actor] Episode 1 Step 19 Loss: 551.1080932617188
[Actor] Episode 1 Step 20 Loss: 708.3179321289062
[Actor] Episode 1 Step 21 Loss: 508.5901184082031
[Actor] Episode 1 Step 22 Loss: 528.9299926757812
[Actor] Episode 1 Step 23 Loss: 591.6895141601562
[Actor] Episode 1 Step 24 Loss: 489.6144714355469
[Actor] Episode 1 Step 25 Loss: 504.0930480957031
[Actor] Episode 1 Step 26 Loss: 553.31884765625
-------------------------------------------------
[Actor] Episode 1 Average Loss: 625.9026749222367
[Actor] Learning Rate: 0.009926991537213326
[Actor] Epoch Time: 1490.7648124694824s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 589.663818359375
[Actor] Episode 2 Step 1 Loss: 475.38446044921875
[Actor] Episode 2 Step 2 Loss: 616.6332397460938
[Actor] Episode 2 Step 3 Loss: 591.169189453125
[Actor] Episode 2 Step 4 Loss: 551.81201171875
[Actor] Episode 2 Step 5 Loss: 441.9855651855469
[Actor] Episode 2 Step 6 Loss: 522.7155151367188
[Actor] Episode 2 Step 7 Loss: 534.0743408203125
[Actor] Episode 2 Step 8 Loss: 499.3860778808594
[Actor] Episode 2 Step 9 Loss: 433.2607727050781
[Actor] Episode 2 Step 10 Loss: 535.0280151367188
[Actor] Episode 2 Step 11 Loss: 451.2891845703125
[Actor] Episode 2 Step 12 Loss: 426.4078063964844
[Actor] Episode 2 Step 13 Loss: 445.3050842285156
[Actor] Episode 2 Step 14 Loss: 437.93359375
[Actor] Episode 2 Step 15 Loss: 419.3627014160156
[Actor] Episode 2 Step 16 Loss: 426.2709655761719
[Actor] Episode 2 Step 17 Loss: 423.3105773925781
[Actor] Episode 2 Step 18 Loss: 458.3331604003906
2021-03-29 05:11:36.534557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:3232): Gdk-CRITICAL **: 05:12:19.453: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:12:30.993785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:3538): Gdk-CRITICAL **: 05:12:34.645: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:12:36.568513: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:12:36.571590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:12:37.222757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:37.223387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:12:37.223570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:12:38.739956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:12:38.740222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:12:39.370300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:12:39.770507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:12:41.269702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:12:41.778868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:12:41.882903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:12:41.883145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:41.883941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:42.118563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:12:42.606313: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:12:42.606685: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:12:42.606990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:42.607639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:12:42.607679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:12:42.607942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:12:42.608068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:12:42.608156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:12:42.608229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:12:42.608293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:12:42.608352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:12:42.608411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:12:42.608558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:42.609346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:12:42.609962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:12:42.697023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:13:22.102364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:13:22.102422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:13:22.102439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:13:22.202547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:13:22.203367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:13:22.204102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:13:22.204717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 05:13:58.237689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:3779): Gdk-CRITICAL **: 05:14:01.482: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:14:01.860826: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:14:01.862838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:14:01.966683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:01.967667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:14:01.967794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:14:01.971823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:14:01.972117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:14:01.973855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:14:01.974489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:14:01.978934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:14:01.980456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:14:01.980787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:14:01.981051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:01.982353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:01.983473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:14:02.286757: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:14:02.287023: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:14:02.287341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:02.288250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:14:02.288399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:14:02.288678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:14:02.288886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:14:02.289014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:14:02.289167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:14:02.289304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:14:02.289392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:14:02.289459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:14:02.289632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:02.290434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:02.291025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:14:02.291128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:14:03.069336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:14:03.069381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:14:03.069393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:14:03.069730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:03.070783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:03.071663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:14:03.072435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616994846.029040086, 115.879000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616994846.029843353, 115.881000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616994846.029904300, 115.881000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616994847.295006628, 117.144000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616994847.616651402, 117.464000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616994848.018684786, 117.864000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616994848.418491614, 118.263000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for weights/actor_pretrain/exp16/pretrain_actor/actor_pretrained_pretrain_enc_16_9.ckpt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "learn.py", line 991, in <module>
    learner.load_actor(
  File "learn.py", line 550, in load_actor
    self.actor.model.load_weights(path)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 2199, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 99, in NewCheckpointReader
    error_translator(e)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for weights/actor_pretrain/exp16/pretrain_actor/actor_pretrained_pretrain_enc_16_9.ckpt
2021-03-29 05:15:15.290659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:4153): Gdk-CRITICAL **: 05:15:18.473: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:15:18.874611: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:15:18.876028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:15:18.986236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:18.987261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:15:18.988443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:18.999454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:15:19.000439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:15:19.004023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:15:19.005309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:15:19.016765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:15:19.019431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:15:19.019920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:15:19.020770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:19.023695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:19.025656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:15:19.317533: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:15:19.317983: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:15:19.318560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:19.319639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:15:19.319784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:19.320165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:15:19.320378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:15:19.320527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:15:19.320666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:15:19.320840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:15:19.320971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:15:19.321106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:15:19.321485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:19.322563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:19.323590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:15:19.323710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:20.289310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:15:20.289350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:15:20.289361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:15:20.289751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:20.290758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:20.291732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:20.292521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 05:15:52.360086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:4392): Gdk-CRITICAL **: 05:15:55.845: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:15:56.134970: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:15:56.136311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:15:56.206772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.208010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:15:56.208161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:56.215488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:15:56.215734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:15:56.218384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:15:56.219056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:15:56.224636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:15:56.226405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:15:56.226776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:15:56.227090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.228474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.229747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:15:56.496856: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:15:56.497155: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:15:56.497481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.498464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:15:56.498512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:56.498718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:15:56.498800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:15:56.498870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:15:56.498933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:15:56.498995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:15:56.499059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:15:56.499124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:15:56.499307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.500191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:56.500926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:15:56.501003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:15:57.271240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:15:57.271282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:15:57.271294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:15:57.271631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:57.272486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:57.273273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:15:57.273949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616994960.343301237, 228.279000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616994960.344145106, 228.280000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616994960.344200770, 228.280000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616994961.621901396, 229.556000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616994961.926443337, 229.860000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616994962.327908894, 230.261000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616994962.730715561, 230.662000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 05:16:26.935540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:16:53.396276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 973.426025390625
[Actor] Episode 0 Step 1 Loss: 900.2642211914062
[Actor] Episode 0 Step 2 Loss: 1061.865478515625
[Actor] Episode 0 Step 3 Loss: 1047.0948486328125
[Actor] Episode 0 Step 4 Loss: 940.9752807617188
[Actor] Episode 0 Step 5 Loss: 1037.00927734375
[Actor] Episode 0 Step 6 Loss: 1039.451904296875
[Actor] Episode 0 Step 7 Loss: 877.638671875
[Actor] Episode 0 Step 8 Loss: 1053.43603515625
[Actor] Episode 0 Step 9 Loss: 984.9393310546875
[Actor] Episode 0 Step 10 Loss: 1007.5653686523438
[Actor] Episode 0 Step 11 Loss: 995.0545654296875
[Actor] Episode 0 Step 12 Loss: 996.5516357421875
[Actor] Episode 0 Step 13 Loss: 917.8294677734375
[Actor] Episode 0 Step 14 Loss: 1007.8319702148438
[Actor] Episode 0 Step 15 Loss: 1000.8442993164062
[Actor] Episode 0 Step 16 Loss: 995.34228515625
[Actor] Episode 0 Step 17 Loss: 1006.0570678710938
[Actor] Episode 0 Step 18 Loss: 1051.6064453125
[Actor] Episode 0 Step 19 Loss: 934.0607299804688
[Actor] Episode 0 Step 20 Loss: 1083.222900390625
[Actor] Episode 0 Step 21 Loss: 968.4573974609375
[Actor] Episode 0 Step 22 Loss: 1037.2288818359375
[Actor] Episode 0 Step 23 Loss: 1037.275146484375
[Actor] Episode 0 Step 24 Loss: 1065.352783203125
[Actor] Episode 0 Step 25 Loss: 888.8529663085938
[Actor] Episode 0 Step 26 Loss: 1015.465576171875
-------------------------------------------------
[Actor] Episode 0 Average Loss: 997.2111319082754
[Actor] Learning Rate: 0.0009963428601622581
[Actor] Epoch Time: 1022.1522192955017s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 966.064208984375
[Actor] Episode 1 Step 1 Loss: 989.72412109375
[Actor] Episode 1 Step 2 Loss: 1089.7232666015625
[Actor] Episode 1 Step 3 Loss: 1078.4027099609375
[Actor] Episode 1 Step 4 Loss: 968.7144165039062
[Actor] Episode 1 Step 5 Loss: 1034.85498046875
[Actor] Episode 1 Step 6 Loss: 1032.140380859375
[Actor] Episode 1 Step 7 Loss: 1093.33544921875
[Actor] Episode 1 Step 8 Loss: 979.3560791015625
[Actor] Episode 1 Step 9 Loss: 1007.6973876953125
[Actor] Episode 1 Step 10 Loss: 924.2094116210938
[Actor] Episode 1 Step 11 Loss: 959.68310546875
[Actor] Episode 1 Step 12 Loss: 993.1049194335938
[Actor] Episode 1 Step 13 Loss: 866.8441162109375
2021-03-29 05:43:56.651544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:4958): Gdk-CRITICAL **: 05:43:59.874: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:44:00.109162: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:44:00.110149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:44:00.169227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.170203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:44:00.170249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:00.174075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:44:00.174234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:44:00.175896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:44:00.176343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:44:00.180683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:44:00.181663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:44:00.181907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:44:00.182095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.183116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.183922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:44:00.603109: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:44:00.603602: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:44:00.604573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.607183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:44:00.607944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:00.608384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:44:00.609408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:44:00.609596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:44:00.609758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:44:00.610526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:44:00.611079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:44:00.611432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:44:00.611853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.614774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:00.617665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:44:00.618464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:01.561582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:44:01.561622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:44:01.561631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:44:01.561944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:01.562824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:01.563599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:01.564171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
2021-03-29 05:44:36.784784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:5193): Gdk-CRITICAL **: 05:44:40.113: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-29 05:44:40.471109: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:44:40.472417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-29 05:44:40.586725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.588526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:44:40.588825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:40.599679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:44:40.600476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:44:40.604353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:44:40.605614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:44:40.627295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:44:40.629669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:44:40.629974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:44:40.630201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.631193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.631980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-29 05:44:40.870350: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 05:44:40.870595: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 05:44:40.870898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.871647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-29 05:44:40.871686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:40.871873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:44:40.871936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-29 05:44:40.871995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-29 05:44:40.872045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-29 05:44:40.872080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-29 05:44:40.872107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-29 05:44:40.872133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-29 05:44:40.872254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.873144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:40.873846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 05:44:40.873909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-29 05:44:41.612800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 05:44:41.612841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-29 05:44:41.612851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-29 05:44:41.613188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:41.614021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:41.614776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-29 05:44:41.615451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13963 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1616996684.723962334, 1919.201000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1616996684.724864136, 1919.202000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1616996684.724950489, 1919.202000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1616996685.839085585, 1920.314000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1616996686.247601265, 1920.721000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1616996686.648289859, 1921.122000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1616996687.048743119, 1921.522000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float64, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-29 05:45:11.301033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-29 05:45:11.907539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 1048.23876953125
[Actor] Episode 0 Step 1 Loss: 1010.306640625
[Actor] Episode 0 Step 2 Loss: 981.23876953125
[Actor] Episode 0 Step 3 Loss: 988.1609497070312
[Actor] Episode 0 Step 4 Loss: 1042.220458984375
[Actor] Episode 0 Step 5 Loss: 1079.2772216796875
[Actor] Episode 0 Step 6 Loss: 1104.057373046875
[Actor] Episode 0 Step 7 Loss: 941.5396118164062
[Actor] Episode 0 Step 8 Loss: 978.501220703125
[Actor] Episode 0 Step 9 Loss: 1143.9407958984375
[Actor] Episode 0 Step 10 Loss: 1079.7938232421875
[Actor] Episode 0 Step 11 Loss: 1072.8997802734375
[Actor] Episode 0 Step 12 Loss: 951.2373657226562
[Actor] Episode 0 Step 13 Loss: 1051.000244140625
[Actor] Episode 0 Step 14 Loss: 976.8919677734375
[Actor] Episode 0 Step 15 Loss: 1043.048583984375
[Actor] Episode 0 Step 16 Loss: 1184.4315185546875
[Actor] Episode 0 Step 17 Loss: 969.583740234375
[Actor] Episode 0 Step 18 Loss: 1001.6433715820312
[Actor] Episode 0 Step 19 Loss: 944.3175048828125
[Actor] Episode 0 Step 20 Loss: 951.1355590820312
[Actor] Episode 0 Step 21 Loss: 1011.649658203125
[Actor] Episode 0 Step 22 Loss: 956.6199340820312
[Actor] Episode 0 Step 23 Loss: 1044.13330078125
[Actor] Episode 0 Step 24 Loss: 944.0895385742188
[Actor] Episode 0 Step 25 Loss: 968.9493408203125
[Actor] Episode 0 Step 26 Loss: 916.644775390625
-------------------------------------------------
[Actor] Episode 0 Average Loss: 1014.2796969943577
[Actor] Learning Rate: 0.0009963428601622581
[Actor] Epoch Time: 1060.338547706604s
-------------------------------------------------
[Actor] Starting Episode 1
[Actor] Episode 1 Step 0 Loss: 995.549072265625
[Actor] Episode 1 Step 1 Loss: 1047.6588134765625
[Actor] Episode 1 Step 2 Loss: 926.0635986328125
[Actor] Episode 1 Step 3 Loss: 1029.8289794921875
[Actor] Episode 1 Step 4 Loss: 1135.317626953125
[Actor] Episode 1 Step 5 Loss: 1060.601806640625
[Actor] Episode 1 Step 6 Loss: 1027.3624267578125
[Actor] Episode 1 Step 7 Loss: 1028.6744384765625
[Actor] Episode 1 Step 8 Loss: 923.3951416015625
[Actor] Episode 1 Step 9 Loss: 908.7482299804688
[Actor] Episode 1 Step 10 Loss: 888.3937377929688
[Actor] Episode 1 Step 11 Loss: 1049.6402587890625
[Actor] Episode 1 Step 12 Loss: 998.5778198242188
[Actor] Episode 1 Step 13 Loss: 1175.708740234375
[Actor] Episode 1 Step 14 Loss: 1038.78662109375
[Actor] Episode 1 Step 15 Loss: 930.0682983398438
[Actor] Episode 1 Step 16 Loss: 1099.26025390625
[Actor] Episode 1 Step 17 Loss: 1026.05126953125
[Actor] Episode 1 Step 18 Loss: 995.3416137695312
[Actor] Episode 1 Step 19 Loss: 950.1363525390625
[Actor] Episode 1 Step 20 Loss: 950.8516845703125
[Actor] Episode 1 Step 21 Loss: 948.6279907226562
[Actor] Episode 1 Step 22 Loss: 993.0410766601562
[Actor] Episode 1 Step 23 Loss: 920.2992553710938
[Actor] Episode 1 Step 24 Loss: 1049.5888671875
[Actor] Episode 1 Step 25 Loss: 1120.694091796875
[Actor] Episode 1 Step 26 Loss: 1099.762939453125
-------------------------------------------------
[Actor] Episode 1 Average Loss: 1011.7789261429398
[Actor] Learning Rate: 0.000992699177004397
[Actor] Epoch Time: 1061.565167427063s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 973.1818237304688
[Actor] Episode 2 Step 1 Loss: 968.0332641601562
[Actor] Episode 2 Step 2 Loss: 945.8518676757812
[Actor] Episode 2 Step 3 Loss: 1042.98388671875
[Actor] Episode 2 Step 4 Loss: 948.1763305664062
[Actor] Episode 2 Step 5 Loss: 971.5062866210938
[Actor] Episode 2 Step 6 Loss: 1002.587646484375
[Actor] Episode 2 Step 7 Loss: 1052.8956298828125
[Actor] Episode 2 Step 8 Loss: 1039.8812255859375
[Actor] Episode 2 Step 9 Loss: 909.85791015625
[Actor] Episode 2 Step 10 Loss: 964.8322143554688
[Actor] Episode 2 Step 11 Loss: 1123.65234375
[Actor] Episode 2 Step 12 Loss: 1067.539794921875
[Actor] Episode 2 Step 13 Loss: 983.132080078125
[Actor] Episode 2 Step 14 Loss: 949.7520141601562
[Actor] Episode 2 Step 15 Loss: 1053.1458740234375
[Actor] Episode 2 Step 16 Loss: 1028.9774169921875
[Actor] Episode 2 Step 17 Loss: 850.3802490234375
[Actor] Episode 2 Step 18 Loss: 1065.991943359375
[Actor] Episode 2 Step 19 Loss: 975.2044677734375
[Actor] Episode 2 Step 20 Loss: 1002.90283203125
[Actor] Episode 2 Step 21 Loss: 899.5308837890625
[Actor] Episode 2 Step 22 Loss: 1095.6466064453125
[Actor] Episode 2 Step 23 Loss: 1006.6341552734375
[Actor] Episode 2 Step 24 Loss: 1041.092041015625
[Actor] Episode 2 Step 25 Loss: 915.2984008789062
[Actor] Episode 2 Step 26 Loss: 971.7450561523438
-------------------------------------------------
[Actor] Episode 2 Average Loss: 994.4597868742766
[Actor] Learning Rate: 0.000989068765193224
[Actor] Epoch Time: 1137.1561756134033s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 1016.7793579101562
[Actor] Episode 3 Step 1 Loss: 971.2974853515625
[Actor] Episode 3 Step 2 Loss: 927.8424682617188
[Actor] Episode 3 Step 3 Loss: 871.259033203125
[Actor] Episode 3 Step 4 Loss: 874.2991333007812
[Actor] Episode 3 Step 5 Loss: 934.5009765625
[Actor] Episode 3 Step 6 Loss: 949.1947631835938
[Actor] Episode 3 Step 7 Loss: 910.4199829101562
[Actor] Episode 3 Step 8 Loss: 812.5695190429688
[Actor] Episode 3 Step 9 Loss: 867.9229736328125
[Actor] Episode 3 Step 10 Loss: 907.3547973632812
[Actor] Episode 3 Step 11 Loss: 985.5792236328125
[Actor] Episode 3 Step 12 Loss: 851.7770385742188
[Actor] Episode 3 Step 13 Loss: 808.6275024414062
[Actor] Episode 3 Step 14 Loss: 931.3814086914062
[Actor] Episode 3 Step 15 Loss: 893.9700927734375
[Actor] Episode 3 Step 16 Loss: 877.8460693359375
[Actor] Episode 3 Step 17 Loss: 934.931396484375
[Actor] Episode 3 Step 18 Loss: 876.0778198242188
[Actor] Episode 3 Step 19 Loss: 898.3524169921875
[Actor] Episode 3 Step 20 Loss: 910.7659301757812
[Actor] Episode 3 Step 21 Loss: 873.5162353515625
[Actor] Episode 3 Step 22 Loss: 822.2279052734375
[Actor] Episode 3 Step 23 Loss: 790.259033203125
[Actor] Episode 3 Step 24 Loss: 941.849853515625
[Actor] Episode 3 Step 25 Loss: 769.9158325195312
[Actor] Episode 3 Step 26 Loss: 755.4495849609375
-------------------------------------------------
[Actor] Episode 3 Average Loss: 887.6284383138021
[Actor] Learning Rate: 0.000985451741144061
[Actor] Epoch Time: 1072.5567178726196s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 758.9537963867188
[Actor] Episode 4 Step 1 Loss: 885.9672241210938
[Actor] Episode 4 Step 2 Loss: 841.6369018554688
[Actor] Episode 4 Step 3 Loss: 812.6010131835938
[Actor] Episode 4 Step 4 Loss: 809.802001953125
[Actor] Episode 4 Step 5 Loss: 759.5868530273438
[Actor] Episode 4 Step 6 Loss: 795.8975830078125
[Actor] Episode 4 Step 7 Loss: 835.8165283203125
[Actor] Episode 4 Step 8 Loss: 807.2592163085938
[Actor] Episode 4 Step 9 Loss: 833.4659423828125
[Actor] Episode 4 Step 10 Loss: 700.5607299804688
[Actor] Episode 4 Step 11 Loss: 684.6427612304688
[Actor] Episode 4 Step 12 Loss: 682.66357421875
[Actor] Episode 4 Step 13 Loss: 828.7830200195312
[Actor] Episode 4 Step 14 Loss: 684.443115234375
[Actor] Episode 4 Step 15 Loss: 798.6753540039062
[Actor] Episode 4 Step 16 Loss: 608.888916015625
[Actor] Episode 4 Step 17 Loss: 743.088134765625
[Actor] Episode 4 Step 18 Loss: 804.1433715820312
[Actor] Episode 4 Step 19 Loss: 833.182373046875
[Actor] Episode 4 Step 20 Loss: 716.5038452148438
[Actor] Episode 4 Step 21 Loss: 768.8053588867188
[Actor] Episode 4 Step 22 Loss: 742.0098266601562
[Actor] Episode 4 Step 23 Loss: 737.5158081054688
[Actor] Episode 4 Step 24 Loss: 824.9223022460938
[Actor] Episode 4 Step 25 Loss: 733.7990112304688
[Actor] Episode 4 Step 26 Loss: 724.327392578125
-------------------------------------------------
[Actor] Episode 4 Average Loss: 768.812665020978
[Actor] Learning Rate: 0.0009818477556109428
[Actor] Epoch Time: 1170.7114362716675s
-------------------------------------------------
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 753.32568359375
[Actor] Episode 5 Step 1 Loss: 739.2908935546875
[Actor] Episode 5 Step 2 Loss: 663.966064453125
[Actor] Episode 5 Step 3 Loss: 784.1350708007812
[Actor] Episode 5 Step 4 Loss: 846.3869018554688
[Actor] Episode 5 Step 5 Loss: 672.78515625
[Actor] Episode 5 Step 6 Loss: 767.4061279296875
[Actor] Episode 5 Step 7 Loss: 830.8779296875
[Actor] Episode 5 Step 8 Loss: 685.6254272460938
[Actor] Episode 5 Step 9 Loss: 681.294189453125
[Actor] Episode 5 Step 10 Loss: 752.0921630859375
[Actor] Episode 5 Step 11 Loss: 790.8790893554688
[Actor] Episode 5 Step 12 Loss: 665.14501953125
[Actor] Episode 5 Step 13 Loss: 696.1603393554688
[Actor] Episode 5 Step 14 Loss: 650.8390502929688
[Actor] Episode 5 Step 15 Loss: 620.489501953125
[Actor] Episode 5 Step 16 Loss: 556.4080810546875
[Actor] Episode 5 Step 17 Loss: 685.6320190429688
[Actor] Episode 5 Step 18 Loss: 737.86767578125
[Actor] Episode 5 Step 19 Loss: 730.7401123046875
[Actor] Episode 5 Step 20 Loss: 594.3134155273438
[Actor] Episode 5 Step 21 Loss: 765.6741333007812
[Actor] Episode 5 Step 22 Loss: 738.8511352539062
[Actor] Episode 5 Step 23 Loss: 673.3271484375
[Actor] Episode 5 Step 24 Loss: 725.3469848632812
[Actor] Episode 5 Step 25 Loss: 779.7463989257812
[Actor] Episode 5 Step 26 Loss: 809.2454833984375
-------------------------------------------------
[Actor] Episode 5 Average Loss: 718.4389331958912
[Actor] Learning Rate: 0.0009782570414245129
[Actor] Epoch Time: 1067.4364786148071s
-------------------------------------------------
[Actor] Starting Episode 6
[Actor] Episode 6 Step 0 Loss: 644.0234375
[Actor] Episode 6 Step 1 Loss: 690.6748657226562
[Actor] Episode 6 Step 2 Loss: 685.4011840820312
[Actor] Episode 6 Step 3 Loss: 620.9635620117188
[Actor] Episode 6 Step 4 Loss: 639.7554321289062
[Actor] Episode 6 Step 5 Loss: 666.1900634765625
[Actor] Episode 6 Step 6 Loss: 734.4744873046875
[Actor] Episode 6 Step 7 Loss: 780.4843139648438
[Actor] Episode 6 Step 8 Loss: 607.1014404296875
[Actor] Episode 6 Step 9 Loss: 757.3408813476562
[Actor] Episode 6 Step 10 Loss: 617.8233032226562
[Actor] Episode 6 Step 11 Loss: 818.451416015625
[Actor] Episode 6 Step 12 Loss: 589.295166015625
[Actor] Episode 6 Step 13 Loss: 690.9360961914062
[Actor] Episode 6 Step 14 Loss: 641.5660400390625
[Actor] Episode 6 Step 15 Loss: 647.2883911132812
[Actor] Episode 6 Step 16 Loss: 743.056396484375
[Actor] Episode 6 Step 17 Loss: 725.6209106445312
[Actor] Episode 6 Step 18 Loss: 680.0374755859375
[Actor] Episode 6 Step 19 Loss: 668.9305419921875
[Actor] Episode 6 Step 20 Loss: 630.8067626953125
[Actor] Episode 6 Step 21 Loss: 604.9512329101562
[Actor] Episode 6 Step 22 Loss: 575.1173095703125
[Actor] Episode 6 Step 23 Loss: 706.4556884765625
[Actor] Episode 6 Step 24 Loss: 690.96044921875
[Actor] Episode 6 Step 25 Loss: 670.4114990234375
[Actor] Episode 6 Step 26 Loss: 523.4332275390625
-------------------------------------------------
[Actor] Episode 6 Average Loss: 668.5759842484085
[Actor] Learning Rate: 0.0009746794239617884
[Actor] Epoch Time: 1076.2033007144928s
-------------------------------------------------
[Actor] Starting Episode 7
[Actor] Episode 7 Step 0 Loss: 732.9488525390625
[Actor] Episode 7 Step 1 Loss: 720.2437133789062
[Actor] Episode 7 Step 2 Loss: 683.8771362304688
[Actor] Episode 7 Step 3 Loss: 712.80517578125
[Actor] Episode 7 Step 4 Loss: 657.2897338867188
[Actor] Episode 7 Step 5 Loss: 595.0869140625
[Actor] Episode 7 Step 6 Loss: 648.719970703125
[Actor] Episode 7 Step 7 Loss: 748.003662109375
[Actor] Episode 7 Step 8 Loss: 593.3131103515625
[Actor] Episode 7 Step 9 Loss: 691.9284057617188
[Actor] Episode 7 Step 10 Loss: 617.1388549804688
[Actor] Episode 7 Step 11 Loss: 724.4486083984375
[Actor] Episode 7 Step 12 Loss: 752.280029296875
[Actor] Episode 7 Step 13 Loss: 667.1917114257812
[Actor] Episode 7 Step 14 Loss: 630.639404296875
[Actor] Episode 7 Step 15 Loss: 640.6656494140625
[Actor] Episode 7 Step 16 Loss: 663.2469482421875
[Actor] Episode 7 Step 17 Loss: 652.3917236328125
[Actor] Episode 7 Step 18 Loss: 590.068603515625
[Actor] Episode 7 Step 19 Loss: 634.1270141601562
[Actor] Episode 7 Step 20 Loss: 721.9310913085938
[Actor] Episode 7 Step 21 Loss: 591.5343627929688
[Actor] Episode 7 Step 22 Loss: 729.9594116210938
[Actor] Episode 7 Step 23 Loss: 529.2147216796875
[Actor] Episode 7 Step 24 Loss: 624.4511108398438
[Actor] Episode 7 Step 25 Loss: 683.6860961914062
[Actor] Episode 7 Step 26 Loss: 618.1585083007812
-------------------------------------------------
[Actor] Episode 7 Average Loss: 661.3092787000868
[Actor] Learning Rate: 0.0009711149032227695
[Actor] Epoch Time: 1071.7817211151123s
-------------------------------------------------
[Actor] Starting Episode 8
[Actor] Episode 8 Step 0 Loss: 608.2587280273438
[Actor] Episode 8 Step 1 Loss: 669.037353515625
[Actor] Episode 8 Step 2 Loss: 671.6884765625
[Actor] Episode 8 Step 3 Loss: 715.57763671875
[Actor] Episode 8 Step 4 Loss: 648.6188354492188
[Actor] Episode 8 Step 5 Loss: 646.7531127929688
[Actor] Episode 8 Step 6 Loss: 709.9309692382812
[Actor] Episode 8 Step 7 Loss: 632.6023559570312
[Actor] Episode 8 Step 8 Loss: 601.2470703125
[Actor] Episode 8 Step 9 Loss: 724.0471801757812
[Actor] Episode 8 Step 10 Loss: 620.4959106445312
[Actor] Episode 8 Step 11 Loss: 590.2521362304688
[Actor] Episode 8 Step 12 Loss: 663.6053466796875
[Actor] Episode 8 Step 13 Loss: 600.0581665039062
[Actor] Episode 8 Step 14 Loss: 592.8856201171875
[Actor] Episode 8 Step 15 Loss: 756.2810668945312
[Actor] Episode 8 Step 16 Loss: 692.4268188476562
[Actor] Episode 8 Step 17 Loss: 612.9993896484375
[Actor] Episode 8 Step 18 Loss: 600.07861328125
[Actor] Episode 8 Step 19 Loss: 675.7114868164062
[Actor] Episode 8 Step 20 Loss: 539.94580078125
[Actor] Episode 8 Step 21 Loss: 657.6118774414062
[Actor] Episode 8 Step 22 Loss: 620.6876220703125
[Actor] Episode 8 Step 23 Loss: 615.60107421875
[Actor] Episode 8 Step 24 Loss: 604.8947143554688
[Actor] Episode 8 Step 25 Loss: 717.8157348632812
[Actor] Episode 8 Step 26 Loss: 697.1611328125
-------------------------------------------------
[Actor] Episode 8 Average Loss: 647.6397863317419
[Actor] Learning Rate: 0.0009675634209997952
[Actor] Epoch Time: 1205.3937096595764s
-------------------------------------------------
[Actor] Starting Episode 9
[Actor] Episode 9 Step 0 Loss: 632.1488647460938
[Actor] Episode 9 Step 1 Loss: 565.2777099609375
[Actor] Episode 9 Step 2 Loss: 502.0123291015625
[Actor] Episode 9 Step 3 Loss: 653.7673950195312
[Actor] Episode 9 Step 4 Loss: 630.1260986328125
[Actor] Episode 9 Step 5 Loss: 488.598876953125
[Actor] Episode 9 Step 6 Loss: 597.5306396484375
[Actor] Episode 9 Step 7 Loss: 697.10107421875
[Actor] Episode 9 Step 8 Loss: 625.7816772460938
[Actor] Episode 9 Step 9 Loss: 655.7296142578125
[Actor] Episode 9 Step 10 Loss: 608.13525390625
[Actor] Episode 9 Step 11 Loss: 623.7335205078125
