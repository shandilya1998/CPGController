2021-03-30 07:02:27.955538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:34332): Gdk-CRITICAL **: 07:02:31.708: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-30 07:02:31.971438: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 07:02:31.972597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-30 07:02:32.002336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.003077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 07:02:32.003115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:02:32.006767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 07:02:32.006891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 07:02:32.008596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 07:02:32.008993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 07:02:32.013001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 07:02:32.013987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 07:02:32.014240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 07:02:32.014467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.015378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.016084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-30 07:02:32.245260: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-30 07:02:32.245491: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 07:02:32.245873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.246429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 07:02:32.246455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:02:32.246685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 07:02:32.246825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 07:02:32.246879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 07:02:32.246910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 07:02:32.246936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 07:02:32.246962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 07:02:32.246991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 07:02:32.247164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.248056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:32.248689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-30 07:02:32.248740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:02:33.073357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-30 07:02:33.073402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-30 07:02:33.073411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-30 07:02:33.073773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:33.074622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:33.075369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:02:33.076054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617087756.808490131, 7512.153000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617087756.809383960, 7512.153000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617087756.809563384, 7512.153000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617087757.967937830, 7513.272000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617087758.324907256, 7513.599000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617087758.758554065, 7514.000000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617087758.966005292, 7514.199000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] Creating Data.
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.18s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.18s/it]
[Actor] Number of Data Points: 135
0it [00:00, ?it/s]1it [00:06,  6.41s/it]2021-03-30 07:03:35.208335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:34569): Gdk-CRITICAL **: 07:03:38.366: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-30 07:03:38.598670: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 07:03:38.599866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-30 07:03:38.631740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.632638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 07:03:38.632669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:03:38.636950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 07:03:38.637105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 07:03:38.638987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 07:03:38.639510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 07:03:38.643720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 07:03:38.644806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 07:03:38.645074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 07:03:38.645378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.646259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.647093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-30 07:03:38.874679: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-30 07:03:38.874968: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 07:03:38.875309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.876119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 07:03:38.876167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:03:38.876378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 07:03:38.876482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 07:03:38.876575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 07:03:38.876652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 07:03:38.876732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 07:03:38.876827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 07:03:38.876911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 07:03:38.877098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.877929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:38.878617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-30 07:03:38.878668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 07:03:39.700178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-30 07:03:39.700225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-30 07:03:39.700237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-30 07:03:39.700617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:39.701531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:39.702326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 07:03:39.703055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617087823.284056175, 7573.196000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617087823.285524314, 7573.201000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617087823.285577994, 7573.201000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617087824.471478346, 7574.335000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617087824.743106544, 7574.600000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617087825.432763603, 7575.199000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617087825.849440540, 7575.600000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-30 07:03:58.442529: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-30 07:04:02.601107: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
2021-03-30 07:04:09.069165: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float32, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 0
2021-03-30 07:04:13.198161: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-30 07:04:16.123201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 07:04:16.872222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 0 Step 0 Loss: 2.4514546394348145
[Actor] Episode 0 Step 1 Loss: 2.119870185852051
[Actor] Episode 0 Step 2 Loss: 1.873120665550232
[Actor] Episode 0 Step 3 Loss: 1.6693813800811768
[Actor] Episode 0 Step 4 Loss: 1.526763916015625
[Actor] Episode 0 Step 5 Loss: 1.4107123613357544
[Actor] Episode 0 Step 6 Loss: 1.2989501953125
[Actor] Episode 0 Step 7 Loss: 1.2030123472213745
[Actor] Episode 0 Step 8 Loss: 1.127565860748291
[Actor] Episode 0 Step 9 Loss: 1.0667834281921387
[Actor] Episode 0 Step 10 Loss: 1.021525263786316
[Actor] Episode 0 Step 11 Loss: 0.9923293590545654
[Actor] Episode 0 Step 12 Loss: 0.9690917730331421
[Actor] Episode 0 Step 13 Loss: 0.9474021196365356
[Actor] Episode 0 Step 14 Loss: 0.9260697960853577
[Actor] Episode 0 Step 15 Loss: 0.9076623320579529
[Actor] Episode 0 Step 16 Loss: 0.8993671536445618
[Actor] Episode 0 Step 17 Loss: 0.8845163583755493
[Actor] Episode 0 Step 18 Loss: 0.8770095109939575
[Actor] Episode 0 Step 19 Loss: 0.8717666864395142
[Actor] Episode 0 Step 20 Loss: 0.8624897599220276
[Actor] Episode 0 Step 21 Loss: 0.8536728620529175
[Actor] Episode 0 Step 22 Loss: 0.8467801213264465
[Actor] Episode 0 Step 23 Loss: 0.8404080867767334
[Actor] Episode 0 Step 24 Loss: 0.836898148059845
[Actor] Episode 0 Step 25 Loss: 0.8288914561271667
[Actor] Episode 0 Step 26 Loss: 0.8248893022537231
-------------------------------------------------
[Actor] Episode 0 Average Loss: 1.1458661136803803
[Actor] Learning Rate: 0.004978673066943884
[Actor] Epoch Time: 1420.9856860637665s
-------------------------------------------------
[Actor] Starting Episode 1
2021-03-30 07:27:54.405228: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Episode 1 Step 0 Loss: 0.8217421770095825
[Actor] Episode 1 Step 1 Loss: 0.8195392489433289
[Actor] Episode 1 Step 2 Loss: 0.8142460584640503
[Actor] Episode 1 Step 3 Loss: 0.8148167133331299
[Actor] Episode 1 Step 4 Loss: 0.8105827569961548
[Actor] Episode 1 Step 5 Loss: 0.8082152009010315
[Actor] Episode 1 Step 6 Loss: 0.8048093318939209
[Actor] Episode 1 Step 7 Loss: 0.8011322021484375
[Actor] Episode 1 Step 8 Loss: 0.8023213744163513
[Actor] Episode 1 Step 9 Loss: 0.8008822798728943
[Actor] Episode 1 Step 10 Loss: 0.8010032176971436
[Actor] Episode 1 Step 11 Loss: 0.7949587106704712
[Actor] Episode 1 Step 12 Loss: 0.7966514229774475
[Actor] Episode 1 Step 13 Loss: 0.7951451539993286
[Actor] Episode 1 Step 14 Loss: 0.7936782240867615
[Actor] Episode 1 Step 15 Loss: 0.7933036684989929
[Actor] Episode 1 Step 16 Loss: 0.790453314781189
[Actor] Episode 1 Step 17 Loss: 0.7923654913902283
[Actor] Episode 1 Step 18 Loss: 0.7898129224777222
[Actor] Episode 1 Step 19 Loss: 0.7902254462242126
[Actor] Episode 1 Step 20 Loss: 0.7890639901161194
[Actor] Episode 1 Step 21 Loss: 0.7864766120910645
[Actor] Episode 1 Step 22 Loss: 0.7874579429626465
[Actor] Episode 1 Step 23 Loss: 0.7873121500015259
[Actor] Episode 1 Step 24 Loss: 0.7864499688148499
[Actor] Episode 1 Step 25 Loss: 0.7861366271972656
[Actor] Episode 1 Step 26 Loss: 0.7871373295783997
-------------------------------------------------
[Actor] Episode 1 Average Loss: 0.7979970199090464
[Actor] Learning Rate: 0.004957437515258789
[Actor] Epoch Time: 1395.9853777885437s
-------------------------------------------------
[Actor] Starting Episode 2
[Actor] Episode 2 Step 0 Loss: 0.7852481603622437
[Actor] Episode 2 Step 1 Loss: 0.7847862243652344
[Actor] Episode 2 Step 2 Loss: 0.7861778736114502
[Actor] Episode 2 Step 3 Loss: 0.7844954133033752
[Actor] Episode 2 Step 4 Loss: 0.784614086151123
[Actor] Episode 2 Step 5 Loss: 0.7847442030906677
[Actor] Episode 2 Step 6 Loss: 0.782712996006012
[Actor] Episode 2 Step 7 Loss: 0.7838534116744995
[Actor] Episode 2 Step 8 Loss: 0.7825840711593628
[Actor] Episode 2 Step 9 Loss: 0.7834962010383606
[Actor] Episode 2 Step 10 Loss: 0.7831941843032837
[Actor] Episode 2 Step 11 Loss: 0.7825035452842712
[Actor] Episode 2 Step 12 Loss: 0.7835193872451782
[Actor] Episode 2 Step 13 Loss: 0.7814739942550659
[Actor] Episode 2 Step 14 Loss: 0.7831694483757019
[Actor] Episode 2 Step 15 Loss: 0.7827858924865723
[Actor] Episode 2 Step 16 Loss: 0.7821947336196899
[Actor] Episode 2 Step 17 Loss: 0.7819312214851379
[Actor] Episode 2 Step 18 Loss: 0.7817820310592651
[Actor] Episode 2 Step 19 Loss: 0.7813363671302795
[Actor] Episode 2 Step 20 Loss: 0.7815378308296204
[Actor] Episode 2 Step 21 Loss: 0.7811321020126343
[Actor] Episode 2 Step 22 Loss: 0.7804086804389954
[Actor] Episode 2 Step 23 Loss: 0.783030092716217
[Actor] Episode 2 Step 24 Loss: 0.7810598015785217
[Actor] Episode 2 Step 25 Loss: 0.7825294733047485
[Actor] Episode 2 Step 26 Loss: 0.7815296053886414
-------------------------------------------------
[Actor] Episode 2 Average Loss: 0.7828826308250427
[Actor] Learning Rate: 0.004936292767524719
[Actor] Epoch Time: 1144.716560602188s
-------------------------------------------------
[Actor] Starting Episode 3
[Actor] Episode 3 Step 0 Loss: 0.780141294002533
[Actor] Episode 3 Step 1 Loss: 0.7797914147377014
[Actor] Episode 3 Step 2 Loss: 0.7827180624008179
[Actor] Episode 3 Step 3 Loss: 0.7812072038650513
[Actor] Episode 3 Step 4 Loss: 0.7812408208847046
[Actor] Episode 3 Step 5 Loss: 0.7818519473075867
[Actor] Episode 3 Step 6 Loss: 0.7818911671638489
[Actor] Episode 3 Step 7 Loss: 0.7804075479507446
[Actor] Episode 3 Step 8 Loss: 0.781941294670105
[Actor] Episode 3 Step 9 Loss: 0.7789999842643738
[Actor] Episode 3 Step 10 Loss: 0.7787753939628601
[Actor] Episode 3 Step 11 Loss: 0.7806854248046875
[Actor] Episode 3 Step 12 Loss: 0.7808261513710022
[Actor] Episode 3 Step 13 Loss: 0.7784878611564636
[Actor] Episode 3 Step 14 Loss: 0.7791956067085266
[Actor] Episode 3 Step 15 Loss: 0.778759241104126
[Actor] Episode 3 Step 16 Loss: 0.780268132686615
[Actor] Episode 3 Step 17 Loss: 0.7806366086006165
[Actor] Episode 3 Step 18 Loss: 0.7806519865989685
[Actor] Episode 3 Step 19 Loss: 0.7800101041793823
[Actor] Episode 3 Step 20 Loss: 0.7803255319595337
[Actor] Episode 3 Step 21 Loss: 0.7784533500671387
[Actor] Episode 3 Step 22 Loss: 0.7790887355804443
[Actor] Episode 3 Step 23 Loss: 0.7810935974121094
[Actor] Episode 3 Step 24 Loss: 0.7799997329711914
[Actor] Episode 3 Step 25 Loss: 0.7806952595710754
[Actor] Episode 3 Step 26 Loss: 0.7799387574195862
-------------------------------------------------
[Actor] Episode 3 Average Loss: 0.7802993412371035
[Actor] Learning Rate: 0.0049152374267578125
[Actor] Epoch Time: 1146.8915886878967s
-------------------------------------------------
[Actor] Starting Episode 4
[Actor] Episode 4 Step 0 Loss: 0.7803746461868286
[Actor] Episode 4 Step 1 Loss: 0.7809281945228577
[Actor] Episode 4 Step 2 Loss: 0.7793484926223755
[Actor] Episode 4 Step 3 Loss: 0.7806228995323181
[Actor] Episode 4 Step 4 Loss: 0.7801851034164429
[Actor] Episode 4 Step 5 Loss: 0.7785038352012634
[Actor] Episode 4 Step 6 Loss: 0.7794370651245117
[Actor] Episode 4 Step 7 Loss: 0.7778347134590149
[Actor] Episode 4 Step 8 Loss: 0.7792807817459106
[Actor] Episode 4 Step 9 Loss: 0.7787619829177856
[Actor] Episode 4 Step 10 Loss: 0.7804109454154968
[Actor] Episode 4 Step 11 Loss: 0.7785335183143616
[Actor] Episode 4 Step 12 Loss: 0.7785836458206177
[Actor] Episode 4 Step 13 Loss: 0.779228925704956
[Actor] Episode 4 Step 14 Loss: 0.7774674296379089
[Actor] Episode 4 Step 15 Loss: 0.7787953019142151
[Actor] Episode 4 Step 16 Loss: 0.7800412774085999
[Actor] Episode 4 Step 17 Loss: 0.7775749564170837
[Actor] Episode 4 Step 18 Loss: 0.7796139121055603
[Actor] Episode 4 Step 19 Loss: 0.7788739204406738
[Actor] Episode 4 Step 20 Loss: 0.7799898982048035
[Actor] Episode 4 Step 21 Loss: 0.7784156799316406
[Actor] Episode 4 Step 22 Loss: 0.7796195149421692
[Actor] Episode 4 Step 23 Loss: 0.7773704528808594
[Actor] Episode 4 Step 24 Loss: 0.7787078619003296
[Actor] Episode 4 Step 25 Loss: 0.779778003692627
[Actor] Episode 4 Step 26 Loss: 0.7791671752929688
-------------------------------------------------
[Actor] Episode 4 Average Loss: 0.7791648198057104
[Actor] Learning Rate: 0.004894272889941931
[Actor] Epoch Time: 1158.6188700199127s
-------------------------------------------------
[Actor] Starting Episode 5
[Actor] Episode 5 Step 0 Loss: 0.7790926694869995
[Actor] Episode 5 Step 1 Loss: 0.7803983688354492
[Actor] Episode 5 Step 2 Loss: 0.7780107855796814
[Actor] Episode 5 Step 3 Loss: 0.7783096432685852
[Actor] Episode 5 Step 4 Loss: 0.7791686058044434
[Actor] Episode 5 Step 5 Loss: 0.7782403826713562
[Actor] Episode 5 Step 6 Loss: 0.7795699834823608
[Actor] Episode 5 Step 7 Loss: 0.7799346446990967
[Actor] Episode 5 Step 8 Loss: 0.7781473398208618
[Actor] Episode 5 Step 9 Loss: 0.7789384126663208
[Actor] Episode 5 Step 10 Loss: 0.7802443504333496
[Actor] Episode 5 Step 11 Loss: 0.7799563407897949
[Actor] Episode 5 Step 12 Loss: 0.7788281440734863
[Actor] Episode 5 Step 13 Loss: 0.7786102294921875
[Actor] Episode 5 Step 14 Loss: 0.7790616750717163
[Actor] Episode 5 Step 15 Loss: 0.7789537906646729
[Actor] Episode 5 Step 16 Loss: 0.7787753939628601
[Actor] Episode 5 Step 17 Loss: 0.7784127593040466
[Actor] Episode 5 Step 18 Loss: 0.7790330648422241
[Actor] Episode 5 Step 19 Loss: 0.7779955267906189
[Actor] Episode 5 Step 20 Loss: 0.7780202627182007
[Actor] Episode 5 Step 21 Loss: 0.7783637642860413
[Actor] Episode 5 Step 22 Loss: 0.7793259024620056
[Actor] Episode 5 Step 23 Loss: 0.7786122560501099
[Actor] Episode 5 Step 24 Loss: 0.7768312096595764
[Actor] Episode 5 Step 25 Loss: 0.7770978212356567
[Actor] Episode 5 Step 26 Loss: 0.7804821133613586
-------------------------------------------------
[Actor] Episode 5 Average Loss: 0.7788302015375208
[Actor] Learning Rate: 0.0048733968287706375
[Actor] Epoch Time: 1405.6199021339417s
-------------------------------------------------
[Actor] Starting Episode 6
2021-03-30 09:24:34.598855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:35892): Gdk-CRITICAL **: 09:24:43.899: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-30 09:24:44.481083: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:24:44.482671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-30 09:24:44.522477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.523481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:24:44.523517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:24:44.546260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:24:44.546439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:24:44.569059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:24:44.577630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:24:44.613444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:24:44.620452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:24:44.623197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:24:44.623492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.625392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.626237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-30 09:24:44.876393: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-30 09:24:44.876757: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:24:44.877067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.877779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:24:44.877809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:24:44.877983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:24:44.878032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:24:44.878070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:24:44.878105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:24:44.878139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:24:44.878180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:24:44.878215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:24:44.878341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.878957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:44.879450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-30 09:24:44.880627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:24:46.903344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-30 09:24:46.903379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-30 09:24:46.903386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-30 09:24:46.904904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:46.905898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:46.906800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:24:46.907634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617096290.823189577, 14834.109000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617096290.824107696, 14834.110000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617096290.824198547, 14834.110000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617096292.198797357, 14835.432000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617096292.581164999, 14835.799000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617096292.994925308, 14836.199000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617096293.407831381, 14836.600000000]: Ready to take commands for planning group back_left_leg.[0m
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for weights/actor_pretrain/exp21/pretrain_enc/actor_pretrained_pretrain_actor_21_3.ckpt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "learn.py", line 1048, in <module>
    learner.load_actor(
  File "learn.py", line 607, in load_actor
    self.actor.model.load_weights(path)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 2199, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 99, in NewCheckpointReader
    error_translator(e)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for weights/actor_pretrain/exp21/pretrain_enc/actor_pretrained_pretrain_actor_21_3.ckpt
2021-03-30 09:25:39.050506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:36081): Gdk-CRITICAL **: 09:25:42.192: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-30 09:25:42.421395: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:25:42.422592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-30 09:25:42.450730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.451434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:25:42.451468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:25:42.455437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:25:42.455566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:25:42.457357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:25:42.457793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:25:42.461896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:25:42.462707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:25:42.462975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:25:42.463163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.464089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.464767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-30 09:25:42.702497: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-30 09:25:42.702764: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:25:42.703105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.703837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:25:42.703878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:25:42.704129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:25:42.704208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:25:42.704280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:25:42.704358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:25:42.704435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:25:42.704511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:25:42.704590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:25:42.704766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.705566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:42.706267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-30 09:25:42.706313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:25:43.515766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-30 09:25:43.515823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-30 09:25:43.515836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-30 09:25:43.516171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:43.517146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:43.517990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:25:43.518691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617096347.008874712, 14884.853000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617096347.009829231, 14884.853000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617096347.009888726, 14884.853000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617096348.186658609, 14885.974000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617096348.636054323, 14886.400000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617096348.841019276, 14886.599000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617096349.255392531, 14886.999000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-30 09:26:30.764331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(learn.py:36230): Gdk-CRITICAL **: 09:26:33.927: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
2021-03-30 09:26:34.153251: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:26:34.154502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-30 09:26:34.181619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.182403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:26:34.182437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:26:34.185964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:26:34.186072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:26:34.187684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:26:34.188052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:26:34.192343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:26:34.193270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:26:34.193548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:26:34.193731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.194494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.195201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
[DDPG] Building the actor model
2021-03-30 09:26:34.419296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-30 09:26:34.419532: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-30 09:26:34.419855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.420594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-03-30 09:26:34.420632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:26:34.420801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:26:34.420867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-30 09:26:34.420918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-30 09:26:34.420968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-30 09:26:34.421022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-30 09:26:34.421067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-30 09:26:34.421120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-30 09:26:34.421286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.422086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:34.422726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-30 09:26:34.422773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-30 09:26:35.221047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-30 09:26:35.221099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-30 09:26:35.221112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-30 09:26:35.221520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:35.222362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:35.223240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-30 09:26:35.223979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11669 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[DDPG] Building the actor model
[DDPG] Building the critic model
[DDPG] Building the critic model
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[DDPG] Waiting for joint trajectory action
[DDPG] Found joint trajectory action!
[0m[ INFO] [1617096398.787091636, 14934.587000000]: Loading robot model 'quadruped'...[0m
[0m[ INFO] [1617096398.788212760, 14934.587000000]: No root/virtual joint specified in SRDF. Assuming fixed joint[0m
[33m[ WARN] [1617096398.788292966, 14934.587000000]: Link dummy_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.[0m
[0m[ INFO] [1617096399.971825486, 14935.723000000]: Ready to take commands for planning group front_right_leg.[0m
[0m[ INFO] [1617096400.263256612, 14935.999000000]: Ready to take commands for planning group front_left_leg.[0m
[0m[ INFO] [1617096400.677110401, 14936.399000000]: Ready to take commands for planning group back_right_leg.[0m
[0m[ INFO] [1617096401.326259689, 14937.000000000]: Ready to take commands for planning group back_left_leg.[0m
2021-03-30 09:26:54.006479: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-30 09:26:58.251331: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] GPU>>>>>>>>>>>>
[Actor] [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[Actor] Memory Growth Allowed
[DDPG] Loading Actor Weights
2021-03-30 09:27:04.894810: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Dataset <PrefetchDataset shapes: (((1125, 6), (1125, 34), (1125, 60)), ((1125, 350, 12), (1125, 1), (1125, 12), (1125, 12))), types: ((tf.float32, tf.float32, tf.float64), (tf.float32, tf.float32, tf.float32, tf.float32))>
[Actor] Starting Actor Pretraining
[Actor] Starting Episode 4
2021-03-30 09:27:09.021217: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
2021-03-30 09:27:11.492017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-30 09:27:13.217981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
[Actor] Episode 4 Step 0 Loss: 0.7808271646499634
[Actor] Episode 4 Step 1 Loss: 0.8708877563476562
[Actor] Episode 4 Step 2 Loss: 0.7971894145011902
[Actor] Episode 4 Step 3 Loss: 0.8107984662055969
[Actor] Episode 4 Step 4 Loss: 0.8135375380516052
[Actor] Episode 4 Step 5 Loss: 0.8084062337875366
[Actor] Episode 4 Step 6 Loss: 0.798500657081604
[Actor] Episode 4 Step 7 Loss: 0.7931340932846069
[Actor] Episode 4 Step 8 Loss: 0.792288601398468
[Actor] Episode 4 Step 9 Loss: 0.7942415475845337
[Actor] Episode 4 Step 10 Loss: 0.7930254340171814
[Actor] Episode 4 Step 11 Loss: 0.7896584272384644
[Actor] Episode 4 Step 12 Loss: 0.7922728657722473
[Actor] Episode 4 Step 13 Loss: 0.7861103415489197
[Actor] Episode 4 Step 14 Loss: 0.78413987159729
[Actor] Episode 4 Step 15 Loss: 0.785962700843811
[Actor] Episode 4 Step 16 Loss: 0.7863619923591614
[Actor] Episode 4 Step 17 Loss: 0.7873111367225647
[Actor] Episode 4 Step 18 Loss: 0.7855628132820129
[Actor] Episode 4 Step 19 Loss: 0.7830468416213989
[Actor] Episode 4 Step 20 Loss: 0.781524658203125
[Actor] Episode 4 Step 21 Loss: 0.7814324498176575
[Actor] Episode 4 Step 22 Loss: 0.7834281921386719
[Actor] Episode 4 Step 23 Loss: 0.7811203002929688
[Actor] Episode 4 Step 24 Loss: 0.7814880609512329
[Actor] Episode 4 Step 25 Loss: 0.7801619172096252
[Actor] Episode 4 Step 26 Loss: 0.782901406288147
-------------------------------------------------
[Actor] Episode 4 Average Loss: 0.7927896623258237
[Actor] Learning Rate: 0.004894272889941931
[Actor] Epoch Time: 1470.2757849693298s
-------------------------------------------------
[Actor] Starting Episode 5
2021-03-30 09:51:39.299708: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 793800000 exceeds 10% of free system memory.
[Actor] Episode 5 Step 0 Loss: 0.7821373343467712
[Actor] Episode 5 Step 1 Loss: 0.7824878096580505
[Actor] Episode 5 Step 2 Loss: 0.7811692357063293
[Actor] Episode 5 Step 3 Loss: 0.7797587513923645
[Actor] Episode 5 Step 4 Loss: 0.7809581756591797
[Actor] Episode 5 Step 5 Loss: 0.7815287113189697
[Actor] Episode 5 Step 6 Loss: 0.7830824255943298
[Actor] Episode 5 Step 7 Loss: 0.7813121676445007
[Actor] Episode 5 Step 8 Loss: 0.781464695930481
[Actor] Episode 5 Step 9 Loss: 0.7810435891151428
[Actor] Episode 5 Step 10 Loss: 0.7800402641296387
[Actor] Episode 5 Step 11 Loss: 0.7814895510673523
[Actor] Episode 5 Step 12 Loss: 0.7795573472976685
[Actor] Episode 5 Step 13 Loss: 0.7787306904792786
[Actor] Episode 5 Step 14 Loss: 0.7804125547409058
[Actor] Episode 5 Step 15 Loss: 0.7776326537132263
[Actor] Episode 5 Step 16 Loss: 0.7784331440925598
[Actor] Episode 5 Step 17 Loss: 0.7797830700874329
[Actor] Episode 5 Step 18 Loss: 0.7807360291481018
[Actor] Episode 5 Step 19 Loss: 0.778810977935791
[Actor] Episode 5 Step 20 Loss: 0.7798754572868347
[Actor] Episode 5 Step 21 Loss: 0.7792338132858276
[Actor] Episode 5 Step 22 Loss: 0.7800267934799194
[Actor] Episode 5 Step 23 Loss: 0.7794805765151978
[Actor] Episode 5 Step 24 Loss: 0.780092716217041
[Actor] Episode 5 Step 25 Loss: 0.7783371806144714
[Actor] Episode 5 Step 26 Loss: 0.7802218198776245
-------------------------------------------------
[Actor] Episode 5 Average Loss: 0.7802902791235182
[Actor] Learning Rate: 0.0048733968287706375
[Actor] Epoch Time: 1480.0983278751373s
-------------------------------------------------
[Actor] Starting Episode 6
[Actor] Episode 6 Step 0 Loss: 0.7799832224845886
[Actor] Episode 6 Step 1 Loss: 0.7794478535652161
[Actor] Episode 6 Step 2 Loss: 0.7792362570762634
[Actor] Episode 6 Step 3 Loss: 0.7788011431694031
[Actor] Episode 6 Step 4 Loss: 0.778644323348999
[Actor] Episode 6 Step 5 Loss: 0.7801888585090637
[Actor] Episode 6 Step 6 Loss: 0.7790161967277527
[Actor] Episode 6 Step 7 Loss: 0.78116774559021
[Actor] Episode 6 Step 8 Loss: 0.7800467014312744
[Actor] Episode 6 Step 9 Loss: 0.779566764831543
[Actor] Episode 6 Step 10 Loss: 0.780163586139679
[Actor] Episode 6 Step 11 Loss: 0.780457615852356
[Actor] Episode 6 Step 12 Loss: 0.7808958292007446
[Actor] Episode 6 Step 13 Loss: 0.7801727652549744
[Actor] Episode 6 Step 14 Loss: 0.7797373533248901
[Actor] Episode 6 Step 15 Loss: 0.7794374823570251
[Actor] Episode 6 Step 16 Loss: 0.7781106233596802
[Actor] Episode 6 Step 17 Loss: 0.7799819111824036
[Actor] Episode 6 Step 18 Loss: 0.7813272476196289
[Actor] Episode 6 Step 19 Loss: 0.7785527110099792
[Actor] Episode 6 Step 20 Loss: 0.7798136472702026
[Actor] Episode 6 Step 21 Loss: 0.7793869376182556
[Actor] Episode 6 Step 22 Loss: 0.7791556715965271
[Actor] Episode 6 Step 23 Loss: 0.779829204082489
[Actor] Episode 6 Step 24 Loss: 0.7814635038375854
[Actor] Episode 6 Step 25 Loss: 0.7776116132736206
[Actor] Episode 6 Step 26 Loss: 0.7804973125457764
-------------------------------------------------
[Actor] Episode 6 Average Loss: 0.779729410454079
[Actor] Learning Rate: 0.004852610174566507
[Actor] Epoch Time: 1495.2178092002869s
-------------------------------------------------
[Actor] Starting Episode 7
[Actor] Episode 7 Step 0 Loss: 0.7804966568946838
[Actor] Episode 7 Step 1 Loss: 0.7789384126663208
[Actor] Episode 7 Step 2 Loss: 0.7788198590278625
[Actor] Episode 7 Step 3 Loss: 0.7795531749725342
[Actor] Episode 7 Step 4 Loss: 0.7783656716346741
[Actor] Episode 7 Step 5 Loss: 0.7782194018363953
[Actor] Episode 7 Step 6 Loss: 0.7790407538414001
[Actor] Episode 7 Step 7 Loss: 0.7795376181602478
[Actor] Episode 7 Step 8 Loss: 0.7803223729133606
[Actor] Episode 7 Step 9 Loss: 0.779228150844574
[Actor] Episode 7 Step 10 Loss: 0.7768740653991699
[Actor] Episode 7 Step 11 Loss: 0.7778211236000061
[Actor] Episode 7 Step 12 Loss: 0.7782377004623413
[Actor] Episode 7 Step 13 Loss: 0.7777537703514099
[Actor] Episode 7 Step 14 Loss: 0.7795836329460144
[Actor] Episode 7 Step 15 Loss: 0.7818254232406616
[Actor] Episode 7 Step 16 Loss: 0.7806866765022278
[Actor] Episode 7 Step 17 Loss: 0.7793287038803101
[Actor] Episode 7 Step 18 Loss: 0.7789338231086731
[Actor] Episode 7 Step 19 Loss: 0.7790484428405762
[Actor] Episode 7 Step 20 Loss: 0.7787975072860718
[Actor] Episode 7 Step 21 Loss: 0.7806652784347534
[Actor] Episode 7 Step 22 Loss: 0.779902994632721
[Actor] Episode 7 Step 23 Loss: 0.7781906723976135
[Actor] Episode 7 Step 24 Loss: 0.7774670720100403
[Actor] Episode 7 Step 25 Loss: 0.7775127291679382
[Actor] Episode 7 Step 26 Loss: 0.7791600227355957
-------------------------------------------------
[Actor] Episode 7 Average Loss: 0.7790485819180807
[Actor] Learning Rate: 0.004831912461668253
[Actor] Epoch Time: 1248.8987398147583s
-------------------------------------------------
[Actor] Starting Episode 8
[Actor] Episode 8 Step 0 Loss: 0.7807720303535461
[Actor] Episode 8 Step 1 Loss: 0.7770928144454956
[Actor] Episode 8 Step 2 Loss: 0.7784353494644165
[Actor] Episode 8 Step 3 Loss: 0.7799904346466064
[Actor] Episode 8 Step 4 Loss: 0.7782993912696838
[Actor] Episode 8 Step 5 Loss: 0.7783393263816833
[Actor] Episode 8 Step 6 Loss: 0.7799691557884216
[Actor] Episode 8 Step 7 Loss: 0.7775083184242249
[Actor] Episode 8 Step 8 Loss: 0.779193639755249
[Actor] Episode 8 Step 9 Loss: 0.780661940574646
[Actor] Episode 8 Step 10 Loss: 0.7786847352981567
[Actor] Episode 8 Step 11 Loss: 0.7798385620117188
[Actor] Episode 8 Step 12 Loss: 0.7796416282653809
[Actor] Episode 8 Step 13 Loss: 0.7788224220275879
[Actor] Episode 8 Step 14 Loss: 0.7784410119056702
[Actor] Episode 8 Step 15 Loss: 0.7791070938110352
[Actor] Episode 8 Step 16 Loss: 0.7798081636428833
[Actor] Episode 8 Step 17 Loss: 0.7790282964706421
[Actor] Episode 8 Step 18 Loss: 0.7788381576538086
[Actor] Episode 8 Step 19 Loss: 0.7785255312919617
[Actor] Episode 8 Step 20 Loss: 0.7772842645645142
[Actor] Episode 8 Step 21 Loss: 0.7809588313102722
[Actor] Episode 8 Step 22 Loss: 0.7797493934631348
[Actor] Episode 8 Step 23 Loss: 0.7785557508468628
[Actor] Episode 8 Step 24 Loss: 0.7805257439613342
[Actor] Episode 8 Step 25 Loss: 0.7780450582504272
[Actor] Episode 8 Step 26 Loss: 0.779068648815155
-------------------------------------------------
[Actor] Episode 8 Average Loss: 0.7790809516553525
[Actor] Learning Rate: 0.0048113027587533
[Actor] Epoch Time: 1408.1728088855743s
-------------------------------------------------
[Actor] Starting Episode 9
[Actor] Episode 9 Step 0 Loss: 0.7786721587181091
[Actor] Episode 9 Step 1 Loss: 0.7797269821166992
[Actor] Episode 9 Step 2 Loss: 0.7785446643829346
[Actor] Episode 9 Step 3 Loss: 0.7789536118507385
[Actor] Episode 9 Step 4 Loss: 0.778022825717926
[Actor] Episode 9 Step 5 Loss: 0.7777484655380249
[Actor] Episode 9 Step 6 Loss: 0.7805256247520447
[Actor] Episode 9 Step 7 Loss: 0.7778140902519226
[Actor] Episode 9 Step 8 Loss: 0.7769917249679565
[Actor] Episode 9 Step 9 Loss: 0.7788079380989075
[Actor] Episode 9 Step 10 Loss: 0.7777761816978455
[Actor] Episode 9 Step 11 Loss: 0.777199387550354
[Actor] Episode 9 Step 12 Loss: 0.7790317535400391
[Actor] Episode 9 Step 13 Loss: 0.7795364856719971
[Actor] Episode 9 Step 14 Loss: 0.7791869640350342
[Actor] Episode 9 Step 15 Loss: 0.7804422974586487
[Actor] Episode 9 Step 16 Loss: 0.7797385454177856
[Actor] Episode 9 Step 17 Loss: 0.7807822227478027
[Actor] Episode 9 Step 18 Loss: 0.7800967693328857
[Actor] Episode 9 Step 19 Loss: 0.7809869050979614
[Actor] Episode 9 Step 20 Loss: 0.7788611650466919
[Actor] Episode 9 Step 21 Loss: 0.7794392108917236
[Actor] Episode 9 Step 22 Loss: 0.780571699142456
[Actor] Episode 9 Step 23 Loss: 0.7798988223075867
[Actor] Episode 9 Step 24 Loss: 0.7794816493988037
[Actor] Episode 9 Step 25 Loss: 0.7796099185943604
[Actor] Episode 9 Step 26 Loss: 0.7805498838424683
-------------------------------------------------
[Actor] Episode 9 Average Loss: 0.7792221462285077
[Actor] Learning Rate: 0.004790781065821648
[Actor] Epoch Time: 1468.4933080673218s
-------------------------------------------------
[Actor] Starting Episode 10
